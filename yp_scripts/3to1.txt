Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_ettm1', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_ettm1_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=4.6223430252075195
Epoch #1: loss=2.46884654045105
Epoch #2: loss=2.150397052764893
Epoch #3: loss=2.094075698852539
Epoch #4: loss=1.8700350189208985
Epoch #5: loss=1.712248339653015
Epoch #6: loss=1.597791361808777
Epoch #7: loss=1.4836233234405518
Epoch #8: loss=1.3151738214492799
Epoch #9: loss=1.2872679710388184
Epoch #10: loss=1.2330720233917236
Epoch #11: loss=1.2017350339889525
Epoch #12: loss=1.1022357606887818
Epoch #13: loss=1.0715016651153564
Epoch #14: loss=0.966259949207306
Epoch #15: loss=0.9664642429351806
Epoch #16: loss=1.0180681848526
Epoch #17: loss=0.969482171535492
Epoch #18: loss=0.8846343898773193
Epoch #19: loss=0.92003737449646
Epoch #20: loss=0.8357271242141724
Epoch #21: loss=0.7906935286521911
Epoch #22: loss=0.6728107464313507
Epoch #23: loss=0.6767038357257843
Epoch #24: loss=0.799654449224472
Epoch #25: loss=0.7233664214611053
Epoch #26: loss=0.8258619749546051
Epoch #27: loss=0.691699720621109
Epoch #28: loss=0.6939658439159393
Epoch #29: loss=0.8303805470466614
Epoch #30: loss=0.7659197676181794
Epoch #31: loss=0.7594508600234985
Epoch #32: loss=0.6714348292350769
Epoch #33: loss=0.6475239849090576
Epoch #34: loss=0.6865132570266723
Epoch #35: loss=0.5690665340423584
Epoch #36: loss=0.5751216721534729
Epoch #37: loss=0.5894639527797699
Epoch #38: loss=0.5763284373283386
Epoch #39: loss=0.6876132297515869
Epoch #40: loss=0.552500296831131
Epoch #41: loss=0.6629052710533142
Epoch #42: loss=0.6107896673679352
Epoch #43: loss=0.5133591139316559
Epoch #44: loss=0.5211443638801575
Epoch #45: loss=0.48848026871681216
Epoch #46: loss=0.5279985183477401
Epoch #47: loss=0.468344042301178
Epoch #48: loss=0.5388385629653931
Epoch #49: loss=0.4512551403045654
Epoch #50: loss=0.42552126288414
Epoch #51: loss=0.4067444032430649
Epoch #52: loss=0.4622237849235535
Epoch #53: loss=0.5581536841392517
Epoch #54: loss=0.47369369864463806
Epoch #55: loss=0.45905564963817597
Epoch #56: loss=0.48483346581459047
Epoch #57: loss=0.48824178814888003
Epoch #58: loss=0.414952649474144
Epoch #59: loss=0.3889418888092041
Epoch #60: loss=0.379714127779007
Epoch #61: loss=0.3693598437309265
Epoch #62: loss=0.3781658482551575
Epoch #63: loss=0.3964070415496826
Epoch #64: loss=0.37237713575363157
Epoch #65: loss=0.42032777667045595
Epoch #66: loss=0.5118149936199188
Epoch #67: loss=0.475237802863121
Epoch #68: loss=0.4175077772140503
Epoch #69: loss=0.4239868479967117
Epoch #70: loss=0.3822479569911957
Epoch #71: loss=0.3993604773283005
Epoch #72: loss=0.3420931798219681
Epoch #73: loss=0.34786838829517364
Epoch #74: loss=0.3799270385503769
Epoch #75: loss=0.31358495831489563
Epoch #76: loss=0.32770824372768403
Epoch #77: loss=0.3377750617265701
Epoch #78: loss=0.2940030831098557
Epoch #79: loss=0.3370013588666916
Epoch #80: loss=0.28918779134750366
Epoch #81: loss=0.3564068555831909
Epoch #82: loss=0.3558822959661484
Epoch #83: loss=0.2892703664302826
Epoch #84: loss=0.30168563783168795
Epoch #85: loss=0.257438018321991
Epoch #86: loss=0.4240860319137573
Epoch #87: loss=0.34531857430934904
Epoch #88: loss=0.30992636263370515
Epoch #89: loss=0.3362433379888535
Epoch #90: loss=0.35354786813259126
Epoch #91: loss=0.2918475580215454
Epoch #92: loss=0.27759537756443026
Epoch #93: loss=0.2581391257047653
Epoch #94: loss=0.2640935230255127
Epoch #95: loss=0.25981378078460693
Epoch #96: loss=0.27947612285614015
Epoch #97: loss=0.2660434585809708
Epoch #98: loss=0.28428219616413114
Epoch #99: loss=0.3673567771911621
Epoch #100: loss=0.4117666804790497
Epoch #101: loss=0.4162885272502899
Epoch #102: loss=0.30170094907283784
Epoch #103: loss=0.33923691987991333
Epoch #104: loss=0.328212114572525
Epoch #105: loss=0.28899186074733735
Epoch #106: loss=0.20955572724342347
Epoch #107: loss=0.259823115170002
Epoch #108: loss=0.29211275070905685
Epoch #109: loss=0.25454609870910644
Epoch #110: loss=0.24950026512145995
Epoch #111: loss=0.2702717065811157
Epoch #112: loss=0.19693999856710434
Epoch #113: loss=0.21291471421718597
Epoch #114: loss=0.21663341134786607
Epoch #115: loss=0.21448634386062623
Epoch #116: loss=0.18999818354845047
Epoch #117: loss=0.20063409835100174
Epoch #118: loss=0.19557298928499223
Epoch #119: loss=0.21499727189540863
Epoch #120: loss=0.24480199933052063
Epoch #121: loss=0.24674017667770387
Epoch #122: loss=0.2738096103072166
Epoch #123: loss=0.23060578972101212
Epoch #124: loss=0.18604814618825913
Epoch #125: loss=0.17825775265693664
Epoch #126: loss=0.2961435440182686
Epoch #127: loss=0.28213753521442414
Epoch #128: loss=0.20428034782409668
Epoch #129: loss=0.18811969220638275
Epoch #130: loss=0.18309250324964524
Epoch #131: loss=0.244055635035038
Epoch #132: loss=0.2099286660552025
Epoch #133: loss=0.22745014160871505
Epoch #134: loss=0.16409831196069719
Epoch #135: loss=0.19974870711565018
Epoch #136: loss=0.14923664540052414
Epoch #137: loss=0.15327371448278426
Epoch #138: loss=0.1719328474998474
Epoch #139: loss=0.26269815653562545
Epoch #140: loss=0.1859843447804451
Epoch #141: loss=0.15412645310163497
Epoch #142: loss=0.1846471557021141
Epoch #143: loss=0.14511890918016435
Epoch #144: loss=0.1753600209951401
Epoch #145: loss=0.16159003853797912
Epoch #146: loss=0.17292729556560515
Epoch #147: loss=0.12733749702572822
Epoch #148: loss=0.15912550389766694
Epoch #149: loss=0.15135622322559356
Epoch #150: loss=0.14498442515730858
Epoch #151: loss=0.1314309385418892
Epoch #152: loss=0.12945552051067352
Epoch #153: loss=0.1301991206407547
Epoch #154: loss=0.12417445346713066
Epoch #155: loss=0.16929989710450172
Epoch #156: loss=0.18650853648781776
Epoch #157: loss=0.21937939584255217
Epoch #158: loss=0.18336753755807877
Epoch #159: loss=0.29441556811332703
Epoch #160: loss=0.24248223960399629
Epoch #161: loss=0.18226635307073594
Epoch #162: loss=0.14166965037584306
Epoch #163: loss=0.17955677211284637
Epoch #164: loss=0.15583677634596824
Epoch #165: loss=0.13141570076346398
Epoch #166: loss=0.1277154703438282
Epoch #167: loss=0.10480115100741387
Epoch #168: loss=0.1743101678788662
Epoch #169: loss=0.12602398097515105
Epoch #170: loss=0.13535310491919517
Epoch #171: loss=0.11746592938899994
Epoch #172: loss=0.1281718848645687
Epoch #173: loss=0.10381313174962997
Epoch #174: loss=0.13083801716566085
Epoch #175: loss=0.09283100888133049
Epoch #176: loss=0.10051164016127587
Epoch #177: loss=0.12736160740256308
Epoch #178: loss=0.12467909470200539
Epoch #179: loss=0.09551372289657593
Epoch #180: loss=0.15892238795757294
Epoch #181: loss=0.09683353364467621
Epoch #182: loss=0.09652870282530784
Epoch #183: loss=0.11593669474124908
Epoch #184: loss=0.10694648712873459
Epoch #185: loss=0.16576207160949707
Epoch #186: loss=0.1462039002776146
Epoch #187: loss=0.15145612463355065
Epoch #188: loss=0.11603546053171158
Epoch #189: loss=0.11987269148230553
Epoch #190: loss=0.20755213156342506
Epoch #191: loss=0.10618321165442467
Epoch #192: loss=0.10593190506100654
Epoch #193: loss=0.1233000960946083
Epoch #194: loss=0.08934694692492486
Epoch #195: loss=0.15085377365350724
Epoch #196: loss=0.10505678236484528
Epoch #197: loss=0.12628596857190133
Epoch #198: loss=0.09037024229764938
Epoch #199: loss=0.12705915465950965
Epoch #200: loss=0.15788092613220214
Epoch #201: loss=0.1406695558130741
Epoch #202: loss=0.11769601091742515
Epoch #203: loss=0.09007319748401642
Epoch #204: loss=0.10191226534545422
Epoch #205: loss=0.14501064911484718
Epoch #206: loss=0.1250461046397686
Epoch #207: loss=0.1325596286356449
Epoch #208: loss=0.10824402302503586
Epoch #209: loss=0.1085013873130083
Epoch #210: loss=0.09019438773393632
Epoch #211: loss=0.0790482871979475
Epoch #212: loss=0.09208860643208026
Epoch #213: loss=0.1467284719645977
Epoch #214: loss=0.0804980994015932
Epoch #215: loss=0.08014909103512764
Epoch #216: loss=0.07320355400443077
Epoch #217: loss=0.07468271940946579
Epoch #218: loss=0.09023350849747658
Epoch #219: loss=0.06177923776209354
Epoch #220: loss=0.09354627929627896
Epoch #221: loss=0.10971873857080937
Epoch #222: loss=0.08259949639439583
Epoch #223: loss=0.07488276988267899
Epoch #224: loss=0.06437984146177769
Epoch #225: loss=0.05968906164169312
Epoch #226: loss=0.05956069014966488
Epoch #227: loss=0.060578968673944474
Epoch #228: loss=0.13198284044861794
Epoch #229: loss=0.18603853940963744
Epoch #230: loss=0.1238504122197628
Epoch #231: loss=0.07324666194617749
Epoch #232: loss=0.14197777934372424
Epoch #233: loss=0.08859339416027069
Epoch #234: loss=0.09277494810521603
Epoch #235: loss=0.09955575428903103
Epoch #236: loss=0.14245925575494767
Epoch #237: loss=0.1311817215383053
Epoch #238: loss=0.1365630665421486
Epoch #239: loss=0.08625910237431526
Epoch #240: loss=0.0903200576454401
Epoch #241: loss=0.23628452681005002
Epoch #242: loss=0.10727481588721276
Epoch #243: loss=0.0905996535718441
Epoch #244: loss=0.09828812964260578
Epoch #245: loss=0.07684171512722969
Epoch #246: loss=0.07962061896920204
Epoch #247: loss=0.07308804899454117
Epoch #248: loss=0.07814014047384261
Epoch #249: loss=0.07770819716155529

Training time: 0:20:42.064180

Finished.
n2one setting etth1_etth2_ettm1 -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm1_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_etth2_ettm1', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.46364e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.84875e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.46364e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3828184108921154, 'MAE': 0.4326582357078259}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_ettm1 -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm1_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_etth2_ettm1', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.63052e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.01853e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.63052e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.9119459844739713, 'MAE': 0.7761720495185424}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_ettm1 -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm1_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_etth2_ettm1', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.55511e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.2276443421423413, 'MAE': 0.323999291801823}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_ettm2', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_ettm2_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=4.7720858669281006
Epoch #1: loss=2.4792526531219483
Epoch #2: loss=2.1717482089996336
Epoch #3: loss=2.118217625617981
Epoch #4: loss=1.913448920249939
Epoch #5: loss=1.7553479051589966
Epoch #6: loss=1.6217941665649414
Epoch #7: loss=1.5171757698059083
Epoch #8: loss=1.346158308982849
Epoch #9: loss=1.3233362174034118
Epoch #10: loss=1.2476977729797363
Epoch #11: loss=1.2176814770698547
Epoch #12: loss=1.1435816478729248
Epoch #13: loss=1.0911475801467896
Epoch #14: loss=0.9779672574996948
Epoch #15: loss=0.9735022068023682
Epoch #16: loss=1.0415723466873168
Epoch #17: loss=0.9903850388526917
Epoch #18: loss=0.9119204998016357
Epoch #19: loss=0.9161313009262085
Epoch #20: loss=0.8832236385345459
Epoch #21: loss=0.8486923503875733
Epoch #22: loss=0.726021112203598
Epoch #23: loss=0.7406681847572326
Epoch #24: loss=0.8345785307884216
Epoch #25: loss=0.8013348817825318
Epoch #26: loss=0.880164065361023
Epoch #27: loss=0.7294251632690429
Epoch #28: loss=0.7101899456977844
Epoch #29: loss=0.8164848971366883
Epoch #30: loss=0.7779240608215332
Epoch #31: loss=0.7161166548728943
Epoch #32: loss=0.6172337687015533
Epoch #33: loss=0.6012406611442566
Epoch #34: loss=0.6609213089942932
Epoch #35: loss=0.565186972618103
Epoch #36: loss=0.5709249782562256
Epoch #37: loss=0.6298791253566742
Epoch #38: loss=0.5809940254688263
Epoch #39: loss=0.6584587001800537
Epoch #40: loss=0.5620143508911133
Epoch #41: loss=0.6785758328437805
Epoch #42: loss=0.6265421974658966
Epoch #43: loss=0.5210954129695893
Epoch #44: loss=0.5105081868171691
Epoch #45: loss=0.484952347278595
Epoch #46: loss=0.507056416273117
Epoch #47: loss=0.4721511518955231
Epoch #48: loss=0.5557683205604553
Epoch #49: loss=0.4795657694339752
Epoch #50: loss=0.42744115471839905
Epoch #51: loss=0.4291424745321274
Epoch #52: loss=0.48014578223228455
Epoch #53: loss=0.5734872543811798
Epoch #54: loss=0.4916953957080841
Epoch #55: loss=0.4592685985565186
Epoch #56: loss=0.45665438532829283
Epoch #57: loss=0.4682155060768127
Epoch #58: loss=0.414286305308342
Epoch #59: loss=0.39621268808841703
Epoch #60: loss=0.37826462924480436
Epoch #61: loss=0.4053570032119751
Epoch #62: loss=0.4475674587488174
Epoch #63: loss=0.45093381524085996
Epoch #64: loss=0.4186417776346207
Epoch #65: loss=0.3997457057237625
Epoch #66: loss=0.4425390362739563
Epoch #67: loss=0.377946515083313
Epoch #68: loss=0.36244953274726865
Epoch #69: loss=0.40983174920082094
Epoch #70: loss=0.3513551199436188
Epoch #71: loss=0.391749854683876
Epoch #72: loss=0.334703431725502
Epoch #73: loss=0.3609593820571899
Epoch #74: loss=0.3950103372335434
Epoch #75: loss=0.3145703172683716
Epoch #76: loss=0.32905508935451505
Epoch #77: loss=0.35584921717643736
Epoch #78: loss=0.29628663659095766
Epoch #79: loss=0.35576431930065155
Epoch #80: loss=0.2943710786104202
Epoch #81: loss=0.35552915692329407
Epoch #82: loss=0.36199477553367615
Epoch #83: loss=0.3037063729763031
Epoch #84: loss=0.3348606300354004
Epoch #85: loss=0.2786271744966507
Epoch #86: loss=0.4390850222110748
Epoch #87: loss=0.3442162698507309
Epoch #88: loss=0.29900348246097563
Epoch #89: loss=0.3262100076675415
Epoch #90: loss=0.3343813216686249
Epoch #91: loss=0.3097387307882309
Epoch #92: loss=0.28594492495059964
Epoch #93: loss=0.2639261680841446
Epoch #94: loss=0.31321330428123473
Epoch #95: loss=0.2732675808668137
Epoch #96: loss=0.2837924575805664
Epoch #97: loss=0.2846945434808731
Epoch #98: loss=0.3060140532255173
Epoch #99: loss=0.38968927919864654
Epoch #100: loss=0.4112796920537949
Epoch #101: loss=0.3844888591766357
Epoch #102: loss=0.2821068382263184
Epoch #103: loss=0.32426343142986297
Epoch #104: loss=0.31667819917201995
Epoch #105: loss=0.29918867647647857
Epoch #106: loss=0.21498273849487304
Epoch #107: loss=0.26564949095249174
Epoch #108: loss=0.30580922663211824
Epoch #109: loss=0.321138756275177
Epoch #110: loss=0.31696582794189454
Epoch #111: loss=0.32064205467700957
Epoch #112: loss=0.221141320168972
Epoch #113: loss=0.2283032739162445
Epoch #114: loss=0.2202845945954323
Epoch #115: loss=0.20862844347953796
Epoch #116: loss=0.1911453750729561
Epoch #117: loss=0.2053255432844162
Epoch #118: loss=0.22412455826997757
Epoch #119: loss=0.22964617013931274
Epoch #120: loss=0.2380364465713501
Epoch #121: loss=0.2274546405673027
Epoch #122: loss=0.2608353352546692
Epoch #123: loss=0.22359333723783492
Epoch #124: loss=0.17913301885128022
Epoch #125: loss=0.16624671071767808
Epoch #126: loss=0.2360575580596924
Epoch #127: loss=0.24655693620443345
Epoch #128: loss=0.19211959332227707
Epoch #129: loss=0.20068930268287657
Epoch #130: loss=0.15940405249595643
Epoch #131: loss=0.23724125057458878
Epoch #132: loss=0.18947258710861206
Epoch #133: loss=0.18658469200134278
Epoch #134: loss=0.1520893406867981
Epoch #135: loss=0.2013525915145874
Epoch #136: loss=0.14867571234703064
Epoch #137: loss=0.15656712174415588
Epoch #138: loss=0.16595125883817674
Epoch #139: loss=0.2261743065714836
Epoch #140: loss=0.15957727462053298
Epoch #141: loss=0.1425198036432266
Epoch #142: loss=0.17914789497852326
Epoch #143: loss=0.15086423069238664
Epoch #144: loss=0.1886732631921768
Epoch #145: loss=0.17265736013650895
Epoch #146: loss=0.19154589325189592
Epoch #147: loss=0.1302306954562664
Epoch #148: loss=0.1711941194534302
Epoch #149: loss=0.18154361814260483
Epoch #150: loss=0.21846098184585572
Epoch #151: loss=0.22400870203971862
Epoch #152: loss=0.16973663598299027
Epoch #153: loss=0.147140933573246
Epoch #154: loss=0.13536348015069963
Epoch #155: loss=0.1748776388168335
Epoch #156: loss=0.19756773501634597
Epoch #157: loss=0.17110533237457276
Epoch #158: loss=0.16576600074768066
Epoch #159: loss=0.3239395296573639
Epoch #160: loss=0.2516078060865402
Epoch #161: loss=0.18373204559087752
Epoch #162: loss=0.1415828962624073
Epoch #163: loss=0.17278336852788925
Epoch #164: loss=0.1429697471857071
Epoch #165: loss=0.12374224469065666
Epoch #166: loss=0.12404381155967713
Epoch #167: loss=0.1081237867474556
Epoch #168: loss=0.16811363145709038
Epoch #169: loss=0.12060709893703461
Epoch #170: loss=0.15707197695970535
Epoch #171: loss=0.11557832658290863
Epoch #172: loss=0.13012543305754662
Epoch #173: loss=0.12977071568369866
Epoch #174: loss=0.1640651822090149
Epoch #175: loss=0.11810360491275787
Epoch #176: loss=0.10107760936021805
Epoch #177: loss=0.11673512980341912
Epoch #178: loss=0.13203952312469483
Epoch #179: loss=0.10354619637131691
Epoch #180: loss=0.16481248557567596
Epoch #181: loss=0.11341073304414749
Epoch #182: loss=0.10487829282879829
Epoch #183: loss=0.11601374387741088
Epoch #184: loss=0.10574343591928483
Epoch #185: loss=0.16722875505685805
Epoch #186: loss=0.13477425917983055
Epoch #187: loss=0.16942323252558708
Epoch #188: loss=0.15823779702186586
Epoch #189: loss=0.14070741191506386
Epoch #190: loss=0.22105560034513475
Epoch #191: loss=0.13524097502231597
Epoch #192: loss=0.11466468945145607
Epoch #193: loss=0.12410041779279708
Epoch #194: loss=0.09240634016692638
Epoch #195: loss=0.15586398154497147
Epoch #196: loss=0.1140517146885395
Epoch #197: loss=0.14431345507502555
Epoch #198: loss=0.12063077047467231
Epoch #199: loss=0.13431391075253488
Epoch #200: loss=0.15222993656992911
Epoch #201: loss=0.1221348774433136
Epoch #202: loss=0.11207180365920066
Epoch #203: loss=0.08190016210079193
Epoch #204: loss=0.09144771285355091
Epoch #205: loss=0.15064533054828644
Epoch #206: loss=0.1501795755326748
Epoch #207: loss=0.15744576528668403
Epoch #208: loss=0.11063723608851433
Epoch #209: loss=0.11334691449999809
Epoch #210: loss=0.09261883273720742
Epoch #211: loss=0.07821743957698345
Epoch #212: loss=0.0796986223757267
Epoch #213: loss=0.13423317730426787
Epoch #214: loss=0.08361295104026795
Epoch #215: loss=0.0955044462531805
Epoch #216: loss=0.07622203797101974
Epoch #217: loss=0.09291423007845878
Epoch #218: loss=0.10936817593872547
Epoch #219: loss=0.0732115437835455
Epoch #220: loss=0.10027652882039546
Epoch #221: loss=0.11132237695157528
Epoch #222: loss=0.08345819145441055
Epoch #223: loss=0.09671596817672252
Epoch #224: loss=0.08881330288946629
Epoch #225: loss=0.0811419826745987
Epoch #226: loss=0.06622193075716495
Epoch #227: loss=0.07684088252484798
Epoch #228: loss=0.1469926957041025
Epoch #229: loss=0.12568854823708533
Epoch #230: loss=0.08334189370274543
Epoch #231: loss=0.056201637536287305
Epoch #232: loss=0.12637605980038644
Epoch #233: loss=0.11989893585443497
Epoch #234: loss=0.14041066840291022
Epoch #235: loss=0.1601349274814129
Epoch #236: loss=0.15529170215129853
Epoch #237: loss=0.14340829163789748
Epoch #238: loss=0.1439154775440693
Epoch #239: loss=0.07192426331341267
Epoch #240: loss=0.08119985066354275
Epoch #241: loss=0.21185762017965318
Epoch #242: loss=0.0953685086965561
Epoch #243: loss=0.0805497757345438
Epoch #244: loss=0.10881884023547173
Epoch #245: loss=0.09360076278448105
Epoch #246: loss=0.08382118344306946
Epoch #247: loss=0.08039194911718368
Epoch #248: loss=0.07328783422708511
Epoch #249: loss=0.07269610911607742

Training time: 0:17:14.411299

Finished.
n2one setting etth1_etth2_ettm2 -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm2_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_etth2_ettm2', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.77191e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.26759e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.77191e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.38792267905759575, 'MAE': 0.44102467299990583}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_ettm2 -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm2_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_etth2_ettm2', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.56648e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.96076e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.56648e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.7177653445477324, 'MAE': 0.6774010890884978}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_ettm2 -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm2_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_etth2_ettm2', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.32377e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.2125640075199712, 'MAE': 0.31498276338877373}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_electricity', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_electricity_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.6905680330831614
Epoch #1: loss=0.6901563010109004
Epoch #2: loss=0.4515266782312251
Epoch #3: loss=0.3598232869336854
Epoch #4: loss=0.29286411231133475
Epoch #5: loss=0.26717702248203223
Epoch #6: loss=0.2237764504196039
Epoch #7: loss=0.19820884559581528
Epoch #8: loss=0.17430972957344198
Epoch #9: loss=0.15755685191990723
Epoch #10: loss=0.15080174180998732
Epoch #11: loss=0.11869671419262887
Epoch #12: loss=0.11906985166802335
Epoch #13: loss=0.11335199082742876
Epoch #14: loss=0.10333623153282635
Epoch #15: loss=0.10770901945878321
Epoch #16: loss=0.08915138105625536
Epoch #17: loss=0.09512258349403517
Epoch #18: loss=0.09176874388176114
Epoch #19: loss=0.07011305082088976
Epoch #20: loss=0.0689005124229771
Epoch #21: loss=0.05953979521934221
Epoch #22: loss=0.06782571534389881
Epoch #23: loss=0.07149919784669556
Epoch #24: loss=0.04433671234926181
Epoch #25: loss=0.08013423123577637
Epoch #26: loss=0.05644956573899557
Epoch #27: loss=0.03979391744360328
Epoch #28: loss=0.05680661879118477
Epoch #29: loss=0.034317057760460165
Epoch #30: loss=0.04653099819239396
Epoch #31: loss=0.03489021655561319
Epoch #32: loss=0.04204895446813707
Epoch #33: loss=0.03600777856824892
Epoch #34: loss=0.0405849141416265
Epoch #35: loss=0.035689811890861435
Epoch #36: loss=0.029223319842243817
Epoch #37: loss=0.02830486564910901
Epoch #38: loss=0.03709974909590474
Epoch #39: loss=0.037928729930392174
Epoch #40: loss=0.028783651676946388
Epoch #41: loss=0.026938842257846204
Epoch #42: loss=0.03112524239930199
Epoch #43: loss=0.033943667419171375
Epoch #44: loss=0.03376188515059984
Epoch #45: loss=0.032684262958702755
Epoch #46: loss=0.03348748602681974
Epoch #47: loss=0.028665128592818754
Epoch #48: loss=0.022176725384362266
Epoch #49: loss=0.02695781921502203
Epoch #50: loss=0.023442484118364085
Epoch #51: loss=0.031159454422182778
Epoch #52: loss=0.021794953698695486
Epoch #53: loss=0.02662668641441182
Epoch #54: loss=0.014898138039974746
Epoch #55: loss=0.02284341927812393
Epoch #56: loss=0.028044290990054385
Epoch #57: loss=0.025743106562894448
Epoch #58: loss=0.02584543059746832
Epoch #59: loss=0.01469176260671064
Epoch #60: loss=0.02028743994019147
Epoch #61: loss=0.028474913721681754
Epoch #62: loss=0.03240346704025878
Epoch #63: loss=0.019200975905040475
Epoch #64: loss=0.01738019155567762
Epoch #65: loss=0.018219793005672686
Epoch #66: loss=0.020393627497833224
Epoch #67: loss=0.03991616520641455
Epoch #68: loss=0.02373773849485859
Epoch #69: loss=0.02913451207203985
Epoch #70: loss=0.019421710901017953
Epoch #71: loss=0.017300011445733426
Epoch #72: loss=0.05581798013143325
Epoch #73: loss=0.026833386528097206
Epoch #74: loss=0.018585618855362175
Epoch #75: loss=0.018520530937378533
Epoch #76: loss=0.011421224564042832
Epoch #77: loss=0.019143185118185496
Epoch #78: loss=0.052418194045382206
Epoch #79: loss=0.02127742485747909
Epoch #80: loss=0.01373594706259501
Epoch #81: loss=0.014445922488986112
Epoch #82: loss=0.01731355323668208
Epoch #83: loss=0.02213952546372815
Epoch #84: loss=0.013069238121023596
Epoch #85: loss=0.0163254682864271
Epoch #86: loss=0.015616536817735812
Epoch #87: loss=0.013700597568540208
Epoch #88: loss=0.018163220490739027
Epoch #89: loss=0.017314721508743938
Epoch #90: loss=0.01840422153872535
Epoch #91: loss=0.04037691016799645
Epoch #92: loss=0.014598898615674186
Epoch #93: loss=0.014320919277500918
Epoch #94: loss=0.015842023611402335
Epoch #95: loss=0.03829075852026746
Epoch #96: loss=0.028124976848988837
Epoch #97: loss=0.035568038691113246
Epoch #98: loss=0.01700533929996804
Epoch #99: loss=0.019236909605409785
Epoch #100: loss=0.014576526464366201
Epoch #101: loss=0.014142928351891407
Epoch #102: loss=0.02106266015021603
Epoch #103: loss=0.01624728604098226
Epoch #104: loss=0.010580399154282327
Epoch #105: loss=0.01329052198553152
Epoch #106: loss=0.015362333052847257
Epoch #107: loss=0.021357593163430912
Epoch #108: loss=0.01611072844165419
Epoch #109: loss=0.01607155277716941
Epoch #110: loss=0.014887378426657907
Epoch #111: loss=0.01400941908707036
Epoch #112: loss=0.01515778782933867
Epoch #113: loss=0.013054098651584571
Epoch #114: loss=0.017994278120467746
Epoch #115: loss=0.018444173110808842
Epoch #116: loss=0.019256546485599185
Epoch #117: loss=0.016379840459514742
Epoch #118: loss=0.014771178538855444
Epoch #119: loss=0.018544493555334576
Epoch #120: loss=0.022941389090186958
Epoch #121: loss=0.025452682438980676
Epoch #122: loss=0.017155101812277824
Epoch #123: loss=0.01031647395366914
Epoch #124: loss=0.01417157230029967
Epoch #125: loss=0.011666499373655933
Epoch #126: loss=0.01885753440003453
Epoch #127: loss=0.014588199925970342
Epoch #128: loss=0.0123508950757947
Epoch #129: loss=0.011678640966289747
Epoch #130: loss=0.016011211372661725
Epoch #131: loss=0.01402981635721734
Epoch #132: loss=0.019243775504648186
Epoch #133: loss=0.011362853961902907
Epoch #134: loss=0.011268554254845064
Epoch #135: loss=0.02058773165718138
Epoch #136: loss=0.009491238147263596
Epoch #137: loss=0.010542764414602251
Epoch #138: loss=0.011328139152975559
Epoch #139: loss=0.014708703707333709
Epoch #140: loss=0.013555665767696033
Epoch #141: loss=0.01661812025956365
Epoch #142: loss=0.011416051047854125
Epoch #143: loss=0.014472928103285411
Epoch #144: loss=0.012047281109297009
Epoch #145: loss=0.009482599294278771
Epoch #146: loss=0.01410801547645494
Epoch #147: loss=0.013272949574956559
Epoch #148: loss=0.01288508313079017
Epoch #149: loss=0.013481894755430187
Epoch #150: loss=0.011897542644396368
Epoch #151: loss=0.013863816027314083
Epoch #152: loss=0.01770980899455026
Epoch #153: loss=0.011847023533678044
Epoch #154: loss=0.010629389889420136
Epoch #155: loss=0.010492277779067352
Epoch #156: loss=0.009925354856288812
Epoch #157: loss=0.015419960851127755
Epoch #158: loss=0.012355476449966542
Epoch #159: loss=0.009379937626341525
Epoch #160: loss=0.020044346737550265
Epoch #161: loss=0.01660752083077582
Epoch #162: loss=0.006489308604643917
Epoch #163: loss=0.007600979359973389
Epoch #164: loss=0.016122328740051154
Epoch #165: loss=0.007809121351091386
Epoch #166: loss=0.019342738311258215
Epoch #167: loss=0.011166388521478303
Epoch #168: loss=0.014942658061349291
Epoch #169: loss=0.013223438299914349
Epoch #170: loss=0.010529536801240922
Epoch #171: loss=0.03620463731723018
Epoch #172: loss=0.015093939245240624
Epoch #173: loss=0.008324063825160403
Epoch #174: loss=0.010843680829066895
Epoch #175: loss=0.009056337786066944
Epoch #176: loss=0.00916581509309932
Epoch #177: loss=0.011783546260419065
Epoch #178: loss=0.013619292914909101
Epoch #179: loss=0.008797551921235203
Epoch #180: loss=0.012640577230651154
Epoch #181: loss=0.008316464797218344
Epoch #182: loss=0.014099023040425755
Epoch #183: loss=0.038797824608453955
Epoch #184: loss=0.016768026399884874
Epoch #185: loss=0.014661072619231557
Epoch #186: loss=0.008665078327949367
Epoch #187: loss=0.01318390902719085
Epoch #188: loss=0.008850253624372435
Epoch #189: loss=0.013130506547211335
Epoch #190: loss=0.009836336558358048
Epoch #191: loss=0.010440906925203362
Epoch #192: loss=0.011028281593028067
Epoch #193: loss=0.010369552518744996
Epoch #194: loss=0.010915131466515335
Epoch #195: loss=0.012018933213479233
Epoch #196: loss=0.013221450742341078
Epoch #197: loss=0.012022452710940044
Epoch #198: loss=0.007561651155623649
Epoch #199: loss=0.010851162602541162
Epoch #200: loss=0.01084030081375516
Epoch #201: loss=0.012817606572218155
Epoch #202: loss=0.014853379570135375
Epoch #203: loss=0.011977623344169679
Epoch #204: loss=0.00855799329800726
Epoch #205: loss=0.00784208510634003
Epoch #206: loss=0.008249245992637546
Epoch #207: loss=0.02013542420272507
Epoch #208: loss=0.012433540413882444
Epoch #209: loss=0.009592836406759557
Epoch #210: loss=0.014382622123056495
Epoch #211: loss=0.01052245584910791
Epoch #212: loss=0.014108242172619273
Epoch #213: loss=0.0119031237309743
Epoch #214: loss=0.007852059270084989
Epoch #215: loss=0.006060411855743489
Epoch #216: loss=0.013160225138009123
Epoch #217: loss=0.01116101802622121
Epoch #218: loss=0.013579021014599825
Epoch #219: loss=0.010151533800378832
Epoch #220: loss=0.011042266134033675
Epoch #221: loss=0.009323879309283542
Epoch #222: loss=0.00654999727735977
Epoch #223: loss=0.009538389389740248
Epoch #224: loss=0.012061923382275585
Epoch #225: loss=0.005822607284540366
Epoch #226: loss=0.020638119726382725
Epoch #227: loss=0.008071656870297782
Epoch #228: loss=0.009588035547918181
Epoch #229: loss=0.011161240068639614
Epoch #230: loss=0.010715825059677043
Epoch #231: loss=0.011665872730481535
Epoch #232: loss=0.0101928721942223
Epoch #233: loss=0.012116764617628598
Epoch #234: loss=0.011762570518367826
Epoch #235: loss=0.011274905510875744
Epoch #236: loss=0.010223192771125251
Epoch #237: loss=0.009606347057912776
Epoch #238: loss=0.007523542449769647
Epoch #239: loss=0.015321262262817194
Epoch #240: loss=0.012732611379912818
Epoch #241: loss=0.010047407601542994
Epoch #242: loss=0.01287017226481546
Epoch #243: loss=0.009023949265942228
Epoch #244: loss=0.007978235429792261
Epoch #245: loss=0.011954054349873549
Epoch #246: loss=0.009585266904349425
Epoch #247: loss=0.018531827993496362
Epoch #248: loss=0.004922787440982439
Epoch #249: loss=0.005072323482666963

Training time: 4:30:46.968235

Finished.
n2one setting etth1_etth2_electricity -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_electricity_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_etth2_electricity', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.38822e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.07099e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.38822e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.9009533050081461, 'MAE': 0.7309282437544368}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_electricity -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_electricity_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_etth2_electricity', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.53318e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.24914493809715865, 'MAE': 0.34599996106149167}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_traffic', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_traffic_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.0177232118229889
Epoch #1: loss=0.35799418456138
Epoch #2: loss=0.26072308167679126
Epoch #3: loss=0.1862702463162408
Epoch #4: loss=0.14512942926575467
Epoch #5: loss=0.12304211366649496
Epoch #6: loss=0.106509861266283
Epoch #7: loss=0.09689908966711258
Epoch #8: loss=0.07349872877863853
Epoch #9: loss=0.06401292893920757
Epoch #10: loss=0.07068107583662113
Epoch #11: loss=0.06589713541431497
Epoch #12: loss=0.05595773166273062
Epoch #13: loss=0.05029655848023775
Epoch #14: loss=0.0544924328909532
Epoch #15: loss=0.039623319657761856
Epoch #16: loss=0.041507929979746984
Epoch #17: loss=0.03931061958880312
Epoch #18: loss=0.03588928293796111
Epoch #19: loss=0.04077613896229963
Epoch #20: loss=0.03217407617479835
Epoch #21: loss=0.03217531730658502
Epoch #22: loss=0.029197057344569063
Epoch #23: loss=0.0306667372037882
Epoch #24: loss=0.047608575533164374
Epoch #25: loss=0.029765431315092728
Epoch #26: loss=0.026879429706100154
Epoch #27: loss=0.027716453439267947
Epoch #28: loss=0.029043610803899885
Epoch #29: loss=0.02395899709913195
Epoch #30: loss=0.024885116798455557
Epoch #31: loss=0.020514860714227066
Epoch #32: loss=0.028138292646984416
Epoch #33: loss=0.02129764695846918
Epoch #34: loss=0.02364099009573028
Epoch #35: loss=0.02044206066113566
Epoch #36: loss=0.028429974726088703
Epoch #37: loss=0.021116556482324186
Epoch #38: loss=0.02121466259098905
Epoch #39: loss=0.020316777442734513
Epoch #40: loss=0.0222138946250131
Epoch #41: loss=0.022363728543886484
Epoch #42: loss=0.019821864020753945
Epoch #43: loss=0.020221651926916835
Epoch #44: loss=0.025505889807009144
Epoch #45: loss=0.03006744302577205
Epoch #46: loss=0.01463578766773744
Epoch #47: loss=0.020708331928219536
Epoch #48: loss=0.01773197657575397
Epoch #49: loss=0.01850360946038198
Epoch #50: loss=0.04305509102786466
Epoch #51: loss=0.016237762061675445
Epoch #52: loss=0.020091763609987323
Epoch #53: loss=0.01972413562276357
Epoch #54: loss=0.01845212473493382
Epoch #55: loss=0.015342335913930466
Epoch #56: loss=0.02170458045788375
Epoch #57: loss=0.02196394145827885
Epoch #58: loss=0.018993548331737036
Epoch #59: loss=0.0242835643034658
Epoch #60: loss=0.01714713754944108
Epoch #61: loss=0.01728000981725495
Epoch #62: loss=0.016865136949574047
Epoch #63: loss=0.01779246177040859
Epoch #64: loss=0.02900693075247396
Epoch #65: loss=0.02005435169324147
Epoch #66: loss=0.014359505126942756
Epoch #67: loss=0.01587653914834617
Epoch #68: loss=0.01875157892564737
Epoch #69: loss=0.011361761387282362
Epoch #70: loss=0.01637076342843322
Epoch #71: loss=0.01322326483065422
Epoch #72: loss=0.021553475131532156
Epoch #73: loss=0.011431261047768551
Epoch #74: loss=0.014082468772519934
Epoch #75: loss=0.017407491228202482
Epoch #76: loss=0.020966222830880624
Epoch #77: loss=0.012739797915756218
Epoch #78: loss=0.012791950596007677
Epoch #79: loss=0.018090356276548664
Epoch #80: loss=0.012247589654915118
Epoch #81: loss=0.02080251895035851
Epoch #82: loss=0.01602568792680371
Epoch #83: loss=0.013279711887870062
Epoch #84: loss=0.014120607456564745
Epoch #85: loss=0.013744873344830714
Epoch #86: loss=0.02129596165598255
Epoch #87: loss=0.023839997696771593
Epoch #88: loss=0.019474980579010055
Epoch #89: loss=0.012950951316266068
Epoch #90: loss=0.016695088702491877
Epoch #91: loss=0.0131704035864866
Epoch #92: loss=0.020060834661378635
Epoch #93: loss=0.013929358449034694
Epoch #94: loss=0.013276537034064414
Epoch #95: loss=0.011888415503837105
Epoch #96: loss=0.015025352102500486
Epoch #97: loss=0.013894965827117406
Epoch #98: loss=0.016528600815347513
Epoch #99: loss=0.017569391800770558
Epoch #100: loss=0.00842255330176096
Epoch #101: loss=0.020921378654880862
Epoch #102: loss=0.021473068118012473
Epoch #103: loss=0.010473872841650526
Epoch #104: loss=0.012589485119092615
Epoch #105: loss=0.016250580379268426
Epoch #106: loss=0.015576873775820097
Epoch #107: loss=0.014251513817443535
Epoch #108: loss=0.024414962202924002
Epoch #109: loss=0.013751068149364264
Epoch #110: loss=0.009257984524174805
Epoch #111: loss=0.009600056370879208
Epoch #112: loss=0.015010019097374603
Epoch #113: loss=0.01592176329819209
Epoch #114: loss=0.01294136315311218
Epoch #115: loss=0.017489668809328777
Epoch #116: loss=0.015270868732351289
Epoch #117: loss=0.017810503514518124
Epoch #118: loss=0.012081548801161345
Epoch #119: loss=0.014752619922301704
Epoch #120: loss=0.01710861574363529
Epoch #121: loss=0.015860264898199677
Epoch #122: loss=0.01393116362681017
Epoch #123: loss=0.008974098355955067
Epoch #124: loss=0.014231692248317211
Epoch #125: loss=0.016305592008987305
Epoch #126: loss=0.018394321915411845
Epoch #127: loss=0.008767507448590459
Epoch #128: loss=0.00806212666537905
Epoch #129: loss=0.013599495280151095
Epoch #130: loss=0.009367967555191757
Epoch #131: loss=0.01603725544465642
Epoch #132: loss=0.011577723777490683
Epoch #133: loss=0.012156637361334035
Epoch #134: loss=0.012665590876985829
Epoch #135: loss=0.013294686237846798
Epoch #136: loss=0.011212672216958073
Epoch #137: loss=0.011795306806657229
Epoch #138: loss=0.012086760448600213
Epoch #139: loss=0.011122399315188297
Epoch #140: loss=0.010254201265761617
Epoch #141: loss=0.018497289557020034
Epoch #142: loss=0.012133847494831852
Epoch #143: loss=0.009309418984566822
Epoch #144: loss=0.013078958976396667
Epoch #145: loss=0.011162846465601166
Epoch #146: loss=0.010005163931503512
Epoch #147: loss=0.010553786061243282
Epoch #148: loss=0.010967270456670175
Epoch #149: loss=0.00647561856415338
Epoch #150: loss=0.012377269302978425
Epoch #151: loss=0.015333670916305015
Epoch #152: loss=0.012527290009139302
Epoch #153: loss=0.01141385807744525
Epoch #154: loss=0.01355707751964187
Epoch #155: loss=0.01091777402164399
Epoch #156: loss=0.009461075390187267
Epoch #157: loss=0.014072283138657897
Epoch #158: loss=0.009048621330210768
Epoch #159: loss=0.01186560487680187
Epoch #160: loss=0.007900629849453535
Epoch #161: loss=0.01820735957495577
Epoch #162: loss=0.00985533396015276
Epoch #163: loss=0.011158825961323286
Epoch #164: loss=0.01052320750783592
Epoch #165: loss=0.014569891506163174
Epoch #166: loss=0.010312978346577371
Epoch #167: loss=0.010073515653234671
Epoch #168: loss=0.01839770077896245
Epoch #169: loss=0.009460003656514848
Epoch #170: loss=0.022122841621812894
Epoch #171: loss=0.007926084047527458
Epoch #172: loss=0.009094436789606856
Epoch #173: loss=0.012294136948400994
Epoch #174: loss=0.013711784468335418
Epoch #175: loss=0.0168868515241283
Epoch #176: loss=0.007201494291201755
Epoch #177: loss=0.011135520436575097
Epoch #178: loss=0.010994026857081665
Epoch #179: loss=0.021178227264902417
Epoch #180: loss=0.010012390551928879
Epoch #181: loss=0.008490583675308977
Epoch #182: loss=0.008530445402714299
Epoch #183: loss=0.011131802139236043
Epoch #184: loss=0.010603546628647577
Epoch #185: loss=0.011039503436542508
Epoch #186: loss=0.007623303325920681
Epoch #187: loss=0.009496330139558118
Epoch #188: loss=0.01424116158779069
Epoch #189: loss=0.015126964478195616
Epoch #190: loss=0.01133150422267393
Epoch #191: loss=0.014203905864608353
Epoch #192: loss=0.010282865571865193
Epoch #193: loss=0.010333612212428444
Epoch #194: loss=0.009102063812524772
Epoch #195: loss=0.007385401542826385
Epoch #196: loss=0.011090157243175016
Epoch #197: loss=0.01673930202743419
Epoch #198: loss=0.007353007129553522
Epoch #199: loss=0.011414283771930607
Epoch #200: loss=0.0130513161831133
Epoch #201: loss=0.00764885855328243
Epoch #202: loss=0.010607766883405107
Epoch #203: loss=0.011273314039956206
Epoch #204: loss=0.007640025543222272
Epoch #205: loss=0.011088921339915571
Epoch #206: loss=0.016371999159399485
Epoch #207: loss=0.008826338094171427
Epoch #208: loss=0.013885306970028422
Epoch #209: loss=0.012786822550916527
Epoch #210: loss=0.012136866061034726
Epoch #211: loss=0.011508197926447531
Epoch #212: loss=0.006998264533553972
Epoch #213: loss=0.008273838683315627
Epoch #214: loss=0.012636329883419308
Epoch #215: loss=0.011995204034019272
Epoch #216: loss=0.006821490132973368
Epoch #217: loss=0.010286434617550596
Epoch #218: loss=0.01037710509437818
Epoch #219: loss=0.013259610322518827
Epoch #220: loss=0.008723309631388317
Epoch #221: loss=0.011702265819173453
Epoch #222: loss=0.008581755818610695
Epoch #223: loss=0.00874606480720436
Epoch #224: loss=0.01567883507664088
Epoch #225: loss=0.015550242819629034
Epoch #226: loss=0.00990491689315845
Epoch #227: loss=0.008276058358675056
Epoch #228: loss=0.007864345570735301
Epoch #229: loss=0.008792380981424906
Epoch #230: loss=0.011895137898688795
Epoch #231: loss=0.00930765961627032
Epoch #232: loss=0.00998705099276336
Epoch #233: loss=0.009769652218502211
Epoch #234: loss=0.010182421604095911
Epoch #235: loss=0.009078866564590973
Epoch #236: loss=0.009830879155838395
Epoch #237: loss=0.00788176232398983
Epoch #238: loss=0.010183405565300193
Epoch #239: loss=0.009450369179465427
Epoch #240: loss=0.02066974883868394
Epoch #241: loss=0.013363303100049961
Epoch #242: loss=0.009384129460482804
Epoch #243: loss=0.010277238372675718
Epoch #244: loss=0.009763982100199619
Epoch #245: loss=0.010729179829846112
Epoch #246: loss=0.011578517565445907
Epoch #247: loss=0.01078137648948217
Epoch #248: loss=0.008855143265389241
Epoch #249: loss=0.010391835456599214

Training time: 10:22:41.479075

Finished.
n2one setting etth1_etth2_traffic -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_traffic_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_etth2_traffic', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.42844e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.90478e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.7617e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.42844e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4081747931196734, 'MAE': 0.45304138174563763}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_traffic -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_traffic_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_etth2_traffic', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.29547e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.7383e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.29547e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3732736479871421, 'MAE': 0.45070153373637367}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_traffic -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_traffic_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_etth2_traffic', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
Evaluation result: {'MSE': 0.48933247402716323, 'MAE': 0.4510308068033607}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_weather', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_weather_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=7.502092367410659
Epoch #1: loss=3.0239446580410005
Epoch #2: loss=2.5957408964633943
Epoch #3: loss=2.29336002767086
Epoch #4: loss=2.2512045323848726
Epoch #5: loss=2.0396409928798676
Epoch #6: loss=1.8668824523687362
Epoch #7: loss=1.8144312977790833
Epoch #8: loss=1.8428464710712433
Epoch #9: loss=1.6917981058359146
Epoch #10: loss=1.5107340812683105
Epoch #11: loss=1.4538110852241517
Epoch #12: loss=1.4119087904691696
Epoch #13: loss=1.3581641346216202
Epoch #14: loss=1.1928377911448478
Epoch #15: loss=1.1869272410869598
Epoch #16: loss=1.15935720205307
Epoch #17: loss=1.1048321828246117
Epoch #18: loss=1.0397596955299377
Epoch #19: loss=0.9841871157288551
Epoch #20: loss=0.9559498101472854
Epoch #21: loss=0.9253692910075187
Epoch #22: loss=0.9839203670620918
Epoch #23: loss=0.8646086141467094
Epoch #24: loss=0.8582020804286004
Epoch #25: loss=0.8695125758647919
Epoch #26: loss=0.9023007720708847
Epoch #27: loss=0.8062520280480385
Epoch #28: loss=0.7927867874503136
Epoch #29: loss=0.7103688701987266
Epoch #30: loss=0.8420537680387497
Epoch #31: loss=0.7703169204294682
Epoch #32: loss=0.6751709587872028
Epoch #33: loss=0.652273690700531
Epoch #34: loss=0.6256676234304905
Epoch #35: loss=0.7744664765894413
Epoch #36: loss=0.9407287567853928
Epoch #37: loss=0.71795374751091
Epoch #38: loss=0.6561567656695843
Epoch #39: loss=0.6299052268266678
Epoch #40: loss=0.6117188416421413
Epoch #41: loss=0.5847877256572247
Epoch #42: loss=0.576361595839262
Epoch #43: loss=0.5454889260232448
Epoch #44: loss=0.5645688802003861
Epoch #45: loss=0.5461306668817997
Epoch #46: loss=0.4816605806350708
Epoch #47: loss=0.4834061101078987
Epoch #48: loss=0.5151151143014431
Epoch #49: loss=0.5099852085113525
Epoch #50: loss=0.47217343673110007
Epoch #51: loss=0.517608754336834
Epoch #52: loss=0.43813408985733987
Epoch #53: loss=0.4600567393004894
Epoch #54: loss=0.5093675576150417
Epoch #55: loss=0.43752785846590997
Epoch #56: loss=0.487127935141325
Epoch #57: loss=0.46867658346891405
Epoch #58: loss=0.44104022458195685
Epoch #59: loss=0.37653927952051164
Epoch #60: loss=0.38355548605322837
Epoch #61: loss=0.3611012361943722
Epoch #62: loss=0.3840697448700666
Epoch #63: loss=0.4861865945160389
Epoch #64: loss=0.442510199919343
Epoch #65: loss=0.4089376263320446
Epoch #66: loss=0.3424082025885582
Epoch #67: loss=0.3627344712615013
Epoch #68: loss=0.35769121497869494
Epoch #69: loss=0.433242042735219
Epoch #70: loss=0.38336957395076754
Epoch #71: loss=0.3513426922261715
Epoch #72: loss=0.271365387737751
Epoch #73: loss=0.2905335873365402
Epoch #74: loss=0.3519467949867249
Epoch #75: loss=0.3728896252810955
Epoch #76: loss=0.4294776275753975
Epoch #77: loss=0.2825956683605909
Epoch #78: loss=0.326164310798049
Epoch #79: loss=0.2511828806251287
Epoch #80: loss=0.3745372246950865
Epoch #81: loss=0.3359308812767267
Epoch #82: loss=0.28398016951978206
Epoch #83: loss=0.2602976540103555
Epoch #84: loss=0.3331883940845728
Epoch #85: loss=0.28210581820458175
Epoch #86: loss=0.35986996740102767
Epoch #87: loss=0.2836264636367559
Epoch #88: loss=0.3128859085962176
Epoch #89: loss=0.2424617398530245
Epoch #90: loss=0.22625244446098805
Epoch #91: loss=0.26414733584970235
Epoch #92: loss=0.2748975891619921
Epoch #93: loss=0.22920273672789335
Epoch #94: loss=0.21205043010413646
Epoch #95: loss=0.23621284533292056
Epoch #96: loss=0.19266523830592633
Epoch #97: loss=0.17744277976453304
Epoch #98: loss=0.245115839317441
Epoch #99: loss=0.2277690326794982
Epoch #100: loss=0.28644951675087216
Epoch #101: loss=0.25801495369523764
Epoch #102: loss=0.21730053871870042
Epoch #103: loss=0.2048058606684208
Epoch #104: loss=0.18942139353603124
Epoch #105: loss=0.2108219176530838
Epoch #106: loss=0.18222986478358508
Epoch #107: loss=0.22661548275500537
Epoch #108: loss=0.3083231933414936
Epoch #109: loss=0.21978326067328452
Epoch #110: loss=0.21706201899796723
Epoch #111: loss=0.20784861873835325
Epoch #112: loss=0.18844247348606585
Epoch #113: loss=0.20866633355617523
Epoch #114: loss=0.2671280739828944
Epoch #115: loss=0.18550895061343908
Epoch #116: loss=0.19352408722043038
Epoch #117: loss=0.17547454107552768
Epoch #118: loss=0.1570024191401899
Epoch #119: loss=0.1995156653225422
Epoch #120: loss=0.1940965917892754
Epoch #121: loss=0.13937647938728331
Epoch #122: loss=0.14722410216927528
Epoch #123: loss=0.1637468076311052
Epoch #124: loss=0.37709425389766693
Epoch #125: loss=0.6572115413844586
Epoch #126: loss=0.2950544061139226
Epoch #127: loss=0.23800248289480805
Epoch #128: loss=0.20437656212598085
Epoch #129: loss=0.21834818907082082
Epoch #130: loss=0.18858106415718795
Epoch #131: loss=0.18431267831474543
Epoch #132: loss=0.1585357513278723
Epoch #133: loss=0.135171920619905
Epoch #134: loss=0.13905786033719778
Epoch #135: loss=0.16421116683632137
Epoch #136: loss=0.12088384116068482
Epoch #137: loss=0.1639172312337905
Epoch #138: loss=0.13777026562020184
Epoch #139: loss=0.12122684167698025
Epoch #140: loss=0.13578734789043664
Epoch #141: loss=0.2013874461874366
Epoch #142: loss=0.1423888743855059
Epoch #143: loss=0.14862019540742039
Epoch #144: loss=0.16247402504086494
Epoch #145: loss=0.12860022196546197
Epoch #146: loss=0.12878890633583068
Epoch #147: loss=0.11069551915861667
Epoch #148: loss=0.21796806007623673
Epoch #149: loss=0.14814891703426838
Epoch #150: loss=0.1354728430043906
Epoch #151: loss=0.13403756292536856
Epoch #152: loss=0.1231450847350061
Epoch #153: loss=0.10792925236746669
Epoch #154: loss=0.14142844933085144
Epoch #155: loss=0.09642828912474215
Epoch #156: loss=0.10428566173650325
Epoch #157: loss=0.11335997711867093
Epoch #158: loss=0.1397740114480257
Epoch #159: loss=0.13878492470830678
Epoch #160: loss=0.1316418402828276
Epoch #161: loss=0.09970519882626831
Epoch #162: loss=0.13718135613016785
Epoch #163: loss=0.1216846493538469
Epoch #164: loss=0.11158891222439707
Epoch #165: loss=0.15716950930655002
Epoch #166: loss=0.10994250262156129
Epoch #167: loss=0.14359359918162226
Epoch #168: loss=0.10502625741064549
Epoch #169: loss=0.0957502900622785
Epoch #170: loss=0.10339840217493475
Epoch #171: loss=0.10421520178206264
Epoch #172: loss=0.13181754071265459
Epoch #173: loss=0.10211825254373252
Epoch #174: loss=0.12995333224534988
Epoch #175: loss=0.11403030045330524
Epoch #176: loss=0.13630904140882194
Epoch #177: loss=0.1424275679513812
Epoch #178: loss=0.16939091407693924
Epoch #179: loss=0.08838264644145966
Epoch #180: loss=0.08755901511758565
Epoch #181: loss=0.1011364558711648
Epoch #182: loss=0.11608108994551003
Epoch #183: loss=0.11740681258961558
Epoch #184: loss=0.2943891126662493
Epoch #185: loss=0.1775942967273295
Epoch #186: loss=0.11110236290842294
Epoch #187: loss=0.15246787592768668
Epoch #188: loss=0.1824167625978589
Epoch #189: loss=0.10378249613568187
Epoch #190: loss=0.09073838256299496
Epoch #191: loss=0.07478744564577937
Epoch #192: loss=0.10525474059395493
Epoch #193: loss=0.08464009405579417
Epoch #194: loss=0.10459003073628992
Epoch #195: loss=0.08727696174755692
Epoch #196: loss=0.08612801155541092
Epoch #197: loss=0.10251484997570515
Epoch #198: loss=0.0906080246437341
Epoch #199: loss=0.11332796984352171
Epoch #200: loss=0.1274915300309658
Epoch #201: loss=0.1400754958158359
Epoch #202: loss=0.1337858979124576
Epoch #203: loss=0.09478619759902358
Epoch #204: loss=0.08973474190570414
Epoch #205: loss=0.10855063050985336
Epoch #206: loss=0.09039403386414051
Epoch #207: loss=0.09210033817216753
Epoch #208: loss=0.10538682020269334
Epoch #209: loss=0.09183029914274812
Epoch #210: loss=0.11635534828528762
Epoch #211: loss=0.09680818137712777
Epoch #212: loss=0.0958746176213026
Epoch #213: loss=0.18224663343280553
Epoch #214: loss=0.10683585908263922
Epoch #215: loss=0.11082502542994917
Epoch #216: loss=0.08382845493033528
Epoch #217: loss=0.09524788320995867
Epoch #218: loss=0.0923865023534745
Epoch #219: loss=0.08610371043905615
Epoch #220: loss=0.0718822720227763
Epoch #221: loss=0.10808683710638434
Epoch #222: loss=0.07176684709265828
Epoch #223: loss=0.07743904343806207
Epoch #224: loss=0.06112769527826458
Epoch #225: loss=0.06975645755883306
Epoch #226: loss=0.11783040687441826
Epoch #227: loss=0.08207492674700916
Epoch #228: loss=0.0842604465316981
Epoch #229: loss=0.08895290484651923
Epoch #230: loss=0.08115840561222284
Epoch #231: loss=0.07752157601062208
Epoch #232: loss=0.07617111650761217
Epoch #233: loss=0.07192578336689621
Epoch #234: loss=0.07019591357093305
Epoch #235: loss=0.05916790019255132
Epoch #236: loss=0.06440217490307987
Epoch #237: loss=0.0624982071807608
Epoch #238: loss=0.08703158304560929
Epoch #239: loss=0.04884591607842594
Epoch #240: loss=0.058814577420707795
Epoch #241: loss=0.09225566773675382
Epoch #242: loss=0.08303029832895845
Epoch #243: loss=0.08704917791765183
Epoch #244: loss=0.0958432570565492
Epoch #245: loss=0.09003197900019586
Epoch #246: loss=0.07510100188665092
Epoch #247: loss=0.0668075014371425
Epoch #248: loss=0.14367136063519864
Epoch #249: loss=0.10740630649961531

Training time: 0:37:14.961616

Finished.
n2one setting etth1_etth2_weather -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_weather_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_etth2_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.61505e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.17432e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.61505e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3737998793414846, 'MAE': 0.43314695051924484}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_weather_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_etth2_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.06418e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.1859449258757793, 'MAE': 0.29849826081504777}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=4.174574819478122
Epoch #1: loss=2.2326122359796003
Epoch #2: loss=1.9514911283146252
Epoch #3: loss=1.8274484493515708
Epoch #4: loss=1.7587990110570735
Epoch #5: loss=1.665848265994679
Epoch #6: loss=1.5506843761964277
Epoch #7: loss=1.5058372779326006
Epoch #8: loss=1.3730949705297297
Epoch #9: loss=1.34259893135591
Epoch #10: loss=1.2542872049591758
Epoch #11: loss=1.2203592983159153
Epoch #12: loss=1.2038035230203108
Epoch #13: loss=1.1116283671422438
Epoch #14: loss=1.0966002209620043
Epoch #15: loss=1.0737578923052007
Epoch #16: loss=1.0433284884149379
Epoch #17: loss=1.0377565622329712
Epoch #18: loss=1.0483753789554944
Epoch #19: loss=1.012632500041615
Epoch #20: loss=0.9410211254249919
Epoch #21: loss=0.8743051507256248
Epoch #22: loss=0.9006979790600863
Epoch #23: loss=0.9241997139020399
Epoch #24: loss=0.813342968171293
Epoch #25: loss=0.8457209508527409
Epoch #26: loss=0.8116724518212405
Epoch #27: loss=0.8271937722509558
Epoch #28: loss=0.7777158387682654
Epoch #29: loss=0.7996276170015335
Epoch #30: loss=0.7326282574371858
Epoch #31: loss=0.7592387768355283
Epoch #32: loss=0.6416279348460111
Epoch #33: loss=0.7843710373748433
Epoch #34: loss=0.6953267549926584
Epoch #35: loss=0.617518347772685
Epoch #36: loss=0.6867949285290458
Epoch #37: loss=0.6230231130664999
Epoch #38: loss=0.659223192117431
Epoch #39: loss=0.6586053317243402
Epoch #40: loss=0.7345890470526435
Epoch #41: loss=0.688917570493438
Epoch #42: loss=0.6217009208419106
Epoch #43: loss=0.6998097124424848
Epoch #44: loss=0.7067772326144305
Epoch #45: loss=0.5695136771960692
Epoch #46: loss=0.5494788085872476
Epoch #47: loss=0.5841802968220278
Epoch #48: loss=0.573925955729051
Epoch #49: loss=0.49575788189064374
Epoch #50: loss=0.5199454602870074
Epoch #51: loss=0.5626066259362481
Epoch #52: loss=0.47216128490187903
Epoch #53: loss=0.6543199433521791
Epoch #54: loss=0.6463375958529386
Epoch #55: loss=0.5191801894794811
Epoch #56: loss=0.45239930938590656
Epoch #57: loss=0.5126465369354595
Epoch #58: loss=0.5267917798324064
Epoch #59: loss=0.4927456636320461
Epoch #60: loss=0.41903924264691095
Epoch #61: loss=0.47126697410236706
Epoch #62: loss=0.459749774499373
Epoch #63: loss=0.4422940666025335
Epoch #64: loss=0.44271253591234033
Epoch #65: loss=0.4942308271473104
Epoch #66: loss=0.49049194021658465
Epoch #67: loss=0.5119671659036116
Epoch #68: loss=0.46288586272434756
Epoch #69: loss=0.48931859975511377
Epoch #70: loss=0.3952464840628884
Epoch #71: loss=0.5372152491049333
Epoch #72: loss=0.5410069362683729
Epoch #73: loss=0.46211932599544525
Epoch #74: loss=0.49153258448297327
Epoch #75: loss=0.5104034001177008
Epoch #76: loss=0.4026955447413705
Epoch #77: loss=0.3734332309527831
Epoch #78: loss=0.4451502473516898
Epoch #79: loss=0.4456031715328043
Epoch #80: loss=0.4547147913412614
Epoch #81: loss=0.3668093058195981
Epoch #82: loss=0.3704610494050113
Epoch #83: loss=0.351401380517266
Epoch #84: loss=0.36315665529532865
Epoch #85: loss=0.3827617100693963
Epoch #86: loss=0.3928352262486111
Epoch #87: loss=0.3397492231293158
Epoch #88: loss=0.29066237062215805
Epoch #89: loss=0.33313416012308816
Epoch #90: loss=0.2904370938512412
Epoch #91: loss=0.32665727829391306
Epoch #92: loss=0.40262954478914087
Epoch #93: loss=0.3141458650881594
Epoch #94: loss=0.3157843459736217
Epoch #95: loss=0.32932760092345154
Epoch #96: loss=0.3510712032968348
Epoch #97: loss=0.34811442684043536
Epoch #98: loss=0.3071748038584536
Epoch #99: loss=0.37391435422680597
Epoch #100: loss=0.4604064097458666
Epoch #101: loss=0.3866694671186534
Epoch #102: loss=0.3599354706027291
Epoch #103: loss=0.44775368544188415
Epoch #104: loss=0.2850828184322877
Epoch #105: loss=0.31803007186813786
Epoch #106: loss=0.30516170913522894
Epoch #107: loss=0.30335204845125024
Epoch #108: loss=0.3433713296597654
Epoch #109: loss=0.35639383508400485
Epoch #110: loss=0.31361441991545935
Epoch #111: loss=0.3664210878989913
Epoch #112: loss=0.2977180392904715
Epoch #113: loss=0.299738772213459
Epoch #114: loss=0.27536711909554223
Epoch #115: loss=0.2589229111644355
Epoch #116: loss=0.24460177394476804
Epoch #117: loss=0.3944059671326117
Epoch #118: loss=0.3485282517292283
Epoch #119: loss=0.2897701561450958
Epoch #120: loss=0.2695265005935322
Epoch #121: loss=0.2652136155150153
Epoch #122: loss=0.29684034260836517
Epoch #123: loss=0.26253238862211054
Epoch #124: loss=0.2809532359242439
Epoch #125: loss=0.2852011468600143
Epoch #126: loss=0.3363311988386241
Epoch #127: loss=0.2801196351647377
Epoch #128: loss=0.27078406580469827
Epoch #129: loss=0.37391063841906463
Epoch #130: loss=0.35279239985075866
Epoch #131: loss=0.28192849321798846
Epoch #132: loss=0.2463963356885043
Epoch #133: loss=0.30672181329943915
Epoch #134: loss=0.2987183583053676
Epoch #135: loss=0.2796596007590944
Epoch #136: loss=0.2806992676447738
Epoch #137: loss=0.42477071623910556
Epoch #138: loss=0.35811851444569504
Epoch #139: loss=0.38203079388900235
Epoch #140: loss=0.2537852397019213
Epoch #141: loss=0.23843964053825897
Epoch #142: loss=0.2686494067311287
Epoch #143: loss=0.26461257379163394
Epoch #144: loss=0.22849840501492674
Epoch #145: loss=0.2738976072181355
Epoch #146: loss=0.2637190090661699
Epoch #147: loss=0.2553347596390681
Epoch #148: loss=0.25774192810058594
Epoch #149: loss=0.22698367556387727
Epoch #150: loss=0.23567396571690385
Epoch #151: loss=0.24000503326004202
Epoch #152: loss=0.1935503709722649
Epoch #153: loss=0.21759343452074312
Epoch #154: loss=0.31005682152780617
Epoch #155: loss=0.2429846440526572
Epoch #156: loss=0.20828789167783476
Epoch #157: loss=0.2017736824398691
Epoch #158: loss=0.18677712401205843
Epoch #159: loss=0.2123502946712754
Epoch #160: loss=0.23262089050628923
Epoch #161: loss=0.23346288366751236
Epoch #162: loss=0.32278736850077455
Epoch #163: loss=0.28716776045885956
Epoch #164: loss=0.2796988107941367
Epoch #165: loss=0.2689037113027139
Epoch #166: loss=0.30899772522124375
Epoch #167: loss=0.2755139134824276
Epoch #168: loss=0.2517960566011342
Epoch #169: loss=0.19927918301387268
Epoch #170: loss=0.23519909246401352
Epoch #171: loss=0.1980177074332129
Epoch #172: loss=0.2339073158800602
Epoch #173: loss=0.24930191988294775
Epoch #174: loss=0.2809350097721273
Epoch #175: loss=0.2051321000538089
Epoch #176: loss=0.2401272640986876
Epoch #177: loss=0.20941675386645578
Epoch #178: loss=0.19253804805603894
Epoch #179: loss=0.20122967558828267
Epoch #180: loss=0.18421706049279732
Epoch #181: loss=0.28602630441839044
Epoch #182: loss=0.2224019845439629
Epoch #183: loss=0.22154719111594287
Epoch #184: loss=0.19245896590026942
Epoch #185: loss=0.149536421014504
Epoch #186: loss=0.1900943714109334
Epoch #187: loss=0.2881681827658957
Epoch #188: loss=0.1801400465721434
Epoch #189: loss=0.21370694650845093
Epoch #190: loss=0.2929199222813953
Epoch #191: loss=0.18476668813011862
Epoch #192: loss=0.2094907486303286
Epoch #193: loss=0.22812727838754654
Epoch #194: loss=0.3159754384647716
Epoch #195: loss=0.26113746281374584
Epoch #196: loss=0.20652515576644379
Epoch #197: loss=0.2039832736958157
Epoch #198: loss=0.16928427530960602
Epoch #199: loss=0.15167731656269592
Epoch #200: loss=0.20073762739246542
Epoch #201: loss=0.1802680671892383
Epoch #202: loss=0.14387288909744134
Epoch #203: loss=0.1547935992817987
Epoch #204: loss=0.2882302352650599
Epoch #205: loss=0.1778958605771715
Epoch #206: loss=0.15595312890681354
Epoch #207: loss=0.16645074872808022
Epoch #208: loss=0.18490981513803656
Epoch #209: loss=0.16708659820935942
Epoch #210: loss=0.17167305506088518
Epoch #211: loss=0.16354641267521816
Epoch #212: loss=0.15109576335684818
Epoch #213: loss=0.16929922642355616
Epoch #214: loss=0.21914207749068737
Epoch #215: loss=0.40851856260137126
Epoch #216: loss=0.25051660666411574
Epoch #217: loss=0.1812547587535598
Epoch #218: loss=0.17837585712021048
Epoch #219: loss=0.15227319300174713
Epoch #220: loss=0.23093870383771983
Epoch #221: loss=0.2125530798326839
Epoch #222: loss=0.1449560165743936
Epoch #223: loss=0.19048068062825638
Epoch #224: loss=0.16212687573649667
Epoch #225: loss=0.16040030426599763
Epoch #226: loss=0.23653843338516625
Epoch #227: loss=0.23547981035980312
Epoch #228: loss=0.20776594091545453
Epoch #229: loss=0.20313387431881644
Epoch #230: loss=0.17214288901198993
Epoch #231: loss=0.15773502737283707
Epoch #232: loss=0.14876601506363263
Epoch #233: loss=0.11928090233017098
Epoch #234: loss=0.15703905585475944
Epoch #235: loss=0.1433175135065209
Epoch #236: loss=0.16541687212884426
Epoch #237: loss=0.1448967573656277
Epoch #238: loss=0.14532774297351186
Epoch #239: loss=0.22276954234323718
Epoch #240: loss=0.2039195964620872
Epoch #241: loss=0.27551036260344763
Epoch #242: loss=0.26668269593607297
Epoch #243: loss=0.1970642933791334
Epoch #244: loss=0.15318841419436716
Epoch #245: loss=0.1626319946213202
Epoch #246: loss=0.1555688711391254
Epoch #247: loss=0.17718155580488118
Epoch #248: loss=0.16273423047228294
Epoch #249: loss=0.1343197492374615

Training time: 0:15:06.314043

Finished.
n2one setting etth1_etth2_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_etth2_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.36094e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.62268e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.36094e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3636108844601381, 'MAE': 0.4280284910471251}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_etth2_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.28988e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.45842e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.87961e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.28988e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.49589012209783406, 'MAE': 0.5239535826120121}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm1_ettm2', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm1_ettm2_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=4.6008284749655886
Epoch #1: loss=2.520519059279869
Epoch #2: loss=2.1616082766960405
Epoch #3: loss=1.9590778761896595
Epoch #4: loss=1.7904976441942413
Epoch #5: loss=1.6198127434171479
Epoch #6: loss=1.4203397487771923
Epoch #7: loss=1.4817212203453327
Epoch #8: loss=1.2563867815609635
Epoch #9: loss=1.204168926025259
Epoch #10: loss=1.1596932657833756
Epoch #11: loss=1.0880468981019382
Epoch #12: loss=1.0071146981469516
Epoch #13: loss=1.00116235428843
Epoch #14: loss=0.9219650831715814
Epoch #15: loss=0.8819460683855517
Epoch #16: loss=0.8922448117157509
Epoch #17: loss=0.8858880791170843
Epoch #18: loss=0.8138767665830152
Epoch #19: loss=0.8171959211086405
Epoch #20: loss=0.8524895515935175
Epoch #21: loss=0.8451850270402843
Epoch #22: loss=0.6750158503137785
Epoch #23: loss=0.6897055383386284
Epoch #24: loss=0.6271238306473041
Epoch #25: loss=0.6490741567365055
Epoch #26: loss=0.6041219131699924
Epoch #27: loss=0.624615124587355
Epoch #28: loss=0.6017037311504627
Epoch #29: loss=0.8223610972536022
Epoch #30: loss=0.6283471676810034
Epoch #31: loss=0.5839547545745455
Epoch #32: loss=0.49428771795897647
Epoch #33: loss=0.519605754778303
Epoch #34: loss=0.5145249818933422
Epoch #35: loss=0.5797153546892363
Epoch #36: loss=0.5379062695749874
Epoch #37: loss=0.6138482648750831
Epoch #38: loss=0.4805689114948799
Epoch #39: loss=0.5294545169534355
Epoch #40: loss=0.4434686775865226
Epoch #41: loss=0.48586145146139736
Epoch #42: loss=0.4644824132837098
Epoch #43: loss=0.435595513417803
Epoch #44: loss=0.5514635248430844
Epoch #45: loss=0.5205801088234474
Epoch #46: loss=0.4947419711228075
Epoch #47: loss=0.407661280755339
Epoch #48: loss=0.37461696102701386
Epoch #49: loss=0.3259727389648043
Epoch #50: loss=0.4059988008490924
Epoch #51: loss=0.4473661831740675
Epoch #52: loss=0.3839382149022201
Epoch #53: loss=0.4636795988370632
Epoch #54: loss=0.39138353487540933
Epoch #55: loss=0.4587050686622488
Epoch #56: loss=0.40337780477671786
Epoch #57: loss=0.388342395938676
Epoch #58: loss=0.31452330278939217
Epoch #59: loss=0.35957636298804446
Epoch #60: loss=0.38837580382823944
Epoch #61: loss=0.3182855839359349
Epoch #62: loss=0.3191537384329171
Epoch #63: loss=0.39515705458049116
Epoch #64: loss=0.5427428966966169
Epoch #65: loss=0.34649560369294263
Epoch #66: loss=0.3544803498120144
Epoch #67: loss=0.2896407524059559
Epoch #68: loss=0.29905005159049197
Epoch #69: loss=0.28614641674633684
Epoch #70: loss=0.30933810976044884
Epoch #71: loss=0.422223178990956
Epoch #72: loss=0.28538385084990797
Epoch #73: loss=0.3161732025187591
Epoch #74: loss=0.27517719361288795
Epoch #75: loss=0.3056741626612071
Epoch #76: loss=0.26074671257158805
Epoch #77: loss=0.22160641309516182
Epoch #78: loss=0.24529993379938192
Epoch #79: loss=0.17571505313289576
Epoch #80: loss=0.2569050598761131
Epoch #81: loss=0.23848340377725405
Epoch #82: loss=0.3313005702762768
Epoch #83: loss=0.2717727502358371
Epoch #84: loss=0.1901267196597724
Epoch #85: loss=0.2204935729246715
Epoch #86: loss=0.16804016163123064
Epoch #87: loss=0.18869566236590518
Epoch #88: loss=0.18180344934607373
Epoch #89: loss=0.1713587190827419
Epoch #90: loss=0.1863329257687618
Epoch #91: loss=0.2075560948458211
Epoch #92: loss=0.15297590684274148
Epoch #93: loss=0.17611467555679125
Epoch #94: loss=0.15848728384951066
Epoch #95: loss=0.18024600322904258
Epoch #96: loss=0.21504459440194326
Epoch #97: loss=0.2315960886149571
Epoch #98: loss=0.22845188900828362
Epoch #99: loss=0.20009194699854688
Epoch #100: loss=0.15617715104900556
Epoch #101: loss=0.1212718093703533
Epoch #102: loss=0.12217940280920472
Epoch #103: loss=0.23483956181283655
Epoch #104: loss=0.1773730682144905
Epoch #105: loss=0.1306375933104548
Epoch #106: loss=0.12340115807179747
Epoch #107: loss=0.11077733581949925
Epoch #108: loss=0.14086052338624822
Epoch #109: loss=0.20133001447237772
Epoch #110: loss=0.1401436805468181
Epoch #111: loss=0.12187551809795971
Epoch #112: loss=0.15561228431761265
Epoch #113: loss=0.15322426719398335
Epoch #114: loss=0.107254174891217
Epoch #115: loss=0.1831221071810558
Epoch #116: loss=0.13149385931419916
Epoch #117: loss=0.13480600451344046
Epoch #118: loss=0.2529681113002629
Epoch #119: loss=0.17263515653281375
Epoch #120: loss=0.10616369378463976
Epoch #121: loss=0.14115990865333328
Epoch #122: loss=0.1635503127271759
Epoch #123: loss=0.2196018397808075
Epoch #124: loss=0.167541710852549
Epoch #125: loss=0.16807411463353142
Epoch #126: loss=0.11600921238804686
Epoch #127: loss=0.11743781433023255
Epoch #128: loss=0.10632211201149842
Epoch #129: loss=0.12421724508548605
Epoch #130: loss=0.11509854963113522
Epoch #131: loss=0.14213070915690784
Epoch #132: loss=0.14911369883037848
Epoch #133: loss=0.1052053358148912
Epoch #134: loss=0.6286881426028137
Epoch #135: loss=0.2839460229051524
Epoch #136: loss=0.13257789342054005
Epoch #137: loss=0.10903396804271073
Epoch #138: loss=0.10394465473705325
Epoch #139: loss=0.14303262570294842
Epoch #140: loss=0.17440263092004019
Epoch #141: loss=0.11781381282570033
Epoch #142: loss=0.10967839502825819
Epoch #143: loss=0.13896617884265966
Epoch #144: loss=0.1438718480539733
Epoch #145: loss=0.12313158591759615
Epoch #146: loss=0.1389401126652956
Epoch #147: loss=0.07795284598551948
Epoch #148: loss=0.17460374245098953
Epoch #149: loss=0.0957035605378192
Epoch #150: loss=0.10229887434377752
Epoch #151: loss=0.09104224448574
Epoch #152: loss=0.1006839455201708
Epoch #153: loss=0.10373949336594548
Epoch #154: loss=0.13504744815672265
Epoch #155: loss=0.12866505896993752
Epoch #156: loss=0.11691031682080236
Epoch #157: loss=0.09199094720955553
Epoch #158: loss=0.08302332017699192
Epoch #159: loss=0.08689688830154724
Epoch #160: loss=0.08984306120666964
Epoch #161: loss=0.08495901155703027
Epoch #162: loss=0.09773882696854658
Epoch #163: loss=0.16301127442897395
Epoch #164: loss=0.09826108800439999
Epoch #165: loss=0.15083095424904905
Epoch #166: loss=0.10549162119498541
Epoch #167: loss=0.0888924505882736
Epoch #168: loss=0.09325399063527584
Epoch #169: loss=0.08356426074972441
Epoch #170: loss=0.07310004391033074
Epoch #171: loss=0.0817871258497752
Epoch #172: loss=0.07630984552589984
Epoch #173: loss=0.09091655479679847
Epoch #174: loss=0.093027890788327
Epoch #175: loss=0.14602673214314313
Epoch #176: loss=0.13919401547775187
Epoch #177: loss=0.11946726635355374
Epoch #178: loss=0.12460988194778047
Epoch #179: loss=0.0735480818126736
Epoch #180: loss=0.06909661717584421
Epoch #181: loss=0.0897014547010948
Epoch #182: loss=0.14278504409795179
Epoch #183: loss=0.11938778844116063
Epoch #184: loss=0.07452478256590407
Epoch #185: loss=0.19403560575226259
Epoch #186: loss=0.14143108486615377
Epoch #187: loss=0.09938483505413451
Epoch #188: loss=0.1655111064299427
Epoch #189: loss=0.13494967315988293
Epoch #190: loss=0.08476429188559795
Epoch #191: loss=0.09879264142364264
Epoch #192: loss=0.07066024149414794
Epoch #193: loss=0.09828052547728193
Epoch #194: loss=0.07508042904323545
Epoch #195: loss=0.09179908217027269
Epoch #196: loss=0.07916057983349109
Epoch #197: loss=0.06073087235463077
Epoch #198: loss=0.05999535598374646
Epoch #199: loss=0.061786698016883995
Epoch #200: loss=0.07295822663682289
Epoch #201: loss=0.08597292664364495
Epoch #202: loss=0.09877115109100423
Epoch #203: loss=0.11253087884136315
Epoch #204: loss=0.12456472873173911
Epoch #205: loss=0.13992571204515367
Epoch #206: loss=0.08393703979151003
Epoch #207: loss=0.07241654585533101
Epoch #208: loss=0.07725320984448852
Epoch #209: loss=0.08498783399961118
Epoch #210: loss=0.07806202627975366
Epoch #211: loss=0.07175442878285358
Epoch #212: loss=0.06760922715003634
Epoch #213: loss=0.05366842715262339
Epoch #214: loss=0.05082007850809344
Epoch #215: loss=0.07306460796951733
Epoch #216: loss=0.05766175199171592
Epoch #217: loss=0.06422704217377408
Epoch #218: loss=0.06370282200454123
Epoch #219: loss=0.0810340582232537
Epoch #220: loss=0.060019778440995465
Epoch #221: loss=0.08839801233261824
Epoch #222: loss=0.05317025307309011
Epoch #223: loss=0.04782594029053018
Epoch #224: loss=0.06906646130413845
Epoch #225: loss=0.10188011208484912
Epoch #226: loss=0.09030275830420954
Epoch #227: loss=0.06315985347690253
Epoch #228: loss=0.06979703588475442
Epoch #229: loss=0.09413978569851868
Epoch #230: loss=0.08553212107127083
Epoch #231: loss=0.08186414693321648
Epoch #232: loss=0.07808708364208197
Epoch #233: loss=0.06343074332408864
Epoch #234: loss=0.13583152384722028
Epoch #235: loss=0.06646236546080687
Epoch #236: loss=0.08316246188920119
Epoch #237: loss=0.06301803451737967
Epoch #238: loss=0.06095061753073643
Epoch #239: loss=0.05054400499974345
Epoch #240: loss=0.07167368504250872
Epoch #241: loss=0.06454189166683576
Epoch #242: loss=0.03982964408551824
Epoch #243: loss=0.060499147383560395
Epoch #244: loss=0.061352641016630266
Epoch #245: loss=0.0880791815158365
Epoch #246: loss=0.05166854654792054
Epoch #247: loss=0.051445471219204626
Epoch #248: loss=0.061093379839740954
Epoch #249: loss=0.042669922948397436

Training time: 0:28:24.197482

Finished.
n2one setting etth1_ettm1_ettm2 -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_ettm2_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_ettm1_ettm2', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.48551e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.88643e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.48551e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.37770679058456225, 'MAE': 0.433397974284174}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm1_ettm2 -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_ettm2_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_ettm1_ettm2', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.7477e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.27388e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.7477e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.9464562492874926, 'MAE': 0.790016258828734}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm1_ettm2 -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_ettm2_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_ettm1_ettm2', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.98536e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.25159354235540826, 'MAE': 0.33873490682808177}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm1_electricity', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm1_electricity_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.7500588886857384
Epoch #1: loss=0.7304417068100257
Epoch #2: loss=0.5030717596104012
Epoch #3: loss=0.3844055016044319
Epoch #4: loss=0.34452295734115757
Epoch #5: loss=0.2991216148862445
Epoch #6: loss=0.25011146657586447
Epoch #7: loss=0.24486619906615367
Epoch #8: loss=0.18686674561648242
Epoch #9: loss=0.16899102770209665
Epoch #10: loss=0.15316618858097578
Epoch #11: loss=0.140614216834043
Epoch #12: loss=0.15843311647793887
Epoch #13: loss=0.11732010592797161
Epoch #14: loss=0.11434643448036505
Epoch #15: loss=0.11404040316806606
Epoch #16: loss=0.09965769043274686
Epoch #17: loss=0.10061492746184884
Epoch #18: loss=0.09194982924380485
Epoch #19: loss=0.06970109384792657
Epoch #20: loss=0.0788553583910991
Epoch #21: loss=0.0615667426645492
Epoch #22: loss=0.07042310883189416
Epoch #23: loss=0.06969385198935603
Epoch #24: loss=0.05306386751339807
Epoch #25: loss=0.06498771887217651
Epoch #26: loss=0.05904940334437168
Epoch #27: loss=0.04814835682588253
Epoch #28: loss=0.056593025968599636
Epoch #29: loss=0.04050561214266977
Epoch #30: loss=0.058000266973676495
Epoch #31: loss=0.044928938282274566
Epoch #32: loss=0.0389464002186405
Epoch #33: loss=0.0368203921827342
Epoch #34: loss=0.0392332609817056
Epoch #35: loss=0.0398901290470421
Epoch #36: loss=0.03920556956580717
Epoch #37: loss=0.032399368788332716
Epoch #38: loss=0.03265189054727027
Epoch #39: loss=0.036783242238284386
Epoch #40: loss=0.03166528614059332
Epoch #41: loss=0.0409629842600233
Epoch #42: loss=0.03014597166219732
Epoch #43: loss=0.03622818361572196
Epoch #44: loss=0.07958756547811328
Epoch #45: loss=0.0353514753353499
Epoch #46: loss=0.027061592660786633
Epoch #47: loss=0.04417754270227016
Epoch #48: loss=0.03278972265780368
Epoch #49: loss=0.03393259947943696
Epoch #50: loss=0.03151134409080465
Epoch #51: loss=0.03395623953533592
Epoch #52: loss=0.03458494340635528
Epoch #53: loss=0.018720819903290376
Epoch #54: loss=0.0295489217500837
Epoch #55: loss=0.023663232494131894
Epoch #56: loss=0.03483864525333047
Epoch #57: loss=0.025763102588010265
Epoch #58: loss=0.028003160499728622
Epoch #59: loss=0.019893649946637233
Epoch #60: loss=0.01810347733216959
Epoch #61: loss=0.03277447911846152
Epoch #62: loss=0.03506200591680542
Epoch #63: loss=0.025284124452107006
Epoch #64: loss=0.02619133713541162
Epoch #65: loss=0.016928121285131173
Epoch #66: loss=0.022857031054866216
Epoch #67: loss=0.034235590411580905
Epoch #68: loss=0.02420131720267346
Epoch #69: loss=0.016260129538677896
Epoch #70: loss=0.017940939299159225
Epoch #71: loss=0.02223772036013328
Epoch #72: loss=0.029525962389338002
Epoch #73: loss=0.023018995650898346
Epoch #74: loss=0.014848988108298464
Epoch #75: loss=0.021577880127152158
Epoch #76: loss=0.01602477575123453
Epoch #77: loss=0.02083031515965848
Epoch #78: loss=0.03542864456007691
Epoch #79: loss=0.014303870769567887
Epoch #80: loss=0.015263520540727254
Epoch #81: loss=0.019184033460242007
Epoch #82: loss=0.024757553624115598
Epoch #83: loss=0.01860617006823948
Epoch #84: loss=0.011309198560062687
Epoch #85: loss=0.01662480972235429
Epoch #86: loss=0.015670843394425118
Epoch #87: loss=0.023771642208488104
Epoch #88: loss=0.01638287619414951
Epoch #89: loss=0.017578236863276697
Epoch #90: loss=0.015216638451111764
Epoch #91: loss=0.016730747229947125
Epoch #92: loss=0.015171691696681523
Epoch #93: loss=0.023393130820700596
Epoch #94: loss=0.018710603073835482
Epoch #95: loss=0.013066644893490756
Epoch #96: loss=0.03741371275302144
Epoch #97: loss=0.01909878670758565
Epoch #98: loss=0.018441827347911454
Epoch #99: loss=0.01535028831553879
Epoch #100: loss=0.019571428266175334
Epoch #101: loss=0.01322034899293717
Epoch #102: loss=0.01341063563593809
Epoch #103: loss=0.015951435158069033
Epoch #104: loss=0.01650316251670546
Epoch #105: loss=0.016005822694496387
Epoch #106: loss=0.0250846044312212
Epoch #107: loss=0.01423762595108614
Epoch #108: loss=0.06282822223198889
Epoch #109: loss=0.015400063080622493
Epoch #110: loss=0.020059358596954232
Epoch #111: loss=0.013743728296426028
Epoch #112: loss=0.031919900676136655
Epoch #113: loss=0.015122284580563479
Epoch #114: loss=0.01730047984491377
Epoch #115: loss=0.012167866184488818
Epoch #116: loss=0.013934781642494707
Epoch #117: loss=0.017417655333981007
Epoch #118: loss=0.019016829553502545
Epoch #119: loss=0.016045219128934946
Epoch #120: loss=0.013521331131999494
Epoch #121: loss=0.015333037157227069
Epoch #122: loss=0.015735485413452408
Epoch #123: loss=0.019056087672115637
Epoch #124: loss=0.025998603330738293
Epoch #125: loss=0.012322688755729706
Epoch #126: loss=0.009256179014802567
Epoch #127: loss=0.014786783239741022
Epoch #128: loss=0.017884106176443794
Epoch #129: loss=0.017735161807746584
Epoch #130: loss=0.014345089047989234
Epoch #131: loss=0.013947017390932064
Epoch #132: loss=0.012009991304214034
Epoch #133: loss=0.020903915578601086
Epoch #134: loss=0.011983852620081356
Epoch #135: loss=0.01575557339423443
Epoch #136: loss=0.016524992162048554
Epoch #137: loss=0.013666744639095644
Epoch #138: loss=0.015027591277320477
Epoch #139: loss=0.009618542521984583
Epoch #140: loss=0.017450461697772937
Epoch #141: loss=0.00978743501382215
Epoch #142: loss=0.007390795780035357
Epoch #143: loss=0.016953835396060397
Epoch #144: loss=0.012284590274261745
Epoch #145: loss=0.01704759006117193
Epoch #146: loss=0.017778092569288327
Epoch #147: loss=0.016279873864005447
Epoch #148: loss=0.01218184163808688
Epoch #149: loss=0.009381505408994633
Epoch #150: loss=0.013961893367954697
Epoch #151: loss=0.009672735097775494
Epoch #152: loss=0.007926513587885637
Epoch #153: loss=0.01631542424424785
Epoch #154: loss=0.018662985251834588
Epoch #155: loss=0.0248334364844335
Epoch #156: loss=0.010916200937180584
Epoch #157: loss=0.012984225585003133
Epoch #158: loss=0.008857651549220774
Epoch #159: loss=0.018064935227710435
Epoch #160: loss=0.013615119833997822
Epoch #161: loss=0.01382196791230352
Epoch #162: loss=0.008480792095665586
Epoch #163: loss=0.017381659322411404
Epoch #164: loss=0.010788154837422645
Epoch #165: loss=0.011497275598101995
Epoch #166: loss=0.018201349200619037
Epoch #167: loss=0.011773734574980902
Epoch #168: loss=0.011192342140409645
Epoch #169: loss=0.012856439558361934
Epoch #170: loss=0.009539065903339777
Epoch #171: loss=0.011091958860019194
Epoch #172: loss=0.012239753946718269
Epoch #173: loss=0.014250127011844834
Epoch #174: loss=0.01131111620758814
Epoch #175: loss=0.011384516123889679
Epoch #176: loss=0.010870389780355892
Epoch #177: loss=0.012363007095035242
Epoch #178: loss=0.007054414903964149
Epoch #179: loss=0.015699324849683925
Epoch #180: loss=0.014739725150076596
Epoch #181: loss=0.009806925904625273
Epoch #182: loss=0.010932047644566201
Epoch #183: loss=0.011961990397679001
Epoch #184: loss=0.010966519955397998
Epoch #185: loss=0.013980674995662325
Epoch #186: loss=0.012766199172836739
Epoch #187: loss=0.012885130272050467
Epoch #188: loss=0.00814335152603326
Epoch #189: loss=0.011680531643631876
Epoch #190: loss=0.013398294150279863
Epoch #191: loss=0.01202114092276753
Epoch #192: loss=0.011873910142792867
Epoch #193: loss=0.008300568663517211
Epoch #194: loss=0.004349132130483295
Epoch #195: loss=0.006987756864489866
Epoch #196: loss=0.018316360955623837
Epoch #197: loss=0.01174431528518688
Epoch #198: loss=0.007543935839778395
Epoch #199: loss=0.011200101099356152
Epoch #200: loss=0.014365434355825697
Epoch #201: loss=0.020529340626998148
Epoch #202: loss=0.007936273588507731
Epoch #203: loss=0.00945556707776208
Epoch #204: loss=0.013807239173619616
Epoch #205: loss=0.008975125336710495
Epoch #206: loss=0.012079071449967524
Epoch #207: loss=0.011438106447506344
Epoch #208: loss=0.0101951818902404
Epoch #209: loss=0.013248586287577073
Epoch #210: loss=0.01923844917844926
Epoch #211: loss=0.012539506743759588
Epoch #212: loss=0.011280119775727139
Epoch #213: loss=0.009642961718760853
Epoch #214: loss=0.013230934604153498
Epoch #215: loss=0.018611873058941502
Epoch #216: loss=0.023847707136960668
Epoch #217: loss=0.008459133942797643
Epoch #218: loss=0.007817128723934376
Epoch #219: loss=0.010619602744415358
Epoch #220: loss=0.012505995689693475
Epoch #221: loss=0.0108163942301139
Epoch #222: loss=0.012839193400586228
Epoch #223: loss=0.012062918268687403
Epoch #224: loss=0.009329827192959246
Epoch #225: loss=0.00951328484735477
Epoch #226: loss=0.008103432920369922
Epoch #227: loss=0.007626281278280014
Epoch #228: loss=0.01093416715488607
Epoch #229: loss=0.013004354763416172
Epoch #230: loss=0.011878728120179798
Epoch #231: loss=0.008945033115016814
Epoch #232: loss=0.010854509492386902
Epoch #233: loss=0.009167696354430991
Epoch #234: loss=0.008727923961235059
Epoch #235: loss=0.011485180284961533
Epoch #236: loss=0.008903190144509418
Epoch #237: loss=0.013069455082264555
Epoch #238: loss=0.008108022394655327
Epoch #239: loss=0.008273799506453577
Epoch #240: loss=0.013553033940675896
Epoch #241: loss=0.019678547600394797
Epoch #242: loss=0.009471014646331129
Epoch #243: loss=0.009056003368837391
Epoch #244: loss=0.011515303219996179
Epoch #245: loss=0.012198754767856387
Epoch #246: loss=0.005849604395710641
Epoch #247: loss=0.010117172163459238
Epoch #248: loss=0.007335821861177298
Epoch #249: loss=0.01648397923682083

Training time: 4:36:50.808938

Finished.
n2one setting etth1_ettm1_electricity -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_electricity_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_ettm1_electricity', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.26806e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.43403e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.6920069164534485, 'MAE': 0.6571355316666653}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm1_electricity -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_electricity_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_ettm1_electricity', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.65265e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.24097090539186303, 'MAE': 0.33758949006818834}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm1_traffic', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm1_traffic_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.040435377643867
Epoch #1: loss=0.36600975988602097
Epoch #2: loss=0.27445998137647454
Epoch #3: loss=0.19447082162580706
Epoch #4: loss=0.16350671470757913
Epoch #5: loss=0.12816032895987683
Epoch #6: loss=0.11249581563117152
Epoch #7: loss=0.11490246768067168
Epoch #8: loss=0.08322039906634018
Epoch #9: loss=0.0783115651416169
Epoch #10: loss=0.07003921503624455
Epoch #11: loss=0.06447816662839614
Epoch #12: loss=0.0570952950775708
Epoch #13: loss=0.06670739208506844
Epoch #14: loss=0.05271589871104383
Epoch #15: loss=0.04318251329717565
Epoch #16: loss=0.04192079951013015
Epoch #17: loss=0.059886686846783214
Epoch #18: loss=0.04809551758622878
Epoch #19: loss=0.04851250476971142
Epoch #20: loss=0.0419907808692766
Epoch #21: loss=0.038357429126732644
Epoch #22: loss=0.03143768192914484
Epoch #23: loss=0.03946469944441395
Epoch #24: loss=0.03695190279739274
Epoch #25: loss=0.031477244057697876
Epoch #26: loss=0.03292804992696884
Epoch #27: loss=0.03138508615957107
Epoch #28: loss=0.03319512446297185
Epoch #29: loss=0.029543233683084095
Epoch #30: loss=0.03480624539237893
Epoch #31: loss=0.02470485312614156
Epoch #32: loss=0.04453861738372573
Epoch #33: loss=0.026588667621465653
Epoch #34: loss=0.031227024367597715
Epoch #35: loss=0.030601280132652228
Epoch #36: loss=0.026737876438445794
Epoch #37: loss=0.021378865204447223
Epoch #38: loss=0.02432896861467849
Epoch #39: loss=0.023363103898406155
Epoch #40: loss=0.024686143526460827
Epoch #41: loss=0.02774857958363348
Epoch #42: loss=0.027053187685470964
Epoch #43: loss=0.02199999143340392
Epoch #44: loss=0.019939458739298227
Epoch #45: loss=0.024756944216510007
Epoch #46: loss=0.03788583442113701
Epoch #47: loss=0.020021814822658517
Epoch #48: loss=0.019608657058217266
Epoch #49: loss=0.018988428842368937
Epoch #50: loss=0.015606459255319682
Epoch #51: loss=0.022920654697968116
Epoch #52: loss=0.020984431954076916
Epoch #53: loss=0.020305935473284492
Epoch #54: loss=0.024372609721533742
Epoch #55: loss=0.020057757494725013
Epoch #56: loss=0.0285664031581043
Epoch #57: loss=0.01618821769860171
Epoch #58: loss=0.021270887165618743
Epoch #59: loss=0.020321561762830242
Epoch #60: loss=0.01772500071787032
Epoch #61: loss=0.023733071188020073
Epoch #62: loss=0.017199474625720707
Epoch #63: loss=0.0183819961840775
Epoch #64: loss=0.026294539236815496
Epoch #65: loss=0.014097176619675751
Epoch #66: loss=0.01737226074315417
Epoch #67: loss=0.02109312769544803
Epoch #68: loss=0.01939780946115868
Epoch #69: loss=0.017924325448323297
Epoch #70: loss=0.029570344750060363
Epoch #71: loss=0.015770777787970886
Epoch #72: loss=0.014383941682172007
Epoch #73: loss=0.01375521845253719
Epoch #74: loss=0.016565062706186753
Epoch #75: loss=0.01864723332711781
Epoch #76: loss=0.022904045624388594
Epoch #77: loss=0.014639056636158124
Epoch #78: loss=0.015484857004048535
Epoch #79: loss=0.017185438370341383
Epoch #80: loss=0.017045576265875505
Epoch #81: loss=0.01415060079003028
Epoch #82: loss=0.016155825752205352
Epoch #83: loss=0.015869899207940432
Epoch #84: loss=0.015063367029175755
Epoch #85: loss=0.015425229131373768
Epoch #86: loss=0.018338041754991125
Epoch #87: loss=0.0163588188236066
Epoch #88: loss=0.013687640232059163
Epoch #89: loss=0.017836156620619062
Epoch #90: loss=0.015284150302944577
Epoch #91: loss=0.01443822439700439
Epoch #92: loss=0.014343512857720436
Epoch #93: loss=0.016431356030906584
Epoch #94: loss=0.012035359424209508
Epoch #95: loss=0.013597088582702616
Epoch #96: loss=0.014961240859139996
Epoch #97: loss=0.0149487219501845
Epoch #98: loss=0.023138168395036535
Epoch #99: loss=0.022237530587219886
Epoch #100: loss=0.015374333150942799
Epoch #101: loss=0.014585103665211301
Epoch #102: loss=0.016199975157261095
Epoch #103: loss=0.018948526322889268
Epoch #104: loss=0.012803513175227139
Epoch #105: loss=0.013296721029275265
Epoch #106: loss=0.014525360753693596
Epoch #107: loss=0.03596240274822445
Epoch #108: loss=0.012804557018468833
Epoch #109: loss=0.015126974771820558
Epoch #110: loss=0.014836011401398123
Epoch #111: loss=0.013560715998557333
Epoch #112: loss=0.01640663572748467
Epoch #113: loss=0.018407014832767098
Epoch #114: loss=0.01208440395153461
Epoch #115: loss=0.011876915667380672
Epoch #116: loss=0.012329913556360142
Epoch #117: loss=0.00873754094612774
Epoch #118: loss=0.017131734938084266
Epoch #119: loss=0.014155016266224927
Epoch #120: loss=0.014197526913961735
Epoch #121: loss=0.015394438727492922
Epoch #122: loss=0.01129678338385764
Epoch #123: loss=0.018516989567036613
Epoch #124: loss=0.012868922583055048
Epoch #125: loss=0.01255304737615833
Epoch #126: loss=0.016993791168550324
Epoch #127: loss=0.012738351581852343
Epoch #128: loss=0.011733392396474135
Epoch #129: loss=0.011119683666633632
Epoch #130: loss=0.014853527491637082
Epoch #131: loss=0.011823245867146231
Epoch #132: loss=0.010830249874726921
Epoch #133: loss=0.010921831312556274
Epoch #134: loss=0.01477063014830161
Epoch #135: loss=0.014681487464887058
Epoch #136: loss=0.009432894195081396
Epoch #137: loss=0.01311516952532243
Epoch #138: loss=0.01274308954988638
Epoch #139: loss=0.031858054266988296
Epoch #140: loss=0.012484964482262677
Epoch #141: loss=0.010787869125422069
Epoch #142: loss=0.011277535187069919
Epoch #143: loss=0.012284430371850745
Epoch #144: loss=0.017857938896254796
Epoch #145: loss=0.013274368203490832
Epoch #146: loss=0.011642021602495911
Epoch #147: loss=0.01634485219593361
Epoch #148: loss=0.011366343988298798
Epoch #149: loss=0.013312553703082647
Epoch #150: loss=0.01271461910483512
Epoch #151: loss=0.01291377918784168
Epoch #152: loss=0.012384718806259281
Epoch #153: loss=0.010351867453341997
Epoch #154: loss=0.012492311411055694
Epoch #155: loss=0.015659285656345837
Epoch #156: loss=0.015193272134869899
Epoch #157: loss=0.013413101156038465
Epoch #158: loss=0.011137311370062393
Epoch #159: loss=0.013298903220923173
Epoch #160: loss=0.01193939736437063
Epoch #161: loss=0.01113376274760495
Epoch #162: loss=0.016005443814025386
Epoch #163: loss=0.01430889781740916
Epoch #164: loss=0.010328913988467485
Epoch #165: loss=0.015206182884470433
Epoch #166: loss=0.008607795737473431
Epoch #167: loss=0.010572906385740762
Epoch #168: loss=0.013097332540862474
Epoch #169: loss=0.014035374409352451
Epoch #170: loss=0.012079607466016155
Epoch #171: loss=0.006681735663567617
Epoch #172: loss=0.01616747638727247
Epoch #173: loss=0.011213835949324262
Epoch #174: loss=0.012067108233069038
Epoch #175: loss=0.009292785352723017
Epoch #176: loss=0.009144830487077177
Epoch #177: loss=0.011333079447418144
Epoch #178: loss=0.012309364027479123
Epoch #179: loss=0.015420340273174753
Epoch #180: loss=0.013422142516308936
Epoch #181: loss=0.009093150101232989
Epoch #182: loss=0.007773976349471923
Epoch #183: loss=0.01394700447655685
Epoch #184: loss=0.012758139090279159
Epoch #185: loss=0.012297203091723283
Epoch #186: loss=0.011135500062647968
Epoch #187: loss=0.00930322018305312
Epoch #188: loss=0.009387380147605158
Epoch #189: loss=0.010704890339029435
Epoch #190: loss=0.010821854885150308
Epoch #191: loss=0.015422791348762323
Epoch #192: loss=0.008773541631986022
Epoch #193: loss=0.011611950294272075
Epoch #194: loss=0.010503042197623555
Epoch #195: loss=0.011895530525295975
Epoch #196: loss=0.010855328601808817
Epoch #197: loss=0.010634031334749041
Epoch #198: loss=0.007737748148449761
Epoch #199: loss=0.012828751078235324
Epoch #200: loss=0.009935568844825453
Epoch #201: loss=0.010550462988600306
Epoch #202: loss=0.010683191330231653
Epoch #203: loss=0.011130136206826468
Epoch #204: loss=0.01252409132607268
Epoch #205: loss=0.008262383936595473
Epoch #206: loss=0.014696421115679021
Epoch #207: loss=0.009333323500058296
Epoch #208: loss=0.007684400099953398
Epoch #209: loss=0.013499570704549445
Epoch #210: loss=0.010512076776120177
Epoch #211: loss=0.007988938128869966
Epoch #212: loss=0.009426918941847941
Epoch #213: loss=0.013760812879759627
Epoch #214: loss=0.01195258394024925
Epoch #215: loss=0.012333624565491681
Epoch #216: loss=0.007372514200853237
Epoch #217: loss=0.011298461820578351
Epoch #218: loss=0.009687918517804726
Epoch #219: loss=0.008447578312453434
Epoch #220: loss=0.010740349367684261
Epoch #221: loss=0.009848881933662183
Epoch #222: loss=0.011098762741147022
Epoch #223: loss=0.009953080046993405
Epoch #224: loss=0.008564415244803636
Epoch #225: loss=0.009906693102361301
Epoch #226: loss=0.008769981464010099
Epoch #227: loss=0.009413650762855302
Epoch #228: loss=0.0074591436664625446
Epoch #229: loss=0.012483528531546736
Epoch #230: loss=0.010988123301963654
Epoch #231: loss=0.010074147677253429
Epoch #232: loss=0.011139442984544572
Epoch #233: loss=0.028337614321853007
Epoch #234: loss=0.01477808503525673
Epoch #235: loss=0.008505987242857704
Epoch #236: loss=0.011768347283892085
Epoch #237: loss=0.009483044380480848
Epoch #238: loss=0.011641396098622697
Epoch #239: loss=0.008309718686265651
Epoch #240: loss=0.010976200976950746
Epoch #241: loss=0.010660884203339677
Epoch #242: loss=0.01197876011180845
Epoch #243: loss=0.016073437928703655
Epoch #244: loss=0.012902814668896926
Epoch #245: loss=0.00858303022951878
Epoch #246: loss=0.008523270242635177
Epoch #247: loss=0.0075378426454831655
Epoch #248: loss=0.009481904140267778
Epoch #249: loss=0.01581548484748716

Training time: 10:07:35.931044

Finished.
n2one setting etth1_ettm1_traffic -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_traffic_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_ettm1_traffic', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.91018e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.03763e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.05833e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.91018e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.425021506008438, 'MAE': 0.4649895056157434}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm1_traffic -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_traffic_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_ettm1_traffic', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.75621e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.39917e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.6320538184584137, 'MAE': 0.6388838818998261}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm1_traffic -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_traffic_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_ettm1_traffic', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
Evaluation result: {'MSE': 0.3051519265307171, 'MAE': 0.36134361206985116}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm1_weather', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm1_weather_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=6.7479586167768995
Epoch #1: loss=2.8020380329002035
Epoch #2: loss=2.6085389906709846
Epoch #3: loss=2.3217032714323564
Epoch #4: loss=2.086698583581231
Epoch #5: loss=1.9936164048585026
Epoch #6: loss=1.8440299169583754
Epoch #7: loss=1.7459267350760372
Epoch #8: loss=1.6141172674569217
Epoch #9: loss=1.5410250235687604
Epoch #10: loss=1.425722444599325
Epoch #11: loss=1.3182566585865887
Epoch #12: loss=1.2829099785197864
Epoch #13: loss=1.158482401208444
Epoch #14: loss=1.127065653150732
Epoch #15: loss=1.073112266984853
Epoch #16: loss=1.1887780184095555
Epoch #17: loss=1.1053571633317254
Epoch #18: loss=1.1063848693262448
Epoch #19: loss=1.014234634962949
Epoch #20: loss=0.9638638686050068
Epoch #21: loss=0.8650346181609414
Epoch #22: loss=0.8306140533902429
Epoch #23: loss=0.8368250226432626
Epoch #24: loss=0.7981749786572023
Epoch #25: loss=0.7186306836930189
Epoch #26: loss=0.7292461679740385
Epoch #27: loss=0.7637567818164825
Epoch #28: loss=0.7427490570328452
Epoch #29: loss=0.8373362029140646
Epoch #30: loss=0.8096342262896624
Epoch #31: loss=0.7140276323665272
Epoch #32: loss=0.6630177003416148
Epoch #33: loss=0.7059143273667856
Epoch #34: loss=0.6285055848685178
Epoch #35: loss=0.6153189973397688
Epoch #36: loss=0.5653129463846033
Epoch #37: loss=0.5754978121681646
Epoch #38: loss=0.5626417696475983
Epoch #39: loss=0.5643581775101748
Epoch #40: loss=0.5185186680067669
Epoch #41: loss=0.5379051545804198
Epoch #42: loss=0.510429172353311
Epoch #43: loss=0.5630176372148774
Epoch #44: loss=0.5366627993908796
Epoch #45: loss=0.4959426705132831
Epoch #46: loss=0.5642906034534628
Epoch #47: loss=0.5096042074940421
Epoch #48: loss=0.4186218584125692
Epoch #49: loss=0.4313201748512008
Epoch #50: loss=0.4309332143854011
Epoch #51: loss=0.39695788648995484
Epoch #52: loss=0.516505126926032
Epoch #53: loss=0.5005380247126926
Epoch #54: loss=0.4772384332662279
Epoch #55: loss=0.4358095746826042
Epoch #56: loss=0.35856334831226955
Epoch #57: loss=0.4287695816972039
Epoch #58: loss=0.40810899571938947
Epoch #59: loss=0.39846664430065587
Epoch #60: loss=0.4180328869684176
Epoch #61: loss=0.36130123416131193
Epoch #62: loss=0.3542201102457263
Epoch #63: loss=0.3434087827124379
Epoch #64: loss=0.32567467811432754
Epoch #65: loss=0.42041627249934455
Epoch #66: loss=0.39607875455509534
Epoch #67: loss=0.3298947966911576
Epoch #68: loss=0.3268853700296445
Epoch #69: loss=0.291503289883787
Epoch #70: loss=0.27745692956853996
Epoch #71: loss=0.27843660048463126
Epoch #72: loss=0.27245367589322006
Epoch #73: loss=0.299538081003861
Epoch #74: loss=0.2689171291210435
Epoch #75: loss=0.27531626414168964
Epoch #76: loss=0.3104680879888209
Epoch #77: loss=0.3481052741408348
Epoch #78: loss=0.38094189356673847
Epoch #79: loss=0.3456156397746368
Epoch #80: loss=0.3457645616409453
Epoch #81: loss=0.46042624014345085
Epoch #82: loss=0.45061563937501475
Epoch #83: loss=0.4085765325210311
Epoch #84: loss=0.3457948347045617
Epoch #85: loss=0.3304203340614384
Epoch #86: loss=0.25121205587956036
Epoch #87: loss=0.2217076053334908
Epoch #88: loss=0.19169738313013857
Epoch #89: loss=0.1888709119097753
Epoch #90: loss=0.22474192311479288
Epoch #91: loss=0.21519865772940897
Epoch #92: loss=0.19292223123325544
Epoch #93: loss=0.3150113551792773
Epoch #94: loss=0.22116924500600857
Epoch #95: loss=0.18482645761898972
Epoch #96: loss=0.2125046927989884
Epoch #97: loss=0.20365855563431978
Epoch #98: loss=0.2496528894725171
Epoch #99: loss=0.3054853427139195
Epoch #100: loss=0.24555821183391593
Epoch #101: loss=0.1848775501447645
Epoch #102: loss=0.17544286427172748
Epoch #103: loss=0.21864760303023187
Epoch #104: loss=0.1768674576147036
Epoch #105: loss=0.24575184734368866
Epoch #106: loss=0.23336639136753298
Epoch #107: loss=0.16764755758710884
Epoch #108: loss=0.3328127678145062
Epoch #109: loss=0.19870176555758173
Epoch #110: loss=0.21102747998454355
Epoch #111: loss=0.16377033970572732
Epoch #112: loss=0.12416962728920308
Epoch #113: loss=0.15682219282131304
Epoch #114: loss=0.16708870985629884
Epoch #115: loss=0.15088950368491086
Epoch #116: loss=0.13347151096571575
Epoch #117: loss=0.1590681862594052
Epoch #118: loss=0.15943489164452662
Epoch #119: loss=0.16547248504039916
Epoch #120: loss=0.16617946064269
Epoch #121: loss=0.1820218050005761
Epoch #122: loss=0.13415197316895833
Epoch #123: loss=0.14638874747536398
Epoch #124: loss=0.1729907775297761
Epoch #125: loss=0.17607576535506683
Epoch #126: loss=0.1433439297516915
Epoch #127: loss=0.13895540836859832
Epoch #128: loss=0.1343199046836658
Epoch #129: loss=0.13567531388252974
Epoch #130: loss=0.18189838249236345
Epoch #131: loss=0.13482531668110329
Epoch #132: loss=0.11292141857980327
Epoch #133: loss=0.11649775441566651
Epoch #134: loss=0.12646706372668798
Epoch #135: loss=0.1701293705793267
Epoch #136: loss=0.15421867819333618
Epoch #137: loss=0.12202836530791088
Epoch #138: loss=0.15075381087477913
Epoch #139: loss=0.13763571496714244
Epoch #140: loss=0.18308905135332185
Epoch #141: loss=0.1303406393324787
Epoch #142: loss=0.12785981536250224
Epoch #143: loss=0.130442345938222
Epoch #144: loss=0.11339622105217793
Epoch #145: loss=0.12260717026550662
Epoch #146: loss=0.13896646900949153
Epoch #147: loss=0.1198413041420281
Epoch #148: loss=0.11015014888041398
Epoch #149: loss=0.08415667479857802
Epoch #150: loss=0.08967575375837358
Epoch #151: loss=0.1876535112546249
Epoch #152: loss=0.13675734506581316
Epoch #153: loss=0.09679913681677797
Epoch #154: loss=0.2636361370201815
Epoch #155: loss=0.1348453661934896
Epoch #156: loss=0.13474067325957798
Epoch #157: loss=0.09715189573101023
Epoch #158: loss=0.146588500673798
Epoch #159: loss=0.09656730861487714
Epoch #160: loss=0.13963583679023114
Epoch #161: loss=0.09205747268755328
Epoch #162: loss=0.12184309790080244
Epoch #163: loss=0.1220349839634516
Epoch #164: loss=0.12241519246758385
Epoch #165: loss=0.0826948124238036
Epoch #166: loss=0.0782542462376031
Epoch #167: loss=0.09198030018755658
Epoch #168: loss=0.256374990821562
Epoch #169: loss=0.17214352840727026
Epoch #170: loss=0.12405169704421
Epoch #171: loss=0.11490748818455772
Epoch #172: loss=0.13243801180611958
Epoch #173: loss=0.08808642765507102
Epoch #174: loss=0.0986186486076225
Epoch #175: loss=0.0955392814410681
Epoch #176: loss=0.11842863282866099
Epoch #177: loss=0.08124744337560101
Epoch #178: loss=0.07714573325673965
Epoch #179: loss=0.1162004386371171
Epoch #180: loss=0.09168670258738777
Epoch #181: loss=0.096725232899189
Epoch #182: loss=0.08727440889924765
Epoch #183: loss=0.08196266749027101
Epoch #184: loss=0.06841053489849648
Epoch #185: loss=0.22706826640800995
Epoch #186: loss=0.10428963047028943
Epoch #187: loss=0.0820837773551995
Epoch #188: loss=0.0874007641845806
Epoch #189: loss=0.1331750633703037
Epoch #190: loss=0.10344705607911403
Epoch #191: loss=0.07718091225251555
Epoch #192: loss=0.15273715039207178
Epoch #193: loss=0.10223959238183769
Epoch #194: loss=0.09039099150421945
Epoch #195: loss=0.07582833181897347
Epoch #196: loss=0.07069107314402406
Epoch #197: loss=0.08730984578671103
Epoch #198: loss=0.07920685537498105
Epoch #199: loss=0.0786311668343842
Epoch #200: loss=0.09838654151694341
Epoch #201: loss=0.08094326025721701
Epoch #202: loss=0.10117197129875422
Epoch #203: loss=0.12666564104570585
Epoch #204: loss=0.10441113690930334
Epoch #205: loss=0.08875828636386855
Epoch #206: loss=0.07246328598227013
Epoch #207: loss=0.10067844014106826
Epoch #208: loss=0.10141066487201235
Epoch #209: loss=0.06378370912914927
Epoch #210: loss=0.06066457533531568
Epoch #211: loss=0.09045009966939688
Epoch #212: loss=0.06352516545236787
Epoch #213: loss=0.06657816761765968
Epoch #214: loss=0.05933821487071162
Epoch #215: loss=0.060569215269589964
Epoch #216: loss=0.05497377547858791
Epoch #217: loss=0.05058433162048459
Epoch #218: loss=0.08137306748804721
Epoch #219: loss=0.10864620486443693
Epoch #220: loss=0.0852521246468479
Epoch #221: loss=0.09365043776448477
Epoch #222: loss=0.047069863649085164
Epoch #223: loss=0.04857822793366557
Epoch #224: loss=0.05842554184015502
Epoch #225: loss=0.10316765909506516
Epoch #226: loss=0.0795736633960835
Epoch #227: loss=0.06730195115828379
Epoch #228: loss=0.07978408265096898
Epoch #229: loss=0.05665334240025417
Epoch #230: loss=0.05428055328824981
Epoch #231: loss=0.05083665040067651
Epoch #232: loss=0.056159434956498444
Epoch #233: loss=0.1059201129034839
Epoch #234: loss=0.08156422684392468
Epoch #235: loss=0.09236983434212478
Epoch #236: loss=0.11921403573995287
Epoch #237: loss=0.07628171975639733
Epoch #238: loss=0.05487992316061123
Epoch #239: loss=0.0562089625005187
Epoch #240: loss=0.06256883474998176
Epoch #241: loss=0.06907613086514175
Epoch #242: loss=0.11696988020346245
Epoch #243: loss=0.0759386644825678
Epoch #244: loss=0.06379396457817745
Epoch #245: loss=0.1057703153187917
Epoch #246: loss=0.06278364851393482
Epoch #247: loss=0.08095933892764151
Epoch #248: loss=0.17924985981715674
Epoch #249: loss=0.08281036618758332

Training time: 0:43:10.383981

Finished.
n2one setting etth1_ettm1_weather -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_weather_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_ettm1_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.54415e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.9066e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.54415e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3803085766869267, 'MAE': 0.43128247414293785}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm1_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_weather_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_ettm1_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.37315e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.1965495134733127, 'MAE': 0.30376611534860426}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm1_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm1_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=4.436292075193846
Epoch #1: loss=2.4010503796430736
Epoch #2: loss=2.114537674647111
Epoch #3: loss=2.0189421818806577
Epoch #4: loss=1.8909380665192237
Epoch #5: loss=1.8156847816247206
Epoch #6: loss=1.6539368308507478
Epoch #7: loss=1.584125055716588
Epoch #8: loss=1.5147794347542982
Epoch #9: loss=1.4671602019896874
Epoch #10: loss=1.3243067585504973
Epoch #11: loss=1.309860293681805
Epoch #12: loss=1.2181130876907935
Epoch #13: loss=1.2110439057533557
Epoch #14: loss=1.1504604678887587
Epoch #15: loss=1.194088651583745
Epoch #16: loss=1.0598758734189546
Epoch #17: loss=1.1173349160414476
Epoch #18: loss=1.0021261618687556
Epoch #19: loss=1.0294890770545373
Epoch #20: loss=0.9535617942993457
Epoch #21: loss=0.9862777521977057
Epoch #22: loss=0.9368001612333151
Epoch #23: loss=0.8696113435121683
Epoch #24: loss=0.9804357955088983
Epoch #25: loss=1.1344708273044
Epoch #26: loss=0.967034067098911
Epoch #27: loss=0.912844146673496
Epoch #28: loss=0.8729263704556686
Epoch #29: loss=0.8541034437142886
Epoch #30: loss=0.9841368679816906
Epoch #31: loss=0.8522698489519266
Epoch #32: loss=0.9229049453368554
Epoch #33: loss=0.9173881709575653
Epoch #34: loss=0.8138434267961062
Epoch #35: loss=0.7281087166987933
Epoch #36: loss=0.7462827746684735
Epoch #37: loss=0.8687080695078924
Epoch #38: loss=0.7667315075030694
Epoch #39: loss=0.7710346109591998
Epoch #40: loss=0.7559020014909598
Epoch #41: loss=0.7644430043605658
Epoch #42: loss=0.7177373881523426
Epoch #43: loss=0.6741662277625158
Epoch #44: loss=0.7203288066845673
Epoch #45: loss=0.6517712771892548
Epoch #46: loss=0.8237302234539619
Epoch #47: loss=0.7178089916706085
Epoch #48: loss=0.6758539940302188
Epoch #49: loss=0.5537221248333271
Epoch #50: loss=0.6267947222177799
Epoch #51: loss=0.5573981232368029
Epoch #52: loss=0.5530113451755964
Epoch #53: loss=0.6253188447310374
Epoch #54: loss=0.6426785897750121
Epoch #55: loss=0.6538530943485407
Epoch #56: loss=0.4911583432784447
Epoch #57: loss=0.5225298427618467
Epoch #58: loss=0.7622595968154761
Epoch #59: loss=0.6636343724452533
Epoch #60: loss=0.5851581899019388
Epoch #61: loss=0.5690567195415497
Epoch #62: loss=0.535344205223597
Epoch #63: loss=0.5607601621976266
Epoch #64: loss=0.488448087985699
Epoch #65: loss=0.49978722631931305
Epoch #66: loss=0.5277819581902944
Epoch #67: loss=0.5043007146853667
Epoch #68: loss=0.5535458228909053
Epoch #69: loss=0.5485003911531888
Epoch #70: loss=0.5572132857946249
Epoch #71: loss=0.4588251830293582
Epoch #72: loss=0.486737745312544
Epoch #73: loss=0.49130450934171677
Epoch #74: loss=0.49987019254611087
Epoch #75: loss=0.38181402591558605
Epoch #76: loss=0.418435414823202
Epoch #77: loss=0.41446730895684314
Epoch #78: loss=0.5150818973779678
Epoch #79: loss=0.41646197037054944
Epoch #80: loss=0.4905614096384782
Epoch #81: loss=0.42055507004261017
Epoch #82: loss=0.4770900481022321
Epoch #83: loss=0.4273426274840648
Epoch #84: loss=0.5002886400772975
Epoch #85: loss=0.37906637673194593
Epoch #86: loss=0.4524730077156654
Epoch #87: loss=0.43691191707666105
Epoch #88: loss=0.3867509508362183
Epoch #89: loss=0.4283000815373201
Epoch #90: loss=0.41349991181722057
Epoch #91: loss=0.3761168351540199
Epoch #92: loss=0.3682635615651424
Epoch #93: loss=0.4099384746872462
Epoch #94: loss=0.4928971580587901
Epoch #95: loss=0.4685457612459476
Epoch #96: loss=0.42968757909077865
Epoch #97: loss=0.43219838062158
Epoch #98: loss=0.3594858944416046
Epoch #99: loss=0.41113848984241486
Epoch #100: loss=0.3799382236141425
Epoch #101: loss=0.37953799619124484
Epoch #102: loss=0.40644751259913814
Epoch #103: loss=0.3824441816944342
Epoch #104: loss=0.37599696333591753
Epoch #105: loss=0.3979214361080757
Epoch #106: loss=0.4024172912423427
Epoch #107: loss=0.36172310893352216
Epoch #108: loss=0.3461746513270415
Epoch #109: loss=0.2821705848551713
Epoch #110: loss=0.3901237418445257
Epoch #111: loss=0.32640683020536715
Epoch #112: loss=0.29271369026257443
Epoch #113: loss=0.293135873400248
Epoch #114: loss=0.31237717545949495
Epoch #115: loss=0.3032259250489565
Epoch #116: loss=0.32490938558028293
Epoch #117: loss=0.2747248918391191
Epoch #118: loss=0.2919288406578394
Epoch #119: loss=0.29785620507139426
Epoch #120: loss=0.2938089215984711
Epoch #121: loss=0.3532298751748525
Epoch #122: loss=0.2944607843573277
Epoch #123: loss=0.31336860014842105
Epoch #124: loss=0.2850540022437389
Epoch #125: loss=0.2898536848907287
Epoch #126: loss=0.2548712162444225
Epoch #127: loss=0.23893922939896584
Epoch #128: loss=0.3788249624463228
Epoch #129: loss=0.3541158460653745
Epoch #130: loss=0.42051664711191106
Epoch #131: loss=0.3524136474499336
Epoch #132: loss=0.2929972347158652
Epoch #133: loss=0.26209498941898346
Epoch #134: loss=0.20071485380713755
Epoch #135: loss=0.23624263933071724
Epoch #136: loss=0.18948030557769996
Epoch #137: loss=0.16745867723455796
Epoch #138: loss=0.32242368505551267
Epoch #139: loss=0.2863505525657764
Epoch #140: loss=0.33261680287810474
Epoch #141: loss=0.2831466318323062
Epoch #142: loss=0.28297690932567304
Epoch #143: loss=0.30231745827656525
Epoch #144: loss=0.21929039605534995
Epoch #145: loss=0.5271501449438242
Epoch #146: loss=0.4004663948256236
Epoch #147: loss=0.4304983254808646
Epoch #148: loss=0.33069801044005614
Epoch #149: loss=0.24214321604141822
Epoch #150: loss=0.28261870174453807
Epoch #151: loss=0.3574641960171553
Epoch #152: loss=0.2678856004316073
Epoch #153: loss=0.26098088318338764
Epoch #154: loss=0.2452878292936545
Epoch #155: loss=0.21248381642194894
Epoch #156: loss=0.21602067609245962
Epoch #157: loss=0.23522477568342134
Epoch #158: loss=0.21660468010948256
Epoch #159: loss=0.18433900650304097
Epoch #160: loss=0.2079126531114945
Epoch #161: loss=0.1680364038508672
Epoch #162: loss=0.20783323063873327
Epoch #163: loss=0.15597512744940245
Epoch #164: loss=0.19237622418082678
Epoch #165: loss=0.21851036640313956
Epoch #166: loss=0.21005935307878715
Epoch #167: loss=0.2127055018567122
Epoch #168: loss=0.20307657581109267
Epoch #169: loss=0.1722752400315725
Epoch #170: loss=0.15769331372128084
Epoch #171: loss=0.2371695375499817
Epoch #172: loss=0.23330319787447268
Epoch #173: loss=0.1981494237597172
Epoch #174: loss=0.16109081658606345
Epoch #175: loss=0.17666877161424893
Epoch #176: loss=0.1474651052401616
Epoch #177: loss=0.1727582772190754
Epoch #178: loss=0.16259398612265402
Epoch #179: loss=0.2113263543981772
Epoch #180: loss=0.2186878936795088
Epoch #181: loss=0.17253204263173616
Epoch #182: loss=0.14829308582613102
Epoch #183: loss=0.15395897010771128
Epoch #184: loss=0.1816896850673052
Epoch #185: loss=0.15392337897076055
Epoch #186: loss=0.16859464046473688
Epoch #187: loss=0.21438263184749162
Epoch #188: loss=0.1599264838374578
Epoch #189: loss=0.20209206096254861
Epoch #190: loss=0.1644026909310084
Epoch #191: loss=0.21958284280621088
Epoch #192: loss=0.15899482211814478
Epoch #193: loss=0.20295854901465085
Epoch #194: loss=0.18294484426195806
Epoch #195: loss=0.19390832217266926
Epoch #196: loss=0.16631318614459956
Epoch #197: loss=0.1865279435251768
Epoch #198: loss=0.16255356500355098
Epoch #199: loss=0.1497918598067302
Epoch #200: loss=0.14448929864626664
Epoch #201: loss=0.17778883272638688
Epoch #202: loss=0.1777849505440547
Epoch #203: loss=0.17772216794009393
Epoch #204: loss=0.13583924621343613
Epoch #205: loss=0.15567229143702066
Epoch #206: loss=0.20596238956428492
Epoch #207: loss=0.18513771375784507
Epoch #208: loss=0.14814186425736317
Epoch #209: loss=0.12762840722615904
Epoch #210: loss=0.13173100209006897
Epoch #211: loss=0.12335629116457242
Epoch #212: loss=0.15113441818035567
Epoch #213: loss=0.18399754739724672
Epoch #214: loss=0.139396166572204
Epoch #215: loss=0.15866694857294744
Epoch #216: loss=0.168383822704737
Epoch #217: loss=0.17807562018816286
Epoch #218: loss=0.17694924370600626
Epoch #219: loss=0.2269858379776661
Epoch #220: loss=0.16798078111157969
Epoch #221: loss=0.15538458296885857
Epoch #222: loss=0.15695971006957385
Epoch #223: loss=0.1346825803988255
Epoch #224: loss=0.1693793903463162
Epoch #225: loss=0.2060527573697842
Epoch #226: loss=0.1830777915624472
Epoch #227: loss=0.17670137334901553
Epoch #228: loss=0.16406875734145826
Epoch #229: loss=0.1728967412446554
Epoch #230: loss=0.12520479683119518
Epoch #231: loss=0.25038514386575955
Epoch #232: loss=0.16198598177960286
Epoch #233: loss=0.21006840453124964
Epoch #234: loss=0.16073324044163412
Epoch #235: loss=0.13387383979100448
Epoch #236: loss=0.1342630131313434
Epoch #237: loss=0.11012782142139398
Epoch #238: loss=0.18194767667983586
Epoch #239: loss=0.18050889341303936
Epoch #240: loss=0.19287488466271988
Epoch #241: loss=0.28728284099354195
Epoch #242: loss=0.24726484859218964
Epoch #243: loss=0.20423915007939705
Epoch #244: loss=0.1749171232088254
Epoch #245: loss=0.12945445641302145
Epoch #246: loss=0.120484572620346
Epoch #247: loss=0.10269330814480782
Epoch #248: loss=0.11290302972954053
Epoch #249: loss=0.10366612758774024

Training time: 0:21:33.520284

Finished.
n2one setting etth1_ettm1_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_ettm1_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.20033e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.38856e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.20033e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3508045844400987, 'MAE': 0.42189674116372894}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm1_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_ettm1_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.39599e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.9259e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.39599e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.8605610597900643, 'MAE': 0.7270805741981168}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm2_electricity', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm2_electricity_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.7629548974093434
Epoch #1: loss=0.7398020612806697
Epoch #2: loss=0.5097623652940655
Epoch #3: loss=0.38948132422997184
Epoch #4: loss=0.3458973525811789
Epoch #5: loss=0.29122817437205695
Epoch #6: loss=0.2572815245715214
Epoch #7: loss=0.23650016393897105
Epoch #8: loss=0.19019781534386948
Epoch #9: loss=0.178052122614025
Epoch #10: loss=0.15889451823095657
Epoch #11: loss=0.14671725909442676
Epoch #12: loss=0.16190025442249656
Epoch #13: loss=0.11715798337111431
Epoch #14: loss=0.12443026712378569
Epoch #15: loss=0.11356820663365819
Epoch #16: loss=0.10155982420309982
Epoch #17: loss=0.10354045840601127
Epoch #18: loss=0.09213067516464751
Epoch #19: loss=0.07567735585579127
Epoch #20: loss=0.08346366196607066
Epoch #21: loss=0.06543484824410142
Epoch #22: loss=0.07690167993823599
Epoch #23: loss=0.06643330020099263
Epoch #24: loss=0.06055032151440779
Epoch #25: loss=0.0735941591087432
Epoch #26: loss=0.05952174627224868
Epoch #27: loss=0.05064320025531504
Epoch #28: loss=0.054981774521392704
Epoch #29: loss=0.04653790347404492
Epoch #30: loss=0.05564420932497291
Epoch #31: loss=0.0419560577521227
Epoch #32: loss=0.04299960971417065
Epoch #33: loss=0.04020644903353314
Epoch #34: loss=0.03695326776499242
Epoch #35: loss=0.03667180133629096
Epoch #36: loss=0.04280074145081714
Epoch #37: loss=0.03951358789122034
Epoch #38: loss=0.03238977385639518
Epoch #39: loss=0.030618362884919068
Epoch #40: loss=0.03926736175475483
Epoch #41: loss=0.04244306200159203
Epoch #42: loss=0.03233955695038348
Epoch #43: loss=0.03441837690440954
Epoch #44: loss=0.08567015632882627
Epoch #45: loss=0.04041882899760167
Epoch #46: loss=0.03144472296099703
Epoch #47: loss=0.05420249826783056
Epoch #48: loss=0.03579417814893489
Epoch #49: loss=0.0284496416110452
Epoch #50: loss=0.027938765821192733
Epoch #51: loss=0.03736408902703067
Epoch #52: loss=0.03596916749069308
Epoch #53: loss=0.018428176771959286
Epoch #54: loss=0.030089404600518576
Epoch #55: loss=0.026538671030742624
Epoch #56: loss=0.034477038052108874
Epoch #57: loss=0.023162994370315014
Epoch #58: loss=0.02760154449251813
Epoch #59: loss=0.021995136058603613
Epoch #60: loss=0.020564418800166948
Epoch #61: loss=0.04042252700997016
Epoch #62: loss=0.04465247946070194
Epoch #63: loss=0.026976439897877586
Epoch #64: loss=0.01746270485403659
Epoch #65: loss=0.016614000866214323
Epoch #66: loss=0.021747577572131534
Epoch #67: loss=0.026609104109521418
Epoch #68: loss=0.02338340453278812
Epoch #69: loss=0.017092669905358404
Epoch #70: loss=0.023108428138257402
Epoch #71: loss=0.025467325118370354
Epoch #72: loss=0.027669856322388053
Epoch #73: loss=0.01892374204588466
Epoch #74: loss=0.014420363943883737
Epoch #75: loss=0.02478188253522941
Epoch #76: loss=0.01608985837048969
Epoch #77: loss=0.022710346451625337
Epoch #78: loss=0.02499283484600836
Epoch #79: loss=0.012092745046105214
Epoch #80: loss=0.018353846836574157
Epoch #81: loss=0.02062460307408245
Epoch #82: loss=0.021924090461124143
Epoch #83: loss=0.019599619285810662
Epoch #84: loss=0.015006199510009812
Epoch #85: loss=0.019606693250822194
Epoch #86: loss=0.01726805803243752
Epoch #87: loss=0.019199316713864198
Epoch #88: loss=0.020821607536031895
Epoch #89: loss=0.0196496162990762
Epoch #90: loss=0.015241699253420475
Epoch #91: loss=0.018150419794204356
Epoch #92: loss=0.015039355423855032
Epoch #93: loss=0.026045019763788334
Epoch #94: loss=0.018419820398770843
Epoch #95: loss=0.014931756562991534
Epoch #96: loss=0.02906939917629321
Epoch #97: loss=0.02109989805396366
Epoch #98: loss=0.015570743644838757
Epoch #99: loss=0.01442983752452414
Epoch #100: loss=0.021624494110821995
Epoch #101: loss=0.014011770045895756
Epoch #102: loss=0.018121779194908014
Epoch #103: loss=0.01680880029370547
Epoch #104: loss=0.013807889317735139
Epoch #105: loss=0.018023683927859836
Epoch #106: loss=0.025002566244004015
Epoch #107: loss=0.015090433191638549
Epoch #108: loss=0.059981146107900306
Epoch #109: loss=0.013603324447634868
Epoch #110: loss=0.026571859106295097
Epoch #111: loss=0.01868644565966112
Epoch #112: loss=0.03419565931814215
Epoch #113: loss=0.01817097179684376
Epoch #114: loss=0.016802240911545644
Epoch #115: loss=0.012998379819396647
Epoch #116: loss=0.012708503058232411
Epoch #117: loss=0.012809608031200261
Epoch #118: loss=0.011321953623342687
Epoch #119: loss=0.016455321410374858
Epoch #120: loss=0.013263495021347221
Epoch #121: loss=0.01287930377198941
Epoch #122: loss=0.018310085590104615
Epoch #123: loss=0.016223581650316343
Epoch #124: loss=0.023914280495019823
Epoch #125: loss=0.017708475837500487
Epoch #126: loss=0.011879427829492221
Epoch #127: loss=0.016345644173978838
Epoch #128: loss=0.013508812865382473
Epoch #129: loss=0.017028828530131417
Epoch #130: loss=0.020243082759052976
Epoch #131: loss=0.013338127323209272
Epoch #132: loss=0.012918980873895914
Epoch #133: loss=0.020278838014980136
Epoch #134: loss=0.014273984102047376
Epoch #135: loss=0.010885801515370266
Epoch #136: loss=0.016633739334889645
Epoch #137: loss=0.010805512883200427
Epoch #138: loss=0.01376081810061199
Epoch #139: loss=0.0130353942005222
Epoch #140: loss=0.015554899158187013
Epoch #141: loss=0.01050846214467319
Epoch #142: loss=0.011588268923802592
Epoch #143: loss=0.02500719328360786
Epoch #144: loss=0.01218697535159797
Epoch #145: loss=0.01447827362484274
Epoch #146: loss=0.0253125631103119
Epoch #147: loss=0.0095084689923797
Epoch #148: loss=0.01184170475266709
Epoch #149: loss=0.009959935830153283
Epoch #150: loss=0.014847750754568144
Epoch #151: loss=0.01656689963428507
Epoch #152: loss=0.008104158427609559
Epoch #153: loss=0.01544951057862724
Epoch #154: loss=0.017775080586401718
Epoch #155: loss=0.014969213252542348
Epoch #156: loss=0.012251394321959312
Epoch #157: loss=0.012403777450395908
Epoch #158: loss=0.009817648470054235
Epoch #159: loss=0.01789660741826437
Epoch #160: loss=0.015079555195700624
Epoch #161: loss=0.011827055719415972
Epoch #162: loss=0.010453763229540305
Epoch #163: loss=0.015377529807509662
Epoch #164: loss=0.017096154790719874
Epoch #165: loss=0.008161718107878085
Epoch #166: loss=0.016693891404171896
Epoch #167: loss=0.010297190023147966
Epoch #168: loss=0.013624917555416338
Epoch #169: loss=0.020299531019926015
Epoch #170: loss=0.013954638177254251
Epoch #171: loss=0.01346930669490825
Epoch #172: loss=0.011220677115488797
Epoch #173: loss=0.00926395873143372
Epoch #174: loss=0.014312822042736376
Epoch #175: loss=0.012465368233882798
Epoch #176: loss=0.010202055079343929
Epoch #177: loss=0.012449131516539176
Epoch #178: loss=0.011893789952546687
Epoch #179: loss=0.019835469311592236
Epoch #180: loss=0.012903262165843463
Epoch #181: loss=0.007536030949031931
Epoch #182: loss=0.01819981675499578
Epoch #183: loss=0.010985092432334316
Epoch #184: loss=0.010667455005583115
Epoch #185: loss=0.019100748340442644
Epoch #186: loss=0.008476516307916446
Epoch #187: loss=0.010794553935086866
Epoch #188: loss=0.006943803027586099
Epoch #189: loss=0.010537162891198994
Epoch #190: loss=0.012861974263161277
Epoch #191: loss=0.013272278198174264
Epoch #192: loss=0.013514638706185968
Epoch #193: loss=0.008633078584017555
Epoch #194: loss=0.005076869419321918
Epoch #195: loss=0.008015742158870265
Epoch #196: loss=0.011582080983013535
Epoch #197: loss=0.009613151451027443
Epoch #198: loss=0.012134978210980727
Epoch #199: loss=0.015083377690474808
Epoch #200: loss=0.019685099865938332
Epoch #201: loss=0.013715035708588176
Epoch #202: loss=0.0098040372042767
Epoch #203: loss=0.010042133337748031
Epoch #204: loss=0.008520449885764024
Epoch #205: loss=0.011844562452714369
Epoch #206: loss=0.009768630983548344
Epoch #207: loss=0.012700500305340924
Epoch #208: loss=0.014433547046041023
Epoch #209: loss=0.01293507614258847
Epoch #210: loss=0.01452178497174425
Epoch #211: loss=0.010402468613752063
Epoch #212: loss=0.012518647680684765
Epoch #213: loss=0.008291852155152248
Epoch #214: loss=0.01211855303191176
Epoch #215: loss=0.01749933965587961
Epoch #216: loss=0.025802902563112434
Epoch #217: loss=0.00998322053429201
Epoch #218: loss=0.008999641494142787
Epoch #219: loss=0.013586691873124732
Epoch #220: loss=0.011519367288711212
Epoch #221: loss=0.018401366261013984
Epoch #222: loss=0.013452941722650037
Epoch #223: loss=0.00897744377909481
Epoch #224: loss=0.010858695408666595
Epoch #225: loss=0.006703755785469007
Epoch #226: loss=0.008630317754910952
Epoch #227: loss=0.008488747862955434
Epoch #228: loss=0.013067626067063604
Epoch #229: loss=0.010129683159784878
Epoch #230: loss=0.007720924538881641
Epoch #231: loss=0.009024506250345203
Epoch #232: loss=0.009751982695287764
Epoch #233: loss=0.007560073672350809
Epoch #234: loss=0.01040812464984502
Epoch #235: loss=0.014356651377059234
Epoch #236: loss=0.01255624778627124
Epoch #237: loss=0.01279339638066816
Epoch #238: loss=0.0075232560295133595
Epoch #239: loss=0.008351570204247866
Epoch #240: loss=0.008031668999832629
Epoch #241: loss=0.012214770705774317
Epoch #242: loss=0.014694536950612293
Epoch #243: loss=0.009192007034742287
Epoch #244: loss=0.010101805704990594
Epoch #245: loss=0.013420771104046679
Epoch #246: loss=0.007374474754346504
Epoch #247: loss=0.008930740352228262
Epoch #248: loss=0.011145576725045637
Epoch #249: loss=0.007427058618784962

Training time: 4:49:47.584046

Finished.
n2one setting etth1_ettm2_electricity -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm2_electricity_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_ettm2_electricity', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.13091e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.14179e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.21802e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.13091e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3640006466705713, 'MAE': 0.43331211005705506}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm2_electricity -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm2_electricity_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_ettm2_electricity', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.26554e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.22598058224329168, 'MAE': 0.3279565743914696}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm2_traffic', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm2_traffic_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.046805932677605
Epoch #1: loss=0.3685729769143191
Epoch #2: loss=0.27675578495148906
Epoch #3: loss=0.19147369207983667
Epoch #4: loss=0.16490232915278863
Epoch #5: loss=0.13181799248453568
Epoch #6: loss=0.11589137202509764
Epoch #7: loss=0.1214085360713811
Epoch #8: loss=0.08818698234178803
Epoch #9: loss=0.07382733421294357
Epoch #10: loss=0.07257314791627736
Epoch #11: loss=0.06596369354149581
Epoch #12: loss=0.05895031589898281
Epoch #13: loss=0.06403995691163634
Epoch #14: loss=0.05245149743753824
Epoch #15: loss=0.04354330628173722
Epoch #16: loss=0.04371418564299926
Epoch #17: loss=0.05473353102914354
Epoch #18: loss=0.04927829684033482
Epoch #19: loss=0.047522941375923854
Epoch #20: loss=0.04607706595905421
Epoch #21: loss=0.03752474056567404
Epoch #22: loss=0.03073041168946392
Epoch #23: loss=0.03861858872299887
Epoch #24: loss=0.03537439663354731
Epoch #25: loss=0.03326768539528447
Epoch #26: loss=0.033991022309849295
Epoch #27: loss=0.02925494743884139
Epoch #28: loss=0.03150165560827273
Epoch #29: loss=0.027492163308157947
Epoch #30: loss=0.02979856737881412
Epoch #31: loss=0.027551401079769923
Epoch #32: loss=0.03781219365919242
Epoch #33: loss=0.028586302597845628
Epoch #34: loss=0.028919308401633648
Epoch #35: loss=0.02690156290273907
Epoch #36: loss=0.028698716729228513
Epoch #37: loss=0.02285445563724021
Epoch #38: loss=0.022120618785331978
Epoch #39: loss=0.02164758668414751
Epoch #40: loss=0.03137547664717369
Epoch #41: loss=0.024364466322929896
Epoch #42: loss=0.027353264483595426
Epoch #43: loss=0.0222751058843807
Epoch #44: loss=0.020472771714941534
Epoch #45: loss=0.02327752048487045
Epoch #46: loss=0.03183815347967373
Epoch #47: loss=0.020745195741024375
Epoch #48: loss=0.017966889675484377
Epoch #49: loss=0.019704105563207782
Epoch #50: loss=0.016208698141748423
Epoch #51: loss=0.025528761889092328
Epoch #52: loss=0.019967369089565843
Epoch #53: loss=0.016656770922881235
Epoch #54: loss=0.02138821693581783
Epoch #55: loss=0.02030783031676203
Epoch #56: loss=0.02608526171335887
Epoch #57: loss=0.0179382704821447
Epoch #58: loss=0.018048941051793835
Epoch #59: loss=0.01686301257187469
Epoch #60: loss=0.017772595715227494
Epoch #61: loss=0.01868002030129322
Epoch #62: loss=0.02026190153066471
Epoch #63: loss=0.01783414283199818
Epoch #64: loss=0.026625860476435097
Epoch #65: loss=0.016314353316093648
Epoch #66: loss=0.019163970636344112
Epoch #67: loss=0.01777133218201925
Epoch #68: loss=0.016199411658056884
Epoch #69: loss=0.01772386377654026
Epoch #70: loss=0.02543595684725336
Epoch #71: loss=0.017553411858137802
Epoch #72: loss=0.015813609228114894
Epoch #73: loss=0.013924856816612935
Epoch #74: loss=0.012520886213050373
Epoch #75: loss=0.016211139127964007
Epoch #76: loss=0.02275986088577404
Epoch #77: loss=0.012421964810842342
Epoch #78: loss=0.013795245164808213
Epoch #79: loss=0.01715223396581264
Epoch #80: loss=0.01585948949085088
Epoch #81: loss=0.013224089217626236
Epoch #82: loss=0.014072566506382084
Epoch #83: loss=0.014969374191555702
Epoch #84: loss=0.015064406151180843
Epoch #85: loss=0.016984616667303436
Epoch #86: loss=0.021333639213646
Epoch #87: loss=0.015387710787564918
Epoch #88: loss=0.01335004698237092
Epoch #89: loss=0.017135958147429683
Epoch #90: loss=0.01324129964068561
Epoch #91: loss=0.012989072198351178
Epoch #92: loss=0.015891478350452168
Epoch #93: loss=0.013391104058246128
Epoch #94: loss=0.014030288313072313
Epoch #95: loss=0.01616994213863191
Epoch #96: loss=0.016126265840483194
Epoch #97: loss=0.012441063872723713
Epoch #98: loss=0.019265842972262446
Epoch #99: loss=0.017918350091250347
Epoch #100: loss=0.015541906524330526
Epoch #101: loss=0.013910744442413985
Epoch #102: loss=0.017040882394675546
Epoch #103: loss=0.013400466586244875
Epoch #104: loss=0.015387353992264253
Epoch #105: loss=0.011880383881791865
Epoch #106: loss=0.012453755134926971
Epoch #107: loss=0.028287403712205228
Epoch #108: loss=0.012223650010359547
Epoch #109: loss=0.01596440186946314
Epoch #110: loss=0.011722026119539144
Epoch #111: loss=0.01337178865687747
Epoch #112: loss=0.014708344911692125
Epoch #113: loss=0.016472479002649462
Epoch #114: loss=0.013422327474638058
Epoch #115: loss=0.010233496011840709
Epoch #116: loss=0.015080705102379646
Epoch #117: loss=0.009865977435269584
Epoch #118: loss=0.013188807745047432
Epoch #119: loss=0.01972408934591592
Epoch #120: loss=0.012832011101934106
Epoch #121: loss=0.017305101736465902
Epoch #122: loss=0.010858293655473972
Epoch #123: loss=0.0183788480999779
Epoch #124: loss=0.011244872528914129
Epoch #125: loss=0.012703275669561911
Epoch #126: loss=0.017316754090709516
Epoch #127: loss=0.011311475552230893
Epoch #128: loss=0.011041202200282317
Epoch #129: loss=0.009114493314733739
Epoch #130: loss=0.013334765361088846
Epoch #131: loss=0.012875553721162511
Epoch #132: loss=0.01395949252916828
Epoch #133: loss=0.012484721510058576
Epoch #134: loss=0.01577825318603242
Epoch #135: loss=0.014440448954436844
Epoch #136: loss=0.009578578208178938
Epoch #137: loss=0.01240554537482901
Epoch #138: loss=0.011435758985383224
Epoch #139: loss=0.02018034480375222
Epoch #140: loss=0.013211432544697097
Epoch #141: loss=0.014026202793651134
Epoch #142: loss=0.011103348459834126
Epoch #143: loss=0.009962857855581124
Epoch #144: loss=0.013300365691628195
Epoch #145: loss=0.014268079233773857
Epoch #146: loss=0.012517131044031968
Epoch #147: loss=0.014706682194214822
Epoch #148: loss=0.00961756774611951
Epoch #149: loss=0.014023151177785952
Epoch #150: loss=0.011744154533682211
Epoch #151: loss=0.012620110158803238
Epoch #152: loss=0.01223435675027841
Epoch #153: loss=0.010763699872768484
Epoch #154: loss=0.018205479502417306
Epoch #155: loss=0.014872717725599862
Epoch #156: loss=0.015563047122685187
Epoch #157: loss=0.014524630668430209
Epoch #158: loss=0.012484828888839481
Epoch #159: loss=0.011651298331021694
Epoch #160: loss=0.008600116451006298
Epoch #161: loss=0.013354773901664885
Epoch #162: loss=0.01575490598681261
Epoch #163: loss=0.014679447460366646
Epoch #164: loss=0.010756951230293701
Epoch #165: loss=0.01780521631252751
Epoch #166: loss=0.00937658068770278
Epoch #167: loss=0.01062456525745471
Epoch #168: loss=0.009925850097252723
Epoch #169: loss=0.014400025847531982
Epoch #170: loss=0.013182418243046744
Epoch #171: loss=0.008614844623773685
Epoch #172: loss=0.01767935904096124
Epoch #173: loss=0.01744576632614057
Epoch #174: loss=0.012022534592225301
Epoch #175: loss=0.010198679411802336
Epoch #176: loss=0.011270391392016873
Epoch #177: loss=0.00956958085033958
Epoch #178: loss=0.0105517072220788
Epoch #179: loss=0.01180903002704409
Epoch #180: loss=0.013665933539596154
Epoch #181: loss=0.008113341298187813
Epoch #182: loss=0.01603354479114139
Epoch #183: loss=0.008895747281448249
Epoch #184: loss=0.009101322663462435
Epoch #185: loss=0.012510389678341612
Epoch #186: loss=0.01156041464455484
Epoch #187: loss=0.010515984239761814
Epoch #188: loss=0.010466180896434129
Epoch #189: loss=0.009096244164117128
Epoch #190: loss=0.01213769576144973
Epoch #191: loss=0.012924363978593398
Epoch #192: loss=0.009849687228052063
Epoch #193: loss=0.013804359703466286
Epoch #194: loss=0.010698660546751688
Epoch #195: loss=0.0137176422783589
Epoch #196: loss=0.01152335835675496
Epoch #197: loss=0.009256948184073818
Epoch #198: loss=0.005914817787032172
Epoch #199: loss=0.014147510924786647
Epoch #200: loss=0.010082926710178568
Epoch #201: loss=0.012344092808416463
Epoch #202: loss=0.01065041234413167
Epoch #203: loss=0.010035061543864934
Epoch #204: loss=0.014423101398245887
Epoch #205: loss=0.008488920821285072
Epoch #206: loss=0.008609027774119486
Epoch #207: loss=0.012611261476097401
Epoch #208: loss=0.007654059608797649
Epoch #209: loss=0.012720855684326501
Epoch #210: loss=0.013377784706343928
Epoch #211: loss=0.008552615157094061
Epoch #212: loss=0.0082480071438278
Epoch #213: loss=0.010584375349241204
Epoch #214: loss=0.013623022133569149
Epoch #215: loss=0.01124018052864399
Epoch #216: loss=0.007172628950241812
Epoch #217: loss=0.01064560870103874
Epoch #218: loss=0.010819169946444163
Epoch #219: loss=0.009419450241958574
Epoch #220: loss=0.00672605422825489
Epoch #221: loss=0.011629084061794194
Epoch #222: loss=0.00884409152579544
Epoch #223: loss=0.007870611040909187
Epoch #224: loss=0.007854966110858185
Epoch #225: loss=0.01177051682322847
Epoch #226: loss=0.008194127221182932
Epoch #227: loss=0.010236851940862834
Epoch #228: loss=0.008714428527177503
Epoch #229: loss=0.009911202298561957
Epoch #230: loss=0.009363767674139208
Epoch #231: loss=0.009180874391644134
Epoch #232: loss=0.011122513276065796
Epoch #233: loss=0.024079564032382966
Epoch #234: loss=0.015582962781263632
Epoch #235: loss=0.008640560577544998
Epoch #236: loss=0.009300745757553325
Epoch #237: loss=0.007280350103974343
Epoch #238: loss=0.010059055787827344
Epoch #239: loss=0.011798218996039044
Epoch #240: loss=0.011920565026825484
Epoch #241: loss=0.008348230213000947
Epoch #242: loss=0.008931788878709828
Epoch #243: loss=0.012794351733993443
Epoch #244: loss=0.00997376809107002
Epoch #245: loss=0.00853362415382435
Epoch #246: loss=0.007308341270469431
Epoch #247: loss=0.01328414505540691
Epoch #248: loss=0.009511106249746345
Epoch #249: loss=0.008088501205474007

Training time: 10:23:22.125124

Finished.
n2one setting etth1_ettm2_traffic -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm2_traffic_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_ettm2_traffic', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.42587e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.94736e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.90892e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.42587e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4265622870970827, 'MAE': 0.46584152682508995}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm2_traffic -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm2_traffic_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_ettm2_traffic', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.65236e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.32546e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.65236e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.8738274735872736, 'MAE': 0.7533367381066053}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm2_traffic -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm2_traffic_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_ettm2_traffic', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.64015e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.25283668913804186, 'MAE': 0.3382068446101678}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm2_weather', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm2_weather_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=7.008138662034815
Epoch #1: loss=2.8099767565727234
Epoch #2: loss=2.6248221451585945
Epoch #3: loss=2.3453234163197605
Epoch #4: loss=2.104366484013471
Epoch #5: loss=2.010404960675673
Epoch #6: loss=1.8657127185301348
Epoch #7: loss=1.7673396549441598
Epoch #8: loss=1.6478732445023276
Epoch #9: loss=1.5661195624958386
Epoch #10: loss=1.4517660845409741
Epoch #11: loss=1.336506580764597
Epoch #12: loss=1.3175211115316912
Epoch #13: loss=1.18698573383418
Epoch #14: loss=1.138498999855735
Epoch #15: loss=1.0856683579358188
Epoch #16: loss=1.1628192771564831
Epoch #17: loss=1.0668919018723748
Epoch #18: loss=1.03336423906413
Epoch #19: loss=0.9957715421915054
Epoch #20: loss=0.9317020814527165
Epoch #21: loss=0.8600675815885718
Epoch #22: loss=0.8335293693975969
Epoch #23: loss=0.8326437134634365
Epoch #24: loss=0.7992428243160248
Epoch #25: loss=0.725330579009923
Epoch #26: loss=0.7176470038565722
Epoch #27: loss=0.7510510777885263
Epoch #28: loss=0.7455688972364772
Epoch #29: loss=0.8287323645570062
Epoch #30: loss=0.8027392070401799
Epoch #31: loss=0.7135579233819788
Epoch #32: loss=0.6965332390232519
Epoch #33: loss=0.7193217900666323
Epoch #34: loss=0.6216845464977351
Epoch #35: loss=0.6119086573069746
Epoch #36: loss=0.5731237578121099
Epoch #37: loss=0.5658589587970213
Epoch #38: loss=0.5567066662690856
Epoch #39: loss=0.5673565072092143
Epoch #40: loss=0.5149094157598235
Epoch #41: loss=0.5403644835407083
Epoch #42: loss=0.49846647544340655
Epoch #43: loss=0.5541169474070723
Epoch #44: loss=0.5307134146040137
Epoch #45: loss=0.49368402090939606
Epoch #46: loss=0.5841520875692368
Epoch #47: loss=0.5181129344485023
Epoch #48: loss=0.42552012543786655
Epoch #49: loss=0.42314489118077536
Epoch #50: loss=0.4316048930314454
Epoch #51: loss=0.39748334647579625
Epoch #52: loss=0.5037277591499415
Epoch #53: loss=0.4893913905728947
Epoch #54: loss=0.4680571203882044
Epoch #55: loss=0.4242070523852652
Epoch #56: loss=0.35200376503846864
Epoch #57: loss=0.41341866315765813
Epoch #58: loss=0.3958927017043937
Epoch #59: loss=0.37413953854279086
Epoch #60: loss=0.40671786361119966
Epoch #61: loss=0.3596738329665227
Epoch #62: loss=0.34683474458076735
Epoch #63: loss=0.3220271688293327
Epoch #64: loss=0.33743540434674785
Epoch #65: loss=0.4212946729226546
Epoch #66: loss=0.43132076615637
Epoch #67: loss=0.32144119488922035
Epoch #68: loss=0.32404035939411685
Epoch #69: loss=0.3405933888121085
Epoch #70: loss=0.3665573789992116
Epoch #71: loss=0.3084174804389477
Epoch #72: loss=0.6907758633182808
Epoch #73: loss=0.45034918798641727
Epoch #74: loss=0.32186461172320624
Epoch #75: loss=0.31681010889058764
Epoch #76: loss=0.345061946998943
Epoch #77: loss=0.4301038875498555
Epoch #78: loss=0.5003958926959471
Epoch #79: loss=0.4079541245644743
Epoch #80: loss=0.29176504469730635
Epoch #81: loss=0.2926652311262759
Epoch #82: loss=0.35155083950270305
Epoch #83: loss=0.27111932973970065
Epoch #84: loss=0.30089286680925975
Epoch #85: loss=0.2981199969283559
Epoch #86: loss=0.23697134412147783
Epoch #87: loss=0.21613444235514512
Epoch #88: loss=0.18977968208491802
Epoch #89: loss=0.19153822382742708
Epoch #90: loss=0.2328410085967996
Epoch #91: loss=0.21679374321617864
Epoch #92: loss=0.18001388081095435
Epoch #93: loss=0.32219524444504216
Epoch #94: loss=0.23678090440278704
Epoch #95: loss=0.1958996397866444
Epoch #96: loss=0.22198334310881115
Epoch #97: loss=0.2020489416000518
Epoch #98: loss=0.21595233433287253
Epoch #99: loss=0.3028195862742988
Epoch #100: loss=0.26726983521472325
Epoch #101: loss=0.22952565923333168
Epoch #102: loss=0.20789305527101865
Epoch #103: loss=0.2330183373256163
Epoch #104: loss=0.16616460503163663
Epoch #105: loss=0.2137792526998303
Epoch #106: loss=0.23649567856707357
Epoch #107: loss=0.169287352822721
Epoch #108: loss=0.3305639172480865
Epoch #109: loss=0.18568023387342691
Epoch #110: loss=0.20857653191143816
Epoch #111: loss=0.17595559578727593
Epoch #112: loss=0.1370117733763023
Epoch #113: loss=0.16914004222913223
Epoch #114: loss=0.17435159940611233
Epoch #115: loss=0.16678225122053514
Epoch #116: loss=0.1454136303879998
Epoch #117: loss=0.16771476385606962
Epoch #118: loss=0.18855669044635512
Epoch #119: loss=0.17217243420468134
Epoch #120: loss=0.1521112738515843
Epoch #121: loss=0.1677071734924208
Epoch #122: loss=0.16859942733902822
Epoch #123: loss=0.16342884784733708
Epoch #124: loss=0.1842045442793857
Epoch #125: loss=0.1957457892766053
Epoch #126: loss=0.15388311030851168
Epoch #127: loss=0.15501373904672536
Epoch #128: loss=0.20174346373162486
Epoch #129: loss=0.20030902529304678
Epoch #130: loss=0.19629593676125462
Epoch #131: loss=0.16580403503030539
Epoch #132: loss=0.22840154759416526
Epoch #133: loss=0.2151383258063685
Epoch #134: loss=0.14810431037436833
Epoch #135: loss=0.1888580233366652
Epoch #136: loss=0.1555820984596556
Epoch #137: loss=0.11867249697785485
Epoch #138: loss=0.1488750877536156
Epoch #139: loss=0.1425009714016183
Epoch #140: loss=0.18055037946694277
Epoch #141: loss=0.1371720788407732
Epoch #142: loss=0.14681599742140283
Epoch #143: loss=0.13777986719188365
Epoch #144: loss=0.12134340058334848
Epoch #145: loss=0.13262379939921878
Epoch #146: loss=0.1386447897688909
Epoch #147: loss=0.12128795679150657
Epoch #148: loss=0.1154768974520266
Epoch #149: loss=0.08979447037828239
Epoch #150: loss=0.10266058350151236
Epoch #151: loss=0.18211300916631112
Epoch #152: loss=0.137456752656197
Epoch #153: loss=0.10247901632365855
Epoch #154: loss=0.2828685598109256
Epoch #155: loss=0.14875034462999215
Epoch #156: loss=0.14019738853147085
Epoch #157: loss=0.10940692895515398
Epoch #158: loss=0.15404715333980593
Epoch #159: loss=0.09688777827911756
Epoch #160: loss=0.1277592537755316
Epoch #161: loss=0.1000608154149218
Epoch #162: loss=0.12492851282215932
Epoch #163: loss=0.12757267519323665
Epoch #164: loss=0.13066616396165706
Epoch #165: loss=0.08710381424647164
Epoch #166: loss=0.07933308541859416
Epoch #167: loss=0.08860065599649468
Epoch #168: loss=0.23242126528004353
Epoch #169: loss=0.1589180168441751
Epoch #170: loss=0.12464750816368243
Epoch #171: loss=0.1128290055573664
Epoch #172: loss=0.12231047290631315
Epoch #173: loss=0.09170787828043103
Epoch #174: loss=0.09669672200371596
Epoch #175: loss=0.10841728590259497
Epoch #176: loss=0.1392090299420736
Epoch #177: loss=0.08947096566076983
Epoch #178: loss=0.08517160148105839
Epoch #179: loss=0.1236106422518126
Epoch #180: loss=0.11244876847856423
Epoch #181: loss=0.11875092555684122
Epoch #182: loss=0.10679214244539087
Epoch #183: loss=0.09852331430143253
Epoch #184: loss=0.0839367601808838
Epoch #185: loss=0.2144506856460463
Epoch #186: loss=0.10331471954387697
Epoch #187: loss=0.08339124545454979
Epoch #188: loss=0.08140285533260215
Epoch #189: loss=0.1200248262506317
Epoch #190: loss=0.09609415441412818
Epoch #191: loss=0.08837240290912715
Epoch #192: loss=0.1615909353660589
Epoch #193: loss=0.1189620397053659
Epoch #194: loss=0.10094980203377252
Epoch #195: loss=0.07205545872619207
Epoch #196: loss=0.07421662563204089
Epoch #197: loss=0.09290339776568791
Epoch #198: loss=0.0793820950414308
Epoch #199: loss=0.09487711701711471
Epoch #200: loss=0.11412119361656634
Epoch #201: loss=0.08958783948963339
Epoch #202: loss=0.08980280853045935
Epoch #203: loss=0.0664220867170529
Epoch #204: loss=0.07525603018108416
Epoch #205: loss=0.08118625599044291
Epoch #206: loss=0.061005347344855014
Epoch #207: loss=0.08562824214723977
Epoch #208: loss=0.09559854259714484
Epoch #209: loss=0.07393763821826062
Epoch #210: loss=0.07797166453251107
Epoch #211: loss=0.10995327355340123
Epoch #212: loss=0.08716025099750947
Epoch #213: loss=0.08749650300226429
Epoch #214: loss=0.07188977419652721
Epoch #215: loss=0.060018336760218845
Epoch #216: loss=0.062159329250624236
Epoch #217: loss=0.06024456762878055
Epoch #218: loss=0.0894215735395185
Epoch #219: loss=0.12416459471833977
Epoch #220: loss=0.09245798969641328
Epoch #221: loss=0.10445579541423781
Epoch #222: loss=0.05130216599950059
Epoch #223: loss=0.05091382425532422
Epoch #224: loss=0.05096437014766376
Epoch #225: loss=0.09831084700470621
Epoch #226: loss=0.07691663918508725
Epoch #227: loss=0.07449445073408159
Epoch #228: loss=0.08043217318217186
Epoch #229: loss=0.06193915291012011
Epoch #230: loss=0.06045241284565153
Epoch #231: loss=0.05842361283827235
Epoch #232: loss=0.06115743295628239
Epoch #233: loss=0.11009215555069121
Epoch #234: loss=0.08363032144155692
Epoch #235: loss=0.1048523158004338
Epoch #236: loss=0.10580338158814068
Epoch #237: loss=0.07982757323506204
Epoch #238: loss=0.06211552015421065
Epoch #239: loss=0.07790275646204298
Epoch #240: loss=0.09252458287995648
Epoch #241: loss=0.11184919646687129
Epoch #242: loss=0.23047949847849933
Epoch #243: loss=0.23756267308172854
Epoch #244: loss=0.14780867925252428
Epoch #245: loss=0.13128668366169388
Epoch #246: loss=0.08153807721100748
Epoch #247: loss=0.10149019152264703
Epoch #248: loss=0.19118937337771058
Epoch #249: loss=0.09311835404316132

Training time: 0:42:58.998543

Finished.
n2one setting etth1_ettm2_weather -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm2_weather_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_ettm2_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.55219e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.04169e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.55219e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3793801048706216, 'MAE': 0.43616404915676865}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm2_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm2_weather_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_ettm2_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.00877e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.20875263733590402, 'MAE': 0.3140826621924881}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm2_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm2_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=4.4564804297227125
Epoch #1: loss=2.4657898361866293
Epoch #2: loss=2.146479679987981
Epoch #3: loss=2.0534211213772116
Epoch #4: loss=1.9194308244265044
Epoch #5: loss=1.8392418026924133
Epoch #6: loss=1.684914992405818
Epoch #7: loss=1.6130622854599586
Epoch #8: loss=1.5435944933157701
Epoch #9: loss=1.492391008597154
Epoch #10: loss=1.3283963753626897
Epoch #11: loss=1.3163484243246226
Epoch #12: loss=1.2474895211366506
Epoch #13: loss=1.2414265802273383
Epoch #14: loss=1.1599867527301495
Epoch #15: loss=1.1735742436005518
Epoch #16: loss=1.0548621714115143
Epoch #17: loss=1.1013652636454656
Epoch #18: loss=0.9782631374322451
Epoch #19: loss=1.017782252568465
Epoch #20: loss=0.9426081616144913
Epoch #21: loss=0.9718998212080735
Epoch #22: loss=0.9643294192277468
Epoch #23: loss=0.9246586492428412
Epoch #24: loss=0.9977853344036982
Epoch #25: loss=1.1726866777126606
Epoch #26: loss=0.9896759895177988
Epoch #27: loss=0.956114106453382
Epoch #28: loss=0.8757680310652807
Epoch #29: loss=0.8688543507686028
Epoch #30: loss=1.0020334674761846
Epoch #31: loss=0.8435551317838522
Epoch #32: loss=0.9520999628763932
Epoch #33: loss=0.9196825990310082
Epoch #34: loss=0.8080124006821559
Epoch #35: loss=0.7448874379579837
Epoch #36: loss=0.7691537050100473
Epoch #37: loss=0.8770506611237159
Epoch #38: loss=0.7831268104223105
Epoch #39: loss=0.7729551196098328
Epoch #40: loss=0.7660267249895976
Epoch #41: loss=0.7626002281904221
Epoch #42: loss=0.7248214345711929
Epoch #43: loss=0.6720565832578219
Epoch #44: loss=0.6886993646621704
Epoch #45: loss=0.631699854364762
Epoch #46: loss=0.8443835251606427
Epoch #47: loss=0.7277510017156601
Epoch #48: loss=0.6934698396004163
Epoch #49: loss=0.5787086670215313
Epoch #50: loss=0.6398957234162551
Epoch #51: loss=0.5829567164182663
Epoch #52: loss=0.605826313679035
Epoch #53: loss=0.6866273398582752
Epoch #54: loss=0.7065032663253638
Epoch #55: loss=0.7105551121326593
Epoch #56: loss=0.580516428901599
Epoch #57: loss=0.536784597314321
Epoch #58: loss=0.7306981086730957
Epoch #59: loss=0.6324414496238415
Epoch #60: loss=0.5404777377843857
Epoch #61: loss=0.54398568547689
Epoch #62: loss=0.5140778892315351
Epoch #63: loss=0.5180765505020435
Epoch #64: loss=0.46081994531246334
Epoch #65: loss=0.48420726450589985
Epoch #66: loss=0.5282384271805103
Epoch #67: loss=0.5296146875390639
Epoch #68: loss=0.5356095398847873
Epoch #69: loss=0.5199133467215759
Epoch #70: loss=0.4824736869105926
Epoch #71: loss=0.422353880909773
Epoch #72: loss=0.5070535701054794
Epoch #73: loss=0.5413157395445384
Epoch #74: loss=0.6012022907917316
Epoch #75: loss=0.45649135227386767
Epoch #76: loss=0.46983299347070545
Epoch #77: loss=0.46907165818489516
Epoch #78: loss=0.5462510310686551
Epoch #79: loss=0.43421151431707233
Epoch #80: loss=0.5099286351066369
Epoch #81: loss=0.42006398278933305
Epoch #82: loss=0.45245285217578596
Epoch #83: loss=0.4161440105392383
Epoch #84: loss=0.5060439075414951
Epoch #85: loss=0.33616535250957197
Epoch #86: loss=0.4517329203394743
Epoch #87: loss=0.45134435766018355
Epoch #88: loss=0.37412342715721864
Epoch #89: loss=0.42661731231671113
Epoch #90: loss=0.4131932510779454
Epoch #91: loss=0.3702101959631993
Epoch #92: loss=0.3516526548908307
Epoch #93: loss=0.3748145023217568
Epoch #94: loss=0.4592666608782915
Epoch #95: loss=0.43451065054306615
Epoch #96: loss=0.42381265186346495
Epoch #97: loss=0.4782257475532018
Epoch #98: loss=0.4092172493155186
Epoch #99: loss=0.45433417019935757
Epoch #100: loss=0.39753837482287335
Epoch #101: loss=0.42074632759277636
Epoch #102: loss=0.40834720719319123
Epoch #103: loss=0.3284185580336131
Epoch #104: loss=0.3336106206362064
Epoch #105: loss=0.3598039625928952
Epoch #106: loss=0.39885523800666517
Epoch #107: loss=0.3644003633123178
Epoch #108: loss=0.35686534012739474
Epoch #109: loss=0.28861440517581427
Epoch #110: loss=0.38729433772655636
Epoch #111: loss=0.32048131324923956
Epoch #112: loss=0.29686764627695084
Epoch #113: loss=0.29143347018040144
Epoch #114: loss=0.3253713364784534
Epoch #115: loss=0.3298250141625221
Epoch #116: loss=0.36776688064520174
Epoch #117: loss=0.29211773121586215
Epoch #118: loss=0.3065836721887955
Epoch #119: loss=0.3041587414649817
Epoch #120: loss=0.3192291557788849
Epoch #121: loss=0.35919558944610447
Epoch #122: loss=0.29068838776304173
Epoch #123: loss=0.3155498527563535
Epoch #124: loss=0.28182493379482854
Epoch #125: loss=0.2901295836155231
Epoch #126: loss=0.2581647244783548
Epoch #127: loss=0.2507187807216094
Epoch #128: loss=0.3931338179569978
Epoch #129: loss=0.42939365483247316
Epoch #130: loss=0.41770774928423077
Epoch #131: loss=0.3868093232695873
Epoch #132: loss=0.31006856348652106
Epoch #133: loss=0.2620430433979401
Epoch #134: loss=0.20819704635785177
Epoch #135: loss=0.2501783285003442
Epoch #136: loss=0.20158718440395135
Epoch #137: loss=0.18799992077625716
Epoch #138: loss=0.30878962776981866
Epoch #139: loss=0.23795968752640945
Epoch #140: loss=0.24543047266510817
Epoch #141: loss=0.23333689713707337
Epoch #142: loss=0.2696004593028472
Epoch #143: loss=0.30747123950949085
Epoch #144: loss=0.2480353839122332
Epoch #145: loss=0.5017298597555894
Epoch #146: loss=0.3670707577123092
Epoch #147: loss=0.3669771764140863
Epoch #148: loss=0.2936613542529253
Epoch #149: loss=0.22501576921114555
Epoch #150: loss=0.2658818925802524
Epoch #151: loss=0.3316466696560383
Epoch #152: loss=0.24780342942820147
Epoch #153: loss=0.2542278557442702
Epoch #154: loss=0.247197813139512
Epoch #155: loss=0.21733872420512712
Epoch #156: loss=0.25021748588635373
Epoch #157: loss=0.24971539641802126
Epoch #158: loss=0.23438517921246016
Epoch #159: loss=0.19163189341242498
Epoch #160: loss=0.21093639502158532
Epoch #161: loss=0.1637225982088309
Epoch #162: loss=0.2115160873016486
Epoch #163: loss=0.17238926199766305
Epoch #164: loss=0.18387530342890665
Epoch #165: loss=0.2443939381493972
Epoch #166: loss=0.23332991135808137
Epoch #167: loss=0.23037568135903433
Epoch #168: loss=0.2229238347365306
Epoch #169: loss=0.17594891958511794
Epoch #170: loss=0.16268373939853448
Epoch #171: loss=0.2401741763147024
Epoch #172: loss=0.236286682005112
Epoch #173: loss=0.226224077722201
Epoch #174: loss=0.1874708397170672
Epoch #175: loss=0.214718634979083
Epoch #176: loss=0.16558443869535738
Epoch #177: loss=0.17092396361896625
Epoch #178: loss=0.17138736766691393
Epoch #179: loss=0.18828733380024248
Epoch #180: loss=0.21144676896241996
Epoch #181: loss=0.19704087909597617
Epoch #182: loss=0.17344426936828172
Epoch #183: loss=0.18408424278291372
Epoch #184: loss=0.21545163513376162
Epoch #185: loss=0.1718354755296157
Epoch #186: loss=0.17797647846432832
Epoch #187: loss=0.18746284853953582
Epoch #188: loss=0.13631122616621164
Epoch #189: loss=0.16445258460365808
Epoch #190: loss=0.15714113586224043
Epoch #191: loss=0.2248447695030616
Epoch #192: loss=0.15491161194558328
Epoch #193: loss=0.17856318317353725
Epoch #194: loss=0.17547475202725485
Epoch #195: loss=0.2016183930234267
Epoch #196: loss=0.1495329548533146
Epoch #197: loss=0.17745166057004377
Epoch #198: loss=0.16609676067645734
Epoch #199: loss=0.15862032155004832
Epoch #200: loss=0.16888544952067044
Epoch #201: loss=0.21472890932972616
Epoch #202: loss=0.22329519115961516
Epoch #203: loss=0.24319924929967293
Epoch #204: loss=0.17745755498225874
Epoch #205: loss=0.1814522803402864
Epoch #206: loss=0.2090550480553737
Epoch #207: loss=0.1667583643530424
Epoch #208: loss=0.14727314017139947
Epoch #209: loss=0.12397298575020753
Epoch #210: loss=0.13969191908836365
Epoch #211: loss=0.12063355013155021
Epoch #212: loss=0.15479858147983366
Epoch #213: loss=0.16046647713161433
Epoch #214: loss=0.12736307098888433
Epoch #215: loss=0.14762771201248354
Epoch #216: loss=0.14410046473718607
Epoch #217: loss=0.168226230602998
Epoch #218: loss=0.15373023885947007
Epoch #219: loss=0.29844895148506534
Epoch #220: loss=0.2614007734048825
Epoch #221: loss=0.22889172486387765
Epoch #222: loss=0.19756287006804577
Epoch #223: loss=0.15806110489826936
Epoch #224: loss=0.18373798149136397
Epoch #225: loss=0.21207770576270726
Epoch #226: loss=0.18023020802782133
Epoch #227: loss=0.16450795602913088
Epoch #228: loss=0.13349364826885554
Epoch #229: loss=0.15857289631206256
Epoch #230: loss=0.11305590289143416
Epoch #231: loss=0.23946837436121243
Epoch #232: loss=0.15849471779970023
Epoch #233: loss=0.1950733860811362
Epoch #234: loss=0.16313746113043565
Epoch #235: loss=0.12149793382447499
Epoch #236: loss=0.1085856814797108
Epoch #237: loss=0.09843439766420768
Epoch #238: loss=0.15606256674688596
Epoch #239: loss=0.15080641568280184
Epoch #240: loss=0.1159269569728237
Epoch #241: loss=0.2065091638897474
Epoch #242: loss=0.2295191323814484
Epoch #243: loss=0.21299979993357107
Epoch #244: loss=0.1986082696284239
Epoch #245: loss=0.1673893825365947
Epoch #246: loss=0.16443604932954678
Epoch #247: loss=0.12259935372723983
Epoch #248: loss=0.12488053137293229
Epoch #249: loss=0.13183075547791445

Training time: 0:21:46.658233

Finished.
n2one setting etth1_ettm2_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm2_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_ettm2_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.50954e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.88702e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.50954e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3679454613168139, 'MAE': 0.43411323795683515}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm2_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm2_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_ettm2_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.35941e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.58747e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.35941e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 1.0982315970541847, 'MAE': 0.8227528960070999}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_electricity_traffic', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_electricity_traffic_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.8500582993907086
Epoch #1: loss=0.29834602376868746
Epoch #2: loss=0.19125421665170614
Epoch #3: loss=0.13790945016285952
Epoch #4: loss=0.11682516957531457
Epoch #5: loss=0.08368883271145972
Epoch #6: loss=0.07292976272918535
Epoch #7: loss=0.061322645331192915
Epoch #8: loss=0.05471653812017073
Epoch #9: loss=0.05509461192648952
Epoch #10: loss=0.04419734765278535
Epoch #11: loss=0.05062846076291273
Epoch #12: loss=0.04184502780343555
Epoch #13: loss=0.0367850222368529
Epoch #14: loss=0.035548173575935996
Epoch #15: loss=0.0335402942713577
Epoch #16: loss=0.02863601272213547
Epoch #17: loss=0.03331941862447782
Epoch #18: loss=0.03149033250950449
Epoch #19: loss=0.028783670124820894
Epoch #20: loss=0.027556447274306083
Epoch #21: loss=0.02793132473544429
Epoch #22: loss=0.028302890555580936
Epoch #23: loss=0.02268352811058451
Epoch #24: loss=0.030022774419175977
Epoch #25: loss=0.031802621720840044
Epoch #26: loss=0.031654898265470605
Epoch #27: loss=0.020974330913799837
Epoch #28: loss=0.022870171167633395
Epoch #29: loss=0.034658495231997224
Epoch #30: loss=0.021439435461363874
Epoch #31: loss=0.02816244181296436
Epoch #32: loss=0.021761583986236253
Epoch #33: loss=0.02530654689244253
Epoch #34: loss=0.02085316329651528
Epoch #35: loss=0.018705730734612135
Epoch #36: loss=0.019489488528626617
Epoch #37: loss=0.018816659244622627
Epoch #38: loss=0.017640780358909855
Epoch #39: loss=0.019348019793700082
Epoch #40: loss=0.015751929870491628
Epoch #41: loss=0.024271358329922103
Epoch #42: loss=0.018589936913834385
Epoch #43: loss=0.016076427851431853
Epoch #44: loss=0.018184779996801747
Epoch #45: loss=0.016307448915537533
Epoch #46: loss=0.01904526096264863
Epoch #47: loss=0.017932979133079893
Epoch #48: loss=0.01744871279691882
Epoch #49: loss=0.021252941216602372
Epoch #50: loss=0.013558351510094808
Epoch #51: loss=0.01623452125753554
Epoch #52: loss=0.015525685802655795
Epoch #53: loss=0.01526940921732389
Epoch #54: loss=0.016251541030110925
Epoch #55: loss=0.015164740375945533
Epoch #56: loss=0.01940995566562814
Epoch #57: loss=0.01244049337232767
Epoch #58: loss=0.01299956034049157
Epoch #59: loss=0.01969864451421323
Epoch #60: loss=0.016522537075431172
Epoch #61: loss=0.014636383152971858
Epoch #62: loss=0.013752815736425422
Epoch #63: loss=0.011611486344398665
Epoch #64: loss=0.017173062594110507
Epoch #65: loss=0.014718789681488993
Epoch #66: loss=0.01728407794417923
Epoch #67: loss=0.014185584516058081
Epoch #68: loss=0.014816834994502748
Epoch #69: loss=0.014958028038919652
Epoch #70: loss=0.013949757915268018
Epoch #71: loss=0.014626533384904453
Epoch #72: loss=0.013747610240791212
Epoch #73: loss=0.013323465633028022
Epoch #74: loss=0.018349284195476174
Epoch #75: loss=0.010450909915184523
Epoch #76: loss=0.014426494408628763
Epoch #77: loss=0.013030755940087124
Epoch #78: loss=0.01123541050364917
Epoch #79: loss=0.014466971301296608
Epoch #80: loss=0.01681785096469171
Epoch #81: loss=0.011604443000567913
Epoch #82: loss=0.010479786106032622
Epoch #83: loss=0.014688426131815962
Epoch #84: loss=0.014437138131881296
Epoch #85: loss=0.012631792496711782
Epoch #86: loss=0.0139774640508
Epoch #87: loss=0.015441199416635135
Epoch #88: loss=0.012430775022582236
Epoch #89: loss=0.011950931777251188
Epoch #90: loss=0.015827984384277214
Epoch #91: loss=0.013854415032500499
Epoch #92: loss=0.013740820138511725
Epoch #93: loss=0.011261775986215162
Epoch #94: loss=0.01249144027469887
Epoch #95: loss=0.013469049173574542
Epoch #96: loss=0.01166583531093001
Epoch #97: loss=0.012126343585247518
Epoch #98: loss=0.013741839472280264
Epoch #99: loss=0.014005407317323384
Epoch #100: loss=0.012512925723660542
Epoch #101: loss=0.010266158610881706
Epoch #102: loss=0.012241867917003853
Epoch #103: loss=0.011791697598882744
Epoch #104: loss=0.012050336109243916
Epoch #105: loss=0.01125277574289054
Epoch #106: loss=0.015435912286251428
Epoch #107: loss=0.012942418091986211
Epoch #108: loss=0.015437406865843696
Epoch #109: loss=0.010816990318336375
Epoch #110: loss=0.016828424020578884
Epoch #111: loss=0.011773869858618372
Epoch #112: loss=0.017093707596469367
Epoch #113: loss=0.009848455654798631
Epoch #114: loss=0.012298970533355859
Epoch #115: loss=0.010792699403864696
Epoch #116: loss=0.012151422786933347
Epoch #117: loss=0.013338883402430845
Epoch #118: loss=0.009352877483022803
Epoch #119: loss=0.01230394711185779
Epoch #120: loss=0.0126348062042008
Epoch #121: loss=0.017245434553662273
Epoch #122: loss=0.0091625304777589
Epoch #123: loss=0.011282475920995216
Epoch #124: loss=0.011422291621096245
Epoch #125: loss=0.011690533716422839
Epoch #126: loss=0.014222770990515735
Epoch #127: loss=0.01237677973959235
Epoch #128: loss=0.006556300049441761
Epoch #129: loss=0.015392933044012269
Epoch #130: loss=0.011406876146915651
Epoch #131: loss=0.011323071469967605
Epoch #132: loss=0.008539784949824622
Epoch #133: loss=0.012738704553804313
Epoch #134: loss=0.01348973038173946
Epoch #135: loss=0.00938689904420748
Epoch #136: loss=0.012094779961112448
Epoch #137: loss=0.008850512500219399
Epoch #138: loss=0.014073707864748436
Epoch #139: loss=0.0105632652872694
Epoch #140: loss=0.010260344012258888
Epoch #141: loss=0.011904680574295197
Epoch #142: loss=0.012826871203342766
Epoch #143: loss=0.009849554329094116
Epoch #144: loss=0.013663032160878196
Epoch #145: loss=0.015911723407471608
Epoch #146: loss=0.016188737227505134
Epoch #147: loss=0.006157177555516162
Epoch #148: loss=0.010292030436179048
Epoch #149: loss=0.010542354875874212
Epoch #150: loss=0.008134035538491194
Epoch #151: loss=0.01205564077959216
Epoch #152: loss=0.009777466911683314
Epoch #153: loss=0.00914902222615286
Epoch #154: loss=0.011283494717443455
Epoch #155: loss=0.009518659327913149
Epoch #156: loss=0.015868590294503673
Epoch #157: loss=0.010922065602252045
Epoch #158: loss=0.015308676481793806
Epoch #159: loss=0.010781147510513758
Epoch #160: loss=0.010397429343439176
Epoch #161: loss=0.010932016619696368
Epoch #162: loss=0.018669184249142937
Epoch #163: loss=0.00846053017699551
Epoch #164: loss=0.01221239624108176
Epoch #165: loss=0.012081482004082739
Epoch #166: loss=0.00762632878403328
Epoch #167: loss=0.00882488307052736
Epoch #168: loss=0.007933964113303276
Epoch #169: loss=0.013714296248679817
Epoch #170: loss=0.009760499435125755
Epoch #171: loss=0.01071749022394368
Epoch #172: loss=0.010396743710204165
Epoch #173: loss=0.008260849909526746
Epoch #174: loss=0.010158343893852957
Epoch #175: loss=0.006654626366407454
Epoch #176: loss=0.008894436330580497
Epoch #177: loss=0.010465521289880911
Epoch #178: loss=0.014753968654539897
Epoch #179: loss=0.008627356462249523
Epoch #180: loss=0.01096326794601026
Epoch #181: loss=0.009495667863375886
Epoch #182: loss=0.011281113283211726
Epoch #183: loss=0.00914737778728507
Epoch #184: loss=0.010596924093004096
Epoch #185: loss=0.00776955000756596
Epoch #186: loss=0.014989631045636616
Epoch #187: loss=0.011511830136753685
Epoch #188: loss=0.00687247474683119
Epoch #189: loss=0.011458439442210248
Epoch #190: loss=0.010666519381996625
Epoch #191: loss=0.012406297829337203
Epoch #192: loss=0.005425756019816495
Epoch #193: loss=0.01236189780609172
Epoch #194: loss=0.006618110435362318
Epoch #195: loss=0.009437174590484498
Epoch #196: loss=0.009503916365254921
Epoch #197: loss=0.012092782820021233
Epoch #198: loss=0.00749584478340816
Epoch #199: loss=0.009678917034737522
Epoch #200: loss=0.010311526205354495
Epoch #201: loss=0.018168472910107664
Epoch #202: loss=0.019214986140904323
Epoch #203: loss=0.01032123113097036
Epoch #204: loss=0.007416490294961767
Epoch #205: loss=0.020412294115778745
Epoch #206: loss=0.006916559747559167
Epoch #207: loss=0.009195216313521026
Epoch #208: loss=0.005420648166763072
Epoch #209: loss=0.014368342324304336
Epoch #210: loss=0.014828902150469073
Epoch #211: loss=0.010939048677550809
Epoch #212: loss=0.023088050985923075
Epoch #213: loss=0.007133143134431047
Epoch #214: loss=0.007041997202630977
Epoch #215: loss=0.010280040985165544
Epoch #216: loss=0.009382027271796779
Epoch #217: loss=0.008370550171417837
Epoch #218: loss=0.007785180990634087
Epoch #219: loss=0.011082132136463403
Epoch #220: loss=0.012476920019192015
Epoch #221: loss=0.009165629511344454
Epoch #222: loss=0.007569805713015327
Epoch #223: loss=0.009505505576220947
Epoch #224: loss=0.00970504135581882
Epoch #225: loss=0.009721778706903002
Epoch #226: loss=0.008894487054142494
Epoch #227: loss=0.007482625986351592
Epoch #228: loss=0.008345600385083734
Epoch #229: loss=0.020234470643194103
Epoch #230: loss=0.0073648108620790395
Epoch #231: loss=0.0067476466887394755
Epoch #232: loss=0.011213751660245118
Epoch #233: loss=0.0073136057857421085
Epoch #234: loss=0.011308364528074799
Epoch #235: loss=0.007116294899178148
Epoch #236: loss=0.010716198283387544
Epoch #237: loss=0.010171783921475613
Epoch #238: loss=0.010219030719024948
Epoch #239: loss=0.0133527556262341
Epoch #240: loss=0.00679579640067566
Epoch #241: loss=0.008507334028662696
Epoch #242: loss=0.008959064179227517
Epoch #243: loss=0.008121483236308671
Epoch #244: loss=0.00977191086464142
Epoch #245: loss=0.010190107324221778
Epoch #246: loss=0.009409330681674651
Epoch #247: loss=0.007879884685838483
Epoch #248: loss=0.008450157407322946
Epoch #249: loss=0.006816068738310093

Training time: 14:30:35.915832

Finished.
n2one setting etth1_electricity_traffic -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_electricity_traffic_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_electricity_traffic', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.15685e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.54213e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.54213e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.36479641352366105, 'MAE': 0.44374131793902993}
Finished.
------------------------- record done -------------------------
n2one setting etth1_electricity_traffic -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_electricity_traffic_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_electricity_traffic', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.97465e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.17721594686138342, 'MAE': 0.2894933428154131}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_electricity_weather', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_electricity_weather_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.8443976849485926
Epoch #1: loss=0.8956427612042023
Epoch #2: loss=0.616455886997072
Epoch #3: loss=0.45869218907450554
Epoch #4: loss=0.42718908241239645
Epoch #5: loss=0.3904819956607064
Epoch #6: loss=0.31757456826119773
Epoch #7: loss=0.30781864387504126
Epoch #8: loss=0.2629971280694008
Epoch #9: loss=0.25072595047748697
Epoch #10: loss=0.2157186568414761
Epoch #11: loss=0.22036695301448558
Epoch #12: loss=0.18491951304640475
Epoch #13: loss=0.17524612597110917
Epoch #14: loss=0.17747519157911087
Epoch #15: loss=0.17340724239662542
Epoch #16: loss=0.1673575812414036
Epoch #17: loss=0.15096336144343608
Epoch #18: loss=0.11136422603585794
Epoch #19: loss=0.13236446393453805
Epoch #20: loss=0.12025961918114438
Epoch #21: loss=0.0993056129295863
Epoch #22: loss=0.11919789360888765
Epoch #23: loss=0.10538481527907868
Epoch #24: loss=0.09669165644731562
Epoch #25: loss=0.08449668537741159
Epoch #26: loss=0.07731686083147418
Epoch #27: loss=0.07279415463891911
Epoch #28: loss=0.0793869238909818
Epoch #29: loss=0.07645010784278902
Epoch #30: loss=0.0687601648357902
Epoch #31: loss=0.06537445760358357
Epoch #32: loss=0.05040974661413222
Epoch #33: loss=0.0675813548732549
Epoch #34: loss=0.07351177513841434
Epoch #35: loss=0.06860556777719261
Epoch #36: loss=0.04692645089590322
Epoch #37: loss=0.049269674563554175
Epoch #38: loss=0.05557403878550871
Epoch #39: loss=0.05553038540035802
Epoch #40: loss=0.04190149956309147
Epoch #41: loss=0.037709379099088454
Epoch #42: loss=0.042430943057682934
Epoch #43: loss=0.0528621947317842
Epoch #44: loss=0.04449042142763481
Epoch #45: loss=0.03857776994217124
Epoch #46: loss=0.03722819358427446
Epoch #47: loss=0.03502648888750391
Epoch #48: loss=0.04210584050131236
Epoch #49: loss=0.03411887647481477
Epoch #50: loss=0.048933224801873884
Epoch #51: loss=0.04090106042002007
Epoch #52: loss=0.040370342470994906
Epoch #53: loss=0.05770918018925188
Epoch #54: loss=0.045712037478957725
Epoch #55: loss=0.03731506049736945
Epoch #56: loss=0.03237405526622772
Epoch #57: loss=0.039459740900563464
Epoch #58: loss=0.02598594564459113
Epoch #59: loss=0.04380180579176078
Epoch #60: loss=0.03198033646584388
Epoch #61: loss=0.02761164644639676
Epoch #62: loss=0.02942177866444802
Epoch #63: loss=0.02739044543326764
Epoch #64: loss=0.02715274190075043
Epoch #65: loss=0.022567203336810997
Epoch #66: loss=0.026442335533125506
Epoch #67: loss=0.026586443070377525
Epoch #68: loss=0.024826019624508602
Epoch #69: loss=0.0298495649687004
Epoch #70: loss=0.04391799868994766
Epoch #71: loss=0.036432163699432724
Epoch #72: loss=0.01937273976433822
Epoch #73: loss=0.027915820112717628
Epoch #74: loss=0.07558220541065211
Epoch #75: loss=0.042674292330787976
Epoch #76: loss=0.023349883663928463
Epoch #77: loss=0.020913916573883428
Epoch #78: loss=0.019521755217324605
Epoch #79: loss=0.023730153627009632
Epoch #80: loss=0.0247071653780117
Epoch #81: loss=0.02675652028210093
Epoch #82: loss=0.0193977479939349
Epoch #83: loss=0.030118945040733494
Epoch #84: loss=0.02107063366697396
Epoch #85: loss=0.019884458962218878
Epoch #86: loss=0.024565854291845966
Epoch #87: loss=0.023260212020940637
Epoch #88: loss=0.019168003211337232
Epoch #89: loss=0.03519603335673495
Epoch #90: loss=0.05202576877038905
Epoch #91: loss=0.028361944860244685
Epoch #92: loss=0.0259840156183194
Epoch #93: loss=0.023881461036570455
Epoch #94: loss=0.028351739124594898
Epoch #95: loss=0.021029494848006303
Epoch #96: loss=0.01810167148764545
Epoch #97: loss=0.02117381954439363
Epoch #98: loss=0.01914935626154029
Epoch #99: loss=0.034018127151993816
Epoch #100: loss=0.03944844343452215
Epoch #101: loss=0.02073833081867325
Epoch #102: loss=0.021964511794951024
Epoch #103: loss=0.03653381638311765
Epoch #104: loss=0.027108148423728592
Epoch #105: loss=0.023912579713370862
Epoch #106: loss=0.02838775501941662
Epoch #107: loss=0.020376386366242616
Epoch #108: loss=0.02565537165441961
Epoch #109: loss=0.024602380653055343
Epoch #110: loss=0.018079042067030433
Epoch #111: loss=0.0205495419385376
Epoch #112: loss=0.024688844656010057
Epoch #113: loss=0.012511636798091148
Epoch #114: loss=0.015286147784037873
Epoch #115: loss=0.017191994085836902
Epoch #116: loss=0.02162411938208329
Epoch #117: loss=0.013819205984297906
Epoch #118: loss=0.011410811878750654
Epoch #119: loss=0.017863734387845265
Epoch #120: loss=0.039622475239869184
Epoch #121: loss=0.02544104246821223
Epoch #122: loss=0.018343436914018622
Epoch #123: loss=0.017563758682200455
Epoch #124: loss=0.02517525780397483
Epoch #125: loss=0.013437796514981169
Epoch #126: loss=0.019954273030609104
Epoch #127: loss=0.016975131491100477
Epoch #128: loss=0.025195372889264312
Epoch #129: loss=0.016668723522893305
Epoch #130: loss=0.014396466158174562
Epoch #131: loss=0.016392549913406825
Epoch #132: loss=0.014080462935525334
Epoch #133: loss=0.017115439382206787
Epoch #134: loss=0.018062949004829045
Epoch #135: loss=0.035714285306291824
Epoch #136: loss=0.021868471934599537
Epoch #137: loss=0.013883552660029067
Epoch #138: loss=0.016156781344453537
Epoch #139: loss=0.01453310718804619
Epoch #140: loss=0.01275035472028352
Epoch #141: loss=0.01207454984933322
Epoch #142: loss=0.014545833811247431
Epoch #143: loss=0.017210170049332136
Epoch #144: loss=0.013335212357447477
Epoch #145: loss=0.0153735068273674
Epoch #146: loss=0.0164272588122594
Epoch #147: loss=0.011461384901921607
Epoch #148: loss=0.019333190058909176
Epoch #149: loss=0.016001572555403284
Epoch #150: loss=0.016535512234990637
Epoch #151: loss=0.01373103432410586
Epoch #152: loss=0.04024188147264528
Epoch #153: loss=0.02096511728520305
Epoch #154: loss=0.017546699201493487
Epoch #155: loss=0.022378236379544777
Epoch #156: loss=0.013699686550502375
Epoch #157: loss=0.013876914796333939
Epoch #158: loss=0.016719120953282693
Epoch #159: loss=0.015259279648340597
Epoch #160: loss=0.009287911760841107
Epoch #161: loss=0.011627122620054874
Epoch #162: loss=0.0163547522309473
Epoch #163: loss=0.017281985510779297
Epoch #164: loss=0.014486162438377012
Epoch #165: loss=0.012330264855099915
Epoch #166: loss=0.010118369488186982
Epoch #167: loss=0.03976818133279744
Epoch #168: loss=0.018241748320153194
Epoch #169: loss=0.016116518076406634
Epoch #170: loss=0.017010875426740568
Epoch #171: loss=0.015834199086734026
Epoch #172: loss=0.024499892761455953
Epoch #173: loss=0.02879108156134785
Epoch #174: loss=0.01473645782699982
Epoch #175: loss=0.017173954701685153
Epoch #176: loss=0.015805339125740753
Epoch #177: loss=0.016450843083018456
Epoch #178: loss=0.016692658894617074
Epoch #179: loss=0.01665927895821965
Epoch #180: loss=0.01811222270467203
Epoch #181: loss=0.01132939433834205
Epoch #182: loss=0.009712632147807071
Epoch #183: loss=0.019986329207888745
Epoch #184: loss=0.014284321386663053
Epoch #185: loss=0.016462274005825336
Epoch #186: loss=0.01357632045342066
Epoch #187: loss=0.021108192421783994
Epoch #188: loss=0.015968018628168185
Epoch #189: loss=0.014490993553213512
Epoch #190: loss=0.018078853486376778
Epoch #191: loss=0.01275903923201209
Epoch #192: loss=0.01837953242738363
Epoch #193: loss=0.014022385781449345
Epoch #194: loss=0.015131559970263803
Epoch #195: loss=0.009673277968817028
Epoch #196: loss=0.018080613679465663
Epoch #197: loss=0.012084312198896061
Epoch #198: loss=0.01231923757192
Epoch #199: loss=0.011965539988451296
Epoch #200: loss=0.014740154637720325
Epoch #201: loss=0.011565328970463357
Epoch #202: loss=0.0142990685568591
Epoch #203: loss=0.014832916701282242
Epoch #204: loss=0.015305485984995846
Epoch #205: loss=0.022002258693857257
Epoch #206: loss=0.01449175551961213
Epoch #207: loss=0.014419657379730163
Epoch #208: loss=0.013003952667547263
Epoch #209: loss=0.022162642980081235
Epoch #210: loss=0.01641479962489615
Epoch #211: loss=0.017250127283366935
Epoch #212: loss=0.015414818132488257
Epoch #213: loss=0.01092010114827367
Epoch #214: loss=0.015118624937081299
Epoch #215: loss=0.011399568453754066
Epoch #216: loss=0.012265718570814368
Epoch #217: loss=0.00858313929290237
Epoch #218: loss=0.014195602345013976
Epoch #219: loss=0.010378258253314853
Epoch #220: loss=0.012900558112456863
Epoch #221: loss=0.018982004237296797
Epoch #222: loss=0.016349559500688518
Epoch #223: loss=0.011003450627667609
Epoch #224: loss=0.010998892585193149
Epoch #225: loss=0.02142401909607589
Epoch #226: loss=0.01448636558508674
Epoch #227: loss=0.013713996091661554
Epoch #228: loss=0.013446889204643325
Epoch #229: loss=0.012924233382918983
Epoch #230: loss=0.00937036435628878
Epoch #231: loss=0.012953336630805822
Epoch #232: loss=0.02054125246559638
Epoch #233: loss=0.014668328899332443
Epoch #234: loss=0.023690059600532117
Epoch #235: loss=0.0157296560065246
Epoch #236: loss=0.010404727346968238
Epoch #237: loss=0.015217842991870964
Epoch #238: loss=0.01311574303505595
Epoch #239: loss=0.014773813274946843
Epoch #240: loss=0.026059074684323762
Epoch #241: loss=0.010074489172824296
Epoch #242: loss=0.01220834648432631
Epoch #243: loss=0.01662637617427193
Epoch #244: loss=0.014934392676620986
Epoch #245: loss=0.010470283414055672
Epoch #246: loss=0.009480507600651975
Epoch #247: loss=0.01610634345694453
Epoch #248: loss=0.027847942760040573
Epoch #249: loss=0.014234131564337518

Training time: 4:51:30.131631

Finished.
n2one setting etth1_electricity_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_electricity_weather_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_electricity_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.21568e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.31787505480936806, 'MAE': 0.3775130208112116}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_electricity_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_electricity_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.702980001235292
Epoch #1: loss=0.7081231066868419
Epoch #2: loss=0.49581315328500103
Epoch #3: loss=0.3833169023107205
Epoch #4: loss=0.325282696057998
Epoch #5: loss=0.3085346461406776
Epoch #6: loss=0.25582441179791376
Epoch #7: loss=0.2573506946098946
Epoch #8: loss=0.226856211488623
Epoch #9: loss=0.18691435795543448
Epoch #10: loss=0.17248827090398186
Epoch #11: loss=0.1770454795166318
Epoch #12: loss=0.17321989919236375
Epoch #13: loss=0.14743736686761535
Epoch #14: loss=0.11409295868084189
Epoch #15: loss=0.12441378472084623
Epoch #16: loss=0.11147344048644993
Epoch #17: loss=0.1137143505315873
Epoch #18: loss=0.10391178983263671
Epoch #19: loss=0.09926453798211046
Epoch #20: loss=0.09060766707573618
Epoch #21: loss=0.08336689427960664
Epoch #22: loss=0.08931845526898369
Epoch #23: loss=0.09002597085366558
Epoch #24: loss=0.08687504774258871
Epoch #25: loss=0.07423697387067867
Epoch #26: loss=0.07205017810199588
Epoch #27: loss=0.05809916954049619
Epoch #28: loss=0.06467340630063388
Epoch #29: loss=0.045428528146918064
Epoch #30: loss=0.06594332612474404
Epoch #31: loss=0.05170694335191954
Epoch #32: loss=0.04525297700976288
Epoch #33: loss=0.05701392185125899
Epoch #34: loss=0.0507003619963403
Epoch #35: loss=0.05602382357686847
Epoch #36: loss=0.05715445374482356
Epoch #37: loss=0.05647015322687193
Epoch #38: loss=0.06028616171291409
Epoch #39: loss=0.0559620391674495
Epoch #40: loss=0.04312161297587279
Epoch #41: loss=0.05047243538761644
Epoch #42: loss=0.046194858233017534
Epoch #43: loss=0.036578829987168625
Epoch #44: loss=0.051952547921072914
Epoch #45: loss=0.04606831257600182
Epoch #46: loss=0.032990531257902536
Epoch #47: loss=0.04036671341288768
Epoch #48: loss=0.03739522079524163
Epoch #49: loss=0.033383847349406484
Epoch #50: loss=0.03153929405483983
Epoch #51: loss=0.04458725252161024
Epoch #52: loss=0.036284145445235824
Epoch #53: loss=0.03662285251179821
Epoch #54: loss=0.0437709332105615
Epoch #55: loss=0.03352862291649217
Epoch #56: loss=0.03499002497327248
Epoch #57: loss=0.0398273763639736
Epoch #58: loss=0.04254840785801034
Epoch #59: loss=0.03365093238937247
Epoch #60: loss=0.029168163213485275
Epoch #61: loss=0.031633117729576214
Epoch #62: loss=0.04038624365403805
Epoch #63: loss=0.03575304322501844
Epoch #64: loss=0.02383490795113002
Epoch #65: loss=0.026242764440775362
Epoch #66: loss=0.02089325506919219
Epoch #67: loss=0.04242699807703806
Epoch #68: loss=0.027449185010309088
Epoch #69: loss=0.025443583002751916
Epoch #70: loss=0.030710922102333
Epoch #71: loss=0.06909638985304073
Epoch #72: loss=0.02859864159767139
Epoch #73: loss=0.029428681905431273
Epoch #74: loss=0.03202990647661777
Epoch #75: loss=0.02984017340696439
Epoch #76: loss=0.03277494525051831
Epoch #77: loss=0.03046628025982673
Epoch #78: loss=0.02381468920863145
Epoch #79: loss=0.022473144098642348
Epoch #80: loss=0.04059214011171467
Epoch #81: loss=0.02906733483541757
Epoch #82: loss=0.03117116896187543
Epoch #83: loss=0.024812561957722728
Epoch #84: loss=0.02165886752551333
Epoch #85: loss=0.021336871287314266
Epoch #86: loss=0.020828216316225563
Epoch #87: loss=0.029762167787945753
Epoch #88: loss=0.025685660868648916
Epoch #89: loss=0.02408194232148595
Epoch #90: loss=0.02535353695878127
Epoch #91: loss=0.02949700498131625
Epoch #92: loss=0.04962559607520234
Epoch #93: loss=0.03264793858882816
Epoch #94: loss=0.030343820996807023
Epoch #95: loss=0.02983677322724058
Epoch #96: loss=0.027076964153994118
Epoch #97: loss=0.021070997322524255
Epoch #98: loss=0.0357991681710354
Epoch #99: loss=0.02797228366779607
Epoch #100: loss=0.02657284910674207
Epoch #101: loss=0.02722215478951555
Epoch #102: loss=0.03118729749084672
Epoch #103: loss=0.027079748445040814
Epoch #104: loss=0.03191440441046974
Epoch #105: loss=0.03809874218131881
Epoch #106: loss=0.0412306459592877
Epoch #107: loss=0.03241311306538548
Epoch #108: loss=0.03503296517841851
Epoch #109: loss=0.025392713143013508
Epoch #110: loss=0.024763434343358745
Epoch #111: loss=0.035865051713439504
Epoch #112: loss=0.026182292873272672
Epoch #113: loss=0.016043301745715628
Epoch #114: loss=0.013369713157208892
Epoch #115: loss=0.023751478826896
Epoch #116: loss=0.017535697913921296
Epoch #117: loss=0.020060114477452033
Epoch #118: loss=0.023392329502149506
Epoch #119: loss=0.03038083655077831
Epoch #120: loss=0.05648533835275365
Epoch #121: loss=0.023297848315754283
Epoch #122: loss=0.02239379662101523
Epoch #123: loss=0.020423844894442784
Epoch #124: loss=0.04162744501324293
Epoch #125: loss=0.018527893199678232
Epoch #126: loss=0.023706797352220053
Epoch #127: loss=0.023726710217098507
Epoch #128: loss=0.020129721386529992
Epoch #129: loss=0.023761994082590155
Epoch #130: loss=0.01258065189523179
Epoch #131: loss=0.020517042915300755
Epoch #132: loss=0.014870079159404017
Epoch #133: loss=0.02117030086187047
Epoch #134: loss=0.023166653327886404
Epoch #135: loss=0.025329974343462493
Epoch #136: loss=0.018435684264356194
Epoch #137: loss=0.025229637611378815
Epoch #138: loss=0.017358770103739863
Epoch #139: loss=0.016908830904347787
Epoch #140: loss=0.02019840005232254
Epoch #141: loss=0.024673050356969248
Epoch #142: loss=0.02254298032303701
Epoch #143: loss=0.016268103381229422
Epoch #144: loss=0.017897943187909687
Epoch #145: loss=0.02036744897555937
Epoch #146: loss=0.01917167415290134
Epoch #147: loss=0.06737742916967752
Epoch #148: loss=0.0258498845159054
Epoch #149: loss=0.03857338016643466
Epoch #150: loss=0.02155040864246465
Epoch #151: loss=0.020348180616565514
Epoch #152: loss=0.022054157531827167
Epoch #153: loss=0.01734883474039504
Epoch #154: loss=0.011245837526508868
Epoch #155: loss=0.015460225378947576
Epoch #156: loss=0.01481381357561553
Epoch #157: loss=0.013268302367664762
Epoch #158: loss=0.015784414005056965
Epoch #159: loss=0.014741078853365338
Epoch #160: loss=0.03334519219130189
Epoch #161: loss=0.01972818550296194
Epoch #162: loss=0.017206212403488325
Epoch #163: loss=0.03516282731825846
Epoch #164: loss=0.02034965279086637
Epoch #165: loss=0.014887471748980238
Epoch #166: loss=0.015745605886920765
Epoch #167: loss=0.021858155828037223
Epoch #168: loss=0.033403394932282116
Epoch #169: loss=0.021817451209721013
Epoch #170: loss=0.014944104448572727
Epoch #171: loss=0.013342629312059475
Epoch #172: loss=0.01744072702500229
Epoch #173: loss=0.016250155138550326
Epoch #174: loss=0.013853349580867438
Epoch #175: loss=0.01940068914024908
Epoch #176: loss=0.02148562572221549
Epoch #177: loss=0.01440599029055669
Epoch #178: loss=0.01896103787779187
Epoch #179: loss=0.017212011203290394
Epoch #180: loss=0.012388422499151645
Epoch #181: loss=0.014467663041570978
Epoch #182: loss=0.017356220281120233
Epoch #183: loss=0.017832806554430307
Epoch #184: loss=0.031318791229361
Epoch #185: loss=0.02660533433836896
Epoch #186: loss=0.02272386226260486
Epoch #187: loss=0.01579540479092213
Epoch #188: loss=0.012740708512692003
Epoch #189: loss=0.01281877835373009
Epoch #190: loss=0.019402981575088536
Epoch #191: loss=0.02404871746208907
Epoch #192: loss=0.02374965563926491
Epoch #193: loss=0.019548071042836887
Epoch #194: loss=0.01457497582651697
Epoch #195: loss=0.01618293562361422
Epoch #196: loss=0.02437155820206542
Epoch #197: loss=0.008925909902159003
Epoch #198: loss=0.012500175528181163
Epoch #199: loss=0.014512479144330081
Epoch #200: loss=0.015052415886072725
Epoch #201: loss=0.015148159902309999
Epoch #202: loss=0.014172129400928194
Epoch #203: loss=0.0184707912894304
Epoch #204: loss=0.016208342539314236
Epoch #205: loss=0.014802254110777756
Epoch #206: loss=0.019378941076865885
Epoch #207: loss=0.015367670852616097
Epoch #208: loss=0.03516165330473173
Epoch #209: loss=0.03091069196653691
Epoch #210: loss=0.01835273095622099
Epoch #211: loss=0.02234330099877081
Epoch #212: loss=0.024833967967251305
Epoch #213: loss=0.01854421910026022
Epoch #214: loss=0.015761960482666922
Epoch #215: loss=0.010360906953272726
Epoch #216: loss=0.00919996210835788
Epoch #217: loss=0.009218278788033612
Epoch #218: loss=0.019938790151216034
Epoch #219: loss=0.012196606149483983
Epoch #220: loss=0.011779561416395674
Epoch #221: loss=0.014573387934520031
Epoch #222: loss=0.019831094343576945
Epoch #223: loss=0.018199925997101844
Epoch #224: loss=0.014569894881008492
Epoch #225: loss=0.015570943289709422
Epoch #226: loss=0.022947220952205714
Epoch #227: loss=0.017101980404168854
Epoch #228: loss=0.013142227602397074
Epoch #229: loss=0.016183880585924185
Epoch #230: loss=0.014630451534598944
Epoch #231: loss=0.01584297810162146
Epoch #232: loss=0.01464108257572488
Epoch #233: loss=0.015187357728358447
Epoch #234: loss=0.011505883134218277
Epoch #235: loss=0.010246736177664605
Epoch #236: loss=0.006841063863075327
Epoch #237: loss=0.013119442028168816
Epoch #238: loss=0.01480085446963217
Epoch #239: loss=0.01897770216618526
Epoch #240: loss=0.020053036975912705
Epoch #241: loss=0.013791505560047448
Epoch #242: loss=0.019244296475205504
Epoch #243: loss=0.013884551465058135
Epoch #244: loss=0.012695794749864339
Epoch #245: loss=0.013140496581659786
Epoch #246: loss=0.02123339655259943
Epoch #247: loss=0.01988871748489189
Epoch #248: loss=0.02172538644784557
Epoch #249: loss=0.021669328160766912

Training time: 4:18:08.419445

Finished.
n2one setting etth1_electricity_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_electricity_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_electricity_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.54472e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.144e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4731018185342529, 'MAE': 0.5225752638363861}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_traffic_weather', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_traffic_weather_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.133431768783644
Epoch #1: loss=0.42934308325112197
Epoch #2: loss=0.3190977995205858
Epoch #3: loss=0.2343568245292376
Epoch #4: loss=0.1938491157313299
Epoch #5: loss=0.16138589446271598
Epoch #6: loss=0.14991452245655673
Epoch #7: loss=0.12880040572633625
Epoch #8: loss=0.10771955780622514
Epoch #9: loss=0.09745018061812363
Epoch #10: loss=0.0844378225318047
Epoch #11: loss=0.0852517675317033
Epoch #12: loss=0.07986090917598103
Epoch #13: loss=0.0702104060338321
Epoch #14: loss=0.06550543892129673
Epoch #15: loss=0.060820901021881646
Epoch #16: loss=0.0530642722298875
Epoch #17: loss=0.06153192924252352
Epoch #18: loss=0.058674038073578696
Epoch #19: loss=0.05155160481698145
Epoch #20: loss=0.04468427507256225
Epoch #21: loss=0.055456921511704324
Epoch #22: loss=0.045874926704892564
Epoch #23: loss=0.04749964402452652
Epoch #24: loss=0.038874058632112456
Epoch #25: loss=0.03782716499376189
Epoch #26: loss=0.04119492257183012
Epoch #27: loss=0.0322237044395931
Epoch #28: loss=0.033887639596626454
Epoch #29: loss=0.04142416602484466
Epoch #30: loss=0.039379068197618765
Epoch #31: loss=0.030611414992895665
Epoch #32: loss=0.040190095967722425
Epoch #33: loss=0.023282491921072606
Epoch #34: loss=0.030068513659068367
Epoch #35: loss=0.02804249633368958
Epoch #36: loss=0.02944044330867538
Epoch #37: loss=0.03132238636930166
Epoch #38: loss=0.038002048419299404
Epoch #39: loss=0.03155175893672862
Epoch #40: loss=0.025404540233589793
Epoch #41: loss=0.031795352382725885
Epoch #42: loss=0.03790365958985659
Epoch #43: loss=0.02086685509577019
Epoch #44: loss=0.026014368108398276
Epoch #45: loss=0.025367375510398756
Epoch #46: loss=0.020316919925500374
Epoch #47: loss=0.02117148525544635
Epoch #48: loss=0.024317763982257448
Epoch #49: loss=0.021824053250117926
Epoch #50: loss=0.024287166598437656
Epoch #51: loss=0.02317825013227948
Epoch #52: loss=0.026278251788888502
Epoch #53: loss=0.01660158977175246
Epoch #54: loss=0.028252985263139258
Epoch #55: loss=0.022149512030421002
Epoch #56: loss=0.022796843060573262
Epoch #57: loss=0.025761299850172024
Epoch #58: loss=0.019526278913182378
Epoch #59: loss=0.020561899897881767
Epoch #60: loss=0.019970046711874887
Epoch #61: loss=0.021444801620972558
Epoch #62: loss=0.016633236535575094
Epoch #63: loss=0.02474870526006799
Epoch #64: loss=0.02000908262373401
Epoch #65: loss=0.02315274810622701
Epoch #66: loss=0.0245752405472797
Epoch #67: loss=0.017438903982151435
Epoch #68: loss=0.018380009937139133
Epoch #69: loss=0.013984780950639554
Epoch #70: loss=0.02701368648168636
Epoch #71: loss=0.02021897930454192
Epoch #72: loss=0.01626582977169469
Epoch #73: loss=0.020758358645252883
Epoch #74: loss=0.017338202072038542
Epoch #75: loss=0.01593751583418122
Epoch #76: loss=0.024034560826547216
Epoch #77: loss=0.026373590118064436
Epoch #78: loss=0.01724292125888481
Epoch #79: loss=0.013722287176935232
Epoch #80: loss=0.019222564328924944
Epoch #81: loss=0.01564674137645354
Epoch #82: loss=0.018508696960163037
Epoch #83: loss=0.023778673094357806
Epoch #84: loss=0.014832752748937528
Epoch #85: loss=0.015674954298597516
Epoch #86: loss=0.02348325937416004
Epoch #87: loss=0.017140342606597074
Epoch #88: loss=0.025729219653440754
Epoch #89: loss=0.022774453682034127
Epoch #90: loss=0.015261539348951338
Epoch #91: loss=0.015965404030125505
Epoch #92: loss=0.015238608388482545
Epoch #93: loss=0.02623131131953638
Epoch #94: loss=0.01625805779918898
Epoch #95: loss=0.011953273903241631
Epoch #96: loss=0.016989754814935545
Epoch #97: loss=0.018435247821210463
Epoch #98: loss=0.014259246722212992
Epoch #99: loss=0.028133925697610158
Epoch #100: loss=0.016117304242827393
Epoch #101: loss=0.011184341389121352
Epoch #102: loss=0.02292472340889124
Epoch #103: loss=0.019485967702560086
Epoch #104: loss=0.02246677423547693
Epoch #105: loss=0.022455543619170838
Epoch #106: loss=0.018086670784737562
Epoch #107: loss=0.01062245085873178
Epoch #108: loss=0.016929043426312372
Epoch #109: loss=0.01737494111680894
Epoch #110: loss=0.01177190431324094
Epoch #111: loss=0.010882295890940176
Epoch #112: loss=0.015420977065115958
Epoch #113: loss=0.01613656096918087
Epoch #114: loss=0.015896639764027973
Epoch #115: loss=0.01715470176787173
Epoch #116: loss=0.021916924043676903
Epoch #117: loss=0.01319988849337893
Epoch #118: loss=0.016251421560905352
Epoch #119: loss=0.03407722531314471
Epoch #120: loss=0.013755323114224798
Epoch #121: loss=0.017958081772943762
Epoch #122: loss=0.013830922225713938
Epoch #123: loss=0.012045618727741222
Epoch #124: loss=0.019929092528438976
Epoch #125: loss=0.01382630890044748
Epoch #126: loss=0.013018745853300285
Epoch #127: loss=0.01918966682538697
Epoch #128: loss=0.01042441631884863
Epoch #129: loss=0.017779613709091546
Epoch #130: loss=0.01527236329115844
Epoch #131: loss=0.014499024573359743
Epoch #132: loss=0.012038394890206094
Epoch #133: loss=0.012575508380834242
Epoch #134: loss=0.016620423254204455
Epoch #135: loss=0.014140972395930908
Epoch #136: loss=0.013964579343261176
Epoch #137: loss=0.01007783759160377
Epoch #138: loss=0.013447859331327439
Epoch #139: loss=0.01816334621834454
Epoch #140: loss=0.012120646663145397
Epoch #141: loss=0.012496145401317783
Epoch #142: loss=0.010204208474775371
Epoch #143: loss=0.014302296563804114
Epoch #144: loss=0.01956758738899286
Epoch #145: loss=0.013327414118983996
Epoch #146: loss=0.012956269265916042
Epoch #147: loss=0.01131168919623252
Epoch #148: loss=0.01375265593576933
Epoch #149: loss=0.008315515820965867
Epoch #150: loss=0.014928807463111907
Epoch #151: loss=0.013947746588708053
Epoch #152: loss=0.016479810741378838
Epoch #153: loss=0.010765565899213745
Epoch #154: loss=0.019693245911367847
Epoch #155: loss=0.019486336352715957
Epoch #156: loss=0.010925024410666815
Epoch #157: loss=0.010393014262520121
Epoch #158: loss=0.018470328277973302
Epoch #159: loss=0.010345105664488815
Epoch #160: loss=0.013638956811117767
Epoch #161: loss=0.01016260796345578
Epoch #162: loss=0.016190450373443896
Epoch #163: loss=0.014346546147346454
Epoch #164: loss=0.0131119863935304
Epoch #165: loss=0.007743969957383906
Epoch #166: loss=0.010656321104013019
Epoch #167: loss=0.01340352595528827
Epoch #168: loss=0.01469824070292369
Epoch #169: loss=0.0102749594172961
Epoch #170: loss=0.013455239999857238
Epoch #171: loss=0.01104561700851477
Epoch #172: loss=0.016986835420563527
Epoch #173: loss=0.012634771255523945
Epoch #174: loss=0.011698916996406475
Epoch #175: loss=0.013600127636651227
Epoch #176: loss=0.010949435050377503
Epoch #177: loss=0.01035918822266843
Epoch #178: loss=0.016733990944746372
Epoch #179: loss=0.016590404139497375
Epoch #180: loss=0.013446714533034415
Epoch #181: loss=0.010447583380776363
Epoch #182: loss=0.009749800991315742
Epoch #183: loss=0.013900286114372069
Epoch #184: loss=0.014776788207418779
Epoch #185: loss=0.011120526012984057
Epoch #186: loss=0.01637702354552893
Epoch #187: loss=0.013929514905311656
Epoch #188: loss=0.009314718060377548
Epoch #189: loss=0.007814401094497068
Epoch #190: loss=0.010770731409666955
Epoch #191: loss=0.00967683435215123
Epoch #192: loss=0.011441363866067642
Epoch #193: loss=0.010062204940665991
Epoch #194: loss=0.01666612821584307
Epoch #195: loss=0.008882312073148579
Epoch #196: loss=0.017040958937908544
Epoch #197: loss=0.010482496543583856
Epoch #198: loss=0.012865170561474378
Epoch #199: loss=0.01843680164164749
Epoch #200: loss=0.013980813291640536
Epoch #201: loss=0.012451651962763401
Epoch #202: loss=0.008843127367582287
Epoch #203: loss=0.010717433156002074
Epoch #204: loss=0.007571636973691625
Epoch #205: loss=0.01245853422427818
Epoch #206: loss=0.04816911467503855
Epoch #207: loss=0.016930792030947304
Epoch #208: loss=0.011333400980691691
Epoch #209: loss=0.013057754007275425
Epoch #210: loss=0.018258110499146066
Epoch #211: loss=0.00948371261760837
Epoch #212: loss=0.019429725336444867
Epoch #213: loss=0.018477560803925035
Epoch #214: loss=0.00857030873610599
Epoch #215: loss=0.011608456064167813
Epoch #216: loss=0.008247495806995811
Epoch #217: loss=0.010067674570343608
Epoch #218: loss=0.014948046509815151
Epoch #219: loss=0.02533388189719756
Epoch #220: loss=0.013277371763528127
Epoch #221: loss=0.014114003476550849
Epoch #222: loss=0.011658231648564464
Epoch #223: loss=0.030733124680190176
Epoch #224: loss=0.00953388795303441
Epoch #225: loss=0.009870386869528243
Epoch #226: loss=0.008702639052296427
Epoch #227: loss=0.011226982399564387
Epoch #228: loss=0.015383961664443814
Epoch #229: loss=0.013805376094025846
Epoch #230: loss=0.010335631774056848
Epoch #231: loss=0.0075540351287290124
Epoch #232: loss=0.011192165677030519
Epoch #233: loss=0.012972963649900526
Epoch #234: loss=0.007835584698217614
Epoch #235: loss=0.0177147364785619
Epoch #236: loss=0.023978279994956123
Epoch #237: loss=0.02494968051307408
Epoch #238: loss=0.013054789927792632
Epoch #239: loss=0.009590275061538563
Epoch #240: loss=0.009110832200210032
Epoch #241: loss=0.009374523546036812
Epoch #242: loss=0.011005603000063152
Epoch #243: loss=0.00917587818676416
Epoch #244: loss=0.011252449292692163
Epoch #245: loss=0.011627035695189927
Epoch #246: loss=0.00958064712251357
Epoch #247: loss=0.009363094612620458
Epoch #248: loss=0.009468781309138578
Epoch #249: loss=0.00885635135831427

Training time: 11:19:15.862032

Finished.
n2one setting etth1_traffic_weather -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_traffic_weather_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_traffic_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.00136e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.2173e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.6562e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.00136e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4073571992970656, 'MAE': 0.45404364012593235}
Finished.
------------------------- record done -------------------------
n2one setting etth1_traffic_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_traffic_weather_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_traffic_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.42748e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.42609907193937435, 'MAE': 0.4056589761727691}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_traffic_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_traffic_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.1039991154162343
Epoch #1: loss=0.407423408011754
Epoch #2: loss=0.28290147377664443
Epoch #3: loss=0.22078115403006532
Epoch #4: loss=0.18496399219471754
Epoch #5: loss=0.15313844058233628
Epoch #6: loss=0.12050564991078735
Epoch #7: loss=0.10303275863573108
Epoch #8: loss=0.09220925814863995
Epoch #9: loss=0.0771778411324324
Epoch #10: loss=0.07492262209439597
Epoch #11: loss=0.07117361122659464
Epoch #12: loss=0.06486892399188034
Epoch #13: loss=0.06796288874930571
Epoch #14: loss=0.06003145870095291
Epoch #15: loss=0.048942139069841774
Epoch #16: loss=0.04674360956391373
Epoch #17: loss=0.04314195546863161
Epoch #18: loss=0.050740843044887025
Epoch #19: loss=0.0464236147814837
Epoch #20: loss=0.042042420287122746
Epoch #21: loss=0.04586588422913304
Epoch #22: loss=0.032912285809836295
Epoch #23: loss=0.03520146523538059
Epoch #24: loss=0.03395204269313949
Epoch #25: loss=0.03446051511133542
Epoch #26: loss=0.035903722001876824
Epoch #27: loss=0.03746849281194077
Epoch #28: loss=0.03552508374974514
Epoch #29: loss=0.029969431125259446
Epoch #30: loss=0.034721863039125694
Epoch #31: loss=0.02946670119772254
Epoch #32: loss=0.03271096600155891
Epoch #33: loss=0.036025957771610925
Epoch #34: loss=0.032361553003453995
Epoch #35: loss=0.028387091669533827
Epoch #36: loss=0.02279565271155796
Epoch #37: loss=0.024604648631225374
Epoch #38: loss=0.02482353127979649
Epoch #39: loss=0.03105232514376766
Epoch #40: loss=0.027463452997373176
Epoch #41: loss=0.02402082429120918
Epoch #42: loss=0.03217159812017413
Epoch #43: loss=0.024317258817224446
Epoch #44: loss=0.024067851776614767
Epoch #45: loss=0.023295720423913712
Epoch #46: loss=0.02446159769555537
Epoch #47: loss=0.020528512721270122
Epoch #48: loss=0.02538670685929177
Epoch #49: loss=0.021182895410262227
Epoch #50: loss=0.026478167143682212
Epoch #51: loss=0.021321388298673225
Epoch #52: loss=0.024396209709957973
Epoch #53: loss=0.021062820445692555
Epoch #54: loss=0.028149964265045343
Epoch #55: loss=0.02226556484260811
Epoch #56: loss=0.020532037327748363
Epoch #57: loss=0.023829311639308917
Epoch #58: loss=0.02463108752009925
Epoch #59: loss=0.020779122031425755
Epoch #60: loss=0.025799544324233974
Epoch #61: loss=0.022819997758966707
Epoch #62: loss=0.017477051642266216
Epoch #63: loss=0.019770554767641745
Epoch #64: loss=0.02300959664844019
Epoch #65: loss=0.026245364032849296
Epoch #66: loss=0.019635765733910956
Epoch #67: loss=0.020739594702154904
Epoch #68: loss=0.02069914036779797
Epoch #69: loss=0.02330824424737816
Epoch #70: loss=0.025543473563844628
Epoch #71: loss=0.023531331426645614
Epoch #72: loss=0.014573196913472758
Epoch #73: loss=0.02141377767233365
Epoch #74: loss=0.019521459437950014
Epoch #75: loss=0.029747413865055892
Epoch #76: loss=0.02274769023559911
Epoch #77: loss=0.022228066371159125
Epoch #78: loss=0.020725767238478694
Epoch #79: loss=0.01843752229385537
Epoch #80: loss=0.016560077935343337
Epoch #81: loss=0.02173242704791695
Epoch #82: loss=0.017819030381215604
Epoch #83: loss=0.021390390770777715
Epoch #84: loss=0.01668799431946637
Epoch #85: loss=0.018750396233890684
Epoch #86: loss=0.021697475913802677
Epoch #87: loss=0.02103623062305969
Epoch #88: loss=0.01518572829924593
Epoch #89: loss=0.020004811273835684
Epoch #90: loss=0.018077049379958056
Epoch #91: loss=0.02016024913686883
Epoch #92: loss=0.020987082461992698
Epoch #93: loss=0.02267130286141565
Epoch #94: loss=0.020225678229519456
Epoch #95: loss=0.016718180143558966
Epoch #96: loss=0.022770273578935966
Epoch #97: loss=0.022788761491516124
Epoch #98: loss=0.012990911273583622
Epoch #99: loss=0.024950793878724342
Epoch #100: loss=0.01624890871854335
Epoch #101: loss=0.01471055732226752
Epoch #102: loss=0.016788057636065
Epoch #103: loss=0.017411118685618305
Epoch #104: loss=0.0293520300961981
Epoch #105: loss=0.013969602579335357
Epoch #106: loss=0.015371275285810834
Epoch #107: loss=0.017504714271580662
Epoch #108: loss=0.014971076350526654
Epoch #109: loss=0.0204588403547514
Epoch #110: loss=0.017338786846879783
Epoch #111: loss=0.016606833763239254
Epoch #112: loss=0.013624957705313762
Epoch #113: loss=0.018179676078912774
Epoch #114: loss=0.016011599124125985
Epoch #115: loss=0.015777759170749073
Epoch #116: loss=0.013881623376902361
Epoch #117: loss=0.015139926762654347
Epoch #118: loss=0.012258140279719247
Epoch #119: loss=0.015986740419795385
Epoch #120: loss=0.02125620758760282
Epoch #121: loss=0.016270636759224234
Epoch #122: loss=0.016322539718739343
Epoch #123: loss=0.01843161375837681
Epoch #124: loss=0.021798502155886263
Epoch #125: loss=0.015111471574244853
Epoch #126: loss=0.01673749166387749
Epoch #127: loss=0.01600630765741913
Epoch #128: loss=0.01574590669851564
Epoch #129: loss=0.016027353945500967
Epoch #130: loss=0.016751087966779654
Epoch #131: loss=0.02189512592883719
Epoch #132: loss=0.014591070270929603
Epoch #133: loss=0.013875623501325133
Epoch #134: loss=0.014582236631508724
Epoch #135: loss=0.01228951317186631
Epoch #136: loss=0.013152025856563908
Epoch #137: loss=0.013949200765479583
Epoch #138: loss=0.014229667030392744
Epoch #139: loss=0.01144059986190219
Epoch #140: loss=0.012982453644435487
Epoch #141: loss=0.01695410717267303
Epoch #142: loss=0.015412108399950396
Epoch #143: loss=0.016667352609605578
Epoch #144: loss=0.024387170398877847
Epoch #145: loss=0.013936524817786693
Epoch #146: loss=0.013476273410118896
Epoch #147: loss=0.012233397713842449
Epoch #148: loss=0.01481428977645357
Epoch #149: loss=0.02578850609431295
Epoch #150: loss=0.015165187248085629
Epoch #151: loss=0.013239252500229663
Epoch #152: loss=0.01151314003111905
Epoch #153: loss=0.013805205706693338
Epoch #154: loss=0.010929318740168807
Epoch #155: loss=0.01680672552583669
Epoch #156: loss=0.015587413912182917
Epoch #157: loss=0.017575464669399722
Epoch #158: loss=0.01303108560304081
Epoch #159: loss=0.011232081229905752
Epoch #160: loss=0.014223169457080308
Epoch #161: loss=0.013803693047450417
Epoch #162: loss=0.014966618448818164
Epoch #163: loss=0.023897055516331676
Epoch #164: loss=0.009230800595375026
Epoch #165: loss=0.014128235322205581
Epoch #166: loss=0.016659362634046306
Epoch #167: loss=0.013894224609520462
Epoch #168: loss=0.012660426067135551
Epoch #169: loss=0.010069421751442357
Epoch #170: loss=0.01346811007064111
Epoch #171: loss=0.013124922463806301
Epoch #172: loss=0.012847704214679487
Epoch #173: loss=0.014800475804958075
Epoch #174: loss=0.015222290803852493
Epoch #175: loss=0.012916603547587573
Epoch #176: loss=0.015051863498569221
Epoch #177: loss=0.013925271972801755
Epoch #178: loss=0.017729881621329515
Epoch #179: loss=0.011785930466708982
Epoch #180: loss=0.012196998164469765
Epoch #181: loss=0.00960402962432905
Epoch #182: loss=0.011731703069687321
Epoch #183: loss=0.015126331460698292
Epoch #184: loss=0.016144867927366347
Epoch #185: loss=0.013360550306804326
Epoch #186: loss=0.013947825231273449
Epoch #187: loss=0.011752156392195817
Epoch #188: loss=0.011862213775529361
Epoch #189: loss=0.012744494581664354
Epoch #190: loss=0.01540696233438759
Epoch #191: loss=0.0108669503677441
Epoch #192: loss=0.011027095926360853
Epoch #193: loss=0.011277727536853677
Epoch #194: loss=0.011180703779208625
Epoch #195: loss=0.017167999157425867
Epoch #196: loss=0.01075971731606095
Epoch #197: loss=0.011152993888276822
Epoch #198: loss=0.008210642015761372
Epoch #199: loss=0.015391124425260265
Epoch #200: loss=0.01390791408412125
Epoch #201: loss=0.011709980669292274
Epoch #202: loss=0.009900425258633508
Epoch #203: loss=0.015510382495585302
Epoch #204: loss=0.016040450041400037
Epoch #205: loss=0.01015041762667054
Epoch #206: loss=0.00906435917997085
Epoch #207: loss=0.018804966678172285
Epoch #208: loss=0.020719667993198673
Epoch #209: loss=0.01230043544167331
Epoch #210: loss=0.012353912996916825
Epoch #211: loss=0.009412161545699092
Epoch #212: loss=0.017160446467383805
Epoch #213: loss=0.011589023203740615
Epoch #214: loss=0.007691441053440189
Epoch #215: loss=0.015251134365788812
Epoch #216: loss=0.012725599053909974
Epoch #217: loss=0.00993688959261841
Epoch #218: loss=0.01489861759320252
Epoch #219: loss=0.013526225701061278
Epoch #220: loss=0.013570347546897546
Epoch #221: loss=0.01093442462497333
Epoch #222: loss=0.01596248554434981
Epoch #223: loss=0.010903919750205724
Epoch #224: loss=0.012763384553739756
Epoch #225: loss=0.012547715891458857
Epoch #226: loss=0.009990058636473743
Epoch #227: loss=0.015704696563400643
Epoch #228: loss=0.009274975108110187
Epoch #229: loss=0.011209766515048458
Epoch #230: loss=0.012674022738929591
Epoch #231: loss=0.010928365896224175
Epoch #232: loss=0.011286680512333001
Epoch #233: loss=0.0105137051174209
Epoch #234: loss=0.010557100345394409
Epoch #235: loss=0.013142671324799852
Epoch #236: loss=0.012026501122824667
Epoch #237: loss=0.013276288732696493
Epoch #238: loss=0.011286547984274798
Epoch #239: loss=0.010395381278216905
Epoch #240: loss=0.01350695649374655
Epoch #241: loss=0.011317443105568308
Epoch #242: loss=0.012689530993731477
Epoch #243: loss=0.009135612201572427
Epoch #244: loss=0.011005148778388388
Epoch #245: loss=0.008418208665313107
Epoch #246: loss=0.009541685906607016
Epoch #247: loss=0.011623690222694508
Epoch #248: loss=0.008176717742863193
Epoch #249: loss=0.012046366355705069

Training time: 10:21:50.181121

Finished.
n2one setting etth1_traffic_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_traffic_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_traffic_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.12207e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.2597e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.46909e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.12207e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.39249247510810137, 'MAE': 0.44674744711985576}
Finished.
------------------------- record done -------------------------
n2one setting etth1_traffic_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_traffic_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_traffic_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.91785e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.91203e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.91785e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.7869521569693393, 'MAE': 0.7010214577266277}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_weather_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_weather_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=6.336050359214225
Epoch #1: loss=2.7600383235187067
Epoch #2: loss=2.3231793002384467
Epoch #3: loss=2.4061517686378666
Epoch #4: loss=2.1069118685838655
Epoch #5: loss=2.0774646386867617
Epoch #6: loss=1.9532415256267641
Epoch #7: loss=1.8329015097967007
Epoch #8: loss=1.7378628341163076
Epoch #9: loss=1.6442351777379105
Epoch #10: loss=1.6355020331173409
Epoch #11: loss=1.4483818833420916
Epoch #12: loss=1.4538551336381493
Epoch #13: loss=1.451566789208389
Epoch #14: loss=1.3572674582644206
Epoch #15: loss=1.2521786515305682
Epoch #16: loss=1.2483805330788218
Epoch #17: loss=1.1445934249133598
Epoch #18: loss=1.0873343144975058
Epoch #19: loss=1.101080010576946
Epoch #20: loss=0.9918914393680852
Epoch #21: loss=0.9637901361395673
Epoch #22: loss=1.0195800051456545
Epoch #23: loss=0.9900372159190294
Epoch #24: loss=0.931028491113244
Epoch #25: loss=0.9200619691755714
Epoch #26: loss=0.9226176113617129
Epoch #27: loss=0.8917547391682137
Epoch #28: loss=0.8931251924212386
Epoch #29: loss=0.8272519373312229
Epoch #30: loss=0.801631402678606
Epoch #31: loss=0.8777440030400346
Epoch #32: loss=0.7780565953836208
Epoch #33: loss=0.7526495791063076
Epoch #34: loss=0.7672070795443
Epoch #35: loss=0.6787457000918504
Epoch #36: loss=0.7452237533359993
Epoch #37: loss=0.7479646540269619
Epoch #38: loss=0.6592598157684978
Epoch #39: loss=0.6864768426592757
Epoch #40: loss=0.6513578877216433
Epoch #41: loss=0.6890810219252982
Epoch #42: loss=0.638032836884987
Epoch #43: loss=0.5823788533850414
Epoch #44: loss=0.7024392885405842
Epoch #45: loss=0.7068937340887581
Epoch #46: loss=0.6504530695880332
Epoch #47: loss=0.6164669634365454
Epoch #48: loss=0.6096783367598929
Epoch #49: loss=0.5735621619515303
Epoch #50: loss=0.568393366365898
Epoch #51: loss=0.6580380506631804
Epoch #52: loss=0.5638327467732314
Epoch #53: loss=0.5530655834732986
Epoch #54: loss=0.5455634710265369
Epoch #55: loss=0.5379453875669619
Epoch #56: loss=0.5589052794910059
Epoch #57: loss=0.5066377622325245
Epoch #58: loss=0.5317090466255094
Epoch #59: loss=0.6115276951615404
Epoch #60: loss=0.5349498492915455
Epoch #61: loss=0.5438148902683724
Epoch #62: loss=0.5238656423440794
Epoch #63: loss=0.4551781793920005
Epoch #64: loss=0.3924567132461362
Epoch #65: loss=0.4355030648592042
Epoch #66: loss=0.478940206329997
Epoch #67: loss=0.4959398620739216
Epoch #68: loss=0.45053241710837294
Epoch #69: loss=0.41527332002069894
Epoch #70: loss=0.46827901972503194
Epoch #71: loss=0.4382165147037041
Epoch #72: loss=0.33983272423104544
Epoch #73: loss=0.4271430558547741
Epoch #74: loss=0.36860596806537815
Epoch #75: loss=0.37945959807896035
Epoch #76: loss=0.4990839936384341
Epoch #77: loss=0.4966555521255586
Epoch #78: loss=0.4552837068714747
Epoch #79: loss=0.4015167649926209
Epoch #80: loss=0.37735563916404075
Epoch #81: loss=0.3708087518447783
Epoch #82: loss=0.5145906438914741
Epoch #83: loss=0.4097673598586059
Epoch #84: loss=0.4033388077485852
Epoch #85: loss=0.3613712267904747
Epoch #86: loss=0.3041255208777218
Epoch #87: loss=0.2973595619565103
Epoch #88: loss=0.264165349668119
Epoch #89: loss=0.332925462686434
Epoch #90: loss=0.30417113369557913
Epoch #91: loss=0.3024000654496798
Epoch #92: loss=0.2940952756055972
Epoch #93: loss=0.2300145109979118
Epoch #94: loss=0.23661317421895703
Epoch #95: loss=0.24884722926994648
Epoch #96: loss=0.2556027581052082
Epoch #97: loss=0.27022764595543464
Epoch #98: loss=0.22100028958989354
Epoch #99: loss=0.2682761081108233
Epoch #100: loss=0.25989518078362067
Epoch #101: loss=0.271433359784324
Epoch #102: loss=0.26580180591199454
Epoch #103: loss=0.2693484545480914
Epoch #104: loss=0.2768869034764243
Epoch #105: loss=0.2526436309988906
Epoch #106: loss=0.2615421170868525
Epoch #107: loss=0.2985924400570916
Epoch #108: loss=0.25531495871340354
Epoch #109: loss=0.2787892199689295
Epoch #110: loss=0.31651910939594596
Epoch #111: loss=0.3048141507840738
Epoch #112: loss=0.2374010038811986
Epoch #113: loss=0.2381048751313512
Epoch #114: loss=0.28620773462987525
Epoch #115: loss=0.26821334260266
Epoch #116: loss=0.2545589943666284
Epoch #117: loss=0.25461731996478104
Epoch #118: loss=0.20592046329161015
Epoch #119: loss=0.25182716784680764
Epoch #120: loss=0.22667736650967016
Epoch #121: loss=0.2144390736229536
Epoch #122: loss=0.1917873839052712
Epoch #123: loss=0.19364673471668872
Epoch #124: loss=0.22911828383803368
Epoch #125: loss=0.2962704493505199
Epoch #126: loss=0.2233385914346067
Epoch #127: loss=0.19811032812406376
Epoch #128: loss=0.19772336277656438
Epoch #129: loss=0.2647608922022145
Epoch #130: loss=0.23568144804093896
Epoch #131: loss=0.20737380861509136
Epoch #132: loss=0.17977878178765133
Epoch #133: loss=0.2353225784694276
Epoch #134: loss=0.3042127888922284
Epoch #135: loss=0.46693774149185274
Epoch #136: loss=0.23879201673879857
Epoch #137: loss=0.334850429943422
Epoch #138: loss=0.26613381541356806
Epoch #139: loss=0.22682883381480123
Epoch #140: loss=0.21617414211718047
Epoch #141: loss=0.20656828237016026
Epoch #142: loss=0.20902696633484305
Epoch #143: loss=0.22652444261603238
Epoch #144: loss=0.1632844825706831
Epoch #145: loss=0.3382095871720372
Epoch #146: loss=0.30369330370208114
Epoch #147: loss=0.22122373622728558
Epoch #148: loss=0.21986598621417835
Epoch #149: loss=0.18322965857095835
Epoch #150: loss=0.17870937633078274
Epoch #151: loss=0.16185596521671225
Epoch #152: loss=0.17624491516773294
Epoch #153: loss=0.1602969320445526
Epoch #154: loss=0.1671816731644113
Epoch #155: loss=0.20642428999630416
Epoch #156: loss=0.16962466570662288
Epoch #157: loss=0.19595420106155118
Epoch #158: loss=0.16777310493152317
Epoch #159: loss=0.1293053577949361
Epoch #160: loss=0.1565062233769312
Epoch #161: loss=0.16240289543823497
Epoch #162: loss=0.1856621538357037
Epoch #163: loss=0.13443031239255174
Epoch #164: loss=0.18434222269712425
Epoch #165: loss=0.15668315026999974
Epoch #166: loss=0.1927392460950991
Epoch #167: loss=0.23702565280766022
Epoch #168: loss=0.18627581091188802
Epoch #169: loss=0.15460486442032384
Epoch #170: loss=0.19741745874649141
Epoch #171: loss=0.19300379940285917
Epoch #172: loss=0.14415609554910078
Epoch #173: loss=0.1327025476025372
Epoch #174: loss=0.13074762178812085
Epoch #175: loss=0.14567837718783355
Epoch #176: loss=0.1738943973692452
Epoch #177: loss=0.1715721728325617
Epoch #178: loss=0.18168080425480518
Epoch #179: loss=0.14703540013330738
Epoch #180: loss=0.11970309054524433
Epoch #181: loss=0.12702760759105042
Epoch #182: loss=0.14206881871128954
Epoch #183: loss=0.13329676820374117
Epoch #184: loss=0.11477454801703371
Epoch #185: loss=0.10714410758781724
Epoch #186: loss=0.11635852777739851
Epoch #187: loss=0.11481010591293253
Epoch #188: loss=0.11263044996232521
Epoch #189: loss=0.1159584414123035
Epoch #190: loss=0.10260352455988163
Epoch #191: loss=0.1067967816914727
Epoch #192: loss=0.12898963771578742
Epoch #193: loss=0.12061379291117191
Epoch #194: loss=0.1298559762355758
Epoch #195: loss=0.18228076775444718
Epoch #196: loss=0.17153515375968886
Epoch #197: loss=0.10889686789454484
Epoch #198: loss=0.1555865474226998
Epoch #199: loss=0.1311349535315502
Epoch #200: loss=0.14369213980872456
Epoch #201: loss=0.1475537025892153
Epoch #202: loss=0.13300353020611333
Epoch #203: loss=0.1062190186050607
Epoch #204: loss=0.17478430248433496
Epoch #205: loss=0.1500250153788706
Epoch #206: loss=0.1318249629765022
Epoch #207: loss=0.14045453162454977
Epoch #208: loss=0.09276362994640339
Epoch #209: loss=0.17508987223774922
Epoch #210: loss=0.2151274259043176
Epoch #211: loss=0.19740510268545733
Epoch #212: loss=0.13339144532091735
Epoch #213: loss=0.129138674178138
Epoch #214: loss=0.0993458274297598
Epoch #215: loss=0.10777643136680126
Epoch #216: loss=0.15487352140792987
Epoch #217: loss=0.16575083531802748
Epoch #218: loss=0.10293676622393655
Epoch #219: loss=0.12401514595783339
Epoch #220: loss=0.10868950633377564
Epoch #221: loss=0.10355311073362827
Epoch #222: loss=0.09727503899939177
Epoch #223: loss=0.12234244491087228
Epoch #224: loss=0.10726902138714384
Epoch #225: loss=0.0987377933612684
Epoch #226: loss=0.10222617748034436
Epoch #227: loss=0.07481355272324347
Epoch #228: loss=0.09218923631692078
Epoch #229: loss=0.12879331600738736
Epoch #230: loss=0.10912676687102492
Epoch #231: loss=0.10908008680292745
Epoch #232: loss=0.11471975912771575
Epoch #233: loss=0.08708470030801325
Epoch #234: loss=0.0993449665242579
Epoch #235: loss=0.13456935258355082
Epoch #236: loss=0.11455183271772978
Epoch #237: loss=0.11130591936227752
Epoch #238: loss=0.12940590565161006
Epoch #239: loss=0.13839231267934893
Epoch #240: loss=0.2089159897551304
Epoch #241: loss=0.15179032768781592
Epoch #242: loss=0.21212558302937484
Epoch #243: loss=0.16266538557119486
Epoch #244: loss=0.1420239654437798
Epoch #245: loss=0.09601077696353924
Epoch #246: loss=0.17996061520605552
Epoch #247: loss=0.11759332117692727
Epoch #248: loss=0.16727832777471077
Epoch #249: loss=0.10144099724910609

Training time: 0:37:23.777818

Finished.
n2one setting etth1_weather_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_weather_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_weather_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.65296e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.2437e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.65296e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.415810609207846, 'MAE': 0.44773982718251837}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm1_ettm2', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm1_ettm2_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=4.526741332021253
Epoch #1: loss=2.4994319882886162
Epoch #2: loss=2.141564837817488
Epoch #3: loss=1.9239770502879703
Epoch #4: loss=1.7682033160637165
Epoch #5: loss=1.5930584997966373
Epoch #6: loss=1.4012573176416858
Epoch #7: loss=1.4541026929329182
Epoch #8: loss=1.2320530085728085
Epoch #9: loss=1.188504379371117
Epoch #10: loss=1.13468003067477
Epoch #11: loss=1.0633384729253834
Epoch #12: loss=0.9923831532741415
Epoch #13: loss=0.9587475513589794
Epoch #14: loss=0.8953765281315508
Epoch #15: loss=0.877646359904059
Epoch #16: loss=0.8797349621509684
Epoch #17: loss=0.9018441582548207
Epoch #18: loss=0.7808790761848976
Epoch #19: loss=0.8044469952583313
Epoch #20: loss=0.8410919658068953
Epoch #21: loss=0.7832192161987568
Epoch #22: loss=0.6489447622463621
Epoch #23: loss=0.7144537876392233
Epoch #24: loss=0.6878105073139585
Epoch #25: loss=0.6880540107858593
Epoch #26: loss=0.6405855622784845
Epoch #27: loss=0.6919564111479397
Epoch #28: loss=0.5738114981815733
Epoch #29: loss=0.666826758919091
Epoch #30: loss=0.5672221656503349
Epoch #31: loss=0.5623083700393808
Epoch #32: loss=0.5173279673888765
Epoch #33: loss=0.5404381402607622
Epoch #34: loss=0.5289098928714621
Epoch #35: loss=0.5847745948824389
Epoch #36: loss=0.5314875337584265
Epoch #37: loss=0.6203072646568561
Epoch #38: loss=0.47324836254119873
Epoch #39: loss=0.5067283202861917
Epoch #40: loss=0.4191835738461593
Epoch #41: loss=0.4679218653974862
Epoch #42: loss=0.44612862529425784
Epoch #43: loss=0.42625342566391516
Epoch #44: loss=0.5417541964300747
Epoch #45: loss=0.5300618471770451
Epoch #46: loss=0.5048462429950977
Epoch #47: loss=0.392030819736678
Epoch #48: loss=0.35867449692611036
Epoch #49: loss=0.3195235287321025
Epoch #50: loss=0.3690943157878415
Epoch #51: loss=0.4054324323761052
Epoch #52: loss=0.3651899911206344
Epoch #53: loss=0.4480512090798082
Epoch #54: loss=0.3544345832076566
Epoch #55: loss=0.37856794277141836
Epoch #56: loss=0.3551170193943484
Epoch #57: loss=0.3684987800902334
Epoch #58: loss=0.32974184844000587
Epoch #59: loss=0.3426255064791647
Epoch #60: loss=0.3761785950126319
Epoch #61: loss=0.3131606825466814
Epoch #62: loss=0.31169655970458326
Epoch #63: loss=0.4083767980337143
Epoch #64: loss=0.4987953608406001
Epoch #65: loss=0.3292718221401346
Epoch #66: loss=0.3425877582410286
Epoch #67: loss=0.2802721631938013
Epoch #68: loss=0.29327153080496293
Epoch #69: loss=0.3243672010199777
Epoch #70: loss=0.31868263359727533
Epoch #71: loss=0.4009689812002511
Epoch #72: loss=0.24059682416504827
Epoch #73: loss=0.21777885972425856
Epoch #74: loss=0.22257267812202716
Epoch #75: loss=0.2659605995848261
Epoch #76: loss=0.23912748822878147
Epoch #77: loss=0.2093738903259409
Epoch #78: loss=0.22633397913184658
Epoch #79: loss=0.17595557457414165
Epoch #80: loss=0.2601732146637193
Epoch #81: loss=0.24937502911378598
Epoch #82: loss=0.3316540849106065
Epoch #83: loss=0.2639757389652318
Epoch #84: loss=0.18896390292151222
Epoch #85: loss=0.2062617569904903
Epoch #86: loss=0.15138207298928294
Epoch #87: loss=0.1825845056566699
Epoch #88: loss=0.18434270831017657
Epoch #89: loss=0.18847121375388112
Epoch #90: loss=0.19862358426225596
Epoch #91: loss=0.20825172549691692
Epoch #92: loss=0.14797518016963168
Epoch #93: loss=0.17758847117937845
Epoch #94: loss=0.14814036095450664
Epoch #95: loss=0.1658536213739165
Epoch #96: loss=0.1890418791565402
Epoch #97: loss=0.17055782958351332
Epoch #98: loss=0.1850372276686389
Epoch #99: loss=0.1954776999251596
Epoch #100: loss=0.15883681948842673
Epoch #101: loss=0.11519517980772874
Epoch #102: loss=0.131129610512791
Epoch #103: loss=0.22820402219377714
Epoch #104: loss=0.1844200959493374
Epoch #105: loss=0.1320395379744727
Epoch #106: loss=0.12873743050571146
Epoch #107: loss=0.11366140405679571
Epoch #108: loss=0.13904624046950503
Epoch #109: loss=0.1901373046225515
Epoch #110: loss=0.12886318988327322
Epoch #111: loss=0.12461562005096469
Epoch #112: loss=0.15472300671811762
Epoch #113: loss=0.13638466493836765
Epoch #114: loss=0.1049259403270894
Epoch #115: loss=0.18977192930620293
Epoch #116: loss=0.13577908605080227
Epoch #117: loss=0.14486518322393813
Epoch #118: loss=0.2596948317669589
Epoch #119: loss=0.1420061381469513
Epoch #120: loss=0.09944035344082734
Epoch #121: loss=0.12350705972519414
Epoch #122: loss=0.16732356504633508
Epoch #123: loss=0.23592136260764351
Epoch #124: loss=0.19640155020972777
Epoch #125: loss=0.20005036736356802
Epoch #126: loss=0.12170855315594838
Epoch #127: loss=0.12067589157357297
Epoch #128: loss=0.10586861623772259
Epoch #129: loss=0.10738201240270302
Epoch #130: loss=0.09837634238446581
Epoch #131: loss=0.12624692887967004
Epoch #132: loss=0.1187518241590467
Epoch #133: loss=0.09823454100767086
Epoch #134: loss=0.5970343039210501
Epoch #135: loss=0.28642629086971283
Epoch #136: loss=0.13453875520619854
Epoch #137: loss=0.1135336003940681
Epoch #138: loss=0.1146954551082233
Epoch #139: loss=0.15673067407875224
Epoch #140: loss=0.16927759143812904
Epoch #141: loss=0.1199128104951875
Epoch #142: loss=0.1350679651288123
Epoch #143: loss=0.14685511210098348
Epoch #144: loss=0.14723088508792992
Epoch #145: loss=0.12902442886140839
Epoch #146: loss=0.1477186568081379
Epoch #147: loss=0.07416668463626812
Epoch #148: loss=0.15690480159788295
Epoch #149: loss=0.09493179529391486
Epoch #150: loss=0.10646660298365972
Epoch #151: loss=0.10026990513092485
Epoch #152: loss=0.08981963369096148
Epoch #153: loss=0.07480741272969492
Epoch #154: loss=0.09446288430099857
Epoch #155: loss=0.11709316607950063
Epoch #156: loss=0.11208669924787407
Epoch #157: loss=0.09896241902405846
Epoch #158: loss=0.07186948231838901
Epoch #159: loss=0.09357629559034931
Epoch #160: loss=0.07986444690874939
Epoch #161: loss=0.08059102598706196
Epoch #162: loss=0.0924603536660815
Epoch #163: loss=0.16579959724612278
Epoch #164: loss=0.1126568002690529
Epoch #165: loss=0.18703080418294873
Epoch #166: loss=0.1720553020593421
Epoch #167: loss=0.08189171787094453
Epoch #168: loss=0.08388586522176347
Epoch #169: loss=0.07500686490073286
Epoch #170: loss=0.0984103709523534
Epoch #171: loss=0.09628005528116021
Epoch #172: loss=0.10158544496215623
Epoch #173: loss=0.09485696570883537
Epoch #174: loss=0.09956433001006472
Epoch #175: loss=0.10798931873307147
Epoch #176: loss=0.10304240509867668
Epoch #177: loss=0.09992627028761239
Epoch #178: loss=0.11609371391863658
Epoch #179: loss=0.08203377227844863
Epoch #180: loss=0.06451948266476393
Epoch #181: loss=0.0737846268276716
Epoch #182: loss=0.13171713686837205
Epoch #183: loss=0.10974436394613364
Epoch #184: loss=0.07380263073819465
Epoch #185: loss=0.18983959599301733
Epoch #186: loss=0.1319337959947257
Epoch #187: loss=0.09535453574539259
Epoch #188: loss=0.1516717838701503
Epoch #189: loss=0.129667849440513
Epoch #190: loss=0.0846896783352412
Epoch #191: loss=0.08105848029512784
Epoch #192: loss=0.06858863283334107
Epoch #193: loss=0.07731507179038279
Epoch #194: loss=0.07168696107792444
Epoch #195: loss=0.11166460571232541
Epoch #196: loss=0.10502669555616789
Epoch #197: loss=0.07760753720228014
Epoch #198: loss=0.0731899474972281
Epoch #199: loss=0.07160734568305056
Epoch #200: loss=0.09550829912567961
Epoch #201: loss=0.08358066082643024
Epoch #202: loss=0.0989760123193264
Epoch #203: loss=0.1218695573765656
Epoch #204: loss=0.12591393189183597
Epoch #205: loss=0.12906043899470362
Epoch #206: loss=0.07175108446771729
Epoch #207: loss=0.05634767864027928
Epoch #208: loss=0.05134648033257189
Epoch #209: loss=0.07829062767519519
Epoch #210: loss=0.06628802219598458
Epoch #211: loss=0.07399073345907803
Epoch #212: loss=0.05298925955490819
Epoch #213: loss=0.05132563079803668
Epoch #214: loss=0.04889546802010516
Epoch #215: loss=0.0761373620480299
Epoch #216: loss=0.06562631734614742
Epoch #217: loss=0.05890070977781353
Epoch #218: loss=0.06848566524748659
Epoch #219: loss=0.08135481156280329
Epoch #220: loss=0.06257614133686855
Epoch #221: loss=0.07987718955324642
Epoch #222: loss=0.05785326462174798
Epoch #223: loss=0.06253653854645531
Epoch #224: loss=0.07678447540142927
Epoch #225: loss=0.11127199682182279
Epoch #226: loss=0.08767537852941916
Epoch #227: loss=0.06849967826414725
Epoch #228: loss=0.06432733729738614
Epoch #229: loss=0.08658985466021916
Epoch #230: loss=0.0875391006662414
Epoch #231: loss=0.07133700634384978
Epoch #232: loss=0.07770195613005038
Epoch #233: loss=0.06984212731236014
Epoch #234: loss=0.13988783637639776
Epoch #235: loss=0.06687118479147039
Epoch #236: loss=0.10038044653704455
Epoch #237: loss=0.07211529184132814
Epoch #238: loss=0.07141630589191256
Epoch #239: loss=0.04362240574997047
Epoch #240: loss=0.0743382221794334
Epoch #241: loss=0.07239706544526692
Epoch #242: loss=0.04574231581826662
Epoch #243: loss=0.0848893504589796
Epoch #244: loss=0.07105223664307389
Epoch #245: loss=0.11234002351632406
Epoch #246: loss=0.08019855377617581
Epoch #247: loss=0.05573907141284696
Epoch #248: loss=0.06294304925691464
Epoch #249: loss=0.04081074182136819

Training time: 0:27:33.388819

Finished.
n2one setting etth2_ettm1_ettm2 -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_ettm2_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_ettm1_ettm2', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.48295e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.90435e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.48295e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3747796667345244, 'MAE': 0.4306155464821334}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm1_ettm2 -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_ettm2_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_ettm1_ettm2', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.56444e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.9522e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.56444e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.7579325373127097, 'MAE': 0.6905296989375302}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm1_ettm2 -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_ettm2_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_ettm1_ettm2', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.30367e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.24816010359708549, 'MAE': 0.33860336232955107}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm1_electricity', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm1_electricity_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.7146925236974846
Epoch #1: loss=0.7200747973623529
Epoch #2: loss=0.4939919585763177
Epoch #3: loss=0.37805380067818284
Epoch #4: loss=0.33783853506795775
Epoch #5: loss=0.2928634962852726
Epoch #6: loss=0.24333141416662915
Epoch #7: loss=0.23892666087389697
Epoch #8: loss=0.18245995086466668
Epoch #9: loss=0.17347584572513547
Epoch #10: loss=0.15207992955646685
Epoch #11: loss=0.14524619691183785
Epoch #12: loss=0.16098942581267484
Epoch #13: loss=0.11367631827791531
Epoch #14: loss=0.11415758629530053
Epoch #15: loss=0.11078853107944878
Epoch #16: loss=0.10826887957378123
Epoch #17: loss=0.0975237815176579
Epoch #18: loss=0.08377257260359318
Epoch #19: loss=0.07782294453124469
Epoch #20: loss=0.07489929758122185
Epoch #21: loss=0.06489486467631693
Epoch #22: loss=0.06888477546011804
Epoch #23: loss=0.07078503704132584
Epoch #24: loss=0.056345676808208664
Epoch #25: loss=0.0676397637431139
Epoch #26: loss=0.056791768995852684
Epoch #27: loss=0.05255523885416202
Epoch #28: loss=0.04851927971577266
Epoch #29: loss=0.053189104560290114
Epoch #30: loss=0.06047400085744516
Epoch #31: loss=0.04562675397139823
Epoch #32: loss=0.043258378084386345
Epoch #33: loss=0.03533661857200649
Epoch #34: loss=0.036514816823577545
Epoch #35: loss=0.035324455874870396
Epoch #36: loss=0.04076859025163768
Epoch #37: loss=0.03247030313740756
Epoch #38: loss=0.035335517607239186
Epoch #39: loss=0.036589595260494184
Epoch #40: loss=0.03446886887578816
Epoch #41: loss=0.04074132407790154
Epoch #42: loss=0.027322118782169107
Epoch #43: loss=0.03707713721688166
Epoch #44: loss=0.07845303124492675
Epoch #45: loss=0.034670753595432965
Epoch #46: loss=0.028389028250514516
Epoch #47: loss=0.0461820790634812
Epoch #48: loss=0.030616318745535845
Epoch #49: loss=0.027587621834041183
Epoch #50: loss=0.0331624611771932
Epoch #51: loss=0.03641391197524437
Epoch #52: loss=0.03852976009367819
Epoch #53: loss=0.0208282931433073
Epoch #54: loss=0.029663067737904687
Epoch #55: loss=0.02634822978647728
Epoch #56: loss=0.037283905757080134
Epoch #57: loss=0.028353474766378645
Epoch #58: loss=0.02287506718005831
Epoch #59: loss=0.023009341891448407
Epoch #60: loss=0.02014650839190672
Epoch #61: loss=0.028199559421028534
Epoch #62: loss=0.03203242258470956
Epoch #63: loss=0.020804257974149466
Epoch #64: loss=0.01847096290514917
Epoch #65: loss=0.018299601185355324
Epoch #66: loss=0.032171581251956086
Epoch #67: loss=0.02258223997549893
Epoch #68: loss=0.01871619323353698
Epoch #69: loss=0.018503349254822637
Epoch #70: loss=0.021230882098438125
Epoch #71: loss=0.01752611996408876
Epoch #72: loss=0.03226568682220899
Epoch #73: loss=0.018552219548577217
Epoch #74: loss=0.01752889557751198
Epoch #75: loss=0.020679857259393728
Epoch #76: loss=0.022828770591946084
Epoch #77: loss=0.018218091963433214
Epoch #78: loss=0.030652540640089564
Epoch #79: loss=0.01712679829047361
Epoch #80: loss=0.022174634603964807
Epoch #81: loss=0.018733966404676526
Epoch #82: loss=0.02369764466185513
Epoch #83: loss=0.018982603629861455
Epoch #84: loss=0.01427940934691111
Epoch #85: loss=0.017549782416715964
Epoch #86: loss=0.01557278517990134
Epoch #87: loss=0.018919547665198017
Epoch #88: loss=0.02336065911043677
Epoch #89: loss=0.02207625398750947
Epoch #90: loss=0.012687684811691542
Epoch #91: loss=0.0210196139417303
Epoch #92: loss=0.014800383214348416
Epoch #93: loss=0.020872064496961953
Epoch #94: loss=0.015870167367616365
Epoch #95: loss=0.01746016821448326
Epoch #96: loss=0.03011476935559175
Epoch #97: loss=0.018231299277230176
Epoch #98: loss=0.01879449005526831
Epoch #99: loss=0.022024367879980015
Epoch #100: loss=0.01722397304491681
Epoch #101: loss=0.01406483752838443
Epoch #102: loss=0.013278636289142337
Epoch #103: loss=0.016102298318784805
Epoch #104: loss=0.016460310167751128
Epoch #105: loss=0.016217401885986603
Epoch #106: loss=0.026237544691901666
Epoch #107: loss=0.01725912997056112
Epoch #108: loss=0.06147444292087009
Epoch #109: loss=0.014429647677404954
Epoch #110: loss=0.027820155023841688
Epoch #111: loss=0.015464376527706167
Epoch #112: loss=0.02785556513787272
Epoch #113: loss=0.012094109796831017
Epoch #114: loss=0.01845487252942006
Epoch #115: loss=0.014036904635514987
Epoch #116: loss=0.013419234213264039
Epoch #117: loss=0.015853299197684533
Epoch #118: loss=0.011968108886855608
Epoch #119: loss=0.018452043963766554
Epoch #120: loss=0.016061579979609993
Epoch #121: loss=0.01647258073844944
Epoch #122: loss=0.013195132162932933
Epoch #123: loss=0.014332257247781298
Epoch #124: loss=0.02681917520147229
Epoch #125: loss=0.017212337710047113
Epoch #126: loss=0.011977583008191952
Epoch #127: loss=0.016389345168994582
Epoch #128: loss=0.014184680079768624
Epoch #129: loss=0.017495544083522233
Epoch #130: loss=0.014889611771425018
Epoch #131: loss=0.015483287631401485
Epoch #132: loss=0.020068206910557693
Epoch #133: loss=0.021570188270134516
Epoch #134: loss=0.009594040750258034
Epoch #135: loss=0.01058146322980883
Epoch #136: loss=0.014853811868333195
Epoch #137: loss=0.014192731147851785
Epoch #138: loss=0.014065636598345739
Epoch #139: loss=0.015687824724342367
Epoch #140: loss=0.014920283043702135
Epoch #141: loss=0.010470446646811061
Epoch #142: loss=0.01172195374896986
Epoch #143: loss=0.027394634236411294
Epoch #144: loss=0.012065656264937568
Epoch #145: loss=0.014270910602420086
Epoch #146: loss=0.01481361748258498
Epoch #147: loss=0.010150873330184794
Epoch #148: loss=0.012583037125939849
Epoch #149: loss=0.01451304703222857
Epoch #150: loss=0.013359351646825451
Epoch #151: loss=0.012842196510667888
Epoch #152: loss=0.011092462240729295
Epoch #153: loss=0.01647473942055051
Epoch #154: loss=0.022682410954521105
Epoch #155: loss=0.01414923497941345
Epoch #156: loss=0.00850326928157623
Epoch #157: loss=0.010089265516149375
Epoch #158: loss=0.011182450158294884
Epoch #159: loss=0.01938125092136484
Epoch #160: loss=0.018091548921727194
Epoch #161: loss=0.012554833025549288
Epoch #162: loss=0.011946359166983998
Epoch #163: loss=0.017985328793962512
Epoch #164: loss=0.009143413878564523
Epoch #165: loss=0.008696848887518862
Epoch #166: loss=0.017367485598839577
Epoch #167: loss=0.011259037281172267
Epoch #168: loss=0.015686064319318342
Epoch #169: loss=0.014800357922518785
Epoch #170: loss=0.011070115975352212
Epoch #171: loss=0.011467046591839244
Epoch #172: loss=0.01013929685227474
Epoch #173: loss=0.012860736133157108
Epoch #174: loss=0.014361709375710538
Epoch #175: loss=0.00954960731013024
Epoch #176: loss=0.015673931134668258
Epoch #177: loss=0.012075988844962197
Epoch #178: loss=0.006232203376135352
Epoch #179: loss=0.014276955358115379
Epoch #180: loss=0.012728365459345463
Epoch #181: loss=0.010440819798929241
Epoch #182: loss=0.017033814605576836
Epoch #183: loss=0.01593926626344824
Epoch #184: loss=0.015465714690408732
Epoch #185: loss=0.015042571252202312
Epoch #186: loss=0.007474456714850144
Epoch #187: loss=0.009721890779742339
Epoch #188: loss=0.007341842958549103
Epoch #189: loss=0.017060045482402607
Epoch #190: loss=0.010303497313766308
Epoch #191: loss=0.015071871266686592
Epoch #192: loss=0.012707069304814304
Epoch #193: loss=0.009997988816238748
Epoch #194: loss=0.0076944628226636716
Epoch #195: loss=0.006530660239016022
Epoch #196: loss=0.01107168429792834
Epoch #197: loss=0.010907597715346896
Epoch #198: loss=0.01221680960955873
Epoch #199: loss=0.011509550488959163
Epoch #200: loss=0.017539781840826496
Epoch #201: loss=0.01665323710973597
Epoch #202: loss=0.008808125747789445
Epoch #203: loss=0.008472608882584609
Epoch #204: loss=0.011241233191805944
Epoch #205: loss=0.011960383279611023
Epoch #206: loss=0.009435529503741255
Epoch #207: loss=0.01531356668469268
Epoch #208: loss=0.009953447193910772
Epoch #209: loss=0.012628708383312948
Epoch #210: loss=0.021723067418501815
Epoch #211: loss=0.00824933520861308
Epoch #212: loss=0.012922796462391226
Epoch #213: loss=0.01046787439618853
Epoch #214: loss=0.01766967477634409
Epoch #215: loss=0.018895488467093578
Epoch #216: loss=0.02758923882929674
Epoch #217: loss=0.00987536463663971
Epoch #218: loss=0.009150220120186948
Epoch #219: loss=0.010822296074154076
Epoch #220: loss=0.010299976353648951
Epoch #221: loss=0.012798576582354358
Epoch #222: loss=0.01191001377277252
Epoch #223: loss=0.009955325994261466
Epoch #224: loss=0.011943882191313326
Epoch #225: loss=0.010991226350507696
Epoch #226: loss=0.013263625997684589
Epoch #227: loss=0.01098635066407087
Epoch #228: loss=0.011635669306450136
Epoch #229: loss=0.0091507429533307
Epoch #230: loss=0.007854949480039754
Epoch #231: loss=0.009238050724218317
Epoch #232: loss=0.01627812184019778
Epoch #233: loss=0.00864011324160172
Epoch #234: loss=0.008626058013631708
Epoch #235: loss=0.010266460915464237
Epoch #236: loss=0.010277457575789024
Epoch #237: loss=0.012608792295591538
Epoch #238: loss=0.010727339842292181
Epoch #239: loss=0.00828239288037522
Epoch #240: loss=0.0089143484000324
Epoch #241: loss=0.013639851984091289
Epoch #242: loss=0.010752575368545592
Epoch #243: loss=0.010368642358033461
Epoch #244: loss=0.011826604446581672
Epoch #245: loss=0.015832747931140242
Epoch #246: loss=0.01111337095897392
Epoch #247: loss=0.010642201617390335
Epoch #248: loss=0.012183248276264574
Epoch #249: loss=0.009668200080877768

Training time: 4:43:01.884541

Finished.
n2one setting etth2_ettm1_electricity -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_electricity_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_ettm1_electricity', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.3975e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.78344e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.78344e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.39003193464996444, 'MAE': 0.4462906132779311}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm1_electricity -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_electricity_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_ettm1_electricity', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.90355e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.26335604840547694, 'MAE': 0.34769555042342243}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm1_traffic', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm1_traffic_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.0171249771660025
Epoch #1: loss=0.36187883966009726
Epoch #2: loss=0.26994961350309576
Epoch #3: loss=0.19000766864893112
Epoch #4: loss=0.16422442601231688
Epoch #5: loss=0.13287093133284625
Epoch #6: loss=0.10595780173739926
Epoch #7: loss=0.1191390602955256
Epoch #8: loss=0.08218108781888574
Epoch #9: loss=0.07498485523233699
Epoch #10: loss=0.06965337385561063
Epoch #11: loss=0.06525472319071096
Epoch #12: loss=0.061269642514790494
Epoch #13: loss=0.06485335358778353
Epoch #14: loss=0.050764000062322755
Epoch #15: loss=0.043196139074544504
Epoch #16: loss=0.04713294294885021
Epoch #17: loss=0.0532944607476979
Epoch #18: loss=0.042497950575092217
Epoch #19: loss=0.047965095571337525
Epoch #20: loss=0.04397744286067212
Epoch #21: loss=0.03492113337918206
Epoch #22: loss=0.03016270016113677
Epoch #23: loss=0.034705105022559024
Epoch #24: loss=0.03466407713025216
Epoch #25: loss=0.028384914454892912
Epoch #26: loss=0.03935121713187651
Epoch #27: loss=0.030941183379565536
Epoch #28: loss=0.029223800448579078
Epoch #29: loss=0.030145840889930366
Epoch #30: loss=0.0309440088327392
Epoch #31: loss=0.026526532806085676
Epoch #32: loss=0.03719003180952065
Epoch #33: loss=0.025049534021143866
Epoch #34: loss=0.027846458372501232
Epoch #35: loss=0.026376285270610176
Epoch #36: loss=0.03218374355505644
Epoch #37: loss=0.024705979821605564
Epoch #38: loss=0.022833730854307014
Epoch #39: loss=0.023634161998432483
Epoch #40: loss=0.025163981750797988
Epoch #41: loss=0.025820157523743215
Epoch #42: loss=0.030160419050397732
Epoch #43: loss=0.02444725320833227
Epoch #44: loss=0.0207603961851088
Epoch #45: loss=0.020610008270622614
Epoch #46: loss=0.033327713806713954
Epoch #47: loss=0.023112564096134686
Epoch #48: loss=0.019169020811717598
Epoch #49: loss=0.018789136829053116
Epoch #50: loss=0.018041432373402957
Epoch #51: loss=0.02255845129488576
Epoch #52: loss=0.018469226700472064
Epoch #53: loss=0.020780713050507157
Epoch #54: loss=0.01980184276657052
Epoch #55: loss=0.020169575522942813
Epoch #56: loss=0.02614037736658991
Epoch #57: loss=0.014666614787182135
Epoch #58: loss=0.022794161477544216
Epoch #59: loss=0.01991282129899694
Epoch #60: loss=0.0177924482942961
Epoch #61: loss=0.01771959980191737
Epoch #62: loss=0.01910346944020024
Epoch #63: loss=0.01765893888018168
Epoch #64: loss=0.022505895871687574
Epoch #65: loss=0.01988491405202446
Epoch #66: loss=0.01810133693103456
Epoch #67: loss=0.019022100812336164
Epoch #68: loss=0.01552648805769753
Epoch #69: loss=0.01936111927041731
Epoch #70: loss=0.032976088752349655
Epoch #71: loss=0.017397359484708764
Epoch #72: loss=0.016613746891909448
Epoch #73: loss=0.014115301458125694
Epoch #74: loss=0.01715476595107413
Epoch #75: loss=0.0176550641990616
Epoch #76: loss=0.020023423660710582
Epoch #77: loss=0.014270739340711523
Epoch #78: loss=0.017640416794562373
Epoch #79: loss=0.016775132622404435
Epoch #80: loss=0.016339463043815075
Epoch #81: loss=0.014985175854764582
Epoch #82: loss=0.015686948661988772
Epoch #83: loss=0.012475748239508406
Epoch #84: loss=0.01849662104333137
Epoch #85: loss=0.018288403327295037
Epoch #86: loss=0.020778938745272833
Epoch #87: loss=0.02011384753654552
Epoch #88: loss=0.016228221458566786
Epoch #89: loss=0.015309060665251971
Epoch #90: loss=0.016017036563392716
Epoch #91: loss=0.01600424742117122
Epoch #92: loss=0.014916057482167327
Epoch #93: loss=0.013053121452346453
Epoch #94: loss=0.012920977271013809
Epoch #95: loss=0.0162082337464364
Epoch #96: loss=0.016171354929677115
Epoch #97: loss=0.014601261543694736
Epoch #98: loss=0.015173572762498887
Epoch #99: loss=0.023867774838766887
Epoch #100: loss=0.014247962049739726
Epoch #101: loss=0.01674927632669675
Epoch #102: loss=0.01604706046260121
Epoch #103: loss=0.01679407980470635
Epoch #104: loss=0.013726650489281218
Epoch #105: loss=0.01089779660572028
Epoch #106: loss=0.012624011809682336
Epoch #107: loss=0.031786648241673404
Epoch #108: loss=0.012039847272535553
Epoch #109: loss=0.01209950176608717
Epoch #110: loss=0.015690719545289705
Epoch #111: loss=0.014720724300092447
Epoch #112: loss=0.018291626756862654
Epoch #113: loss=0.014455902402021987
Epoch #114: loss=0.012854493683930327
Epoch #115: loss=0.0089949185423889
Epoch #116: loss=0.009570475363034348
Epoch #117: loss=0.013836664621538314
Epoch #118: loss=0.017149456076533006
Epoch #119: loss=0.015185943391803779
Epoch #120: loss=0.013341567555736136
Epoch #121: loss=0.012609234047968957
Epoch #122: loss=0.013098990553507148
Epoch #123: loss=0.015622277196036356
Epoch #124: loss=0.014945015269536684
Epoch #125: loss=0.013200170323530488
Epoch #126: loss=0.01509053701867577
Epoch #127: loss=0.011376696801099487
Epoch #128: loss=0.01637374382288809
Epoch #129: loss=0.011017669146200537
Epoch #130: loss=0.010880593881707186
Epoch #131: loss=0.014217182104766834
Epoch #132: loss=0.013734848019389161
Epoch #133: loss=0.012602694832127203
Epoch #134: loss=0.016583966131127618
Epoch #135: loss=0.013229133886786506
Epoch #136: loss=0.007556685725781294
Epoch #137: loss=0.008569610894466511
Epoch #138: loss=0.014480562705946134
Epoch #139: loss=0.030251558683829154
Epoch #140: loss=0.010632524831023395
Epoch #141: loss=0.010683250841181937
Epoch #142: loss=0.009646483268559016
Epoch #143: loss=0.009296014293861597
Epoch #144: loss=0.012345170211648854
Epoch #145: loss=0.013485348232808808
Epoch #146: loss=0.01803303714825068
Epoch #147: loss=0.0135674663415557
Epoch #148: loss=0.009549648835887969
Epoch #149: loss=0.011854200755161318
Epoch #150: loss=0.013651102553392941
Epoch #151: loss=0.013611909801065022
Epoch #152: loss=0.014565653305842054
Epoch #153: loss=0.010037657966677216
Epoch #154: loss=0.014784061782236015
Epoch #155: loss=0.01438149502712556
Epoch #156: loss=0.011898441401056267
Epoch #157: loss=0.012700179833055616
Epoch #158: loss=0.011980965216439059
Epoch #159: loss=0.010135170076467727
Epoch #160: loss=0.011125792407686028
Epoch #161: loss=0.013841000830904126
Epoch #162: loss=0.015719522071859417
Epoch #163: loss=0.01216261372030038
Epoch #164: loss=0.011693088287674154
Epoch #165: loss=0.018381321487322567
Epoch #166: loss=0.007834777486806905
Epoch #167: loss=0.010972206936424879
Epoch #168: loss=0.00995393638837744
Epoch #169: loss=0.01782677581898249
Epoch #170: loss=0.011995235943918074
Epoch #171: loss=0.00812146987553371
Epoch #172: loss=0.011721462622170458
Epoch #173: loss=0.01717512716892419
Epoch #174: loss=0.009359225508557178
Epoch #175: loss=0.011097521530522996
Epoch #176: loss=0.009780030433946443
Epoch #177: loss=0.013490955320230568
Epoch #178: loss=0.010756090252041097
Epoch #179: loss=0.016496558099375266
Epoch #180: loss=0.011047908129793624
Epoch #181: loss=0.006666506216788548
Epoch #182: loss=0.00888604923070075
Epoch #183: loss=0.015331145128104915
Epoch #184: loss=0.018334364896509213
Epoch #185: loss=0.011075121334447017
Epoch #186: loss=0.009825093390761389
Epoch #187: loss=0.009562555780609149
Epoch #188: loss=0.01122284246926442
Epoch #189: loss=0.007267616601728316
Epoch #190: loss=0.013988285023912216
Epoch #191: loss=0.013789525722793107
Epoch #192: loss=0.009221303909461395
Epoch #193: loss=0.011122930439358409
Epoch #194: loss=0.012000365045258315
Epoch #195: loss=0.012833342197038952
Epoch #196: loss=0.011372944661872515
Epoch #197: loss=0.009770453716919291
Epoch #198: loss=0.00894879696100938
Epoch #199: loss=0.011104845930508004
Epoch #200: loss=0.01097545037975413
Epoch #201: loss=0.010125933194864377
Epoch #202: loss=0.007866869654555393
Epoch #203: loss=0.013237674065360559
Epoch #204: loss=0.011701139306255342
Epoch #205: loss=0.008331419291310092
Epoch #206: loss=0.009597411735525052
Epoch #207: loss=0.0169175308760962
Epoch #208: loss=0.007633717897459229
Epoch #209: loss=0.014195630706258684
Epoch #210: loss=0.009419455579220746
Epoch #211: loss=0.006863712318574306
Epoch #212: loss=0.01075692207956639
Epoch #213: loss=0.012201512901579422
Epoch #214: loss=0.009435018219054634
Epoch #215: loss=0.01146893578025728
Epoch #216: loss=0.009753584856058628
Epoch #217: loss=0.012883838437483064
Epoch #218: loss=0.010121888253524957
Epoch #219: loss=0.008244197600734795
Epoch #220: loss=0.007517983350110378
Epoch #221: loss=0.015053392396508901
Epoch #222: loss=0.009870353994533202
Epoch #223: loss=0.007667316028445467
Epoch #224: loss=0.010668682591627161
Epoch #225: loss=0.010109938615112862
Epoch #226: loss=0.008433818924705024
Epoch #227: loss=0.008903944635387068
Epoch #228: loss=0.013085433157588837
Epoch #229: loss=0.008599712662511262
Epoch #230: loss=0.010273104348833974
Epoch #231: loss=0.008472767775856482
Epoch #232: loss=0.015886599698470408
Epoch #233: loss=0.02755671989586765
Epoch #234: loss=0.012248713945452685
Epoch #235: loss=0.009082888793250664
Epoch #236: loss=0.010767865544237958
Epoch #237: loss=0.011708978729753157
Epoch #238: loss=0.008765006596513558
Epoch #239: loss=0.00818646547350826
Epoch #240: loss=0.014209081174976745
Epoch #241: loss=0.008557860720148627
Epoch #242: loss=0.010158736322542113
Epoch #243: loss=0.013833724533254677
Epoch #244: loss=0.013059065770721644
Epoch #245: loss=0.008793315165108983
Epoch #246: loss=0.009113586007201361
Epoch #247: loss=0.006949137574908739
Epoch #248: loss=0.010631487336021647
Epoch #249: loss=0.009053172632725776

Training time: 10:30:16.141174

Finished.
n2one setting etth2_ettm1_traffic -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_traffic_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_ettm1_traffic', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.0246e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.05493e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.24063e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.0246e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4134817264961174, 'MAE': 0.45872337705837396}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm1_traffic -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_traffic_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_ettm1_traffic', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.25387e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.31924e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.89713e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.25387e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.846556210508279, 'MAE': 0.7389536237064926}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm1_traffic -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_traffic_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_ettm1_traffic', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
Evaluation result: {'MSE': 0.25207962398358535, 'MAE': 0.3409198075785733}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm1_weather', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm1_weather_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=6.492038298736919
Epoch #1: loss=2.7725818644870412
Epoch #2: loss=2.579050221226432
Epoch #3: loss=2.3155810128558767
Epoch #4: loss=2.0686157291585747
Epoch #5: loss=1.988852389834144
Epoch #6: loss=1.8281771567734806
Epoch #7: loss=1.7162071601911024
Epoch #8: loss=1.5949402993375605
Epoch #9: loss=1.5091903643174605
Epoch #10: loss=1.3763453499837355
Epoch #11: loss=1.2737139544703744
Epoch #12: loss=1.2628211731260472
Epoch #13: loss=1.1430385180495002
Epoch #14: loss=1.0855206156318837
Epoch #15: loss=1.0585159821943804
Epoch #16: loss=1.0869111500003121
Epoch #17: loss=1.0180157179182225
Epoch #18: loss=1.0246952027082443
Epoch #19: loss=0.977674818851731
Epoch #20: loss=0.9732199270616878
Epoch #21: loss=0.8701759183948691
Epoch #22: loss=0.8422375050458041
Epoch #23: loss=0.8348702923818068
Epoch #24: loss=0.7895634783939882
Epoch #25: loss=0.7107770348137076
Epoch #26: loss=0.7100241563536904
Epoch #27: loss=0.7596222189339724
Epoch #28: loss=0.7318641692399979
Epoch #29: loss=0.8177518289197575
Epoch #30: loss=0.7903086299246008
Epoch #31: loss=0.7000625268979506
Epoch #32: loss=0.639492926272479
Epoch #33: loss=0.6897644170305945
Epoch #34: loss=0.5982533293691549
Epoch #35: loss=0.6089608107100833
Epoch #36: loss=0.563964762470939
Epoch #37: loss=0.5713124322620305
Epoch #38: loss=0.5724080909382213
Epoch #39: loss=0.5570831082083962
Epoch #40: loss=0.5065884414044294
Epoch #41: loss=0.5042293004014275
Epoch #42: loss=0.5011001046408307
Epoch #43: loss=0.5590594634413719
Epoch #44: loss=0.5344793620434675
Epoch #45: loss=0.5174746879122474
Epoch #46: loss=0.7176488780162551
Epoch #47: loss=0.528871133246205
Epoch #48: loss=0.4306378493254835
Epoch #49: loss=0.45300156284462323
Epoch #50: loss=0.45366384901783685
Epoch #51: loss=0.4140169901604002
Epoch #52: loss=0.5037732076915827
Epoch #53: loss=0.5027959556742148
Epoch #54: loss=0.4825456558980725
Epoch #55: loss=0.4364109845323996
Epoch #56: loss=0.34923048181967303
Epoch #57: loss=0.42425019802017644
Epoch #58: loss=0.4006102088500153
Epoch #59: loss=0.37550472569736565
Epoch #60: loss=0.4000422070649537
Epoch #61: loss=0.35925043001770973
Epoch #62: loss=0.3521152345294302
Epoch #63: loss=0.3207679499279369
Epoch #64: loss=0.3187217228114605
Epoch #65: loss=0.3949935988269069
Epoch #66: loss=0.36531669985164295
Epoch #67: loss=0.31530041654001584
Epoch #68: loss=0.32491109655662015
Epoch #69: loss=0.2989804101261226
Epoch #70: loss=0.27513682114129717
Epoch #71: loss=0.27462763068350876
Epoch #72: loss=0.2737156306816773
Epoch #73: loss=0.27129879932511936
Epoch #74: loss=0.2466188482940197
Epoch #75: loss=0.2580087970603596
Epoch #76: loss=0.35307899388399994
Epoch #77: loss=0.32657396827231755
Epoch #78: loss=0.30172700790519064
Epoch #79: loss=0.3267357965761965
Epoch #80: loss=0.23745176060633225
Epoch #81: loss=0.38055237535048614
Epoch #82: loss=0.43618220395662566
Epoch #83: loss=0.3305571936070919
Epoch #84: loss=0.3780605528842319
Epoch #85: loss=0.3277026799253442
Epoch #86: loss=0.2426471220837398
Epoch #87: loss=0.2093668578361923
Epoch #88: loss=0.1933420728892088
Epoch #89: loss=0.19192865914241833
Epoch #90: loss=0.24056794138794596
Epoch #91: loss=0.21251150779426098
Epoch #92: loss=0.18092887696217408
Epoch #93: loss=0.3204871849580245
Epoch #94: loss=0.22332889366556297
Epoch #95: loss=0.18232540583068674
Epoch #96: loss=0.21651395977559415
Epoch #97: loss=0.19903155932710928
Epoch #98: loss=0.21623681807382542
Epoch #99: loss=0.29419616711410607
Epoch #100: loss=0.23337013071233575
Epoch #101: loss=0.20309870342978023
Epoch #102: loss=0.19517277511344713
Epoch #103: loss=0.24512890861793
Epoch #104: loss=0.18741094854406334
Epoch #105: loss=0.19191451379182664
Epoch #106: loss=0.199518084526062
Epoch #107: loss=0.1585455977950584
Epoch #108: loss=0.30462397457185114
Epoch #109: loss=0.16436572237448258
Epoch #110: loss=0.18991870814087716
Epoch #111: loss=0.1460618024522608
Epoch #112: loss=0.12518189716237513
Epoch #113: loss=0.15402564795857127
Epoch #114: loss=0.16582212749529968
Epoch #115: loss=0.15798546771772884
Epoch #116: loss=0.13173638500103896
Epoch #117: loss=0.16152996159243313
Epoch #118: loss=0.15671533608639782
Epoch #119: loss=0.15197935107756744
Epoch #120: loss=0.14742119479077784
Epoch #121: loss=0.17263842560350895
Epoch #122: loss=0.1286787058819424
Epoch #123: loss=0.14589315483515913
Epoch #124: loss=0.17706198427318173
Epoch #125: loss=0.19507087978788398
Epoch #126: loss=0.1708696653897112
Epoch #127: loss=0.16059067646380176
Epoch #128: loss=0.19656447896903212
Epoch #129: loss=0.17679751020940868
Epoch #130: loss=0.1807514148848978
Epoch #131: loss=0.12897003230384804
Epoch #132: loss=0.11330504677343098
Epoch #133: loss=0.11125475587323308
Epoch #134: loss=0.12197880633175373
Epoch #135: loss=0.17210736980831082
Epoch #136: loss=0.14238561304624786
Epoch #137: loss=0.11529933872886679
Epoch #138: loss=0.1411522144282406
Epoch #139: loss=0.1268496340225366
Epoch #140: loss=0.17890948154540223
Epoch #141: loss=0.13345503828234292
Epoch #142: loss=0.14970692856745285
Epoch #143: loss=0.15760981202633542
Epoch #144: loss=0.1100433542901142
Epoch #145: loss=0.12251219953494993
Epoch #146: loss=0.12543542801656507
Epoch #147: loss=0.10917102638632059
Epoch #148: loss=0.12454738620329987
Epoch #149: loss=0.29384608439762483
Epoch #150: loss=0.12974377924745734
Epoch #151: loss=0.1902339059690183
Epoch #152: loss=0.37406272610480135
Epoch #153: loss=0.14273043561049484
Epoch #154: loss=0.29287652544338594
Epoch #155: loss=0.1400757395154373
Epoch #156: loss=0.15458727039566095
Epoch #157: loss=0.10593353973870928
Epoch #158: loss=0.14307659220966426
Epoch #159: loss=0.09739652441137216
Epoch #160: loss=0.13285508696836504
Epoch #161: loss=0.1008726933293722
Epoch #162: loss=0.12462848255580122
Epoch #163: loss=0.13648075148971242
Epoch #164: loss=0.12767100994559852
Epoch #165: loss=0.0869760334661061
Epoch #166: loss=0.07474863696420057
Epoch #167: loss=0.08529047934677113
Epoch #168: loss=0.22260537057776342
Epoch #169: loss=0.13035386910831387
Epoch #170: loss=0.11077712302688848
Epoch #171: loss=0.09110512245785106
Epoch #172: loss=0.12154360636222092
Epoch #173: loss=0.08676956767554987
Epoch #174: loss=0.09137866620651701
Epoch #175: loss=0.09633872171186587
Epoch #176: loss=0.1245559575882825
Epoch #177: loss=0.08597695205191319
Epoch #178: loss=0.06831689475273545
Epoch #179: loss=0.1074248396960849
Epoch #180: loss=0.08946732804179192
Epoch #181: loss=0.09547617396509106
Epoch #182: loss=0.08979443888264624
Epoch #183: loss=0.08660128071311522
Epoch #184: loss=0.06669901751659134
Epoch #185: loss=0.19487687704068693
Epoch #186: loss=0.09219300315122712
Epoch #187: loss=0.07564692089164798
Epoch #188: loss=0.0759920165027407
Epoch #189: loss=0.09195119572210718
Epoch #190: loss=0.08111104733225974
Epoch #191: loss=0.07663210599937222
Epoch #192: loss=0.15018948980353095
Epoch #193: loss=0.10942217301238667
Epoch #194: loss=0.0994125979698517
Epoch #195: loss=0.08239420797591182
Epoch #196: loss=0.09438918748955158
Epoch #197: loss=0.09233350277116353
Epoch #198: loss=0.07472353701649065
Epoch #199: loss=0.08059855946339667
Epoch #200: loss=0.09519589721987193
Epoch #201: loss=0.07552860819057307
Epoch #202: loss=0.07442291140217673
Epoch #203: loss=0.06431411058557304
Epoch #204: loss=0.06139778957532888
Epoch #205: loss=0.08217637477950616
Epoch #206: loss=0.05434533820318228
Epoch #207: loss=0.08353736232542856
Epoch #208: loss=0.09175065881572664
Epoch #209: loss=0.06993413204327226
Epoch #210: loss=0.06387973640283401
Epoch #211: loss=0.09421976560472765
Epoch #212: loss=0.0651979298457842
Epoch #213: loss=0.06518352042290974
Epoch #214: loss=0.06459806753661144
Epoch #215: loss=0.06249499564397742
Epoch #216: loss=0.05491106658750637
Epoch #217: loss=0.052668810949068175
Epoch #218: loss=0.0825366872489791
Epoch #219: loss=0.11254696541635151
Epoch #220: loss=0.08400974439626391
Epoch #221: loss=0.09498980899595401
Epoch #222: loss=0.054335795173590835
Epoch #223: loss=0.06779984596439383
Epoch #224: loss=0.08604826500893316
Epoch #225: loss=0.12161199799315496
Epoch #226: loss=0.08898808921433309
Epoch #227: loss=0.08442546287551522
Epoch #228: loss=0.08474718093533408
Epoch #229: loss=0.0627527924423868
Epoch #230: loss=0.06253971413455227
Epoch #231: loss=0.05332830804400146
Epoch #232: loss=0.060641631060703236
Epoch #233: loss=0.10583910083567555
Epoch #234: loss=0.08552314364351332
Epoch #235: loss=0.09161714074963873
Epoch #236: loss=0.11196662769229575
Epoch #237: loss=0.08034681071611968
Epoch #238: loss=0.05642871181903915
Epoch #239: loss=0.061011272546073254
Epoch #240: loss=0.05831443381876769
Epoch #241: loss=0.07639078139750795
Epoch #242: loss=0.12949347381734036
Epoch #243: loss=0.0841131686783311
Epoch #244: loss=0.06639428131959656
Epoch #245: loss=0.0958444745999507
Epoch #246: loss=0.057768318950283254
Epoch #247: loss=0.08377005305903201
Epoch #248: loss=0.16878045075149697
Epoch #249: loss=0.08137779064815152

Training time: 0:44:54.140273

Finished.
n2one setting etth2_ettm1_weather -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_weather_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_ettm1_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.42763e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.76457e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.42763e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.38549984772043483, 'MAE': 0.4342170128000975}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm1_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_weather_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_ettm1_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.79768e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.19516571408658556, 'MAE': 0.30371342723954814}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm1_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm1_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=4.377023320931655
Epoch #1: loss=2.378115924505087
Epoch #2: loss=2.11120396393996
Epoch #3: loss=2.009637575883132
Epoch #4: loss=1.9027830545718853
Epoch #5: loss=1.803318019096668
Epoch #6: loss=1.6448177420175993
Epoch #7: loss=1.5620791361882136
Epoch #8: loss=1.5164529360257661
Epoch #9: loss=1.4407036900520325
Epoch #10: loss=1.3014786289288447
Epoch #11: loss=1.2778284343389363
Epoch #12: loss=1.227217293702639
Epoch #13: loss=1.2134065971924708
Epoch #14: loss=1.1336227976358855
Epoch #15: loss=1.1679045810149267
Epoch #16: loss=1.0362083728496845
Epoch #17: loss=1.1188950286461756
Epoch #18: loss=1.0025634949023907
Epoch #19: loss=1.008055139046449
Epoch #20: loss=0.9360416829586029
Epoch #21: loss=0.9593373307814965
Epoch #22: loss=0.9670179784297943
Epoch #23: loss=0.9080314544531015
Epoch #24: loss=1.0011109572190504
Epoch #25: loss=1.1492591293958516
Epoch #26: loss=0.9483697689496554
Epoch #27: loss=0.9007227191558251
Epoch #28: loss=0.8712714108136984
Epoch #29: loss=0.8526232907405267
Epoch #30: loss=0.9729714278991406
Epoch #31: loss=0.8609628906616797
Epoch #32: loss=0.944405204974688
Epoch #33: loss=0.9068909814724555
Epoch #34: loss=0.8220517199773055
Epoch #35: loss=0.7496299285155076
Epoch #36: loss=0.7344107673718379
Epoch #37: loss=0.8674164368556097
Epoch #38: loss=0.791691032739786
Epoch #39: loss=0.77389573936279
Epoch #40: loss=0.7767913811481916
Epoch #41: loss=0.7498132918889706
Epoch #42: loss=0.710025062927833
Epoch #43: loss=0.6326438016616381
Epoch #44: loss=0.6715577474007239
Epoch #45: loss=0.6326653407170222
Epoch #46: loss=0.8540446013212204
Epoch #47: loss=0.7664163823311145
Epoch #48: loss=0.6797293023421214
Epoch #49: loss=0.5525037497282028
Epoch #50: loss=0.6046981811523438
Epoch #51: loss=0.5448353840754583
Epoch #52: loss=0.5587271463412505
Epoch #53: loss=0.6445155178125088
Epoch #54: loss=0.6635206513679944
Epoch #55: loss=0.6640058973660836
Epoch #56: loss=0.4842218659245051
Epoch #57: loss=0.47536488622426987
Epoch #58: loss=0.6900991487961549
Epoch #59: loss=0.6089128301693842
Epoch #60: loss=0.5483667873419248
Epoch #61: loss=0.538892632493606
Epoch #62: loss=0.5045162863456286
Epoch #63: loss=0.5246780136456857
Epoch #64: loss=0.4743267956834573
Epoch #65: loss=0.48243603626122844
Epoch #66: loss=0.5084130981793771
Epoch #67: loss=0.5119698534791286
Epoch #68: loss=0.5046538022848276
Epoch #69: loss=0.506027225118417
Epoch #70: loss=0.4864475635381845
Epoch #71: loss=0.4097191955034549
Epoch #72: loss=0.47977099739588225
Epoch #73: loss=0.47379380292617357
Epoch #74: loss=0.49749800906731534
Epoch #75: loss=0.4095255405857013
Epoch #76: loss=0.44783838723714536
Epoch #77: loss=0.4121631710575177
Epoch #78: loss=0.5046059288657628
Epoch #79: loss=0.4075551904164828
Epoch #80: loss=0.4644955900999216
Epoch #81: loss=0.39198942539783627
Epoch #82: loss=0.46478311201700795
Epoch #83: loss=0.4213165365732633
Epoch #84: loss=0.5297486392351297
Epoch #85: loss=0.3445886339132602
Epoch #86: loss=0.43135622487618375
Epoch #87: loss=0.43956322939350057
Epoch #88: loss=0.356433865829156
Epoch #89: loss=0.4104084762243124
Epoch #90: loss=0.395421822483723
Epoch #91: loss=0.3468814277305053
Epoch #92: loss=0.3581369696901395
Epoch #93: loss=0.3817522677664573
Epoch #94: loss=0.4554060600124873
Epoch #95: loss=0.41505336646850294
Epoch #96: loss=0.39687279611825943
Epoch #97: loss=0.43765643353645617
Epoch #98: loss=0.3581780241085933
Epoch #99: loss=0.42982592949500453
Epoch #100: loss=0.38502597407652783
Epoch #101: loss=0.3994193028372068
Epoch #102: loss=0.3884485535896741
Epoch #103: loss=0.3337240666151047
Epoch #104: loss=0.33506325575021595
Epoch #105: loss=0.3696633723492806
Epoch #106: loss=0.4177196031579605
Epoch #107: loss=0.37426883498063457
Epoch #108: loss=0.3293949216604233
Epoch #109: loss=0.28069546532172424
Epoch #110: loss=0.3938528605951713
Epoch #111: loss=0.3275785050713099
Epoch #112: loss=0.2909848764538765
Epoch #113: loss=0.3276389671059755
Epoch #114: loss=0.3285005665742434
Epoch #115: loss=0.33142625798399633
Epoch #116: loss=0.35363597995959795
Epoch #117: loss=0.2784493278998595
Epoch #118: loss=0.2807012263398904
Epoch #119: loss=0.2897517340114483
Epoch #120: loss=0.300901802113423
Epoch #121: loss=0.3733195330087955
Epoch #122: loss=0.2968972995877266
Epoch #123: loss=0.3068454320041033
Epoch #124: loss=0.29515447610845935
Epoch #125: loss=0.2718103530888374
Epoch #126: loss=0.25766902846785694
Epoch #127: loss=0.25002301971499735
Epoch #128: loss=0.40332267261468446
Epoch #129: loss=0.4298523303407889
Epoch #130: loss=0.41994474025873035
Epoch #131: loss=0.3193492041184352
Epoch #132: loss=0.2721363572547069
Epoch #133: loss=0.22433389608676618
Epoch #134: loss=0.19243076558296496
Epoch #135: loss=0.22340244728212172
Epoch #136: loss=0.18229141960350367
Epoch #137: loss=0.16794287642607322
Epoch #138: loss=0.32738073284809405
Epoch #139: loss=0.2679187047940034
Epoch #140: loss=0.2809262057909599
Epoch #141: loss=0.25820866456398595
Epoch #142: loss=0.28295566600102645
Epoch #143: loss=0.3167141005396843
Epoch #144: loss=0.23752988846256182
Epoch #145: loss=0.4913426147630581
Epoch #146: loss=0.419074742266765
Epoch #147: loss=0.4083203959923524
Epoch #148: loss=0.30123193848591584
Epoch #149: loss=0.2395673285310085
Epoch #150: loss=0.27317551695383513
Epoch #151: loss=0.3451590466384704
Epoch #152: loss=0.2512647764613995
Epoch #153: loss=0.26022996037052226
Epoch #154: loss=0.2585523839180286
Epoch #155: loss=0.22318937686773446
Epoch #156: loss=0.2089786222920968
Epoch #157: loss=0.2076352185641344
Epoch #158: loss=0.19566533342003822
Epoch #159: loss=0.1685636087965507
Epoch #160: loss=0.17760464491752478
Epoch #161: loss=0.15635987027333334
Epoch #162: loss=0.19460814360242623
Epoch #163: loss=0.14380924503963727
Epoch #164: loss=0.17937732602541262
Epoch #165: loss=0.21996093942568853
Epoch #166: loss=0.19349332841543052
Epoch #167: loss=0.18543026051842249
Epoch #168: loss=0.1939752119091841
Epoch #169: loss=0.1788470779473965
Epoch #170: loss=0.184980454783027
Epoch #171: loss=0.2339891570691879
Epoch #172: loss=0.2301534954458475
Epoch #173: loss=0.21994944088734114
Epoch #174: loss=0.1818153578788042
Epoch #175: loss=0.17378395695525867
Epoch #176: loss=0.14309105491982058
Epoch #177: loss=0.16160388448490545
Epoch #178: loss=0.18136981072334143
Epoch #179: loss=0.24062798143579409
Epoch #180: loss=0.26163166818710476
Epoch #181: loss=0.2195303700864315
Epoch #182: loss=0.19337125036578912
Epoch #183: loss=0.196722838597802
Epoch #184: loss=0.2234359162931259
Epoch #185: loss=0.18759189632076484
Epoch #186: loss=0.16063611438641182
Epoch #187: loss=0.187224409614618
Epoch #188: loss=0.13646653165610936
Epoch #189: loss=0.1647310287046891
Epoch #190: loss=0.15448803755526358
Epoch #191: loss=0.22276842450866333
Epoch #192: loss=0.17083758044128233
Epoch #193: loss=0.2141752139880107
Epoch #194: loss=0.19954495991651827
Epoch #195: loss=0.16661001971134773
Epoch #196: loss=0.13825134761058366
Epoch #197: loss=0.16403668388151205
Epoch #198: loss=0.15687703097668979
Epoch #199: loss=0.13824723574977654
Epoch #200: loss=0.1406753587608154
Epoch #201: loss=0.16357420929349387
Epoch #202: loss=0.17342862128638303
Epoch #203: loss=0.17370077380194113
Epoch #204: loss=0.12392265679171452
Epoch #205: loss=0.1368661313675917
Epoch #206: loss=0.18748838540453178
Epoch #207: loss=0.1741355462716176
Epoch #208: loss=0.14351006368031868
Epoch #209: loss=0.12413241599614804
Epoch #210: loss=0.13908708640016043
Epoch #211: loss=0.12457245588302612
Epoch #212: loss=0.15048759359006697
Epoch #213: loss=0.16877270833804056
Epoch #214: loss=0.13652957144838113
Epoch #215: loss=0.14683824204481566
Epoch #216: loss=0.14518445887817785
Epoch #217: loss=0.16608409554912493
Epoch #218: loss=0.15392951180155462
Epoch #219: loss=0.21358804103846735
Epoch #220: loss=0.15123370877252176
Epoch #221: loss=0.13526426857480636
Epoch #222: loss=0.16460931687974012
Epoch #223: loss=0.14598383897772202
Epoch #224: loss=0.23285729036881372
Epoch #225: loss=0.2535447280567426
Epoch #226: loss=0.2648686288067928
Epoch #227: loss=0.211458829876322
Epoch #228: loss=0.17797945224894926
Epoch #229: loss=0.18839132671172804
Epoch #230: loss=0.1415979849317899
Epoch #231: loss=0.2525518278662975
Epoch #232: loss=0.1706621185518228
Epoch #233: loss=0.20435699319037107
Epoch #234: loss=0.1386563484198772
Epoch #235: loss=0.11862552509858058
Epoch #236: loss=0.10859570752542752
Epoch #237: loss=0.09900940266939309
Epoch #238: loss=0.14587011431845334
Epoch #239: loss=0.13034436163993982
Epoch #240: loss=0.1265919946420651
Epoch #241: loss=0.22037823541233173
Epoch #242: loss=0.19869761211940876
Epoch #243: loss=0.16723413851398689
Epoch #244: loss=0.1510273374330539
Epoch #245: loss=0.12595951442535108
Epoch #246: loss=0.10809292730230552
Epoch #247: loss=0.08977454313291953
Epoch #248: loss=0.1086914952701101
Epoch #249: loss=0.10409305230356179

Training time: 0:21:42.754995

Finished.
n2one setting etth2_ettm1_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_ettm1_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.48896e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.89468e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.48896e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.36449559997523406, 'MAE': 0.4296741457739871}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm1_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_ettm1_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.33419e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.71676e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.7529167114390873, 'MAE': 0.6630236006088303}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm2_electricity', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm2_electricity_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.721382387971456
Epoch #1: loss=0.7266277517013493
Epoch #2: loss=0.5030108658173794
Epoch #3: loss=0.3778678512854562
Epoch #4: loss=0.33364221989932663
Epoch #5: loss=0.2855127464793073
Epoch #6: loss=0.25224098624732993
Epoch #7: loss=0.24261003038172876
Epoch #8: loss=0.18198655119336107
Epoch #9: loss=0.17503265748597177
Epoch #10: loss=0.15155019078150964
Epoch #11: loss=0.14437761308301164
Epoch #12: loss=0.15410499128576224
Epoch #13: loss=0.11871524496899594
Epoch #14: loss=0.11154479411455383
Epoch #15: loss=0.112427179209866
Epoch #16: loss=0.10256700563329686
Epoch #17: loss=0.10448780695970959
Epoch #18: loss=0.08294387917229384
Epoch #19: loss=0.08661622857361768
Epoch #20: loss=0.07963245476879026
Epoch #21: loss=0.066439525188554
Epoch #22: loss=0.07389071302428006
Epoch #23: loss=0.06716899106218575
Epoch #24: loss=0.06058855524566849
Epoch #25: loss=0.06654141155129249
Epoch #26: loss=0.05377803892199401
Epoch #27: loss=0.04622825833757279
Epoch #28: loss=0.05650077313926499
Epoch #29: loss=0.046757340799346785
Epoch #30: loss=0.054586656564698285
Epoch #31: loss=0.040578962620320264
Epoch #32: loss=0.042826241352059674
Epoch #33: loss=0.03668741648467285
Epoch #34: loss=0.04019432717791393
Epoch #35: loss=0.0402345106893035
Epoch #36: loss=0.0422465324568065
Epoch #37: loss=0.03703300139570065
Epoch #38: loss=0.03634275445662395
Epoch #39: loss=0.03386656138469028
Epoch #40: loss=0.04300657066222621
Epoch #41: loss=0.03482797032271603
Epoch #42: loss=0.026082743042365682
Epoch #43: loss=0.023862290708485518
Epoch #44: loss=0.08224883638761915
Epoch #45: loss=0.03140171336155703
Epoch #46: loss=0.03211821636952911
Epoch #47: loss=0.04362496534626173
Epoch #48: loss=0.030183247176883605
Epoch #49: loss=0.026724914621127697
Epoch #50: loss=0.030177030157762137
Epoch #51: loss=0.03796582200199058
Epoch #52: loss=0.03951698761765782
Epoch #53: loss=0.023123730923554648
Epoch #54: loss=0.027863833606160716
Epoch #55: loss=0.02377909087956468
Epoch #56: loss=0.030217697708949907
Epoch #57: loss=0.026305030344897513
Epoch #58: loss=0.0246772829575085
Epoch #59: loss=0.020904629687012163
Epoch #60: loss=0.01762999377692816
Epoch #61: loss=0.03694460459484837
Epoch #62: loss=0.04666974138575647
Epoch #63: loss=0.02430202599798925
Epoch #64: loss=0.018549350425491114
Epoch #65: loss=0.01889537580453469
Epoch #66: loss=0.0232987473931735
Epoch #67: loss=0.03349724519107722
Epoch #68: loss=0.018571766130117958
Epoch #69: loss=0.02025653281339079
Epoch #70: loss=0.021617661251385686
Epoch #71: loss=0.018895819837469224
Epoch #72: loss=0.030962726579646643
Epoch #73: loss=0.017301202239503034
Epoch #74: loss=0.017137938409159097
Epoch #75: loss=0.02149880976982107
Epoch #76: loss=0.019644251403880958
Epoch #77: loss=0.02099831192582505
Epoch #78: loss=0.025574562171746078
Epoch #79: loss=0.01734345517712604
Epoch #80: loss=0.01753355041170317
Epoch #81: loss=0.021575050514190015
Epoch #82: loss=0.02233830029433346
Epoch #83: loss=0.01592975227158121
Epoch #84: loss=0.013891743742970744
Epoch #85: loss=0.01906764028926317
Epoch #86: loss=0.01338783756449989
Epoch #87: loss=0.02110546366291005
Epoch #88: loss=0.016366522720909146
Epoch #89: loss=0.022639269935403977
Epoch #90: loss=0.013438618582931614
Epoch #91: loss=0.01733279546721396
Epoch #92: loss=0.014766224706339428
Epoch #93: loss=0.023552532143311183
Epoch #94: loss=0.019640608727767142
Epoch #95: loss=0.016496803917321803
Epoch #96: loss=0.025235403036550346
Epoch #97: loss=0.018204536404705176
Epoch #98: loss=0.02158983684231453
Epoch #99: loss=0.017792777593074516
Epoch #100: loss=0.01260034012100673
Epoch #101: loss=0.013079334301791624
Epoch #102: loss=0.011067299992512296
Epoch #103: loss=0.018597817984732434
Epoch #104: loss=0.018806063988696574
Epoch #105: loss=0.016566375056027562
Epoch #106: loss=0.02816457163568608
Epoch #107: loss=0.015231073428093728
Epoch #108: loss=0.06081441065961369
Epoch #109: loss=0.01672391156967493
Epoch #110: loss=0.02977961835081917
Epoch #111: loss=0.01888605629321968
Epoch #112: loss=0.02469745458355778
Epoch #113: loss=0.013860772285029391
Epoch #114: loss=0.01459667156347428
Epoch #115: loss=0.01625034015761018
Epoch #116: loss=0.017282622259702247
Epoch #117: loss=0.01414927219746052
Epoch #118: loss=0.010487015547462984
Epoch #119: loss=0.017075432085357937
Epoch #120: loss=0.015587841899437791
Epoch #121: loss=0.015575698835797234
Epoch #122: loss=0.014191902099228066
Epoch #123: loss=0.02293928098249466
Epoch #124: loss=0.030483099339038113
Epoch #125: loss=0.011777362633931964
Epoch #126: loss=0.009848890265149056
Epoch #127: loss=0.01366852985912725
Epoch #128: loss=0.014326264704014435
Epoch #129: loss=0.01251581839868211
Epoch #130: loss=0.017899096048860138
Epoch #131: loss=0.016428526922590635
Epoch #132: loss=0.013898275804961413
Epoch #133: loss=0.019527434409358387
Epoch #134: loss=0.008747309566012537
Epoch #135: loss=0.013546488641013987
Epoch #136: loss=0.012639890135929352
Epoch #137: loss=0.01104547291071014
Epoch #138: loss=0.014252866020290165
Epoch #139: loss=0.017080664478797344
Epoch #140: loss=0.013526036004861405
Epoch #141: loss=0.01074773103725385
Epoch #142: loss=0.009698361273069254
Epoch #143: loss=0.01955384847324803
Epoch #144: loss=0.012807154851473846
Epoch #145: loss=0.015867233594792283
Epoch #146: loss=0.016731553314704238
Epoch #147: loss=0.011878705879015392
Epoch #148: loss=0.013132790108791698
Epoch #149: loss=0.012274089090081047
Epoch #150: loss=0.009622317063519154
Epoch #151: loss=0.014213399122473248
Epoch #152: loss=0.01529752873629469
Epoch #153: loss=0.019313923277958108
Epoch #154: loss=0.017640356685977243
Epoch #155: loss=0.014146779702150792
Epoch #156: loss=0.013124540535242717
Epoch #157: loss=0.008556085805512367
Epoch #158: loss=0.011020099787641822
Epoch #159: loss=0.019277600598470706
Epoch #160: loss=0.015744007388638074
Epoch #161: loss=0.013207371726204231
Epoch #162: loss=0.013221895833194783
Epoch #163: loss=0.0172761255361148
Epoch #164: loss=0.010458413509110807
Epoch #165: loss=0.012115164830076033
Epoch #166: loss=0.0140838236845913
Epoch #167: loss=0.012052324458003418
Epoch #168: loss=0.010817322526834521
Epoch #169: loss=0.013180896930862218
Epoch #170: loss=0.010052906450520855
Epoch #171: loss=0.009351423108444761
Epoch #172: loss=0.01107650553700473
Epoch #173: loss=0.010731538130532934
Epoch #174: loss=0.013594085761520375
Epoch #175: loss=0.009836489182229327
Epoch #176: loss=0.014105207071801686
Epoch #177: loss=0.017085850601267223
Epoch #178: loss=0.0068148212189027895
Epoch #179: loss=0.011063230989238516
Epoch #180: loss=0.01135391702722335
Epoch #181: loss=0.009029603456449214
Epoch #182: loss=0.015006917290740501
Epoch #183: loss=0.012793997610173295
Epoch #184: loss=0.012860417626502823
Epoch #185: loss=0.016088895942616775
Epoch #186: loss=0.010818462451843676
Epoch #187: loss=0.00952225122135476
Epoch #188: loss=0.008271834060737237
Epoch #189: loss=0.01709168711004114
Epoch #190: loss=0.013533791353044191
Epoch #191: loss=0.012083149986076484
Epoch #192: loss=0.012200939933670503
Epoch #193: loss=0.009207917862244851
Epoch #194: loss=0.008523389184710111
Epoch #195: loss=0.010834832276457339
Epoch #196: loss=0.009921373356275184
Epoch #197: loss=0.009735299886793591
Epoch #198: loss=0.011609365129438132
Epoch #199: loss=0.015402380770342259
Epoch #200: loss=0.01391315020342319
Epoch #201: loss=0.016421398088960308
Epoch #202: loss=0.010486248771163461
Epoch #203: loss=0.010130546034700415
Epoch #204: loss=0.012995204857377483
Epoch #205: loss=0.010193112993370439
Epoch #206: loss=0.009713929963410093
Epoch #207: loss=0.013242555269748275
Epoch #208: loss=0.011496394797373195
Epoch #209: loss=0.01480875139038496
Epoch #210: loss=0.010367118500401114
Epoch #211: loss=0.010062883238965415
Epoch #212: loss=0.015754836064229023
Epoch #213: loss=0.01383480583839558
Epoch #214: loss=0.01930617687005995
Epoch #215: loss=0.02102012670846865
Epoch #216: loss=0.024783228204659787
Epoch #217: loss=0.008783344996359563
Epoch #218: loss=0.009467114799241824
Epoch #219: loss=0.009865033211925542
Epoch #220: loss=0.012505654063351194
Epoch #221: loss=0.011990969548442134
Epoch #222: loss=0.012488673141831944
Epoch #223: loss=0.01117947682100252
Epoch #224: loss=0.013247375018262115
Epoch #225: loss=0.008852734586207991
Epoch #226: loss=0.010775415309921875
Epoch #227: loss=0.008810052465665316
Epoch #228: loss=0.011726147220998859
Epoch #229: loss=0.010692369551270798
Epoch #230: loss=0.012165581226877038
Epoch #231: loss=0.00871981529813091
Epoch #232: loss=0.010229339779513973
Epoch #233: loss=0.008578027383758135
Epoch #234: loss=0.01416528162573585
Epoch #235: loss=0.008798673149465466
Epoch #236: loss=0.00995868103236824
Epoch #237: loss=0.013762076625361445
Epoch #238: loss=0.009687503221153576
Epoch #239: loss=0.005573908905561356
Epoch #240: loss=0.00863710273906127
Epoch #241: loss=0.017533891826420255
Epoch #242: loss=0.014576164733413827
Epoch #243: loss=0.013126094672491685
Epoch #244: loss=0.00942539481688593
Epoch #245: loss=0.013448262817187202
Epoch #246: loss=0.008818833281905568
Epoch #247: loss=0.010220005089821635
Epoch #248: loss=0.007973131467862972
Epoch #249: loss=0.006758825068779641

Training time: 4:40:58.914432

Finished.
n2one setting etth2_ettm2_electricity -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm2_electricity_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_ettm2_electricity', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.46849e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.94927e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.46849e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.9075405099694329, 'MAE': 0.7339878302842165}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm2_electricity -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm2_electricity_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_ettm2_electricity', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.84844e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.23910643131437048, 'MAE': 0.3304055674555844}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm2_traffic', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm2_traffic_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.019852405515584
Epoch #1: loss=0.3605002559382807
Epoch #2: loss=0.27149826041846115
Epoch #3: loss=0.18517002579332753
Epoch #4: loss=0.16434836453673515
Epoch #5: loss=0.13325305401178247
Epoch #6: loss=0.10987736333203925
Epoch #7: loss=0.1160283689154312
Epoch #8: loss=0.08202632046516307
Epoch #9: loss=0.07781594646142119
Epoch #10: loss=0.069607827617173
Epoch #11: loss=0.06336457703886977
Epoch #12: loss=0.0571696062148972
Epoch #13: loss=0.06961889247230085
Epoch #14: loss=0.04983102804028683
Epoch #15: loss=0.04196523502760101
Epoch #16: loss=0.0396771176562073
Epoch #17: loss=0.058618645318148824
Epoch #18: loss=0.04400777696811763
Epoch #19: loss=0.047883485960350795
Epoch #20: loss=0.04091157660375095
Epoch #21: loss=0.03530458905204961
Epoch #22: loss=0.03268066766547484
Epoch #23: loss=0.03698433387961069
Epoch #24: loss=0.031189835152657577
Epoch #25: loss=0.03478668198500104
Epoch #26: loss=0.03306499868948859
Epoch #27: loss=0.02690939388703555
Epoch #28: loss=0.03067545763531763
Epoch #29: loss=0.03166593492695194
Epoch #30: loss=0.028938505293626803
Epoch #31: loss=0.024243304318489124
Epoch #32: loss=0.04353950316739925
Epoch #33: loss=0.025688299268685197
Epoch #34: loss=0.030243730172250335
Epoch #35: loss=0.023889904988358135
Epoch #36: loss=0.02969824602623703
Epoch #37: loss=0.021011755132812223
Epoch #38: loss=0.02146818185012142
Epoch #39: loss=0.02605998383478436
Epoch #40: loss=0.025959554089720106
Epoch #41: loss=0.022832020523955263
Epoch #42: loss=0.027254475839568346
Epoch #43: loss=0.020783246863323834
Epoch #44: loss=0.021190113578499717
Epoch #45: loss=0.022873299843856578
Epoch #46: loss=0.037655592493088495
Epoch #47: loss=0.020913814648652492
Epoch #48: loss=0.016682062804800973
Epoch #49: loss=0.01754490986813008
Epoch #50: loss=0.017824780191850468
Epoch #51: loss=0.02144397623983836
Epoch #52: loss=0.01940622975737576
Epoch #53: loss=0.017440186773720515
Epoch #54: loss=0.025394165568154263
Epoch #55: loss=0.017771741487707583
Epoch #56: loss=0.022979275809749115
Epoch #57: loss=0.018592198166879827
Epoch #58: loss=0.01696849652534266
Epoch #59: loss=0.018346574554412985
Epoch #60: loss=0.0180846976493988
Epoch #61: loss=0.01749453294449433
Epoch #62: loss=0.022171471176228474
Epoch #63: loss=0.021727317759955025
Epoch #64: loss=0.021779268209965348
Epoch #65: loss=0.016690316144178558
Epoch #66: loss=0.02226171497049191
Epoch #67: loss=0.01657586144832418
Epoch #68: loss=0.01601809144631261
Epoch #69: loss=0.018821209537484472
Epoch #70: loss=0.029745975043823075
Epoch #71: loss=0.018058540507594114
Epoch #72: loss=0.014870705079043877
Epoch #73: loss=0.011760134860477675
Epoch #74: loss=0.011900742502422706
Epoch #75: loss=0.02109442215415501
Epoch #76: loss=0.02103960508165156
Epoch #77: loss=0.012713559116739569
Epoch #78: loss=0.016537485527409114
Epoch #79: loss=0.015356452603770198
Epoch #80: loss=0.015817262295240653
Epoch #81: loss=0.014529655858958986
Epoch #82: loss=0.014476513654252895
Epoch #83: loss=0.014973225824426416
Epoch #84: loss=0.016315900772976667
Epoch #85: loss=0.016577383951020735
Epoch #86: loss=0.019325481929560986
Epoch #87: loss=0.017395093482231127
Epoch #88: loss=0.01758706351399517
Epoch #89: loss=0.016605657528932418
Epoch #90: loss=0.01244844763291026
Epoch #91: loss=0.012392287874536122
Epoch #92: loss=0.017273320758266146
Epoch #93: loss=0.0130431769619463
Epoch #94: loss=0.011238366755903619
Epoch #95: loss=0.01265512189703176
Epoch #96: loss=0.015790608321582442
Epoch #97: loss=0.010511472627066806
Epoch #98: loss=0.029250240486395674
Epoch #99: loss=0.02277289855413652
Epoch #100: loss=0.013222490707597569
Epoch #101: loss=0.01462776904577781
Epoch #102: loss=0.014596330645144918
Epoch #103: loss=0.018447361731787994
Epoch #104: loss=0.013279645583679667
Epoch #105: loss=0.01151276623363215
Epoch #106: loss=0.011198402688685084
Epoch #107: loss=0.02488979642971985
Epoch #108: loss=0.010688933810987775
Epoch #109: loss=0.01312272127877143
Epoch #110: loss=0.012516086882202548
Epoch #111: loss=0.016234754107112663
Epoch #112: loss=0.015960711462056763
Epoch #113: loss=0.013071534050819041
Epoch #114: loss=0.012418599530990998
Epoch #115: loss=0.009268737006211517
Epoch #116: loss=0.012186292997648706
Epoch #117: loss=0.011710753208039519
Epoch #118: loss=0.01908951385891917
Epoch #119: loss=0.017123024784152882
Epoch #120: loss=0.01756231758557657
Epoch #121: loss=0.01438040939777817
Epoch #122: loss=0.008035680345148483
Epoch #123: loss=0.017070755604204763
Epoch #124: loss=0.012540130388879333
Epoch #125: loss=0.011972108298472119
Epoch #126: loss=0.017664387721015373
Epoch #127: loss=0.012338623641831376
Epoch #128: loss=0.01355787994335432
Epoch #129: loss=0.008184834771302782
Epoch #130: loss=0.012445538876305694
Epoch #131: loss=0.012820298717799068
Epoch #132: loss=0.01140899446284245
Epoch #133: loss=0.01148462126118168
Epoch #134: loss=0.01513546500545999
Epoch #135: loss=0.01101910634872845
Epoch #136: loss=0.010212848587980262
Epoch #137: loss=0.009973695563181454
Epoch #138: loss=0.012297463627659122
Epoch #139: loss=0.020936428467130824
Epoch #140: loss=0.01088095648126248
Epoch #141: loss=0.013569611707829278
Epoch #142: loss=0.009921076467518023
Epoch #143: loss=0.012921393005010693
Epoch #144: loss=0.011931400544331568
Epoch #145: loss=0.012408823326818079
Epoch #146: loss=0.012598844514782699
Epoch #147: loss=0.01810793257933586
Epoch #148: loss=0.009808817781363773
Epoch #149: loss=0.013516363606289484
Epoch #150: loss=0.011383573238179618
Epoch #151: loss=0.011820678598682704
Epoch #152: loss=0.01319584498520602
Epoch #153: loss=0.009177105397462913
Epoch #154: loss=0.01556782526925169
Epoch #155: loss=0.015386408692740423
Epoch #156: loss=0.011646299713439393
Epoch #157: loss=0.012838515862412433
Epoch #158: loss=0.013182841993859091
Epoch #159: loss=0.011123211820978958
Epoch #160: loss=0.011896809091922478
Epoch #161: loss=0.011148051443358948
Epoch #162: loss=0.009656477187408282
Epoch #163: loss=0.017036411935226748
Epoch #164: loss=0.010714218667255243
Epoch #165: loss=0.01802969796167004
Epoch #166: loss=0.008345372257661604
Epoch #167: loss=0.011891132657480987
Epoch #168: loss=0.008797512752690554
Epoch #169: loss=0.012567261753726846
Epoch #170: loss=0.010574670934635254
Epoch #171: loss=0.008972096262640538
Epoch #172: loss=0.013627261293169629
Epoch #173: loss=0.013737543846193809
Epoch #174: loss=0.008597350408358167
Epoch #175: loss=0.00827556885871507
Epoch #176: loss=0.01322657774187519
Epoch #177: loss=0.010448333363725934
Epoch #178: loss=0.013498679331612286
Epoch #179: loss=0.012988769406431608
Epoch #180: loss=0.010550295662364368
Epoch #181: loss=0.007636067864078716
Epoch #182: loss=0.008753688592597345
Epoch #183: loss=0.017765649102131482
Epoch #184: loss=0.009838511985038746
Epoch #185: loss=0.011509861625877834
Epoch #186: loss=0.010962280378424278
Epoch #187: loss=0.012382473340089333
Epoch #188: loss=0.011401889191091124
Epoch #189: loss=0.01054382120806126
Epoch #190: loss=0.009516010051877608
Epoch #191: loss=0.014752573139759823
Epoch #192: loss=0.009560909472495702
Epoch #193: loss=0.011868701371796223
Epoch #194: loss=0.00932655416399939
Epoch #195: loss=0.011724757668013229
Epoch #196: loss=0.00921064921976722
Epoch #197: loss=0.010728657045257767
Epoch #198: loss=0.0073069663824919025
Epoch #199: loss=0.008596592559164989
Epoch #200: loss=0.009006655283139315
Epoch #201: loss=0.011066200286396885
Epoch #202: loss=0.008989089243062732
Epoch #203: loss=0.008820302106389797
Epoch #204: loss=0.015999769493596844
Epoch #205: loss=0.008357231326061249
Epoch #206: loss=0.011338320523894005
Epoch #207: loss=0.0094708708676411
Epoch #208: loss=0.007129530968367445
Epoch #209: loss=0.015205004068238022
Epoch #210: loss=0.012854449588148208
Epoch #211: loss=0.00905034762062397
Epoch #212: loss=0.008674856184970022
Epoch #213: loss=0.008654713176077746
Epoch #214: loss=0.011144998087547719
Epoch #215: loss=0.011375952608167691
Epoch #216: loss=0.008851183659995017
Epoch #217: loss=0.010654593406053953
Epoch #218: loss=0.011236954939142214
Epoch #219: loss=0.007761975832479286
Epoch #220: loss=0.010363408162331986
Epoch #221: loss=0.009290284228402676
Epoch #222: loss=0.010854822064844815
Epoch #223: loss=0.011047139573268147
Epoch #224: loss=0.007940879853958905
Epoch #225: loss=0.009197814642414993
Epoch #226: loss=0.010226224629381745
Epoch #227: loss=0.008162538052585494
Epoch #228: loss=0.008420272386947338
Epoch #229: loss=0.010266620815855276
Epoch #230: loss=0.007601474017555047
Epoch #231: loss=0.0073169225927234615
Epoch #232: loss=0.015349668918563772
Epoch #233: loss=0.0256159723451922
Epoch #234: loss=0.01149243632452536
Epoch #235: loss=0.00948791472186382
Epoch #236: loss=0.009499917974112164
Epoch #237: loss=0.009255991206439582
Epoch #238: loss=0.009568054752856948
Epoch #239: loss=0.007824137267826617
Epoch #240: loss=0.013352278156724589
Epoch #241: loss=0.009438877395338998
Epoch #242: loss=0.010581525658166025
Epoch #243: loss=0.011242243950135327
Epoch #244: loss=0.01215044025749111
Epoch #245: loss=0.008768987144470554
Epoch #246: loss=0.008670045270528962
Epoch #247: loss=0.006759853231578332
Epoch #248: loss=0.008254181707212122
Epoch #249: loss=0.009278326182059324

Training time: 10:17:01.470360

Finished.
n2one setting etth2_ettm2_traffic -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm2_traffic_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_ettm2_traffic', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.27069e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.30858e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.52216e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.27069e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4176965658624845, 'MAE': 0.4601799373072111}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm2_traffic -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm2_traffic_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_ettm2_traffic', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.64405e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.37973e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.64405e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.5698544394823556, 'MAE': 0.5882973909924795}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm2_traffic -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm2_traffic_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_ettm2_traffic', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
Evaluation result: {'MSE': 0.3047954230542287, 'MAE': 0.36573894354203174}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm2_weather', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm2_weather_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=6.758825182914734
Epoch #1: loss=2.7904675657098945
Epoch #2: loss=2.5991366017948496
Epoch #3: loss=2.3304679854349657
Epoch #4: loss=2.0876953818581323
Epoch #5: loss=2.0097900195555254
Epoch #6: loss=1.859704914418134
Epoch #7: loss=1.7566788277842782
Epoch #8: loss=1.6333497193726627
Epoch #9: loss=1.5306406373327428
Epoch #10: loss=1.4161560399965807
Epoch #11: loss=1.303008565848524
Epoch #12: loss=1.2983879325064747
Epoch #13: loss=1.1677351932634006
Epoch #14: loss=1.1119597269730135
Epoch #15: loss=1.0873453440991314
Epoch #16: loss=1.1793183982372284
Epoch #17: loss=1.1180677143010227
Epoch #18: loss=1.1011734821579673
Epoch #19: loss=1.0129071081226522
Epoch #20: loss=0.9400522099299864
Epoch #21: loss=0.8379883170127869
Epoch #22: loss=0.8298448446122083
Epoch #23: loss=0.8271538723598827
Epoch #24: loss=0.8035657405853271
Epoch #25: loss=0.7255960120396181
Epoch #26: loss=0.7173025919632479
Epoch #27: loss=0.7575768110426989
Epoch #28: loss=0.7466423050923781
Epoch #29: loss=0.83440431275151
Epoch #30: loss=0.7992604889652946
Epoch #31: loss=0.7095226848667319
Epoch #32: loss=0.6444687924601815
Epoch #33: loss=0.7063490538434549
Epoch #34: loss=0.6196501715616747
Epoch #35: loss=0.6155327734622088
Epoch #36: loss=0.583315331150185
Epoch #37: loss=0.5731608278372071
Epoch #38: loss=0.5639593323523348
Epoch #39: loss=0.5654882328076796
Epoch #40: loss=0.5272477154027332
Epoch #41: loss=0.5235222523862665
Epoch #42: loss=0.517095229842446
Epoch #43: loss=0.5843102024360136
Epoch #44: loss=0.5561355501413345
Epoch #45: loss=0.49857646836475894
Epoch #46: loss=0.5807650129903447
Epoch #47: loss=0.49887543645772064
Epoch #48: loss=0.41478846764022653
Epoch #49: loss=0.4223107729445804
Epoch #50: loss=0.4369868138297038
Epoch #51: loss=0.40915336595340207
Epoch #52: loss=0.5065065527504141
Epoch #53: loss=0.5065221661193804
Epoch #54: loss=0.476203168657693
Epoch #55: loss=0.43335502086715266
Epoch #56: loss=0.34868079830299725
Epoch #57: loss=0.4198022864081643
Epoch #58: loss=0.40432471985166724
Epoch #59: loss=0.3770789216187867
Epoch #60: loss=0.4069896563887596
Epoch #61: loss=0.3681490397588773
Epoch #62: loss=0.3601150353523818
Epoch #63: loss=0.3486615920608694
Epoch #64: loss=0.3570237268101085
Epoch #65: loss=0.4422939829528332
Epoch #66: loss=0.4098821539770473
Epoch #67: loss=0.33117955415086314
Epoch #68: loss=0.3142348961396651
Epoch #69: loss=0.2952574410221793
Epoch #70: loss=0.2721193241463466
Epoch #71: loss=0.2656217285177924
Epoch #72: loss=0.26926555890928616
Epoch #73: loss=0.280623102391308
Epoch #74: loss=0.2555838061327284
Epoch #75: loss=0.2779344448989088
Epoch #76: loss=0.29751768826761027
Epoch #77: loss=0.2992107361893762
Epoch #78: loss=0.33189129727807914
Epoch #79: loss=0.3464245786043731
Epoch #80: loss=0.2375613979317925
Epoch #81: loss=0.2386174640533599
Epoch #82: loss=0.324060597372326
Epoch #83: loss=0.2667733178558675
Epoch #84: loss=0.2749350653453307
Epoch #85: loss=0.29848048920658504
Epoch #86: loss=0.23264989714053544
Epoch #87: loss=0.21009109905836257
Epoch #88: loss=0.19220450859178195
Epoch #89: loss=0.17922956225546924
Epoch #90: loss=0.22685302319851788
Epoch #91: loss=0.20573229207233948
Epoch #92: loss=0.18500039413232694
Epoch #93: loss=0.33297255415130744
Epoch #94: loss=0.23721903240816158
Epoch #95: loss=0.1901361895725131
Epoch #96: loss=0.24947791792113672
Epoch #97: loss=0.5848620967431502
Epoch #98: loss=0.5000367780978029
Epoch #99: loss=0.34317871098491276
Epoch #100: loss=0.32151014831933106
Epoch #101: loss=0.227484156800942
Epoch #102: loss=0.33152204836634075
Epoch #103: loss=0.25966837045482616
Epoch #104: loss=0.1830779075283896
Epoch #105: loss=0.2319626183333722
Epoch #106: loss=0.23125005767426707
Epoch #107: loss=0.1683321384374391
Epoch #108: loss=0.3123048554089936
Epoch #109: loss=0.16383641594174234
Epoch #110: loss=0.1971807505258105
Epoch #111: loss=0.15876229361376978
Epoch #112: loss=0.13876313411376692
Epoch #113: loss=0.15717479595067826
Epoch #114: loss=0.16394511093808847
Epoch #115: loss=0.15903749130666256
Epoch #116: loss=0.14976580694995142
Epoch #117: loss=0.16427650201049718
Epoch #118: loss=0.1624656351791187
Epoch #119: loss=0.15257491620088165
Epoch #120: loss=0.14936823888935827
Epoch #121: loss=0.16082418519495564
Epoch #122: loss=0.11988101916557009
Epoch #123: loss=0.12987525286999616
Epoch #124: loss=0.15083627597513524
Epoch #125: loss=0.16787676530128176
Epoch #126: loss=0.14145881758833473
Epoch #127: loss=0.1374304013072767
Epoch #128: loss=0.15369314505633982
Epoch #129: loss=0.14668984732336618
Epoch #130: loss=0.17245068307965994
Epoch #131: loss=0.1364031664349816
Epoch #132: loss=0.11274966085329652
Epoch #133: loss=0.11840573812580922
Epoch #134: loss=0.12127917496995493
Epoch #135: loss=0.17197167272256178
Epoch #136: loss=0.14325405217029832
Epoch #137: loss=0.12087852296165445
Epoch #138: loss=0.1425722411156378
Epoch #139: loss=0.13274128451435405
Epoch #140: loss=0.19276918995786796
Epoch #141: loss=0.15557120359418067
Epoch #142: loss=0.155449456196617
Epoch #143: loss=0.15601399117572742
Epoch #144: loss=0.11551268115131692
Epoch #145: loss=0.12360505954447118
Epoch #146: loss=0.12945158635689455
Epoch #147: loss=0.11463982658460736
Epoch #148: loss=0.10866071990775791
Epoch #149: loss=0.0925423103300008
Epoch #150: loss=0.09288143853402951
Epoch #151: loss=0.1778735970993611
Epoch #152: loss=0.13473312624476172
Epoch #153: loss=0.09998167179186236
Epoch #154: loss=0.308355418541892
Epoch #155: loss=0.13906194883483378
Epoch #156: loss=0.1440905259329487
Epoch #157: loss=0.11099398085339503
Epoch #158: loss=0.15355393129654907
Epoch #159: loss=0.09742195866155354
Epoch #160: loss=0.11935530569065701
Epoch #161: loss=0.09416748528284105
Epoch #162: loss=0.1137165881439366
Epoch #163: loss=0.12424447505988857
Epoch #164: loss=0.12798777066001837
Epoch #165: loss=0.10097575598311695
Epoch #166: loss=0.0884445525536483
Epoch #167: loss=0.10070846847851168
Epoch #168: loss=0.2316858900541609
Epoch #169: loss=0.15538984156129035
Epoch #170: loss=0.12081776893782345
Epoch #171: loss=0.09641354677098041
Epoch #172: loss=0.11767427915368568
Epoch #173: loss=0.09228338400663977
Epoch #174: loss=0.08969094782051715
Epoch #175: loss=0.090477495665916
Epoch #176: loss=0.12072310592471198
Epoch #177: loss=0.07887346983294595
Epoch #178: loss=0.06056730984710157
Epoch #179: loss=0.11793316862630573
Epoch #180: loss=0.10107315771959045
Epoch #181: loss=0.12018249306658452
Epoch #182: loss=0.09518168028444052
Epoch #183: loss=0.10671010143546895
Epoch #184: loss=0.08614033786579967
Epoch #185: loss=0.23111734763634476
Epoch #186: loss=0.11859181337058544
Epoch #187: loss=0.08870003258132121
Epoch #188: loss=0.08485870795663107
Epoch #189: loss=0.09997126187028532
Epoch #190: loss=0.0846752086230977
Epoch #191: loss=0.07848061811686917
Epoch #192: loss=0.15039831878278742
Epoch #193: loss=0.11265730172057044
Epoch #194: loss=0.0861661946401
Epoch #195: loss=0.06763587593608959
Epoch #196: loss=0.07601427877406505
Epoch #197: loss=0.10255092526362701
Epoch #198: loss=0.09689751917242327
Epoch #199: loss=0.0915752842345021
Epoch #200: loss=0.1069105035117404
Epoch #201: loss=0.08014199398034676
Epoch #202: loss=0.0877880803309381
Epoch #203: loss=0.06983093335293233
Epoch #204: loss=0.0742936244403774
Epoch #205: loss=0.10051694059405815
Epoch #206: loss=0.0613082678438249
Epoch #207: loss=0.08667136140337045
Epoch #208: loss=0.10022505156865175
Epoch #209: loss=0.0874525522813201
Epoch #210: loss=0.07533595033667305
Epoch #211: loss=0.10451561788266356
Epoch #212: loss=0.07688598745417866
Epoch #213: loss=0.08794574325226924
Epoch #214: loss=0.08144870252263817
Epoch #215: loss=0.09904896091161804
Epoch #216: loss=0.12333474574949253
Epoch #217: loss=0.0815059537152675
Epoch #218: loss=0.09883391982029108
Epoch #219: loss=0.2217060733501884
Epoch #220: loss=0.19745761575177312
Epoch #221: loss=0.17880097844383933
Epoch #222: loss=0.0742456836795265
Epoch #223: loss=0.06220361107791012
Epoch #224: loss=0.06467576769434592
Epoch #225: loss=0.10805389953946526
Epoch #226: loss=0.07937495425258848
Epoch #227: loss=0.07844215440987186
Epoch #228: loss=0.07661253218115731
Epoch #229: loss=0.07202575796029785
Epoch #230: loss=0.06256348955106329
Epoch #231: loss=0.05258412477137013
Epoch #232: loss=0.05641725793777203
Epoch #233: loss=0.10549187850715085
Epoch #234: loss=0.07159842011010782
Epoch #235: loss=0.07871313831260936
Epoch #236: loss=0.1019917441193353
Epoch #237: loss=0.07839019399728965
Epoch #238: loss=0.05321958612396636
Epoch #239: loss=0.07158474869687449
Epoch #240: loss=0.08931397409601645
Epoch #241: loss=0.10470513764514842
Epoch #242: loss=0.1404539799233052
Epoch #243: loss=0.09097740219228646
Epoch #244: loss=0.06329551265066997
Epoch #245: loss=0.10163443603298881
Epoch #246: loss=0.058917481346394525
Epoch #247: loss=0.07835239203731445
Epoch #248: loss=0.15780731119130822
Epoch #249: loss=0.07629985154860398

Training time: 0:43:52.786578

Finished.
n2one setting etth2_ettm2_weather -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm2_weather_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_ettm2_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.37583e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.74451e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.37583e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.37371210667835797, 'MAE': 0.43358282087704825}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm2_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm2_weather_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_ettm2_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.75967e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.90802e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.19511337489352518, 'MAE': 0.30304235804285734}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm2_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm2_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=4.354570627212524
Epoch #1: loss=2.4372118528072653
Epoch #2: loss=2.133751827936906
Epoch #3: loss=2.0361899687693668
Epoch #4: loss=1.923037322667929
Epoch #5: loss=1.8196433324080248
Epoch #6: loss=1.6646166031177227
Epoch #7: loss=1.5908860197434058
Epoch #8: loss=1.5306479243131785
Epoch #9: loss=1.461964955696693
Epoch #10: loss=1.307150350167201
Epoch #11: loss=1.2717378666767707
Epoch #12: loss=1.2361053893199334
Epoch #13: loss=1.2347706166597514
Epoch #14: loss=1.1315029423970442
Epoch #15: loss=1.1490636238685021
Epoch #16: loss=1.0221934364392207
Epoch #17: loss=1.1013291707405677
Epoch #18: loss=0.9874465580169971
Epoch #19: loss=1.0089613130459418
Epoch #20: loss=0.9480171570411096
Epoch #21: loss=0.9931789567837348
Epoch #22: loss=0.9758096383168147
Epoch #23: loss=0.9476093007968023
Epoch #24: loss=1.005359681753012
Epoch #25: loss=1.146195840377074
Epoch #26: loss=0.9294093526326693
Epoch #27: loss=0.9259152825062091
Epoch #28: loss=0.868852477807265
Epoch #29: loss=0.8897998585150793
Epoch #30: loss=0.9702378075856429
Epoch #31: loss=0.8465817822859838
Epoch #32: loss=0.9619941906287119
Epoch #33: loss=0.9066473085146683
Epoch #34: loss=0.821000181711637
Epoch #35: loss=0.7543700750057514
Epoch #36: loss=0.7424731105566025
Epoch #37: loss=0.835997183735554
Epoch #38: loss=0.7510107388863196
Epoch #39: loss=0.7650688898104888
Epoch #40: loss=0.7716222474208245
Epoch #41: loss=0.7459537570293133
Epoch #42: loss=0.722661011494123
Epoch #43: loss=0.6506546666988959
Epoch #44: loss=0.6813970678127729
Epoch #45: loss=0.6340513607630363
Epoch #46: loss=0.8579950733826711
Epoch #47: loss=0.7734915912151337
Epoch #48: loss=0.6675503700971603
Epoch #49: loss=0.5530621317716745
Epoch #50: loss=0.6183610386573352
Epoch #51: loss=0.5593106620586835
Epoch #52: loss=0.5605253474070475
Epoch #53: loss=0.6486673148778769
Epoch #54: loss=0.6415976744431716
Epoch #55: loss=0.6491653930682403
Epoch #56: loss=0.49340571004610795
Epoch #57: loss=0.49476248255142796
Epoch #58: loss=0.7180948853492737
Epoch #59: loss=0.6515241528932865
Epoch #60: loss=0.5970359444618225
Epoch #61: loss=0.5524677015267886
Epoch #62: loss=0.5074053458296336
Epoch #63: loss=0.5627476722002029
Epoch #64: loss=0.47955428579678905
Epoch #65: loss=0.47580788341852337
Epoch #66: loss=0.5087601508085544
Epoch #67: loss=0.4943490234705118
Epoch #68: loss=0.501267393047993
Epoch #69: loss=0.5106796186703902
Epoch #70: loss=0.49447129208308
Epoch #71: loss=0.43808072003034443
Epoch #72: loss=0.5010836617304728
Epoch #73: loss=0.4701705460365002
Epoch #74: loss=0.4900747612118721
Epoch #75: loss=0.41808100732473225
Epoch #76: loss=0.45092489513067097
Epoch #77: loss=0.43444025631134325
Epoch #78: loss=0.5431832040731723
Epoch #79: loss=0.4252289986381164
Epoch #80: loss=0.4827029917102594
Epoch #81: loss=0.3788682881456155
Epoch #82: loss=0.40609442442655563
Epoch #83: loss=0.3882961250268496
Epoch #84: loss=0.49313185192071474
Epoch #85: loss=0.3804797346775348
Epoch #86: loss=0.48746965481684756
Epoch #87: loss=0.4619624362542079
Epoch #88: loss=0.35260129089538866
Epoch #89: loss=0.39995098744447416
Epoch #90: loss=0.38378777183019197
Epoch #91: loss=0.3442462579562114
Epoch #92: loss=0.3396430972677011
Epoch #93: loss=0.39131836478526777
Epoch #94: loss=0.44648882230887044
Epoch #95: loss=0.39930405353124326
Epoch #96: loss=0.4017952772287222
Epoch #97: loss=0.3903648274449202
Epoch #98: loss=0.3422091964345712
Epoch #99: loss=0.40093709700382674
Epoch #100: loss=0.35231077441802394
Epoch #101: loss=0.3617859508555669
Epoch #102: loss=0.3952771247579501
Epoch #103: loss=0.3663802651258615
Epoch #104: loss=0.38280821247742725
Epoch #105: loss=0.4205034999893262
Epoch #106: loss=0.39367662026331973
Epoch #107: loss=0.36133795460829365
Epoch #108: loss=0.33590460224793506
Epoch #109: loss=0.27479224709364086
Epoch #110: loss=0.3889427362726285
Epoch #111: loss=0.3115621277919182
Epoch #112: loss=0.28260594319838744
Epoch #113: loss=0.28625493639936817
Epoch #114: loss=0.3068263221245546
Epoch #115: loss=0.30510464024085265
Epoch #116: loss=0.35082413198856205
Epoch #117: loss=0.2800745448240867
Epoch #118: loss=0.3150807481545668
Epoch #119: loss=0.3279141147549336
Epoch #120: loss=0.3481599184182974
Epoch #121: loss=0.4149052787285585
Epoch #122: loss=0.36382683423849255
Epoch #123: loss=0.33670879155397415
Epoch #124: loss=0.30653719432078874
Epoch #125: loss=0.30025895656301427
Epoch #126: loss=0.2752835203248721
Epoch #127: loss=0.25957741187169003
Epoch #128: loss=0.39467453211545944
Epoch #129: loss=0.34972963195580703
Epoch #130: loss=0.34746723020306003
Epoch #131: loss=0.3146954390865106
Epoch #132: loss=0.25173638560450995
Epoch #133: loss=0.21768684713886335
Epoch #134: loss=0.18707511803278556
Epoch #135: loss=0.26323677456149686
Epoch #136: loss=0.19159448290100464
Epoch #137: loss=0.18511458457662508
Epoch #138: loss=0.3148840353465997
Epoch #139: loss=0.2362453986245852
Epoch #140: loss=0.22235776111483574
Epoch #141: loss=0.21517595190268296
Epoch #142: loss=0.23151605318372065
Epoch #143: loss=0.26947855576872826
Epoch #144: loss=0.21823403812371767
Epoch #145: loss=0.4679797644225451
Epoch #146: loss=0.3739886593360167
Epoch #147: loss=0.36796216236857265
Epoch #148: loss=0.28868908607042754
Epoch #149: loss=0.23829349502921104
Epoch #150: loss=0.27144524311790097
Epoch #151: loss=0.3369047767840899
Epoch #152: loss=0.24445134730866322
Epoch #153: loss=0.26390523750048417
Epoch #154: loss=0.26241430611564565
Epoch #155: loss=0.22258796055729574
Epoch #156: loss=0.21729992129481757
Epoch #157: loss=0.2240535353238766
Epoch #158: loss=0.21080491720483854
Epoch #159: loss=0.17870295735505912
Epoch #160: loss=0.20405988309245843
Epoch #161: loss=0.16726477530140144
Epoch #162: loss=0.20591211247329527
Epoch #163: loss=0.1584438025378264
Epoch #164: loss=0.17395258981447953
Epoch #165: loss=0.21942608430981636
Epoch #166: loss=0.18185814140507808
Epoch #167: loss=0.1555977979531655
Epoch #168: loss=0.1646420365342727
Epoch #169: loss=0.1451948873985272
Epoch #170: loss=0.15462171773497874
Epoch #171: loss=0.2264476538850711
Epoch #172: loss=0.23257088431945214
Epoch #173: loss=0.250471653846594
Epoch #174: loss=0.19346457461898142
Epoch #175: loss=0.20233834004746035
Epoch #176: loss=0.1585049408559616
Epoch #177: loss=0.15082891342731622
Epoch #178: loss=0.1494241116138605
Epoch #179: loss=0.19690261996136263
Epoch #180: loss=0.22875776743659607
Epoch #181: loss=0.2233095753651399
Epoch #182: loss=0.2183067652468498
Epoch #183: loss=0.19611679304104584
Epoch #184: loss=0.23376179945010406
Epoch #185: loss=0.20642774810011572
Epoch #186: loss=0.18997251958801195
Epoch #187: loss=0.19730268848630098
Epoch #188: loss=0.13427795813633844
Epoch #189: loss=0.16260331095411226
Epoch #190: loss=0.15630373645287293
Epoch #191: loss=0.21580681018531322
Epoch #192: loss=0.1511361149068062
Epoch #193: loss=0.18634122438155687
Epoch #194: loss=0.1712717946905356
Epoch #195: loss=0.1874989612171283
Epoch #196: loss=0.1353575729120236
Epoch #197: loss=0.1588099535841208
Epoch #198: loss=0.15608898249383157
Epoch #199: loss=0.13511234392913488
Epoch #200: loss=0.14150200762714332
Epoch #201: loss=0.16168406720344836
Epoch #202: loss=0.16998546026073968
Epoch #203: loss=0.17965399846434593
Epoch #204: loss=0.1390650700777769
Epoch #205: loss=0.15221418626606464
Epoch #206: loss=0.19421907815222555
Epoch #207: loss=0.1787003785944902
Epoch #208: loss=0.15282993763685226
Epoch #209: loss=0.12791397666128781
Epoch #210: loss=0.14135527840027443
Epoch #211: loss=0.1222823803814558
Epoch #212: loss=0.15348377580252978
Epoch #213: loss=0.17637088593955225
Epoch #214: loss=0.13985797175421164
Epoch #215: loss=0.15951440769892472
Epoch #216: loss=0.16473767519570315
Epoch #217: loss=0.19780365105431813
Epoch #218: loss=0.1909570906024713
Epoch #219: loss=0.24891363858030394
Epoch #220: loss=0.19097717392903107
Epoch #221: loss=0.16760181850538805
Epoch #222: loss=0.19391389277118903
Epoch #223: loss=0.17364404250222903
Epoch #224: loss=0.2163329219015745
Epoch #225: loss=0.23570303260706937
Epoch #226: loss=0.19038458798940366
Epoch #227: loss=0.1587607473708116
Epoch #228: loss=0.13993843043079743
Epoch #229: loss=0.14675141054277235
Epoch #230: loss=0.11394639370533136
Epoch #231: loss=0.23544517990488273
Epoch #232: loss=0.1833606562935389
Epoch #233: loss=0.20117218219316924
Epoch #234: loss=0.1512972802783434
Epoch #235: loss=0.11837237199338582
Epoch #236: loss=0.10553443295737872
Epoch #237: loss=0.09317591306395255
Epoch #238: loss=0.14282759751837987
Epoch #239: loss=0.12896189795663723
Epoch #240: loss=0.16002246264654857
Epoch #241: loss=0.29620862279373866
Epoch #242: loss=0.2765068944830161
Epoch #243: loss=0.26021330459759784
Epoch #244: loss=0.1625629710749938
Epoch #245: loss=0.12008105791532077
Epoch #246: loss=0.1222325273287984
Epoch #247: loss=0.10108189843595028
Epoch #248: loss=0.11834713723510504
Epoch #249: loss=0.1065321621986536

Training time: 0:21:33.295721

Finished.
n2one setting etth2_ettm2_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm2_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_ettm2_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.57793e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.16394e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.57793e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.38094154209905007, 'MAE': 0.44050528657739424}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm2_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm2_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_ettm2_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.45078e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.71163e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.71163e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.47396674365638963, 'MAE': 0.5082643361317081}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_electricity_traffic', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_electricity_traffic_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.8329057542341096
Epoch #1: loss=0.2957313361726388
Epoch #2: loss=0.18994185205768135
Epoch #3: loss=0.1355250665182326
Epoch #4: loss=0.11634583497936485
Epoch #5: loss=0.08361774938525397
Epoch #6: loss=0.07440050691600983
Epoch #7: loss=0.05882680697264854
Epoch #8: loss=0.05678423012317229
Epoch #9: loss=0.05187668812210758
Epoch #10: loss=0.04944789328029332
Epoch #11: loss=0.04506694451013596
Epoch #12: loss=0.04088558613600507
Epoch #13: loss=0.03660002355287712
Epoch #14: loss=0.036531352650710704
Epoch #15: loss=0.03497481014493446
Epoch #16: loss=0.02972530504334483
Epoch #17: loss=0.025908312771348047
Epoch #18: loss=0.035444232714049395
Epoch #19: loss=0.026637764965421754
Epoch #20: loss=0.0279274351830289
Epoch #21: loss=0.0266105236274292
Epoch #22: loss=0.025765123607457748
Epoch #23: loss=0.023081342893615443
Epoch #24: loss=0.02541718458342992
Epoch #25: loss=0.03113825992170424
Epoch #26: loss=0.03142512039596434
Epoch #27: loss=0.02058659557824438
Epoch #28: loss=0.022722257367196345
Epoch #29: loss=0.03779452148601883
Epoch #30: loss=0.022874813408203454
Epoch #31: loss=0.028038900365129488
Epoch #32: loss=0.01928924666272531
Epoch #33: loss=0.024781714189414154
Epoch #34: loss=0.017367109204270727
Epoch #35: loss=0.020130450085383653
Epoch #36: loss=0.017249357216246035
Epoch #37: loss=0.01872314733390485
Epoch #38: loss=0.018733036597019664
Epoch #39: loss=0.01570914743097397
Epoch #40: loss=0.016944732439230753
Epoch #41: loss=0.02201311244382797
Epoch #42: loss=0.01750237891463242
Epoch #43: loss=0.015656744958314373
Epoch #44: loss=0.01899678778537244
Epoch #45: loss=0.016012733094707257
Epoch #46: loss=0.020572570263909004
Epoch #47: loss=0.018740078909767737
Epoch #48: loss=0.017756216884042848
Epoch #49: loss=0.017914462231633746
Epoch #50: loss=0.01425682591925426
Epoch #51: loss=0.017105962731728735
Epoch #52: loss=0.016284598169815062
Epoch #53: loss=0.013845892863919441
Epoch #54: loss=0.014465082893999169
Epoch #55: loss=0.013759799164762923
Epoch #56: loss=0.015919000462300197
Epoch #57: loss=0.013323939862972157
Epoch #58: loss=0.013360508129674698
Epoch #59: loss=0.016881982067320105
Epoch #60: loss=0.015953929695210756
Epoch #61: loss=0.013479344037013175
Epoch #62: loss=0.014438740635181175
Epoch #63: loss=0.011483074077150683
Epoch #64: loss=0.0142180382856657
Epoch #65: loss=0.017494870993992787
Epoch #66: loss=0.01200055326058768
Epoch #67: loss=0.013773949859206987
Epoch #68: loss=0.015308030651483152
Epoch #69: loss=0.015318523781465077
Epoch #70: loss=0.012857631724518568
Epoch #71: loss=0.013668972214619324
Epoch #72: loss=0.014132861130916857
Epoch #73: loss=0.013336212195831688
Epoch #74: loss=0.017232779698434654
Epoch #75: loss=0.009661244681670464
Epoch #76: loss=0.017625103901216698
Epoch #77: loss=0.012938405868600752
Epoch #78: loss=0.01270087975199127
Epoch #79: loss=0.015616719467622157
Epoch #80: loss=0.012937984836215404
Epoch #81: loss=0.010737678567250846
Epoch #82: loss=0.009863564853584335
Epoch #83: loss=0.012750202710001667
Epoch #84: loss=0.013245421732744561
Epoch #85: loss=0.015575462343643749
Epoch #86: loss=0.013293857889043503
Epoch #87: loss=0.01274784156329198
Epoch #88: loss=0.01544391718226438
Epoch #89: loss=0.009260922338825283
Epoch #90: loss=0.01751730857013936
Epoch #91: loss=0.014533135968068725
Epoch #92: loss=0.014187604106939202
Epoch #93: loss=0.011246822374905147
Epoch #94: loss=0.010717305386421357
Epoch #95: loss=0.013103293937728794
Epoch #96: loss=0.013986617601217366
Epoch #97: loss=0.01039392953448021
Epoch #98: loss=0.013526621383410377
Epoch #99: loss=0.012490418005075322
Epoch #100: loss=0.0114868515008227
Epoch #101: loss=0.010047242480822734
Epoch #102: loss=0.011653885067691987
Epoch #103: loss=0.00813465247755164
Epoch #104: loss=0.013553451063764916
Epoch #105: loss=0.012162863958417633
Epoch #106: loss=0.014874483662728793
Epoch #107: loss=0.011282007827080137
Epoch #108: loss=0.015624699930383524
Epoch #109: loss=0.008517726447346167
Epoch #110: loss=0.014568620292688015
Epoch #111: loss=0.010279661803403596
Epoch #112: loss=0.012650787214293172
Epoch #113: loss=0.010941250879095452
Epoch #114: loss=0.011879535232956264
Epoch #115: loss=0.013066439255213603
Epoch #116: loss=0.015299224754146832
Epoch #117: loss=0.010510422679289448
Epoch #118: loss=0.010139686792040687
Epoch #119: loss=0.012015794712865232
Epoch #120: loss=0.009736175199397332
Epoch #121: loss=0.015125990051290944
Epoch #122: loss=0.010223084322774603
Epoch #123: loss=0.009795441804649387
Epoch #124: loss=0.010596190019842813
Epoch #125: loss=0.01032429511713631
Epoch #126: loss=0.01760282272297132
Epoch #127: loss=0.01453046507472094
Epoch #128: loss=0.006681677670711287
Epoch #129: loss=0.011230913659021114
Epoch #130: loss=0.011839315631356435
Epoch #131: loss=0.01283745814974228
Epoch #132: loss=0.00983711357173338
Epoch #133: loss=0.013206458511515794
Epoch #134: loss=0.00817640850276069
Epoch #135: loss=0.011060558259574638
Epoch #136: loss=0.012728719193803365
Epoch #137: loss=0.011000829315333463
Epoch #138: loss=0.011280734236623619
Epoch #139: loss=0.00930881809290746
Epoch #140: loss=0.008881168433601044
Epoch #141: loss=0.00996225832856579
Epoch #142: loss=0.012612786918094464
Epoch #143: loss=0.008883921604052268
Epoch #144: loss=0.011608109560852847
Epoch #145: loss=0.01249325947240269
Epoch #146: loss=0.0148888659092672
Epoch #147: loss=0.007095768203554839
Epoch #148: loss=0.00786573190022306
Epoch #149: loss=0.0126394626981028
Epoch #150: loss=0.008403026108569349
Epoch #151: loss=0.01254363136684929
Epoch #152: loss=0.009216356321712546
Epoch #153: loss=0.013095435455340641
Epoch #154: loss=0.011615087569910375
Epoch #155: loss=0.008387100288960295
Epoch #156: loss=0.013210293865084459
Epoch #157: loss=0.011921499889591482
Epoch #158: loss=0.017721894842256038
Epoch #159: loss=0.011248819644089901
Epoch #160: loss=0.009935708826274744
Epoch #161: loss=0.009632957065063421
Epoch #162: loss=0.018894220116335955
Epoch #163: loss=0.009357599367374386
Epoch #164: loss=0.011151885486708292
Epoch #165: loss=0.013195388845688744
Epoch #166: loss=0.009643623664287436
Epoch #167: loss=0.00882384839115279
Epoch #168: loss=0.008027780316765643
Epoch #169: loss=0.010821425810968895
Epoch #170: loss=0.009369246269971966
Epoch #171: loss=0.01119922774804985
Epoch #172: loss=0.01233107293261403
Epoch #173: loss=0.007692373706463934
Epoch #174: loss=0.012637230183365716
Epoch #175: loss=0.008092674924837945
Epoch #176: loss=0.006457139698889042
Epoch #177: loss=0.011784587792976135
Epoch #178: loss=0.008322431368055312
Epoch #179: loss=0.008555104290458037
Epoch #180: loss=0.011553964845712899
Epoch #181: loss=0.008429046537411536
Epoch #182: loss=0.011120964942877612
Epoch #183: loss=0.01025769943748053
Epoch #184: loss=0.009283083979403082
Epoch #185: loss=0.006431404286766858
Epoch #186: loss=0.02049476414366905
Epoch #187: loss=0.008510879694118298
Epoch #188: loss=0.008344375088156941
Epoch #189: loss=0.009799169105556322
Epoch #190: loss=0.009196672632695007
Epoch #191: loss=0.01053843394564093
Epoch #192: loss=0.007591493629817186
Epoch #193: loss=0.01377404087071846
Epoch #194: loss=0.00991669253677525
Epoch #195: loss=0.008603409366357383
Epoch #196: loss=0.0076487813622078335
Epoch #197: loss=0.009720173256546102
Epoch #198: loss=0.0081215532440565
Epoch #199: loss=0.010121253257546245
Epoch #200: loss=0.008873788240764822
Epoch #201: loss=0.013603182624587241
Epoch #202: loss=0.013638871415843992
Epoch #203: loss=0.008250292905417032
Epoch #204: loss=0.006935659197010902
Epoch #205: loss=0.019017247811347216
Epoch #206: loss=0.009379840252051293
Epoch #207: loss=0.008833684228378262
Epoch #208: loss=0.006112763513686202
Epoch #209: loss=0.011865241244262154
Epoch #210: loss=0.019716992542052742
Epoch #211: loss=0.012002893560663835
Epoch #212: loss=0.024562717398932836
Epoch #213: loss=0.008539024278849996
Epoch #214: loss=0.005980030921979479
Epoch #215: loss=0.012027322483249498
Epoch #216: loss=0.008576985563130994
Epoch #217: loss=0.0075151194834459515
Epoch #218: loss=0.009022148259724158
Epoch #219: loss=0.007056999867493404
Epoch #220: loss=0.01428250965686513
Epoch #221: loss=0.008810700509663448
Epoch #222: loss=0.009327053325532
Epoch #223: loss=0.012382721170054713
Epoch #224: loss=0.007333784165823717
Epoch #225: loss=0.011854157004475712
Epoch #226: loss=0.00761680088951437
Epoch #227: loss=0.007727256133235458
Epoch #228: loss=0.009903869243214463
Epoch #229: loss=0.02564236963057241
Epoch #230: loss=0.00879119237411147
Epoch #231: loss=0.006353632842860441
Epoch #232: loss=0.009513745073325924
Epoch #233: loss=0.008717100797812924
Epoch #234: loss=0.00910575164997062
Epoch #235: loss=0.00580616184145759
Epoch #236: loss=0.011124791473754586
Epoch #237: loss=0.009388888214731701
Epoch #238: loss=0.008538157328347697
Epoch #239: loss=0.012094624514472397
Epoch #240: loss=0.008054729174683653
Epoch #241: loss=0.008561781366139457
Epoch #242: loss=0.007610236426928871
Epoch #243: loss=0.007618748906979282
Epoch #244: loss=0.007249813013180098
Epoch #245: loss=0.010873941714804963
Epoch #246: loss=0.009170785821126109
Epoch #247: loss=0.009095535097443675
Epoch #248: loss=0.007533189342933181
Epoch #249: loss=0.008818534685012898

Training time: 14:21:58.398273

Finished.
n2one setting etth2_electricity_traffic -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_electricity_traffic_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_electricity_traffic', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.21169e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.48385e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.5585505446146417, 'MAE': 0.5768215011683839}
Finished.
------------------------- record done -------------------------
n2one setting etth2_electricity_traffic -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_electricity_traffic_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_electricity_traffic', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.37996e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.346846433296361, 'MAE': 0.392741220870937}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_electricity_weather', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_electricity_weather_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.802015444316433
Epoch #1: loss=0.8771621431671294
Epoch #2: loss=0.6134810883783351
Epoch #3: loss=0.45003618270495516
Epoch #4: loss=0.42163665685276525
Epoch #5: loss=0.38660614024111106
Epoch #6: loss=0.313326192272585
Epoch #7: loss=0.30539217936453844
Epoch #8: loss=0.2641945888767135
Epoch #9: loss=0.24784678765862
Epoch #10: loss=0.21078592357830814
Epoch #11: loss=0.21717946521811565
Epoch #12: loss=0.1863135459838109
Epoch #13: loss=0.1758617564383368
Epoch #14: loss=0.1702797132949371
Epoch #15: loss=0.16219527691097582
Epoch #16: loss=0.16598904972611847
Epoch #17: loss=0.13536381806736275
Epoch #18: loss=0.10019462773481667
Epoch #19: loss=0.1463367805347941
Epoch #20: loss=0.11979286512623062
Epoch #21: loss=0.1019002978537379
Epoch #22: loss=0.10498378231153313
Epoch #23: loss=0.09999664137297767
Epoch #24: loss=0.10088469585835261
Epoch #25: loss=0.08136879639584298
Epoch #26: loss=0.07455201775077624
Epoch #27: loss=0.07025805358264574
Epoch #28: loss=0.08304004816043764
Epoch #29: loss=0.07701204945649004
Epoch #30: loss=0.07361923868236485
Epoch #31: loss=0.0634213594567178
Epoch #32: loss=0.04871184338741846
Epoch #33: loss=0.054448774375158264
Epoch #34: loss=0.07048767296029097
Epoch #35: loss=0.07769244813918015
Epoch #36: loss=0.05478312251405359
Epoch #37: loss=0.048685256222731274
Epoch #38: loss=0.050422548142782714
Epoch #39: loss=0.056919489329480856
Epoch #40: loss=0.03939421685599317
Epoch #41: loss=0.04085106865731778
Epoch #42: loss=0.0361919610933427
Epoch #43: loss=0.0498417444431123
Epoch #44: loss=0.04787186362864818
Epoch #45: loss=0.039023976679628265
Epoch #46: loss=0.03717927921479199
Epoch #47: loss=0.044434501431714006
Epoch #48: loss=0.045128778075683586
Epoch #49: loss=0.03574418524046044
Epoch #50: loss=0.04688010378977505
Epoch #51: loss=0.05068994311110701
Epoch #52: loss=0.039834902594839405
Epoch #53: loss=0.03304968124662005
Epoch #54: loss=0.031445369189526194
Epoch #55: loss=0.029025128002391633
Epoch #56: loss=0.033146999403439716
Epoch #57: loss=0.046932387956297075
Epoch #58: loss=0.02823725318184943
Epoch #59: loss=0.04216192880912426
Epoch #60: loss=0.035582502586977545
Epoch #61: loss=0.03456047135023769
Epoch #62: loss=0.029325967787444004
Epoch #63: loss=0.02722588132430226
Epoch #64: loss=0.029112657899429
Epoch #65: loss=0.02682422846753024
Epoch #66: loss=0.023970366978496943
Epoch #67: loss=0.0301571436940645
Epoch #68: loss=0.024893393323396327
Epoch #69: loss=0.03210733194705914
Epoch #70: loss=0.0389516165214959
Epoch #71: loss=0.03916084224990921
Epoch #72: loss=0.019976853763639908
Epoch #73: loss=0.025791369522934895
Epoch #74: loss=0.06964268658762682
Epoch #75: loss=0.03014534071093099
Epoch #76: loss=0.02179639352555255
Epoch #77: loss=0.020926360293465146
Epoch #78: loss=0.020677350704837064
Epoch #79: loss=0.026360864317278764
Epoch #80: loss=0.028656136633244234
Epoch #81: loss=0.02398252786212143
Epoch #82: loss=0.021214209401277603
Epoch #83: loss=0.03075545157340755
Epoch #84: loss=0.01965848151180041
Epoch #85: loss=0.02723158856901198
Epoch #86: loss=0.06080545244855533
Epoch #87: loss=0.02741503815849359
Epoch #88: loss=0.01795681937772644
Epoch #89: loss=0.021820927000312546
Epoch #90: loss=0.038462207508260265
Epoch #91: loss=0.01860931035677776
Epoch #92: loss=0.02125224456622523
Epoch #93: loss=0.025228390242578197
Epoch #94: loss=0.023527258573662974
Epoch #95: loss=0.02387163384934614
Epoch #96: loss=0.0205892958223825
Epoch #97: loss=0.020861909926032363
Epoch #98: loss=0.02189106337586681
Epoch #99: loss=0.031813215453830146
Epoch #100: loss=0.03927033262276012
Epoch #101: loss=0.02100588226037121
Epoch #102: loss=0.02392203526112309
Epoch #103: loss=0.026834336285068955
Epoch #104: loss=0.01921627147627684
Epoch #105: loss=0.019615769581139184
Epoch #106: loss=0.02293253594208351
Epoch #107: loss=0.016901937035329398
Epoch #108: loss=0.021080183978935723
Epoch #109: loss=0.02221122994396762
Epoch #110: loss=0.02165269909810017
Epoch #111: loss=0.016781032980731452
Epoch #112: loss=0.021125569513743732
Epoch #113: loss=0.014179627261602051
Epoch #114: loss=0.018817590515387093
Epoch #115: loss=0.019794546749106065
Epoch #116: loss=0.02650765434800684
Epoch #117: loss=0.01337008519242202
Epoch #118: loss=0.01643764754325825
Epoch #119: loss=0.0246094510115099
Epoch #120: loss=0.04255304015146195
Epoch #121: loss=0.027190999717564758
Epoch #122: loss=0.015537649076885813
Epoch #123: loss=0.017045859098145055
Epoch #124: loss=0.015780918733913997
Epoch #125: loss=0.01757144832445603
Epoch #126: loss=0.02961319626149811
Epoch #127: loss=0.016582987669001643
Epoch #128: loss=0.01999609668309653
Epoch #129: loss=0.015934816089400883
Epoch #130: loss=0.013592809404011048
Epoch #131: loss=0.01751319844358585
Epoch #132: loss=0.014648281531586012
Epoch #133: loss=0.011889163909169534
Epoch #134: loss=0.015568257496369304
Epoch #135: loss=0.03634584262884238
Epoch #136: loss=0.028051613026632703
Epoch #137: loss=0.014357990619139798
Epoch #138: loss=0.015224952046992257
Epoch #139: loss=0.015226133323292968
Epoch #140: loss=0.015030078432558231
Epoch #141: loss=0.010709171637558605
Epoch #142: loss=0.021212117732989227
Epoch #143: loss=0.012334933230360065
Epoch #144: loss=0.01541791308446298
Epoch #145: loss=0.013043091520943316
Epoch #146: loss=0.01606122515145242
Epoch #147: loss=0.01008913449087709
Epoch #148: loss=0.020379878428309503
Epoch #149: loss=0.02834278640947647
Epoch #150: loss=0.021260387384553707
Epoch #151: loss=0.012619235823003281
Epoch #152: loss=0.0157140084487415
Epoch #153: loss=0.015535040987434528
Epoch #154: loss=0.014325578476033978
Epoch #155: loss=0.021120169370186563
Epoch #156: loss=0.01421577523782781
Epoch #157: loss=0.014144709176748286
Epoch #158: loss=0.01569176612452783
Epoch #159: loss=0.0151926546445048
Epoch #160: loss=0.018576913686221896
Epoch #161: loss=0.016504269133066747
Epoch #162: loss=0.01927243511910724
Epoch #163: loss=0.016740026934260483
Epoch #164: loss=0.018165577611804408
Epoch #165: loss=0.01249238976973272
Epoch #166: loss=0.008475845115569073
Epoch #167: loss=0.02088475692211545
Epoch #168: loss=0.014837888594964087
Epoch #169: loss=0.01154988897659508
Epoch #170: loss=0.012234176679923447
Epoch #171: loss=0.0153252851851199
Epoch #172: loss=0.02329557550390972
Epoch #173: loss=0.027621357922463962
Epoch #174: loss=0.010906355932689045
Epoch #175: loss=0.012439659242613615
Epoch #176: loss=0.016248785750381384
Epoch #177: loss=0.017500405113336413
Epoch #178: loss=0.017552416248069115
Epoch #179: loss=0.017106431394968036
Epoch #180: loss=0.017823889823946153
Epoch #181: loss=0.016287747588114534
Epoch #182: loss=0.010802495787179987
Epoch #183: loss=0.02202470362183801
Epoch #184: loss=0.015513170002775509
Epoch #185: loss=0.02396875218386988
Epoch #186: loss=0.02018583253256866
Epoch #187: loss=0.02038853317183458
Epoch #188: loss=0.015630952047715543
Epoch #189: loss=0.013928903699398703
Epoch #190: loss=0.01311722666529628
Epoch #191: loss=0.01413279761503369
Epoch #192: loss=0.020651158567756088
Epoch #193: loss=0.009967604584960361
Epoch #194: loss=0.014098367989303329
Epoch #195: loss=0.007288565013954274
Epoch #196: loss=0.012794545428409099
Epoch #197: loss=0.016707579334632173
Epoch #198: loss=0.016278768556638446
Epoch #199: loss=0.01111062613766743
Epoch #200: loss=0.016186098640078896
Epoch #201: loss=0.010750985355527497
Epoch #202: loss=0.01624006823022287
Epoch #203: loss=0.012409515821030968
Epoch #204: loss=0.019986961751197605
Epoch #205: loss=0.019075388430340196
Epoch #206: loss=0.01426850936732697
Epoch #207: loss=0.00996982151917695
Epoch #208: loss=0.009659820402009507
Epoch #209: loss=0.021520998536761704
Epoch #210: loss=0.016483455816794206
Epoch #211: loss=0.024331625994613214
Epoch #212: loss=0.01839010400410168
Epoch #213: loss=0.012022218895608448
Epoch #214: loss=0.01278377226614696
Epoch #215: loss=0.011748140437415365
Epoch #216: loss=0.012996706209131674
Epoch #217: loss=0.010479864322446882
Epoch #218: loss=0.016760687654957012
Epoch #219: loss=0.006605730548451357
Epoch #220: loss=0.014227680058306014
Epoch #221: loss=0.011514420755517321
Epoch #222: loss=0.014218738795627081
Epoch #223: loss=0.012029528055267046
Epoch #224: loss=0.010133758583073214
Epoch #225: loss=0.021255148111597247
Epoch #226: loss=0.013562326082574351
Epoch #227: loss=0.012610910712914952
Epoch #228: loss=0.015260279273412369
Epoch #229: loss=0.009889057469189215
Epoch #230: loss=0.009932749345224472
Epoch #231: loss=0.013064239795995867
Epoch #232: loss=0.014485503042427203
Epoch #233: loss=0.012983333328469146
Epoch #234: loss=0.01876866137887592
Epoch #235: loss=0.014112160430333543
Epoch #236: loss=0.008851257155568466
Epoch #237: loss=0.016664358202531135
Epoch #238: loss=0.009646014501649813
Epoch #239: loss=0.010749474845042796
Epoch #240: loss=0.03230003862790395
Epoch #241: loss=0.011921129057066788
Epoch #242: loss=0.009667869811347492
Epoch #243: loss=0.016334105202287574
Epoch #244: loss=0.011107457965963631
Epoch #245: loss=0.009472638320264612
Epoch #246: loss=0.010722537958267076
Epoch #247: loss=0.014368698166076246
Epoch #248: loss=0.026411157828906292
Epoch #249: loss=0.016064412523873972

Training time: 4:56:21.483558

Finished.
n2one setting etth2_electricity_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_electricity_weather_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_electricity_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.18712e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.37881407630194713, 'MAE': 0.4064074879323397}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_electricity_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_electricity_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.6622518043787706
Epoch #1: loss=0.6929112208918446
Epoch #2: loss=0.4831202208020148
Epoch #3: loss=0.3778645516417566
Epoch #4: loss=0.3196936294525152
Epoch #5: loss=0.3082769400484505
Epoch #6: loss=0.2519417145688619
Epoch #7: loss=0.24510725773870945
Epoch #8: loss=0.228558133090181
Epoch #9: loss=0.18192050433052437
Epoch #10: loss=0.16872919689021296
Epoch #11: loss=0.17491722437331364
Epoch #12: loss=0.17571498103262412
Epoch #13: loss=0.14582481011304826
Epoch #14: loss=0.11597610260581687
Epoch #15: loss=0.11889719333876633
Epoch #16: loss=0.10609944002880227
Epoch #17: loss=0.11820306527494852
Epoch #18: loss=0.10005871567963845
Epoch #19: loss=0.09461931015331564
Epoch #20: loss=0.09853411473089918
Epoch #21: loss=0.08443898520532198
Epoch #22: loss=0.08628852217225358
Epoch #23: loss=0.08525963583850257
Epoch #24: loss=0.08588523340378222
Epoch #25: loss=0.07197113289675187
Epoch #26: loss=0.07556962123185042
Epoch #27: loss=0.05796285087542076
Epoch #28: loss=0.06059342164302334
Epoch #29: loss=0.05034776179430386
Epoch #30: loss=0.06265667096955613
Epoch #31: loss=0.060697099788480306
Epoch #32: loss=0.04477383238346582
Epoch #33: loss=0.05520517485898121
Epoch #34: loss=0.05168340250453357
Epoch #35: loss=0.05955716003137197
Epoch #36: loss=0.06483292477371703
Epoch #37: loss=0.045283696155474035
Epoch #38: loss=0.04533903805921519
Epoch #39: loss=0.04360528060490088
Epoch #40: loss=0.0395661300786915
Epoch #41: loss=0.041671868223125956
Epoch #42: loss=0.04274767519659474
Epoch #43: loss=0.034203078340007256
Epoch #44: loss=0.04763346991066577
Epoch #45: loss=0.05242399230787885
Epoch #46: loss=0.038045868093225486
Epoch #47: loss=0.034626434916087113
Epoch #48: loss=0.033501498122599775
Epoch #49: loss=0.03329674821067047
Epoch #50: loss=0.03924988449407032
Epoch #51: loss=0.03840207510594545
Epoch #52: loss=0.04255508966854818
Epoch #53: loss=0.04101424561910486
Epoch #54: loss=0.055811284186174384
Epoch #55: loss=0.03684752631635915
Epoch #56: loss=0.033704525064898745
Epoch #57: loss=0.03772224010927381
Epoch #58: loss=0.037187474369559256
Epoch #59: loss=0.03651057601001369
Epoch #60: loss=0.0285146767692779
Epoch #61: loss=0.04648855626804843
Epoch #62: loss=0.03883373766092561
Epoch #63: loss=0.02807528788564793
Epoch #64: loss=0.027828131088470053
Epoch #65: loss=0.03174830231000669
Epoch #66: loss=0.027514102565744127
Epoch #67: loss=0.02817732262822877
Epoch #68: loss=0.024237701847076614
Epoch #69: loss=0.0262676941018158
Epoch #70: loss=0.047425731930984295
Epoch #71: loss=0.0697736092967846
Epoch #72: loss=0.0281048492892989
Epoch #73: loss=0.02554264653839969
Epoch #74: loss=0.026770285852849372
Epoch #75: loss=0.03118308267689177
Epoch #76: loss=0.03524266039243057
Epoch #77: loss=0.029384059311095848
Epoch #78: loss=0.02099891459996191
Epoch #79: loss=0.025674663138661777
Epoch #80: loss=0.03640680061757199
Epoch #81: loss=0.03250088670375546
Epoch #82: loss=0.03054979197310916
Epoch #83: loss=0.027798648392490577
Epoch #84: loss=0.022788691256469713
Epoch #85: loss=0.027412648901753572
Epoch #86: loss=0.02144812912662192
Epoch #87: loss=0.030065847524037098
Epoch #88: loss=0.02329775116664851
Epoch #89: loss=0.029016621366498015
Epoch #90: loss=0.02603741492445503
Epoch #91: loss=0.022199417219477862
Epoch #92: loss=0.03615074186174232
Epoch #93: loss=0.02989929580750565
Epoch #94: loss=0.02904878252766572
Epoch #95: loss=0.027985530590480527
Epoch #96: loss=0.025306652152115323
Epoch #97: loss=0.022556326537943233
Epoch #98: loss=0.034860018163661674
Epoch #99: loss=0.0330889873695837
Epoch #100: loss=0.03135223689016476
Epoch #101: loss=0.03438981933418074
Epoch #102: loss=0.028431381766235324
Epoch #103: loss=0.02637298403542012
Epoch #104: loss=0.03466233122145197
Epoch #105: loss=0.030414038874109144
Epoch #106: loss=0.03861132912078617
Epoch #107: loss=0.03972368485674018
Epoch #108: loss=0.038791106832269134
Epoch #109: loss=0.02098538146570458
Epoch #110: loss=0.024218092488375816
Epoch #111: loss=0.03836409602046756
Epoch #112: loss=0.024715670897941373
Epoch #113: loss=0.01505033944652366
Epoch #114: loss=0.016077753459588468
Epoch #115: loss=0.02610500462712177
Epoch #116: loss=0.02243086390721839
Epoch #117: loss=0.02049190785570924
Epoch #118: loss=0.02383795690998557
Epoch #119: loss=0.01797956069917529
Epoch #120: loss=0.04632190625332961
Epoch #121: loss=0.01602803381891655
Epoch #122: loss=0.019782970297369286
Epoch #123: loss=0.01604814272416531
Epoch #124: loss=0.038823117032734444
Epoch #125: loss=0.020183838632614685
Epoch #126: loss=0.02526540656098015
Epoch #127: loss=0.018483430509583003
Epoch #128: loss=0.02316671301932296
Epoch #129: loss=0.02333931608639735
Epoch #130: loss=0.012276045615657321
Epoch #131: loss=0.01844362190119379
Epoch #132: loss=0.017765821527323818
Epoch #133: loss=0.027533646411376095
Epoch #134: loss=0.022334129064672328
Epoch #135: loss=0.01828687116254254
Epoch #136: loss=0.0160796893816864
Epoch #137: loss=0.022086471920331297
Epoch #138: loss=0.0168697407226275
Epoch #139: loss=0.015554828189210855
Epoch #140: loss=0.01618289869483782
Epoch #141: loss=0.02095045115233266
Epoch #142: loss=0.015344246080660793
Epoch #143: loss=0.015815651208305054
Epoch #144: loss=0.015450116928626639
Epoch #145: loss=0.015183066010303307
Epoch #146: loss=0.015302384027780221
Epoch #147: loss=0.06562618487216587
Epoch #148: loss=0.02572547251093922
Epoch #149: loss=0.03924814217593632
Epoch #150: loss=0.014845195441012038
Epoch #151: loss=0.015256326425948092
Epoch #152: loss=0.019255929160689925
Epoch #153: loss=0.014021100673181493
Epoch #154: loss=0.013781111372996488
Epoch #155: loss=0.015858948009866123
Epoch #156: loss=0.01570730742276369
Epoch #157: loss=0.026720875350292772
Epoch #158: loss=0.037429197620700246
Epoch #159: loss=0.023250717667993047
Epoch #160: loss=0.026698234273291228
Epoch #161: loss=0.01814541693844755
Epoch #162: loss=0.017509375875912763
Epoch #163: loss=0.035027191882233764
Epoch #164: loss=0.02302777859776619
Epoch #165: loss=0.014940999781607562
Epoch #166: loss=0.014874278230785248
Epoch #167: loss=0.014840283990668553
Epoch #168: loss=0.025642721977592806
Epoch #169: loss=0.019097226267019454
Epoch #170: loss=0.020231189246260328
Epoch #171: loss=0.015608147178552047
Epoch #172: loss=0.026151910054198067
Epoch #173: loss=0.017942786733155594
Epoch #174: loss=0.012112020198574533
Epoch #175: loss=0.023728639022270466
Epoch #176: loss=0.032042229000667465
Epoch #177: loss=0.018539223009741233
Epoch #178: loss=0.01491627257512716
Epoch #179: loss=0.016728770670548936
Epoch #180: loss=0.014644524196011758
Epoch #181: loss=0.01617717471041639
Epoch #182: loss=0.019576579064700388
Epoch #183: loss=0.017742940108638278
Epoch #184: loss=0.02249705130608553
Epoch #185: loss=0.013464988461367153
Epoch #186: loss=0.015789714205658084
Epoch #187: loss=0.016376066509110387
Epoch #188: loss=0.017077357377621366
Epoch #189: loss=0.022140232920459572
Epoch #190: loss=0.022842565385958767
Epoch #191: loss=0.023964428398487923
Epoch #192: loss=0.016589253706202033
Epoch #193: loss=0.014192426610818421
Epoch #194: loss=0.014499919751653493
Epoch #195: loss=0.015114408108707894
Epoch #196: loss=0.02217851239038282
Epoch #197: loss=0.01049474891529133
Epoch #198: loss=0.011728059238694619
Epoch #199: loss=0.012312850325716204
Epoch #200: loss=0.010790535439376808
Epoch #201: loss=0.01176217814359656
Epoch #202: loss=0.020736222036898004
Epoch #203: loss=0.015246735368453387
Epoch #204: loss=0.01264107038419059
Epoch #205: loss=0.018211613327106795
Epoch #206: loss=0.018732127703818453
Epoch #207: loss=0.025828456236576175
Epoch #208: loss=0.026397633946630993
Epoch #209: loss=0.03164821867817193
Epoch #210: loss=0.017597791501473347
Epoch #211: loss=0.01719809639152594
Epoch #212: loss=0.02294774980120045
Epoch #213: loss=0.02662998635787517
Epoch #214: loss=0.020148852512474627
Epoch #215: loss=0.018250927579217768
Epoch #216: loss=0.014951830346208658
Epoch #217: loss=0.015421344562907637
Epoch #218: loss=0.019564451651517413
Epoch #219: loss=0.013949796632957822
Epoch #220: loss=0.017401870654534184
Epoch #221: loss=0.027110380644444376
Epoch #222: loss=0.02607987157067068
Epoch #223: loss=0.014640667256355214
Epoch #224: loss=0.017071456921344395
Epoch #225: loss=0.014290709832753887
Epoch #226: loss=0.018308201770975887
Epoch #227: loss=0.014653756678204186
Epoch #228: loss=0.010425630467839906
Epoch #229: loss=0.01275076104875119
Epoch #230: loss=0.015371068630234472
Epoch #231: loss=0.014810845912247064
Epoch #232: loss=0.020808664285834225
Epoch #233: loss=0.015045264090683
Epoch #234: loss=0.014675250966146927
Epoch #235: loss=0.010898032447065427
Epoch #236: loss=0.010468729129743656
Epoch #237: loss=0.025309075001305678
Epoch #238: loss=0.030063923530785058
Epoch #239: loss=0.021599279395775824
Epoch #240: loss=0.017633133587272216
Epoch #241: loss=0.011058379452151712
Epoch #242: loss=0.01319094363039074
Epoch #243: loss=0.013009414555459184
Epoch #244: loss=0.01643866040224869
Epoch #245: loss=0.0224119315208511
Epoch #246: loss=0.027404960472874034
Epoch #247: loss=0.022274148934056506
Epoch #248: loss=0.01565043811777806
Epoch #249: loss=0.011527354974792356

Training time: 4:39:40.682511

Finished.
n2one setting etth2_electricity_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_electricity_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_electricity_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.45294e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.03809e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.45294e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4722468348176715, 'MAE': 0.5010274637570263}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_traffic_weather', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_traffic_weather_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.1377890298153435
Epoch #1: loss=0.4288818699188073
Epoch #2: loss=0.31373343314538454
Epoch #3: loss=0.23692985373502337
Epoch #4: loss=0.19263198397346049
Epoch #5: loss=0.16187433478885524
Epoch #6: loss=0.13980022285903632
Epoch #7: loss=0.12349416033349224
Epoch #8: loss=0.10793490891433295
Epoch #9: loss=0.09830256132252889
Epoch #10: loss=0.08335793803981896
Epoch #11: loss=0.08296387387574884
Epoch #12: loss=0.0763577586731889
Epoch #13: loss=0.07527090564536648
Epoch #14: loss=0.06441588792949915
Epoch #15: loss=0.0632800678108616
Epoch #16: loss=0.05404439978743773
Epoch #17: loss=0.06466133028851541
Epoch #18: loss=0.05209703718301679
Epoch #19: loss=0.048568135922951575
Epoch #20: loss=0.045032594736805966
Epoch #21: loss=0.05763770396087589
Epoch #22: loss=0.04703709742837383
Epoch #23: loss=0.05382057367225682
Epoch #24: loss=0.03914501920196763
Epoch #25: loss=0.0397163239989284
Epoch #26: loss=0.03524518943594654
Epoch #27: loss=0.034226056155566564
Epoch #28: loss=0.0378491705676343
Epoch #29: loss=0.03384151410626237
Epoch #30: loss=0.03224181982808273
Epoch #31: loss=0.03549967372566253
Epoch #32: loss=0.040103187753725275
Epoch #33: loss=0.024985943998433856
Epoch #34: loss=0.027026405367953442
Epoch #35: loss=0.02658171405613828
Epoch #36: loss=0.029915059563006642
Epoch #37: loss=0.031383951601452666
Epoch #38: loss=0.038908746371087335
Epoch #39: loss=0.02579848922538056
Epoch #40: loss=0.020599259597551097
Epoch #41: loss=0.03132843827333187
Epoch #42: loss=0.0402332722243213
Epoch #43: loss=0.021124665178397575
Epoch #44: loss=0.028648179245141993
Epoch #45: loss=0.02502561138706105
Epoch #46: loss=0.017982333589035643
Epoch #47: loss=0.01852489217895333
Epoch #48: loss=0.030137897003429854
Epoch #49: loss=0.016784458886246672
Epoch #50: loss=0.022886505309497554
Epoch #51: loss=0.02349631712094272
Epoch #52: loss=0.023862861653181137
Epoch #53: loss=0.019423276336259246
Epoch #54: loss=0.024382874829364243
Epoch #55: loss=0.026491957271534056
Epoch #56: loss=0.022739504506569565
Epoch #57: loss=0.019044046833208508
Epoch #58: loss=0.02511460129913026
Epoch #59: loss=0.01903597014311014
Epoch #60: loss=0.021302085442991416
Epoch #61: loss=0.018507644908623666
Epoch #62: loss=0.016110048383505566
Epoch #63: loss=0.021812058199852623
Epoch #64: loss=0.017849623378269976
Epoch #65: loss=0.0260339662695418
Epoch #66: loss=0.02019095133636251
Epoch #67: loss=0.017733354904095763
Epoch #68: loss=0.015263932642355229
Epoch #69: loss=0.015701463963971707
Epoch #70: loss=0.02221194695345359
Epoch #71: loss=0.01866843036861112
Epoch #72: loss=0.02316007406350652
Epoch #73: loss=0.01954358361278369
Epoch #74: loss=0.01574364433197731
Epoch #75: loss=0.016151504046686888
Epoch #76: loss=0.02213071035539898
Epoch #77: loss=0.02549938138271292
Epoch #78: loss=0.026255645860290916
Epoch #79: loss=0.012536991313073847
Epoch #80: loss=0.018111437053469077
Epoch #81: loss=0.01430323844168767
Epoch #82: loss=0.023908439156171402
Epoch #83: loss=0.016461816086601622
Epoch #84: loss=0.012087759104695213
Epoch #85: loss=0.01983764259064669
Epoch #86: loss=0.02323257841362342
Epoch #87: loss=0.018961223443630593
Epoch #88: loss=0.018984068047733945
Epoch #89: loss=0.025638019677944865
Epoch #90: loss=0.013092283019535867
Epoch #91: loss=0.01467416963004117
Epoch #92: loss=0.017933656879981677
Epoch #93: loss=0.020561225371573164
Epoch #94: loss=0.014946974623413736
Epoch #95: loss=0.013090160102733051
Epoch #96: loss=0.015042905154470198
Epoch #97: loss=0.018818894377844564
Epoch #98: loss=0.019589295362085937
Epoch #99: loss=0.02330690241069533
Epoch #100: loss=0.020272976862183413
Epoch #101: loss=0.01203001687870954
Epoch #102: loss=0.017872485539722437
Epoch #103: loss=0.017812154814405835
Epoch #104: loss=0.018145796560744793
Epoch #105: loss=0.019936785369125513
Epoch #106: loss=0.017372121401300247
Epoch #107: loss=0.0099130102716173
Epoch #108: loss=0.01620654822727171
Epoch #109: loss=0.02496536987340702
Epoch #110: loss=0.014740963105447903
Epoch #111: loss=0.007998200361623414
Epoch #112: loss=0.01558142086008418
Epoch #113: loss=0.012723637930170877
Epoch #114: loss=0.010811291629752253
Epoch #115: loss=0.01681911056778685
Epoch #116: loss=0.020962817971945828
Epoch #117: loss=0.013654224699826172
Epoch #118: loss=0.012856774486298283
Epoch #119: loss=0.02466036989138977
Epoch #120: loss=0.013464457392542982
Epoch #121: loss=0.0174440145776438
Epoch #122: loss=0.01532067392963146
Epoch #123: loss=0.015539055065623895
Epoch #124: loss=0.017698764033253336
Epoch #125: loss=0.014673841575696523
Epoch #126: loss=0.012152016914954315
Epoch #127: loss=0.016230574711915313
Epoch #128: loss=0.013508105976994842
Epoch #129: loss=0.020954781700239136
Epoch #130: loss=0.012203950942565515
Epoch #131: loss=0.012131240256078667
Epoch #132: loss=0.014810301880703395
Epoch #133: loss=0.011337356203640212
Epoch #134: loss=0.020909812010554127
Epoch #135: loss=0.010263265674808921
Epoch #136: loss=0.011883792359584828
Epoch #137: loss=0.014954237464102254
Epoch #138: loss=0.009902013232237498
Epoch #139: loss=0.0160270152223952
Epoch #140: loss=0.013272610907124189
Epoch #141: loss=0.0156691658399367
Epoch #142: loss=0.011400169708607353
Epoch #143: loss=0.016144441728650556
Epoch #144: loss=0.01763658506672845
Epoch #145: loss=0.009298205608469513
Epoch #146: loss=0.011993073470800772
Epoch #147: loss=0.011169142792763594
Epoch #148: loss=0.01522961294429062
Epoch #149: loss=0.015384931367003833
Epoch #150: loss=0.013339292208954181
Epoch #151: loss=0.016618748335883168
Epoch #152: loss=0.01734429379738477
Epoch #153: loss=0.01149871390626386
Epoch #154: loss=0.018813841950438406
Epoch #155: loss=0.013516175948075596
Epoch #156: loss=0.009564088035229198
Epoch #157: loss=0.011405359224257627
Epoch #158: loss=0.01332362265198733
Epoch #159: loss=0.009951276252433682
Epoch #160: loss=0.014011274535318202
Epoch #161: loss=0.01273659894564163
Epoch #162: loss=0.012345976323505875
Epoch #163: loss=0.008665261615500864
Epoch #164: loss=0.012963822138379977
Epoch #165: loss=0.009450774456994795
Epoch #166: loss=0.012485636894294586
Epoch #167: loss=0.015184113538925478
Epoch #168: loss=0.014529177097294106
Epoch #169: loss=0.009834822438396812
Epoch #170: loss=0.013797606951583115
Epoch #171: loss=0.011226866192198778
Epoch #172: loss=0.016755352163525652
Epoch #173: loss=0.012077916395489852
Epoch #174: loss=0.010343196294898058
Epoch #175: loss=0.011581750989367395
Epoch #176: loss=0.010079200406540601
Epoch #177: loss=0.012374420438349434
Epoch #178: loss=0.014990563251437923
Epoch #179: loss=0.01682931657239285
Epoch #180: loss=0.010977945796164616
Epoch #181: loss=0.010613001220551964
Epoch #182: loss=0.01231888180358632
Epoch #183: loss=0.010033800486502382
Epoch #184: loss=0.0185815267735382
Epoch #185: loss=0.010698272606752053
Epoch #186: loss=0.012564048567294487
Epoch #187: loss=0.010659824644850161
Epoch #188: loss=0.009040273988034768
Epoch #189: loss=0.007855832445485711
Epoch #190: loss=0.011225934703925406
Epoch #191: loss=0.016977324642674468
Epoch #192: loss=0.011487854925256129
Epoch #193: loss=0.013138309179079412
Epoch #194: loss=0.013457660870815175
Epoch #195: loss=0.010019726436468122
Epoch #196: loss=0.014755008784259342
Epoch #197: loss=0.01019957446754113
Epoch #198: loss=0.016069701754529674
Epoch #199: loss=0.015490331949780606
Epoch #200: loss=0.00995561213205912
Epoch #201: loss=0.011315546761944567
Epoch #202: loss=0.008671889013926858
Epoch #203: loss=0.01621797864534112
Epoch #204: loss=0.006670313261777121
Epoch #205: loss=0.012927481358709574
Epoch #206: loss=0.04606991403602199
Epoch #207: loss=0.015783105815556576
Epoch #208: loss=0.011000666620815303
Epoch #209: loss=0.013230853248525777
Epoch #210: loss=0.015164398657081274
Epoch #211: loss=0.013371016049394046
Epoch #212: loss=0.018770980196261933
Epoch #213: loss=0.010701104989938709
Epoch #214: loss=0.008551897532543994
Epoch #215: loss=0.015420946131548818
Epoch #216: loss=0.009458892411804712
Epoch #217: loss=0.007358737671214505
Epoch #218: loss=0.014174257031451344
Epoch #219: loss=0.024645653563582823
Epoch #220: loss=0.010230369369926025
Epoch #221: loss=0.009866861787064692
Epoch #222: loss=0.010942349800262496
Epoch #223: loss=0.02173343987308843
Epoch #224: loss=0.010883886059801427
Epoch #225: loss=0.009933936545204542
Epoch #226: loss=0.00667572874215226
Epoch #227: loss=0.01041803146363236
Epoch #228: loss=0.013207282568620747
Epoch #229: loss=0.018358938333802133
Epoch #230: loss=0.01020024059331903
Epoch #231: loss=0.009916459733907097
Epoch #232: loss=0.00852919145204828
Epoch #233: loss=0.010629547740086944
Epoch #234: loss=0.009764493811064577
Epoch #235: loss=0.017982310022993435
Epoch #236: loss=0.023871866763242933
Epoch #237: loss=0.027785002722082317
Epoch #238: loss=0.014334020513716654
Epoch #239: loss=0.00827447216168915
Epoch #240: loss=0.009503731204264449
Epoch #241: loss=0.00637792154965147
Epoch #242: loss=0.01282875043323443
Epoch #243: loss=0.009408323439462475
Epoch #244: loss=0.011195615536140477
Epoch #245: loss=0.006947933154196255
Epoch #246: loss=0.010933880360183104
Epoch #247: loss=0.009713165848772822
Epoch #248: loss=0.014423913864663402
Epoch #249: loss=0.008159637532369935

Training time: 10:27:22.048726

Finished.
n2one setting etth2_traffic_weather -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_traffic_weather_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_traffic_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.09131e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.17126e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.4173e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.09131e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.41377130668170564, 'MAE': 0.4545685849558007}
Finished.
------------------------- record done -------------------------
n2one setting etth2_traffic_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_traffic_weather_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_traffic_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.93067e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.62268443568659, 'MAE': 0.48472867460634894}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_traffic_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_traffic_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.1067224444997759
Epoch #1: loss=0.40571834923468
Epoch #2: loss=0.28015385669238757
Epoch #3: loss=0.2161164884981163
Epoch #4: loss=0.18458261225317332
Epoch #5: loss=0.15071324775571018
Epoch #6: loss=0.12805007788285766
Epoch #7: loss=0.09627814842611042
Epoch #8: loss=0.09242413820063816
Epoch #9: loss=0.07625485482512036
Epoch #10: loss=0.07329129483529548
Epoch #11: loss=0.06912535971971473
Epoch #12: loss=0.06714698484224801
Epoch #13: loss=0.06800518233908878
Epoch #14: loss=0.05261140096053362
Epoch #15: loss=0.05027773634433967
Epoch #16: loss=0.04420553869010292
Epoch #17: loss=0.047729664248018236
Epoch #18: loss=0.045015597811017605
Epoch #19: loss=0.047551387124519666
Epoch #20: loss=0.040762615686934546
Epoch #21: loss=0.046296672283872506
Epoch #22: loss=0.028599164375271796
Epoch #23: loss=0.0350078331301798
Epoch #24: loss=0.036882894897239844
Epoch #25: loss=0.033336486442661295
Epoch #26: loss=0.03185248669919727
Epoch #27: loss=0.03560787174312298
Epoch #28: loss=0.03804181188747431
Epoch #29: loss=0.03511546452172916
Epoch #30: loss=0.03270278170032102
Epoch #31: loss=0.029734908464813907
Epoch #32: loss=0.03118748012999181
Epoch #33: loss=0.03608755250498567
Epoch #34: loss=0.03123634191497549
Epoch #35: loss=0.028925245533115363
Epoch #36: loss=0.028104372213378512
Epoch #37: loss=0.02302017356124372
Epoch #38: loss=0.026553019540099813
Epoch #39: loss=0.03033737083559828
Epoch #40: loss=0.023093219800159853
Epoch #41: loss=0.022966728674419363
Epoch #42: loss=0.032526273713256004
Epoch #43: loss=0.02502677374625071
Epoch #44: loss=0.024940776439108053
Epoch #45: loss=0.024761424494159655
Epoch #46: loss=0.024811326765705924
Epoch #47: loss=0.022758559766212244
Epoch #48: loss=0.020638228827695063
Epoch #49: loss=0.027693749739689712
Epoch #50: loss=0.025321863821183066
Epoch #51: loss=0.02518074551073966
Epoch #52: loss=0.024648999794388452
Epoch #53: loss=0.018103768248145524
Epoch #54: loss=0.02523011116240866
Epoch #55: loss=0.02411752487899164
Epoch #56: loss=0.022436349146626147
Epoch #57: loss=0.024723080892971757
Epoch #58: loss=0.023916935275001886
Epoch #59: loss=0.022868797245160374
Epoch #60: loss=0.023645445464155986
Epoch #61: loss=0.020996508807060176
Epoch #62: loss=0.01889299104015949
Epoch #63: loss=0.020091207858606186
Epoch #64: loss=0.020706735117620594
Epoch #65: loss=0.027311642524085942
Epoch #66: loss=0.016409838543737575
Epoch #67: loss=0.01815885128196517
Epoch #68: loss=0.023738857838757944
Epoch #69: loss=0.02119379821796944
Epoch #70: loss=0.027399490827544802
Epoch #71: loss=0.026715151441682815
Epoch #72: loss=0.015032849451687619
Epoch #73: loss=0.0182369556718696
Epoch #74: loss=0.016633898590783246
Epoch #75: loss=0.029710183686819967
Epoch #76: loss=0.03663406138378169
Epoch #77: loss=0.018088872867961337
Epoch #78: loss=0.02090619061482824
Epoch #79: loss=0.02517509332856964
Epoch #80: loss=0.020615443114706068
Epoch #81: loss=0.01764019569499549
Epoch #82: loss=0.020692544605130564
Epoch #83: loss=0.019874227288418832
Epoch #84: loss=0.01432853566956289
Epoch #85: loss=0.018143798773261725
Epoch #86: loss=0.020963514091283986
Epoch #87: loss=0.021294808038025873
Epoch #88: loss=0.01722528946849049
Epoch #89: loss=0.015897906023240142
Epoch #90: loss=0.01766403942139147
Epoch #91: loss=0.017999996808360192
Epoch #92: loss=0.01722181786947906
Epoch #93: loss=0.019605517056263545
Epoch #94: loss=0.01960942989961003
Epoch #95: loss=0.017023002365503158
Epoch #96: loss=0.022673269414805946
Epoch #97: loss=0.018927447109904242
Epoch #98: loss=0.013422892476423264
Epoch #99: loss=0.02193300361174797
Epoch #100: loss=0.015087907172143757
Epoch #101: loss=0.012491231168348299
Epoch #102: loss=0.01894080739650459
Epoch #103: loss=0.017517264006713017
Epoch #104: loss=0.026510231174314086
Epoch #105: loss=0.015177495715184723
Epoch #106: loss=0.016824333692243496
Epoch #107: loss=0.015426837970601435
Epoch #108: loss=0.02171696573845642
Epoch #109: loss=0.021585103143229572
Epoch #110: loss=0.015346098761246811
Epoch #111: loss=0.015867147610619442
Epoch #112: loss=0.017624581057446645
Epoch #113: loss=0.017767523310519968
Epoch #114: loss=0.013626162885840103
Epoch #115: loss=0.014788508831503181
Epoch #116: loss=0.018720528457486077
Epoch #117: loss=0.013363677388310121
Epoch #118: loss=0.016332160650059303
Epoch #119: loss=0.016517768672334524
Epoch #120: loss=0.021802649954986996
Epoch #121: loss=0.015348374445568516
Epoch #122: loss=0.014815417066335407
Epoch #123: loss=0.024098546791103848
Epoch #124: loss=0.018636621479669793
Epoch #125: loss=0.01164389004548024
Epoch #126: loss=0.016762940653657143
Epoch #127: loss=0.01360555595930447
Epoch #128: loss=0.015934788047650906
Epoch #129: loss=0.013788996430300017
Epoch #130: loss=0.015033620260264061
Epoch #131: loss=0.019750867192216637
Epoch #132: loss=0.014558352359096405
Epoch #133: loss=0.01735961510817878
Epoch #134: loss=0.015212368152259362
Epoch #135: loss=0.011979047617971412
Epoch #136: loss=0.014820502891515604
Epoch #137: loss=0.016942217051068284
Epoch #138: loss=0.013737404654299635
Epoch #139: loss=0.01382018154300643
Epoch #140: loss=0.011965011628336691
Epoch #141: loss=0.015431044023823016
Epoch #142: loss=0.01987178016819953
Epoch #143: loss=0.01449876845937871
Epoch #144: loss=0.025077694747371315
Epoch #145: loss=0.0128883114775527
Epoch #146: loss=0.018568168214832655
Epoch #147: loss=0.011165953956838027
Epoch #148: loss=0.016670211731779315
Epoch #149: loss=0.02157215103008593
Epoch #150: loss=0.015417445595246106
Epoch #151: loss=0.012963398277614597
Epoch #152: loss=0.015050698546040962
Epoch #153: loss=0.014880852249568194
Epoch #154: loss=0.012644662924056199
Epoch #155: loss=0.015971967887510083
Epoch #156: loss=0.014949982872160051
Epoch #157: loss=0.014514297870823534
Epoch #158: loss=0.014668001672495932
Epoch #159: loss=0.010922276645903067
Epoch #160: loss=0.012107892460546837
Epoch #161: loss=0.01560840503984458
Epoch #162: loss=0.012123960045887372
Epoch #163: loss=0.019497778701516713
Epoch #164: loss=0.015249948237054665
Epoch #165: loss=0.016013916886480368
Epoch #166: loss=0.011996881465385498
Epoch #167: loss=0.011349871859479825
Epoch #168: loss=0.017089052623497032
Epoch #169: loss=0.013112937501313626
Epoch #170: loss=0.012560543867855246
Epoch #171: loss=0.01480981184261508
Epoch #172: loss=0.012619620899808144
Epoch #173: loss=0.011323158502718247
Epoch #174: loss=0.01874083732850818
Epoch #175: loss=0.011688125729323243
Epoch #176: loss=0.016605710209997217
Epoch #177: loss=0.013166312922239347
Epoch #178: loss=0.018170971155546004
Epoch #179: loss=0.014855166825907326
Epoch #180: loss=0.011964714535257296
Epoch #181: loss=0.01071288294178522
Epoch #182: loss=0.012030136021138981
Epoch #183: loss=0.014909560416054943
Epoch #184: loss=0.01810895908774464
Epoch #185: loss=0.011134693005166115
Epoch #186: loss=0.011949106525632944
Epoch #187: loss=0.013669726659272751
Epoch #188: loss=0.015347360669154177
Epoch #189: loss=0.01575367140315952
Epoch #190: loss=0.014809250571992526
Epoch #191: loss=0.012346238048303556
Epoch #192: loss=0.01347720334075387
Epoch #193: loss=0.014800079570360537
Epoch #194: loss=0.012285187973303958
Epoch #195: loss=0.02087488547980001
Epoch #196: loss=0.01008686228120193
Epoch #197: loss=0.0074410741839665675
Epoch #198: loss=0.0141515005445291
Epoch #199: loss=0.019511059641998958
Epoch #200: loss=0.011909248506826346
Epoch #201: loss=0.011090208757595062
Epoch #202: loss=0.009348443041054082
Epoch #203: loss=0.012099627572627624
Epoch #204: loss=0.01272590426933084
Epoch #205: loss=0.012878115139046775
Epoch #206: loss=0.01140773160598613
Epoch #207: loss=0.014744546781741391
Epoch #208: loss=0.020033057185282567
Epoch #209: loss=0.013666343293783276
Epoch #210: loss=0.009800195769185041
Epoch #211: loss=0.013497043405101314
Epoch #212: loss=0.015175498096773984
Epoch #213: loss=0.013338017769496646
Epoch #214: loss=0.00803737762659093
Epoch #215: loss=0.010011218785825468
Epoch #216: loss=0.012032533061298771
Epoch #217: loss=0.009469936169773402
Epoch #218: loss=0.015975200675123667
Epoch #219: loss=0.014643149564588327
Epoch #220: loss=0.01333077132635237
Epoch #221: loss=0.01130214721126245
Epoch #222: loss=0.019788740129211915
Epoch #223: loss=0.006934832225162366
Epoch #224: loss=0.01091670754415136
Epoch #225: loss=0.009618007482596707
Epoch #226: loss=0.012322204774533671
Epoch #227: loss=0.014396043136718412
Epoch #228: loss=0.010782010208061623
Epoch #229: loss=0.010458679340924206
Epoch #230: loss=0.015254097629034256
Epoch #231: loss=0.012592620069745524
Epoch #232: loss=0.01094649216573539
Epoch #233: loss=0.012226437461572278
Epoch #234: loss=0.01214098283396001
Epoch #235: loss=0.0167842301476493
Epoch #236: loss=0.007253178786058956
Epoch #237: loss=0.011353946292785234
Epoch #238: loss=0.009744023645040898
Epoch #239: loss=0.016710947827246407
Epoch #240: loss=0.01616254734016964
Epoch #241: loss=0.010519765241909453
Epoch #242: loss=0.010698605254810848
Epoch #243: loss=0.008823629760987084
Epoch #244: loss=0.009418434174958364
Epoch #245: loss=0.012509757289031103
Epoch #246: loss=0.006693167127313107
Epoch #247: loss=0.00991436979528851
Epoch #248: loss=0.013460763292097335
Epoch #249: loss=0.01263502880750636

Training time: 10:19:04.485056

Finished.
n2one setting etth2_traffic_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_traffic_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_traffic_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.09045e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.22882e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.79895e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.09045e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.399759870271256, 'MAE': 0.4497462646706903}
Finished.
------------------------- record done -------------------------
n2one setting etth2_traffic_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_traffic_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_traffic_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.9314e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.95744e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.9314e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.585748000009017, 'MAE': 0.6054993511762379}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_weather_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_weather_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=6.331331607772083
Epoch #1: loss=2.7398490527781045
Epoch #2: loss=2.329521507751651
Epoch #3: loss=2.403510230343516
Epoch #4: loss=2.1099595325749094
Epoch #5: loss=2.0763365437344805
Epoch #6: loss=1.9588718617834695
Epoch #7: loss=1.821077073492655
Epoch #8: loss=1.7475645309541283
Epoch #9: loss=1.639270503346513
Epoch #10: loss=1.639084766550762
Epoch #11: loss=1.4424170052132956
Epoch #12: loss=1.4643394423694145
Epoch #13: loss=1.4509019241100405
Epoch #14: loss=1.3256116829267361
Epoch #15: loss=1.2472551654024822
Epoch #16: loss=1.2365663037067507
Epoch #17: loss=1.136588132962948
Epoch #18: loss=1.0804562975720662
Epoch #19: loss=1.0974427141794345
Epoch #20: loss=0.9905461058384035
Epoch #21: loss=0.9772063290200582
Epoch #22: loss=1.0263693041917754
Epoch #23: loss=0.9678223554680987
Epoch #24: loss=0.9067000121605105
Epoch #25: loss=0.8978353389879552
Epoch #26: loss=0.939131556487665
Epoch #27: loss=1.141759338902264
Epoch #28: loss=1.0343489007252018
Epoch #29: loss=0.9176260203849979
Epoch #30: loss=0.9123322847412854
Epoch #31: loss=0.8935146971446711
Epoch #32: loss=0.8341948680761384
Epoch #33: loss=0.7613562854324899
Epoch #34: loss=0.7648905341218157
Epoch #35: loss=0.6719842596751887
Epoch #36: loss=0.7606644150687427
Epoch #37: loss=0.7311413128201555
Epoch #38: loss=0.6631341634727106
Epoch #39: loss=0.701785881344865
Epoch #40: loss=0.679201520070797
Epoch #41: loss=0.7272628996430374
Epoch #42: loss=0.6636241565390331
Epoch #43: loss=0.6011861853483247
Epoch #44: loss=0.7203495109953532
Epoch #45: loss=0.6670878631312672
Epoch #46: loss=0.6109811329260105
Epoch #47: loss=0.6276745018435688
Epoch #48: loss=0.5737467800698629
Epoch #49: loss=0.5661246434944432
Epoch #50: loss=0.5639180017680656
Epoch #51: loss=0.631186315199224
Epoch #52: loss=0.5370812757713038
Epoch #53: loss=0.5454940824973874
Epoch #54: loss=0.5217014507549566
Epoch #55: loss=0.523690435217648
Epoch #56: loss=0.5417756641783366
Epoch #57: loss=0.5228700884958593
Epoch #58: loss=0.5200875692251252
Epoch #59: loss=0.5638592272270017
Epoch #60: loss=0.4917383477455232
Epoch #61: loss=0.5092691081326183
Epoch #62: loss=0.5229661268431965
Epoch #63: loss=0.5105432053891624
Epoch #64: loss=0.4853508843154442
Epoch #65: loss=0.5326471510456829
Epoch #66: loss=0.5392951827223708
Epoch #67: loss=0.4796726652761785
Epoch #68: loss=0.42726990653247365
Epoch #69: loss=0.3939373435043707
Epoch #70: loss=0.4403250308298483
Epoch #71: loss=0.44019175884200307
Epoch #72: loss=0.34624874482794504
Epoch #73: loss=0.4635766072244179
Epoch #74: loss=0.4858273925577722
Epoch #75: loss=0.5903030750228138
Epoch #76: loss=0.5251925002510954
Epoch #77: loss=0.4456712458191848
Epoch #78: loss=0.6873609874306655
Epoch #79: loss=0.4462480079836962
Epoch #80: loss=0.391952024000447
Epoch #81: loss=0.4734859477456023
Epoch #82: loss=0.5306090574438979
Epoch #83: loss=0.4246763983150808
Epoch #84: loss=0.4097809580768027
Epoch #85: loss=0.3694731527712287
Epoch #86: loss=0.4402335286140442
Epoch #87: loss=0.34413333055449696
Epoch #88: loss=0.28679184579267736
Epoch #89: loss=0.36226535643019325
Epoch #90: loss=0.31048881607811624
Epoch #91: loss=0.2753728480964172
Epoch #92: loss=0.29057725555286174
Epoch #93: loss=0.23856682548435723
Epoch #94: loss=0.24216056433392735
Epoch #95: loss=0.2659131466615491
Epoch #96: loss=0.26645394941655604
Epoch #97: loss=0.2698750339630174
Epoch #98: loss=0.2247167961989961
Epoch #99: loss=0.29435824402948707
Epoch #100: loss=0.2723128753827839
Epoch #101: loss=0.28343740450899774
Epoch #102: loss=0.306355744600296
Epoch #103: loss=0.29681361993638483
Epoch #104: loss=0.33948520044001135
Epoch #105: loss=0.28424326748382756
Epoch #106: loss=0.26955425939181954
Epoch #107: loss=0.3189626048977782
Epoch #108: loss=0.27686117898400237
Epoch #109: loss=0.27802132597056833
Epoch #110: loss=0.2930544558458212
Epoch #111: loss=0.2908852082200167
Epoch #112: loss=0.26111406505834767
Epoch #113: loss=0.25499811150678775
Epoch #114: loss=0.271171444072956
Epoch #115: loss=0.24411400298519834
Epoch #116: loss=0.23268974745055523
Epoch #117: loss=0.25178971995667715
Epoch #118: loss=0.21192625873699422
Epoch #119: loss=0.2566387776012828
Epoch #120: loss=0.23814690531027027
Epoch #121: loss=0.23207680263170383
Epoch #122: loss=0.21500875019445653
Epoch #123: loss=0.2298109578650172
Epoch #124: loss=0.2747560161642912
Epoch #125: loss=0.30888906775451286
Epoch #126: loss=0.23963876559240063
Epoch #127: loss=0.20183138567499997
Epoch #128: loss=0.2075010451783494
Epoch #129: loss=0.26228594707279673
Epoch #130: loss=0.2447442270633651
Epoch #131: loss=0.213837992036488
Epoch #132: loss=0.17575488621141852
Epoch #133: loss=0.19319299417661456
Epoch #134: loss=0.1737947037852392
Epoch #135: loss=0.22716301915849127
Epoch #136: loss=0.17669975521360956
Epoch #137: loss=0.22103182517173814
Epoch #138: loss=0.24829991070962534
Epoch #139: loss=0.21805233608295277
Epoch #140: loss=0.2261696119860905
Epoch #141: loss=0.1987094413943407
Epoch #142: loss=0.19815694313587212
Epoch #143: loss=0.21162579681088284
Epoch #144: loss=0.1392519877451222
Epoch #145: loss=0.22494927748310856
Epoch #146: loss=0.28843702057876236
Epoch #147: loss=0.20789072008394613
Epoch #148: loss=0.22227912050921741
Epoch #149: loss=0.19612293036245718
Epoch #150: loss=0.18107408648583947
Epoch #151: loss=0.1514695996373165
Epoch #152: loss=0.16973657365434053
Epoch #153: loss=0.1543461271538967
Epoch #154: loss=0.1643701088501186
Epoch #155: loss=0.2168441195858688
Epoch #156: loss=0.17820967470363872
Epoch #157: loss=0.2236018395278512
Epoch #158: loss=0.18790974177238418
Epoch #159: loss=0.13516455298153365
Epoch #160: loss=0.1436413060419443
Epoch #161: loss=0.1533944332381574
Epoch #162: loss=0.18416742517090426
Epoch #163: loss=0.13098396079205885
Epoch #164: loss=0.1709225063734665
Epoch #165: loss=0.14741691529023937
Epoch #166: loss=0.16869542602358795
Epoch #167: loss=0.19630570791480018
Epoch #168: loss=0.16375098014023245
Epoch #169: loss=0.1630562746034163
Epoch #170: loss=0.21301565110319998
Epoch #171: loss=0.20111665647567772
Epoch #172: loss=0.15435342763255283
Epoch #173: loss=0.13369465283140902
Epoch #174: loss=0.14211404582530987
Epoch #175: loss=0.15567507513049172
Epoch #176: loss=0.14669959824077966
Epoch #177: loss=0.13170284073708988
Epoch #178: loss=0.1580153160342356
Epoch #179: loss=0.13110056056118594
Epoch #180: loss=0.12484177828925412
Epoch #181: loss=0.13887685187524412
Epoch #182: loss=0.1963716816702267
Epoch #183: loss=0.1732112982469361
Epoch #184: loss=0.12990099382473203
Epoch #185: loss=0.12255337448200075
Epoch #186: loss=0.12120462109039469
Epoch #187: loss=0.1181277458260699
Epoch #188: loss=0.11510814049440186
Epoch #189: loss=0.10297079484273748
Epoch #190: loss=0.08482254001243812
Epoch #191: loss=0.08995095354209585
Epoch #192: loss=0.10745383835420376
Epoch #193: loss=0.1138099829961614
Epoch #194: loss=0.13078386009466358
Epoch #195: loss=0.16185481959908474
Epoch #196: loss=0.14787248285805307
Epoch #197: loss=0.10664660506313894
Epoch #198: loss=0.1622472099687268
Epoch #199: loss=0.12806268940429863
Epoch #200: loss=0.14947265486528233
Epoch #201: loss=0.14499564232622705
Epoch #202: loss=0.11674572004959351
Epoch #203: loss=0.08099829401003152
Epoch #204: loss=0.1680582928948286
Epoch #205: loss=0.15145275505577646
Epoch #206: loss=0.1441389089677392
Epoch #207: loss=0.18282249956051025
Epoch #208: loss=0.10373208644550021
Epoch #209: loss=0.17133238643589543
Epoch #210: loss=0.2680610563242581
Epoch #211: loss=0.3407229176018296
Epoch #212: loss=0.2592486601050307
Epoch #213: loss=0.32673957062567155
Epoch #214: loss=0.1949201603306503
Epoch #215: loss=0.15465851564232896
Epoch #216: loss=0.17178865108729863
Epoch #217: loss=0.17477734123424785
Epoch #218: loss=0.0977152023555302
Epoch #219: loss=0.12469806154144973
Epoch #220: loss=0.11024621778690233
Epoch #221: loss=0.11100612471743328
Epoch #222: loss=0.10792554374329927
Epoch #223: loss=0.12688974045762202
Epoch #224: loss=0.11682631111726528
Epoch #225: loss=0.1077023034052151
Epoch #226: loss=0.10801905884248454
Epoch #227: loss=0.08014222915943076
Epoch #228: loss=0.09143335572103174
Epoch #229: loss=0.1185227349491381
Epoch #230: loss=0.1371329343173562
Epoch #231: loss=0.17146889815425
Epoch #232: loss=0.1399254194665246
Epoch #233: loss=0.09372394663713328
Epoch #234: loss=0.10922924869852822
Epoch #235: loss=0.12137975389274155
Epoch #236: loss=0.09706254269382576
Epoch #237: loss=0.09667245125988634
Epoch #238: loss=0.09990994014391084
Epoch #239: loss=0.10392116930154038
Epoch #240: loss=0.1114890598578424
Epoch #241: loss=0.08986266109547238
Epoch #242: loss=0.1451409996101042
Epoch #243: loss=0.09607605647477435
Epoch #244: loss=0.10279927711661269
Epoch #245: loss=0.07804461470918685
Epoch #246: loss=0.08601919059618944
Epoch #247: loss=0.07960170132630481
Epoch #248: loss=0.07300101377342533
Epoch #249: loss=0.06341999437569118

Training time: 0:36:27.838614

Finished.
n2one setting etth2_weather_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_weather_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_weather_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.51364e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.06838e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.51364e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4172361575881502, 'MAE': 0.44662225724075244}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='ettm1_ettm2_electricity', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/ettm1_ettm2_electricity_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.7478463330004723
Epoch #1: loss=0.7436810820512799
Epoch #2: loss=0.5158768346636358
Epoch #3: loss=0.4304948559916054
Epoch #4: loss=0.35751761491722683
Epoch #5: loss=0.30678999219795705
Epoch #6: loss=0.26579986058675165
Epoch #7: loss=0.2377618242370144
Epoch #8: loss=0.2089241816290266
Epoch #9: loss=0.17889222693860357
Epoch #10: loss=0.20123768577205545
Epoch #11: loss=0.1534329569483116
Epoch #12: loss=0.1360227685562897
Epoch #13: loss=0.13691651602289245
Epoch #14: loss=0.1320576063267691
Epoch #15: loss=0.11164255017202901
Epoch #16: loss=0.10966030658160285
Epoch #17: loss=0.09900590629688852
Epoch #18: loss=0.08778466909320118
Epoch #19: loss=0.07587877373990355
Epoch #20: loss=0.09238970180859371
Epoch #21: loss=0.07457465898658287
Epoch #22: loss=0.0757220450424896
Epoch #23: loss=0.058604272258937704
Epoch #24: loss=0.06882112431706475
Epoch #25: loss=0.0656273090131255
Epoch #26: loss=0.05201570292847888
Epoch #27: loss=0.06328125699469413
Epoch #28: loss=0.04633387682535862
Epoch #29: loss=0.05858435806256255
Epoch #30: loss=0.04282235309926918
Epoch #31: loss=0.049293184329812625
Epoch #32: loss=0.05131670355772377
Epoch #33: loss=0.037510760026677095
Epoch #34: loss=0.03486806304335225
Epoch #35: loss=0.03162019394281111
Epoch #36: loss=0.041689336302611464
Epoch #37: loss=0.042162672983775726
Epoch #38: loss=0.04148067612847199
Epoch #39: loss=0.03974650050689936
Epoch #40: loss=0.03522769396557166
Epoch #41: loss=0.02355932225045577
Epoch #42: loss=0.04294801862304894
Epoch #43: loss=0.0544358681807289
Epoch #44: loss=0.03228066192801401
Epoch #45: loss=0.03165586386486866
Epoch #46: loss=0.02670812995496149
Epoch #47: loss=0.026085793752760867
Epoch #48: loss=0.0377089862878714
Epoch #49: loss=0.029386254259637683
Epoch #50: loss=0.032313483452245204
Epoch #51: loss=0.02179393745397432
Epoch #52: loss=0.0251268316929177
Epoch #53: loss=0.023388019336642748
Epoch #54: loss=0.026366951352707585
Epoch #55: loss=0.02367761347825712
Epoch #56: loss=0.02546428659531687
Epoch #57: loss=0.02867895931700576
Epoch #58: loss=0.01986996975724664
Epoch #59: loss=0.018383983576279298
Epoch #60: loss=0.03162290510190678
Epoch #61: loss=0.04014571277362243
Epoch #62: loss=0.02302774408650272
Epoch #63: loss=0.03411260813898231
Epoch #64: loss=0.021592063961839766
Epoch #65: loss=0.03406387510398571
Epoch #66: loss=0.02321854275148959
Epoch #67: loss=0.018386637779772716
Epoch #68: loss=0.012544379588766377
Epoch #69: loss=0.019146846052403115
Epoch #70: loss=0.07095357315593098
Epoch #71: loss=0.023760806457560412
Epoch #72: loss=0.019941613327409072
Epoch #73: loss=0.01666632134728025
Epoch #74: loss=0.01705374534845314
Epoch #75: loss=0.023892958859611662
Epoch #76: loss=0.02136672892690563
Epoch #77: loss=0.02002255439774592
Epoch #78: loss=0.020321018806164513
Epoch #79: loss=0.014566867948311541
Epoch #80: loss=0.024526957475102397
Epoch #81: loss=0.02205733957825332
Epoch #82: loss=0.019621663655421857
Epoch #83: loss=0.018250418144906803
Epoch #84: loss=0.016386790528931484
Epoch #85: loss=0.018132123455870897
Epoch #86: loss=0.022686776063953452
Epoch #87: loss=0.02963554468966407
Epoch #88: loss=0.012272158001770834
Epoch #89: loss=0.016922905552404614
Epoch #90: loss=0.01773487115071804
Epoch #91: loss=0.025446212641778064
Epoch #92: loss=0.01648745884841889
Epoch #93: loss=0.015668403829037926
Epoch #94: loss=0.024611489423387752
Epoch #95: loss=0.018836804922892775
Epoch #96: loss=0.01837975106815707
Epoch #97: loss=0.022444319478052862
Epoch #98: loss=0.016507103188647603
Epoch #99: loss=0.01908849625092722
Epoch #100: loss=0.024860141271760595
Epoch #101: loss=0.026376041199512368
Epoch #102: loss=0.020315621018853668
Epoch #103: loss=0.01317220930544301
Epoch #104: loss=0.01231942236312847
Epoch #105: loss=0.01389711395190464
Epoch #106: loss=0.011916965111457463
Epoch #107: loss=0.013286676091201734
Epoch #108: loss=0.01571284064940929
Epoch #109: loss=0.018118565743612588
Epoch #110: loss=0.014921168731552692
Epoch #111: loss=0.011515446276568234
Epoch #112: loss=0.02228299751076793
Epoch #113: loss=0.011475045182715027
Epoch #114: loss=0.020771232444817423
Epoch #115: loss=0.01599522648072386
Epoch #116: loss=0.026471836510068212
Epoch #117: loss=0.013224399219601043
Epoch #118: loss=0.014792138418900909
Epoch #119: loss=0.014691737034315998
Epoch #120: loss=0.00977654302767315
Epoch #121: loss=0.010817489593728302
Epoch #122: loss=0.019824142967291045
Epoch #123: loss=0.015803502835421594
Epoch #124: loss=0.013776669192532452
Epoch #125: loss=0.016210235275091255
Epoch #126: loss=0.018206198460662754
Epoch #127: loss=0.014158672316874846
Epoch #128: loss=0.010501977148582567
Epoch #129: loss=0.012819424632708637
Epoch #130: loss=0.016475505922220475
Epoch #131: loss=0.012201666649031852
Epoch #132: loss=0.014190255380887267
Epoch #133: loss=0.012370258938818464
Epoch #134: loss=0.01162426792147621
Epoch #135: loss=0.014161389064160515
Epoch #136: loss=0.012339858667118578
Epoch #137: loss=0.018273073275547756
Epoch #138: loss=0.02408570964052274
Epoch #139: loss=0.016629463317600398
Epoch #140: loss=0.008588970603937903
Epoch #141: loss=0.012444773140351856
Epoch #142: loss=0.009012598970989119
Epoch #143: loss=0.013130452558391459
Epoch #144: loss=0.011610665679423942
Epoch #145: loss=0.014065799747631714
Epoch #146: loss=0.012635693008198237
Epoch #147: loss=0.020598790444754086
Epoch #148: loss=0.011884172360562793
Epoch #149: loss=0.012929768257254446
Epoch #150: loss=0.011275871320062183
Epoch #151: loss=0.016499765094609948
Epoch #152: loss=0.016666940512012084
Epoch #153: loss=0.013871529901199282
Epoch #154: loss=0.013534400787247948
Epoch #155: loss=0.010345190673446794
Epoch #156: loss=0.016713050788719173
Epoch #157: loss=0.01157508158048957
Epoch #158: loss=0.008853779611963122
Epoch #159: loss=0.017085370453415336
Epoch #160: loss=0.013677672956494543
Epoch #161: loss=0.013314734739468653
Epoch #162: loss=0.009813068382073405
Epoch #163: loss=0.04861604581612811
Epoch #164: loss=0.011038510287866137
Epoch #165: loss=0.015593805666177999
Epoch #166: loss=0.011363924576346994
Epoch #167: loss=0.007293480635436019
Epoch #168: loss=0.01591923339494352
Epoch #169: loss=0.024407078796772303
Epoch #170: loss=0.013299931267021175
Epoch #171: loss=0.012268612357623518
Epoch #172: loss=0.01101192191607012
Epoch #173: loss=0.008863940111221609
Epoch #174: loss=0.008381183171707936
Epoch #175: loss=0.013295860188003798
Epoch #176: loss=0.011421619484999689
Epoch #177: loss=0.011772992349882765
Epoch #178: loss=0.012476227513844359
Epoch #179: loss=0.014481820800286004
Epoch #180: loss=0.015288773342290262
Epoch #181: loss=0.01751674278948114
Epoch #182: loss=0.010473658829237098
Epoch #183: loss=0.010307912463790658
Epoch #184: loss=0.009898883925782077
Epoch #185: loss=0.011588711915883907
Epoch #186: loss=0.010232142857839313
Epoch #187: loss=0.01168114797145321
Epoch #188: loss=0.008856791720193411
Epoch #189: loss=0.005901705694485676
Epoch #190: loss=0.010723930391304483
Epoch #191: loss=0.016955073796444824
Epoch #192: loss=0.013178729988534801
Epoch #193: loss=0.010011683760886963
Epoch #194: loss=0.011665551880026322
Epoch #195: loss=0.01132524514325783
Epoch #196: loss=0.010520327312745556
Epoch #197: loss=0.01016489246260421
Epoch #198: loss=0.01424471640507297
Epoch #199: loss=0.0165117544800168
Epoch #200: loss=0.012734852054966859
Epoch #201: loss=0.013155426109669887
Epoch #202: loss=0.009091827389936889
Epoch #203: loss=0.01957516276661806
Epoch #204: loss=0.011437099932356257
Epoch #205: loss=0.012348518549035637
Epoch #206: loss=0.009584306942658096
Epoch #207: loss=0.009952673725016773
Epoch #208: loss=0.011460792282955998
Epoch #209: loss=0.006539083442582176
Epoch #210: loss=0.009680623648930532
Epoch #211: loss=0.011269211916489875
Epoch #212: loss=0.0064954769563604605
Epoch #213: loss=0.015495037610110427
Epoch #214: loss=0.01031697305967609
Epoch #215: loss=0.009029920663058069
Epoch #216: loss=0.013000386630309849
Epoch #217: loss=0.01008368424735909
Epoch #218: loss=0.01016071341584271
Epoch #219: loss=0.009010294604447125
Epoch #220: loss=0.010633447506015649
Epoch #221: loss=0.012944463003900597
Epoch #222: loss=0.007610734560884638
Epoch #223: loss=0.00996047340555092
Epoch #224: loss=0.008063591957386209
Epoch #225: loss=0.008802582539874095
Epoch #226: loss=0.010434790402491314
Epoch #227: loss=0.005917092518001569
Epoch #228: loss=0.008044353637441453
Epoch #229: loss=0.014287548742726114
Epoch #230: loss=0.014841568695806216
Epoch #231: loss=0.009435004524312339
Epoch #232: loss=0.01425466094270916
Epoch #233: loss=0.016565202633373754
Epoch #234: loss=0.01235210915970407
Epoch #235: loss=0.01125803365381964
Epoch #236: loss=0.010410395939376222
Epoch #237: loss=0.012800616752010099
Epoch #238: loss=0.00796048106346008
Epoch #239: loss=0.008190900325787365
Epoch #240: loss=0.008817092907199576
Epoch #241: loss=0.008826145855777791
Epoch #242: loss=0.015245361110645566
Epoch #243: loss=0.010132493204576352
Epoch #244: loss=0.00622169031860353
Epoch #245: loss=0.00906381176502251
Epoch #246: loss=0.026229193382020823
Epoch #247: loss=0.013008258817734403
Epoch #248: loss=0.018560416261755804
Epoch #249: loss=0.007686259898344535

Training time: 4:49:49.184120

Finished.
n2one setting ettm1_ettm2_electricity -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm1_ettm2_electricity_epochs_250_seed_2021/model.pkl', muti_dataset='ettm1_ettm2_electricity', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.0181e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.1031e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.4779e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.0181e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.44034057918913055, 'MAE': 0.48275241852668677}
Finished.
------------------------- record done -------------------------
n2one setting ettm1_ettm2_electricity -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm1_ettm2_electricity_epochs_250_seed_2021/model.pkl', muti_dataset='ettm1_ettm2_electricity', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.65637e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.24578960207179246, 'MAE': 0.33783481814970917}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='ettm1_ettm2_traffic', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/ettm1_ettm2_traffic_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.0408407525576617
Epoch #1: loss=0.3941198249275868
Epoch #2: loss=0.2789197470908521
Epoch #3: loss=0.21844913158987173
Epoch #4: loss=0.16573377546108417
Epoch #5: loss=0.14240761626537096
Epoch #6: loss=0.11582386772236808
Epoch #7: loss=0.11079118706336523
Epoch #8: loss=0.08742233246725002
Epoch #9: loss=0.08429051233493466
Epoch #10: loss=0.07213669777447484
Epoch #11: loss=0.06975152247587463
Epoch #12: loss=0.06437182987511277
Epoch #13: loss=0.06371641322197098
Epoch #14: loss=0.05264707827441209
Epoch #15: loss=0.04703324012552089
Epoch #16: loss=0.05225771677925787
Epoch #17: loss=0.04381783858991999
Epoch #18: loss=0.04621564899070812
Epoch #19: loss=0.03791683119968237
Epoch #20: loss=0.036920731317128655
Epoch #21: loss=0.03661388472013378
Epoch #22: loss=0.0335213234530903
Epoch #23: loss=0.04112221930904011
Epoch #24: loss=0.03265021862902013
Epoch #25: loss=0.033977094721243974
Epoch #26: loss=0.03934953282879585
Epoch #27: loss=0.026946806941208813
Epoch #28: loss=0.026046042541071995
Epoch #29: loss=0.03424257677825688
Epoch #30: loss=0.029359921033660634
Epoch #31: loss=0.025941658621007047
Epoch #32: loss=0.030337892929845324
Epoch #33: loss=0.0289198921831921
Epoch #34: loss=0.02348729392262892
Epoch #35: loss=0.026688509693024765
Epoch #36: loss=0.024542398803326936
Epoch #37: loss=0.017443392053154313
Epoch #38: loss=0.024388381833175293
Epoch #39: loss=0.023986762266211544
Epoch #40: loss=0.041631483627292035
Epoch #41: loss=0.020051491155030472
Epoch #42: loss=0.022668320087218717
Epoch #43: loss=0.024368903450472955
Epoch #44: loss=0.022245342498795315
Epoch #45: loss=0.020597429089872398
Epoch #46: loss=0.01782513889974
Epoch #47: loss=0.0266259683486247
Epoch #48: loss=0.01634778295783484
Epoch #49: loss=0.02692971353931932
Epoch #50: loss=0.018579876518384785
Epoch #51: loss=0.01760637923199773
Epoch #52: loss=0.023272313832751017
Epoch #53: loss=0.026549148906656536
Epoch #54: loss=0.01820627281340092
Epoch #55: loss=0.019361152057246225
Epoch #56: loss=0.021047285530428828
Epoch #57: loss=0.02028289547032567
Epoch #58: loss=0.02019614259484835
Epoch #59: loss=0.021630633876309202
Epoch #60: loss=0.025043093083872526
Epoch #61: loss=0.015883177268367295
Epoch #62: loss=0.012706073954584975
Epoch #63: loss=0.02038823053178486
Epoch #64: loss=0.024937219400226446
Epoch #65: loss=0.017622694437527963
Epoch #66: loss=0.02227934876387587
Epoch #67: loss=0.018430128781023812
Epoch #68: loss=0.01786000899594157
Epoch #69: loss=0.02059969061980871
Epoch #70: loss=0.012825533082071065
Epoch #71: loss=0.022224296239114892
Epoch #72: loss=0.018880712964737416
Epoch #73: loss=0.020187403223319536
Epoch #74: loss=0.015471561042522397
Epoch #75: loss=0.015215710779775526
Epoch #76: loss=0.018610728853837823
Epoch #77: loss=0.016290399883667005
Epoch #78: loss=0.01550351622367854
Epoch #79: loss=0.01990352684680143
Epoch #80: loss=0.015174784978161085
Epoch #81: loss=0.017127373006431346
Epoch #82: loss=0.02797969154277669
Epoch #83: loss=0.014516705789502418
Epoch #84: loss=0.034785814784822525
Epoch #85: loss=0.015156017379412254
Epoch #86: loss=0.01674579411693185
Epoch #87: loss=0.01949477942351766
Epoch #88: loss=0.0209840108197745
Epoch #89: loss=0.01645048581089032
Epoch #90: loss=0.015497295477488647
Epoch #91: loss=0.022400142096035178
Epoch #92: loss=0.01595581181300488
Epoch #93: loss=0.016050443769087836
Epoch #94: loss=0.010802463457350224
Epoch #95: loss=0.013101008660216632
Epoch #96: loss=0.019324661022285528
Epoch #97: loss=0.027914818103437846
Epoch #98: loss=0.0242284045773503
Epoch #99: loss=0.015658740966776503
Epoch #100: loss=0.011333207332353188
Epoch #101: loss=0.01361666075605188
Epoch #102: loss=0.01896327075779457
Epoch #103: loss=0.013550216452180665
Epoch #104: loss=0.012422400268833907
Epoch #105: loss=0.01849601027512042
Epoch #106: loss=0.013667863228780268
Epoch #107: loss=0.01885795460414585
Epoch #108: loss=0.014652890851754091
Epoch #109: loss=0.014700715708114655
Epoch #110: loss=0.013301828250372455
Epoch #111: loss=0.016753234406361648
Epoch #112: loss=0.01466580037010741
Epoch #113: loss=0.013607797039691432
Epoch #114: loss=0.01688589939627137
Epoch #115: loss=0.013482659421954672
Epoch #116: loss=0.013435841838762584
Epoch #117: loss=0.01690347240966475
Epoch #118: loss=0.015273303803050158
Epoch #119: loss=0.011914732621273403
Epoch #120: loss=0.013319396027446802
Epoch #121: loss=0.017445833123139184
Epoch #122: loss=0.01085979365295287
Epoch #123: loss=0.014537105276832742
Epoch #124: loss=0.015296963359768148
Epoch #125: loss=0.019689736864848904
Epoch #126: loss=0.01677376018393689
Epoch #127: loss=0.008218614073575325
Epoch #128: loss=0.01114962062406263
Epoch #129: loss=0.016820728643443746
Epoch #130: loss=0.011574087915159825
Epoch #131: loss=0.013974091903189602
Epoch #132: loss=0.013579616947463034
Epoch #133: loss=0.011729085554122004
Epoch #134: loss=0.014222639133529242
Epoch #135: loss=0.0166041667870604
Epoch #136: loss=0.015097342841961944
Epoch #137: loss=0.013331606377698944
Epoch #138: loss=0.016070909538926956
Epoch #139: loss=0.0076121994559683395
Epoch #140: loss=0.018233657551179238
Epoch #141: loss=0.01254160697365836
Epoch #142: loss=0.011022414340708343
Epoch #143: loss=0.015037867885171984
Epoch #144: loss=0.013133108750727382
Epoch #145: loss=0.01334626885156418
Epoch #146: loss=0.011666896139363479
Epoch #147: loss=0.01651454651562341
Epoch #148: loss=0.01591820750405013
Epoch #149: loss=0.011725100350123198
Epoch #150: loss=0.011451420107045437
Epoch #151: loss=0.010748128545111282
Epoch #152: loss=0.020854570520583465
Epoch #153: loss=0.014781845988675728
Epoch #154: loss=0.012659251298556553
Epoch #155: loss=0.012361952039343094
Epoch #156: loss=0.01203182487671458
Epoch #157: loss=0.015281793063799365
Epoch #158: loss=0.014426439775143986
Epoch #159: loss=0.00984089377565874
Epoch #160: loss=0.00837176271473077
Epoch #161: loss=0.017629607868562183
Epoch #162: loss=0.010558637509253392
Epoch #163: loss=0.012857214761264486
Epoch #164: loss=0.010886382973316094
Epoch #165: loss=0.017362119457591564
Epoch #166: loss=0.012191480278101754
Epoch #167: loss=0.011315039050907826
Epoch #168: loss=0.011479157640551173
Epoch #169: loss=0.014265724586726406
Epoch #170: loss=0.008484381959899761
Epoch #171: loss=0.0125996653161186
Epoch #172: loss=0.011712550891520365
Epoch #173: loss=0.01255220902954756
Epoch #174: loss=0.00972816319197558
Epoch #175: loss=0.013570861775550266
Epoch #176: loss=0.011361080273849957
Epoch #177: loss=0.010413299261721255
Epoch #178: loss=0.01723055754068789
Epoch #179: loss=0.012942355282394515
Epoch #180: loss=0.014357897263308418
Epoch #181: loss=0.008103372263411988
Epoch #182: loss=0.014458529922680043
Epoch #183: loss=0.010171445768859345
Epoch #184: loss=0.014542045812222609
Epoch #185: loss=0.014185375410899346
Epoch #186: loss=0.009669303685641105
Epoch #187: loss=0.0123307780790729
Epoch #188: loss=0.01122654038514008
Epoch #189: loss=0.012718773768008191
Epoch #190: loss=0.012394139247746303
Epoch #191: loss=0.012619906661629559
Epoch #192: loss=0.008050981079923159
Epoch #193: loss=0.01690923615549273
Epoch #194: loss=0.01751970796320009
Epoch #195: loss=0.01085793240294382
Epoch #196: loss=0.005789987408305567
Epoch #197: loss=0.014107919191541014
Epoch #198: loss=0.009789344498410802
Epoch #199: loss=0.013298782519765706
Epoch #200: loss=0.011589922042570406
Epoch #201: loss=0.010234303547454497
Epoch #202: loss=0.01043542810802388
Epoch #203: loss=0.007544703330067397
Epoch #204: loss=0.018132543325046505
Epoch #205: loss=0.007878038689905142
Epoch #206: loss=0.009574502034670394
Epoch #207: loss=0.008334752968825573
Epoch #208: loss=0.01096746180503765
Epoch #209: loss=0.01078532103832197
Epoch #210: loss=0.010490497108968646
Epoch #211: loss=0.009561872026953258
Epoch #212: loss=0.011624688495554206
Epoch #213: loss=0.017361659882563836
Epoch #214: loss=0.013435455433115267
Epoch #215: loss=0.00961852055324802
Epoch #216: loss=0.00827381769327549
Epoch #217: loss=0.007727676859960156
Epoch #218: loss=0.007890937855657231
Epoch #219: loss=0.011229201506158127
Epoch #220: loss=0.013143573110435649
Epoch #221: loss=0.008987682298251295
Epoch #222: loss=0.010722082516749899
Epoch #223: loss=0.008705567508299924
Epoch #224: loss=0.010722504478882696
Epoch #225: loss=0.019660330949620105
Epoch #226: loss=0.012379161158506943
Epoch #227: loss=0.006861786623433368
Epoch #228: loss=0.010670671924604056
Epoch #229: loss=0.015092260557221833
Epoch #230: loss=0.010660055575557043
Epoch #231: loss=0.007281332316664069
Epoch #232: loss=0.010396657454569474
Epoch #233: loss=0.007600298130994597
Epoch #234: loss=0.010136711464677801
Epoch #235: loss=0.02210267669053948
Epoch #236: loss=0.014317076618508468
Epoch #237: loss=0.01004198633271456
Epoch #238: loss=0.009114119409523853
Epoch #239: loss=0.009649757790941287
Epoch #240: loss=0.00862674796567612
Epoch #241: loss=0.013123971689364064
Epoch #242: loss=0.00851396828032469
Epoch #243: loss=0.00991039613863781
Epoch #244: loss=0.010471618161540705
Epoch #245: loss=0.008315907044500024
Epoch #246: loss=0.011578175506055565
Epoch #247: loss=0.010031878676367408
Epoch #248: loss=0.012153151930950248
Epoch #249: loss=0.007943869727326303

Training time: 10:23:51.706235

Finished.
n2one setting ettm1_ettm2_traffic -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm1_ettm2_traffic_epochs_250_seed_2021/model.pkl', muti_dataset='ettm1_ettm2_traffic', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.02496e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.95277e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.02961e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.02496e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4188819021722389, 'MAE': 0.4597007083238305}
Finished.
------------------------- record done -------------------------
n2one setting ettm1_ettm2_traffic -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm1_ettm2_traffic_epochs_250_seed_2021/model.pkl', muti_dataset='ettm1_ettm2_traffic', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.02539e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.08787e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.23866e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.08787e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 1.1625844018975964, 'MAE': 0.9031694720708436}
Finished.
------------------------- record done -------------------------
n2one setting ettm1_ettm2_traffic -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm1_ettm2_traffic_epochs_250_seed_2021/model.pkl', muti_dataset='ettm1_ettm2_traffic', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
Evaluation result: {'MSE': 0.20749186973873857, 'MAE': 0.3113013562990473}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='ettm1_ettm2_weather', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/ettm1_ettm2_weather_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=6.336899201075236
Epoch #1: loss=2.7437085807323456
Epoch #2: loss=2.37261471649011
Epoch #3: loss=2.1597554658850036
Epoch #4: loss=2.038657531142235
Epoch #5: loss=1.860108348230521
Epoch #6: loss=1.6815124278267224
Epoch #7: loss=1.5031575287381809
Epoch #8: loss=1.3522872477769852
Epoch #9: loss=1.290947704265515
Epoch #10: loss=1.1377124364177387
Epoch #11: loss=1.1344433041910331
Epoch #12: loss=1.1065961457788944
Epoch #13: loss=0.9739331565797329
Epoch #14: loss=0.9621863178908825
Epoch #15: loss=0.941942443450292
Epoch #16: loss=0.9619265645742416
Epoch #17: loss=0.9061327489713827
Epoch #18: loss=0.8032835101087888
Epoch #19: loss=0.7643005053202311
Epoch #20: loss=0.8016084829966227
Epoch #21: loss=0.7618839318553606
Epoch #22: loss=0.6903844277064005
Epoch #23: loss=0.7057474814355373
Epoch #24: loss=0.7077423992256323
Epoch #25: loss=0.6703129801899195
Epoch #26: loss=0.7623056626568238
Epoch #27: loss=0.7163878809660673
Epoch #28: loss=0.7035509614894787
Epoch #29: loss=0.779247730349501
Epoch #30: loss=0.9043509239951769
Epoch #31: loss=0.6369396286706129
Epoch #32: loss=0.5743846129626036
Epoch #33: loss=0.5442244478811821
Epoch #34: loss=0.5621770905951659
Epoch #35: loss=0.5452670883387327
Epoch #36: loss=0.5181144867092371
Epoch #37: loss=0.5106829466919104
Epoch #38: loss=0.5115699699769417
Epoch #39: loss=0.49436499550938606
Epoch #40: loss=0.5144519588599602
Epoch #41: loss=0.49919914081692696
Epoch #42: loss=0.45397140830755234
Epoch #43: loss=0.39210583083331585
Epoch #44: loss=0.4259592896948258
Epoch #45: loss=0.43671673350036144
Epoch #46: loss=0.45156493907173473
Epoch #47: loss=0.3712811078876257
Epoch #48: loss=0.4492001223067443
Epoch #49: loss=0.38894329499453306
Epoch #50: loss=0.3874765858054161
Epoch #51: loss=0.3753089193875591
Epoch #52: loss=0.4279422989736001
Epoch #53: loss=0.41640395391732454
Epoch #54: loss=0.3342061238363385
Epoch #55: loss=0.4088410126666228
Epoch #56: loss=0.33179368016620475
Epoch #57: loss=0.32431789798041183
Epoch #58: loss=0.3649369499956568
Epoch #59: loss=0.31957803790767986
Epoch #60: loss=0.31733793175468844
Epoch #61: loss=0.2874480231354634
Epoch #62: loss=0.3167187583943208
Epoch #63: loss=0.3003939064219594
Epoch #64: loss=0.2742565168688695
Epoch #65: loss=0.26231014759590227
Epoch #66: loss=0.2732778840387861
Epoch #67: loss=0.2725616501023372
Epoch #68: loss=0.22795774151260653
Epoch #69: loss=0.2576999068260193
Epoch #70: loss=0.228727618077149
Epoch #71: loss=0.2153676636517048
Epoch #72: loss=0.28524216342096526
Epoch #73: loss=0.25432556836555403
Epoch #74: loss=0.20156914927065372
Epoch #75: loss=0.1790466901535789
Epoch #76: loss=0.20592832130690417
Epoch #77: loss=0.18553625730176768
Epoch #78: loss=0.20041135884821415
Epoch #79: loss=0.24644906733495495
Epoch #80: loss=0.217136579255263
Epoch #81: loss=0.2143170265480876
Epoch #82: loss=0.20526403561234474
Epoch #83: loss=0.16947143043701848
Epoch #84: loss=0.17175845343930027
Epoch #85: loss=0.1576463155603657
Epoch #86: loss=0.20932734043647847
Epoch #87: loss=0.13753568101674318
Epoch #88: loss=0.23387487403427562
Epoch #89: loss=0.16598911040152112
Epoch #90: loss=0.1405855822376907
Epoch #91: loss=0.13590760699783763
Epoch #92: loss=0.1438318844884634
Epoch #93: loss=0.16235093508536616
Epoch #94: loss=0.13791017971622446
Epoch #95: loss=0.15206953114829957
Epoch #96: loss=0.13476892343411842
Epoch #97: loss=0.13351605413481593
Epoch #98: loss=0.17885736818425357
Epoch #99: loss=0.19648445397615433
Epoch #100: loss=0.19986097405975065
Epoch #101: loss=0.1253958126374831
Epoch #102: loss=0.12919010276285312
Epoch #103: loss=0.16316526189136007
Epoch #104: loss=0.11386711794572572
Epoch #105: loss=0.11977966618724167
Epoch #106: loss=0.10272731469012797
Epoch #107: loss=0.09148166619706899
Epoch #108: loss=0.08048054742782067
Epoch #109: loss=0.09848985301020245
Epoch #110: loss=0.10252816105882327
Epoch #111: loss=0.09071664570365101
Epoch #112: loss=0.09247271239291877
Epoch #113: loss=0.0979784920734043
Epoch #114: loss=0.18635649047791958
Epoch #115: loss=0.14559660789867243
Epoch #116: loss=0.10316738463006914
Epoch #117: loss=0.1003565238788724
Epoch #118: loss=0.12439096889769037
Epoch #119: loss=0.1228843374022593
Epoch #120: loss=0.13903654902242124
Epoch #121: loss=0.38858355476986617
Epoch #122: loss=0.3046760807434718
Epoch #123: loss=0.3156052088209738
Epoch #124: loss=0.12964448045628765
Epoch #125: loss=0.19872105521305153
Epoch #126: loss=0.16493272416604063
Epoch #127: loss=0.12053018649263929
Epoch #128: loss=0.08305105198329936
Epoch #129: loss=0.08330365968868136
Epoch #130: loss=0.08685033399766932
Epoch #131: loss=0.08292347402311862
Epoch #132: loss=0.09628667872554313
Epoch #133: loss=0.09237195613483588
Epoch #134: loss=0.07402366333796333
Epoch #135: loss=0.07184146073025961
Epoch #136: loss=0.05916636910599967
Epoch #137: loss=0.055106805094207324
Epoch #138: loss=0.045781435212120414
Epoch #139: loss=0.04915087800084924
Epoch #140: loss=0.06605194782605395
Epoch #141: loss=0.05924862182776754
Epoch #142: loss=0.08121946465689689
Epoch #143: loss=0.04975958440142373
Epoch #144: loss=0.07138147748385866
Epoch #145: loss=0.058387563175832234
Epoch #146: loss=0.13423506531398743
Epoch #147: loss=0.06612685703051586
Epoch #148: loss=0.06139429747903099
Epoch #149: loss=0.04827419138746336
Epoch #150: loss=0.056719740852713585
Epoch #151: loss=0.06934389246938129
Epoch #152: loss=0.0964563530869782
Epoch #153: loss=0.09819079384518166
Epoch #154: loss=0.09952492344503601
Epoch #155: loss=0.0546380570740439
Epoch #156: loss=0.06060064696551611
Epoch #157: loss=0.05701558495638892
Epoch #158: loss=0.06395216584981729
Epoch #159: loss=0.04436512330236534
Epoch #160: loss=0.06533297419082373
Epoch #161: loss=0.07272365380777046
Epoch #162: loss=0.07142698805546388
Epoch #163: loss=0.048098345675195255
Epoch #164: loss=0.07743126792289938
Epoch #165: loss=0.07913294911850244
Epoch #166: loss=0.1253525932164242
Epoch #167: loss=0.07394123803048085
Epoch #168: loss=0.08344827037459861
Epoch #169: loss=0.06783202957982819
Epoch #170: loss=0.032192865590332076
Epoch #171: loss=0.09752824295234556
Epoch #172: loss=0.06948763962524633
Epoch #173: loss=0.13974421506281942
Epoch #174: loss=0.105606712672549
Epoch #175: loss=0.04236685001524165
Epoch #176: loss=0.048798254147792854
Epoch #177: loss=0.04614285185622672
Epoch #178: loss=0.07775064751816292
Epoch #179: loss=0.07051262670817475
Epoch #180: loss=0.05285833808981503
Epoch #181: loss=0.04794591385871172
Epoch #182: loss=0.20574310701340437
Epoch #183: loss=0.07733998296316713
Epoch #184: loss=0.05890417529735714
Epoch #185: loss=0.05754147198361655
Epoch #186: loss=0.06009132709975044
Epoch #187: loss=0.09071844121596466
Epoch #188: loss=0.0739611506772538
Epoch #189: loss=0.06685777018234755
Epoch #190: loss=0.0434316653603067
Epoch #191: loss=0.04759589344030246
Epoch #192: loss=0.048631711300307266
Epoch #193: loss=0.04144222154476059
Epoch #194: loss=0.04013425391167402
Epoch #195: loss=0.037401383209119864
Epoch #196: loss=0.04696813067615343
Epoch #197: loss=0.12746030039852485
Epoch #198: loss=0.06338523953066517
Epoch #199: loss=0.05412848547954733
Epoch #200: loss=0.09652038314379752
Epoch #201: loss=0.03773550070278967
Epoch #202: loss=0.040804173079474516
Epoch #203: loss=0.044754234802288316
Epoch #204: loss=0.07468968722969294
Epoch #205: loss=0.06733370915753767
Epoch #206: loss=0.05785584228578955
Epoch #207: loss=0.047003984063242875
Epoch #208: loss=0.1005018445236298
Epoch #209: loss=0.05312609069126969
Epoch #210: loss=0.03908959465722243
Epoch #211: loss=0.03730129989950607
Epoch #212: loss=0.050340889215779804
Epoch #213: loss=0.0324690761238647
Epoch #214: loss=0.03863028531971698
Epoch #215: loss=0.23472655027095848
Epoch #216: loss=0.20615924060499916
Epoch #217: loss=0.07873909470314781
Epoch #218: loss=0.06920471663276355
Epoch #219: loss=0.046953440857275076
Epoch #220: loss=0.0495467850608596
Epoch #221: loss=0.04226681035167227
Epoch #222: loss=0.030864350090269
Epoch #223: loss=0.04344353609485552
Epoch #224: loss=0.052614037277332194
Epoch #225: loss=0.04661393613787368
Epoch #226: loss=0.028192213998408988
Epoch #227: loss=0.03440507540168861
Epoch #228: loss=0.029126708725622546
Epoch #229: loss=0.04494976517162286
Epoch #230: loss=0.037076052443201966
Epoch #231: loss=0.025658420296773937
Epoch #232: loss=0.04268498691574981
Epoch #233: loss=0.030172522325301543
Epoch #234: loss=0.03401831251297457
Epoch #235: loss=0.04657562213833444
Epoch #236: loss=0.25366445165127516
Epoch #237: loss=0.10371334167818229
Epoch #238: loss=0.41567749809473753
Epoch #239: loss=0.0718079205447187
Epoch #240: loss=0.061392273055389524
Epoch #241: loss=0.047113636101130396
Epoch #242: loss=0.045725584224176906
Epoch #243: loss=0.04028918028537495
Epoch #244: loss=0.04307034788265204
Epoch #245: loss=0.04205378245872756
Epoch #246: loss=0.03376446931118456
Epoch #247: loss=0.036051527199257784
Epoch #248: loss=0.0839902994048316
Epoch #249: loss=0.034839526032252856

Training time: 0:50:51.030600

Finished.
n2one setting ettm1_ettm2_weather -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm1_ettm2_weather_epochs_250_seed_2021/model.pkl', muti_dataset='ettm1_ettm2_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.63701e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.24352e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.63701e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3780837810495044, 'MAE': 0.42919767031877754}
Finished.
------------------------- record done -------------------------
n2one setting ettm1_ettm2_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm1_ettm2_weather_epochs_250_seed_2021/model.pkl', muti_dataset='ettm1_ettm2_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.43504e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.2096337112831243, 'MAE': 0.30684493073682173}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='ettm1_ettm2_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/ettm1_ettm2_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=4.512759753068289
Epoch #1: loss=2.3813239773114523
Epoch #2: loss=2.1040950059890746
Epoch #3: loss=1.9922324101130167
Epoch #4: loss=1.7993876576423644
Epoch #5: loss=1.6375384291013082
Epoch #6: loss=1.5020442008972168
Epoch #7: loss=1.4038804372151692
Epoch #8: loss=1.3425765911738077
Epoch #9: loss=1.3384725093841552
Epoch #10: loss=1.1646435022354127
Epoch #11: loss=1.1984661519527435
Epoch #12: loss=1.117814878622691
Epoch #13: loss=1.0386301279067993
Epoch #14: loss=0.957661364475886
Epoch #15: loss=0.9445930063724518
Epoch #16: loss=1.0120988408724467
Epoch #17: loss=0.9228063821792603
Epoch #18: loss=0.9564402818679809
Epoch #19: loss=0.809673414627711
Epoch #20: loss=0.8777006169160207
Epoch #21: loss=0.8024556795756023
Epoch #22: loss=0.7785810768604279
Epoch #23: loss=0.7427616735299428
Epoch #24: loss=0.9096576134363811
Epoch #25: loss=0.7852398256460825
Epoch #26: loss=0.6992499719063441
Epoch #27: loss=0.6754331578811009
Epoch #28: loss=0.7650525212287903
Epoch #29: loss=0.6868048896392186
Epoch #30: loss=0.6846732238928477
Epoch #31: loss=0.7027804245551427
Epoch #32: loss=0.7541662106911341
Epoch #33: loss=0.7806496093670527
Epoch #34: loss=0.8599734336137772
Epoch #35: loss=0.819946892062823
Epoch #36: loss=0.6683130393425624
Epoch #37: loss=0.5796357959508895
Epoch #38: loss=0.6116321235895157
Epoch #39: loss=0.5095011492570242
Epoch #40: loss=0.5650274415810903
Epoch #41: loss=0.5177926699320475
Epoch #42: loss=0.5978983302911123
Epoch #43: loss=0.6412063032388687
Epoch #44: loss=0.5526675482590994
Epoch #45: loss=0.4951273520787557
Epoch #46: loss=0.5314302235841751
Epoch #47: loss=0.542607377966245
Epoch #48: loss=0.5797764996687571
Epoch #49: loss=0.4647044608990351
Epoch #50: loss=0.49102861881256105
Epoch #51: loss=0.43225121398766836
Epoch #52: loss=0.4706935465335846
Epoch #53: loss=0.4103791410724322
Epoch #54: loss=0.3835897127787272
Epoch #55: loss=0.49053943902254105
Epoch #56: loss=0.4718377326925596
Epoch #57: loss=0.43547365615765254
Epoch #58: loss=0.4760270948211352
Epoch #59: loss=0.41719184815883636
Epoch #60: loss=0.3250398447116216
Epoch #61: loss=0.4492031698425611
Epoch #62: loss=0.3103330006202062
Epoch #63: loss=0.41844918529192604
Epoch #64: loss=0.37582581490278244
Epoch #65: loss=0.32898607353369397
Epoch #66: loss=0.3353095844388008
Epoch #67: loss=0.3869719088077545
Epoch #68: loss=0.33249749690294267
Epoch #69: loss=0.3654092232386271
Epoch #70: loss=0.31468050479888915
Epoch #71: loss=0.29071165025234225
Epoch #72: loss=0.31119357645511625
Epoch #73: loss=0.39853030691544217
Epoch #74: loss=0.2677115688721339
Epoch #75: loss=0.24198972458640736
Epoch #76: loss=0.2737404326597849
Epoch #77: loss=0.2756878510117531
Epoch #78: loss=0.30404013221462567
Epoch #79: loss=0.34281829645236334
Epoch #80: loss=0.29152766689658166
Epoch #81: loss=0.2841588179270426
Epoch #82: loss=0.17877746596932412
Epoch #83: loss=0.21112839952111245
Epoch #84: loss=0.2803858848909537
Epoch #85: loss=0.20457977851231893
Epoch #86: loss=0.24194274246692657
Epoch #87: loss=0.29282298336426416
Epoch #88: loss=0.27832016224662465
Epoch #89: loss=0.30223267525434494
Epoch #90: loss=0.22426478589574497
Epoch #91: loss=0.1992283324400584
Epoch #92: loss=0.21262934195498626
Epoch #93: loss=0.21138319422801335
Epoch #94: loss=0.24415646865963936
Epoch #95: loss=0.16099033604065577
Epoch #96: loss=0.23910438865423203
Epoch #97: loss=0.16936969359715778
Epoch #98: loss=0.19347830985983214
Epoch #99: loss=0.23146805614233018
Epoch #100: loss=0.266286539286375
Epoch #101: loss=0.23522343710064889
Epoch #102: loss=0.23992908447980882
Epoch #103: loss=0.1968598809093237
Epoch #104: loss=0.18454258181154728
Epoch #105: loss=0.1756333580861489
Epoch #106: loss=0.2261890737960736
Epoch #107: loss=0.1954167584578196
Epoch #108: loss=0.2116206932812929
Epoch #109: loss=0.18299906825025877
Epoch #110: loss=0.14244046807289124
Epoch #111: loss=0.17424490091701347
Epoch #112: loss=0.17397315067549546
Epoch #113: loss=0.11501265540719033
Epoch #114: loss=0.23429090045392514
Epoch #115: loss=0.20309080282847086
Epoch #116: loss=0.14406856000423432
Epoch #117: loss=0.19206632984181246
Epoch #118: loss=0.15301121771335602
Epoch #119: loss=0.15839347317814828
Epoch #120: loss=0.15729236615200837
Epoch #121: loss=0.15958163452645144
Epoch #122: loss=0.12682115646700065
Epoch #123: loss=0.1497536936153968
Epoch #124: loss=0.09940356897811095
Epoch #125: loss=0.11755250748246908
Epoch #126: loss=0.1689941857010126
Epoch #127: loss=0.19946185288329918
Epoch #128: loss=0.15751242687304814
Epoch #129: loss=0.11223908513784409
Epoch #130: loss=0.14381526708602904
Epoch #131: loss=0.1530279806504647
Epoch #132: loss=0.11618038049588601
Epoch #133: loss=0.10531774219125509
Epoch #134: loss=0.18441299634675185
Epoch #135: loss=0.13896756110092004
Epoch #136: loss=0.20528038814663888
Epoch #137: loss=0.24788408155242603
Epoch #138: loss=0.21293470151722432
Epoch #139: loss=0.19562935506304105
Epoch #140: loss=0.1492318091293176
Epoch #141: loss=0.10705548351009687
Epoch #142: loss=0.17664516791701318
Epoch #143: loss=0.21176132708787918
Epoch #144: loss=0.170378752425313
Epoch #145: loss=0.1303374149526159
Epoch #146: loss=0.11968542654067278
Epoch #147: loss=0.1060059539352854
Epoch #148: loss=0.10851404319206874
Epoch #149: loss=0.09536355057110389
Epoch #150: loss=0.11233990291754405
Epoch #151: loss=0.12181282869229713
Epoch #152: loss=0.13243571259081363
Epoch #153: loss=0.16050891820341348
Epoch #154: loss=0.12823814060539007
Epoch #155: loss=0.11543312277644872
Epoch #156: loss=0.12920076412459214
Epoch #157: loss=0.10739926298459371
Epoch #158: loss=0.10495523475110531
Epoch #159: loss=0.0877475411320726
Epoch #160: loss=0.12956238525609176
Epoch #161: loss=0.07273675308873256
Epoch #162: loss=0.1268273752803604
Epoch #163: loss=0.18207285255193711
Epoch #164: loss=0.11063584176202615
Epoch #165: loss=0.09569439614812533
Epoch #166: loss=0.09070308152586222
Epoch #167: loss=0.13161412322272856
Epoch #168: loss=0.1345931259294351
Epoch #169: loss=0.09931999798864126
Epoch #170: loss=0.09655596461767951
Epoch #171: loss=0.12247718259071311
Epoch #172: loss=0.09954137907673916
Epoch #173: loss=0.09439545723920068
Epoch #174: loss=0.11887469589710235
Epoch #175: loss=0.09749059708168109
Epoch #176: loss=0.12420820733532309
Epoch #177: loss=0.12293761937568586
Epoch #178: loss=0.18154188829163712
Epoch #179: loss=0.13596607980628808
Epoch #180: loss=0.09227715296049913
Epoch #181: loss=0.1034096780543526
Epoch #182: loss=0.13405510568991302
Epoch #183: loss=0.13240065152446429
Epoch #184: loss=0.19572943871219953
Epoch #185: loss=0.2747162103652954
Epoch #186: loss=0.21501081163684527
Epoch #187: loss=0.15589747919390598
Epoch #188: loss=0.12279593218117953
Epoch #189: loss=0.14304677564650775
Epoch #190: loss=0.16390509052822988
Epoch #191: loss=0.1048038562759757
Epoch #192: loss=0.08597401871035497
Epoch #193: loss=0.08716622833162546
Epoch #194: loss=0.07361889782672128
Epoch #195: loss=0.08387579638510942
Epoch #196: loss=0.08404841336111228
Epoch #197: loss=0.0887504246396323
Epoch #198: loss=0.085978673864156
Epoch #199: loss=0.07016967578480642
Epoch #200: loss=0.1337427584764858
Epoch #201: loss=0.07130340697864691
Epoch #202: loss=0.09242456924791137
Epoch #203: loss=0.08968320433050395
Epoch #204: loss=0.08006090729807815
Epoch #205: loss=0.1297677280070881
Epoch #206: loss=0.11790427348266046
Epoch #207: loss=0.09235675930976868
Epoch #208: loss=0.10909408008058866
Epoch #209: loss=0.08754482104753454
Epoch #210: loss=0.0803000862399737
Epoch #211: loss=0.06388434826706847
Epoch #212: loss=0.09920484342922767
Epoch #213: loss=0.09130531301101048
Epoch #214: loss=0.08099026574442784
Epoch #215: loss=0.11607148398955663
Epoch #216: loss=0.10054162867988149
Epoch #217: loss=0.07818064407135049
Epoch #218: loss=0.09404918306196729
Epoch #219: loss=0.14087495412677525
Epoch #220: loss=0.15574515368789435
Epoch #221: loss=0.13494758040954669
Epoch #222: loss=0.13707498796284198
Epoch #223: loss=0.10743773399541776
Epoch #224: loss=0.16033279988914728
Epoch #225: loss=0.12312429863959551
Epoch #226: loss=0.09406758404026429
Epoch #227: loss=0.08573677918563287
Epoch #228: loss=0.09542037357265751
Epoch #229: loss=0.06955456820627054
Epoch #230: loss=0.07449044237534205
Epoch #231: loss=0.0749483581011494
Epoch #232: loss=0.07920355225602786
Epoch #233: loss=0.12911201116318505
Epoch #234: loss=0.07831438717742761
Epoch #235: loss=0.06294888195892175
Epoch #236: loss=0.06420845622196794
Epoch #237: loss=0.07446268734832605
Epoch #238: loss=0.06397078422208627
Epoch #239: loss=0.051886670446644224
Epoch #240: loss=0.0577256519968311
Epoch #241: loss=0.05389650001501044
Epoch #242: loss=0.044846837688237426
Epoch #243: loss=0.10256198567027847
Epoch #244: loss=0.0769165702474614
Epoch #245: loss=0.09002448276927073
Epoch #246: loss=0.0930657829468449
Epoch #247: loss=0.07092004027217627
Epoch #248: loss=0.15554351999113958
Epoch #249: loss=0.14242737783739964

Training time: 0:28:09.265590

Finished.
n2one setting ettm1_ettm2_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm1_ettm2_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='ettm1_ettm2_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.60181e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.16968e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.60181e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.37185898283404295, 'MAE': 0.4324585528372378}
Finished.
------------------------- record done -------------------------
n2one setting ettm1_ettm2_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm1_ettm2_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='ettm1_ettm2_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.47787e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.62687e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.47787e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.657442208094537, 'MAE': 0.6068023974499183}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='ettm1_electricity_traffic', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/ettm1_electricity_traffic_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.9006434252214193
Epoch #1: loss=0.31412650076313636
Epoch #2: loss=0.21952558511640358
Epoch #3: loss=0.15252522486800224
Epoch #4: loss=0.11900430945507945
Epoch #5: loss=0.09102434683294727
Epoch #6: loss=0.07978837297904856
Epoch #7: loss=0.07298304575964983
Epoch #8: loss=0.062431651840323406
Epoch #9: loss=0.053520981416221663
Epoch #10: loss=0.04480745109212327
Epoch #11: loss=0.04921126793180803
Epoch #12: loss=0.04334774973741428
Epoch #13: loss=0.039198526497376485
Epoch #14: loss=0.03890411931006597
Epoch #15: loss=0.037541388450061726
Epoch #16: loss=0.0358277983057517
Epoch #17: loss=0.030528907286794155
Epoch #18: loss=0.02799687615554418
Epoch #19: loss=0.036400605120830286
Epoch #20: loss=0.028840581893685338
Epoch #21: loss=0.035062158800184984
Epoch #22: loss=0.02963539313796402
Epoch #23: loss=0.02965712082698837
Epoch #24: loss=0.026547033386246473
Epoch #25: loss=0.025700400220403773
Epoch #26: loss=0.02348180580113966
Epoch #27: loss=0.028138367698736132
Epoch #28: loss=0.0235907629738625
Epoch #29: loss=0.02180956096895011
Epoch #30: loss=0.02550523932902314
Epoch #31: loss=0.021332358150172377
Epoch #32: loss=0.02053715732606546
Epoch #33: loss=0.02207123406404564
Epoch #34: loss=0.02092266517185873
Epoch #35: loss=0.02204108130024166
Epoch #36: loss=0.017822938768274635
Epoch #37: loss=0.017491237477193097
Epoch #38: loss=0.014964092072773954
Epoch #39: loss=0.020719454021304626
Epoch #40: loss=0.014962279127509618
Epoch #41: loss=0.02267124764240032
Epoch #42: loss=0.02080640741919364
Epoch #43: loss=0.016274674552256067
Epoch #44: loss=0.021733249934277866
Epoch #45: loss=0.019592371116875135
Epoch #46: loss=0.015909587090812943
Epoch #47: loss=0.015266535699545364
Epoch #48: loss=0.015938033705054262
Epoch #49: loss=0.01933711089599032
Epoch #50: loss=0.02430959323948012
Epoch #51: loss=0.016734992995296787
Epoch #52: loss=0.015677320460356588
Epoch #53: loss=0.017827171877416947
Epoch #54: loss=0.027489105440507342
Epoch #55: loss=0.030599622533103246
Epoch #56: loss=0.017002999999549104
Epoch #57: loss=0.01828854743917192
Epoch #58: loss=0.01569908511921626
Epoch #59: loss=0.016479002841690966
Epoch #60: loss=0.018694432840664625
Epoch #61: loss=0.01949904953675396
Epoch #62: loss=0.016151982331776196
Epoch #63: loss=0.014079947970531432
Epoch #64: loss=0.012512237605018895
Epoch #65: loss=0.015681426647816157
Epoch #66: loss=0.01803117032831502
Epoch #67: loss=0.014599389450281774
Epoch #68: loss=0.016133044181720953
Epoch #69: loss=0.017345305459579324
Epoch #70: loss=0.01825894618096256
Epoch #71: loss=0.011724311822023627
Epoch #72: loss=0.013941825665812393
Epoch #73: loss=0.013464960914082362
Epoch #74: loss=0.013363356348298727
Epoch #75: loss=0.01617432863085817
Epoch #76: loss=0.016868019797576947
Epoch #77: loss=0.01760992252856214
Epoch #78: loss=0.012028076373817947
Epoch #79: loss=0.01185675241258635
Epoch #80: loss=0.018071502837495
Epoch #81: loss=0.012997742125805829
Epoch #82: loss=0.016997628012983965
Epoch #83: loss=0.009603309751185238
Epoch #84: loss=0.015479766356707489
Epoch #85: loss=0.016635962578345563
Epoch #86: loss=0.014013772336211348
Epoch #87: loss=0.010716849855135407
Epoch #88: loss=0.01418845916317637
Epoch #89: loss=0.014539718279884194
Epoch #90: loss=0.0124322530923008
Epoch #91: loss=0.009459225700713243
Epoch #92: loss=0.015562005530764159
Epoch #93: loss=0.011035584750183264
Epoch #94: loss=0.013437938825920547
Epoch #95: loss=0.016970080498237807
Epoch #96: loss=0.01423815286584636
Epoch #97: loss=0.012059218173262966
Epoch #98: loss=0.009840524613896659
Epoch #99: loss=0.015578332438984445
Epoch #100: loss=0.014165316722084733
Epoch #101: loss=0.009939866322542188
Epoch #102: loss=0.01541093690930226
Epoch #103: loss=0.013636282528677473
Epoch #104: loss=0.01356582413327594
Epoch #105: loss=0.011068099794880205
Epoch #106: loss=0.013114224412987263
Epoch #107: loss=0.011702641448362104
Epoch #108: loss=0.016938097500567944
Epoch #109: loss=0.014417046878338282
Epoch #110: loss=0.010375124449704983
Epoch #111: loss=0.01879668146585562
Epoch #112: loss=0.011631802791038098
Epoch #113: loss=0.011524279710548205
Epoch #114: loss=0.016668105352242123
Epoch #115: loss=0.013384588219665523
Epoch #116: loss=0.007893346374004438
Epoch #117: loss=0.013485133040303115
Epoch #118: loss=0.013233425194372024
Epoch #119: loss=0.013044232417291328
Epoch #120: loss=0.021459899794647096
Epoch #121: loss=0.008841498849201336
Epoch #122: loss=0.011069669691777329
Epoch #123: loss=0.010788558134340648
Epoch #124: loss=0.01152262382352564
Epoch #125: loss=0.014726353114474934
Epoch #126: loss=0.011245565369813562
Epoch #127: loss=0.010295607112575255
Epoch #128: loss=0.013320714438983848
Epoch #129: loss=0.011830516001047767
Epoch #130: loss=0.01259154295289446
Epoch #131: loss=0.008518149049701954
Epoch #132: loss=0.009267951288197924
Epoch #133: loss=0.012237363065175838
Epoch #134: loss=0.011530085236067732
Epoch #135: loss=0.010641639416741356
Epoch #136: loss=0.01248148101563503
Epoch #137: loss=0.011475070288097307
Epoch #138: loss=0.010489609258736318
Epoch #139: loss=0.010750753856637237
Epoch #140: loss=0.0138931392927712
Epoch #141: loss=0.011492695435709039
Epoch #142: loss=0.00891697657599211
Epoch #143: loss=0.008610095695415598
Epoch #144: loss=0.013785984083151988
Epoch #145: loss=0.010265124223218026
Epoch #146: loss=0.01034086497050185
Epoch #147: loss=0.023807607898156165
Epoch #148: loss=0.009958784998222656
Epoch #149: loss=0.010742072633055579
Epoch #150: loss=0.010488879704157923
Epoch #151: loss=0.010219382095870495
Epoch #152: loss=0.011498868222234298
Epoch #153: loss=0.010108432918028938
Epoch #154: loss=0.019078043718569093
Epoch #155: loss=0.009695666572001549
Epoch #156: loss=0.010920239419202414
Epoch #157: loss=0.013011287208742086
Epoch #158: loss=0.008609063849246526
Epoch #159: loss=0.012716705340594603
Epoch #160: loss=0.007509847120190761
Epoch #161: loss=0.01284840413273426
Epoch #162: loss=0.010399447117598543
Epoch #163: loss=0.01058074958103102
Epoch #164: loss=0.009714786071802503
Epoch #165: loss=0.011904525862145979
Epoch #166: loss=0.009818957167674364
Epoch #167: loss=0.009128137787666435
Epoch #168: loss=0.012181376172167248
Epoch #169: loss=0.008843676957813282
Epoch #170: loss=0.009322947881913235
Epoch #171: loss=0.011455138146706078
Epoch #172: loss=0.010219036782346822
Epoch #173: loss=0.012445467235178743
Epoch #174: loss=0.011636739619966138
Epoch #175: loss=0.01087689428179567
Epoch #176: loss=0.009963513711926539
Epoch #177: loss=0.007405074961946166
Epoch #178: loss=0.011830527960357702
Epoch #179: loss=0.009525914554476522
Epoch #180: loss=0.007705473282364789
Epoch #181: loss=0.012145184020903171
Epoch #182: loss=0.009329933272636655
Epoch #183: loss=0.018964591958329998
Epoch #184: loss=0.009044454154782536
Epoch #185: loss=0.009642141101779682
Epoch #186: loss=0.02076629416829073
Epoch #187: loss=0.010017307662994756
Epoch #188: loss=0.009119635897092256
Epoch #189: loss=0.00999735948082262
Epoch #190: loss=0.01598443212444891
Epoch #191: loss=0.01249899276057967
Epoch #192: loss=0.008500364136183318
Epoch #193: loss=0.01149148255613388
Epoch #194: loss=0.009076036145775387
Epoch #195: loss=0.011279438141692653
Epoch #196: loss=0.007280920402204791
Epoch #197: loss=0.009554484367233777
Epoch #198: loss=0.01088732967136714
Epoch #199: loss=0.009125982270841944
Epoch #200: loss=0.01187219110133399
Epoch #201: loss=0.009295471329906943
Epoch #202: loss=0.012905830223984172
Epoch #203: loss=0.009899040112191759
Epoch #204: loss=0.007515514097383193
Epoch #205: loss=0.008401322256299078
Epoch #206: loss=0.012197326604156775
Epoch #207: loss=0.009245123181479317
Epoch #208: loss=0.009105530670890623
Epoch #209: loss=0.011580502944100466
Epoch #210: loss=0.011391578613220007
Epoch #211: loss=0.007958000459276054
Epoch #212: loss=0.008513931533942278
Epoch #213: loss=0.012268764388620177
Epoch #214: loss=0.007103442978685241
Epoch #215: loss=0.008979797972048557
Epoch #216: loss=0.010821407111586362
Epoch #217: loss=0.00923663289918973
Epoch #218: loss=0.00992340316072992
Epoch #219: loss=0.0077437880984566
Epoch #220: loss=0.008251041196030935
Epoch #221: loss=0.01589477730665252
Epoch #222: loss=0.0072696233118567976
Epoch #223: loss=0.010155136495570935
Epoch #224: loss=0.007054698267808087
Epoch #225: loss=0.009235658302229546
Epoch #226: loss=0.010457195498952502
Epoch #227: loss=0.009281924464915603
Epoch #228: loss=0.00850138993647341
Epoch #229: loss=0.010254309961675737
Epoch #230: loss=0.008013419456541276
Epoch #231: loss=0.009402079867956811
Epoch #232: loss=0.012065807009768873
Epoch #233: loss=0.01054733599732779
Epoch #234: loss=0.009375326780896689
Epoch #235: loss=0.0083548294465949
Epoch #236: loss=0.009360448337558145
Epoch #237: loss=0.01083629228172977
Epoch #238: loss=0.007968797140325367
Epoch #239: loss=0.010108962252306017
Epoch #240: loss=0.0083909767359923
Epoch #241: loss=0.00810935521349927
Epoch #242: loss=0.009493676843830932
Epoch #243: loss=0.006823572512563272
Epoch #244: loss=0.012121615726062717
Epoch #245: loss=0.00989117061108057
Epoch #246: loss=0.008539863296181324
Epoch #247: loss=0.008389927807617567
Epoch #248: loss=0.008576658454065295
Epoch #249: loss=0.008098456865351725

Training time: 15:03:10.027864

Finished.
n2one setting ettm1_electricity_traffic -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm1_electricity_traffic_epochs_250_seed_2021/model.pkl', muti_dataset='ettm1_electricity_traffic', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.17905e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.50456e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.17905e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.7373425717889698, 'MAE': 0.6823251041461373}
Finished.
------------------------- record done -------------------------
n2one setting ettm1_electricity_traffic -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm1_electricity_traffic_epochs_250_seed_2021/model.pkl', muti_dataset='ettm1_electricity_traffic', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
Evaluation result: {'MSE': 0.2518521791921257, 'MAE': 0.33867390143360865}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='ettm1_electricity_weather', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/ettm1_electricity_weather_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.938108492330466
Epoch #1: loss=0.8597538312220706
Epoch #2: loss=0.6027836907009839
Epoch #3: loss=0.494814857132941
Epoch #4: loss=0.42190260269455404
Epoch #5: loss=0.38016412752633655
Epoch #6: loss=0.3234869816949248
Epoch #7: loss=0.3188116945867432
Epoch #8: loss=0.29683588255800347
Epoch #9: loss=0.2575053713549782
Epoch #10: loss=0.2272044588400665
Epoch #11: loss=0.21605340391397476
Epoch #12: loss=0.19167897587007318
Epoch #13: loss=0.18194139709269536
Epoch #14: loss=0.1781043292507113
Epoch #15: loss=0.1716074210867369
Epoch #16: loss=0.14245322634929053
Epoch #17: loss=0.13586315764478465
Epoch #18: loss=0.1321966137591354
Epoch #19: loss=0.12689673108719915
Epoch #20: loss=0.13027969652568328
Epoch #21: loss=0.10251307976562217
Epoch #22: loss=0.11665993671364791
Epoch #23: loss=0.09447357943541677
Epoch #24: loss=0.0890601101310601
Epoch #25: loss=0.07222429185054738
Epoch #26: loss=0.10795959649222524
Epoch #27: loss=0.07593578661339326
Epoch #28: loss=0.06637034017993293
Epoch #29: loss=0.07422125779675039
Epoch #30: loss=0.07104766018709491
Epoch #31: loss=0.07499196750434459
Epoch #32: loss=0.06833450188964356
Epoch #33: loss=0.057580713303655634
Epoch #34: loss=0.07059096245683064
Epoch #35: loss=0.06268311597734648
Epoch #36: loss=0.06109919661770486
Epoch #37: loss=0.05409344945586802
Epoch #38: loss=0.048424000911643554
Epoch #39: loss=0.04207692085310047
Epoch #40: loss=0.04301567946875458
Epoch #41: loss=0.044187872102171934
Epoch #42: loss=0.05343068495143059
Epoch #43: loss=0.08213383750729887
Epoch #44: loss=0.045494136211914976
Epoch #45: loss=0.04487869536436512
Epoch #46: loss=0.04939984071443076
Epoch #47: loss=0.09254308958673152
Epoch #48: loss=0.04687121231043868
Epoch #49: loss=0.05970830416473347
Epoch #50: loss=0.05571578136663468
Epoch #51: loss=0.04407359576229963
Epoch #52: loss=0.043896107139019036
Epoch #53: loss=0.039269449057281226
Epoch #54: loss=0.03571433862007884
Epoch #55: loss=0.03828928902531927
Epoch #56: loss=0.03794857531502406
Epoch #57: loss=0.028007202631502554
Epoch #58: loss=0.03891790173778716
Epoch #59: loss=0.05546608199261378
Epoch #60: loss=0.04478577838029567
Epoch #61: loss=0.03362526553494377
Epoch #62: loss=0.04095377532899244
Epoch #63: loss=0.033632838841678586
Epoch #64: loss=0.040587913085298105
Epoch #65: loss=0.03593931813898637
Epoch #66: loss=0.03459898692746933
Epoch #67: loss=0.03036004202908644
Epoch #68: loss=0.022440944823167188
Epoch #69: loss=0.02984102877532002
Epoch #70: loss=0.023588832315609026
Epoch #71: loss=0.029506135777786227
Epoch #72: loss=0.032291980989032826
Epoch #73: loss=0.03149833486418047
Epoch #74: loss=0.03745989369647317
Epoch #75: loss=0.028765396329485837
Epoch #76: loss=0.028176856123811083
Epoch #77: loss=0.029197608410477034
Epoch #78: loss=0.019968441931248575
Epoch #79: loss=0.02113428081850152
Epoch #80: loss=0.024594830430708512
Epoch #81: loss=0.023554476239463554
Epoch #82: loss=0.03303623149059609
Epoch #83: loss=0.027367414340478312
Epoch #84: loss=0.026357124766722508
Epoch #85: loss=0.022236586629358436
Epoch #86: loss=0.016397115095796885
Epoch #87: loss=0.030506072196831106
Epoch #88: loss=0.027370672908093904
Epoch #89: loss=0.02746398113072881
Epoch #90: loss=0.03130256345036424
Epoch #91: loss=0.023515663567251478
Epoch #92: loss=0.02337628970177605
Epoch #93: loss=0.021138458928144043
Epoch #94: loss=0.017210168757491522
Epoch #95: loss=0.031394281013876556
Epoch #96: loss=0.02481349078107849
Epoch #97: loss=0.043927027430585665
Epoch #98: loss=0.020533166605460212
Epoch #99: loss=0.03940056570169553
Epoch #100: loss=0.02294073755203814
Epoch #101: loss=0.018232476980459236
Epoch #102: loss=0.01646342501255642
Epoch #103: loss=0.02701135589376966
Epoch #104: loss=0.019109432281166648
Epoch #105: loss=0.023563000607023318
Epoch #106: loss=0.02214634781147291
Epoch #107: loss=0.034987944101865336
Epoch #108: loss=0.022060560073258677
Epoch #109: loss=0.022999830457333777
Epoch #110: loss=0.01945055407821851
Epoch #111: loss=0.024258551440317466
Epoch #112: loss=0.029056451591343083
Epoch #113: loss=0.012752700883696146
Epoch #114: loss=0.016413314085728204
Epoch #115: loss=0.022859613458279977
Epoch #116: loss=0.023084052368008673
Epoch #117: loss=0.04359410903201954
Epoch #118: loss=0.022374056121620595
Epoch #119: loss=0.016869747375337116
Epoch #120: loss=0.016543045420005825
Epoch #121: loss=0.014979713414951785
Epoch #122: loss=0.025627422129996146
Epoch #123: loss=0.01893097221812002
Epoch #124: loss=0.013689507816397252
Epoch #125: loss=0.02676095181000393
Epoch #126: loss=0.014635692004084473
Epoch #127: loss=0.02340612159007848
Epoch #128: loss=0.01891618996712915
Epoch #129: loss=0.01931703624844957
Epoch #130: loss=0.01912006491297003
Epoch #131: loss=0.022848862911738436
Epoch #132: loss=0.0177750441028838
Epoch #133: loss=0.03295616355517166
Epoch #134: loss=0.026061101078755592
Epoch #135: loss=0.024445778476145878
Epoch #136: loss=0.016058700986944046
Epoch #137: loss=0.018168579412405718
Epoch #138: loss=0.01351070212975519
Epoch #139: loss=0.016637236962755673
Epoch #140: loss=0.020294438899454384
Epoch #141: loss=0.016025527276836243
Epoch #142: loss=0.014489622344718154
Epoch #143: loss=0.019295343459328877
Epoch #144: loss=0.015791596313606812
Epoch #145: loss=0.015047295010088052
Epoch #146: loss=0.01824099536531204
Epoch #147: loss=0.01266217010780875
Epoch #148: loss=0.01786707559348131
Epoch #149: loss=0.011984062228252976
Epoch #150: loss=0.014152951877077718
Epoch #151: loss=0.01991452580280784
Epoch #152: loss=0.01489969502660373
Epoch #153: loss=0.016467655709568756
Epoch #154: loss=0.020411589139338854
Epoch #155: loss=0.020644672932337408
Epoch #156: loss=0.01742894396897374
Epoch #157: loss=0.013489957436120564
Epoch #158: loss=0.01657972757216132
Epoch #159: loss=0.03255359876046332
Epoch #160: loss=0.022773465367818418
Epoch #161: loss=0.014015967289100312
Epoch #162: loss=0.013205129901167036
Epoch #163: loss=0.011605997999912835
Epoch #164: loss=0.020416110432570196
Epoch #165: loss=0.019026464489503247
Epoch #166: loss=0.009040663029065917
Epoch #167: loss=0.01768320272338457
Epoch #168: loss=0.013514271743501947
Epoch #169: loss=0.023611597541453675
Epoch #170: loss=0.015015841958596886
Epoch #171: loss=0.016715604241861956
Epoch #172: loss=0.01364382239884252
Epoch #173: loss=0.028731138066924566
Epoch #174: loss=0.015979772807598405
Epoch #175: loss=0.015211763071623375
Epoch #176: loss=0.01037164552995087
Epoch #177: loss=0.011992078436591906
Epoch #178: loss=0.01600047839917997
Epoch #179: loss=0.022102721543821986
Epoch #180: loss=0.011944919970932328
Epoch #181: loss=0.015367592991815553
Epoch #182: loss=0.03213449450880913
Epoch #183: loss=0.024755551844611555
Epoch #184: loss=0.016754686047925287
Epoch #185: loss=0.016131777083338628
Epoch #186: loss=0.01436065841959165
Epoch #187: loss=0.012929188224077928
Epoch #188: loss=0.015387266831795747
Epoch #189: loss=0.016613613464706967
Epoch #190: loss=0.014129319098321514
Epoch #191: loss=0.009940131989098934
Epoch #192: loss=0.01444574395749411
Epoch #193: loss=0.010782893899601869
Epoch #194: loss=0.021069744356007798
Epoch #195: loss=0.010979740838156024
Epoch #196: loss=0.01891315436428387
Epoch #197: loss=0.01367758298907351
Epoch #198: loss=0.011376632793169786
Epoch #199: loss=0.012874316921091493
Epoch #200: loss=0.01688841505053547
Epoch #201: loss=0.02220729550843611
Epoch #202: loss=0.018766921800372642
Epoch #203: loss=0.014862137466510394
Epoch #204: loss=0.01962886665045029
Epoch #205: loss=0.014186109039462927
Epoch #206: loss=0.01371828452540905
Epoch #207: loss=0.01190721818648198
Epoch #208: loss=0.01085741851615717
Epoch #209: loss=0.015535128010451852
Epoch #210: loss=0.022590504036357824
Epoch #211: loss=0.011091146557643886
Epoch #212: loss=0.009268152034697098
Epoch #213: loss=0.02998345758671308
Epoch #214: loss=0.014048742055281602
Epoch #215: loss=0.015165137606198175
Epoch #216: loss=0.021233365304219178
Epoch #217: loss=0.015733334319825366
Epoch #218: loss=0.01964231452666608
Epoch #219: loss=0.011741456020930418
Epoch #220: loss=0.011716144939874138
Epoch #221: loss=0.017507527530188124
Epoch #222: loss=0.015289651896601657
Epoch #223: loss=0.012125082045738903
Epoch #224: loss=0.012870355756035044
Epoch #225: loss=0.01803895578685206
Epoch #226: loss=0.016405143525956106
Epoch #227: loss=0.01456300516914597
Epoch #228: loss=0.014657027051034877
Epoch #229: loss=0.013847508426435687
Epoch #230: loss=0.020602867332600607
Epoch #231: loss=0.014262085401013432
Epoch #232: loss=0.020478418192828814
Epoch #233: loss=0.025584052588859593
Epoch #234: loss=0.009892142162522998
Epoch #235: loss=0.01699806876097189
Epoch #236: loss=0.016895403967475697
Epoch #237: loss=0.028014427347351958
Epoch #238: loss=0.011497669927086474
Epoch #239: loss=0.012077488130681716
Epoch #240: loss=0.012715770639271044
Epoch #241: loss=0.011654017739373197
Epoch #242: loss=0.008790546280182976
Epoch #243: loss=0.019914144693594815
Epoch #244: loss=0.0232328132330505
Epoch #245: loss=0.017451343192119287
Epoch #246: loss=0.013631110244291424
Epoch #247: loss=0.025174082530413328
Epoch #248: loss=0.0140091063399141
Epoch #249: loss=0.011123206688454713

Training time: 5:01:43.300952

Finished.
n2one setting ettm1_electricity_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm1_electricity_weather_epochs_250_seed_2021/model.pkl', muti_dataset='ettm1_electricity_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.57184e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.57184e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.37260043245169516, 'MAE': 0.4058387408080758}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='ettm1_electricity_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/ettm1_electricity_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.8025273035554326
Epoch #1: loss=0.7649195734192343
Epoch #2: loss=0.522933980208986
Epoch #3: loss=0.4560592840261319
Epoch #4: loss=0.35000772822429155
Epoch #5: loss=0.3151568452225012
Epoch #6: loss=0.29527793390785945
Epoch #7: loss=0.2569975466850926
Epoch #8: loss=0.24925916446920704
Epoch #9: loss=0.21220614587997688
Epoch #10: loss=0.1963170902474838
Epoch #11: loss=0.17836219631135464
Epoch #12: loss=0.16138799933387954
Epoch #13: loss=0.15040986372486634
Epoch #14: loss=0.1473536285407403
Epoch #15: loss=0.12590014508870595
Epoch #16: loss=0.10966229319353314
Epoch #17: loss=0.12631469288950456
Epoch #18: loss=0.09635334449327167
Epoch #19: loss=0.09766508224694168
Epoch #20: loss=0.10813342888894327
Epoch #21: loss=0.09835353967295411
Epoch #22: loss=0.09705747027388391
Epoch #23: loss=0.08704422902425422
Epoch #24: loss=0.08276212036143989
Epoch #25: loss=0.07639180884477409
Epoch #26: loss=0.09069248184780865
Epoch #27: loss=0.06510603720157901
Epoch #28: loss=0.06648967145284747
Epoch #29: loss=0.05951851791126982
Epoch #30: loss=0.06311176772201982
Epoch #31: loss=0.062963231495472
Epoch #32: loss=0.05779056267484146
Epoch #33: loss=0.06551052560851744
Epoch #34: loss=0.05568483485223945
Epoch #35: loss=0.052982859239530035
Epoch #36: loss=0.04863680371850291
Epoch #37: loss=0.045642834338907375
Epoch #38: loss=0.04323428511441521
Epoch #39: loss=0.045486207616597635
Epoch #40: loss=0.047661051675951215
Epoch #41: loss=0.05039471995208741
Epoch #42: loss=0.04297397616867195
Epoch #43: loss=0.0404506169464987
Epoch #44: loss=0.047961798715679085
Epoch #45: loss=0.03756463397397002
Epoch #46: loss=0.042347041555844685
Epoch #47: loss=0.051624480529126764
Epoch #48: loss=0.038037742415497844
Epoch #49: loss=0.04008409332155305
Epoch #50: loss=0.04301995521151077
Epoch #51: loss=0.04944440083413878
Epoch #52: loss=0.04835563281016862
Epoch #53: loss=0.043805279352647414
Epoch #54: loss=0.03295262338566211
Epoch #55: loss=0.0458341487306718
Epoch #56: loss=0.031502853533910476
Epoch #57: loss=0.05788141337962931
Epoch #58: loss=0.02706024386570789
Epoch #59: loss=0.0459602576406563
Epoch #60: loss=0.045472488267456784
Epoch #61: loss=0.042454926872639645
Epoch #62: loss=0.05296828791923711
Epoch #63: loss=0.03233577262384214
Epoch #64: loss=0.04217170675538535
Epoch #65: loss=0.041147257687236344
Epoch #66: loss=0.03472130550071597
Epoch #67: loss=0.028634416441748137
Epoch #68: loss=0.051693632678635526
Epoch #69: loss=0.02933796087368939
Epoch #70: loss=0.027836357829544474
Epoch #71: loss=0.023527267440187963
Epoch #72: loss=0.022793169759611105
Epoch #73: loss=0.04179945796255625
Epoch #74: loss=0.03348252738651354
Epoch #75: loss=0.031309033104780074
Epoch #76: loss=0.02256097706130651
Epoch #77: loss=0.031828433473128824
Epoch #78: loss=0.023680263309506698
Epoch #79: loss=0.03727104722193497
Epoch #80: loss=0.04157615163130686
Epoch #81: loss=0.026608145892661174
Epoch #82: loss=0.02793992479085265
Epoch #83: loss=0.03351528018487015
Epoch #84: loss=0.03396834073423901
Epoch #85: loss=0.02751733952694956
Epoch #86: loss=0.031243316662456732
Epoch #87: loss=0.03988013493910651
Epoch #88: loss=0.02980704973828431
Epoch #89: loss=0.025336887888432316
Epoch #90: loss=0.029784191708313302
Epoch #91: loss=0.028334654040757894
Epoch #92: loss=0.03819938828785192
Epoch #93: loss=0.030539529927259803
Epoch #94: loss=0.029265160609022987
Epoch #95: loss=0.03099465583800338
Epoch #96: loss=0.021069566179443534
Epoch #97: loss=0.024603376278366125
Epoch #98: loss=0.03131435151821386
Epoch #99: loss=0.019652397111606074
Epoch #100: loss=0.017618071647388312
Epoch #101: loss=0.017278505803037927
Epoch #102: loss=0.051875541714595304
Epoch #103: loss=0.025120447583921145
Epoch #104: loss=0.02291469089943669
Epoch #105: loss=0.03561815069782931
Epoch #106: loss=0.03480421928106807
Epoch #107: loss=0.025256961712832836
Epoch #108: loss=0.022915489319883124
Epoch #109: loss=0.041280524822650475
Epoch #110: loss=0.015627964647993556
Epoch #111: loss=0.01740065744790413
Epoch #112: loss=0.02077202324923265
Epoch #113: loss=0.019776160850340282
Epoch #114: loss=0.02093828442687963
Epoch #115: loss=0.02052220097376609
Epoch #116: loss=0.030383806770174382
Epoch #117: loss=0.021491670210311627
Epoch #118: loss=0.025538332161822302
Epoch #119: loss=0.024643527833498356
Epoch #120: loss=0.029838919058880385
Epoch #121: loss=0.033214946667088525
Epoch #122: loss=0.017774719699895393
Epoch #123: loss=0.03600005554069546
Epoch #124: loss=0.018743022541029324
Epoch #125: loss=0.02609481586550828
Epoch #126: loss=0.023374383243636283
Epoch #127: loss=0.02181330983294174
Epoch #128: loss=0.02121353907928364
Epoch #129: loss=0.030291751113733934
Epoch #130: loss=0.021465143254745807
Epoch #131: loss=0.025973810007288944
Epoch #132: loss=0.03375619745724286
Epoch #133: loss=0.027101832765551722
Epoch #134: loss=0.021956577887142295
Epoch #135: loss=0.022713251635500722
Epoch #136: loss=0.015420751543784075
Epoch #137: loss=0.02407911896743291
Epoch #138: loss=0.015962272849933738
Epoch #139: loss=0.01844715226051288
Epoch #140: loss=0.01941202638845425
Epoch #141: loss=0.021324305506149197
Epoch #142: loss=0.024232142328058696
Epoch #143: loss=0.0373506548047504
Epoch #144: loss=0.03209000488619923
Epoch #145: loss=0.021422659349456592
Epoch #146: loss=0.01674757680242799
Epoch #147: loss=0.017784534193924628
Epoch #148: loss=0.017192320670994164
Epoch #149: loss=0.023079766321461647
Epoch #150: loss=0.018590619893717197
Epoch #151: loss=0.023758595888263217
Epoch #152: loss=0.017753655546317425
Epoch #153: loss=0.018274948788423312
Epoch #154: loss=0.024332366504891338
Epoch #155: loss=0.02990387194834458
Epoch #156: loss=0.019325393046807113
Epoch #157: loss=0.02237849283555988
Epoch #158: loss=0.022082014287897276
Epoch #159: loss=0.01845016301410985
Epoch #160: loss=0.013497317908074954
Epoch #161: loss=0.019625505934955607
Epoch #162: loss=0.022019546195138795
Epoch #163: loss=0.01609495443990454
Epoch #164: loss=0.02191664042903165
Epoch #165: loss=0.017499175829888212
Epoch #166: loss=0.013378508321286918
Epoch #167: loss=0.01278630517224562
Epoch #168: loss=0.016272950555225287
Epoch #169: loss=0.017729605292141272
Epoch #170: loss=0.015732838304350426
Epoch #171: loss=0.019814789960989454
Epoch #172: loss=0.022496210503980846
Epoch #173: loss=0.01760247196721406
Epoch #174: loss=0.01827789535848698
Epoch #175: loss=0.023231834734221645
Epoch #176: loss=0.02203599035471116
Epoch #177: loss=0.018916042072198574
Epoch #178: loss=0.01952350648404236
Epoch #179: loss=0.03299893768853508
Epoch #180: loss=0.0186683543594828
Epoch #181: loss=0.019999468873549416
Epoch #182: loss=0.017243819172247588
Epoch #183: loss=0.02091470811077777
Epoch #184: loss=0.015988358899930437
Epoch #185: loss=0.022391410487847787
Epoch #186: loss=0.018794271474710994
Epoch #187: loss=0.022375629038502026
Epoch #188: loss=0.02635237929883742
Epoch #189: loss=0.023985273578385684
Epoch #190: loss=0.028598752368056653
Epoch #191: loss=0.01576251661779893
Epoch #192: loss=0.018582429026890383
Epoch #193: loss=0.012458166037172572
Epoch #194: loss=0.012893998700447435
Epoch #195: loss=0.017490467743824838
Epoch #196: loss=0.020582614404659527
Epoch #197: loss=0.020826390130198835
Epoch #198: loss=0.02158265445905272
Epoch #199: loss=0.016299490757656337
Epoch #200: loss=0.013468144665068179
Epoch #201: loss=0.013792351523400559
Epoch #202: loss=0.02178429624918328
Epoch #203: loss=0.02894987382905503
Epoch #204: loss=0.017859639482305605
Epoch #205: loss=0.016029918440001303
Epoch #206: loss=0.01625898016808445
Epoch #207: loss=0.021017266937825994
Epoch #208: loss=0.022591677271103595
Epoch #209: loss=0.016282811699270764
Epoch #210: loss=0.013492179339107893
Epoch #211: loss=0.014697267414457576
Epoch #212: loss=0.01489393767551519
Epoch #213: loss=0.016958645621728947
Epoch #214: loss=0.016209516746526147
Epoch #215: loss=0.012544275221829165
Epoch #216: loss=0.024179122281630577
Epoch #217: loss=0.012140957279103425
Epoch #218: loss=0.012894241667612839
Epoch #219: loss=0.019521223426529427
Epoch #220: loss=0.02026703997030649
Epoch #221: loss=0.02029807958426639
Epoch #222: loss=0.018786640449509243
Epoch #223: loss=0.021505570389939856
Epoch #224: loss=0.014471721408121726
Epoch #225: loss=0.02607783372308511
Epoch #226: loss=0.022428572965744773
Epoch #227: loss=0.01733614768480252
Epoch #228: loss=0.013597118905540008
Epoch #229: loss=0.010466666101060314
Epoch #230: loss=0.013286907187241868
Epoch #231: loss=0.012289150783737355
Epoch #232: loss=0.01249572359580163
Epoch #233: loss=0.015016867783646482
Epoch #234: loss=0.015344590971739415
Epoch #235: loss=0.022052145038169862
Epoch #236: loss=0.015044285419742879
Epoch #237: loss=0.010073289707618054
Epoch #238: loss=0.01534268717334592
Epoch #239: loss=0.014863040255252546
Epoch #240: loss=0.027318986045258283
Epoch #241: loss=0.025789212175432646
Epoch #242: loss=0.017032944829620915
Epoch #243: loss=0.01791005062011262
Epoch #244: loss=0.015547992838615113
Epoch #245: loss=0.02787854553796077
Epoch #246: loss=0.022169814310858356
Epoch #247: loss=0.02452515410071047
Epoch #248: loss=0.01917651273414616
Epoch #249: loss=0.012447052043845521

Training time: 4:47:13.911282

Finished.
n2one setting ettm1_electricity_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm1_electricity_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='ettm1_electricity_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.30845e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.62523e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.30845e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.45280990202432286, 'MAE': 0.5010912968311988}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='ettm1_traffic_weather', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/ettm1_traffic_weather_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.1795071510968935
Epoch #1: loss=0.4347380404842311
Epoch #2: loss=0.32628647055688237
Epoch #3: loss=0.25454646369672324
Epoch #4: loss=0.19325619120900836
Epoch #5: loss=0.1761749477744169
Epoch #6: loss=0.14881161057097098
Epoch #7: loss=0.12664890501884385
Epoch #8: loss=0.12157492955382064
Epoch #9: loss=0.0998647236446534
Epoch #10: loss=0.09507586874038777
Epoch #11: loss=0.08751691996562269
Epoch #12: loss=0.07926395923433799
Epoch #13: loss=0.07295453869473517
Epoch #14: loss=0.06293998978300656
Epoch #15: loss=0.06422552967794215
Epoch #16: loss=0.05798102293636969
Epoch #17: loss=0.051936620123812866
Epoch #18: loss=0.05494337620082062
Epoch #19: loss=0.05751959415871621
Epoch #20: loss=0.05924482792341363
Epoch #21: loss=0.04613122951785295
Epoch #22: loss=0.041128374635655274
Epoch #23: loss=0.042123422522338166
Epoch #24: loss=0.04025471697442826
Epoch #25: loss=0.044112760799852005
Epoch #26: loss=0.03953104895991258
Epoch #27: loss=0.03656870777814807
Epoch #28: loss=0.03516810345041303
Epoch #29: loss=0.03651217769860426
Epoch #30: loss=0.03472720876774306
Epoch #31: loss=0.029179540186969187
Epoch #32: loss=0.03317598004231553
Epoch #33: loss=0.030069109298717707
Epoch #34: loss=0.0330694367052693
Epoch #35: loss=0.03102882620808591
Epoch #36: loss=0.03401759061164682
Epoch #37: loss=0.028024900659040296
Epoch #38: loss=0.03008696069170175
Epoch #39: loss=0.0299379888541781
Epoch #40: loss=0.02776676520691756
Epoch #41: loss=0.022852166038362914
Epoch #42: loss=0.03076260377313927
Epoch #43: loss=0.023314440617098517
Epoch #44: loss=0.028219094078053408
Epoch #45: loss=0.02550201042542582
Epoch #46: loss=0.03161083616426907
Epoch #47: loss=0.028421992018173456
Epoch #48: loss=0.03816150523591642
Epoch #49: loss=0.025270087684989513
Epoch #50: loss=0.02144723332389149
Epoch #51: loss=0.022781650791707676
Epoch #52: loss=0.021677529282059346
Epoch #53: loss=0.024430039798536828
Epoch #54: loss=0.022600035815516815
Epoch #55: loss=0.02628664330749496
Epoch #56: loss=0.02356187408592902
Epoch #57: loss=0.023626149302279603
Epoch #58: loss=0.01977872858430001
Epoch #59: loss=0.023065193537990455
Epoch #60: loss=0.03089692806057141
Epoch #61: loss=0.017860676108010516
Epoch #62: loss=0.028030453316113178
Epoch #63: loss=0.022064151046903818
Epoch #64: loss=0.028682553298132716
Epoch #65: loss=0.018529285899507454
Epoch #66: loss=0.02396735544246544
Epoch #67: loss=0.018669614314900097
Epoch #68: loss=0.019819288856354547
Epoch #69: loss=0.02075798569057547
Epoch #70: loss=0.020637449538811744
Epoch #71: loss=0.021189116958734135
Epoch #72: loss=0.016957524907943566
Epoch #73: loss=0.018181261956278397
Epoch #74: loss=0.02567988115070684
Epoch #75: loss=0.01741666558640983
Epoch #76: loss=0.025963010270664163
Epoch #77: loss=0.027687149230614553
Epoch #78: loss=0.02153756246168852
Epoch #79: loss=0.01841369124295944
Epoch #80: loss=0.01621122381437735
Epoch #81: loss=0.01870045285838738
Epoch #82: loss=0.01927991488933443
Epoch #83: loss=0.02269194155475135
Epoch #84: loss=0.017057943903544277
Epoch #85: loss=0.014141688750291738
Epoch #86: loss=0.01729385267352132
Epoch #87: loss=0.02535355243872275
Epoch #88: loss=0.02377151558593302
Epoch #89: loss=0.02841971914598732
Epoch #90: loss=0.016931963603111198
Epoch #91: loss=0.013442253640295266
Epoch #92: loss=0.02046480083030579
Epoch #93: loss=0.01850185010976986
Epoch #94: loss=0.03656855101753606
Epoch #95: loss=0.014459583721459284
Epoch #96: loss=0.020534271820776218
Epoch #97: loss=0.013423077771677124
Epoch #98: loss=0.01967615612622742
Epoch #99: loss=0.019220348948444984
Epoch #100: loss=0.0137234036820651
Epoch #101: loss=0.01748405031562232
Epoch #102: loss=0.018230408888509096
Epoch #103: loss=0.016561138804193153
Epoch #104: loss=0.014147249392885922
Epoch #105: loss=0.0354745419782346
Epoch #106: loss=0.0192575139429536
Epoch #107: loss=0.014080672301718493
Epoch #108: loss=0.014952559612808725
Epoch #109: loss=0.01741500366209163
Epoch #110: loss=0.01982780861274885
Epoch #111: loss=0.015150874854040614
Epoch #112: loss=0.01268391575213901
Epoch #113: loss=0.014399870606448794
Epoch #114: loss=0.02312633567470907
Epoch #115: loss=0.021825092773605087
Epoch #116: loss=0.017265020989648713
Epoch #117: loss=0.01516675922336695
Epoch #118: loss=0.01432778352157506
Epoch #119: loss=0.017319349613403527
Epoch #120: loss=0.01513754686971197
Epoch #121: loss=0.014431325590787808
Epoch #122: loss=0.014712852098026237
Epoch #123: loss=0.01262055876950611
Epoch #124: loss=0.018108232694294554
Epoch #125: loss=0.012691253528474297
Epoch #126: loss=0.010110911525963589
Epoch #127: loss=0.018464516341614768
Epoch #128: loss=0.018887081904015276
Epoch #129: loss=0.02256725304528244
Epoch #130: loss=0.015309830661312739
Epoch #131: loss=0.01361861822993489
Epoch #132: loss=0.015218513245554226
Epoch #133: loss=0.012267047282436798
Epoch #134: loss=0.017320919086668718
Epoch #135: loss=0.013292585305084327
Epoch #136: loss=0.01616824621735327
Epoch #137: loss=0.0158443450705328
Epoch #138: loss=0.013445516229463815
Epoch #139: loss=0.014011390421350354
Epoch #140: loss=0.012334542470446502
Epoch #141: loss=0.016481544504999324
Epoch #142: loss=0.019747252738827402
Epoch #143: loss=0.012218149953704505
Epoch #144: loss=0.015744091156714473
Epoch #145: loss=0.015035513148387844
Epoch #146: loss=0.01459277198412062
Epoch #147: loss=0.012856175694601457
Epoch #148: loss=0.0119082712909819
Epoch #149: loss=0.021448348014065383
Epoch #150: loss=0.026592599463574507
Epoch #151: loss=0.013032668758299226
Epoch #152: loss=0.015349495062042282
Epoch #153: loss=0.013072944285793
Epoch #154: loss=0.008665456054161781
Epoch #155: loss=0.01953347350195676
Epoch #156: loss=0.015728969585948296
Epoch #157: loss=0.01089011886011026
Epoch #158: loss=0.011345411494625948
Epoch #159: loss=0.012764057979274912
Epoch #160: loss=0.014031181104356388
Epoch #161: loss=0.014286495464147163
Epoch #162: loss=0.01535237850546236
Epoch #163: loss=0.012146115772618038
Epoch #164: loss=0.009736451079782245
Epoch #165: loss=0.010419852978501168
Epoch #166: loss=0.019938829487641068
Epoch #167: loss=0.010896643715035492
Epoch #168: loss=0.014314937965383181
Epoch #169: loss=0.0136499779367663
Epoch #170: loss=0.012723826499020286
Epoch #171: loss=0.013735281559276094
Epoch #172: loss=0.012735547462986028
Epoch #173: loss=0.01949410306111608
Epoch #174: loss=0.009998772124808672
Epoch #175: loss=0.015752322962756235
Epoch #176: loss=0.015510130204780656
Epoch #177: loss=0.011096766631467811
Epoch #178: loss=0.01580230991952525
Epoch #179: loss=0.015109755011233066
Epoch #180: loss=0.009923405497874176
Epoch #181: loss=0.013264779907756007
Epoch #182: loss=0.010526266704318377
Epoch #183: loss=0.008973287465361603
Epoch #184: loss=0.027891367705082014
Epoch #185: loss=0.01002195673808738
Epoch #186: loss=0.011651547876458865
Epoch #187: loss=0.014392939324952406
Epoch #188: loss=0.008588318961492617
Epoch #189: loss=0.011668859331190233
Epoch #190: loss=0.01723399707975381
Epoch #191: loss=0.012872287918267644
Epoch #192: loss=0.014522304977776583
Epoch #193: loss=0.009711799509313114
Epoch #194: loss=0.013379337751480504
Epoch #195: loss=0.011506442212848276
Epoch #196: loss=0.009517755279820843
Epoch #197: loss=0.01160451094407883
Epoch #198: loss=0.010153977663071828
Epoch #199: loss=0.013440172256601773
Epoch #200: loss=0.014339116186572905
Epoch #201: loss=0.010499297338314494
Epoch #202: loss=0.013957095197737331
Epoch #203: loss=0.012801665091091763
Epoch #204: loss=0.018077826428840153
Epoch #205: loss=0.016578967599655336
Epoch #206: loss=0.014112413282827573
Epoch #207: loss=0.013236546748543358
Epoch #208: loss=0.012036655548602563
Epoch #209: loss=0.011746600216223643
Epoch #210: loss=0.01152115397340332
Epoch #211: loss=0.012037946857648354
Epoch #212: loss=0.014944654256210313
Epoch #213: loss=0.013954453353663373
Epoch #214: loss=0.01576663230723744
Epoch #215: loss=0.00695318850730463
Epoch #216: loss=0.010266272702852101
Epoch #217: loss=0.00993797229034777
Epoch #218: loss=0.016775715825552207
Epoch #219: loss=0.012410738958911897
Epoch #220: loss=0.010133597523725599
Epoch #221: loss=0.00938749152899798
Epoch #222: loss=0.010940245782573955
Epoch #223: loss=0.011085800711607205
Epoch #224: loss=0.012142319912652903
Epoch #225: loss=0.009525895738472812
Epoch #226: loss=0.009843800731798509
Epoch #227: loss=0.010206321902815004
Epoch #228: loss=0.015705068130531734
Epoch #229: loss=0.010772298677416272
Epoch #230: loss=0.011923793024476463
Epoch #231: loss=0.01250401150004123
Epoch #232: loss=0.014007669418894001
Epoch #233: loss=0.010537591509550014
Epoch #234: loss=0.010711784481791215
Epoch #235: loss=0.016682634156472354
Epoch #236: loss=0.00908444401502331
Epoch #237: loss=0.00936131828402201
Epoch #238: loss=0.01542296583822657
Epoch #239: loss=0.013334168960600346
Epoch #240: loss=0.010614680502538722
Epoch #241: loss=0.01209409375633034
Epoch #242: loss=0.01281512009971972
Epoch #243: loss=0.008405505743922612
Epoch #244: loss=0.010763301457403004
Epoch #245: loss=0.012008673504031977
Epoch #246: loss=0.02308664136611933
Epoch #247: loss=0.010924529051126926
Epoch #248: loss=0.008034529130587428
Epoch #249: loss=0.014124222425993213

Training time: 11:00:10.920504

Finished.
n2one setting ettm1_traffic_weather -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm1_traffic_weather_epochs_250_seed_2021/model.pkl', muti_dataset='ettm1_traffic_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.08575e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.27515e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.49704e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.08575e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4123306185629893, 'MAE': 0.4575414571795074}
Finished.
------------------------- record done -------------------------
n2one setting ettm1_traffic_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm1_traffic_weather_epochs_250_seed_2021/model.pkl', muti_dataset='ettm1_traffic_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.33186e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.487119260038849, 'MAE': 0.4232511230074814}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='ettm1_traffic_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/ettm1_traffic_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.1324464864817434
Epoch #1: loss=0.3971466677988563
Epoch #2: loss=0.3134529633906318
Epoch #3: loss=0.21715754381339747
Epoch #4: loss=0.18663523585517613
Epoch #5: loss=0.14303245510436619
Epoch #6: loss=0.12811306772265207
Epoch #7: loss=0.11266288006832563
Epoch #8: loss=0.09159321331172741
Epoch #9: loss=0.0787660581219379
Epoch #10: loss=0.08213530605284669
Epoch #11: loss=0.06656775009056191
Epoch #12: loss=0.06585630646850765
Epoch #13: loss=0.06498187021421063
Epoch #14: loss=0.0712775592578556
Epoch #15: loss=0.05852219568978822
Epoch #16: loss=0.055078214079894286
Epoch #17: loss=0.05693059098414197
Epoch #18: loss=0.057730390148228894
Epoch #19: loss=0.06721436481174424
Epoch #20: loss=0.042156785265642996
Epoch #21: loss=0.04766814964049085
Epoch #22: loss=0.040866210820046586
Epoch #23: loss=0.037956393380394624
Epoch #24: loss=0.052077245285151
Epoch #25: loss=0.04877187752164372
Epoch #26: loss=0.039477158801378545
Epoch #27: loss=0.03195701759820223
Epoch #28: loss=0.034547513093832125
Epoch #29: loss=0.04332398163407373
Epoch #30: loss=0.036661567198293374
Epoch #31: loss=0.04323967521725842
Epoch #32: loss=0.03869656633221514
Epoch #33: loss=0.03631515415434521
Epoch #34: loss=0.03498418321891156
Epoch #35: loss=0.041873854639830024
Epoch #36: loss=0.032926267668764476
Epoch #37: loss=0.03170162943711401
Epoch #38: loss=0.030065827782051247
Epoch #39: loss=0.034486139512295275
Epoch #40: loss=0.027744827914145797
Epoch #41: loss=0.0353341108598592
Epoch #42: loss=0.029975977683070917
Epoch #43: loss=0.02817167034430829
Epoch #44: loss=0.03334550026164123
Epoch #45: loss=0.02418952521991733
Epoch #46: loss=0.03200585627888734
Epoch #47: loss=0.029950763486032653
Epoch #48: loss=0.025286308321178834
Epoch #49: loss=0.02784323104834036
Epoch #50: loss=0.027406556528020928
Epoch #51: loss=0.024325353180525547
Epoch #52: loss=0.02498028247830459
Epoch #53: loss=0.02546051915583838
Epoch #54: loss=0.024451548969581887
Epoch #55: loss=0.031088483612746565
Epoch #56: loss=0.030247142873931713
Epoch #57: loss=0.01900902340722732
Epoch #58: loss=0.04944161049745212
Epoch #59: loss=0.022954103223137477
Epoch #60: loss=0.020597985346849677
Epoch #61: loss=0.02636912240761477
Epoch #62: loss=0.02236823136952603
Epoch #63: loss=0.02025222157160001
Epoch #64: loss=0.025367412842377
Epoch #65: loss=0.022163118455251395
Epoch #66: loss=0.023196468588478004
Epoch #67: loss=0.021080536890796635
Epoch #68: loss=0.027547895809647147
Epoch #69: loss=0.022543665155780022
Epoch #70: loss=0.02679232284865394
Epoch #71: loss=0.02015662145708126
Epoch #72: loss=0.01829628233489169
Epoch #73: loss=0.016048833071266085
Epoch #74: loss=0.02101009902823135
Epoch #75: loss=0.026011721707341895
Epoch #76: loss=0.016292159529492707
Epoch #77: loss=0.021726239847872145
Epoch #78: loss=0.014887662807946747
Epoch #79: loss=0.028797282695875448
Epoch #80: loss=0.021074800544148037
Epoch #81: loss=0.021783687983281175
Epoch #82: loss=0.019919576657334476
Epoch #83: loss=0.02276181016409628
Epoch #84: loss=0.020143368409137337
Epoch #85: loss=0.01707863125148801
Epoch #86: loss=0.02127214095322151
Epoch #87: loss=0.02623684496262558
Epoch #88: loss=0.017972665921682927
Epoch #89: loss=0.020332504480680247
Epoch #90: loss=0.01956376623204792
Epoch #91: loss=0.015442300380102416
Epoch #92: loss=0.025245738879219333
Epoch #93: loss=0.016024162852436317
Epoch #94: loss=0.017648319300074104
Epoch #95: loss=0.01622158722348393
Epoch #96: loss=0.020369895103717357
Epoch #97: loss=0.018729292399912785
Epoch #98: loss=0.01736353806465247
Epoch #99: loss=0.018000117189835737
Epoch #100: loss=0.018324407077747306
Epoch #101: loss=0.01673094556779494
Epoch #102: loss=0.016665904681493236
Epoch #103: loss=0.02176452337840977
Epoch #104: loss=0.022236271169370676
Epoch #105: loss=0.03325391091028689
Epoch #106: loss=0.011653988082436253
Epoch #107: loss=0.015192557875186979
Epoch #108: loss=0.013004862346836269
Epoch #109: loss=0.01804255036790866
Epoch #110: loss=0.014627025419609382
Epoch #111: loss=0.016318714616195325
Epoch #112: loss=0.014670250955412786
Epoch #113: loss=0.018624860399211605
Epoch #114: loss=0.017431628333167335
Epoch #115: loss=0.015776301629230313
Epoch #116: loss=0.016319715147563144
Epoch #117: loss=0.017969923865414256
Epoch #118: loss=0.013594206880432396
Epoch #119: loss=0.0186808292873449
Epoch #120: loss=0.015953190749949563
Epoch #121: loss=0.015209048170536634
Epoch #122: loss=0.01778215529254683
Epoch #123: loss=0.0184356783176841
Epoch #124: loss=0.01853925582761888
Epoch #125: loss=0.01861458377714827
Epoch #126: loss=0.0157073428623762
Epoch #127: loss=0.016601124593047092
Epoch #128: loss=0.011792733977427474
Epoch #129: loss=0.02080627559124208
Epoch #130: loss=0.01411602751728624
Epoch #131: loss=0.016528939217756895
Epoch #132: loss=0.019928487270831834
Epoch #133: loss=0.013508368375215353
Epoch #134: loss=0.018470908704908327
Epoch #135: loss=0.01755446805131107
Epoch #136: loss=0.016092785816866545
Epoch #137: loss=0.015510008579543417
Epoch #138: loss=0.015522880244186934
Epoch #139: loss=0.011175256259997733
Epoch #140: loss=0.019119769956148308
Epoch #141: loss=0.017089518647164976
Epoch #142: loss=0.012521880038878611
Epoch #143: loss=0.016702807550198293
Epoch #144: loss=0.019174746692223712
Epoch #145: loss=0.015633747850011696
Epoch #146: loss=0.01603720544542875
Epoch #147: loss=0.014549334504309657
Epoch #148: loss=0.014250182679806234
Epoch #149: loss=0.020150190792605438
Epoch #150: loss=0.01532345846344645
Epoch #151: loss=0.015868117879993187
Epoch #152: loss=0.013870981201068599
Epoch #153: loss=0.018683975845464072
Epoch #154: loss=0.015543586467791805
Epoch #155: loss=0.015161313727796956
Epoch #156: loss=0.016116135550794386
Epoch #157: loss=0.014055303396315132
Epoch #158: loss=0.012109734428579794
Epoch #159: loss=0.013504625687994872
Epoch #160: loss=0.01128768149280242
Epoch #161: loss=0.016411299805999147
Epoch #162: loss=0.015785881457064103
Epoch #163: loss=0.016859885681500906
Epoch #164: loss=0.01504658250795626
Epoch #165: loss=0.012439586739631943
Epoch #166: loss=0.0150521953083986
Epoch #167: loss=0.012034372503045475
Epoch #168: loss=0.01102390544204
Epoch #169: loss=0.014806162923451292
Epoch #170: loss=0.01312326926508893
Epoch #171: loss=0.01898124507303581
Epoch #172: loss=0.012126161617261388
Epoch #173: loss=0.010770475820612604
Epoch #174: loss=0.011806641797402716
Epoch #175: loss=0.01592809862603759
Epoch #176: loss=0.016296611541116272
Epoch #177: loss=0.013883367555771471
Epoch #178: loss=0.015371638091029198
Epoch #179: loss=0.011177828855893551
Epoch #180: loss=0.012151120388363705
Epoch #181: loss=0.011994293573394123
Epoch #182: loss=0.014257497950559115
Epoch #183: loss=0.014862431881095152
Epoch #184: loss=0.015914455814409693
Epoch #185: loss=0.0146981095589531
Epoch #186: loss=0.0163096077440565
Epoch #187: loss=0.018113882936135296
Epoch #188: loss=0.01235854972747739
Epoch #189: loss=0.010617720869706233
Epoch #190: loss=0.016005765680713876
Epoch #191: loss=0.01152853023388479
Epoch #192: loss=0.011873914109600843
Epoch #193: loss=0.013061751147157859
Epoch #194: loss=0.01493328753149213
Epoch #195: loss=0.01296370913467907
Epoch #196: loss=0.013100010834737505
Epoch #197: loss=0.013186267170797803
Epoch #198: loss=0.011520010782740049
Epoch #199: loss=0.01557620433048175
Epoch #200: loss=0.01469511864831168
Epoch #201: loss=0.015223407760848134
Epoch #202: loss=0.010699196372855884
Epoch #203: loss=0.013694193241597132
Epoch #204: loss=0.010386865844078748
Epoch #205: loss=0.01383921811839947
Epoch #206: loss=0.013509960918665216
Epoch #207: loss=0.01449352103887323
Epoch #208: loss=0.011761414155981923
Epoch #209: loss=0.011195546321489079
Epoch #210: loss=0.011511533978617424
Epoch #211: loss=0.010244343090005891
Epoch #212: loss=0.013582628276809589
Epoch #213: loss=0.01706738006116777
Epoch #214: loss=0.013406027653210962
Epoch #215: loss=0.013016409147074911
Epoch #216: loss=0.010716884602588338
Epoch #217: loss=0.017209376658652048
Epoch #218: loss=0.01018258972434318
Epoch #219: loss=0.011644770982628345
Epoch #220: loss=0.015368742942269606
Epoch #221: loss=0.014707163820375142
Epoch #222: loss=0.014932311119882509
Epoch #223: loss=0.01794943057464151
Epoch #224: loss=0.012323285897540417
Epoch #225: loss=0.009885676640823746
Epoch #226: loss=0.011260519172185868
Epoch #227: loss=0.011153735133285965
Epoch #228: loss=0.011296655666615746
Epoch #229: loss=0.01851417207803681
Epoch #230: loss=0.014224823998139588
Epoch #231: loss=0.010094088503830458
Epoch #232: loss=0.015374484557207043
Epoch #233: loss=0.012393315720746138
Epoch #234: loss=0.011325810596417022
Epoch #235: loss=0.012111837292120715
Epoch #236: loss=0.010643574629265976
Epoch #237: loss=0.022172354405376567
Epoch #238: loss=0.013100575931640088
Epoch #239: loss=0.014073571555274693
Epoch #240: loss=0.009868993591746473
Epoch #241: loss=0.010412379721607475
Epoch #242: loss=0.011658837886238588
Epoch #243: loss=0.011517809898621337
Epoch #244: loss=0.018615411830253996
Epoch #245: loss=0.018270584517487597
Epoch #246: loss=0.012858556081771732
Epoch #247: loss=0.01040208305291822
Epoch #248: loss=0.01132020361267747
Epoch #249: loss=0.025750651701036884

Training time: 10:27:55.579440

Finished.
n2one setting ettm1_traffic_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm1_traffic_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='ettm1_traffic_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.0589e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.22994e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.47849e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.0589e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.39297591605525584, 'MAE': 0.4443703148784338}
Finished.
------------------------- record done -------------------------
n2one setting ettm1_traffic_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm1_traffic_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='ettm1_traffic_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.89982e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.7894e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.89982e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 1.0357573807652123, 'MAE': 0.8408737334383403}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='ettm1_weather_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/ettm1_weather_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=5.042245154910617
Epoch #1: loss=2.576817732387119
Epoch #2: loss=2.663329768180847
Epoch #3: loss=2.168322449260288
Epoch #4: loss=1.9974595149358114
Epoch #5: loss=1.876388316684299
Epoch #6: loss=1.7616095701853434
Epoch #7: loss=1.646122431755066
Epoch #8: loss=1.420642031563653
Epoch #9: loss=1.4444855954911975
Epoch #10: loss=1.329764355553521
Epoch #11: loss=1.273321341143714
Epoch #12: loss=1.1983787986967298
Epoch #13: loss=1.1805883606274923
Epoch #14: loss=1.0933863123257954
Epoch #15: loss=1.1294986883799234
Epoch #16: loss=1.0551800118552315
Epoch #17: loss=1.0045197010040283
Epoch #18: loss=0.9893531084060669
Epoch #19: loss=0.9333887762493558
Epoch #20: loss=0.9467843943172031
Epoch #21: loss=0.8699873659345839
Epoch #22: loss=0.910329532623291
Epoch #23: loss=0.8626868089040121
Epoch #24: loss=0.8206357492340935
Epoch #25: loss=0.7951729549301996
Epoch #26: loss=0.7513914929495917
Epoch #27: loss=0.6919539451599122
Epoch #28: loss=0.7491612116495768
Epoch #29: loss=0.8123340732521481
Epoch #30: loss=0.6822131686740451
Epoch #31: loss=0.7425508075290256
Epoch #32: loss=0.6757912192079756
Epoch #33: loss=0.7466765708393521
Epoch #34: loss=0.6610642512639363
Epoch #35: loss=0.6059870521227518
Epoch #36: loss=0.5874686274263594
Epoch #37: loss=0.6509678430027432
Epoch #38: loss=0.6417918774816725
Epoch #39: loss=0.601502980126275
Epoch #40: loss=0.5549532499578264
Epoch #41: loss=0.6337775270144145
Epoch #42: loss=0.5881026890542772
Epoch #43: loss=0.5217073871029748
Epoch #44: loss=0.5278552962674035
Epoch #45: loss=0.611664871374766
Epoch #46: loss=0.5759330663416121
Epoch #47: loss=0.5905536141660478
Epoch #48: loss=0.6867064601845212
Epoch #49: loss=0.844580798678928
Epoch #50: loss=0.5713894274499681
Epoch #51: loss=0.5065962006648381
Epoch #52: loss=0.4649154196182887
Epoch #53: loss=0.4722388393349118
Epoch #54: loss=0.4627353668212891
Epoch #55: loss=0.39909229344791836
Epoch #56: loss=0.45038714077737596
Epoch #57: loss=0.44111539324124655
Epoch #58: loss=0.42337139546871183
Epoch #59: loss=0.40620563692516753
Epoch #60: loss=0.3518762634860145
Epoch #61: loss=0.4036429405212402
Epoch #62: loss=0.4247334712081485
Epoch #63: loss=0.3832990053627226
Epoch #64: loss=0.40247681703832416
Epoch #65: loss=0.38874395622147456
Epoch #66: loss=0.3953118983242247
Epoch #67: loss=0.3809242549869749
Epoch #68: loss=0.33048802614212036
Epoch #69: loss=0.3141223238574134
Epoch #70: loss=0.3220337352818913
Epoch #71: loss=0.3156059208843443
Epoch #72: loss=0.25433993140856426
Epoch #73: loss=0.44379246383905413
Epoch #74: loss=0.32548430926269956
Epoch #75: loss=0.3364632576704025
Epoch #76: loss=0.3173892671863238
Epoch #77: loss=0.407609776324696
Epoch #78: loss=0.3956359803676605
Epoch #79: loss=0.3097850915458467
Epoch #80: loss=0.32589966787232294
Epoch #81: loss=0.31743196381462946
Epoch #82: loss=0.31678377555476295
Epoch #83: loss=0.29365685449706186
Epoch #84: loss=0.28905013220177755
Epoch #85: loss=0.3417664595776134
Epoch #86: loss=0.28039026492171815
Epoch #87: loss=0.23889388177129958
Epoch #88: loss=0.20538526591327455
Epoch #89: loss=0.2963856071233749
Epoch #90: loss=0.2756026551127434
Epoch #91: loss=0.24954994668563207
Epoch #92: loss=0.25780244668324787
Epoch #93: loss=0.23729918267991806
Epoch #94: loss=0.3116094748179118
Epoch #95: loss=0.2809611921509107
Epoch #96: loss=0.23490779979361429
Epoch #97: loss=0.2669566623038716
Epoch #98: loss=0.20858680539660984
Epoch #99: loss=0.2503282927804523
Epoch #100: loss=0.24123632626401054
Epoch #101: loss=0.2403797232442432
Epoch #102: loss=0.22149672011534374
Epoch #103: loss=0.20352203705244595
Epoch #104: loss=0.2254195178548495
Epoch #105: loss=0.2263709903591209
Epoch #106: loss=0.28077075332403184
Epoch #107: loss=0.217553947865963
Epoch #108: loss=0.2085780631336901
Epoch #109: loss=0.19704973126451175
Epoch #110: loss=0.21357090233100784
Epoch #111: loss=0.18919806107878684
Epoch #112: loss=0.14388300561242634
Epoch #113: loss=0.282932438618607
Epoch #114: loss=0.21369166208638085
Epoch #115: loss=0.28707874069611233
Epoch #116: loss=0.22612505679329237
Epoch #117: loss=0.1965888445576032
Epoch #118: loss=0.15561069010032547
Epoch #119: loss=0.15631392267015246
Epoch #120: loss=0.16405969911979304
Epoch #121: loss=0.17134474474522804
Epoch #122: loss=0.20802272790008122
Epoch #123: loss=0.2180213230351607
Epoch #124: loss=0.18157964096301132
Epoch #125: loss=0.21147759507099786
Epoch #126: loss=0.19837190881371497
Epoch #127: loss=0.17082867721716563
Epoch #128: loss=0.1383957748611768
Epoch #129: loss=0.13082037025855647
Epoch #130: loss=0.14147124307023154
Epoch #131: loss=0.14486162625253202
Epoch #132: loss=0.1402063528696696
Epoch #133: loss=0.1469869496093856
Epoch #134: loss=0.1421788324084547
Epoch #135: loss=0.13982195431987446
Epoch #136: loss=0.14458795976307656
Epoch #137: loss=0.14642130782206852
Epoch #138: loss=0.13636247863372167
Epoch #139: loss=0.19465514752599927
Epoch #140: loss=0.18387545380327436
Epoch #141: loss=0.18769381683733727
Epoch #142: loss=0.176127577573061
Epoch #143: loss=0.17990908444755607
Epoch #144: loss=0.17684908997681406
Epoch #145: loss=0.19179457045263715
Epoch #146: loss=0.2375550765958097
Epoch #147: loss=0.24830404222011565
Epoch #148: loss=0.1760738828115993
Epoch #149: loss=0.11524286079737875
Epoch #150: loss=0.15055261109438206
Epoch #151: loss=0.11753659082783594
Epoch #152: loss=0.1919589145316018
Epoch #153: loss=0.13235113020572398
Epoch #154: loss=0.1607212102247609
Epoch #155: loss=0.1737848397344351
Epoch #156: loss=0.12440808411273692
Epoch #157: loss=0.09302910777429739
Epoch #158: loss=0.12607460485564337
Epoch #159: loss=0.15181788975993793
Epoch #160: loss=0.13722279369831086
Epoch #161: loss=0.1486042891939481
Epoch #162: loss=0.10899040972193082
Epoch #163: loss=0.09427880326078998
Epoch #164: loss=0.09622457660734654
Epoch #165: loss=0.1093827729837762
Epoch #166: loss=0.13692287099030281
Epoch #167: loss=0.13669374713467228
Epoch #168: loss=0.13456339227656525
Epoch #169: loss=0.1283833577401108
Epoch #170: loss=0.1265844415873289
Epoch #171: loss=0.151494368372692
Epoch #172: loss=0.13327289935615327
Epoch #173: loss=0.12419709973037243
Epoch #174: loss=0.16883058432075712
Epoch #175: loss=0.14630584712657663
Epoch #176: loss=0.10787595531178845
Epoch #177: loss=0.09823955301609304
Epoch #178: loss=0.0830894330309497
Epoch #179: loss=0.09167007176826397
Epoch #180: loss=0.06929286813570393
Epoch #181: loss=0.07374271899461746
Epoch #182: loss=0.10577023232148754
Epoch #183: loss=0.14662307298017874
Epoch #184: loss=0.09958006561630302
Epoch #185: loss=0.09569168128073216
Epoch #186: loss=0.13561327958272562
Epoch #187: loss=0.1279673319723871
Epoch #188: loss=0.149951191039549
Epoch #189: loss=0.11317106381886535
Epoch #190: loss=0.12435493932829964
Epoch #191: loss=0.09785592953364054
Epoch #192: loss=0.09856233052495453
Epoch #193: loss=0.21953686682714357
Epoch #194: loss=0.11354354756573835
Epoch #195: loss=0.08148319468730025
Epoch #196: loss=0.07393159055047566
Epoch #197: loss=0.07423335177203019
Epoch #198: loss=0.08782957332829634
Epoch #199: loss=0.12047527730464935
Epoch #200: loss=0.08916171507702933
Epoch #201: loss=0.09048427660018206
Epoch #202: loss=0.14306713069478671
Epoch #203: loss=0.12626953435440857
Epoch #204: loss=0.10137726325127813
Epoch #205: loss=0.09575784641007583
Epoch #206: loss=0.11490000651942359
Epoch #207: loss=0.07974111710985501
Epoch #208: loss=0.06698276756538285
Epoch #209: loss=0.08323498639381594
Epoch #210: loss=0.1151103913784027
Epoch #211: loss=0.11424200870096683
Epoch #212: loss=0.16913789858420689
Epoch #213: loss=0.11119922167725033
Epoch #214: loss=0.07268350517584218
Epoch #215: loss=0.09497664692915148
Epoch #216: loss=0.09849527799006966
Epoch #217: loss=0.08353793896320794
Epoch #218: loss=0.08564058858901262
Epoch #219: loss=0.058276365469727254
Epoch #220: loss=0.11335866306391028
Epoch #221: loss=0.09924475525816281
Epoch #222: loss=0.09183830662320057
Epoch #223: loss=0.10576486227413019
Epoch #224: loss=0.2482884481963184
Epoch #225: loss=0.2700617091109355
Epoch #226: loss=0.1965119676457511
Epoch #227: loss=0.10587490337590376
Epoch #228: loss=0.09724545155962308
Epoch #229: loss=0.11035064678225252
Epoch #230: loss=0.14863172587421206
Epoch #231: loss=0.12365790849758519
Epoch #232: loss=0.10927037269704871
Epoch #233: loss=0.11869881575306257
Epoch #234: loss=0.1407139046324624
Epoch #235: loss=0.10352646588451332
Epoch #236: loss=0.07445942217277156
Epoch #237: loss=0.10257772451473607
Epoch #238: loss=0.07253099636485179
Epoch #239: loss=0.04782218744771348
Epoch #240: loss=0.11131460275501012
Epoch #241: loss=0.1058331889203853
Epoch #242: loss=0.06461969465017318
Epoch #243: loss=0.0765414942883783
Epoch #244: loss=0.08088586556000842
Epoch #245: loss=0.06300549393312799
Epoch #246: loss=0.08247835257401069
Epoch #247: loss=0.09636265757597155
Epoch #248: loss=0.0623520453977916
Epoch #249: loss=0.07193490831802289

Training time: 0:43:59.464964

Finished.
n2one setting ettm1_weather_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm1_weather_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='ettm1_weather_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.41948e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.75985e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.41948e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3668141881668479, 'MAE': 0.4319801151969787}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='ettm2_electricity_traffic', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/ettm2_electricity_traffic_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.9139973238185423
Epoch #1: loss=0.3161943297727124
Epoch #2: loss=0.22196486581060754
Epoch #3: loss=0.15214254561861607
Epoch #4: loss=0.12093079495563529
Epoch #5: loss=0.09291394271652278
Epoch #6: loss=0.07914647301487387
Epoch #7: loss=0.07066410156146279
Epoch #8: loss=0.060582084781716464
Epoch #9: loss=0.053504286635779406
Epoch #10: loss=0.04665579738612544
Epoch #11: loss=0.04941527317769488
Epoch #12: loss=0.040842918458280045
Epoch #13: loss=0.037004096609995804
Epoch #14: loss=0.03862145108637249
Epoch #15: loss=0.03637770167932186
Epoch #16: loss=0.037483331081426235
Epoch #17: loss=0.032996111939535624
Epoch #18: loss=0.029713574561354403
Epoch #19: loss=0.031676672007482955
Epoch #20: loss=0.03226534411916821
Epoch #21: loss=0.03579598415500236
Epoch #22: loss=0.023576861097367396
Epoch #23: loss=0.025834446945215982
Epoch #24: loss=0.027919092445942015
Epoch #25: loss=0.025504455195780425
Epoch #26: loss=0.026832694378568382
Epoch #27: loss=0.0281082462069736
Epoch #28: loss=0.024540956631412814
Epoch #29: loss=0.02247783982819352
Epoch #30: loss=0.023507539077991094
Epoch #31: loss=0.021053207606918426
Epoch #32: loss=0.021682044464846763
Epoch #33: loss=0.02537339992553676
Epoch #34: loss=0.01832823166045535
Epoch #35: loss=0.02161937053245141
Epoch #36: loss=0.01744370725711962
Epoch #37: loss=0.01928497666039292
Epoch #38: loss=0.01637767156908972
Epoch #39: loss=0.018825738310688712
Epoch #40: loss=0.018212089243930356
Epoch #41: loss=0.025685579685302815
Epoch #42: loss=0.01983813262876853
Epoch #43: loss=0.017252865224954606
Epoch #44: loss=0.01952095230411168
Epoch #45: loss=0.015885750093193915
Epoch #46: loss=0.01919309528025064
Epoch #47: loss=0.018678026299099197
Epoch #48: loss=0.01276682096255504
Epoch #49: loss=0.018663570158580597
Epoch #50: loss=0.024875616035529475
Epoch #51: loss=0.015467056894590657
Epoch #52: loss=0.01803842683443043
Epoch #53: loss=0.0189425027695977
Epoch #54: loss=0.02265689286028567
Epoch #55: loss=0.03175296801731491
Epoch #56: loss=0.015865353036075565
Epoch #57: loss=0.02076015837255193
Epoch #58: loss=0.01723857127050374
Epoch #59: loss=0.021686436331532957
Epoch #60: loss=0.01945655026126589
Epoch #61: loss=0.018277155841788288
Epoch #62: loss=0.012886882967403755
Epoch #63: loss=0.01725150446602595
Epoch #64: loss=0.012884536991310244
Epoch #65: loss=0.016704213481113298
Epoch #66: loss=0.01776302913590424
Epoch #67: loss=0.011758494074432019
Epoch #68: loss=0.015763759527139373
Epoch #69: loss=0.016489044917247005
Epoch #70: loss=0.018613574339649788
Epoch #71: loss=0.01249522412990624
Epoch #72: loss=0.013387288870295772
Epoch #73: loss=0.01755081245331897
Epoch #74: loss=0.012522548702465514
Epoch #75: loss=0.015688971279062144
Epoch #76: loss=0.021289276919779884
Epoch #77: loss=0.015475539582462375
Epoch #78: loss=0.013711109925660115
Epoch #79: loss=0.010498505251530295
Epoch #80: loss=0.015206849121588472
Epoch #81: loss=0.015720513097018936
Epoch #82: loss=0.014317991543438175
Epoch #83: loss=0.011538436734535844
Epoch #84: loss=0.015488518943253147
Epoch #85: loss=0.014000021567705852
Epoch #86: loss=0.013431757076781273
Epoch #87: loss=0.010664449741714243
Epoch #88: loss=0.01480863239007559
Epoch #89: loss=0.014331682818427872
Epoch #90: loss=0.016122730076317895
Epoch #91: loss=0.009538266609113397
Epoch #92: loss=0.014927112014421732
Epoch #93: loss=0.01119742244286065
Epoch #94: loss=0.0137023446309537
Epoch #95: loss=0.01996222415689519
Epoch #96: loss=0.011306203544209867
Epoch #97: loss=0.010067638109188131
Epoch #98: loss=0.009929925912966889
Epoch #99: loss=0.017700456660436865
Epoch #100: loss=0.016858071435258103
Epoch #101: loss=0.010623073543531515
Epoch #102: loss=0.01644358294670017
Epoch #103: loss=0.014285406736500098
Epoch #104: loss=0.010262453295191508
Epoch #105: loss=0.014398768441858362
Epoch #106: loss=0.01244648770766106
Epoch #107: loss=0.010718264876071882
Epoch #108: loss=0.016779445592769136
Epoch #109: loss=0.011817765596902058
Epoch #110: loss=0.012149399301292448
Epoch #111: loss=0.016761431037599958
Epoch #112: loss=0.008452059432276848
Epoch #113: loss=0.012652148357974237
Epoch #114: loss=0.0159108388089016
Epoch #115: loss=0.013272667139259356
Epoch #116: loss=0.007897015315947751
Epoch #117: loss=0.014742507701060092
Epoch #118: loss=0.010843497342614819
Epoch #119: loss=0.017498755521236836
Epoch #120: loss=0.01585954610909935
Epoch #121: loss=0.009581887323292904
Epoch #122: loss=0.012367339524309037
Epoch #123: loss=0.009037442345325145
Epoch #124: loss=0.013746541691432126
Epoch #125: loss=0.0125369102354257
Epoch #126: loss=0.01235242817667703
Epoch #127: loss=0.01088048079081985
Epoch #128: loss=0.013690808957202401
Epoch #129: loss=0.013291487725061783
Epoch #130: loss=0.013545838759223801
Epoch #131: loss=0.009049319475306641
Epoch #132: loss=0.009553185389678453
Epoch #133: loss=0.011812089033230048
Epoch #134: loss=0.011709136396008457
Epoch #135: loss=0.011176386266892973
Epoch #136: loss=0.01131280455152817
Epoch #137: loss=0.01189325188621126
Epoch #138: loss=0.00905786434247619
Epoch #139: loss=0.011096059556839037
Epoch #140: loss=0.011104274142107563
Epoch #141: loss=0.015300601714204293
Epoch #142: loss=0.012285157568809608
Epoch #143: loss=0.006731688601679619
Epoch #144: loss=0.013372026230265125
Epoch #145: loss=0.01317129782109012
Epoch #146: loss=0.010426299644814892
Epoch #147: loss=0.019462538103404738
Epoch #148: loss=0.009781896573551064
Epoch #149: loss=0.014228684452053381
Epoch #150: loss=0.009394500372409052
Epoch #151: loss=0.009522211487659771
Epoch #152: loss=0.009789833415548182
Epoch #153: loss=0.0104481480259007
Epoch #154: loss=0.018706001345218562
Epoch #155: loss=0.010348436245695244
Epoch #156: loss=0.008231403345017015
Epoch #157: loss=0.012949094813042305
Epoch #158: loss=0.009867807939984565
Epoch #159: loss=0.010836763175778088
Epoch #160: loss=0.008600569303617495
Epoch #161: loss=0.013561076849210641
Epoch #162: loss=0.007695290767335196
Epoch #163: loss=0.011513377698044268
Epoch #164: loss=0.009891495293001816
Epoch #165: loss=0.009890577774576298
Epoch #166: loss=0.01214305428663558
Epoch #167: loss=0.012422448729690035
Epoch #168: loss=0.011814354874339529
Epoch #169: loss=0.008348650403721857
Epoch #170: loss=0.010931781641669006
Epoch #171: loss=0.008583304656470012
Epoch #172: loss=0.00799252604228115
Epoch #173: loss=0.010098090758934263
Epoch #174: loss=0.011307182338117904
Epoch #175: loss=0.011719077918451833
Epoch #176: loss=0.009383575517030092
Epoch #177: loss=0.008672492129953814
Epoch #178: loss=0.013015206215452322
Epoch #179: loss=0.00955459015769377
Epoch #180: loss=0.008032010531523288
Epoch #181: loss=0.010082335151648166
Epoch #182: loss=0.008316353972108712
Epoch #183: loss=0.014255350410639278
Epoch #184: loss=0.009639339919364952
Epoch #185: loss=0.009564360788514095
Epoch #186: loss=0.018707136488304132
Epoch #187: loss=0.00808221806153999
Epoch #188: loss=0.011123386171145363
Epoch #189: loss=0.010508989842930907
Epoch #190: loss=0.015130695256339156
Epoch #191: loss=0.011947464190622295
Epoch #192: loss=0.010705294167308779
Epoch #193: loss=0.008594486461573052
Epoch #194: loss=0.00988089670671138
Epoch #195: loss=0.010178341490251751
Epoch #196: loss=0.007415355898181045
Epoch #197: loss=0.011485818946595425
Epoch #198: loss=0.010670029623578735
Epoch #199: loss=0.00928183900553326
Epoch #200: loss=0.009533011489056388
Epoch #201: loss=0.01064534455272254
Epoch #202: loss=0.014401549057602797
Epoch #203: loss=0.008649997567214936
Epoch #204: loss=0.008066506934358264
Epoch #205: loss=0.010588162468799364
Epoch #206: loss=0.012539898355424087
Epoch #207: loss=0.00930403625235787
Epoch #208: loss=0.007779087551361898
Epoch #209: loss=0.010716983831535468
Epoch #210: loss=0.010807388319775861
Epoch #211: loss=0.010386772081894539
Epoch #212: loss=0.007831308862025719
Epoch #213: loss=0.010426902285108376
Epoch #214: loss=0.009850163334541112
Epoch #215: loss=0.008623751025051004
Epoch #216: loss=0.009137094937659868
Epoch #217: loss=0.009150188194409681
Epoch #218: loss=0.007389398208419719
Epoch #219: loss=0.011310437114248142
Epoch #220: loss=0.009749790519401641
Epoch #221: loss=0.014148523492817285
Epoch #222: loss=0.007402121246243279
Epoch #223: loss=0.010924996860352199
Epoch #224: loss=0.006939814623199181
Epoch #225: loss=0.006826166636550125
Epoch #226: loss=0.009270128719280497
Epoch #227: loss=0.007054748285864544
Epoch #228: loss=0.011519471971916094
Epoch #229: loss=0.012937750938664665
Epoch #230: loss=0.007096657854939868
Epoch #231: loss=0.008760610467342878
Epoch #232: loss=0.013705449325991544
Epoch #233: loss=0.008964196233556753
Epoch #234: loss=0.008437946622169094
Epoch #235: loss=0.0059566431314924005
Epoch #236: loss=0.009514747817225097
Epoch #237: loss=0.011926153144588378
Epoch #238: loss=0.009409763146344131
Epoch #239: loss=0.009193144596076211
Epoch #240: loss=0.008406092556235348
Epoch #241: loss=0.008288142672072856
Epoch #242: loss=0.008784331945240994
Epoch #243: loss=0.008525113623922826
Epoch #244: loss=0.010208131581974072
Epoch #245: loss=0.008787920976275319
Epoch #246: loss=0.006429796652730964
Epoch #247: loss=0.009868321510156035
Epoch #248: loss=0.010484999468612682
Epoch #249: loss=0.0074778443308505405

Training time: 14:50:23.227575

Finished.
n2one setting ettm2_electricity_traffic -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm2_electricity_traffic_epochs_250_seed_2021/model.pkl', muti_dataset='ettm2_electricity_traffic', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.24403e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.58253e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.24403e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.40074377368536335, 'MAE': 0.47313278933545255}
Finished.
------------------------- record done -------------------------
n2one setting ettm2_electricity_traffic -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm2_electricity_traffic_epochs_250_seed_2021/model.pkl', muti_dataset='ettm2_electricity_traffic', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.73644e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.26589682882773574, 'MAE': 0.34221372647591736}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='ettm2_electricity_weather', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/ettm2_electricity_weather_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.9581650848495227
Epoch #1: loss=0.8609217489398392
Epoch #2: loss=0.6021348595952188
Epoch #3: loss=0.4900015734094481
Epoch #4: loss=0.422069357094152
Epoch #5: loss=0.3805175253798842
Epoch #6: loss=0.32337847526845986
Epoch #7: loss=0.3154489867514072
Epoch #8: loss=0.28936155167455113
Epoch #9: loss=0.23886081461883124
Epoch #10: loss=0.21732186014092833
Epoch #11: loss=0.21925549256984747
Epoch #12: loss=0.18980830528008538
Epoch #13: loss=0.18231299803618278
Epoch #14: loss=0.17591330563056404
Epoch #15: loss=0.17915676105455314
Epoch #16: loss=0.14354540011195163
Epoch #17: loss=0.12706565203967207
Epoch #18: loss=0.12859688065529867
Epoch #19: loss=0.12623546970227745
Epoch #20: loss=0.12025309884764629
Epoch #21: loss=0.10373756458576998
Epoch #22: loss=0.11196156391124736
Epoch #23: loss=0.09120564089370006
Epoch #24: loss=0.09241551423299663
Epoch #25: loss=0.07294383218678432
Epoch #26: loss=0.11191660078897989
Epoch #27: loss=0.08072577926782923
Epoch #28: loss=0.07784595564476021
Epoch #29: loss=0.0760995657755551
Epoch #30: loss=0.06607645726502566
Epoch #31: loss=0.06343069307079445
Epoch #32: loss=0.06305236986437657
Epoch #33: loss=0.06272807825153807
Epoch #34: loss=0.0611449221712303
Epoch #35: loss=0.05258145862175724
Epoch #36: loss=0.05975047585700103
Epoch #37: loss=0.06277274935084848
Epoch #38: loss=0.04815130576220804
Epoch #39: loss=0.038161618976499986
Epoch #40: loss=0.04305798900456756
Epoch #41: loss=0.04324963670965367
Epoch #42: loss=0.056778745375854596
Epoch #43: loss=0.07619310690183713
Epoch #44: loss=0.03753505995582956
Epoch #45: loss=0.041494068015866276
Epoch #46: loss=0.046602142728896366
Epoch #47: loss=0.0963689562742333
Epoch #48: loss=0.05912286613277009
Epoch #49: loss=0.05518242407540723
Epoch #50: loss=0.05022165935106742
Epoch #51: loss=0.03978742922684854
Epoch #52: loss=0.035040052383279625
Epoch #53: loss=0.03862480169380677
Epoch #54: loss=0.035655557029027306
Epoch #55: loss=0.036694922344303854
Epoch #56: loss=0.03560352561847104
Epoch #57: loss=0.0281336388720444
Epoch #58: loss=0.03747016937646224
Epoch #59: loss=0.05576499455475753
Epoch #60: loss=0.04671915288781747
Epoch #61: loss=0.02815185035071622
Epoch #62: loss=0.030059801997010745
Epoch #63: loss=0.027068404838515643
Epoch #64: loss=0.036025794176775025
Epoch #65: loss=0.04376986438692053
Epoch #66: loss=0.04063752659189374
Epoch #67: loss=0.0304511792592928
Epoch #68: loss=0.021488172314474464
Epoch #69: loss=0.03258106010990717
Epoch #70: loss=0.02958765866556179
Epoch #71: loss=0.02659164075238901
Epoch #72: loss=0.02785207817718574
Epoch #73: loss=0.025270333361432123
Epoch #74: loss=0.030574834901012232
Epoch #75: loss=0.026510482254976604
Epoch #76: loss=0.021094581269979082
Epoch #77: loss=0.03326439609206099
Epoch #78: loss=0.0206911637933597
Epoch #79: loss=0.027059071697945077
Epoch #80: loss=0.02294963203252205
Epoch #81: loss=0.02248154539506305
Epoch #82: loss=0.03278961380379139
Epoch #83: loss=0.0258264726898685
Epoch #84: loss=0.034025894488044106
Epoch #85: loss=0.03059440020858128
Epoch #86: loss=0.023835552282053873
Epoch #87: loss=0.027693675779906626
Epoch #88: loss=0.030443661328530013
Epoch #89: loss=0.0274829583709335
Epoch #90: loss=0.027982775184037113
Epoch #91: loss=0.019022268849924497
Epoch #92: loss=0.02073992432846932
Epoch #93: loss=0.021571732022930924
Epoch #94: loss=0.02240009324699276
Epoch #95: loss=0.03428893119201465
Epoch #96: loss=0.02208259914170524
Epoch #97: loss=0.041075231098341
Epoch #98: loss=0.020125024511859956
Epoch #99: loss=0.03771874505321511
Epoch #100: loss=0.020051143475868036
Epoch #101: loss=0.017437551101811447
Epoch #102: loss=0.01807437442124733
Epoch #103: loss=0.026496400059312687
Epoch #104: loss=0.02033876879212275
Epoch #105: loss=0.020790196948375177
Epoch #106: loss=0.020964900016727437
Epoch #107: loss=0.028377165052585834
Epoch #108: loss=0.025656386117279197
Epoch #109: loss=0.022043554526597637
Epoch #110: loss=0.018480087708494516
Epoch #111: loss=0.02609577097874083
Epoch #112: loss=0.026168430898814623
Epoch #113: loss=0.01179760677447964
Epoch #114: loss=0.01630910339455677
Epoch #115: loss=0.02084479017369189
Epoch #116: loss=0.021147187656460214
Epoch #117: loss=0.046275145761368215
Epoch #118: loss=0.023879455807183054
Epoch #119: loss=0.015447967204001248
Epoch #120: loss=0.0207009590938154
Epoch #121: loss=0.03642643108253768
Epoch #122: loss=0.020488673053010675
Epoch #123: loss=0.017697204935218744
Epoch #124: loss=0.01798723418153068
Epoch #125: loss=0.025729616666401285
Epoch #126: loss=0.014202630555441905
Epoch #127: loss=0.02264019819763463
Epoch #128: loss=0.016940123422231328
Epoch #129: loss=0.013943181230017379
Epoch #130: loss=0.01955019130859935
Epoch #131: loss=0.022208993394037074
Epoch #132: loss=0.02029938803606552
Epoch #133: loss=0.028443757127892412
Epoch #134: loss=0.02199913446538478
Epoch #135: loss=0.02181616738095864
Epoch #136: loss=0.016942468913097725
Epoch #137: loss=0.016516845056614136
Epoch #138: loss=0.013460107256304577
Epoch #139: loss=0.013604809853473324
Epoch #140: loss=0.02016740338681734
Epoch #141: loss=0.017494239612851896
Epoch #142: loss=0.016574992019131613
Epoch #143: loss=0.0211656230352897
Epoch #144: loss=0.017930476852613318
Epoch #145: loss=0.013257093403219147
Epoch #146: loss=0.01585124945024148
Epoch #147: loss=0.014331663649073312
Epoch #148: loss=0.014660634229615898
Epoch #149: loss=0.013847582679005814
Epoch #150: loss=0.01868040382502114
Epoch #151: loss=0.02206151952005158
Epoch #152: loss=0.019200610723047302
Epoch #153: loss=0.013388303030632156
Epoch #154: loss=0.017462269399382106
Epoch #155: loss=0.022475778291963806
Epoch #156: loss=0.019446723603750136
Epoch #157: loss=0.018659588357130608
Epoch #158: loss=0.016448633517197192
Epoch #159: loss=0.02613261665377568
Epoch #160: loss=0.016460924906777766
Epoch #161: loss=0.012241925333458123
Epoch #162: loss=0.015135663866056337
Epoch #163: loss=0.01207646583107771
Epoch #164: loss=0.015449514878066985
Epoch #165: loss=0.019196126157549266
Epoch #166: loss=0.011716676775304934
Epoch #167: loss=0.018612249915822353
Epoch #168: loss=0.013803112391979492
Epoch #169: loss=0.021879679854525456
Epoch #170: loss=0.011346205486346937
Epoch #171: loss=0.01589104766270026
Epoch #172: loss=0.01771546001728187
Epoch #173: loss=0.02263362229250205
Epoch #174: loss=0.01374406366955031
Epoch #175: loss=0.013597345142966713
Epoch #176: loss=0.010493099156672176
Epoch #177: loss=0.010534942485572163
Epoch #178: loss=0.020068919125166538
Epoch #179: loss=0.026867106258700077
Epoch #180: loss=0.012525271852360909
Epoch #181: loss=0.018029772328907446
Epoch #182: loss=0.023977657639734997
Epoch #183: loss=0.02047113996722954
Epoch #184: loss=0.018398308030306232
Epoch #185: loss=0.011832196070918653
Epoch #186: loss=0.013549620689750732
Epoch #187: loss=0.014201793724468743
Epoch #188: loss=0.014275937256931364
Epoch #189: loss=0.012370171276192369
Epoch #190: loss=0.017098705266168544
Epoch #191: loss=0.010009864788416607
Epoch #192: loss=0.01358062036778692
Epoch #193: loss=0.013050369477724167
Epoch #194: loss=0.015565991771404823
Epoch #195: loss=0.012331760149203922
Epoch #196: loss=0.01922317015782048
Epoch #197: loss=0.01373912877820734
Epoch #198: loss=0.017219885330622516
Epoch #199: loss=0.020214095419531626
Epoch #200: loss=0.016283854447333167
Epoch #201: loss=0.019472297518491333
Epoch #202: loss=0.02333502353665903
Epoch #203: loss=0.010829417939885134
Epoch #204: loss=0.015211488139931393
Epoch #205: loss=0.012458944034144184
Epoch #206: loss=0.012314028164187144
Epoch #207: loss=0.011076034789426283
Epoch #208: loss=0.008557560894795688
Epoch #209: loss=0.013482420069689721
Epoch #210: loss=0.015781892513805563
Epoch #211: loss=0.011833315169374983
Epoch #212: loss=0.009340747800254387
Epoch #213: loss=0.027299116582508255
Epoch #214: loss=0.015740853567821022
Epoch #215: loss=0.017218385989564423
Epoch #216: loss=0.024509855526627572
Epoch #217: loss=0.016139436473594535
Epoch #218: loss=0.014616536466741685
Epoch #219: loss=0.010432309747882338
Epoch #220: loss=0.01439063871076445
Epoch #221: loss=0.012605546114025845
Epoch #222: loss=0.01405534986439083
Epoch #223: loss=0.015952374525260903
Epoch #224: loss=0.010977869360969797
Epoch #225: loss=0.014232143006604893
Epoch #226: loss=0.01497811454659791
Epoch #227: loss=0.018337596283462054
Epoch #228: loss=0.01825618837028742
Epoch #229: loss=0.011673460175610387
Epoch #230: loss=0.010623694307840034
Epoch #231: loss=0.012081531933951062
Epoch #232: loss=0.018956315524677105
Epoch #233: loss=0.01884516876700787
Epoch #234: loss=0.010624929645653832
Epoch #235: loss=0.016652207711736564
Epoch #236: loss=0.015393676028480264
Epoch #237: loss=0.03578274378687333
Epoch #238: loss=0.011517631462820697
Epoch #239: loss=0.01157897455889638
Epoch #240: loss=0.013136684201597939
Epoch #241: loss=0.012847164988695961
Epoch #242: loss=0.010283188272317008
Epoch #243: loss=0.014132194237360163
Epoch #244: loss=0.020405245737228593
Epoch #245: loss=0.01953871522136826
Epoch #246: loss=0.01178296052544461
Epoch #247: loss=0.019062988877598216
Epoch #248: loss=0.015063938154388926
Epoch #249: loss=0.014982006848333196

Training time: 5:04:16.090269

Finished.
n2one setting ettm2_electricity_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm2_electricity_weather_epochs_250_seed_2021/model.pkl', muti_dataset='ettm2_electricity_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.98821e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.98821e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3025455094762649, 'MAE': 0.3601830949081804}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='ettm2_electricity_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/ettm2_electricity_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.8317126938525368
Epoch #1: loss=0.7771481019609114
Epoch #2: loss=0.5243380198145614
Epoch #3: loss=0.4566326605484766
Epoch #4: loss=0.35075293450671086
Epoch #5: loss=0.3222310065346606
Epoch #6: loss=0.29987454580910067
Epoch #7: loss=0.25742491005974655
Epoch #8: loss=0.2506088631118045
Epoch #9: loss=0.21026503735167137
Epoch #10: loss=0.19661406370646814
Epoch #11: loss=0.18265416025019743
Epoch #12: loss=0.15933952216497238
Epoch #13: loss=0.15618593633613165
Epoch #14: loss=0.1495311326073373
Epoch #15: loss=0.12176895156940994
Epoch #16: loss=0.11271159532206024
Epoch #17: loss=0.12261461752521641
Epoch #18: loss=0.096565376123523
Epoch #19: loss=0.09363498655695687
Epoch #20: loss=0.10398572658407776
Epoch #21: loss=0.1029800483272137
Epoch #22: loss=0.09434649733114331
Epoch #23: loss=0.08304671827868065
Epoch #24: loss=0.07841347834807547
Epoch #25: loss=0.07393291660392766
Epoch #26: loss=0.09840270560508703
Epoch #27: loss=0.0705079865463845
Epoch #28: loss=0.0600367283955326
Epoch #29: loss=0.05782589726286995
Epoch #30: loss=0.05885138039011508
Epoch #31: loss=0.06488827195100705
Epoch #32: loss=0.06550550973453724
Epoch #33: loss=0.08184164349564954
Epoch #34: loss=0.06328234457520439
Epoch #35: loss=0.05656308251131764
Epoch #36: loss=0.046173008029034145
Epoch #37: loss=0.05267629071878379
Epoch #38: loss=0.05493572938721627
Epoch #39: loss=0.04858923291869681
Epoch #40: loss=0.047630826476276575
Epoch #41: loss=0.04683935656006832
Epoch #42: loss=0.05753106672303094
Epoch #43: loss=0.04524899711353047
Epoch #44: loss=0.05139287689645939
Epoch #45: loss=0.04293566356782856
Epoch #46: loss=0.04394531615475631
Epoch #47: loss=0.050573281046372896
Epoch #48: loss=0.033255198535591585
Epoch #49: loss=0.03596185289241154
Epoch #50: loss=0.04444597654989647
Epoch #51: loss=0.04254249477183775
Epoch #52: loss=0.046130525012267755
Epoch #53: loss=0.04994164734517279
Epoch #54: loss=0.03299071954919354
Epoch #55: loss=0.047803308980484654
Epoch #56: loss=0.038503053215304936
Epoch #57: loss=0.062477524844956965
Epoch #58: loss=0.03317179507541689
Epoch #59: loss=0.0400906350254766
Epoch #60: loss=0.04916088258717483
Epoch #61: loss=0.04156529573305948
Epoch #62: loss=0.04949977377648739
Epoch #63: loss=0.036795041578657484
Epoch #64: loss=0.034322194187723865
Epoch #65: loss=0.04108764501322773
Epoch #66: loss=0.030602333732702606
Epoch #67: loss=0.02777101774357588
Epoch #68: loss=0.056996889582232514
Epoch #69: loss=0.02625666979036075
Epoch #70: loss=0.024721280111835393
Epoch #71: loss=0.0240556146720123
Epoch #72: loss=0.02677054776748478
Epoch #73: loss=0.04692378914606867
Epoch #74: loss=0.03073536996722824
Epoch #75: loss=0.02529684226593578
Epoch #76: loss=0.02221772397204083
Epoch #77: loss=0.024881286645883367
Epoch #78: loss=0.02428875604425283
Epoch #79: loss=0.04195074999725501
Epoch #80: loss=0.04113095632466652
Epoch #81: loss=0.028791644318399073
Epoch #82: loss=0.02729979032814941
Epoch #83: loss=0.026894954061615007
Epoch #84: loss=0.029844599707147982
Epoch #85: loss=0.031535019833416514
Epoch #86: loss=0.03604650997680009
Epoch #87: loss=0.028489129437024103
Epoch #88: loss=0.024317177956211654
Epoch #89: loss=0.02864083764006329
Epoch #90: loss=0.024772126149892916
Epoch #91: loss=0.022625106419368154
Epoch #92: loss=0.026828933749964243
Epoch #93: loss=0.03057836240349228
Epoch #94: loss=0.0314195494111011
Epoch #95: loss=0.030385104114333553
Epoch #96: loss=0.023595645503818933
Epoch #97: loss=0.025996856339043008
Epoch #98: loss=0.0312648762089392
Epoch #99: loss=0.025693084920503144
Epoch #100: loss=0.02012242637677392
Epoch #101: loss=0.019402016806827092
Epoch #102: loss=0.04603656377602259
Epoch #103: loss=0.021040453720385866
Epoch #104: loss=0.019439831650165346
Epoch #105: loss=0.036737209080328126
Epoch #106: loss=0.037360124291016664
Epoch #107: loss=0.02409269048281096
Epoch #108: loss=0.026795313566039754
Epoch #109: loss=0.05142108067760573
Epoch #110: loss=0.027577602975618315
Epoch #111: loss=0.023655788088902174
Epoch #112: loss=0.022668964145636624
Epoch #113: loss=0.033191201070440005
Epoch #114: loss=0.025000329195651882
Epoch #115: loss=0.01685649276649415
Epoch #116: loss=0.02515815638437155
Epoch #117: loss=0.017666126955951125
Epoch #118: loss=0.015531032462090746
Epoch #119: loss=0.01909589081085013
Epoch #120: loss=0.024884165283840368
Epoch #121: loss=0.03440963633920011
Epoch #122: loss=0.0201160030275145
Epoch #123: loss=0.024107734144576277
Epoch #124: loss=0.015470452954383183
Epoch #125: loss=0.022716098345014923
Epoch #126: loss=0.01854936663824928
Epoch #127: loss=0.03249448026746155
Epoch #128: loss=0.028394474115510306
Epoch #129: loss=0.038735629565096186
Epoch #130: loss=0.02437871295808102
Epoch #131: loss=0.02204536473607946
Epoch #132: loss=0.01861423488059218
Epoch #133: loss=0.018557223420237492
Epoch #134: loss=0.019088947773493334
Epoch #135: loss=0.021044917121488493
Epoch #136: loss=0.013098910678972436
Epoch #137: loss=0.019960356125375257
Epoch #138: loss=0.016279101602712592
Epoch #139: loss=0.01667661527873647
Epoch #140: loss=0.01677652569984168
Epoch #141: loss=0.01913524474691846
Epoch #142: loss=0.024755341795047143
Epoch #143: loss=0.03664387101033593
Epoch #144: loss=0.02800598918556181
Epoch #145: loss=0.02174123743915355
Epoch #146: loss=0.014486722664578873
Epoch #147: loss=0.01572751771668931
Epoch #148: loss=0.01784326518245507
Epoch #149: loss=0.019294243347351712
Epoch #150: loss=0.024009848122231607
Epoch #151: loss=0.028739174424074865
Epoch #152: loss=0.024891916679232108
Epoch #153: loss=0.020442748221787897
Epoch #154: loss=0.019616372780429252
Epoch #155: loss=0.0240286236461115
Epoch #156: loss=0.01738781036298914
Epoch #157: loss=0.020359171940157572
Epoch #158: loss=0.022236062366830404
Epoch #159: loss=0.02084106936270152
Epoch #160: loss=0.021131635893492356
Epoch #161: loss=0.020792006275287885
Epoch #162: loss=0.014685220854538356
Epoch #163: loss=0.0172998082716196
Epoch #164: loss=0.022367190955350558
Epoch #165: loss=0.01694230212819735
Epoch #166: loss=0.013829158539952272
Epoch #167: loss=0.02380720503963804
Epoch #168: loss=0.024000152367208264
Epoch #169: loss=0.026072772928369778
Epoch #170: loss=0.022790610117783
Epoch #171: loss=0.025164312719168854
Epoch #172: loss=0.019639828271465376
Epoch #173: loss=0.01607090533087852
Epoch #174: loss=0.016697485925225707
Epoch #175: loss=0.02159530161160921
Epoch #176: loss=0.01935690468594925
Epoch #177: loss=0.01622305912177955
Epoch #178: loss=0.019737628636957036
Epoch #179: loss=0.030946325131020892
Epoch #180: loss=0.01708477642164593
Epoch #181: loss=0.017197887250564665
Epoch #182: loss=0.014106846659834606
Epoch #183: loss=0.016236502981594052
Epoch #184: loss=0.018187115904498462
Epoch #185: loss=0.02404053628543967
Epoch #186: loss=0.019375784647726345
Epoch #187: loss=0.016642492577460977
Epoch #188: loss=0.013876561908674536
Epoch #189: loss=0.014958981486544122
Epoch #190: loss=0.020860221177538146
Epoch #191: loss=0.014128703344613313
Epoch #192: loss=0.022156796557143987
Epoch #193: loss=0.015163494069266188
Epoch #194: loss=0.013630072543096236
Epoch #195: loss=0.016150859803704353
Epoch #196: loss=0.015339119313798352
Epoch #197: loss=0.018618496321655315
Epoch #198: loss=0.01543727420948391
Epoch #199: loss=0.023131037988316488
Epoch #200: loss=0.018610411289367166
Epoch #201: loss=0.022977850430213626
Epoch #202: loss=0.022424475939581443
Epoch #203: loss=0.021930470076382762
Epoch #204: loss=0.019879238909411737
Epoch #205: loss=0.014710111358769663
Epoch #206: loss=0.016079450706841754
Epoch #207: loss=0.021176691127423992
Epoch #208: loss=0.02164694784596042
Epoch #209: loss=0.02663319906457807
Epoch #210: loss=0.01751610987669076
Epoch #211: loss=0.015424820714072078
Epoch #212: loss=0.01115748364759116
Epoch #213: loss=0.014955073766759596
Epoch #214: loss=0.01275496830143418
Epoch #215: loss=0.01732877485868384
Epoch #216: loss=0.022211018682163044
Epoch #217: loss=0.01373373245484853
Epoch #218: loss=0.015420450617110712
Epoch #219: loss=0.01787413759404765
Epoch #220: loss=0.02035030242653139
Epoch #221: loss=0.018890764573777287
Epoch #222: loss=0.013719125080730437
Epoch #223: loss=0.016810699507614654
Epoch #224: loss=0.015817746609665097
Epoch #225: loss=0.03160334540383808
Epoch #226: loss=0.026307201473323136
Epoch #227: loss=0.020609979195903766
Epoch #228: loss=0.01955970253013006
Epoch #229: loss=0.022900634684928638
Epoch #230: loss=0.017394818819936035
Epoch #231: loss=0.017232016141711295
Epoch #232: loss=0.020122644454429118
Epoch #233: loss=0.015872534285025563
Epoch #234: loss=0.014155985832022613
Epoch #235: loss=0.01120438067788628
Epoch #236: loss=0.011453340580063762
Epoch #237: loss=0.009276476348425015
Epoch #238: loss=0.0117808908367913
Epoch #239: loss=0.014141474919982583
Epoch #240: loss=0.029416048710974044
Epoch #241: loss=0.021317032368867384
Epoch #242: loss=0.013858278441544183
Epoch #243: loss=0.016150748671498148
Epoch #244: loss=0.01750605793118559
Epoch #245: loss=0.025718220063615318
Epoch #246: loss=0.026702863618608234
Epoch #247: loss=0.020039946359568548
Epoch #248: loss=0.019324439944124177
Epoch #249: loss=0.015104013193237786

Training time: 4:41:47.853766

Finished.
n2one setting ettm2_electricity_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm2_electricity_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='ettm2_electricity_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.66136e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.47049e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.6087285050969157, 'MAE': 0.6137499756182555}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='ettm2_traffic_weather', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/ettm2_traffic_weather_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.1778401965492957
Epoch #1: loss=0.4324040951101613
Epoch #2: loss=0.32681364087891396
Epoch #3: loss=0.2512335701202259
Epoch #4: loss=0.19697055407075648
Epoch #5: loss=0.17972074662054474
Epoch #6: loss=0.14315562054838102
Epoch #7: loss=0.12772337010791224
Epoch #8: loss=0.11366284458801665
Epoch #9: loss=0.10128669931270488
Epoch #10: loss=0.09062014806298778
Epoch #11: loss=0.084430361737925
Epoch #12: loss=0.07935035634460601
Epoch #13: loss=0.07247847131245228
Epoch #14: loss=0.06562108303926827
Epoch #15: loss=0.0556772736663121
Epoch #16: loss=0.057461045123274136
Epoch #17: loss=0.054159565314907454
Epoch #18: loss=0.05424693338826788
Epoch #19: loss=0.05803232248955395
Epoch #20: loss=0.06124107401638817
Epoch #21: loss=0.041625133600838075
Epoch #22: loss=0.036351467714540335
Epoch #23: loss=0.04459619054232037
Epoch #24: loss=0.035536339580448134
Epoch #25: loss=0.04480761413936927
Epoch #26: loss=0.0375821428620531
Epoch #27: loss=0.038029538193257634
Epoch #28: loss=0.03626263211170487
Epoch #29: loss=0.037510950823917415
Epoch #30: loss=0.036841627806699626
Epoch #31: loss=0.0295812981550243
Epoch #32: loss=0.032397587984091744
Epoch #33: loss=0.024670069601886117
Epoch #34: loss=0.032459222204393776
Epoch #35: loss=0.035340397801427365
Epoch #36: loss=0.03280473815938158
Epoch #37: loss=0.028940056870420575
Epoch #38: loss=0.026374505486264743
Epoch #39: loss=0.022234726352428083
Epoch #40: loss=0.02716911913235532
Epoch #41: loss=0.023653343362366994
Epoch #42: loss=0.03563152084663693
Epoch #43: loss=0.026774881265951823
Epoch #44: loss=0.0230895572736159
Epoch #45: loss=0.022779210813258576
Epoch #46: loss=0.030820965278065982
Epoch #47: loss=0.02776232691919659
Epoch #48: loss=0.0439003871210454
Epoch #49: loss=0.024515147166180574
Epoch #50: loss=0.02102426479071238
Epoch #51: loss=0.021618085738704763
Epoch #52: loss=0.026309980556458955
Epoch #53: loss=0.022311333692254492
Epoch #54: loss=0.021523774307696676
Epoch #55: loss=0.02315959689770416
Epoch #56: loss=0.021736207775159368
Epoch #57: loss=0.022959785185908656
Epoch #58: loss=0.023832340472317234
Epoch #59: loss=0.02086119180857551
Epoch #60: loss=0.03229432355211602
Epoch #61: loss=0.018571248534290912
Epoch #62: loss=0.024476490934828486
Epoch #63: loss=0.025207996442478908
Epoch #64: loss=0.02549988875440498
Epoch #65: loss=0.018595269727284966
Epoch #66: loss=0.01926441581114853
Epoch #67: loss=0.01947063154896288
Epoch #68: loss=0.021783370138622523
Epoch #69: loss=0.03212152649410218
Epoch #70: loss=0.022239104761267846
Epoch #71: loss=0.017248195806726423
Epoch #72: loss=0.021140532955414387
Epoch #73: loss=0.0213137756786844
Epoch #74: loss=0.024888315678468477
Epoch #75: loss=0.01869077863546194
Epoch #76: loss=0.02292622200979849
Epoch #77: loss=0.02770045824390753
Epoch #78: loss=0.01654659555287404
Epoch #79: loss=0.015525268239654949
Epoch #80: loss=0.01926147894941201
Epoch #81: loss=0.014581388785015352
Epoch #82: loss=0.01996961264974397
Epoch #83: loss=0.01447866064527676
Epoch #84: loss=0.02087751084292987
Epoch #85: loss=0.01261898726298711
Epoch #86: loss=0.01563587743846971
Epoch #87: loss=0.02336106471599777
Epoch #88: loss=0.020401072921749367
Epoch #89: loss=0.025745189882180622
Epoch #90: loss=0.015460229612738246
Epoch #91: loss=0.015138394249328883
Epoch #92: loss=0.016270485777476903
Epoch #93: loss=0.01927515243871466
Epoch #94: loss=0.02777845751923054
Epoch #95: loss=0.013183257646518252
Epoch #96: loss=0.020695552475596606
Epoch #97: loss=0.013410068225177436
Epoch #98: loss=0.016635251775302628
Epoch #99: loss=0.017788245870749383
Epoch #100: loss=0.015925639068906726
Epoch #101: loss=0.01813879134171659
Epoch #102: loss=0.025523402560186325
Epoch #103: loss=0.017363939772528886
Epoch #104: loss=0.013690666028214784
Epoch #105: loss=0.022708133467750465
Epoch #106: loss=0.018194745214916538
Epoch #107: loss=0.01247985574343134
Epoch #108: loss=0.018725635534590338
Epoch #109: loss=0.016692931423873045
Epoch #110: loss=0.019644880918774275
Epoch #111: loss=0.015128710242110027
Epoch #112: loss=0.014236578833852613
Epoch #113: loss=0.01572519879750866
Epoch #114: loss=0.0202748326461224
Epoch #115: loss=0.022493408991737282
Epoch #116: loss=0.022401674665986936
Epoch #117: loss=0.014350305126884899
Epoch #118: loss=0.015853337813250344
Epoch #119: loss=0.015549642529999796
Epoch #120: loss=0.011568957334798501
Epoch #121: loss=0.015650577911821187
Epoch #122: loss=0.016013621343904483
Epoch #123: loss=0.013484010783615144
Epoch #124: loss=0.02141300741041832
Epoch #125: loss=0.014567681509111537
Epoch #126: loss=0.011615973416895145
Epoch #127: loss=0.01298545125800157
Epoch #128: loss=0.019036909113257065
Epoch #129: loss=0.024249645316488794
Epoch #130: loss=0.01490598686080368
Epoch #131: loss=0.015852148070157317
Epoch #132: loss=0.013932135426638766
Epoch #133: loss=0.011995692670516757
Epoch #134: loss=0.016307926116205313
Epoch #135: loss=0.01361170995782893
Epoch #136: loss=0.016958160229379238
Epoch #137: loss=0.017200573211183845
Epoch #138: loss=0.014047621675270782
Epoch #139: loss=0.01189882316927294
Epoch #140: loss=0.019880682776429046
Epoch #141: loss=0.01404106436400634
Epoch #142: loss=0.018319364779709617
Epoch #143: loss=0.01593126370249042
Epoch #144: loss=0.017671619291371718
Epoch #145: loss=0.013774237396724903
Epoch #146: loss=0.014360528161680094
Epoch #147: loss=0.011313498105185088
Epoch #148: loss=0.01679627669301662
Epoch #149: loss=0.019007879838243064
Epoch #150: loss=0.024079331006067187
Epoch #151: loss=0.013500159892875927
Epoch #152: loss=0.011822544405282423
Epoch #153: loss=0.011463641000786501
Epoch #154: loss=0.010533307116377417
Epoch #155: loss=0.016230990234338983
Epoch #156: loss=0.017693921752607873
Epoch #157: loss=0.013169766254913428
Epoch #158: loss=0.014227117734362431
Epoch #159: loss=0.011092639053521421
Epoch #160: loss=0.010519363654375198
Epoch #161: loss=0.01595054419887474
Epoch #162: loss=0.010131569510239417
Epoch #163: loss=0.015841499681099453
Epoch #164: loss=0.005953057029304479
Epoch #165: loss=0.0162973519754741
Epoch #166: loss=0.014962185490548816
Epoch #167: loss=0.012080875200550827
Epoch #168: loss=0.01484466162887692
Epoch #169: loss=0.01260946455253112
Epoch #170: loss=0.01380561982531171
Epoch #171: loss=0.012703713129139356
Epoch #172: loss=0.009589283449344288
Epoch #173: loss=0.019665186535027055
Epoch #174: loss=0.008982146545884855
Epoch #175: loss=0.015224762165185231
Epoch #176: loss=0.011417804588366262
Epoch #177: loss=0.011601661101872726
Epoch #178: loss=0.019984224255180434
Epoch #179: loss=0.013583936750486357
Epoch #180: loss=0.007353545621870002
Epoch #181: loss=0.013388087105225342
Epoch #182: loss=0.013836205963417525
Epoch #183: loss=0.007317188741085329
Epoch #184: loss=0.029708020982843513
Epoch #185: loss=0.008037118247743521
Epoch #186: loss=0.013195383670134186
Epoch #187: loss=0.01288575682386943
Epoch #188: loss=0.008067556201520457
Epoch #189: loss=0.010632444940707092
Epoch #190: loss=0.019421090329545955
Epoch #191: loss=0.0156539532933379
Epoch #192: loss=0.014529169155798854
Epoch #193: loss=0.014879478453714203
Epoch #194: loss=0.013545776766750653
Epoch #195: loss=0.013308808587043332
Epoch #196: loss=0.009837796166260779
Epoch #197: loss=0.013207287845253976
Epoch #198: loss=0.009209056853282603
Epoch #199: loss=0.012409049203141268
Epoch #200: loss=0.014838945256137326
Epoch #201: loss=0.009445675609350251
Epoch #202: loss=0.016734981282739262
Epoch #203: loss=0.01647215329869588
Epoch #204: loss=0.010032934269938282
Epoch #205: loss=0.011822266868128258
Epoch #206: loss=0.01325126089852612
Epoch #207: loss=0.015991413042430215
Epoch #208: loss=0.016515026005029392
Epoch #209: loss=0.01066996673414317
Epoch #210: loss=0.012090766077845132
Epoch #211: loss=0.012717775936707625
Epoch #212: loss=0.016193957790102135
Epoch #213: loss=0.011076736426389415
Epoch #214: loss=0.0195230504221286
Epoch #215: loss=0.007934004014262228
Epoch #216: loss=0.014411141614075357
Epoch #217: loss=0.010408985467538424
Epoch #218: loss=0.010746610856711351
Epoch #219: loss=0.011998524635217491
Epoch #220: loss=0.010527453671524314
Epoch #221: loss=0.010673001378259127
Epoch #222: loss=0.012802054822654438
Epoch #223: loss=0.014752783343748596
Epoch #224: loss=0.011358094066639795
Epoch #225: loss=0.012136690156700455
Epoch #226: loss=0.01151876902192905
Epoch #227: loss=0.012348156843119606
Epoch #228: loss=0.011497087199478787
Epoch #229: loss=0.009652320258091792
Epoch #230: loss=0.011057979069841566
Epoch #231: loss=0.012123664543575228
Epoch #232: loss=0.014678769957225307
Epoch #233: loss=0.01142491310007028
Epoch #234: loss=0.011334882325919272
Epoch #235: loss=0.016862504041617515
Epoch #236: loss=0.011584116552645098
Epoch #237: loss=0.008687499971280306
Epoch #238: loss=0.014012788257689047
Epoch #239: loss=0.009213459495277878
Epoch #240: loss=0.010249166629441368
Epoch #241: loss=0.013630957651916515
Epoch #242: loss=0.012618213554860964
Epoch #243: loss=0.006617308444364485
Epoch #244: loss=0.01066196367695712
Epoch #245: loss=0.009973888393731459
Epoch #246: loss=0.017600600748453436
Epoch #247: loss=0.013140059949667509
Epoch #248: loss=0.012772370929604392
Epoch #249: loss=0.013207053550920741

Training time: 10:26:43.611776

Finished.
n2one setting ettm2_traffic_weather -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm2_traffic_weather_epochs_250_seed_2021/model.pkl', muti_dataset='ettm2_traffic_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.062e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.11879e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.20378e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.062e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.42734766475989727, 'MAE': 0.46509598029910426}
Finished.
------------------------- record done -------------------------
n2one setting ettm2_traffic_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm2_traffic_weather_epochs_250_seed_2021/model.pkl', muti_dataset='ettm2_traffic_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.436e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.28394230216041827, 'MAE': 0.35227467101453896}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='ettm2_traffic_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/ettm2_traffic_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.129486438094149
Epoch #1: loss=0.39690748591157826
Epoch #2: loss=0.31293909659315317
Epoch #3: loss=0.22030307951295552
Epoch #4: loss=0.19071740116691482
Epoch #5: loss=0.14578424114628222
Epoch #6: loss=0.12969311134980635
Epoch #7: loss=0.11346123275155716
Epoch #8: loss=0.09317818109927092
Epoch #9: loss=0.07692289777273453
Epoch #10: loss=0.0817655095604336
Epoch #11: loss=0.06955199122902483
Epoch #12: loss=0.06934999628151078
Epoch #13: loss=0.06896087715812409
Epoch #14: loss=0.06813279994648208
Epoch #15: loss=0.05391903737508116
Epoch #16: loss=0.05208199144743814
Epoch #17: loss=0.05920105159048004
Epoch #18: loss=0.052547257029949335
Epoch #19: loss=0.06501338558607692
Epoch #20: loss=0.04387587922013171
Epoch #21: loss=0.04708106782383557
Epoch #22: loss=0.037401790537995104
Epoch #23: loss=0.038736264627039954
Epoch #24: loss=0.04671850439507798
Epoch #25: loss=0.04484541404455325
Epoch #26: loss=0.04035270059714886
Epoch #27: loss=0.03517836846292831
Epoch #28: loss=0.03766991176008734
Epoch #29: loss=0.03491457350997129
Epoch #30: loss=0.0379167730867425
Epoch #31: loss=0.039766575367043006
Epoch #32: loss=0.04079368220265346
Epoch #33: loss=0.037606398546862096
Epoch #34: loss=0.0331986148062846
Epoch #35: loss=0.041734483878331195
Epoch #36: loss=0.030336175232313817
Epoch #37: loss=0.028253697940316496
Epoch #38: loss=0.033151622414726356
Epoch #39: loss=0.03331718305202474
Epoch #40: loss=0.024368410428830558
Epoch #41: loss=0.03733192544198456
Epoch #42: loss=0.03300773803946519
Epoch #43: loss=0.025056490448391262
Epoch #44: loss=0.03224248349046595
Epoch #45: loss=0.022674520856716167
Epoch #46: loss=0.03439430236736065
Epoch #47: loss=0.026729419801627876
Epoch #48: loss=0.03215863743017847
Epoch #49: loss=0.02578930879248545
Epoch #50: loss=0.02891908547433757
Epoch #51: loss=0.025092060702483442
Epoch #52: loss=0.02263691593441218
Epoch #53: loss=0.022937704443510846
Epoch #54: loss=0.026695785572856484
Epoch #55: loss=0.030253396578165878
Epoch #56: loss=0.021331534052196843
Epoch #57: loss=0.022057003334545713
Epoch #58: loss=0.04860950506559999
Epoch #59: loss=0.016956137439273572
Epoch #60: loss=0.015961244387449603
Epoch #61: loss=0.021617156263743713
Epoch #62: loss=0.0210458724048606
Epoch #63: loss=0.022049405540068234
Epoch #64: loss=0.021670818966300683
Epoch #65: loss=0.019344019602612082
Epoch #66: loss=0.023407684482840734
Epoch #67: loss=0.018182405660217775
Epoch #68: loss=0.022323170978040513
Epoch #69: loss=0.019295864136956702
Epoch #70: loss=0.020873616274218177
Epoch #71: loss=0.01756908389853729
Epoch #72: loss=0.016684220872377285
Epoch #73: loss=0.019734056330923937
Epoch #74: loss=0.02407796876679442
Epoch #75: loss=0.03022378280122736
Epoch #76: loss=0.01626861946297615
Epoch #77: loss=0.020510350158845076
Epoch #78: loss=0.018229796788953857
Epoch #79: loss=0.022221996329611676
Epoch #80: loss=0.01884282902599324
Epoch #81: loss=0.021673989924595603
Epoch #82: loss=0.02442219245603528
Epoch #83: loss=0.017813780480763472
Epoch #84: loss=0.017204232640758953
Epoch #85: loss=0.017120682308874015
Epoch #86: loss=0.01942487476438772
Epoch #87: loss=0.027543850000746863
Epoch #88: loss=0.01606329773549016
Epoch #89: loss=0.017933055128003382
Epoch #90: loss=0.022854111707786777
Epoch #91: loss=0.015320890552705739
Epoch #92: loss=0.027498591671500643
Epoch #93: loss=0.013925605297790815
Epoch #94: loss=0.015364605848858223
Epoch #95: loss=0.018049879755431555
Epoch #96: loss=0.02012647304069605
Epoch #97: loss=0.017624010679324734
Epoch #98: loss=0.019048802795168223
Epoch #99: loss=0.014032796135646102
Epoch #100: loss=0.015922207900878754
Epoch #101: loss=0.017540514191190282
Epoch #102: loss=0.01621630650462664
Epoch #103: loss=0.025578968071446953
Epoch #104: loss=0.01954329770903957
Epoch #105: loss=0.025527001384930595
Epoch #106: loss=0.012704730518068431
Epoch #107: loss=0.015064267563199145
Epoch #108: loss=0.012163907787094615
Epoch #109: loss=0.019067346870531323
Epoch #110: loss=0.014011341161197675
Epoch #111: loss=0.015810547062226493
Epoch #112: loss=0.01497104047211183
Epoch #113: loss=0.021489477099424753
Epoch #114: loss=0.015965169536493715
Epoch #115: loss=0.01693458705645654
Epoch #116: loss=0.01734575532620168
Epoch #117: loss=0.016568516070324724
Epoch #118: loss=0.013169595787037908
Epoch #119: loss=0.020949270928986307
Epoch #120: loss=0.015917065377080018
Epoch #121: loss=0.016462242832439335
Epoch #122: loss=0.017984603767726724
Epoch #123: loss=0.019757212842683804
Epoch #124: loss=0.013644219442724696
Epoch #125: loss=0.01587498018504678
Epoch #126: loss=0.016324264468554096
Epoch #127: loss=0.017909008915218707
Epoch #128: loss=0.014030597943697778
Epoch #129: loss=0.022341220245076076
Epoch #130: loss=0.017866717064190258
Epoch #131: loss=0.01885225870204528
Epoch #132: loss=0.01888786901638734
Epoch #133: loss=0.016240604632148502
Epoch #134: loss=0.02077214876471286
Epoch #135: loss=0.016715794025455727
Epoch #136: loss=0.014598624510283579
Epoch #137: loss=0.016466971878585392
Epoch #138: loss=0.014407421929187487
Epoch #139: loss=0.015696281713032386
Epoch #140: loss=0.016268046660413257
Epoch #141: loss=0.01313674521897301
Epoch #142: loss=0.015096879833890336
Epoch #143: loss=0.016598827000781385
Epoch #144: loss=0.016986076990549454
Epoch #145: loss=0.012840086580514453
Epoch #146: loss=0.01779750066035148
Epoch #147: loss=0.015351100393138068
Epoch #148: loss=0.013387584178623924
Epoch #149: loss=0.02064093559328678
Epoch #150: loss=0.016467713008073943
Epoch #151: loss=0.01647737961831063
Epoch #152: loss=0.014175029780525952
Epoch #153: loss=0.01957442138949779
Epoch #154: loss=0.017176827022145902
Epoch #155: loss=0.013980483341158425
Epoch #156: loss=0.011410661620047223
Epoch #157: loss=0.01333114690761527
Epoch #158: loss=0.015764861892469843
Epoch #159: loss=0.012796362433923465
Epoch #160: loss=0.011523120856218073
Epoch #161: loss=0.015891636434203688
Epoch #162: loss=0.012947691979144926
Epoch #163: loss=0.018533678127098066
Epoch #164: loss=0.013595219829340944
Epoch #165: loss=0.015123991796935281
Epoch #166: loss=0.017193751751908914
Epoch #167: loss=0.010548392300365575
Epoch #168: loss=0.010742191563056603
Epoch #169: loss=0.015654562174129298
Epoch #170: loss=0.011649960947508298
Epoch #171: loss=0.021395213241098505
Epoch #172: loss=0.014298959918704442
Epoch #173: loss=0.009754649428041572
Epoch #174: loss=0.011203087798650636
Epoch #175: loss=0.013373065379739075
Epoch #176: loss=0.013550077742164521
Epoch #177: loss=0.01541107203430844
Epoch #178: loss=0.017287920551591528
Epoch #179: loss=0.014079653534091583
Epoch #180: loss=0.010582832414813463
Epoch #181: loss=0.012490766182268053
Epoch #182: loss=0.013304618082866381
Epoch #183: loss=0.012230470264961475
Epoch #184: loss=0.014873258070293476
Epoch #185: loss=0.01473790776885324
Epoch #186: loss=0.011781092605662714
Epoch #187: loss=0.019535159035630748
Epoch #188: loss=0.013727326353281952
Epoch #189: loss=0.012004636728234387
Epoch #190: loss=0.01748117394031133
Epoch #191: loss=0.011345547340079169
Epoch #192: loss=0.012905005003051055
Epoch #193: loss=0.015432105947950026
Epoch #194: loss=0.011884375797900732
Epoch #195: loss=0.013803717396290107
Epoch #196: loss=0.01201677800032427
Epoch #197: loss=0.013140920343426682
Epoch #198: loss=0.014659185201420146
Epoch #199: loss=0.015326952852592718
Epoch #200: loss=0.010253236791006396
Epoch #201: loss=0.0137615529999703
Epoch #202: loss=0.013558426664237812
Epoch #203: loss=0.010102013634638961
Epoch #204: loss=0.01312689255624
Epoch #205: loss=0.012194423716426504
Epoch #206: loss=0.012138849582061807
Epoch #207: loss=0.01684213304770878
Epoch #208: loss=0.01239053471861978
Epoch #209: loss=0.016657159436257847
Epoch #210: loss=0.011168470267252283
Epoch #211: loss=0.010007404841992171
Epoch #212: loss=0.013558775102398564
Epoch #213: loss=0.01891385737032747
Epoch #214: loss=0.013410626596133738
Epoch #215: loss=0.011871649864229884
Epoch #216: loss=0.010248901610978627
Epoch #217: loss=0.015816588799712178
Epoch #218: loss=0.010876683416493184
Epoch #219: loss=0.012825280980211783
Epoch #220: loss=0.012219954576288064
Epoch #221: loss=0.01357703030554519
Epoch #222: loss=0.015349918991737845
Epoch #223: loss=0.01516340431660743
Epoch #224: loss=0.013554112168543504
Epoch #225: loss=0.014424741960274136
Epoch #226: loss=0.0134370344632903
Epoch #227: loss=0.013275809097724833
Epoch #228: loss=0.009665509771368552
Epoch #229: loss=0.0144174838431924
Epoch #230: loss=0.014879533347931916
Epoch #231: loss=0.008437708459972118
Epoch #232: loss=0.015544095184628494
Epoch #233: loss=0.010798783124727184
Epoch #234: loss=0.011704356240536215
Epoch #235: loss=0.013979696831392156
Epoch #236: loss=0.01227992652623653
Epoch #237: loss=0.024516277890537456
Epoch #238: loss=0.016260828962060648
Epoch #239: loss=0.01277404902362826
Epoch #240: loss=0.013088963313456383
Epoch #241: loss=0.010576416201512652
Epoch #242: loss=0.011027547998869713
Epoch #243: loss=0.01991928947095986
Epoch #244: loss=0.018976935498168264
Epoch #245: loss=0.020064946396928334
Epoch #246: loss=0.009426873641728955
Epoch #247: loss=0.009145164827092853
Epoch #248: loss=0.010518801995501145
Epoch #249: loss=0.020971981261648866

Training time: 10:21:40.818923

Finished.
n2one setting ettm2_traffic_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm2_traffic_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='ettm2_traffic_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.15267e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.2536e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.51454e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.15267e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4168447899523137, 'MAE': 0.4600421766724885}
Finished.
------------------------- record done -------------------------
n2one setting ettm2_traffic_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm2_traffic_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='ettm2_traffic_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.82432e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.64174e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.82432e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.5334097500145113, 'MAE': 0.5615839381666924}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='ettm2_weather_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/ettm2_weather_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=5.000103791554769
Epoch #1: loss=2.5513588825861615
Epoch #2: loss=2.6521328078375923
Epoch #3: loss=2.150622765223185
Epoch #4: loss=1.9909475750393337
Epoch #5: loss=1.8818207422892252
Epoch #6: loss=1.745858407020569
Epoch #7: loss=1.6204116291469999
Epoch #8: loss=1.397815179824829
Epoch #9: loss=1.4358036094241673
Epoch #10: loss=1.3107560926013522
Epoch #11: loss=1.2762733234299555
Epoch #12: loss=1.2008689747916328
Epoch #13: loss=1.1827516105439928
Epoch #14: loss=1.0920541803042094
Epoch #15: loss=1.116938959227668
Epoch #16: loss=1.061568972799513
Epoch #17: loss=1.0005917615360684
Epoch #18: loss=0.9808660467465719
Epoch #19: loss=0.9356029113133748
Epoch #20: loss=0.9504064030117458
Epoch #21: loss=0.8896127250459459
Epoch #22: loss=0.920606956217024
Epoch #23: loss=0.8514475093947517
Epoch #24: loss=0.8247608767615424
Epoch #25: loss=0.7895336694187588
Epoch #26: loss=0.7492775016360813
Epoch #27: loss=0.6984624220265283
Epoch #28: loss=0.7755843175782098
Epoch #29: loss=0.8360588391621907
Epoch #30: loss=0.7035341448254055
Epoch #31: loss=0.76070204310947
Epoch #32: loss=0.6933870037396749
Epoch #33: loss=0.7579038659731547
Epoch #34: loss=0.6604304167959425
Epoch #35: loss=0.6163216981622908
Epoch #36: loss=0.5888894591066572
Epoch #37: loss=0.6952605969376034
Epoch #38: loss=0.6749978939692179
Epoch #39: loss=0.6405486947960324
Epoch #40: loss=0.5618428753481971
Epoch #41: loss=0.6366261382897694
Epoch #42: loss=0.5955729643503825
Epoch #43: loss=0.5168771564960479
Epoch #44: loss=0.536854319439994
Epoch #45: loss=0.632328701681561
Epoch #46: loss=0.6222217374377781
Epoch #47: loss=0.5981307976775699
Epoch #48: loss=0.5130242023203108
Epoch #49: loss=0.5232130507628123
Epoch #50: loss=0.45307065513398914
Epoch #51: loss=0.4652358445856306
Epoch #52: loss=0.44742527306079866
Epoch #53: loss=0.4566076080004374
Epoch #54: loss=0.4519811779260635
Epoch #55: loss=0.38281689451800455
Epoch #56: loss=0.425326907965872
Epoch #57: loss=0.40451303588019477
Epoch #58: loss=0.4091573741700914
Epoch #59: loss=0.4071263502041499
Epoch #60: loss=0.3361682219637765
Epoch #61: loss=0.38292734887864854
Epoch #62: loss=0.41694486406114367
Epoch #63: loss=0.376187844408883
Epoch #64: loss=0.3993923428985808
Epoch #65: loss=0.39163669645786287
Epoch #66: loss=0.39953927795092264
Epoch #67: loss=0.38536109493838416
Epoch #68: loss=0.3256907080610593
Epoch #69: loss=0.3115675964289241
Epoch #70: loss=0.31885863376988305
Epoch #71: loss=0.3148214737574259
Epoch #72: loss=0.24242739528417587
Epoch #73: loss=0.43466479116015966
Epoch #74: loss=0.3175495243734784
Epoch #75: loss=0.3276035737660196
Epoch #76: loss=0.31142327222559185
Epoch #77: loss=0.4070440507597394
Epoch #78: loss=0.4048450590835677
Epoch #79: loss=0.31192278133498297
Epoch #80: loss=0.3303287535905838
Epoch #81: loss=0.3102422825164265
Epoch #82: loss=0.29882176766792934
Epoch #83: loss=0.2822054225537512
Epoch #84: loss=0.27964145325952106
Epoch #85: loss=0.3308805975649092
Epoch #86: loss=0.25469884773095447
Epoch #87: loss=0.22429748641120062
Epoch #88: loss=0.20391709092590543
Epoch #89: loss=0.28281584779421487
Epoch #90: loss=0.2838453703456455
Epoch #91: loss=0.26286135812600453
Epoch #92: loss=0.26629822734329434
Epoch #93: loss=0.28630877236525215
Epoch #94: loss=0.3187029644846916
Epoch #95: loss=0.3069404910008113
Epoch #96: loss=0.252887233098348
Epoch #97: loss=0.269750782681836
Epoch #98: loss=0.19432880878448486
Epoch #99: loss=0.28517856523394586
Epoch #100: loss=0.24442005025015937
Epoch #101: loss=0.2635196164250374
Epoch #102: loss=0.23845492957366837
Epoch #103: loss=0.2040075792206658
Epoch #104: loss=0.2223934659527408
Epoch #105: loss=0.2172191296186712
Epoch #106: loss=0.19708255330721539
Epoch #107: loss=0.17869385340147548
Epoch #108: loss=0.20397168671091398
Epoch #109: loss=0.21917016473081377
Epoch #110: loss=0.23502941214376025
Epoch #111: loss=0.20491069141361448
Epoch #112: loss=0.1512298801706897
Epoch #113: loss=0.18282617901762327
Epoch #114: loss=0.19704995271232392
Epoch #115: loss=0.24960455008678967
Epoch #116: loss=0.2154683723217911
Epoch #117: loss=0.18819546153148015
Epoch #118: loss=0.15718085459536976
Epoch #119: loss=0.1605468548834324
Epoch #120: loss=0.1822512792216407
Epoch #121: loss=0.17545592370960447
Epoch #122: loss=0.21345376016365158
Epoch #123: loss=0.21426751878526476
Epoch #124: loss=0.17619878446890247
Epoch #125: loss=0.19666612048943838
Epoch #126: loss=0.1711608286533091
Epoch #127: loss=0.16558860060241487
Epoch #128: loss=0.1451511788699362
Epoch #129: loss=0.12239109141131242
Epoch #130: loss=0.1325397184325589
Epoch #131: loss=0.14444085053271719
Epoch #132: loss=0.13918775849872164
Epoch #133: loss=0.15474783620900578
Epoch #134: loss=0.15629037680725258
Epoch #135: loss=0.1636352429787318
Epoch #136: loss=0.16078996194733514
Epoch #137: loss=0.13320752854148546
Epoch #138: loss=0.13008339491983253
Epoch #139: loss=0.1756516987250911
Epoch #140: loss=0.19704136202732722
Epoch #141: loss=0.18544335605369675
Epoch #142: loss=0.1578266906655497
Epoch #143: loss=0.2018994516796536
Epoch #144: loss=0.1569440658721659
Epoch #145: loss=0.214941611720456
Epoch #146: loss=0.2483614123529858
Epoch #147: loss=0.2529196540514628
Epoch #148: loss=0.17150014001462194
Epoch #149: loss=0.1132111519575119
Epoch #150: loss=0.13726638878385225
Epoch #151: loss=0.11902295615937974
Epoch #152: loss=0.1937453797707955
Epoch #153: loss=0.1572030630790525
Epoch #154: loss=0.18484292349053755
Epoch #155: loss=0.20300675961706374
Epoch #156: loss=0.14232466854155063
Epoch #157: loss=0.10666083449290858
Epoch #158: loss=0.1376741071542104
Epoch #159: loss=0.18231426162852182
Epoch #160: loss=0.13399427810476885
Epoch #161: loss=0.13125130861169762
Epoch #162: loss=0.09800213103493055
Epoch #163: loss=0.08113838024437428
Epoch #164: loss=0.09099189129968484
Epoch #165: loss=0.11524250846770075
Epoch #166: loss=0.14086972694430086
Epoch #167: loss=0.13208182002935145
Epoch #168: loss=0.1262372937467363
Epoch #169: loss=0.11002209091352091
Epoch #170: loss=0.11155244550771183
Epoch #171: loss=0.10457389735513263
Epoch #172: loss=0.09872899200353358
Epoch #173: loss=0.09841417330834601
Epoch #174: loss=0.1678185471230083
Epoch #175: loss=0.16072338190343644
Epoch #176: loss=0.11793047715392378
Epoch #177: loss=0.11203924140168561
Epoch #178: loss=0.08147293950120608
Epoch #179: loss=0.0902531547885802
Epoch #180: loss=0.0664630258662833
Epoch #181: loss=0.07127624704606003
Epoch #182: loss=0.10656061880290509
Epoch #183: loss=0.14051344841718674
Epoch #184: loss=0.09269023305839963
Epoch #185: loss=0.0888307276285357
Epoch #186: loss=0.09617294975452953
Epoch #187: loss=0.09037398172335492
Epoch #188: loss=0.13034708355036045
Epoch #189: loss=0.13116649840441014
Epoch #190: loss=0.13660625521507527
Epoch #191: loss=0.13101072907447814
Epoch #192: loss=0.12125677081445853
Epoch #193: loss=0.24591894646485646
Epoch #194: loss=0.1196473461886247
Epoch #195: loss=0.08761753675838312
Epoch #196: loss=0.0746688230170144
Epoch #197: loss=0.07434383084376653
Epoch #198: loss=0.08449240372412735
Epoch #199: loss=0.11781203614340888
Epoch #200: loss=0.09019914153549406
Epoch #201: loss=0.0967337748242749
Epoch #202: loss=0.1354171960718102
Epoch #203: loss=0.14029336637920803
Epoch #204: loss=0.09852254829472966
Epoch #205: loss=0.10570095245622926
Epoch #206: loss=0.12761350903246138
Epoch #207: loss=0.08316857334640292
Epoch #208: loss=0.05868542076398929
Epoch #209: loss=0.0804252490401268
Epoch #210: loss=0.09913255475047562
Epoch #211: loss=0.10219051382607884
Epoch #212: loss=0.14859550591144297
Epoch #213: loss=0.10668422484563457
Epoch #214: loss=0.08195646303809351
Epoch #215: loss=0.12234490588307381
Epoch #216: loss=0.12309794074131383
Epoch #217: loss=0.10617607244186932
Epoch #218: loss=0.08867993681795067
Epoch #219: loss=0.06306905878914727
Epoch #220: loss=0.13197836356444492
Epoch #221: loss=0.10336794147474898
Epoch #222: loss=0.09788099872983164
Epoch #223: loss=0.0778361555809776
Epoch #224: loss=0.11080890906353792
Epoch #225: loss=0.07626544849740134
Epoch #226: loss=0.08816277022576995
Epoch #227: loss=0.08895339866479238
Epoch #228: loss=0.08064960150255097
Epoch #229: loss=0.08902964958300193
Epoch #230: loss=0.10579825683186452
Epoch #231: loss=0.1124683706710736
Epoch #232: loss=0.1261442845273349
Epoch #233: loss=0.14675820411907303
Epoch #234: loss=0.1894315194752481
Epoch #235: loss=0.13565025991863675
Epoch #236: loss=0.09801510721445084
Epoch #237: loss=0.1100393777092298
Epoch #238: loss=0.07927651703357697
Epoch #239: loss=0.049090617212156455
Epoch #240: loss=0.10228508274174399
Epoch #241: loss=0.09929596133944062
Epoch #242: loss=0.06778471022844315
Epoch #243: loss=0.07224359671688742
Epoch #244: loss=0.09145431551668379
Epoch #245: loss=0.07426845485137569
Epoch #246: loss=0.08826753902766439
Epoch #247: loss=0.10185733255412843
Epoch #248: loss=0.07799404615329372
Epoch #249: loss=0.08105208128690719

Training time: 0:43:11.995617

Finished.
n2one setting ettm2_weather_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm2_weather_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='ettm2_weather_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.74634e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.54761e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.74634e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.39017687932715855, 'MAE': 0.43927287729753267}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='electricity_traffic_weather', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/electricity_traffic_weather_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.855845293789683
Epoch #1: loss=0.3456669730266034
Epoch #2: loss=0.2386513392635867
Epoch #3: loss=0.17697892868020892
Epoch #4: loss=0.14518943678270302
Epoch #5: loss=0.10854651007841351
Epoch #6: loss=0.10611669218200016
Epoch #7: loss=0.08229195458638867
Epoch #8: loss=0.07509062999152294
Epoch #9: loss=0.06247178816742659
Epoch #10: loss=0.0596664646910804
Epoch #11: loss=0.052821809032699285
Epoch #12: loss=0.05221203606417041
Epoch #13: loss=0.05059249260666186
Epoch #14: loss=0.0470699682899938
Epoch #15: loss=0.040613181874613574
Epoch #16: loss=0.03986943108734511
Epoch #17: loss=0.050765364820532795
Epoch #18: loss=0.030802584164471628
Epoch #19: loss=0.030203648961790067
Epoch #20: loss=0.02873730238329086
Epoch #21: loss=0.04162678950908382
Epoch #22: loss=0.03007945599066397
Epoch #23: loss=0.029358392206291807
Epoch #24: loss=0.029905177924279016
Epoch #25: loss=0.021464783847474512
Epoch #26: loss=0.03873825217909168
Epoch #27: loss=0.027848114624819384
Epoch #28: loss=0.02875955049339466
Epoch #29: loss=0.02254128331664951
Epoch #30: loss=0.025441768652269565
Epoch #31: loss=0.025546124940220037
Epoch #32: loss=0.02742050500477628
Epoch #33: loss=0.026010601965849565
Epoch #34: loss=0.023413987209784704
Epoch #35: loss=0.03240524663307186
Epoch #36: loss=0.019778949879943736
Epoch #37: loss=0.02734425623534899
Epoch #38: loss=0.021255778404710716
Epoch #39: loss=0.03534114814578726
Epoch #40: loss=0.017153093830277532
Epoch #41: loss=0.017621041765150353
Epoch #42: loss=0.02312913560298887
Epoch #43: loss=0.020396084412560713
Epoch #44: loss=0.025806216423751593
Epoch #45: loss=0.019904894995522577
Epoch #46: loss=0.022415101902377024
Epoch #47: loss=0.019479555269132073
Epoch #48: loss=0.022462934233790158
Epoch #49: loss=0.02053938863826515
Epoch #50: loss=0.019705372389634754
Epoch #51: loss=0.0181941102186932
Epoch #52: loss=0.018314194865235896
Epoch #53: loss=0.023881610947292502
Epoch #54: loss=0.022706465416853075
Epoch #55: loss=0.01868533531579977
Epoch #56: loss=0.014552734072821451
Epoch #57: loss=0.023848068320351853
Epoch #58: loss=0.0144823219086374
Epoch #59: loss=0.015109024104289402
Epoch #60: loss=0.02083792255059381
Epoch #61: loss=0.017250974006164932
Epoch #62: loss=0.01583484567672833
Epoch #63: loss=0.022448482207457647
Epoch #64: loss=0.015116001801949296
Epoch #65: loss=0.013411171087115845
Epoch #66: loss=0.02219870121396787
Epoch #67: loss=0.02113782324837066
Epoch #68: loss=0.015560473833075971
Epoch #69: loss=0.01871211399061654
Epoch #70: loss=0.013547782218822288
Epoch #71: loss=0.014469314160132033
Epoch #72: loss=0.012696451826712056
Epoch #73: loss=0.022886745129659738
Epoch #74: loss=0.01450997719650867
Epoch #75: loss=0.014710252754656556
Epoch #76: loss=0.017173290476567182
Epoch #77: loss=0.019245970219985534
Epoch #78: loss=0.01743267101786085
Epoch #79: loss=0.01996080919214724
Epoch #80: loss=0.014741551647440556
Epoch #81: loss=0.01761372168865683
Epoch #82: loss=0.01922362426766641
Epoch #83: loss=0.013385809267818315
Epoch #84: loss=0.014359888945306295
Epoch #85: loss=0.018505662771521426
Epoch #86: loss=0.016737823106857508
Epoch #87: loss=0.013704897018415835
Epoch #88: loss=0.012683891063404706
Epoch #89: loss=0.018644372122784972
Epoch #90: loss=0.01465283784394463
Epoch #91: loss=0.012593372476977975
Epoch #92: loss=0.011808191469031913
Epoch #93: loss=0.016982317584581408
Epoch #94: loss=0.012302172770727551
Epoch #95: loss=0.013505947696247685
Epoch #96: loss=0.015091520745072355
Epoch #97: loss=0.01578104436868943
Epoch #98: loss=0.01943905883369701
Epoch #99: loss=0.015364112697284233
Epoch #100: loss=0.011482209929127771
Epoch #101: loss=0.014000485706176976
Epoch #102: loss=0.014323331539362563
Epoch #103: loss=0.013997030241354338
Epoch #104: loss=0.014594183375922588
Epoch #105: loss=0.016309523420899738
Epoch #106: loss=0.01553659948313434
Epoch #107: loss=0.013029515468731146
Epoch #108: loss=0.013324207705590506
Epoch #109: loss=0.011672623889499358
Epoch #110: loss=0.01846239157019842
Epoch #111: loss=0.00891508327445488
Epoch #112: loss=0.010584103201556271
Epoch #113: loss=0.014164602432754433
Epoch #114: loss=0.010431437317919501
Epoch #115: loss=0.011013003318415334
Epoch #116: loss=0.015226560288710798
Epoch #117: loss=0.014484892993089084
Epoch #118: loss=0.0105086493125612
Epoch #119: loss=0.012553023576309979
Epoch #120: loss=0.013342991789783747
Epoch #121: loss=0.014633350747266155
Epoch #122: loss=0.015046525401069233
Epoch #123: loss=0.012448276389432406
Epoch #124: loss=0.010861303736338866
Epoch #125: loss=0.010257304901070305
Epoch #126: loss=0.011217404596874994
Epoch #127: loss=0.012932134657613987
Epoch #128: loss=0.012215133436184801
Epoch #129: loss=0.011212039346280669
Epoch #130: loss=0.013243910308519121
Epoch #131: loss=0.013853196541855198
Epoch #132: loss=0.01179729508236484
Epoch #133: loss=0.012107493221547203
Epoch #134: loss=0.011190167008267726
Epoch #135: loss=0.009676345827407395
Epoch #136: loss=0.011128482362301193
Epoch #137: loss=0.014434874111523997
Epoch #138: loss=0.01348154881977285
Epoch #139: loss=0.016810017297039775
Epoch #140: loss=0.012449491762978996
Epoch #141: loss=0.012025849472538193
Epoch #142: loss=0.012184846705544617
Epoch #143: loss=0.01150557484523668
Epoch #144: loss=0.009153186463576324
Epoch #145: loss=0.012313171389714543
Epoch #146: loss=0.016727969672962174
Epoch #147: loss=0.009536451541225913
Epoch #148: loss=0.009699449728411946
Epoch #149: loss=0.011896407816100156
Epoch #150: loss=0.01483061598062402
Epoch #151: loss=0.014105166838324502
Epoch #152: loss=0.011682349305581248
Epoch #153: loss=0.011167267032753949
Epoch #154: loss=0.0146305940520645
Epoch #155: loss=0.013902090039657701
Epoch #156: loss=0.00834697257744765
Epoch #157: loss=0.01372077064260315
Epoch #158: loss=0.01052849046142652
Epoch #159: loss=0.009935042788241907
Epoch #160: loss=0.019070987610359785
Epoch #161: loss=0.009110730147840723
Epoch #162: loss=0.01509496999969365
Epoch #163: loss=0.009108303339465933
Epoch #164: loss=0.012489104753379795
Epoch #165: loss=0.007818429793386854
Epoch #166: loss=0.012321144699720751
Epoch #167: loss=0.008985973582217017
Epoch #168: loss=0.013885811267787504
Epoch #169: loss=0.011271911857066549
Epoch #170: loss=0.010107453168194388
Epoch #171: loss=0.011464192265338177
Epoch #172: loss=0.011476516899603863
Epoch #173: loss=0.011262650045896922
Epoch #174: loss=0.0162083617053064
Epoch #175: loss=0.011389863614914527
Epoch #176: loss=0.008805499749515593
Epoch #177: loss=0.013133245234479172
Epoch #178: loss=0.008157087785911702
Epoch #179: loss=0.010170993299773879
Epoch #180: loss=0.011647450885599634
Epoch #181: loss=0.010395974451581887
Epoch #182: loss=0.011218732707485047
Epoch #183: loss=0.010136793130112086
Epoch #184: loss=0.007989666098748033
Epoch #185: loss=0.012621944484185748
Epoch #186: loss=0.01615936303247739
Epoch #187: loss=0.0145928350009822
Epoch #188: loss=0.010936946677395205
Epoch #189: loss=0.01074276025234006
Epoch #190: loss=0.012187431835609594
Epoch #191: loss=0.009498622437811981
Epoch #192: loss=0.014930854170050991
Epoch #193: loss=0.009868159115793914
Epoch #194: loss=0.010926117051003395
Epoch #195: loss=0.007503866209159682
Epoch #196: loss=0.012230713278447767
Epoch #197: loss=0.009716988120805218
Epoch #198: loss=0.015540526488133782
Epoch #199: loss=0.010238648082782123
Epoch #200: loss=0.011320423784903685
Epoch #201: loss=0.010088774240040356
Epoch #202: loss=0.011586780851105576
Epoch #203: loss=0.014213215013921863
Epoch #204: loss=0.01031618040889924
Epoch #205: loss=0.011379303479975515
Epoch #206: loss=0.008547296309792144
Epoch #207: loss=0.011990046997219894
Epoch #208: loss=0.011158259779633627
Epoch #209: loss=0.014854664414200733
Epoch #210: loss=0.010228489278329901
Epoch #211: loss=0.009687390192271737
Epoch #212: loss=0.008858529229405158
Epoch #213: loss=0.011279543317825325
Epoch #214: loss=0.009306085476544134
Epoch #215: loss=0.013508274724625256
Epoch #216: loss=0.010321698295392994
Epoch #217: loss=0.011903423563142675
Epoch #218: loss=0.008232123115132897
Epoch #219: loss=0.009974111171411342
Epoch #220: loss=0.0104045292053815
Epoch #221: loss=0.009041070821279777
Epoch #222: loss=0.010816937521921836
Epoch #223: loss=0.007864045578039821
Epoch #224: loss=0.010166701240108962
Epoch #225: loss=0.007346094075825658
Epoch #226: loss=0.012284503802518469
Epoch #227: loss=0.01178623799642293
Epoch #228: loss=0.014255141000224588
Epoch #229: loss=0.007920098575267315
Epoch #230: loss=0.009940784939553594
Epoch #231: loss=0.007950448005157273
Epoch #232: loss=0.009883211815698057
Epoch #233: loss=0.009491295118717817
Epoch #234: loss=0.008896092021274242
Epoch #235: loss=0.008765400668948571
Epoch #236: loss=0.013290803389223114
Epoch #237: loss=0.011428993163712022
Epoch #238: loss=0.008766065313774673
Epoch #239: loss=0.010447854834147357
Epoch #240: loss=0.010556376878570995
Epoch #241: loss=0.007551614329861074
Epoch #242: loss=0.009300310896329983
Epoch #243: loss=0.006774793986697171
Epoch #244: loss=0.013778159946725705
Epoch #245: loss=0.005321316932184524
Epoch #246: loss=0.0067418871170042815
Epoch #247: loss=0.011208041909566176
Epoch #248: loss=0.017876453022907073
Epoch #249: loss=0.008752320471762292

Training time: 15:11:24.822849

Finished.
n2one setting electricity_traffic_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/electricity_traffic_weather_epochs_250_seed_2021/model.pkl', muti_dataset='electricity_traffic_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.35541e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4387195325375661, 'MAE': 0.43218210700255855}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='electricity_traffic_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/electricity_traffic_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.8426937197407788
Epoch #1: loss=0.32108348509801926
Epoch #2: loss=0.21483306863245896
Epoch #3: loss=0.15728079217332036
Epoch #4: loss=0.12393033881394129
Epoch #5: loss=0.09488512294900257
Epoch #6: loss=0.08553938751244225
Epoch #7: loss=0.06919753738334145
Epoch #8: loss=0.06460742112976366
Epoch #9: loss=0.05842637394044289
Epoch #10: loss=0.05417906688987633
Epoch #11: loss=0.04776365075109481
Epoch #12: loss=0.04574558819725478
Epoch #13: loss=0.046538269280602236
Epoch #14: loss=0.04776853018191641
Epoch #15: loss=0.04542454859823627
Epoch #16: loss=0.03832496473808889
Epoch #17: loss=0.035875386591902196
Epoch #18: loss=0.03893300754967827
Epoch #19: loss=0.0543909268623795
Epoch #20: loss=0.0391404553872512
Epoch #21: loss=0.028894865156779272
Epoch #22: loss=0.031116236558111306
Epoch #23: loss=0.03013056415851806
Epoch #24: loss=0.03559449226611101
Epoch #25: loss=0.029395153020148102
Epoch #26: loss=0.030522561438120103
Epoch #27: loss=0.02986332805431194
Epoch #28: loss=0.026669821288283387
Epoch #29: loss=0.027505724145579256
Epoch #30: loss=0.025698627721732144
Epoch #31: loss=0.02775823389367481
Epoch #32: loss=0.02621191281969577
Epoch #33: loss=0.031993720501551436
Epoch #34: loss=0.02441188262241457
Epoch #35: loss=0.02434090235510819
Epoch #36: loss=0.020722757876259497
Epoch #37: loss=0.02293276724901745
Epoch #38: loss=0.023239821497392767
Epoch #39: loss=0.025299803012859633
Epoch #40: loss=0.023753894567954896
Epoch #41: loss=0.024559998651966453
Epoch #42: loss=0.021441478932858544
Epoch #43: loss=0.03417799803852569
Epoch #44: loss=0.021286462457877162
Epoch #45: loss=0.021623304388240505
Epoch #46: loss=0.01882161762828115
Epoch #47: loss=0.01879315359568662
Epoch #48: loss=0.021516496106446778
Epoch #49: loss=0.027608292359077958
Epoch #50: loss=0.018543672799593146
Epoch #51: loss=0.017543931588539143
Epoch #52: loss=0.019860115733036657
Epoch #53: loss=0.017321857705373728
Epoch #54: loss=0.023471293398005126
Epoch #55: loss=0.0175342224946904
Epoch #56: loss=0.0213188602318608
Epoch #57: loss=0.019511212711100286
Epoch #58: loss=0.022809383445313806
Epoch #59: loss=0.020730216751765777
Epoch #60: loss=0.01977596683695515
Epoch #61: loss=0.02292274642298991
Epoch #62: loss=0.014781503061822394
Epoch #63: loss=0.017831414577755084
Epoch #64: loss=0.01922716531280106
Epoch #65: loss=0.01607063708753199
Epoch #66: loss=0.01892407299594142
Epoch #67: loss=0.017609882913368593
Epoch #68: loss=0.03091650003595
Epoch #69: loss=0.017181698378628256
Epoch #70: loss=0.014864678640713435
Epoch #71: loss=0.017282585716746922
Epoch #72: loss=0.014621928482614364
Epoch #73: loss=0.017651852150191216
Epoch #74: loss=0.016468493797798547
Epoch #75: loss=0.020353031892992757
Epoch #76: loss=0.017782977962807398
Epoch #77: loss=0.017192931004314495
Epoch #78: loss=0.019690582890370054
Epoch #79: loss=0.014980607848505663
Epoch #80: loss=0.01899922349429916
Epoch #81: loss=0.019491587384941337
Epoch #82: loss=0.014207728386737707
Epoch #83: loss=0.0165597305791085
Epoch #84: loss=0.018552719979943032
Epoch #85: loss=0.013858507376771297
Epoch #86: loss=0.015549877362438586
Epoch #87: loss=0.015439046698713895
Epoch #88: loss=0.017741149501207636
Epoch #89: loss=0.024287521497177948
Epoch #90: loss=0.020313901239873155
Epoch #91: loss=0.011862270650869285
Epoch #92: loss=0.013212600254999532
Epoch #93: loss=0.014676897552383026
Epoch #94: loss=0.01237758568497445
Epoch #95: loss=0.01625285220541278
Epoch #96: loss=0.015059584124439217
Epoch #97: loss=0.013372945361491136
Epoch #98: loss=0.017182663871128056
Epoch #99: loss=0.017103324792303667
Epoch #100: loss=0.013230542270342548
Epoch #101: loss=0.014676159516642653
Epoch #102: loss=0.01630247402284297
Epoch #103: loss=0.013606882466385094
Epoch #104: loss=0.012988475122451696
Epoch #105: loss=0.01498267660137402
Epoch #106: loss=0.020811554148511126
Epoch #107: loss=0.012955922446873741
Epoch #108: loss=0.012685334954349602
Epoch #109: loss=0.019565525907123564
Epoch #110: loss=0.015055857659420675
Epoch #111: loss=0.017881551700322417
Epoch #112: loss=0.012370094007789567
Epoch #113: loss=0.01648686749267669
Epoch #114: loss=0.019575079873120755
Epoch #115: loss=0.011774048554893047
Epoch #116: loss=0.013059660979876205
Epoch #117: loss=0.012705290180160922
Epoch #118: loss=0.03012934337110289
Epoch #119: loss=0.013418718340183924
Epoch #120: loss=0.011898606911950254
Epoch #121: loss=0.01156678713984122
Epoch #122: loss=0.021502509433155455
Epoch #123: loss=0.02034418347339202
Epoch #124: loss=0.01791679287792827
Epoch #125: loss=0.014471085502834104
Epoch #126: loss=0.014457536940572363
Epoch #127: loss=0.0118255086101079
Epoch #128: loss=0.013028671881943467
Epoch #129: loss=0.012876141158767916
Epoch #130: loss=0.012659787099835236
Epoch #131: loss=0.013890637683254114
Epoch #132: loss=0.013103204668238744
Epoch #133: loss=0.013043282623050888
Epoch #134: loss=0.013019246123157857
Epoch #135: loss=0.014377851632659658
Epoch #136: loss=0.012607438244820692
Epoch #137: loss=0.01151369927165059
Epoch #138: loss=0.01342491360501864
Epoch #139: loss=0.014552094755430551
Epoch #140: loss=0.013410304367420507
Epoch #141: loss=0.01871072585758222
Epoch #142: loss=0.014099264324964889
Epoch #143: loss=0.0135643109829262
Epoch #144: loss=0.012527228393756154
Epoch #145: loss=0.00986733047719177
Epoch #146: loss=0.012391976736538546
Epoch #147: loss=0.014340011299060741
Epoch #148: loss=0.01329797335074316
Epoch #149: loss=0.010852948088396543
Epoch #150: loss=0.01174055420844714
Epoch #151: loss=0.018245726698349948
Epoch #152: loss=0.012352224157214686
Epoch #153: loss=0.012236995798824778
Epoch #154: loss=0.010419689711629715
Epoch #155: loss=0.009721889748918045
Epoch #156: loss=0.012402017113208519
Epoch #157: loss=0.023203431574444384
Epoch #158: loss=0.011633042847875688
Epoch #159: loss=0.013823441174644199
Epoch #160: loss=0.01272061045385102
Epoch #161: loss=0.012008623855643398
Epoch #162: loss=0.012790579438978088
Epoch #163: loss=0.011871025879821629
Epoch #164: loss=0.011760291129822872
Epoch #165: loss=0.020695841086864758
Epoch #166: loss=0.009879216940955851
Epoch #167: loss=0.009971074059577471
Epoch #168: loss=0.015845779888327003
Epoch #169: loss=0.01232101700561337
Epoch #170: loss=0.014767682428901727
Epoch #171: loss=0.010599673507251486
Epoch #172: loss=0.012849297215100077
Epoch #173: loss=0.010136075355504025
Epoch #174: loss=0.010764948584942428
Epoch #175: loss=0.010554882757642617
Epoch #176: loss=0.0104760473702714
Epoch #177: loss=0.011020633317523069
Epoch #178: loss=0.013642287444750377
Epoch #179: loss=0.008863153783178819
Epoch #180: loss=0.011237583503476638
Epoch #181: loss=0.010163283185738616
Epoch #182: loss=0.01123550503855498
Epoch #183: loss=0.009448868044905988
Epoch #184: loss=0.011657780807642822
Epoch #185: loss=0.011965032868253655
Epoch #186: loss=0.011755030532633885
Epoch #187: loss=0.011429154699585987
Epoch #188: loss=0.011619827790365857
Epoch #189: loss=0.010352924281569838
Epoch #190: loss=0.012957186221648386
Epoch #191: loss=0.013026725631434975
Epoch #192: loss=0.01200485030649002
Epoch #193: loss=0.013161851322778056
Epoch #194: loss=0.012945841364566422
Epoch #195: loss=0.012712036476590366
Epoch #196: loss=0.011847913514577965
Epoch #197: loss=0.016067290668185966
Epoch #198: loss=0.011829213277165743
Epoch #199: loss=0.009043373416730095
Epoch #200: loss=0.010882339808421513
Epoch #201: loss=0.011215057730114464
Epoch #202: loss=0.009722126345990787
Epoch #203: loss=0.020302478572026564
Epoch #204: loss=0.010944826139853528
Epoch #205: loss=0.010572963040164694
Epoch #206: loss=0.011670547752314377
Epoch #207: loss=0.014815162986606487
Epoch #208: loss=0.01077702673515997
Epoch #209: loss=0.008579104547306256
Epoch #210: loss=0.010266368089332328
Epoch #211: loss=0.013220499182487197
Epoch #212: loss=0.013634914911985393
Epoch #213: loss=0.008937218316589654
Epoch #214: loss=0.012107420705109687
Epoch #215: loss=0.01075032973823495
Epoch #216: loss=0.00783496707219462
Epoch #217: loss=0.014115480071835015
Epoch #218: loss=0.013587291245394692
Epoch #219: loss=0.011274226331893913
Epoch #220: loss=0.0127637858964807
Epoch #221: loss=0.011316660322272102
Epoch #222: loss=0.00948997940687065
Epoch #223: loss=0.011476161163492347
Epoch #224: loss=0.009414798787355738
Epoch #225: loss=0.011604986880404136
Epoch #226: loss=0.010898341217798558
Epoch #227: loss=0.011441683200574555
Epoch #228: loss=0.008737655973363857
Epoch #229: loss=0.010753579414173906
Epoch #230: loss=0.01064260343828805
Epoch #231: loss=0.011618836140719017
Epoch #232: loss=0.010917974967463762
Epoch #233: loss=0.01008902062519188
Epoch #234: loss=0.012532565487119555
Epoch #235: loss=0.014580127585526417
Epoch #236: loss=0.009485855234158264
Epoch #237: loss=0.0116891897811371
Epoch #238: loss=0.008929500213742008
Epoch #239: loss=0.010110476117517203
Epoch #240: loss=0.009220376842548015
Epoch #241: loss=0.012316674794016467
Epoch #242: loss=0.01133936967847925
Epoch #243: loss=0.015290304764994404
Epoch #244: loss=0.010936630618682929
Epoch #245: loss=0.00840323993642858
Epoch #246: loss=0.01003046965241535
Epoch #247: loss=0.010944446365191722
Epoch #248: loss=0.010860277120645434
Epoch #249: loss=0.01070280595976581

Training time: 14:50:34.040941

Finished.
n2one setting electricity_traffic_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/electricity_traffic_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='electricity_traffic_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.8522e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.80673e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.5225730612053027, 'MAE': 0.5509504494841664}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='electricity_weather_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/electricity_weather_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.69244524744195
Epoch #1: loss=0.864055057226772
Epoch #2: loss=0.6002131131333365
Epoch #3: loss=0.5083699892944014
Epoch #4: loss=0.4315770742339148
Epoch #5: loss=0.38647749470153325
Epoch #6: loss=0.3518954576321051
Epoch #7: loss=0.3124795973300934
Epoch #8: loss=0.2951415807428494
Epoch #9: loss=0.27453162426679906
Epoch #10: loss=0.25663349026105775
Epoch #11: loss=0.23311430310279552
Epoch #12: loss=0.2441717116765573
Epoch #13: loss=0.2049216452933533
Epoch #14: loss=0.19841029811912858
Epoch #15: loss=0.15716508806381427
Epoch #16: loss=0.15955318559853124
Epoch #17: loss=0.13941668160784412
Epoch #18: loss=0.14010161898610457
Epoch #19: loss=0.1373337450581537
Epoch #20: loss=0.12903834688936322
Epoch #21: loss=0.12560046149916212
Epoch #22: loss=0.10626424060426128
Epoch #23: loss=0.10432905465574331
Epoch #24: loss=0.12109354626072544
Epoch #25: loss=0.09258123390429036
Epoch #26: loss=0.08810423202287983
Epoch #27: loss=0.102155330731258
Epoch #28: loss=0.09800066259282995
Epoch #29: loss=0.09012094410136343
Epoch #30: loss=0.0873150725927676
Epoch #31: loss=0.07444131045772785
Epoch #32: loss=0.07481546174393783
Epoch #33: loss=0.07389760418388415
Epoch #34: loss=0.09547158516943455
Epoch #35: loss=0.07021115560766676
Epoch #36: loss=0.06898808760411093
Epoch #37: loss=0.060738491727380266
Epoch #38: loss=0.06513929927301869
Epoch #39: loss=0.06010405961948801
Epoch #40: loss=0.06271733507304124
Epoch #41: loss=0.07334769912273952
Epoch #42: loss=0.07060402826025662
Epoch #43: loss=0.05755562254253932
Epoch #44: loss=0.05898524075484192
Epoch #45: loss=0.04285669875803443
Epoch #46: loss=0.04795398588659583
Epoch #47: loss=0.05425028240203228
Epoch #48: loss=0.047291052628728285
Epoch #49: loss=0.05219557055101638
Epoch #50: loss=0.04195350081738557
Epoch #51: loss=0.0717861088720793
Epoch #52: loss=0.05474472076789489
Epoch #53: loss=0.051427923209807824
Epoch #54: loss=0.046811021706679654
Epoch #55: loss=0.04318601823949688
Epoch #56: loss=0.042855847220618644
Epoch #57: loss=0.03543686392835119
Epoch #58: loss=0.09101570920205453
Epoch #59: loss=0.05859687560185475
Epoch #60: loss=0.040055822169827955
Epoch #61: loss=0.03911881715085515
Epoch #62: loss=0.050890786146653266
Epoch #63: loss=0.034818505834866786
Epoch #64: loss=0.03663872615827746
Epoch #65: loss=0.04967721718507753
Epoch #66: loss=0.05902576546945517
Epoch #67: loss=0.04157617079769589
Epoch #68: loss=0.03106566583803317
Epoch #69: loss=0.029732712662883732
Epoch #70: loss=0.03017818624183247
Epoch #71: loss=0.03204488402534224
Epoch #72: loss=0.03564211642435214
Epoch #73: loss=0.03735890815749397
Epoch #74: loss=0.04080084323830588
Epoch #75: loss=0.0329915909208095
Epoch #76: loss=0.03833937929143053
Epoch #77: loss=0.04912957850463268
Epoch #78: loss=0.03143785593795105
Epoch #79: loss=0.034304788497827525
Epoch #80: loss=0.045636037781729664
Epoch #81: loss=0.04173300720252831
Epoch #82: loss=0.0610696957266273
Epoch #83: loss=0.03818022137324155
Epoch #84: loss=0.03555582206086321
Epoch #85: loss=0.04723273457657598
Epoch #86: loss=0.030583608710915373
Epoch #87: loss=0.02469629369115352
Epoch #88: loss=0.026487199556981016
Epoch #89: loss=0.03218744234542664
Epoch #90: loss=0.033479234954329126
Epoch #91: loss=0.02830733022403339
Epoch #92: loss=0.03968144118077528
Epoch #93: loss=0.025385720274758748
Epoch #94: loss=0.026349775659733676
Epoch #95: loss=0.02714990589793929
Epoch #96: loss=0.03800158911994593
Epoch #97: loss=0.03350166962646001
Epoch #98: loss=0.0447921288094785
Epoch #99: loss=0.03127521670974371
Epoch #100: loss=0.03113256266511137
Epoch #101: loss=0.029800845431262286
Epoch #102: loss=0.04067709794674646
Epoch #103: loss=0.03171816867199057
Epoch #104: loss=0.059689468313926755
Epoch #105: loss=0.030202103250751823
Epoch #106: loss=0.02851239863953645
Epoch #107: loss=0.03590245505050481
Epoch #108: loss=0.027981104623382047
Epoch #109: loss=0.02677021601325898
Epoch #110: loss=0.027200548580362343
Epoch #111: loss=0.029670845783761585
Epoch #112: loss=0.020226559363974547
Epoch #113: loss=0.022295408023514745
Epoch #114: loss=0.018706976124216658
Epoch #115: loss=0.029858731398765576
Epoch #116: loss=0.022704685110152816
Epoch #117: loss=0.048041291926121735
Epoch #118: loss=0.025080522111925282
Epoch #119: loss=0.022028168198705036
Epoch #120: loss=0.027067348098670934
Epoch #121: loss=0.026497678771208396
Epoch #122: loss=0.03320611621758205
Epoch #123: loss=0.030943058792199992
Epoch #124: loss=0.03013623986839199
Epoch #125: loss=0.03822475022597002
Epoch #126: loss=0.02204902419692535
Epoch #127: loss=0.034523159861531844
Epoch #128: loss=0.03111426041782899
Epoch #129: loss=0.03567044315777693
Epoch #130: loss=0.024187402828255485
Epoch #131: loss=0.024576363702055435
Epoch #132: loss=0.018803558660618645
Epoch #133: loss=0.01832502808956377
Epoch #134: loss=0.021750461627420982
Epoch #135: loss=0.028136751866361626
Epoch #136: loss=0.025579394167781034
Epoch #137: loss=0.024074948871586944
Epoch #138: loss=0.021509419108288443
Epoch #139: loss=0.021230872442722846
Epoch #140: loss=0.020212326873041375
Epoch #141: loss=0.03061928636112421
Epoch #142: loss=0.031062929130579068
Epoch #143: loss=0.027607282508872975
Epoch #144: loss=0.02636562385596335
Epoch #145: loss=0.02025050120444601
Epoch #146: loss=0.018796534744963626
Epoch #147: loss=0.036946598042792995
Epoch #148: loss=0.037892640387626284
Epoch #149: loss=0.024215308612894636
Epoch #150: loss=0.03827488281072157
Epoch #151: loss=0.05258103943623366
Epoch #152: loss=0.024572336776542778
Epoch #153: loss=0.03392947569463245
Epoch #154: loss=0.025244472109266676
Epoch #155: loss=0.02267792940477539
Epoch #156: loss=0.02500347694755912
Epoch #157: loss=0.026657029597455976
Epoch #158: loss=0.017653907946815952
Epoch #159: loss=0.022565430644112573
Epoch #160: loss=0.019553755912077152
Epoch #161: loss=0.029585255455212588
Epoch #162: loss=0.02251309507598602
Epoch #163: loss=0.020670191845594262
Epoch #164: loss=0.01869420187636344
Epoch #165: loss=0.04836287683549888
Epoch #166: loss=0.02293012615483464
Epoch #167: loss=0.019570525355217323
Epoch #168: loss=0.018525355245957387
Epoch #169: loss=0.018080164351448103
Epoch #170: loss=0.019291394854679338
Epoch #171: loss=0.018120078419164663
Epoch #172: loss=0.020478553966697777
Epoch #173: loss=0.028448876190740404
Epoch #174: loss=0.02552216900955282
Epoch #175: loss=0.05063547028431958
Epoch #176: loss=0.022083017422857
Epoch #177: loss=0.02122401478634754
Epoch #178: loss=0.02245600119324952
Epoch #179: loss=0.023755268486295368
Epoch #180: loss=0.016208297965562786
Epoch #181: loss=0.027692452961132978
Epoch #182: loss=0.022928832864723313
Epoch #183: loss=0.023201635670454673
Epoch #184: loss=0.021623807706506137
Epoch #185: loss=0.05142855590429078
Epoch #186: loss=0.026595684335547383
Epoch #187: loss=0.02500751064631196
Epoch #188: loss=0.019487688276493713
Epoch #189: loss=0.018239044294689297
Epoch #190: loss=0.015986333120676596
Epoch #191: loss=0.020121500435987042
Epoch #192: loss=0.018927233569278105
Epoch #193: loss=0.023868780422949192
Epoch #194: loss=0.023827697796432276
Epoch #195: loss=0.02275497890003747
Epoch #196: loss=0.028598624900717972
Epoch #197: loss=0.01755226711614687
Epoch #198: loss=0.01701707797629995
Epoch #199: loss=0.017343455820318154
Epoch #200: loss=0.0227006348991983
Epoch #201: loss=0.029716123683168224
Epoch #202: loss=0.030643936946273216
Epoch #203: loss=0.019161497202905182
Epoch #204: loss=0.017708034794384115
Epoch #205: loss=0.016848507169125813
Epoch #206: loss=0.013936295056130251
Epoch #207: loss=0.01931030530528441
Epoch #208: loss=0.011576630692915913
Epoch #209: loss=0.016688784598176118
Epoch #210: loss=0.02617311075110067
Epoch #211: loss=0.027222461590189224
Epoch #212: loss=0.041161462030878525
Epoch #213: loss=0.032879792703446785
Epoch #214: loss=0.023578080600029198
Epoch #215: loss=0.017351413211575382
Epoch #216: loss=0.01811779458584054
Epoch #217: loss=0.026287747124000123
Epoch #218: loss=0.020531009799558145
Epoch #219: loss=0.023458855490292044
Epoch #220: loss=0.022388790986946665
Epoch #221: loss=0.023381480190437287
Epoch #222: loss=0.019740145911403578
Epoch #223: loss=0.015048734107363024
Epoch #224: loss=0.020423462908570722
Epoch #225: loss=0.023536586987828626
Epoch #226: loss=0.021651786279989222
Epoch #227: loss=0.013112411527766545
Epoch #228: loss=0.019005757368097582
Epoch #229: loss=0.026216265436960384
Epoch #230: loss=0.021346492844496027
Epoch #231: loss=0.023675711502970365
Epoch #232: loss=0.021296928014153692
Epoch #233: loss=0.019041505081802083
Epoch #234: loss=0.022303131410957012
Epoch #235: loss=0.016406493971753918
Epoch #236: loss=0.01291302929215894
Epoch #237: loss=0.01815263987354882
Epoch #238: loss=0.026840576380786393
Epoch #239: loss=0.016802153853752035
Epoch #240: loss=0.02038156547170447
Epoch #241: loss=0.019431884156074376
Epoch #242: loss=0.01875130871825681
Epoch #243: loss=0.02540949162564726
Epoch #244: loss=0.02261898879988224
Epoch #245: loss=0.016819492487636933
Epoch #246: loss=0.02078368158258406
Epoch #247: loss=0.013996116891437748
Epoch #248: loss=0.013204704716467154
Epoch #249: loss=0.015701519103776533

Training time: 4:56:26.437273

Finished.
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='traffic_weather_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/traffic_weather_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.1033224959059484
Epoch #1: loss=0.45734835096767973
Epoch #2: loss=0.3240085781934405
Epoch #3: loss=0.24631567688525788
Epoch #4: loss=0.20459345353966846
Epoch #5: loss=0.17646404628093088
Epoch #6: loss=0.15171200041160254
Epoch #7: loss=0.13843495515175164
Epoch #8: loss=0.12231348897330463
Epoch #9: loss=0.10172084298808061
Epoch #10: loss=0.08646862468802803
Epoch #11: loss=0.08977003005462134
Epoch #12: loss=0.08881704007736906
Epoch #13: loss=0.0742698129898989
Epoch #14: loss=0.06288532062535523
Epoch #15: loss=0.07226305828329974
Epoch #16: loss=0.06674763636017035
Epoch #17: loss=0.061231380611258955
Epoch #18: loss=0.056295932912429895
Epoch #19: loss=0.06587773385451458
Epoch #20: loss=0.04721456860092336
Epoch #21: loss=0.055431881592344974
Epoch #22: loss=0.05214041259413144
Epoch #23: loss=0.04338006182466155
Epoch #24: loss=0.0483802730914249
Epoch #25: loss=0.04399528562212903
Epoch #26: loss=0.03932618610490733
Epoch #27: loss=0.040091044111769794
Epoch #28: loss=0.0363902622507989
Epoch #29: loss=0.04378986674315196
Epoch #30: loss=0.03617391569774294
Epoch #31: loss=0.03762696190681579
Epoch #32: loss=0.04167901306949976
Epoch #33: loss=0.03090535557495449
Epoch #34: loss=0.04667679088340394
Epoch #35: loss=0.029559098463128715
Epoch #36: loss=0.03117107325540149
Epoch #37: loss=0.027524017200318798
Epoch #38: loss=0.02963916953727416
Epoch #39: loss=0.032935978639735755
Epoch #40: loss=0.03694754398397241
Epoch #41: loss=0.032577777967682256
Epoch #42: loss=0.025373488511637073
Epoch #43: loss=0.025714023321078066
Epoch #44: loss=0.03596337289413246
Epoch #45: loss=0.028170276347866872
Epoch #46: loss=0.031214799913414026
Epoch #47: loss=0.03434873393669997
Epoch #48: loss=0.028079439736757195
Epoch #49: loss=0.02741002760655777
Epoch #50: loss=0.03684981041981571
Epoch #51: loss=0.023194061001082185
Epoch #52: loss=0.027936473597102513
Epoch #53: loss=0.02745712061355984
Epoch #54: loss=0.027474034730663073
Epoch #55: loss=0.03201806126240366
Epoch #56: loss=0.026553940361671784
Epoch #57: loss=0.01902479581219398
Epoch #58: loss=0.035136599885650606
Epoch #59: loss=0.02767583228731902
Epoch #60: loss=0.022214738877989606
Epoch #61: loss=0.025840880875096315
Epoch #62: loss=0.01970539721579761
Epoch #63: loss=0.02267296079636643
Epoch #64: loss=0.031354683561598255
Epoch #65: loss=0.020257710824028306
Epoch #66: loss=0.018636663960478472
Epoch #67: loss=0.026042360961063032
Epoch #68: loss=0.02581462129234881
Epoch #69: loss=0.021313228076061414
Epoch #70: loss=0.01918073260454938
Epoch #71: loss=0.024969090325352487
Epoch #72: loss=0.02123066846336639
Epoch #73: loss=0.03201889762898905
Epoch #74: loss=0.02230108578149676
Epoch #75: loss=0.034406304995331184
Epoch #76: loss=0.01758182923107857
Epoch #77: loss=0.02447071117428225
Epoch #78: loss=0.025576395141147908
Epoch #79: loss=0.025367561388975446
Epoch #80: loss=0.023744554856583427
Epoch #81: loss=0.023246114548133585
Epoch #82: loss=0.0235915585883179
Epoch #83: loss=0.018821410995022752
Epoch #84: loss=0.027959111422920353
Epoch #85: loss=0.024774468768457934
Epoch #86: loss=0.02042181120668829
Epoch #87: loss=0.021773474131967823
Epoch #88: loss=0.027650276998217902
Epoch #89: loss=0.023422366442998412
Epoch #90: loss=0.017290007000968086
Epoch #91: loss=0.018188556218904393
Epoch #92: loss=0.020688238131827217
Epoch #93: loss=0.013582831459513858
Epoch #94: loss=0.01796524407135231
Epoch #95: loss=0.030554912678975858
Epoch #96: loss=0.01816166754094541
Epoch #97: loss=0.017336704852985867
Epoch #98: loss=0.022701781039618903
Epoch #99: loss=0.013664511418028269
Epoch #100: loss=0.025955092267979905
Epoch #101: loss=0.042928209809620706
Epoch #102: loss=0.02046902851212248
Epoch #103: loss=0.01822490885963037
Epoch #104: loss=0.01703979467976881
Epoch #105: loss=0.019257140170598826
Epoch #106: loss=0.016439687440879425
Epoch #107: loss=0.0198473582947502
Epoch #108: loss=0.021722502367993002
Epoch #109: loss=0.013458210177662164
Epoch #110: loss=0.014962867343326382
Epoch #111: loss=0.018814146393489346
Epoch #112: loss=0.02308019510493458
Epoch #113: loss=0.014328025256418186
Epoch #114: loss=0.02086244249617916
Epoch #115: loss=0.019200399478969694
Epoch #116: loss=0.018555498381309526
Epoch #117: loss=0.0248427527390699
Epoch #118: loss=0.01581490400115269
Epoch #119: loss=0.018498110901288913
Epoch #120: loss=0.01733741885225624
Epoch #121: loss=0.023572992166561692
Epoch #122: loss=0.017257817964913817
Epoch #123: loss=0.01866046894604421
Epoch #124: loss=0.01580612271436621
Epoch #125: loss=0.01335324668532069
Epoch #126: loss=0.02121208431841686
Epoch #127: loss=0.015913460120438167
Epoch #128: loss=0.019716487561221845
Epoch #129: loss=0.015046433953192004
Epoch #130: loss=0.025937578239466217
Epoch #131: loss=0.029282839997709482
Epoch #132: loss=0.014169429751453728
Epoch #133: loss=0.015139453576369175
Epoch #134: loss=0.017295433138640095
Epoch #135: loss=0.022688759300405894
Epoch #136: loss=0.01620384376464504
Epoch #137: loss=0.012969797928787687
Epoch #138: loss=0.016736067686971574
Epoch #139: loss=0.01788170215023196
Epoch #140: loss=0.02666323869997151
Epoch #141: loss=0.015246390277525279
Epoch #142: loss=0.01938852000180954
Epoch #143: loss=0.0139240261039179
Epoch #144: loss=0.016394679782868998
Epoch #145: loss=0.018008523253570274
Epoch #146: loss=0.01596237150722248
Epoch #147: loss=0.015514805164636008
Epoch #148: loss=0.017203994090290768
Epoch #149: loss=0.012527757560746977
Epoch #150: loss=0.016897622338677008
Epoch #151: loss=0.014860454870927242
Epoch #152: loss=0.019386148743868552
Epoch #153: loss=0.017077577877379162
Epoch #154: loss=0.014205438468707143
Epoch #155: loss=0.017065820262489848
Epoch #156: loss=0.020409106076385797
Epoch #157: loss=0.01882879289876525
Epoch #158: loss=0.020941528275540935
Epoch #159: loss=0.0193721173007069
Epoch #160: loss=0.02182892746863477
Epoch #161: loss=0.01584212762155143
Epoch #162: loss=0.016698450593399423
Epoch #163: loss=0.013642683104632982
Epoch #164: loss=0.015283347574706698
Epoch #165: loss=0.02207159911037187
Epoch #166: loss=0.013318407704835928
Epoch #167: loss=0.012858305969367783
Epoch #168: loss=0.01288431313464246
Epoch #169: loss=0.012348007884920012
Epoch #170: loss=0.01798448985399708
Epoch #171: loss=0.02245823358371776
Epoch #172: loss=0.016095874449693577
Epoch #173: loss=0.014314014601463245
Epoch #174: loss=0.015689973936624874
Epoch #175: loss=0.01270736778990665
Epoch #176: loss=0.01783557483850018
Epoch #177: loss=0.01247214657301551
Epoch #178: loss=0.015264638018639485
Epoch #179: loss=0.01201349702016939
Epoch #180: loss=0.014317762425727259
Epoch #181: loss=0.016193947071997172
Epoch #182: loss=0.01884648575657723
Epoch #183: loss=0.0170356244416975
Epoch #184: loss=0.01424222036725301
Epoch #185: loss=0.00964583780884303
Epoch #186: loss=0.01317131798326646
Epoch #187: loss=0.012416037005648053
Epoch #188: loss=0.014349574451525118
Epoch #189: loss=0.01422757735999117
Epoch #190: loss=0.014160975487396652
Epoch #191: loss=0.011990207147635244
Epoch #192: loss=0.020014298621650335
Epoch #193: loss=0.017101901654362855
Epoch #194: loss=0.012501030422916821
Epoch #195: loss=0.01622154402904893
Epoch #196: loss=0.010037772790659412
Epoch #197: loss=0.014371288350941671
Epoch #198: loss=0.01586000452029371
Epoch #199: loss=0.021131826496473747
Epoch #200: loss=0.012791385276809055
Epoch #201: loss=0.011597424222990023
Epoch #202: loss=0.016178280069376733
Epoch #203: loss=0.016582524173463144
Epoch #204: loss=0.014492679616653601
Epoch #205: loss=0.025035198274606176
Epoch #206: loss=0.011730007074837496
Epoch #207: loss=0.013275193390264966
Epoch #208: loss=0.015245157813199382
Epoch #209: loss=0.01826541369460496
Epoch #210: loss=0.0158333023248198
Epoch #211: loss=0.017724201475305432
Epoch #212: loss=0.01218601502716865
Epoch #213: loss=0.0152841936008729
Epoch #214: loss=0.01245186134290829
Epoch #215: loss=0.016914621010982955
Epoch #216: loss=0.013811443238507439
Epoch #217: loss=0.011450188221559441
Epoch #218: loss=0.011577686092610102
Epoch #219: loss=0.01514087588611801
Epoch #220: loss=0.0159571352085095
Epoch #221: loss=0.011299672455486132
Epoch #222: loss=0.014973347980717986
Epoch #223: loss=0.019574011410181162
Epoch #224: loss=0.020832758291622407
Epoch #225: loss=0.012558417161228266
Epoch #226: loss=0.012330464861812678
Epoch #227: loss=0.019860296743217987
Epoch #228: loss=0.010937549355373579
Epoch #229: loss=0.013496062687831259
Epoch #230: loss=0.016939480272429006
Epoch #231: loss=0.011961649422541345
Epoch #232: loss=0.01924478696033865
Epoch #233: loss=0.018287606520825
Epoch #234: loss=0.019667419788610068
Epoch #235: loss=0.013948381725153272
Epoch #236: loss=0.010626998228904736
Epoch #237: loss=0.016917445147750447
Epoch #238: loss=0.013347435185502425
Epoch #239: loss=0.011980773603892
Epoch #240: loss=0.015518755921935476
Epoch #241: loss=0.017900385884965026
Epoch #242: loss=0.02393273156310118
Epoch #243: loss=0.01154477452230042
Epoch #244: loss=0.012563750427414025
Epoch #245: loss=0.013429546808051132
Epoch #246: loss=0.014509394132606499
Epoch #247: loss=0.011417068152614515
Epoch #248: loss=0.016684198139971938
Epoch #249: loss=0.01661308512094755

Training time: 10:39:55.929826

Finished.
n2one setting traffic_weather_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/traffic_weather_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='traffic_weather_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.21809e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.44841e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.21809e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3923641650459645, 'MAE': 0.44567224016949136}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_ettm1', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_ettm1_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=4.2607597064971925
Epoch #1: loss=2.4229726505279543
Epoch #2: loss=2.155551257133484
Epoch #3: loss=1.9429883289337158
Epoch #4: loss=1.7618259477615357
Epoch #5: loss=1.583054690361023
Epoch #6: loss=1.4359734535217286
Epoch #7: loss=1.442490029335022
Epoch #8: loss=1.2564763951301574
Epoch #9: loss=1.133346996307373
Epoch #10: loss=1.1905584192276002
Epoch #11: loss=1.1840402722358703
Epoch #12: loss=1.0687598133087157
Epoch #13: loss=0.9376365637779236
Epoch #14: loss=0.9872941136360168
Epoch #15: loss=1.025833420753479
Epoch #16: loss=0.8935749411582947
Epoch #17: loss=0.8519918870925903
Epoch #18: loss=0.7594310355186462
Epoch #19: loss=0.7106241869926453
Epoch #20: loss=0.7721718072891235
Epoch #21: loss=0.7610174071788788
Epoch #22: loss=0.9046423125267029
Epoch #23: loss=0.8057315754890442
Epoch #24: loss=0.8161511921882629
Epoch #25: loss=0.7669710206985474
Epoch #26: loss=0.6614326918125153
Epoch #27: loss=0.6598319554328919
Epoch #28: loss=0.668221150636673
Epoch #29: loss=0.6097485816478729
Epoch #30: loss=0.5670584273338318
Epoch #31: loss=0.6434032511711121
Epoch #32: loss=0.6325037431716919
Epoch #33: loss=0.5587865614891052
Epoch #34: loss=0.5934277284145355
Epoch #35: loss=0.5838560330867767
Epoch #36: loss=0.5896032929420472
Epoch #37: loss=0.5097227132320404
Epoch #38: loss=0.5573837184906005
Epoch #39: loss=0.5178857743740082
Epoch #40: loss=0.5110543489456176
Epoch #41: loss=0.5322319877147674
Epoch #42: loss=0.5302001500129699
Epoch #43: loss=0.5041364371776581
Epoch #44: loss=0.5923204231262207
Epoch #45: loss=0.6369199395179749
Epoch #46: loss=0.45095799803733827
Epoch #47: loss=0.5668826842308045
Epoch #48: loss=0.44334675192832945
Epoch #49: loss=0.519927613735199
Epoch #50: loss=0.4009095072746277
Epoch #51: loss=0.379357253909111
Epoch #52: loss=0.42820749402046204
Epoch #53: loss=0.3816136169433594
Epoch #54: loss=0.42126489520072935
Epoch #55: loss=0.34132222056388856
Epoch #56: loss=0.35203135788440704
Epoch #57: loss=0.3813777667284012
Epoch #58: loss=0.4897686839103699
Epoch #59: loss=0.39637566268444063
Epoch #60: loss=0.3520402193069458
Epoch #61: loss=0.38041747093200684
Epoch #62: loss=0.3589361214637756
Epoch #63: loss=0.4122336745262146
Epoch #64: loss=0.5771090281009674
Epoch #65: loss=0.41117323517799376
Epoch #66: loss=0.36986860692501067
Epoch #67: loss=0.3831933706998825
Epoch #68: loss=0.3847373604774475
Epoch #69: loss=0.33537176430225374
Epoch #70: loss=0.3188855504989624
Epoch #71: loss=0.3401901775598526
Epoch #72: loss=0.35028808176517484
Epoch #73: loss=0.3015528744459152
Epoch #74: loss=0.285565704703331
Epoch #75: loss=0.3030892151594162
Epoch #76: loss=0.3884374612569809
Epoch #77: loss=0.3161960399150848
Epoch #78: loss=0.33699882626533506
Epoch #79: loss=0.3242683506011963
Epoch #80: loss=0.32224214494228365
Epoch #81: loss=0.4096441465616226
Epoch #82: loss=0.30730012357234954
Epoch #83: loss=0.3001004719734192
Epoch #84: loss=0.2932403266429901
Epoch #85: loss=0.28052105724811555
Epoch #86: loss=0.26875455141067506
Epoch #87: loss=0.23493496537208558
Epoch #88: loss=0.23262887179851532
Epoch #89: loss=0.27314238727092743
Epoch #90: loss=0.2828547567129135
Epoch #91: loss=0.24640704512596132
Epoch #92: loss=0.35459028333425524
Epoch #93: loss=0.3297521495819092
Epoch #94: loss=0.2904640769958496
Epoch #95: loss=0.25770627081394193
Epoch #96: loss=0.24293913573026657
Epoch #97: loss=0.2580361631512642
Epoch #98: loss=0.3631748330593109
Epoch #99: loss=0.28045895993709563
Epoch #100: loss=0.2418648213148117
Epoch #101: loss=0.23637096285820008
Epoch #102: loss=0.21905613243579863
Epoch #103: loss=0.23858128041028975
Epoch #104: loss=0.2507328182458878
Epoch #105: loss=0.2025110214948654
Epoch #106: loss=0.2509558907151222
Epoch #107: loss=0.2339450615644455
Epoch #108: loss=0.21667927920818328
Epoch #109: loss=0.22038665890693665
Epoch #110: loss=0.19445256263017655
Epoch #111: loss=0.19774796009063722
Epoch #112: loss=0.1938719269633293
Epoch #113: loss=0.233092240691185
Epoch #114: loss=0.20934515625238417
Epoch #115: loss=0.25453951239585876
Epoch #116: loss=0.24090653032064438
Epoch #117: loss=0.23070412188768386
Epoch #118: loss=0.2060766839981079
Epoch #119: loss=0.21423025906085968
Epoch #120: loss=0.2459613287448883
Epoch #121: loss=0.2334768083691597
Epoch #122: loss=0.21494616240262984
Epoch #123: loss=0.18729366838932038
Epoch #124: loss=0.18597440600395201
Epoch #125: loss=0.25136534333229066
Epoch #126: loss=0.189160638153553
Epoch #127: loss=0.1872456881403923
Epoch #128: loss=0.18556890577077867
Epoch #129: loss=0.19479622393846513
Epoch #130: loss=0.18199322164058684
Epoch #131: loss=0.15044472217559815
Epoch #132: loss=0.14906864494085312
Epoch #133: loss=0.13366431921720504
Epoch #134: loss=0.1853059047460556
Epoch #135: loss=0.19954393118619917
Epoch #136: loss=0.19749993503093718
Epoch #137: loss=0.15023389786481858
Epoch #138: loss=0.2022591334581375
Epoch #139: loss=0.17557525485754014
Epoch #140: loss=0.14448614299297333
Epoch #141: loss=0.15355246156454086
Epoch #142: loss=0.1438819944858551
Epoch #143: loss=0.14098218500614165
Epoch #144: loss=0.15120330691337586
Epoch #145: loss=0.16476529091596603
Epoch #146: loss=0.24688321620225906
Epoch #147: loss=0.141354059278965
Epoch #148: loss=0.17947954595088958
Epoch #149: loss=0.1828024785220623
Epoch #150: loss=0.1239108669757843
Epoch #151: loss=0.16567978084087373
Epoch #152: loss=0.1573759400844574
Epoch #153: loss=0.10538419634103775
Epoch #154: loss=0.10926212474703789
Epoch #155: loss=0.14372867450118065
Epoch #156: loss=0.15387278482317923
Epoch #157: loss=0.15368761420249938
Epoch #158: loss=0.23296103090047837
Epoch #159: loss=0.1385885915160179
Epoch #160: loss=0.16431925654411317
Epoch #161: loss=0.13358497455716134
Epoch #162: loss=0.12225992396473885
Epoch #163: loss=0.10525720328092575
Epoch #164: loss=0.1362146556377411
Epoch #165: loss=0.11323028087615966
Epoch #166: loss=0.13569552317261696
Epoch #167: loss=0.14540201649069787
Epoch #168: loss=0.133785809725523
Epoch #169: loss=0.13296427175402642
Epoch #170: loss=0.11025800615549088
Epoch #171: loss=0.10273952662944794
Epoch #172: loss=0.14684553042054177
Epoch #173: loss=0.14520885944366455
Epoch #174: loss=0.12449021190404892
Epoch #175: loss=0.15090841829776763
Epoch #176: loss=0.14790256455540657
Epoch #177: loss=0.13736532270908355
Epoch #178: loss=0.1217728291451931
Epoch #179: loss=0.12697342082858085
Epoch #180: loss=0.12754459351301192
Epoch #181: loss=0.12641960218548776
Epoch #182: loss=0.1228333467245102
Epoch #183: loss=0.13239131435751916
Epoch #184: loss=0.15991361528635026
Epoch #185: loss=0.12004677474498748
Epoch #186: loss=0.10930476151406765
Epoch #187: loss=0.09394612848758697
Epoch #188: loss=0.134219418913126
Epoch #189: loss=0.12527885258197785
Epoch #190: loss=0.08120539203286171
Epoch #191: loss=0.1112154172360897
Epoch #192: loss=0.09820398785173894
Epoch #193: loss=0.1416774307191372
Epoch #194: loss=0.1048305569589138
Epoch #195: loss=0.1203056101500988
Epoch #196: loss=0.1282286387681961
Epoch #197: loss=0.08915478214621544
Epoch #198: loss=0.13263113737106325
Epoch #199: loss=0.12133118465542793
Epoch #200: loss=0.09116630248725414
Epoch #201: loss=0.11980626881122589
Epoch #202: loss=0.1180581982433796
Epoch #203: loss=0.13018935099244117
Epoch #204: loss=0.09253266140818596
Epoch #205: loss=0.0995392795652151
Epoch #206: loss=0.10278197094798087
Epoch #207: loss=0.17688016965985298
Epoch #208: loss=0.09921996951103211
Epoch #209: loss=0.08295927599072456
Epoch #210: loss=0.08381720751523972
Epoch #211: loss=0.07224955663084984
Epoch #212: loss=0.0807659874856472
Epoch #213: loss=0.0688891015946865
Epoch #214: loss=0.08862300701439381
Epoch #215: loss=0.06691371984779834
Epoch #216: loss=0.08870283000171185
Epoch #217: loss=0.06320366449654102
Epoch #218: loss=0.07696394979953766
Epoch #219: loss=0.08064565919339657
Epoch #220: loss=0.09288607604801655
Epoch #221: loss=0.07291331246495247
Epoch #222: loss=0.08106737427413463
Epoch #223: loss=0.16556510291993617
Epoch #224: loss=0.0937146370112896
Epoch #225: loss=0.22683980099856854
Epoch #226: loss=0.13907770901918412
Epoch #227: loss=0.10905688345432281
Epoch #228: loss=0.08785746276378631
Epoch #229: loss=0.06635636456310749
Epoch #230: loss=0.11819603398442269
Epoch #231: loss=0.07031055331230164
Epoch #232: loss=0.0884040942788124
Epoch #233: loss=0.08095943555235863
Epoch #234: loss=0.06903902761638164
Epoch #235: loss=0.07034275960177183
Epoch #236: loss=0.06437656402587891
Epoch #237: loss=0.06478376865386963
Epoch #238: loss=0.06238336935639381
Epoch #239: loss=0.08840286627411842
Epoch #240: loss=0.0898249800503254
Epoch #241: loss=0.06935189090669155
Epoch #242: loss=0.07716592662036419
Epoch #243: loss=0.05527135610580444
Epoch #244: loss=0.06787347778677941
Epoch #245: loss=0.05673486057668924
Epoch #246: loss=0.06679018996655942
Epoch #247: loss=0.09604470171034336
Epoch #248: loss=0.18192343384027482
Epoch #249: loss=0.10704407669603824

Training time: 0:21:43.093516

Finished.
n2one setting etth1_etth2_ettm1 -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm1_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_etth2_ettm1', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.26736e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.44959e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.26736e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.36271932687741837, 'MAE': 0.42644776928241346}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_ettm1 -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm1_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_etth2_ettm1', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.22051e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.08961e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.22051e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.6800592774167319, 'MAE': 0.6614236236217086}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_ettm1 -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm1_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_etth2_ettm1', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.79135e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.2301597507061438, 'MAE': 0.32644748882941566}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_ettm2', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_ettm2_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=4.38095874786377
Epoch #1: loss=2.43244770526886
Epoch #2: loss=2.1763160753250124
Epoch #3: loss=1.9707812452316285
Epoch #4: loss=1.777040867805481
Epoch #5: loss=1.610333228111267
Epoch #6: loss=1.4585762977600099
Epoch #7: loss=1.4596696710586547
Epoch #8: loss=1.28045996427536
Epoch #9: loss=1.129902307987213
Epoch #10: loss=1.1968729519844055
Epoch #11: loss=1.1940397214889527
Epoch #12: loss=1.0803685760498047
Epoch #13: loss=0.9614050769805909
Epoch #14: loss=1.0264173007011415
Epoch #15: loss=1.0607491517066956
Epoch #16: loss=0.8961572742462158
Epoch #17: loss=0.8500694823265076
Epoch #18: loss=0.7549404740333557
Epoch #19: loss=0.7284206700325012
Epoch #20: loss=0.7826349425315857
Epoch #21: loss=0.7878748345375061
Epoch #22: loss=0.8935365080833435
Epoch #23: loss=0.804268364906311
Epoch #24: loss=0.7879861450195312
Epoch #25: loss=0.7622880840301514
Epoch #26: loss=0.6859998786449433
Epoch #27: loss=0.6582974529266358
Epoch #28: loss=0.661010160446167
Epoch #29: loss=0.6114371180534363
Epoch #30: loss=0.5551124751567841
Epoch #31: loss=0.6297319149971008
Epoch #32: loss=0.6376902675628662
Epoch #33: loss=0.5451936650276185
Epoch #34: loss=0.6026637971401214
Epoch #35: loss=0.6122266185283661
Epoch #36: loss=0.6328036057949066
Epoch #37: loss=0.5202580261230468
Epoch #38: loss=0.5342801797389984
Epoch #39: loss=0.51688472032547
Epoch #40: loss=0.5071298670768738
Epoch #41: loss=0.5480580270290375
Epoch #42: loss=0.5276033437252045
Epoch #43: loss=0.44953333616256713
Epoch #44: loss=0.5070863795280457
Epoch #45: loss=0.5563323390483856
Epoch #46: loss=0.4371104609966278
Epoch #47: loss=0.5407964944839477
Epoch #48: loss=0.44811028957366944
Epoch #49: loss=0.5516736507415771
Epoch #50: loss=0.43602731585502624
Epoch #51: loss=0.39281719565391543
Epoch #52: loss=0.43369766712188723
Epoch #53: loss=0.3865743237733841
Epoch #54: loss=0.42351828813552855
Epoch #55: loss=0.3412781065702438
Epoch #56: loss=0.36100953578948974
Epoch #57: loss=0.42374942541122435
Epoch #58: loss=0.5540143942832947
Epoch #59: loss=0.434577619433403
Epoch #60: loss=0.375390864610672
Epoch #61: loss=0.4097906643152237
Epoch #62: loss=0.3805323433876038
Epoch #63: loss=0.41423076689243316
Epoch #64: loss=0.6348156762123108
Epoch #65: loss=0.41339756608009337
Epoch #66: loss=0.364199150800705
Epoch #67: loss=0.3908622658252716
Epoch #68: loss=0.36985652208328246
Epoch #69: loss=0.3252547311782837
Epoch #70: loss=0.31383117139339445
Epoch #71: loss=0.3660394895076752
Epoch #72: loss=0.3654007583856583
Epoch #73: loss=0.3182396858930588
Epoch #74: loss=0.2970228987932205
Epoch #75: loss=0.30573297560214996
Epoch #76: loss=0.36636425673961637
Epoch #77: loss=0.3167726838588715
Epoch #78: loss=0.33757431447505953
Epoch #79: loss=0.3046297299861908
Epoch #80: loss=0.27560591518878935
Epoch #81: loss=0.36078900218009946
Epoch #82: loss=0.29657650291919707
Epoch #83: loss=0.2977802437543869
Epoch #84: loss=0.256924135684967
Epoch #85: loss=0.25872578799724577
Epoch #86: loss=0.26264631062746047
Epoch #87: loss=0.24738884449005127
Epoch #88: loss=0.25612282276153564
Epoch #89: loss=0.2913961839675903
Epoch #90: loss=0.26577467024326323
Epoch #91: loss=0.25263105690479276
Epoch #92: loss=0.3512745663523674
Epoch #93: loss=0.3141525250673294
Epoch #94: loss=0.29317532539367674
Epoch #95: loss=0.2964390563964844
Epoch #96: loss=0.24694090962409973
Epoch #97: loss=0.26538552284240724
Epoch #98: loss=0.38861468225717544
Epoch #99: loss=0.3027912896871567
Epoch #100: loss=0.2368920338153839
Epoch #101: loss=0.23183577835559846
Epoch #102: loss=0.21591540515422822
Epoch #103: loss=0.23463328152894974
Epoch #104: loss=0.2360771745443344
Epoch #105: loss=0.19913883686065673
Epoch #106: loss=0.2500018593668938
Epoch #107: loss=0.2419338259100914
Epoch #108: loss=0.22376472145318985
Epoch #109: loss=0.2403321498632431
Epoch #110: loss=0.2595964258909225
Epoch #111: loss=0.22917560160160064
Epoch #112: loss=0.23819460451602936
Epoch #113: loss=0.2545450708270073
Epoch #114: loss=0.22913417845964432
Epoch #115: loss=0.2661708909273148
Epoch #116: loss=0.24213331788778306
Epoch #117: loss=0.20397595852613448
Epoch #118: loss=0.17552166789770127
Epoch #119: loss=0.20696258991956712
Epoch #120: loss=0.23312293022871017
Epoch #121: loss=0.2030152413249016
Epoch #122: loss=0.19564647614955902
Epoch #123: loss=0.1755881890654564
Epoch #124: loss=0.17407584309577942
Epoch #125: loss=0.2539807417988777
Epoch #126: loss=0.23150418549776078
Epoch #127: loss=0.22730325400829315
Epoch #128: loss=0.20010845899581908
Epoch #129: loss=0.19940388172864915
Epoch #130: loss=0.18098392218351364
Epoch #131: loss=0.1560719656944275
Epoch #132: loss=0.15167831242084504
Epoch #133: loss=0.13910919070243835
Epoch #134: loss=0.19495150148868562
Epoch #135: loss=0.2061525785923004
Epoch #136: loss=0.22171094119548798
Epoch #137: loss=0.1847041839361191
Epoch #138: loss=0.22085283905267716
Epoch #139: loss=0.1868673449754715
Epoch #140: loss=0.16785609751939773
Epoch #141: loss=0.16900731414556502
Epoch #142: loss=0.14550058990716935
Epoch #143: loss=0.13795503318309785
Epoch #144: loss=0.14813058987259864
Epoch #145: loss=0.1690538367629051
Epoch #146: loss=0.26501849144697187
Epoch #147: loss=0.14812471747398376
Epoch #148: loss=0.20435681521892549
Epoch #149: loss=0.20211779952049255
Epoch #150: loss=0.12656580582261084
Epoch #151: loss=0.15663725659251213
Epoch #152: loss=0.16635204672813417
Epoch #153: loss=0.12299919962882995
Epoch #154: loss=0.12366907000541687
Epoch #155: loss=0.14479067757725717
Epoch #156: loss=0.14618611156940461
Epoch #157: loss=0.13997119188308715
Epoch #158: loss=0.17758508577942847
Epoch #159: loss=0.12073054403066635
Epoch #160: loss=0.19199615567922593
Epoch #161: loss=0.15180313482880592
Epoch #162: loss=0.14933651119470595
Epoch #163: loss=0.15389264434576033
Epoch #164: loss=0.1784323510527611
Epoch #165: loss=0.1286076457798481
Epoch #166: loss=0.119336948543787
Epoch #167: loss=0.1297127567231655
Epoch #168: loss=0.10323709845542908
Epoch #169: loss=0.1091158302128315
Epoch #170: loss=0.10402589529752732
Epoch #171: loss=0.09295512959361077
Epoch #172: loss=0.11164984986186027
Epoch #173: loss=0.11298519372940063
Epoch #174: loss=0.11307872965931892
Epoch #175: loss=0.13515558183193208
Epoch #176: loss=0.151196199208498
Epoch #177: loss=0.14365359425544738
Epoch #178: loss=0.12479157194495201
Epoch #179: loss=0.11225649431347846
Epoch #180: loss=0.09140939638018608
Epoch #181: loss=0.10220808684825897
Epoch #182: loss=0.12082397237420082
Epoch #183: loss=0.14792736262083053
Epoch #184: loss=0.1480446557700634
Epoch #185: loss=0.11349498182535171
Epoch #186: loss=0.10838767945766449
Epoch #187: loss=0.09527859181165695
Epoch #188: loss=0.14519390136003493
Epoch #189: loss=0.13398854121565817
Epoch #190: loss=0.08585740342736244
Epoch #191: loss=0.1009440315514803
Epoch #192: loss=0.09116234980523587
Epoch #193: loss=0.14888033099472522
Epoch #194: loss=0.09404996901750565
Epoch #195: loss=0.10829307243227959
Epoch #196: loss=0.11955893829464913
Epoch #197: loss=0.08173711776733399
Epoch #198: loss=0.1383740200102329
Epoch #199: loss=0.13871975898742675
Epoch #200: loss=0.0973482696712017
Epoch #201: loss=0.1378985920548439
Epoch #202: loss=0.1630307638645172
Epoch #203: loss=0.13320617645978927
Epoch #204: loss=0.10963942013680934
Epoch #205: loss=0.09746280267834663
Epoch #206: loss=0.13076126217842102
Epoch #207: loss=0.18288068294525148
Epoch #208: loss=0.1345875234901905
Epoch #209: loss=0.10427762567996979
Epoch #210: loss=0.08246713995933533
Epoch #211: loss=0.07509204238653183
Epoch #212: loss=0.07874094024300575
Epoch #213: loss=0.06845302581787109
Epoch #214: loss=0.08040610767900944
Epoch #215: loss=0.06494889244437217
Epoch #216: loss=0.10147347547113895
Epoch #217: loss=0.06998874515295028
Epoch #218: loss=0.07221106298267842
Epoch #219: loss=0.08586148664355278
Epoch #220: loss=0.09212958335876464
Epoch #221: loss=0.0772925692051649
Epoch #222: loss=0.10229017145931721
Epoch #223: loss=0.16224477142095567
Epoch #224: loss=0.08566056303679943
Epoch #225: loss=0.23260208837687968
Epoch #226: loss=0.19124508112668992
Epoch #227: loss=0.150964475274086
Epoch #228: loss=0.11671648621559143
Epoch #229: loss=0.10125291660428047
Epoch #230: loss=0.14474668875336646
Epoch #231: loss=0.07700396582484245
Epoch #232: loss=0.09647538542747497
Epoch #233: loss=0.07717436201870441
Epoch #234: loss=0.07569100506603718
Epoch #235: loss=0.08093005664646626
Epoch #236: loss=0.06979350998997688
Epoch #237: loss=0.07354570552706718
Epoch #238: loss=0.061177439615130426
Epoch #239: loss=0.09000469826161861
Epoch #240: loss=0.08233085729181766
Epoch #241: loss=0.07467737339437008
Epoch #242: loss=0.07567923404276371
Epoch #243: loss=0.06250735625624657
Epoch #244: loss=0.0644304583594203
Epoch #245: loss=0.056671713814139366
Epoch #246: loss=0.10714444749057293
Epoch #247: loss=0.13187814578413964
Epoch #248: loss=0.21094054758548736
Epoch #249: loss=0.10749796316027642

Training time: 0:21:45.309488

Finished.
n2one setting etth1_etth2_ettm2 -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm2_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_etth2_ettm2', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.46062e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.30795e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.46062e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3812204078767411, 'MAE': 0.4319755546975207}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_ettm2 -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm2_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_etth2_ettm2', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.60206e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.14711e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.60206e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3569419766240586, 'MAE': 0.4314923407812655}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_ettm2 -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm2_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_etth2_ettm2', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.84543e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.23014344658500693, 'MAE': 0.3245613642376586}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_electricity', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_electricity_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.5684911414758482
Epoch #1: loss=0.6250634285051431
Epoch #2: loss=0.4414781993894435
Epoch #3: loss=0.3354742555920757
Epoch #4: loss=0.28876847464646865
Epoch #5: loss=0.23558307975085813
Epoch #6: loss=0.20166063958139563
Epoch #7: loss=0.18004427638961307
Epoch #8: loss=0.17270116030947485
Epoch #9: loss=0.13493977403685228
Epoch #10: loss=0.12992731506255137
Epoch #11: loss=0.13859395887424697
Epoch #12: loss=0.10669793461018534
Epoch #13: loss=0.09889021266752214
Epoch #14: loss=0.08689778954791488
Epoch #15: loss=0.08706629284059823
Epoch #16: loss=0.07747850909050721
Epoch #17: loss=0.07764411331223908
Epoch #18: loss=0.0571540660516762
Epoch #19: loss=0.07142966414398666
Epoch #20: loss=0.06479997800023699
Epoch #21: loss=0.05333402155717807
Epoch #22: loss=0.04750987385441341
Epoch #23: loss=0.05743471781181088
Epoch #24: loss=0.05791939302945315
Epoch #25: loss=0.054301349375285766
Epoch #26: loss=0.0407367807576683
Epoch #27: loss=0.04172978962201681
Epoch #28: loss=0.03930903189857282
Epoch #29: loss=0.04090169599390964
Epoch #30: loss=0.03621872743007852
Epoch #31: loss=0.04024261581753172
Epoch #32: loss=0.036165146753469955
Epoch #33: loss=0.04031488110603237
Epoch #34: loss=0.036358406194207715
Epoch #35: loss=0.029001188321289288
Epoch #36: loss=0.031189442335961583
Epoch #37: loss=0.04475092170621032
Epoch #38: loss=0.03166001657746843
Epoch #39: loss=0.036039856304206065
Epoch #40: loss=0.02474091691590512
Epoch #41: loss=0.026901865874264224
Epoch #42: loss=0.03496778964468125
Epoch #43: loss=0.027286018454469742
Epoch #44: loss=0.02130300396733653
Epoch #45: loss=0.02453586661479255
Epoch #46: loss=0.04442867511855577
Epoch #47: loss=0.02544785072095692
Epoch #48: loss=0.04385665218526525
Epoch #49: loss=0.021977665237109385
Epoch #50: loss=0.016283926134234045
Epoch #51: loss=0.02032521924337567
Epoch #52: loss=0.028092065559866937
Epoch #53: loss=0.02445558387379565
Epoch #54: loss=0.024030101295115788
Epoch #55: loss=0.017811670390986353
Epoch #56: loss=0.01820238494008446
Epoch #57: loss=0.020918172464789407
Epoch #58: loss=0.01793920788774962
Epoch #59: loss=0.036463951144311856
Epoch #60: loss=0.01530205011993313
Epoch #61: loss=0.022270977128655025
Epoch #62: loss=0.016575739377025347
Epoch #63: loss=0.018127394684785005
Epoch #64: loss=0.022698468136003437
Epoch #65: loss=0.022855994258242758
Epoch #66: loss=0.022881511174865178
Epoch #67: loss=0.02450086430563077
Epoch #68: loss=0.019513243798569623
Epoch #69: loss=0.017085978487826215
Epoch #70: loss=0.02199301635776994
Epoch #71: loss=0.01606247767583648
Epoch #72: loss=0.027061956994054812
Epoch #73: loss=0.0167406524521118
Epoch #74: loss=0.02037073992568054
Epoch #75: loss=0.011534250913354666
Epoch #76: loss=0.019600125737384018
Epoch #77: loss=0.01644532230314312
Epoch #78: loss=0.019062653923782508
Epoch #79: loss=0.025019597735450563
Epoch #80: loss=0.02505973491247799
Epoch #81: loss=0.010125486410236847
Epoch #82: loss=0.013857652262068674
Epoch #83: loss=0.01420476871678161
Epoch #84: loss=0.01604135195053975
Epoch #85: loss=0.0247095521139815
Epoch #86: loss=0.02486228955676779
Epoch #87: loss=0.032070090073689037
Epoch #88: loss=0.01431373981011809
Epoch #89: loss=0.013565979305126551
Epoch #90: loss=0.011222482704272521
Epoch #91: loss=0.018417838858718526
Epoch #92: loss=0.01963832658878875
Epoch #93: loss=0.01641418056201134
Epoch #94: loss=0.01815550042865381
Epoch #95: loss=0.011591045945055728
Epoch #96: loss=0.020481314405854514
Epoch #97: loss=0.011671274666389479
Epoch #98: loss=0.008431854292771209
Epoch #99: loss=0.014502214714572
Epoch #100: loss=0.014770671089506473
Epoch #101: loss=0.0255316471915567
Epoch #102: loss=0.017543977678148772
Epoch #103: loss=0.031825851521162844
Epoch #104: loss=0.021065492322320925
Epoch #105: loss=0.01093286180420459
Epoch #106: loss=0.014114297769873389
Epoch #107: loss=0.014816998433210512
Epoch #108: loss=0.018325794102457254
Epoch #109: loss=0.03445944500836864
Epoch #110: loss=0.01825874688437403
Epoch #111: loss=0.013688864174069587
Epoch #112: loss=0.015153058470963543
Epoch #113: loss=0.012417300553373825
Epoch #114: loss=0.010256068606916536
Epoch #115: loss=0.010468719084138996
Epoch #116: loss=0.013764555797279716
Epoch #117: loss=0.01422819588646126
Epoch #118: loss=0.013222412148893657
Epoch #119: loss=0.02317646497499142
Epoch #120: loss=0.014441942696723697
Epoch #121: loss=0.01333028582644079
Epoch #122: loss=0.012347980893439433
Epoch #123: loss=0.012258737703173685
Epoch #124: loss=0.01387339505860443
Epoch #125: loss=0.0077154466993550755
Epoch #126: loss=0.013048772046206964
Epoch #127: loss=0.01246009710185758
Epoch #128: loss=0.015364572563062687
Epoch #129: loss=0.013120183783910002
Epoch #130: loss=0.019309524261851365
Epoch #131: loss=0.021211115275023142
Epoch #132: loss=0.03889282064255216
Epoch #133: loss=0.010758557161594282
Epoch #134: loss=0.011121612526615386
Epoch #135: loss=0.011164336393712395
Epoch #136: loss=0.011292755463570635
Epoch #137: loss=0.010763248869690543
Epoch #138: loss=0.016116516845676103
Epoch #139: loss=0.011813387319570713
Epoch #140: loss=0.015409971584232329
Epoch #141: loss=0.013822615672243454
Epoch #142: loss=0.009347496006669087
Epoch #143: loss=0.013390524752451968
Epoch #144: loss=0.011689733039438308
Epoch #145: loss=0.013664153264878916
Epoch #146: loss=0.01632143768035362
Epoch #147: loss=0.02053367224567111
Epoch #148: loss=0.010629824601694135
Epoch #149: loss=0.014826383051434671
Epoch #150: loss=0.012446327715653425
Epoch #151: loss=0.009382459484110239
Epoch #152: loss=0.007262686664697283
Epoch #153: loss=0.019252276933689447
Epoch #154: loss=0.01174287107006869
Epoch #155: loss=0.011612241512595383
Epoch #156: loss=0.010655608030692883
Epoch #157: loss=0.010902592281762288
Epoch #158: loss=0.014831416173525321
Epoch #159: loss=0.007978944342241123
Epoch #160: loss=0.009920208811162234
Epoch #161: loss=0.015065141565708528
Epoch #162: loss=0.018144413422351815
Epoch #163: loss=0.017175864837994215
Epoch #164: loss=0.01048107843032913
Epoch #165: loss=0.008078420990921641
Epoch #166: loss=0.009879753299477968
Epoch #167: loss=0.009568030940135941
Epoch #168: loss=0.02273749819185251
Epoch #169: loss=0.013471248751652162
Epoch #170: loss=0.015537748882136961
Epoch #171: loss=0.010822639676026388
Epoch #172: loss=0.008066635473575721
Epoch #173: loss=0.01163243473283321
Epoch #174: loss=0.007863465984223356
Epoch #175: loss=0.011995117482121117
Epoch #176: loss=0.012364921567495912
Epoch #177: loss=0.015666912374114477
Epoch #178: loss=0.009109330468345434
Epoch #179: loss=0.010969888297806202
Epoch #180: loss=0.015017251438051184
Epoch #181: loss=0.010799856361265837
Epoch #182: loss=0.011274060770459195
Epoch #183: loss=0.01330558155513883
Epoch #184: loss=0.01530217531392587
Epoch #185: loss=0.012210819447315785
Epoch #186: loss=0.008606693858833316
Epoch #187: loss=0.008413856982517598
Epoch #188: loss=0.010792415790040907
Epoch #189: loss=0.007278675393639271
Epoch #190: loss=0.01950293410336599
Epoch #191: loss=0.007210759808649934
Epoch #192: loss=0.010730310928062606
Epoch #193: loss=0.025562550651027697
Epoch #194: loss=0.012494665677242204
Epoch #195: loss=0.011979592167737602
Epoch #196: loss=0.013582731066132659
Epoch #197: loss=0.015128955103755832
Epoch #198: loss=0.007708756635382549
Epoch #199: loss=0.007274645782656162
Epoch #200: loss=0.012759448082790946
Epoch #201: loss=0.011988802750615764
Epoch #202: loss=0.01726423602763202
Epoch #203: loss=0.009099251411354809
Epoch #204: loss=0.004608674998978959
Epoch #205: loss=0.008216458391363441
Epoch #206: loss=0.00971630439231756
Epoch #207: loss=0.014218353229373305
Epoch #208: loss=0.012190378587536597
Epoch #209: loss=0.008683909271034037
Epoch #210: loss=0.010132827881876546
Epoch #211: loss=0.008309781503839308
Epoch #212: loss=0.015175639036017706
Epoch #213: loss=0.007778174307200808
Epoch #214: loss=0.011448478737651412
Epoch #215: loss=0.008984894090620523
Epoch #216: loss=0.008995731139804041
Epoch #217: loss=0.018479869202293678
Epoch #218: loss=0.010140092478658476
Epoch #219: loss=0.010507937151384402
Epoch #220: loss=0.016733806706276902
Epoch #221: loss=0.014582034596155133
Epoch #222: loss=0.007854236023146104
Epoch #223: loss=0.012003213092215609
Epoch #224: loss=0.008978370736950814
Epoch #225: loss=0.011401991149560035
Epoch #226: loss=0.007128916458668076
Epoch #227: loss=0.02670990019609262
Epoch #228: loss=0.007283917727355442
Epoch #229: loss=0.021833836909213256
Epoch #230: loss=0.008668959353713375
Epoch #231: loss=0.02711946181666259
Epoch #232: loss=0.0091326655012055
Epoch #233: loss=0.029218509472791913
Epoch #234: loss=0.012437354569469315
Epoch #235: loss=0.005840796508840216
Epoch #236: loss=0.008246783926907524
Epoch #237: loss=0.011014330828798685
Epoch #238: loss=0.014193949561197756
Epoch #239: loss=0.013684146290248844
Epoch #240: loss=0.010115032407295292
Epoch #241: loss=0.007455597516130169
Epoch #242: loss=0.006690424094202498
Epoch #243: loss=0.010630697506799626
Epoch #244: loss=0.011165759465466045
Epoch #245: loss=0.014861708327974957
Epoch #246: loss=0.009063060658222842
Epoch #247: loss=0.009376150257138312
Epoch #248: loss=0.012116184499316307
Epoch #249: loss=0.007387132468848809

Training time: 4:29:22.235878

Finished.
n2one setting etth1_etth2_electricity -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_electricity_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_etth2_electricity', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.05051e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.12095e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.24994e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.05051e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.5730286256161429, 'MAE': 0.5720222207507629}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_electricity -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_electricity_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_etth2_electricity', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.2541e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.2541e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.23915852365889542, 'MAE': 0.34107878863300695}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_traffic', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_traffic_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.952732201002232
Epoch #1: loss=0.3626753439165686
Epoch #2: loss=0.2437887974423633
Epoch #3: loss=0.1712134691576163
Epoch #4: loss=0.1374204255359834
Epoch #5: loss=0.11931568102647452
Epoch #6: loss=0.10131262513685581
Epoch #7: loss=0.08070737073946421
Epoch #8: loss=0.07684079993443912
Epoch #9: loss=0.06671844647993168
Epoch #10: loss=0.06046269961992134
Epoch #11: loss=0.05213979185456793
Epoch #12: loss=0.04699268252067863
Epoch #13: loss=0.04938302612406325
Epoch #14: loss=0.04541002063651582
Epoch #15: loss=0.042448795165337165
Epoch #16: loss=0.034531513932288614
Epoch #17: loss=0.036319536951659716
Epoch #18: loss=0.03350861345074399
Epoch #19: loss=0.039450747193237046
Epoch #20: loss=0.03090149616279329
Epoch #21: loss=0.031094663762104735
Epoch #22: loss=0.033632418012658996
Epoch #23: loss=0.02738845262654683
Epoch #24: loss=0.026013250168615987
Epoch #25: loss=0.024148524908554108
Epoch #26: loss=0.03141098143027874
Epoch #27: loss=0.03147845714619876
Epoch #28: loss=0.02424346737602947
Epoch #29: loss=0.027801517463545953
Epoch #30: loss=0.02668139413020416
Epoch #31: loss=0.026498008819153963
Epoch #32: loss=0.021639427156735117
Epoch #33: loss=0.029299141349165687
Epoch #34: loss=0.01871529721589036
Epoch #35: loss=0.017411728766582032
Epoch #36: loss=0.022000410970867627
Epoch #37: loss=0.024374053252304875
Epoch #38: loss=0.01994165947899216
Epoch #39: loss=0.02108860491065587
Epoch #40: loss=0.01919235438383535
Epoch #41: loss=0.022040874733215893
Epoch #42: loss=0.020868259987615254
Epoch #43: loss=0.020761439264402128
Epoch #44: loss=0.029313201758340502
Epoch #45: loss=0.018516020964433496
Epoch #46: loss=0.014702237912217957
Epoch #47: loss=0.01958371387624775
Epoch #48: loss=0.017172644333834187
Epoch #49: loss=0.01727928324285193
Epoch #50: loss=0.02287172301769146
Epoch #51: loss=0.018966107742864103
Epoch #52: loss=0.01337167345358566
Epoch #53: loss=0.024731336994142886
Epoch #54: loss=0.02003355661108633
Epoch #55: loss=0.019300873697252696
Epoch #56: loss=0.018644896276296778
Epoch #57: loss=0.01591631040006576
Epoch #58: loss=0.01805417296488224
Epoch #59: loss=0.017978585362126074
Epoch #60: loss=0.017836199742288714
Epoch #61: loss=0.03357097130723244
Epoch #62: loss=0.013104003045966288
Epoch #63: loss=0.020936250460658917
Epoch #64: loss=0.011985098362831743
Epoch #65: loss=0.013081961495558079
Epoch #66: loss=0.016395909379881734
Epoch #67: loss=0.018225982243016567
Epoch #68: loss=0.016453989757651243
Epoch #69: loss=0.014223759952348128
Epoch #70: loss=0.0215878346089043
Epoch #71: loss=0.011526649960187279
Epoch #72: loss=0.015464343402888754
Epoch #73: loss=0.009859371800323816
Epoch #74: loss=0.014772812049537174
Epoch #75: loss=0.01698616836589472
Epoch #76: loss=0.01230427547716525
Epoch #77: loss=0.019016612039269777
Epoch #78: loss=0.013163438350901531
Epoch #79: loss=0.0179221765989064
Epoch #80: loss=0.013581405363064104
Epoch #81: loss=0.015479971389256983
Epoch #82: loss=0.015026302422068856
Epoch #83: loss=0.013061169961478814
Epoch #84: loss=0.013697067608535021
Epoch #85: loss=0.017860160980406978
Epoch #86: loss=0.015285480760744099
Epoch #87: loss=0.015820827036771762
Epoch #88: loss=0.014466572870337192
Epoch #89: loss=0.022977227817448206
Epoch #90: loss=0.013259542510743369
Epoch #91: loss=0.016491332682238714
Epoch #92: loss=0.010604127677203768
Epoch #93: loss=0.011228321218484646
Epoch #94: loss=0.014927384178257829
Epoch #95: loss=0.015251277257078625
Epoch #96: loss=0.014715295995040222
Epoch #97: loss=0.013669499514294102
Epoch #98: loss=0.012675834062003111
Epoch #99: loss=0.011753094020829462
Epoch #100: loss=0.018201794183946463
Epoch #101: loss=0.018018863903976272
Epoch #102: loss=0.013179622769317766
Epoch #103: loss=0.01098743604254121
Epoch #104: loss=0.013918473502021968
Epoch #105: loss=0.012795315039507326
Epoch #106: loss=0.015508278280820327
Epoch #107: loss=0.015071085126575914
Epoch #108: loss=0.017309501703136727
Epoch #109: loss=0.01702531743193998
Epoch #110: loss=0.015431212557806127
Epoch #111: loss=0.010640743253777838
Epoch #112: loss=0.01395553128810979
Epoch #113: loss=0.010769462804199721
Epoch #114: loss=0.01833677741497719
Epoch #115: loss=0.012999306241967067
Epoch #116: loss=0.018953872191833733
Epoch #117: loss=0.011761237688832513
Epoch #118: loss=0.008643475754801015
Epoch #119: loss=0.0110529961895246
Epoch #120: loss=0.01751455046530477
Epoch #121: loss=0.009109269353039094
Epoch #122: loss=0.013522974301895582
Epoch #123: loss=0.013320539936751018
Epoch #124: loss=0.0118060531651497
Epoch #125: loss=0.011590273803781472
Epoch #126: loss=0.0136109858642955
Epoch #127: loss=0.018583366441675707
Epoch #128: loss=0.014818452126809
Epoch #129: loss=0.01803677711344391
Epoch #130: loss=0.012437528679666979
Epoch #131: loss=0.013817033247177523
Epoch #132: loss=0.009164065304586369
Epoch #133: loss=0.011534422052643165
Epoch #134: loss=0.009766215206279108
Epoch #135: loss=0.01360734136608088
Epoch #136: loss=0.012590079811157406
Epoch #137: loss=0.011931654309708259
Epoch #138: loss=0.021024675079122757
Epoch #139: loss=0.029355018069779183
Epoch #140: loss=0.011771386912573378
Epoch #141: loss=0.010474386875538996
Epoch #142: loss=0.011374887931765961
Epoch #143: loss=0.01062374975414084
Epoch #144: loss=0.01368969258823465
Epoch #145: loss=0.012876315277200574
Epoch #146: loss=0.010935054030584344
Epoch #147: loss=0.012645323204113698
Epoch #148: loss=0.011263830770229969
Epoch #149: loss=0.012285228133784739
Epoch #150: loss=0.013524912973060793
Epoch #151: loss=0.008703601438243561
Epoch #152: loss=0.015299098999725232
Epoch #153: loss=0.010898717836197518
Epoch #154: loss=0.008833542985248391
Epoch #155: loss=0.0076375186157307305
Epoch #156: loss=0.010532869142181182
Epoch #157: loss=0.008443852640354457
Epoch #158: loss=0.011128208599768694
Epoch #159: loss=0.013840276750699525
Epoch #160: loss=0.012752362765764103
Epoch #161: loss=0.010183231142755135
Epoch #162: loss=0.010175916766274065
Epoch #163: loss=0.01209259425961975
Epoch #164: loss=0.009935840107209411
Epoch #165: loss=0.011962183271550688
Epoch #166: loss=0.008656387231662203
Epoch #167: loss=0.012252113719608477
Epoch #168: loss=0.011556998787160227
Epoch #169: loss=0.012359816201033068
Epoch #170: loss=0.011752718635421452
Epoch #171: loss=0.012520620293234056
Epoch #172: loss=0.007148259059124951
Epoch #173: loss=0.008811013452044516
Epoch #174: loss=0.014644233742944782
Epoch #175: loss=0.009546907955811057
Epoch #176: loss=0.015809636973506413
Epoch #177: loss=0.009274526491919219
Epoch #178: loss=0.011101309966794842
Epoch #179: loss=0.01060759815567566
Epoch #180: loss=0.00915831234342643
Epoch #181: loss=0.009718035065857895
Epoch #182: loss=0.01602954072207978
Epoch #183: loss=0.013773182177347116
Epoch #184: loss=0.009395356331920686
Epoch #185: loss=0.0128012524495982
Epoch #186: loss=0.007864021157795886
Epoch #187: loss=0.010542569321858777
Epoch #188: loss=0.00796551804372748
Epoch #189: loss=0.012254511370572376
Epoch #190: loss=0.010045159336589607
Epoch #191: loss=0.012612186247027335
Epoch #192: loss=0.008090439462553129
Epoch #193: loss=0.01194888025557582
Epoch #194: loss=0.012663453767665122
Epoch #195: loss=0.007951161704561992
Epoch #196: loss=0.010914034679245399
Epoch #197: loss=0.013528782126018522
Epoch #198: loss=0.006036284672244283
Epoch #199: loss=0.009567512386140202
Epoch #200: loss=0.013907568312398122
Epoch #201: loss=0.0074082405895984004
Epoch #202: loss=0.010401479776889686
Epoch #203: loss=0.011286626691524934
Epoch #204: loss=0.011020419707094675
Epoch #205: loss=0.012173279093564388
Epoch #206: loss=0.008796181286348017
Epoch #207: loss=0.008783078183388507
Epoch #208: loss=0.008457104727200852
Epoch #209: loss=0.00911542134327983
Epoch #210: loss=0.014729683931945391
Epoch #211: loss=0.009462432762207654
Epoch #212: loss=0.008473267399773192
Epoch #213: loss=0.006961913491728435
Epoch #214: loss=0.009765963335617203
Epoch #215: loss=0.010121432878771403
Epoch #216: loss=0.012695854810676772
Epoch #217: loss=0.007925274619494353
Epoch #218: loss=0.011264779894747218
Epoch #219: loss=0.012873182949174427
Epoch #220: loss=0.005609306764361538
Epoch #221: loss=0.010565476966031096
Epoch #222: loss=0.012193629443066059
Epoch #223: loss=0.010177799204702501
Epoch #224: loss=0.011648667031847531
Epoch #225: loss=0.006479942406572554
Epoch #226: loss=0.008749138859012797
Epoch #227: loss=0.008437992068146861
Epoch #228: loss=0.011676085406590623
Epoch #229: loss=0.009649346956937891
Epoch #230: loss=0.011191441827581517
Epoch #231: loss=0.011795564217445894
Epoch #232: loss=0.00801214421290465
Epoch #233: loss=0.00844280614902225
Epoch #234: loss=0.010063991684741824
Epoch #235: loss=0.011010612379455886
Epoch #236: loss=0.01846617397717487
Epoch #237: loss=0.006931318452180556
Epoch #238: loss=0.007123993826763211
Epoch #239: loss=0.014791157354472352
Epoch #240: loss=0.008774482962578645
Epoch #241: loss=0.007945211603465108
Epoch #242: loss=0.006768326277808195
Epoch #243: loss=0.010832368637674747
Epoch #244: loss=0.008760969415125644
Epoch #245: loss=0.0071433441967845065
Epoch #246: loss=0.00974516160305407
Epoch #247: loss=0.011686106849399068
Epoch #248: loss=0.0074400114257992984
Epoch #249: loss=0.022339693093940842

Training time: 10:12:39.432158

Finished.
n2one setting etth1_etth2_traffic -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_traffic_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_etth2_traffic', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.25789e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.33441e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.43474e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.25789e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3889979724046158, 'MAE': 0.44164025289062825}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_traffic -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_traffic_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_etth2_traffic', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.81364e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.69694e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.1673e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.81364e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.5704985746414856, 'MAE': 0.5796685593713374}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_traffic -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_traffic_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_etth2_traffic', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.8769e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.29277289315471083, 'MAE': 0.36088141995134193}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_weather', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_weather_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=5.0069163084030155
Epoch #1: loss=2.5037750244140624
Epoch #2: loss=2.2103963792324066
Epoch #3: loss=2.027012196183205
Epoch #4: loss=1.8511899352073669
Epoch #5: loss=1.8836377918720246
Epoch #6: loss=1.5658721178770065
Epoch #7: loss=1.4373004645109178
Epoch #8: loss=1.4096192806959151
Epoch #9: loss=1.2058992654085159
Epoch #10: loss=1.0956963658332826
Epoch #11: loss=1.122461597621441
Epoch #12: loss=0.9978179559111595
Epoch #13: loss=1.0369837135076523
Epoch #14: loss=1.0322539016604424
Epoch #15: loss=0.9097175806760788
Epoch #16: loss=1.0684124618768691
Epoch #17: loss=1.025524878501892
Epoch #18: loss=0.903365409374237
Epoch #19: loss=0.9367586463689804
Epoch #20: loss=0.8252082243561745
Epoch #21: loss=0.8115059554576873
Epoch #22: loss=0.850124791264534
Epoch #23: loss=0.7193564034998416
Epoch #24: loss=0.6638422451913357
Epoch #25: loss=0.7384412556886673
Epoch #26: loss=0.6450637206435204
Epoch #27: loss=0.6596068374812603
Epoch #28: loss=0.6671181805431843
Epoch #29: loss=0.7383482873439788
Epoch #30: loss=0.5784555792808532
Epoch #31: loss=0.6245150789618492
Epoch #32: loss=0.5749821335077285
Epoch #33: loss=0.5977012373507022
Epoch #34: loss=0.5555616304278373
Epoch #35: loss=0.5553048901259899
Epoch #36: loss=0.5469011150300502
Epoch #37: loss=0.5030578307807445
Epoch #38: loss=0.5685234889388084
Epoch #39: loss=0.6246425434947014
Epoch #40: loss=0.5630114458501339
Epoch #41: loss=0.4830048829317093
Epoch #42: loss=0.5085121236741543
Epoch #43: loss=0.5049545623362064
Epoch #44: loss=0.47540281489491465
Epoch #45: loss=0.41144597753882406
Epoch #46: loss=0.406230940669775
Epoch #47: loss=0.4470521867275238
Epoch #48: loss=0.45576431676745416
Epoch #49: loss=0.4342279344797134
Epoch #50: loss=0.4701758872717619
Epoch #51: loss=0.42026434987783434
Epoch #52: loss=0.4618215709924698
Epoch #53: loss=0.45426955446600914
Epoch #54: loss=0.4623950406908989
Epoch #55: loss=0.39105543345212934
Epoch #56: loss=0.3811855424195528
Epoch #57: loss=0.3556372635066509
Epoch #58: loss=0.3363674655556679
Epoch #59: loss=0.386336425691843
Epoch #60: loss=0.3265242002904415
Epoch #61: loss=0.3407598830759525
Epoch #62: loss=0.3363254051655531
Epoch #63: loss=0.3257189836353064
Epoch #64: loss=0.33210711516439917
Epoch #65: loss=0.29958789683878423
Epoch #66: loss=0.3350466448813677
Epoch #67: loss=0.2857316222041845
Epoch #68: loss=0.31375225484371183
Epoch #69: loss=0.30068572275340555
Epoch #70: loss=0.2590840648859739
Epoch #71: loss=0.2952624812722206
Epoch #72: loss=0.23963293861597776
Epoch #73: loss=0.27805358488112686
Epoch #74: loss=0.29259827695786955
Epoch #75: loss=0.2592928986996412
Epoch #76: loss=0.2500260522589087
Epoch #77: loss=0.2462059658020735
Epoch #78: loss=0.2851456370204687
Epoch #79: loss=0.2920583410188556
Epoch #80: loss=0.23277593702077864
Epoch #81: loss=0.26154377683997154
Epoch #82: loss=0.24850483555346728
Epoch #83: loss=0.28742948584258554
Epoch #84: loss=0.2981531601399183
Epoch #85: loss=0.2570504803210497
Epoch #86: loss=0.22783333621919155
Epoch #87: loss=0.467286866530776
Epoch #88: loss=0.3277772249653935
Epoch #89: loss=0.2942196946591139
Epoch #90: loss=0.24891043789684772
Epoch #91: loss=0.24689329601824284
Epoch #92: loss=0.3425825858488679
Epoch #93: loss=0.29456701036542654
Epoch #94: loss=0.24232098404318095
Epoch #95: loss=0.2636512524448335
Epoch #96: loss=0.29542316757142545
Epoch #97: loss=0.3051549918949604
Epoch #98: loss=0.19416857920587063
Epoch #99: loss=0.2179742556065321
Epoch #100: loss=0.2649328872561455
Epoch #101: loss=0.22924976106733083
Epoch #102: loss=0.2098230669274926
Epoch #103: loss=0.21827781591564416
Epoch #104: loss=0.19300050279125572
Epoch #105: loss=0.18019003150984644
Epoch #106: loss=0.1611272213049233
Epoch #107: loss=0.15353317512199283
Epoch #108: loss=0.2586452173069119
Epoch #109: loss=0.17816400956362485
Epoch #110: loss=0.19097504215314984
Epoch #111: loss=0.21197439562529324
Epoch #112: loss=0.16803691694512962
Epoch #113: loss=0.17444518599659203
Epoch #114: loss=0.14056968530640007
Epoch #115: loss=0.15773193361237645
Epoch #116: loss=0.3032788524404168
Epoch #117: loss=0.18782463958486914
Epoch #118: loss=0.20593998497352003
Epoch #119: loss=0.13285903809592128
Epoch #120: loss=0.1595075350254774
Epoch #121: loss=0.15551822623237968
Epoch #122: loss=0.15791707285679876
Epoch #123: loss=0.13483448280021548
Epoch #124: loss=0.14809928070753814
Epoch #125: loss=0.18405750785022973
Epoch #126: loss=0.13922810414806008
Epoch #127: loss=0.14711389355361462
Epoch #128: loss=0.14057399788871408
Epoch #129: loss=0.16490030381828547
Epoch #130: loss=0.11149001088924707
Epoch #131: loss=0.15396686159074308
Epoch #132: loss=0.15781608140096068
Epoch #133: loss=0.10866795815527439
Epoch #134: loss=0.17108185729011893
Epoch #135: loss=0.14978421041741968
Epoch #136: loss=0.19337286688387395
Epoch #137: loss=0.11445568744093179
Epoch #138: loss=0.12691693436354398
Epoch #139: loss=0.1496443659067154
Epoch #140: loss=0.15411647194996475
Epoch #141: loss=0.15275601511821152
Epoch #142: loss=0.10195594690740109
Epoch #143: loss=0.12311107674613594
Epoch #144: loss=0.1115881014149636
Epoch #145: loss=0.13262304225936533
Epoch #146: loss=0.12183106811717152
Epoch #147: loss=0.11353713925927877
Epoch #148: loss=0.12303630323149264
Epoch #149: loss=0.1135555853601545
Epoch #150: loss=0.11816338561475277
Epoch #151: loss=0.09643012932501734
Epoch #152: loss=0.10012322352267802
Epoch #153: loss=0.08433641749434173
Epoch #154: loss=0.1315550932660699
Epoch #155: loss=0.13386827502399684
Epoch #156: loss=0.10735473181121051
Epoch #157: loss=0.09236411387100815
Epoch #158: loss=0.0822848186828196
Epoch #159: loss=0.09469633321277797
Epoch #160: loss=0.09519199840724468
Epoch #161: loss=0.10768684623762965
Epoch #162: loss=0.142963560577482
Epoch #163: loss=0.13362209158949553
Epoch #164: loss=0.0933777576778084
Epoch #165: loss=0.1463096510618925
Epoch #166: loss=0.12241168306209146
Epoch #167: loss=0.11250053350813687
Epoch #168: loss=0.11636555707082152
Epoch #169: loss=0.09842400117777288
Epoch #170: loss=0.1458013778552413
Epoch #171: loss=0.10156120788305997
Epoch #172: loss=0.09564088406041264
Epoch #173: loss=0.09983537304215133
Epoch #174: loss=0.09185015223920345
Epoch #175: loss=0.08598486366681754
Epoch #176: loss=0.08050496738869697
Epoch #177: loss=0.07931407066062093
Epoch #178: loss=0.10612432495690882
Epoch #179: loss=0.14462380711920558
Epoch #180: loss=0.20061156060546637
Epoch #181: loss=0.20689022541046143
Epoch #182: loss=0.14911755020730197
Epoch #183: loss=0.21478277132846416
Epoch #184: loss=0.27549254335463047
Epoch #185: loss=0.16985191628336907
Epoch #186: loss=0.17391479909420013
Epoch #187: loss=0.10991789279505611
Epoch #188: loss=0.08553523481823504
Epoch #189: loss=0.0808869322296232
Epoch #190: loss=0.0979881716426462
Epoch #191: loss=0.08918388928286732
Epoch #192: loss=0.10610937755554914
Epoch #193: loss=0.09066824819892645
Epoch #194: loss=0.07648520716466009
Epoch #195: loss=0.09170076316222549
Epoch #196: loss=0.0947146201506257
Epoch #197: loss=0.13515885286033152
Epoch #198: loss=0.09872649819590151
Epoch #199: loss=0.0904232849366963
Epoch #200: loss=0.10216819380875677
Epoch #201: loss=0.1045290716458112
Epoch #202: loss=0.10037526739761234
Epoch #203: loss=0.07144108931533992
Epoch #204: loss=0.05407345693092793
Epoch #205: loss=0.07687219125218689
Epoch #206: loss=0.07572021957021206
Epoch #207: loss=0.0670562933664769
Epoch #208: loss=0.07941892738454044
Epoch #209: loss=0.06947647025808693
Epoch #210: loss=0.0826959413010627
Epoch #211: loss=0.09395979470573365
Epoch #212: loss=0.07287454179022461
Epoch #213: loss=0.06616270928643644
Epoch #214: loss=0.06085584859829396
Epoch #215: loss=0.08434910371433943
Epoch #216: loss=0.07688290730584413
Epoch #217: loss=0.10531040776986629
Epoch #218: loss=0.09503427627496422
Epoch #219: loss=0.09634078498929739
Epoch #220: loss=0.08171326334122568
Epoch #221: loss=0.06552514508366585
Epoch #222: loss=0.08042610671836883
Epoch #223: loss=0.09878123383969069
Epoch #224: loss=0.08824406834319234
Epoch #225: loss=0.08699872312135995
Epoch #226: loss=0.0681050485232845
Epoch #227: loss=0.1356458800379187
Epoch #228: loss=0.08848807709291577
Epoch #229: loss=0.06477976704481989
Epoch #230: loss=0.06556716300547123
Epoch #231: loss=0.08693093701731414
Epoch #232: loss=0.05237016764003784
Epoch #233: loss=0.06374817457981408
Epoch #234: loss=0.06361129018478096
Epoch #235: loss=0.046860111341811714
Epoch #236: loss=0.10071610661689193
Epoch #237: loss=0.0582523827208206
Epoch #238: loss=0.050138701545074583
Epoch #239: loss=0.06470788947772235
Epoch #240: loss=0.10483449471648783
Epoch #241: loss=0.062306102365255356
Epoch #242: loss=0.06629040434490889
Epoch #243: loss=0.0413795791217126
Epoch #244: loss=0.04542681176681072
Epoch #245: loss=0.06099859166424722
Epoch #246: loss=0.04596485056681558
Epoch #247: loss=0.053350661182776093
Epoch #248: loss=0.06687970836646855
Epoch #249: loss=0.07735951484646648

Training time: 0:36:32.901404

Finished.
n2one setting etth1_etth2_weather -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_weather_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_etth2_weather', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.34087e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.76626e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.34087e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.36360776904401193, 'MAE': 0.4288098208143963}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_weather_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_etth2_weather', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.25264e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.23853370458150516, 'MAE': 0.3343388882527049}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_exchange', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_exchange_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=3.9499741901050913
Epoch #1: loss=2.2213632356036794
Epoch #2: loss=1.926181679422205
Epoch #3: loss=1.8204421238465742
Epoch #4: loss=1.6640747839754277
Epoch #5: loss=1.5872091217474504
Epoch #6: loss=1.4932234395634045
Epoch #7: loss=1.3865233876488425
Epoch #8: loss=1.432268337769942
Epoch #9: loss=1.267600785602223
Epoch #10: loss=1.1965170611034741
Epoch #11: loss=1.2584314427592538
Epoch #12: loss=1.1674992387945002
Epoch #13: loss=1.085881303657185
Epoch #14: loss=1.0775497257709503
Epoch #15: loss=1.0685131522742184
Epoch #16: loss=1.0242767035961151
Epoch #17: loss=1.0660946179520001
Epoch #18: loss=1.0368196151473306
Epoch #19: loss=0.9928383475000208
Epoch #20: loss=0.9224736338311975
Epoch #21: loss=0.9429473578929901
Epoch #22: loss=0.8659073954278772
Epoch #23: loss=0.8577395623380487
Epoch #24: loss=0.8211484415964647
Epoch #25: loss=0.849967441775582
Epoch #26: loss=0.6911063641309738
Epoch #27: loss=0.7563022700223055
Epoch #28: loss=0.7222156402739611
Epoch #29: loss=0.7246976657347246
Epoch #30: loss=0.6416247879916971
Epoch #31: loss=0.6429120248014276
Epoch #32: loss=0.7477500994097103
Epoch #33: loss=0.7223633676767349
Epoch #34: loss=0.6645603410222314
Epoch #35: loss=0.690229980783029
Epoch #36: loss=0.6457118364897642
Epoch #37: loss=0.6805118539116599
Epoch #38: loss=0.5921990370208566
Epoch #39: loss=0.5620277984575792
Epoch #40: loss=0.4837293706156991
Epoch #41: loss=0.5145965936509046
Epoch #42: loss=0.5260444473136555
Epoch #43: loss=0.6029507883570411
Epoch #44: loss=0.6248968704180284
Epoch #45: loss=0.5006901716644113
Epoch #46: loss=0.5072858360680667
Epoch #47: loss=0.6482689069076017
Epoch #48: loss=0.4946786801923405
Epoch #49: loss=0.5707259313626722
Epoch #50: loss=0.45032428069548175
Epoch #51: loss=0.5696066414768045
Epoch #52: loss=0.5105274035172029
Epoch #53: loss=0.5370662374929949
Epoch #54: loss=0.5354261168024756
Epoch #55: loss=0.5290971438993107
Epoch #56: loss=0.5273479981855913
Epoch #57: loss=0.5914439707994461
Epoch #58: loss=0.5256343673576008
Epoch #59: loss=0.43854298374869605
Epoch #60: loss=0.3862146193330938
Epoch #61: loss=0.4985114105723121
Epoch #62: loss=0.4213491766290231
Epoch #63: loss=0.4101258773695339
Epoch #64: loss=0.41253293644298206
Epoch #65: loss=0.3482937921177257
Epoch #66: loss=0.4525997990911657
Epoch #67: loss=0.4036898552016778
Epoch #68: loss=0.400837281210856
Epoch #69: loss=0.4357383352789012
Epoch #70: loss=0.39983071793209424
Epoch #71: loss=0.394425784999674
Epoch #72: loss=0.357990598814054
Epoch #73: loss=0.35711968486959283
Epoch #74: loss=0.39078123799779196
Epoch #75: loss=0.397900827229023
Epoch #76: loss=0.4007717967033386
Epoch #77: loss=0.3493990356271917
Epoch #78: loss=0.4158579768104987
Epoch #79: loss=0.4721081886779178
Epoch #80: loss=0.4107052270661701
Epoch #81: loss=0.40101188895377243
Epoch #82: loss=0.38200315968556836
Epoch #83: loss=0.36834596368399536
Epoch #84: loss=0.44474870372902264
Epoch #85: loss=0.3734742545268752
Epoch #86: loss=0.3444801609624516
Epoch #87: loss=0.28556318513371726
Epoch #88: loss=0.3242128559134223
Epoch #89: loss=0.3168333674019033
Epoch #90: loss=0.40335486829280853
Epoch #91: loss=0.3334441991014914
Epoch #92: loss=0.346465682441538
Epoch #93: loss=0.27094438672065735
Epoch #94: loss=0.25959788398309186
Epoch #95: loss=0.29373200915076514
Epoch #96: loss=0.3104191022840413
Epoch #97: loss=0.2937882339412516
Epoch #98: loss=0.334008745171807
Epoch #99: loss=0.34979030964049423
Epoch #100: loss=0.2938623655248772
Epoch #101: loss=0.26605169983072713
Epoch #102: loss=0.26325604590502655
Epoch #103: loss=0.3584581437436017
Epoch #104: loss=0.355564527890899
Epoch #105: loss=0.26255147091367026
Epoch #106: loss=0.35978720675815234
Epoch #107: loss=0.3434161164543845
Epoch #108: loss=0.2490391263907606
Epoch #109: loss=0.30056654052300885
Epoch #110: loss=0.2724134319207885
Epoch #111: loss=0.2931849316439845
Epoch #112: loss=0.2732566120949658
Epoch #113: loss=0.2442993772300807
Epoch #114: loss=0.3010789589448409
Epoch #115: loss=0.29470338943329727
Epoch #116: loss=0.3007375889203765
Epoch #117: loss=0.3062706461006945
Epoch #118: loss=0.27717058766971936
Epoch #119: loss=0.2585211799226024
Epoch #120: loss=0.24420482021841136
Epoch #121: loss=0.25304598632183944
Epoch #122: loss=0.23292943428863178
Epoch #123: loss=0.30250402878631244
Epoch #124: loss=0.27040582488883624
Epoch #125: loss=0.33156564899466257
Epoch #126: loss=0.27715423093600705
Epoch #127: loss=0.3065017888491804
Epoch #128: loss=0.27309576455842366
Epoch #129: loss=0.36019566181031143
Epoch #130: loss=0.318084527823058
Epoch #131: loss=0.23842829702930016
Epoch #132: loss=0.2731461724774404
Epoch #133: loss=0.28572558747096494
Epoch #134: loss=0.2867164218967611
Epoch #135: loss=0.30660725791345944
Epoch #136: loss=0.27846754545515234
Epoch #137: loss=0.27392507886344736
Epoch #138: loss=0.27984436093406245
Epoch #139: loss=0.3021167862144383
Epoch #140: loss=0.35441487485712225
Epoch #141: loss=0.24811123006723143
Epoch #142: loss=0.28304528004743834
Epoch #143: loss=0.2647152024913918
Epoch #144: loss=0.2808972481976856
Epoch #145: loss=0.2137558450075713
Epoch #146: loss=0.2843430902470242
Epoch #147: loss=0.20634905316612936
Epoch #148: loss=0.19420362026853996
Epoch #149: loss=0.20917694101279433
Epoch #150: loss=0.18460700085217302
Epoch #151: loss=0.20007639496841215
Epoch #152: loss=0.2356752401048487
Epoch #153: loss=0.23413539068265396
Epoch #154: loss=0.21146652136336674
Epoch #155: loss=0.2521005733446641
Epoch #156: loss=0.19998840445821936
Epoch #157: loss=0.220279233191501
Epoch #158: loss=0.2425162693993612
Epoch #159: loss=0.25974777882749384
Epoch #160: loss=0.3012272668155757
Epoch #161: loss=0.32339921390468424
Epoch #162: loss=0.38558616218241776
Epoch #163: loss=0.2883575463836843
Epoch #164: loss=0.25489658185026864
Epoch #165: loss=0.18281428380446
Epoch #166: loss=0.2371953698721799
Epoch #167: loss=0.18919699435884302
Epoch #168: loss=0.1970574909990484
Epoch #169: loss=0.18127605623819612
Epoch #170: loss=0.23120011389255524
Epoch #171: loss=0.19402659515088255
Epoch #172: loss=0.21714648333462802
Epoch #173: loss=0.23943240703506904
Epoch #174: loss=0.23584706099195915
Epoch #175: loss=0.1886322224004702
Epoch #176: loss=0.27491152184930717
Epoch #177: loss=0.16306844997135075
Epoch #178: loss=0.20314111154187808
Epoch #179: loss=0.23421120677482
Epoch #180: loss=0.1872179006988352
Epoch #181: loss=0.18538559431379492
Epoch #182: loss=0.18491406908089464
Epoch #183: loss=0.27198062058199535
Epoch #184: loss=0.18184298480098898
Epoch #185: loss=0.18830711631612343
Epoch #186: loss=0.2275175272741101
Epoch #187: loss=0.218479627574032
Epoch #188: loss=0.21056978167458015
Epoch #189: loss=0.17225114120678467
Epoch #190: loss=0.21164786476980557
Epoch #191: loss=0.208982203155756
Epoch #192: loss=0.21525292843580246
Epoch #193: loss=0.21427662873809988
Epoch #194: loss=0.18230593339963394
Epoch #195: loss=0.25293187085877766
Epoch #196: loss=0.23936202241615814
Epoch #197: loss=0.19492419368841432
Epoch #198: loss=0.15634011274034326
Epoch #199: loss=0.30060231346975674
Epoch #200: loss=0.20436194657602094
Epoch #201: loss=0.19265920567241582
Epoch #202: loss=0.19077257744290613
Epoch #203: loss=0.22436478734016418
Epoch #204: loss=0.18733662129803139
Epoch #205: loss=0.17398932034319098
Epoch #206: loss=0.17416423762386496
Epoch #207: loss=0.20602918551726776
Epoch #208: loss=0.15043806521729988
Epoch #209: loss=0.14220293458889832
Epoch #210: loss=0.1761995872313326
Epoch #211: loss=0.22212117436257275
Epoch #212: loss=0.19298408011143858
Epoch #213: loss=0.14823462983424013
Epoch #214: loss=0.1329432287338105
Epoch #215: loss=0.14244693873280828
Epoch #216: loss=0.14573706212368878
Epoch #217: loss=0.12062980133024129
Epoch #218: loss=0.14873253723437135
Epoch #219: loss=0.13623488067903303
Epoch #220: loss=0.16488725421103564
Epoch #221: loss=0.14385399594902992
Epoch #222: loss=0.17985806614160538
Epoch #223: loss=0.14851403067057783
Epoch #224: loss=0.1328733197667382
Epoch #225: loss=0.1179226106879386
Epoch #226: loss=0.13348973576318135
Epoch #227: loss=0.12770747393369675
Epoch #228: loss=0.1344430958005515
Epoch #229: loss=0.1096471913836219
Epoch #230: loss=0.13571242937310177
Epoch #231: loss=0.12038126062940467
Epoch #232: loss=0.14180513539097525
Epoch #233: loss=0.17626652697270567
Epoch #234: loss=0.11339520171962002
Epoch #235: loss=0.17782046070153062
Epoch #236: loss=0.13306291740049014
Epoch #237: loss=0.14918541654267095
Epoch #238: loss=0.12211106074127284
Epoch #239: loss=0.1644152043895288
Epoch #240: loss=0.1469205507839268
Epoch #241: loss=0.14643186635591768
Epoch #242: loss=0.15472728149457413
Epoch #243: loss=0.13067808815024115
Epoch #244: loss=0.12920165214348922
Epoch #245: loss=0.12666164482520384
Epoch #246: loss=0.1130517279221253
Epoch #247: loss=0.15843113240870563
Epoch #248: loss=0.17622541746293957
Epoch #249: loss=0.17712675153531812

Training time: 0:15:06.512482

Finished.
n2one setting etth1_etth2_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_etth2_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.11217e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.27791e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.51866e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.11217e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3683283480080861, 'MAE': 0.4295533326521765}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_etth2_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.10573e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.17484e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.2904e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.5426473269268547, 'MAE': 0.5388174977955994}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm1_ettm2', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm1_ettm2_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=4.305737224118463
Epoch #1: loss=2.470869989230715
Epoch #2: loss=2.1289289490929963
Epoch #3: loss=1.865030181818995
Epoch #4: loss=1.6710129071926247
Epoch #5: loss=1.5244834875238353
Epoch #6: loss=1.4431334364003148
Epoch #7: loss=1.303015659595358
Epoch #8: loss=1.2041723707626606
Epoch #9: loss=1.1564355266505275
Epoch #10: loss=1.1070812591190995
Epoch #11: loss=1.0355517535374081
Epoch #12: loss=0.9901864158696142
Epoch #13: loss=0.9832182033308621
Epoch #14: loss=0.9069648796114428
Epoch #15: loss=0.8485188155338682
Epoch #16: loss=0.8322882220662874
Epoch #17: loss=0.9095773347492876
Epoch #18: loss=0.8581032752990723
Epoch #19: loss=0.8094936300968302
Epoch #20: loss=0.6989452283957909
Epoch #21: loss=0.7198689312770449
Epoch #22: loss=0.726233774218066
Epoch #23: loss=0.6837259582404432
Epoch #24: loss=0.6613071509476366
Epoch #25: loss=0.6268739402294159
Epoch #26: loss=0.621777128556679
Epoch #27: loss=0.5865305806028431
Epoch #28: loss=0.6146420147912256
Epoch #29: loss=0.6294083184209364
Epoch #30: loss=0.6665421087166359
Epoch #31: loss=0.5831313482646284
Epoch #32: loss=0.6524105596131292
Epoch #33: loss=0.5554533056144056
Epoch #34: loss=0.5266640268523117
Epoch #35: loss=0.43558090205850275
Epoch #36: loss=0.5024630232103939
Epoch #37: loss=0.4472177881619026
Epoch #38: loss=0.5330999401108972
Epoch #39: loss=0.48929428026593963
Epoch #40: loss=0.554338827215392
Epoch #41: loss=0.49659946355326423
Epoch #42: loss=0.4051356017589569
Epoch #43: loss=0.3952152492671177
Epoch #44: loss=0.554734266009824
Epoch #45: loss=0.44851122231319035
Epoch #46: loss=0.4410970709447203
Epoch #47: loss=0.4410606047202801
Epoch #48: loss=0.3506766794056728
Epoch #49: loss=0.40240414286481924
Epoch #50: loss=0.40923724606119355
Epoch #51: loss=0.43914147851795987
Epoch #52: loss=0.3825145261041049
Epoch #53: loss=0.32146101367884666
Epoch #54: loss=0.31490072659377394
Epoch #55: loss=0.37651805117212495
Epoch #56: loss=0.41659835648947746
Epoch #57: loss=0.3642913118518632
Epoch #58: loss=0.4710375491915078
Epoch #59: loss=0.5468382244480068
Epoch #60: loss=0.39569393160014316
Epoch #61: loss=0.3569513651831397
Epoch #62: loss=0.34261127946705655
Epoch #63: loss=0.29355398128772603
Epoch #64: loss=0.308425684941226
Epoch #65: loss=0.3426616433365592
Epoch #66: loss=0.4382128196543661
Epoch #67: loss=0.3960415705524642
Epoch #68: loss=0.30977512330844487
Epoch #69: loss=0.25284683858526164
Epoch #70: loss=0.2521492522852174
Epoch #71: loss=0.2323790470073963
Epoch #72: loss=0.2764936749791277
Epoch #73: loss=0.2887484909131609
Epoch #74: loss=0.23140255438870397
Epoch #75: loss=0.21544987631255183
Epoch #76: loss=0.2629180768954343
Epoch #77: loss=0.2063663714918597
Epoch #78: loss=0.19144495371086845
Epoch #79: loss=0.24272427168385735
Epoch #80: loss=0.255601075188867
Epoch #81: loss=0.2818881915561084
Epoch #82: loss=0.22992202125746627
Epoch #83: loss=0.23444865566903147
Epoch #84: loss=0.22714042997565762
Epoch #85: loss=0.1913723228820439
Epoch #86: loss=0.18065605466735773
Epoch #87: loss=0.19153899930674453
Epoch #88: loss=0.23446833547847024
Epoch #89: loss=0.1759430243280427
Epoch #90: loss=0.20533565919974756
Epoch #91: loss=0.16486519934802218
Epoch #92: loss=0.1566976235601409
Epoch #93: loss=0.14056695515996423
Epoch #94: loss=0.1871689316527597
Epoch #95: loss=0.18010123690654492
Epoch #96: loss=0.16733353610696464
Epoch #97: loss=0.16286012864318386
Epoch #98: loss=0.17162780026937352
Epoch #99: loss=0.17629892751574516
Epoch #100: loss=0.12216636165976524
Epoch #101: loss=0.1684984166560502
Epoch #102: loss=0.13278324015695472
Epoch #103: loss=0.1255321324128529
Epoch #104: loss=0.1933773436166089
Epoch #105: loss=0.1649802197413198
Epoch #106: loss=0.16285560883838554
Epoch #107: loss=0.18795154089557714
Epoch #108: loss=0.14990687434529437
Epoch #109: loss=0.11099358025039065
Epoch #110: loss=0.15189178981657686
Epoch #111: loss=0.13110055774450302
Epoch #112: loss=0.17581011714606448
Epoch #113: loss=0.12107898513304777
Epoch #114: loss=0.11377065249815069
Epoch #115: loss=0.11222026908192141
Epoch #116: loss=0.1938160588515216
Epoch #117: loss=0.12197848319493491
Epoch #118: loss=0.14167064749475183
Epoch #119: loss=0.14252365881512905
Epoch #120: loss=0.22076286336985126
Epoch #121: loss=0.10797429482998519
Epoch #122: loss=0.11470720692184465
Epoch #123: loss=0.13524390847004694
Epoch #124: loss=0.0824875705072592
Epoch #125: loss=0.0788199647233404
Epoch #126: loss=0.11881944209594152
Epoch #127: loss=0.08839412778615952
Epoch #128: loss=0.11757793553687375
Epoch #129: loss=0.14916184216994663
Epoch #130: loss=0.16996613864240975
Epoch #131: loss=0.1428730033723445
Epoch #132: loss=0.1614989248457654
Epoch #133: loss=0.13068919885775138
Epoch #134: loss=0.20560069484957333
Epoch #135: loss=0.11477568238202868
Epoch #136: loss=0.14802529213243518
Epoch #137: loss=0.11169391311705112
Epoch #138: loss=0.0959281288087368
Epoch #139: loss=0.13087509977149553
Epoch #140: loss=0.10718089509113081
Epoch #141: loss=0.0908683966845274
Epoch #142: loss=0.12536792495641216
Epoch #143: loss=0.10833264932293317
Epoch #144: loss=0.21761050126675902
Epoch #145: loss=0.10098655008036515
Epoch #146: loss=0.09869824420532276
Epoch #147: loss=0.11920750809126887
Epoch #148: loss=0.1255384083066521
Epoch #149: loss=0.09628521965752387
Epoch #150: loss=0.0982434761485663
Epoch #151: loss=0.08536187501559997
Epoch #152: loss=0.12792656500020932
Epoch #153: loss=0.10119158196552046
Epoch #154: loss=0.0709016468247463
Epoch #155: loss=0.11532115814243925
Epoch #156: loss=0.0810317821029959
Epoch #157: loss=0.09615960819967861
Epoch #158: loss=0.10561349230079815
Epoch #159: loss=0.10286232270300388
Epoch #160: loss=0.07763271573288687
Epoch #161: loss=0.0766605009678109
Epoch #162: loss=0.07799917186514058
Epoch #163: loss=0.06523311790078878
Epoch #164: loss=0.08177909396331885
Epoch #165: loss=0.06804916487428649
Epoch #166: loss=0.0979679486682189
Epoch #167: loss=0.09825478002814383
Epoch #168: loss=0.1954370543746085
Epoch #169: loss=0.09683827856748269
Epoch #170: loss=0.10922582999899469
Epoch #171: loss=0.12732766164017134
Epoch #172: loss=0.09322521045547107
Epoch #173: loss=0.0729803712717418
Epoch #174: loss=0.0844239866810626
Epoch #175: loss=0.15067607048770476
Epoch #176: loss=0.0758946000373569
Epoch #177: loss=0.08248574999642783
Epoch #178: loss=0.09579771089142766
Epoch #179: loss=0.07454987698844795
Epoch #180: loss=0.07757714734380615
Epoch #181: loss=0.06859153965166931
Epoch #182: loss=0.08917708052643414
Epoch #183: loss=0.08203538394822128
Epoch #184: loss=0.0803515581606791
Epoch #185: loss=0.0646341214727225
Epoch #186: loss=0.06080293372787278
Epoch #187: loss=0.07522209720878766
Epoch #188: loss=0.07998025687090282
Epoch #189: loss=0.06731743198530428
Epoch #190: loss=0.12714307324896598
Epoch #191: loss=0.11926403879348574
Epoch #192: loss=0.07718042615030346
Epoch #193: loss=0.07290130616005125
Epoch #194: loss=0.10349132942742315
Epoch #195: loss=0.148743675957466
Epoch #196: loss=0.07725323942200892
Epoch #197: loss=0.06961479988591425
Epoch #198: loss=0.06219645432228672
Epoch #199: loss=0.2680081982037117
Epoch #200: loss=0.1074524631017241
Epoch #201: loss=0.07046213029915917
Epoch #202: loss=0.13018268828505072
Epoch #203: loss=0.09225318574442945
Epoch #204: loss=0.11788508797000194
Epoch #205: loss=0.06816115789115429
Epoch #206: loss=0.09231500966667101
Epoch #207: loss=0.0689656657391581
Epoch #208: loss=0.062406612046319865
Epoch #209: loss=0.07037621916368089
Epoch #210: loss=0.049986248611119284
Epoch #211: loss=0.0675656361152129
Epoch #212: loss=0.058570562958203516
Epoch #213: loss=0.04727142779477712
Epoch #214: loss=0.04732161832587986
Epoch #215: loss=0.060155262142933645
Epoch #216: loss=0.05202606503434222
Epoch #217: loss=0.061700471580542364
Epoch #218: loss=0.17162062179554124
Epoch #219: loss=0.10197177677062051
Epoch #220: loss=0.08075573796342159
Epoch #221: loss=0.05798222387916055
Epoch #222: loss=0.0602755897742664
Epoch #223: loss=0.059906290298135115
Epoch #224: loss=0.062042394990165686
Epoch #225: loss=0.054571963557652356
Epoch #226: loss=0.0701109131733919
Epoch #227: loss=0.08563017263880064
Epoch #228: loss=0.18220442584876356
Epoch #229: loss=0.11883446500347607
Epoch #230: loss=0.06872233253871572
Epoch #231: loss=0.05592209505366868
Epoch #232: loss=0.06341677258626141
Epoch #233: loss=0.050486936635369885
Epoch #234: loss=0.04025985657012668
Epoch #235: loss=0.04800229657698294
Epoch #236: loss=0.0532649428551567
Epoch #237: loss=0.05593023014030066
Epoch #238: loss=0.060841673631863345
Epoch #239: loss=0.05788530049652889
Epoch #240: loss=0.0390012454851691
Epoch #241: loss=0.050259695275975715
Epoch #242: loss=0.05457063563617653
Epoch #243: loss=0.05770778896865146
Epoch #244: loss=0.06762837266934843
Epoch #245: loss=0.09465231036703134
Epoch #246: loss=0.08001235888564381
Epoch #247: loss=0.07176210439025328
Epoch #248: loss=0.04682730167204964
Epoch #249: loss=0.1160545368068691

Training time: 0:27:58.698461

Finished.
n2one setting etth1_ettm1_ettm2 -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_ettm2_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_ettm1_ettm2', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.81915e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.44533e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.81915e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.36028019627153945, 'MAE': 0.423839715006008}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm1_ettm2 -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_ettm2_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_ettm1_ettm2', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.24739e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.06478e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.24739e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.41444377575770924, 'MAE': 0.4567927618849823}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm1_ettm2 -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_ettm2_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_ettm1_ettm2', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.44419e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.25378707044995125, 'MAE': 0.3384907085473576}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm1_electricity', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm1_electricity_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.6682758605585688
Epoch #1: loss=0.6803865430101884
Epoch #2: loss=0.4781661258246695
Epoch #3: loss=0.37436081939390625
Epoch #4: loss=0.3116417795771343
Epoch #5: loss=0.25884049464907266
Epoch #6: loss=0.23967698697758988
Epoch #7: loss=0.20842654932740867
Epoch #8: loss=0.1934539206919417
Epoch #9: loss=0.16208701156585265
Epoch #10: loss=0.14328786457138779
Epoch #11: loss=0.14077449294362096
Epoch #12: loss=0.1272684678896866
Epoch #13: loss=0.11106363679543357
Epoch #14: loss=0.11974030873218997
Epoch #15: loss=0.10710241624695362
Epoch #16: loss=0.09928905544665183
Epoch #17: loss=0.1048510323352782
Epoch #18: loss=0.08680609242226874
Epoch #19: loss=0.09520108608534467
Epoch #20: loss=0.07825789875611883
Epoch #21: loss=0.06616723026453922
Epoch #22: loss=0.06967265560266982
Epoch #23: loss=0.06496716508020957
Epoch #24: loss=0.06098335411036964
Epoch #25: loss=0.06729830962751379
Epoch #26: loss=0.054978154561204896
Epoch #27: loss=0.046628522072646734
Epoch #28: loss=0.04741359026525664
Epoch #29: loss=0.04923570057607989
Epoch #30: loss=0.05312491970818083
Epoch #31: loss=0.0744045853208212
Epoch #32: loss=0.05374301950774186
Epoch #33: loss=0.04638647757866214
Epoch #34: loss=0.054977950811039955
Epoch #35: loss=0.03859602402590743
Epoch #36: loss=0.04101123405444631
Epoch #37: loss=0.03753626799199917
Epoch #38: loss=0.03951739542430767
Epoch #39: loss=0.03399345829703771
Epoch #40: loss=0.028699842506228427
Epoch #41: loss=0.038834002239843915
Epoch #42: loss=0.034538757110256314
Epoch #43: loss=0.03241714794026649
Epoch #44: loss=0.03562423576817884
Epoch #45: loss=0.0246480261494205
Epoch #46: loss=0.024467142957130827
Epoch #47: loss=0.04236832081792178
Epoch #48: loss=0.03221093947040384
Epoch #49: loss=0.03881134705585057
Epoch #50: loss=0.03348085112391715
Epoch #51: loss=0.03007605125554796
Epoch #52: loss=0.027672554762583436
Epoch #53: loss=0.019549867299324928
Epoch #54: loss=0.022409051176982005
Epoch #55: loss=0.022903695784283907
Epoch #56: loss=0.029973904486157683
Epoch #57: loss=0.03190934468764031
Epoch #58: loss=0.04000963155759889
Epoch #59: loss=0.024473227521715064
Epoch #60: loss=0.022644465201627738
Epoch #61: loss=0.018435546981341103
Epoch #62: loss=0.019434339839039277
Epoch #63: loss=0.027745200212217956
Epoch #64: loss=0.024175199579068385
Epoch #65: loss=0.019962230100087644
Epoch #66: loss=0.02180205444959171
Epoch #67: loss=0.026386189902583165
Epoch #68: loss=0.02597405940121188
Epoch #69: loss=0.01866871913174541
Epoch #70: loss=0.02075351624726249
Epoch #71: loss=0.025794099079195002
Epoch #72: loss=0.024438646813795508
Epoch #73: loss=0.019385309181633545
Epoch #74: loss=0.01693402192140531
Epoch #75: loss=0.023666301553665076
Epoch #76: loss=0.023598213689017128
Epoch #77: loss=0.019256113913524237
Epoch #78: loss=0.022371117994539537
Epoch #79: loss=0.02528908378911647
Epoch #80: loss=0.028352209977094072
Epoch #81: loss=0.04216843369969093
Epoch #82: loss=0.019471123975126077
Epoch #83: loss=0.013436943819062306
Epoch #84: loss=0.017998880033647767
Epoch #85: loss=0.01550599070184158
Epoch #86: loss=0.027572897281758706
Epoch #87: loss=0.015020534136898508
Epoch #88: loss=0.023578608784602082
Epoch #89: loss=0.02389904412346175
Epoch #90: loss=0.018698083391347157
Epoch #91: loss=0.021461420069904695
Epoch #92: loss=0.01774625566044196
Epoch #93: loss=0.021456940106636842
Epoch #94: loss=0.015557708492389933
Epoch #95: loss=0.021805136584729
Epoch #96: loss=0.017150426281418288
Epoch #97: loss=0.014741176098363973
Epoch #98: loss=0.012433085153270842
Epoch #99: loss=0.0167402887384127
Epoch #100: loss=0.017956254358202833
Epoch #101: loss=0.01470489133696091
Epoch #102: loss=0.015503951608324231
Epoch #103: loss=0.01285639092319983
Epoch #104: loss=0.016436933214772097
Epoch #105: loss=0.01234138741863309
Epoch #106: loss=0.017073357193098902
Epoch #107: loss=0.02163889019006237
Epoch #108: loss=0.019244691637237514
Epoch #109: loss=0.02716898845555398
Epoch #110: loss=0.0145364921621753
Epoch #111: loss=0.012374253788342079
Epoch #112: loss=0.03718306036400924
Epoch #113: loss=0.013120068614762606
Epoch #114: loss=0.014892086863330947
Epoch #115: loss=0.015024361942563711
Epoch #116: loss=0.010350591971320553
Epoch #117: loss=0.016828029905171148
Epoch #118: loss=0.028646325208672534
Epoch #119: loss=0.01948874164097956
Epoch #120: loss=0.015147872381791428
Epoch #121: loss=0.013937531530535657
Epoch #122: loss=0.01315133556878815
Epoch #123: loss=0.011571147778139458
Epoch #124: loss=0.011205974534280313
Epoch #125: loss=0.013149932085242464
Epoch #126: loss=0.01301699668473968
Epoch #127: loss=0.015161573065439332
Epoch #128: loss=0.009501369741891585
Epoch #129: loss=0.011692745029080829
Epoch #130: loss=0.013691957593396866
Epoch #131: loss=0.015595834725605088
Epoch #132: loss=0.012737939882354542
Epoch #133: loss=0.015422342048242282
Epoch #134: loss=0.021831937198654904
Epoch #135: loss=0.014139629200761616
Epoch #136: loss=0.012801956860822486
Epoch #137: loss=0.01151493925582013
Epoch #138: loss=0.01155510121148772
Epoch #139: loss=0.01295233779338911
Epoch #140: loss=0.01802672254444295
Epoch #141: loss=0.011275412416419394
Epoch #142: loss=0.01585707955929838
Epoch #143: loss=0.026136852672754906
Epoch #144: loss=0.01582094678530953
Epoch #145: loss=0.0164386382304849
Epoch #146: loss=0.016523505887978195
Epoch #147: loss=0.01514686339594572
Epoch #148: loss=0.011495983658892798
Epoch #149: loss=0.012491735100545605
Epoch #150: loss=0.009682084635443709
Epoch #151: loss=0.010114922611987915
Epoch #152: loss=0.010023449083043614
Epoch #153: loss=0.01350962418539499
Epoch #154: loss=0.009895428385864394
Epoch #155: loss=0.0126178476530722
Epoch #156: loss=0.01465218584465308
Epoch #157: loss=0.019333991509687794
Epoch #158: loss=0.013757295730032005
Epoch #159: loss=0.00825703842719951
Epoch #160: loss=0.011566472257649564
Epoch #161: loss=0.010562275344393269
Epoch #162: loss=0.014808452886990807
Epoch #163: loss=0.011596457464558658
Epoch #164: loss=0.014231362092139743
Epoch #165: loss=0.008476853268502615
Epoch #166: loss=0.01576452251131561
Epoch #167: loss=0.011541113360258847
Epoch #168: loss=0.009149948656740996
Epoch #169: loss=0.022055977335952465
Epoch #170: loss=0.01694462021983127
Epoch #171: loss=0.012256892838935673
Epoch #172: loss=0.03944491444909011
Epoch #173: loss=0.020402094337074114
Epoch #174: loss=0.013039398023063333
Epoch #175: loss=0.011810079331140262
Epoch #176: loss=0.011117074074214021
Epoch #177: loss=0.012570346431232506
Epoch #178: loss=0.008362932175680841
Epoch #179: loss=0.01157992945229882
Epoch #180: loss=0.015987986765024432
Epoch #181: loss=0.012934205002786048
Epoch #182: loss=0.01040387539581772
Epoch #183: loss=0.008769551588766343
Epoch #184: loss=0.01149437350277984
Epoch #185: loss=0.008290449554422749
Epoch #186: loss=0.013793759787342564
Epoch #187: loss=0.01347725488369801
Epoch #188: loss=0.013554142769594378
Epoch #189: loss=0.014867204446898454
Epoch #190: loss=0.011819368083569823
Epoch #191: loss=0.010398333501084473
Epoch #192: loss=0.0151778599872339
Epoch #193: loss=0.013207134092570032
Epoch #194: loss=0.010578016704154423
Epoch #195: loss=0.013225788961420149
Epoch #196: loss=0.010720288507783907
Epoch #197: loss=0.008272874411583567
Epoch #198: loss=0.009403203815636623
Epoch #199: loss=0.012396243560556488
Epoch #200: loss=0.021831371958311207
Epoch #201: loss=0.014106542831334865
Epoch #202: loss=0.010254303054715119
Epoch #203: loss=0.010153521421182747
Epoch #204: loss=0.007747226100154688
Epoch #205: loss=0.009909823218705325
Epoch #206: loss=0.012660889003074187
Epoch #207: loss=0.010772203062118407
Epoch #208: loss=0.012732649540870689
Epoch #209: loss=0.015691652293227734
Epoch #210: loss=0.01495192004958371
Epoch #211: loss=0.010591187510243823
Epoch #212: loss=0.016215743314836085
Epoch #213: loss=0.00824722967714629
Epoch #214: loss=0.008372560630380423
Epoch #215: loss=0.007494388503100789
Epoch #216: loss=0.00829984985110295
Epoch #217: loss=0.012533859428341822
Epoch #218: loss=0.013250301690695939
Epoch #219: loss=0.014704978237307018
Epoch #220: loss=0.027068984544366202
Epoch #221: loss=0.015617712572557648
Epoch #222: loss=0.00949738655036046
Epoch #223: loss=0.010147788727574962
Epoch #224: loss=0.01228880515898328
Epoch #225: loss=0.011654551750255726
Epoch #226: loss=0.008142595297082089
Epoch #227: loss=0.008491337593561753
Epoch #228: loss=0.011118229457649752
Epoch #229: loss=0.009826117262926233
Epoch #230: loss=0.016805880635895748
Epoch #231: loss=0.015480665632030462
Epoch #232: loss=0.011235213970729758
Epoch #233: loss=0.01204814954434527
Epoch #234: loss=0.009360959157581197
Epoch #235: loss=0.007987133589154934
Epoch #236: loss=0.009185520615456159
Epoch #237: loss=0.009751550146089426
Epoch #238: loss=0.018007958484974974
Epoch #239: loss=0.011921377610799836
Epoch #240: loss=0.009062445303133297
Epoch #241: loss=0.01641693927936948
Epoch #242: loss=0.011102660154583137
Epoch #243: loss=0.011459756130215253
Epoch #244: loss=0.01094165227889663
Epoch #245: loss=0.009066549794793755
Epoch #246: loss=0.01611448268428071
Epoch #247: loss=0.008122440020345663
Epoch #248: loss=0.011962365516863907
Epoch #249: loss=0.01138878812191659

Training time: 4:42:51.766703

Finished.
n2one setting etth1_ettm1_electricity -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_electricity_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_ettm1_electricity', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.51087e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.96715e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.72519e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.51087e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 1.0067025869984463, 'MAE': 0.7845510000805651}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm1_electricity -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_electricity_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_ettm1_electricity', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.77117e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3245712040597195, 'MAE': 0.38271989469480655}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm1_traffic', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm1_traffic_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.0037075815553016
Epoch #1: loss=0.36859084062955594
Epoch #2: loss=0.2542174898426641
Epoch #3: loss=0.1901091377335516
Epoch #4: loss=0.15241461521522565
Epoch #5: loss=0.13586242135444826
Epoch #6: loss=0.10967008963819933
Epoch #7: loss=0.08938474819296971
Epoch #8: loss=0.08641926244811408
Epoch #9: loss=0.07418842245295475
Epoch #10: loss=0.06886975682573393
Epoch #11: loss=0.054721843256001275
Epoch #12: loss=0.05166321803275919
Epoch #13: loss=0.05157144872566939
Epoch #14: loss=0.04809585124603473
Epoch #15: loss=0.0485624587581366
Epoch #16: loss=0.04390919034538621
Epoch #17: loss=0.05074031801116441
Epoch #18: loss=0.037787957829211585
Epoch #19: loss=0.03256164168044713
Epoch #20: loss=0.03835056432276774
Epoch #21: loss=0.03699969376982402
Epoch #22: loss=0.03392047963160704
Epoch #23: loss=0.03984660143006212
Epoch #24: loss=0.025511797890860843
Epoch #25: loss=0.027219733522294766
Epoch #26: loss=0.03707453579951438
Epoch #27: loss=0.029817392767290583
Epoch #28: loss=0.025979375653564188
Epoch #29: loss=0.025584945602961606
Epoch #30: loss=0.025663027749132282
Epoch #31: loss=0.026715743697224587
Epoch #32: loss=0.033456140862306874
Epoch #33: loss=0.03118165755612691
Epoch #34: loss=0.024232418589831054
Epoch #35: loss=0.025765457657954273
Epoch #36: loss=0.02660399168155643
Epoch #37: loss=0.02500737248132778
Epoch #38: loss=0.02022270715718729
Epoch #39: loss=0.021750128185059028
Epoch #40: loss=0.021477673215651357
Epoch #41: loss=0.02401721858133731
Epoch #42: loss=0.021685010280700887
Epoch #43: loss=0.019693996830822222
Epoch #44: loss=0.021323298616070217
Epoch #45: loss=0.01999678996329418
Epoch #46: loss=0.017781485949870494
Epoch #47: loss=0.02707737088983942
Epoch #48: loss=0.022994237145956668
Epoch #49: loss=0.020228229961966545
Epoch #50: loss=0.017723617397992216
Epoch #51: loss=0.02873687578897013
Epoch #52: loss=0.019362153283476468
Epoch #53: loss=0.021396451351955132
Epoch #54: loss=0.01483788174902491
Epoch #55: loss=0.01910102603491065
Epoch #56: loss=0.01390370596659936
Epoch #57: loss=0.016313481999862812
Epoch #58: loss=0.024641801959726515
Epoch #59: loss=0.015342661356176408
Epoch #60: loss=0.01800484000870545
Epoch #61: loss=0.018053841105310393
Epoch #62: loss=0.017173234221528135
Epoch #63: loss=0.015170330295024376
Epoch #64: loss=0.021466571391581302
Epoch #65: loss=0.014940878617959574
Epoch #66: loss=0.024983567133577626
Epoch #67: loss=0.013924048819072513
Epoch #68: loss=0.01602327315859756
Epoch #69: loss=0.01868339740692384
Epoch #70: loss=0.01985623882527844
Epoch #71: loss=0.014824647488388689
Epoch #72: loss=0.014130002598077144
Epoch #73: loss=0.013554821862800798
Epoch #74: loss=0.015289537566852893
Epoch #75: loss=0.015479499938043194
Epoch #76: loss=0.01647558816442721
Epoch #77: loss=0.018629519832029474
Epoch #78: loss=0.010682603416518595
Epoch #79: loss=0.015713017576688963
Epoch #80: loss=0.013003756893290714
Epoch #81: loss=0.017887356842600805
Epoch #82: loss=0.01673056978080157
Epoch #83: loss=0.012701164938491936
Epoch #84: loss=0.012981316338978517
Epoch #85: loss=0.013132203533686234
Epoch #86: loss=0.01964371130263978
Epoch #87: loss=0.014366629321540874
Epoch #88: loss=0.011701136447796174
Epoch #89: loss=0.016249261624431133
Epoch #90: loss=0.013250953889986374
Epoch #91: loss=0.015803461868827896
Epoch #92: loss=0.01551936892878571
Epoch #93: loss=0.014253565309643983
Epoch #94: loss=0.01490147341458148
Epoch #95: loss=0.024561772622109856
Epoch #96: loss=0.010716967745049094
Epoch #97: loss=0.009747242800602346
Epoch #98: loss=0.015365276265980686
Epoch #99: loss=0.014018706847689993
Epoch #100: loss=0.013674057198890793
Epoch #101: loss=0.010349878984313611
Epoch #102: loss=0.010166855589986054
Epoch #103: loss=0.01687187802728493
Epoch #104: loss=0.010298960247647218
Epoch #105: loss=0.01478155969376861
Epoch #106: loss=0.014635420851713703
Epoch #107: loss=0.014073303884883485
Epoch #108: loss=0.014443760023790343
Epoch #109: loss=0.010991530842461957
Epoch #110: loss=0.010158239020364073
Epoch #111: loss=0.013897807069390018
Epoch #112: loss=0.015799341633001777
Epoch #113: loss=0.015966230201063972
Epoch #114: loss=0.0125218950662119
Epoch #115: loss=0.00805769522944915
Epoch #116: loss=0.01307080326795668
Epoch #117: loss=0.013339723435472644
Epoch #118: loss=0.011487035237289753
Epoch #119: loss=0.019062436063954507
Epoch #120: loss=0.01283774810116566
Epoch #121: loss=0.01262461017021947
Epoch #122: loss=0.012010425544370016
Epoch #123: loss=0.014470504753957026
Epoch #124: loss=0.013708597603048971
Epoch #125: loss=0.01255160238189009
Epoch #126: loss=0.02155102112985994
Epoch #127: loss=0.012453702343009354
Epoch #128: loss=0.011807786176657167
Epoch #129: loss=0.009940070200702228
Epoch #130: loss=0.011130843823874867
Epoch #131: loss=0.01418006299127228
Epoch #132: loss=0.008742715774926843
Epoch #133: loss=0.013039794752694433
Epoch #134: loss=0.011327013002201883
Epoch #135: loss=0.013753412158191416
Epoch #136: loss=0.012942546460925025
Epoch #137: loss=0.011025014382142796
Epoch #138: loss=0.016103785774280607
Epoch #139: loss=0.008960007966826115
Epoch #140: loss=0.013473905825495338
Epoch #141: loss=0.009281882869229527
Epoch #142: loss=0.012505069667506839
Epoch #143: loss=0.01429869534777853
Epoch #144: loss=0.01155217153528528
Epoch #145: loss=0.008828867758017044
Epoch #146: loss=0.012661157343510157
Epoch #147: loss=0.011918376253759726
Epoch #148: loss=0.014476367837117074
Epoch #149: loss=0.013038767814611095
Epoch #150: loss=0.014182836935684794
Epoch #151: loss=0.0158656335822591
Epoch #152: loss=0.009292478884791225
Epoch #153: loss=0.010834597383660077
Epoch #154: loss=0.013361983620498822
Epoch #155: loss=0.013647026219405233
Epoch #156: loss=0.015133410733456417
Epoch #157: loss=0.017073024997328254
Epoch #158: loss=0.01319127777414079
Epoch #159: loss=0.009485721556633176
Epoch #160: loss=0.009560464685984532
Epoch #161: loss=0.011085858223982954
Epoch #162: loss=0.011243038696883641
Epoch #163: loss=0.009884248547959116
Epoch #164: loss=0.009164621371821174
Epoch #165: loss=0.015332822942813932
Epoch #166: loss=0.013574015022843416
Epoch #167: loss=0.010077169766720379
Epoch #168: loss=0.007650618153126164
Epoch #169: loss=0.011475379349642687
Epoch #170: loss=0.009482478623327883
Epoch #171: loss=0.012403477735394765
Epoch #172: loss=0.013774178859735416
Epoch #173: loss=0.00889986563487665
Epoch #174: loss=0.011079433209306443
Epoch #175: loss=0.01018106848529111
Epoch #176: loss=0.01248698182958337
Epoch #177: loss=0.009959317340111408
Epoch #178: loss=0.01713373559811192
Epoch #179: loss=0.0100734840018049
Epoch #180: loss=0.00998143932715307
Epoch #181: loss=0.010224295244056106
Epoch #182: loss=0.01516120624311787
Epoch #183: loss=0.025387897166166858
Epoch #184: loss=0.008168187694966697
Epoch #185: loss=0.006596292961380227
Epoch #186: loss=0.01237786741041253
Epoch #187: loss=0.01728670531728395
Epoch #188: loss=0.007500368635605396
Epoch #189: loss=0.01035953231899343
Epoch #190: loss=0.011239304253467707
Epoch #191: loss=0.011673338794439174
Epoch #192: loss=0.012462986847227017
Epoch #193: loss=0.010346845089357388
Epoch #194: loss=0.007994526538041927
Epoch #195: loss=0.011621443539082644
Epoch #196: loss=0.01114567384422778
Epoch #197: loss=0.01118759599050298
Epoch #198: loss=0.011641773761204439
Epoch #199: loss=0.013907087505437878
Epoch #200: loss=0.00881623801888054
Epoch #201: loss=0.008006701264399783
Epoch #202: loss=0.009677411173883725
Epoch #203: loss=0.007189816775798166
Epoch #204: loss=0.01343292074713893
Epoch #205: loss=0.005911250868285317
Epoch #206: loss=0.011543639936032626
Epoch #207: loss=0.014914202409950535
Epoch #208: loss=0.011419101452768452
Epoch #209: loss=0.007554499396639419
Epoch #210: loss=0.014114081876637515
Epoch #211: loss=0.00902834470047806
Epoch #212: loss=0.007920645265634945
Epoch #213: loss=0.00935410755975516
Epoch #214: loss=0.008870689507437584
Epoch #215: loss=0.01132553110953929
Epoch #216: loss=0.013516705152290922
Epoch #217: loss=0.011798889927476094
Epoch #218: loss=0.01286738372522946
Epoch #219: loss=0.007310908083110751
Epoch #220: loss=0.011129953808664472
Epoch #221: loss=0.011764167886097063
Epoch #222: loss=0.006881624605836123
Epoch #223: loss=0.009954083918662284
Epoch #224: loss=0.010497055477770283
Epoch #225: loss=0.010209969234578734
Epoch #226: loss=0.013915692080395687
Epoch #227: loss=0.009053883235438579
Epoch #228: loss=0.008236059384316005
Epoch #229: loss=0.007417595531214002
Epoch #230: loss=0.014266338499080369
Epoch #231: loss=0.012691814320124773
Epoch #232: loss=0.007222650540941024
Epoch #233: loss=0.008725867017065783
Epoch #234: loss=0.009280639494918983
Epoch #235: loss=0.016208512251283867
Epoch #236: loss=0.008419303680817723
Epoch #237: loss=0.009366504228422523
Epoch #238: loss=0.007532141357627221
Epoch #239: loss=0.015192175548525649
Epoch #240: loss=0.00506470773976947
Epoch #241: loss=0.008671979260436108
Epoch #242: loss=0.006127415817276084
Epoch #243: loss=0.011007510553686602
Epoch #244: loss=0.01826257933784787
Epoch #245: loss=0.013747815251339158
Epoch #246: loss=0.007379730646607641
Epoch #247: loss=0.01099520407779809
Epoch #248: loss=0.008850876737365483
Epoch #249: loss=0.008868118657714644

Training time: 10:24:28.526769

Finished.
n2one setting etth1_ettm1_traffic -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_traffic_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_ettm1_traffic', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.71746e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.60587e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.98014e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.71746e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4086460799400779, 'MAE': 0.4541357626709094}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm1_traffic -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_traffic_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_ettm1_traffic', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.09074e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.87831e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.68772e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.09074e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.44817328793828326, 'MAE': 0.50471998479273}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm1_traffic -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_traffic_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_ettm1_traffic', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.10364e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3671407535128802, 'MAE': 0.39657875968674067}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm1_weather', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm1_weather_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=4.603882372379303
Epoch #1: loss=2.7755211266604336
Epoch #2: loss=2.269577847285704
Epoch #3: loss=2.130413071675734
Epoch #4: loss=1.8631591796875
Epoch #5: loss=1.6656111831014806
Epoch #6: loss=1.507679676467722
Epoch #7: loss=1.4359337037259883
Epoch #8: loss=1.316168329932473
Epoch #9: loss=1.1513045728206635
Epoch #10: loss=1.1313438591631977
Epoch #11: loss=1.1686602573503146
Epoch #12: loss=1.0904944430698047
Epoch #13: loss=0.9755745272744786
Epoch #14: loss=0.8771839846264232
Epoch #15: loss=0.8913791382854636
Epoch #16: loss=0.8222252089868892
Epoch #17: loss=0.8408936126665636
Epoch #18: loss=0.8675588166171854
Epoch #19: loss=0.798938972028819
Epoch #20: loss=0.7887621142647483
Epoch #21: loss=0.8476255156777122
Epoch #22: loss=0.8538535061207685
Epoch #23: loss=0.805679359219291
Epoch #24: loss=0.6551912311803211
Epoch #25: loss=0.6733375909653577
Epoch #26: loss=0.659494280137799
Epoch #27: loss=0.6309867121956565
Epoch #28: loss=0.633367543193427
Epoch #29: loss=0.6483020626685836
Epoch #30: loss=0.6039038354700262
Epoch #31: loss=0.6188066134398634
Epoch #32: loss=0.5171986411918293
Epoch #33: loss=0.5215096033432267
Epoch #34: loss=0.5740577707236464
Epoch #35: loss=0.6081148501146924
Epoch #36: loss=0.5461102954365991
Epoch #37: loss=0.5436094423586671
Epoch #38: loss=0.5616353438659147
Epoch #39: loss=0.473395010964437
Epoch #40: loss=0.45272958143190906
Epoch #41: loss=0.43037675795229996
Epoch #42: loss=0.4205242618918419
Epoch #43: loss=0.4903032590042461
Epoch #44: loss=0.4625115448778326
Epoch #45: loss=0.475243670696562
Epoch #46: loss=0.434581648897041
Epoch #47: loss=0.553081641820344
Epoch #48: loss=0.5056929317387667
Epoch #49: loss=0.4329539777880365
Epoch #50: loss=0.38640710948543117
Epoch #51: loss=0.3869933909313245
Epoch #52: loss=0.35435725071213464
Epoch #53: loss=0.3283098363740878
Epoch #54: loss=0.36948324604467914
Epoch #55: loss=0.39771008864045143
Epoch #56: loss=0.3568605716255578
Epoch #57: loss=0.34617253122004593
Epoch #58: loss=0.35138258879834955
Epoch #59: loss=0.34819486330855975
Epoch #60: loss=0.40922842479564925
Epoch #61: loss=0.3840025534684008
Epoch #62: loss=0.43754389814355155
Epoch #63: loss=0.37918240475383674
Epoch #64: loss=0.3814302918247201
Epoch #65: loss=0.3387823457067663
Epoch #66: loss=0.32433741946112027
Epoch #67: loss=0.33368573134595697
Epoch #68: loss=0.32450956326316704
Epoch #69: loss=0.3405491484498436
Epoch #70: loss=0.3118939877233722
Epoch #71: loss=0.3506435084749352
Epoch #72: loss=0.29972648925401946
Epoch #73: loss=0.4268598079004071
Epoch #74: loss=0.42334181104194035
Epoch #75: loss=0.2764177623797547
Epoch #76: loss=0.23619391684505073
Epoch #77: loss=0.26403100991790945
Epoch #78: loss=0.2588244810361754
Epoch #79: loss=0.24758252552287144
Epoch #80: loss=0.24676859243349594
Epoch #81: loss=0.21573502180928533
Epoch #82: loss=0.20852934569120407
Epoch #83: loss=0.2589005822823806
Epoch #84: loss=0.20344938998195258
Epoch #85: loss=0.19039193371480162
Epoch #86: loss=0.2812888100743294
Epoch #87: loss=0.2312375263056972
Epoch #88: loss=0.22766932218589567
Epoch #89: loss=0.21580206789076328
Epoch #90: loss=0.22063998530872844
Epoch #91: loss=0.19881366261027075
Epoch #92: loss=0.2390727112069726
Epoch #93: loss=0.22766817513514648
Epoch #94: loss=0.24298388917337765
Epoch #95: loss=0.2126508637924086
Epoch #96: loss=0.19386168433861298
Epoch #97: loss=0.14093152425167235
Epoch #98: loss=0.15384867838160557
Epoch #99: loss=0.2255653737282211
Epoch #100: loss=0.2362794651734558
Epoch #101: loss=0.20210233897986737
Epoch #102: loss=0.2234247370877049
Epoch #103: loss=0.19940020465715366
Epoch #104: loss=0.24714008972726084
Epoch #105: loss=0.20746635137633843
Epoch #106: loss=0.12936231654814698
Epoch #107: loss=0.14298111555928533
Epoch #108: loss=0.17629613524133508
Epoch #109: loss=0.20584751589393074
Epoch #110: loss=0.14455474125729365
Epoch #111: loss=0.14264097344130278
Epoch #112: loss=0.14573467709124088
Epoch #113: loss=0.154099549759518
Epoch #114: loss=0.14993074019862848
Epoch #115: loss=0.20492089091038163
Epoch #116: loss=0.17043996018103577
Epoch #117: loss=0.1442780653014779
Epoch #118: loss=0.1447479688477787
Epoch #119: loss=0.11892454804513942
Epoch #120: loss=0.14573755623264747
Epoch #121: loss=0.18162864395840603
Epoch #122: loss=0.17612631822174246
Epoch #123: loss=0.10187589885158972
Epoch #124: loss=0.11010783622888001
Epoch #125: loss=0.12704512929882517
Epoch #126: loss=0.15425770822912455
Epoch #127: loss=0.14091703613204035
Epoch #128: loss=0.1182734829542989
Epoch #129: loss=0.18339116481894796
Epoch #130: loss=0.12049969463524493
Epoch #131: loss=0.127837540412491
Epoch #132: loss=0.11274148159745065
Epoch #133: loss=0.13335551905699752
Epoch #134: loss=0.11536191568963906
Epoch #135: loss=0.13783193383873862
Epoch #136: loss=0.1701262936165387
Epoch #137: loss=0.15457568410784006
Epoch #138: loss=0.11528875373981216
Epoch #139: loss=0.11105854669585824
Epoch #140: loss=0.12109782826155424
Epoch #141: loss=0.12676104738123037
Epoch #142: loss=0.09294454321603883
Epoch #143: loss=0.10529919988899068
Epoch #144: loss=0.1666303812102838
Epoch #145: loss=0.13461081010543488
Epoch #146: loss=0.11366767453199084
Epoch #147: loss=0.0897492254999551
Epoch #148: loss=0.10509225277399475
Epoch #149: loss=0.13264673338695007
Epoch #150: loss=0.10337487341497432
Epoch #151: loss=0.10056156737052581
Epoch #152: loss=0.10550478858534586
Epoch #153: loss=0.13526974652301182
Epoch #154: loss=0.109569093297151
Epoch #155: loss=0.10191316856071353
Epoch #156: loss=0.13125811428339643
Epoch #157: loss=0.12753523153845558
Epoch #158: loss=0.1355734518305822
Epoch #159: loss=0.10866971512917768
Epoch #160: loss=0.07888049623844298
Epoch #161: loss=0.1110678611704233
Epoch #162: loss=0.09704846740615639
Epoch #163: loss=0.09617630214515058
Epoch #164: loss=0.21479416706345297
Epoch #165: loss=0.17721295898610895
Epoch #166: loss=0.10593159217387438
Epoch #167: loss=0.11001229557124051
Epoch #168: loss=0.09072822743010792
Epoch #169: loss=0.10440168817612258
Epoch #170: loss=0.10282931142401966
Epoch #171: loss=0.11498762942342595
Epoch #172: loss=0.10671418249099092
Epoch #173: loss=0.07436835458925502
Epoch #174: loss=0.07736176392063498
Epoch #175: loss=0.08534303595396606
Epoch #176: loss=0.09887406907298348
Epoch #177: loss=0.07176287506114352
Epoch #178: loss=0.06905294404449788
Epoch #179: loss=0.10540529577569528
Epoch #180: loss=0.08144008088856936
Epoch #181: loss=0.08868208413266322
Epoch #182: loss=0.08899958207356659
Epoch #183: loss=0.05828451830893755
Epoch #184: loss=0.07470860277217897
Epoch #185: loss=0.09625479515472596
Epoch #186: loss=0.08284792433154177
Epoch #187: loss=0.17361491592600942
Epoch #188: loss=0.0788256512446837
Epoch #189: loss=0.22050981697711078
Epoch #190: loss=0.16182066123424607
Epoch #191: loss=0.15116039811718193
Epoch #192: loss=0.1711684489114718
Epoch #193: loss=0.09826715540310199
Epoch #194: loss=0.1162842396138744
Epoch #195: loss=0.08711449353193695
Epoch #196: loss=0.08237754553556442
Epoch #197: loss=0.13944576966406946
Epoch #198: loss=0.11634955275803804
Epoch #199: loss=0.09745141690258276
Epoch #200: loss=0.07540052951398221
Epoch #201: loss=0.08737524829550901
Epoch #202: loss=0.07075605674816127
Epoch #203: loss=0.07828614037399265
Epoch #204: loss=0.061370880575850606
Epoch #205: loss=0.07977323953739622
Epoch #206: loss=0.06153990266929296
Epoch #207: loss=0.057254577478901905
Epoch #208: loss=0.04732318885031749
Epoch #209: loss=0.09604506040076641
Epoch #210: loss=0.07644021331163292
Epoch #211: loss=0.0948275495743887
Epoch #212: loss=0.06766017816368151
Epoch #213: loss=0.05196619480424984
Epoch #214: loss=0.08002945768054236
Epoch #215: loss=0.04802036729895256
Epoch #216: loss=0.0496790830723264
Epoch #217: loss=0.06131075695157051
Epoch #218: loss=0.0578122517644343
Epoch #219: loss=0.056545818065801126
Epoch #220: loss=0.04837132721546699
Epoch #221: loss=0.045128862765109676
Epoch #222: loss=0.08055507978001102
Epoch #223: loss=0.07757530098950322
Epoch #224: loss=0.04808242333290929
Epoch #225: loss=0.06173967856871472
Epoch #226: loss=0.055254579352384266
Epoch #227: loss=0.0836177807809277
Epoch #228: loss=0.07180806787007234
Epoch #229: loss=0.05169718457512896
Epoch #230: loss=0.05217626928986812
Epoch #231: loss=0.04311500659043139
Epoch #232: loss=0.08360193149102005
Epoch #233: loss=0.05378238422880796
Epoch #234: loss=0.04341623365921392
Epoch #235: loss=0.05455620790069753
Epoch #236: loss=0.04922131815163249
Epoch #237: loss=0.05584137076088651
Epoch #238: loss=0.04614699733528224
Epoch #239: loss=0.09690175565298308
Epoch #240: loss=0.06375813149762424
Epoch #241: loss=0.05973591263913973
Epoch #242: loss=0.0686208300546489
Epoch #243: loss=0.053866866235197944
Epoch #244: loss=0.05961752115664157
Epoch #245: loss=0.05836802134713666
Epoch #246: loss=0.0472039309203286
Epoch #247: loss=0.05363120441325009
Epoch #248: loss=0.048344732452691955
Epoch #249: loss=0.09917258886112408

Training time: 0:42:53.364539

Finished.
n2one setting etth1_ettm1_weather -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_weather_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_ettm1_weather', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.57687e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.99745e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.57687e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3628916177355815, 'MAE': 0.4237377930587896}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm1_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_weather_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_ettm1_weather', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.73181e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.19984673483601734, 'MAE': 0.31175139418022724}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm1_exchange', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm1_exchange_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=4.227236110430497
Epoch #1: loss=2.3026437300902147
Epoch #2: loss=2.0438167934234324
Epoch #3: loss=1.93338877421159
Epoch #4: loss=1.834675839314094
Epoch #5: loss=1.6513360096858098
Epoch #6: loss=1.6100891736837535
Epoch #7: loss=1.5359532282902644
Epoch #8: loss=1.4724708703848033
Epoch #9: loss=1.4085935079134428
Epoch #10: loss=1.3200496343465953
Epoch #11: loss=1.2484097939271193
Epoch #12: loss=1.2443085404542775
Epoch #13: loss=1.289714059004417
Epoch #14: loss=1.2122259575587053
Epoch #15: loss=1.0968014162320356
Epoch #16: loss=1.0188264869726622
Epoch #17: loss=1.0158183139104109
Epoch #18: loss=0.9669819703468909
Epoch #19: loss=1.0302192981426532
Epoch #20: loss=0.9240396389594445
Epoch #21: loss=0.9874622936432178
Epoch #22: loss=0.9311221333650442
Epoch #23: loss=0.9554748833179474
Epoch #24: loss=0.856116193991441
Epoch #25: loss=0.8068412336019369
Epoch #26: loss=0.8386140305262345
Epoch #27: loss=0.884926784497041
Epoch #28: loss=0.8556196918854346
Epoch #29: loss=0.9038955110770005
Epoch #30: loss=0.8791970587693728
Epoch #31: loss=0.7681141266456017
Epoch #32: loss=0.7377827832332025
Epoch #33: loss=0.7805276329700763
Epoch #34: loss=0.6629075751854823
Epoch #35: loss=0.7311730843323928
Epoch #36: loss=0.8469529564564044
Epoch #37: loss=0.7296214734132473
Epoch #38: loss=0.7592183580765357
Epoch #39: loss=0.6459047198295593
Epoch #40: loss=0.6914624709349412
Epoch #41: loss=0.7362806361455184
Epoch #42: loss=0.7025174830968564
Epoch #43: loss=0.676103229706104
Epoch #44: loss=0.657101564682447
Epoch #45: loss=0.6696094366220328
Epoch #46: loss=0.5758152237305274
Epoch #47: loss=0.5354522776145202
Epoch #48: loss=0.5509210779116704
Epoch #49: loss=0.5603228887686362
Epoch #50: loss=0.5487427287376844
Epoch #51: loss=0.5779167929520974
Epoch #52: loss=0.547729499064959
Epoch #53: loss=0.7282153826493484
Epoch #54: loss=0.6648286202779183
Epoch #55: loss=0.5583944320678711
Epoch #56: loss=0.5500193650905902
Epoch #57: loss=0.5750950425863266
Epoch #58: loss=0.5301492787324465
Epoch #59: loss=0.49102026797257936
Epoch #60: loss=0.5588650416869384
Epoch #61: loss=0.5200253954300513
Epoch #62: loss=0.4466124176979065
Epoch #63: loss=0.533088811315023
Epoch #64: loss=0.47989414403071773
Epoch #65: loss=0.5096697692687695
Epoch #66: loss=0.5393064858821722
Epoch #67: loss=0.45370615961459965
Epoch #68: loss=0.4253215021811999
Epoch #69: loss=0.4038020292153725
Epoch #70: loss=0.5009009712017499
Epoch #71: loss=0.4634171598232709
Epoch #72: loss=0.46802785190252155
Epoch #73: loss=0.36835063993930817
Epoch #74: loss=0.5039718300104141
Epoch #75: loss=0.4400646801178272
Epoch #76: loss=0.48524399044422
Epoch #77: loss=0.4321348329003041
Epoch #78: loss=0.45634195093925184
Epoch #79: loss=0.4076899719926027
Epoch #80: loss=0.4870578211087447
Epoch #81: loss=0.45987439728700197
Epoch #82: loss=0.4002804526915917
Epoch #83: loss=0.4331299845988934
Epoch #84: loss=0.4329121903731273
Epoch #85: loss=0.3832075297832489
Epoch #86: loss=0.3717174054338382
Epoch #87: loss=0.3893588895981128
Epoch #88: loss=0.3242856476169366
Epoch #89: loss=0.37558578470578563
Epoch #90: loss=0.3969319588862933
Epoch #91: loss=0.4946063653780864
Epoch #92: loss=0.39451792950813586
Epoch #93: loss=0.4744151154389748
Epoch #94: loss=0.45705317419308883
Epoch #95: loss=0.37209045543120456
Epoch #96: loss=0.34400444248547923
Epoch #97: loss=0.3852625483503708
Epoch #98: loss=0.38901565682429534
Epoch #99: loss=0.3642784162209584
Epoch #100: loss=0.4189135523942801
Epoch #101: loss=0.4012969485842265
Epoch #102: loss=0.3079959669938454
Epoch #103: loss=0.3291827170894696
Epoch #104: loss=0.30517988766615206
Epoch #105: loss=0.3393891556904866
Epoch #106: loss=0.316328916985255
Epoch #107: loss=0.3253080051105756
Epoch #108: loss=0.3040529094063319
Epoch #109: loss=0.27786679909779477
Epoch #110: loss=0.26046105846762657
Epoch #111: loss=0.3683004281841792
Epoch #112: loss=0.333112932741642
Epoch #113: loss=0.3006091799873572
Epoch #114: loss=0.32673753712039727
Epoch #115: loss=0.2788117588139497
Epoch #116: loss=0.31343417442761934
Epoch #117: loss=0.2864579257483666
Epoch #118: loss=0.24874151039582032
Epoch #119: loss=0.2194652405495827
Epoch #120: loss=0.22553257128367057
Epoch #121: loss=0.24114733361280882
Epoch #122: loss=0.24906584190634581
Epoch #123: loss=0.2566739802177136
Epoch #124: loss=0.25590608555537003
Epoch #125: loss=0.2690159816008348
Epoch #126: loss=0.3145703621781789
Epoch #127: loss=0.29447975983986485
Epoch #128: loss=0.31326968136888284
Epoch #129: loss=0.2751355921992889
Epoch #130: loss=0.2727116850706247
Epoch #131: loss=0.3624716257819763
Epoch #132: loss=0.2410767637193203
Epoch #133: loss=0.23851232116038984
Epoch #134: loss=0.3346913456916809
Epoch #135: loss=0.2927156626605071
Epoch #136: loss=0.2183952437570462
Epoch #137: loss=0.21221340676912895
Epoch #138: loss=0.2881449105647894
Epoch #139: loss=0.28789619786235005
Epoch #140: loss=0.23762966348574713
Epoch #141: loss=0.3479502997719325
Epoch #142: loss=0.26684328340567076
Epoch #143: loss=0.18079158291220665
Epoch #144: loss=0.19852371528171575
Epoch #145: loss=0.2498676266807776
Epoch #146: loss=0.1863031951853862
Epoch #147: loss=0.1680399288351719
Epoch #148: loss=0.1870455492574435
Epoch #149: loss=0.17004905082285404
Epoch #150: loss=0.23809545100308382
Epoch #151: loss=0.21845550519915727
Epoch #152: loss=0.2093708710028575
Epoch #153: loss=0.15014704460134873
Epoch #154: loss=0.16941784178981414
Epoch #155: loss=0.16019431229394215
Epoch #156: loss=0.19477783888578415
Epoch #157: loss=0.24327431074701822
Epoch #158: loss=0.1987321560199444
Epoch #159: loss=0.1951987763436941
Epoch #160: loss=0.25245647247021014
Epoch #161: loss=0.24318229292447752
Epoch #162: loss=0.2810789335232515
Epoch #163: loss=0.33694955477347743
Epoch #164: loss=0.19637825569281211
Epoch #165: loss=0.2492626358110171
Epoch #166: loss=0.194553236835278
Epoch #167: loss=0.1714557187201885
Epoch #168: loss=0.1640438920316788
Epoch #169: loss=0.18407527056451028
Epoch #170: loss=0.1526192485426481
Epoch #171: loss=0.13970260207469648
Epoch #172: loss=0.1927947857632087
Epoch #173: loss=0.14424103412490624
Epoch #174: loss=0.13703613871565232
Epoch #175: loss=0.14108928235677573
Epoch #176: loss=0.18790862823908144
Epoch #177: loss=0.17207014589355543
Epoch #178: loss=0.24852225843530434
Epoch #179: loss=0.17534569650888443
Epoch #180: loss=0.16065623725836092
Epoch #181: loss=0.13275126582727984
Epoch #182: loss=0.24188393440384132
Epoch #183: loss=0.16758366774481076
Epoch #184: loss=0.21685259645948043
Epoch #185: loss=0.15547392631952578
Epoch #186: loss=0.21516876653409922
Epoch #187: loss=0.17743414038648972
Epoch #188: loss=0.17478973962939703
Epoch #189: loss=0.23340226136721098
Epoch #190: loss=0.1668996108839145
Epoch #191: loss=0.17289385930276835
Epoch #192: loss=0.1720644967773786
Epoch #193: loss=0.13342378646708453
Epoch #194: loss=0.14725544217687386
Epoch #195: loss=0.13728591026021883
Epoch #196: loss=0.1709935455941237
Epoch #197: loss=0.19948506484238002
Epoch #198: loss=0.17689206250585043
Epoch #199: loss=0.14700914618487543
Epoch #200: loss=0.1280153296314753
Epoch #201: loss=0.1412249287017263
Epoch #202: loss=0.15464271067713314
Epoch #203: loss=0.11211925143232712
Epoch #204: loss=0.12387552828742908
Epoch #205: loss=0.1751427428367046
Epoch #206: loss=0.12574525062854475
Epoch #207: loss=0.1674999907039679
Epoch #208: loss=0.1662826371880678
Epoch #209: loss=0.11258288995864299
Epoch #210: loss=0.1187012603936287
Epoch #211: loss=0.17127748098797524
Epoch #212: loss=0.1258100586441847
Epoch #213: loss=0.11191712334178962
Epoch #214: loss=0.17459654320891088
Epoch #215: loss=0.13164076438316932
Epoch #216: loss=0.12369037749102482
Epoch #217: loss=0.1140591437713458
Epoch #218: loss=0.14401317545427725
Epoch #219: loss=0.10275943104464275
Epoch #220: loss=0.1376307814453657
Epoch #221: loss=0.12054135335179475
Epoch #222: loss=0.11584536638110876
Epoch #223: loss=0.11211496699028291
Epoch #224: loss=0.10077549237757921
Epoch #225: loss=0.1618195711993254
Epoch #226: loss=0.10572717174027975
Epoch #227: loss=0.12513756236204734
Epoch #228: loss=0.17721110224150693
Epoch #229: loss=0.1851552312190716
Epoch #230: loss=0.2641128823161125
Epoch #231: loss=0.240333280311181
Epoch #232: loss=0.29810503812936634
Epoch #233: loss=0.22378169372677803
Epoch #234: loss=0.18996186482791716
Epoch #235: loss=0.2059264383636988
Epoch #236: loss=0.1352247323554296
Epoch #237: loss=0.13913676242988843
Epoch #238: loss=0.13644996357078737
Epoch #239: loss=0.17440855947251505
Epoch #240: loss=0.16136216902388975
Epoch #241: loss=0.14097032538400248
Epoch #242: loss=0.1588328295172407
Epoch #243: loss=0.12773588271095201
Epoch #244: loss=0.2612215560646011
Epoch #245: loss=0.17648008766655737
Epoch #246: loss=0.11021959896271045
Epoch #247: loss=0.11546093383087562
Epoch #248: loss=0.08516828257303971
Epoch #249: loss=0.09613557840482546

Training time: 0:21:45.123821

Finished.
n2one setting etth1_ettm1_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_ettm1_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.37664e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.70381e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.37664e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3605801160099194, 'MAE': 0.4256486850622441}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm1_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_ettm1_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.10897e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.13733e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.27244e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.13733e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.6753576956139326, 'MAE': 0.5977848195284828}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm2_electricity', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm2_electricity_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.7011983726931885
Epoch #1: loss=0.6872857765110545
Epoch #2: loss=0.4879802013568822
Epoch #3: loss=0.3855631368613876
Epoch #4: loss=0.31144288019620564
Epoch #5: loss=0.26075391981278195
Epoch #6: loss=0.244873461514096
Epoch #7: loss=0.21571050428271646
Epoch #8: loss=0.18915901970458945
Epoch #9: loss=0.1612757250205078
Epoch #10: loss=0.13808841126418747
Epoch #11: loss=0.15064326605613956
Epoch #12: loss=0.1264251692215074
Epoch #13: loss=0.12319634774573433
Epoch #14: loss=0.11414730586221436
Epoch #15: loss=0.10336087308933953
Epoch #16: loss=0.09047633708951923
Epoch #17: loss=0.1071717579159501
Epoch #18: loss=0.08119107380091792
Epoch #19: loss=0.09376993711081753
Epoch #20: loss=0.08202952643235524
Epoch #21: loss=0.06512281232977775
Epoch #22: loss=0.06809032204558188
Epoch #23: loss=0.061119735221705426
Epoch #24: loss=0.06337624067127441
Epoch #25: loss=0.06759726279758599
Epoch #26: loss=0.057216837789291916
Epoch #27: loss=0.04668683609526857
Epoch #28: loss=0.04699949962347966
Epoch #29: loss=0.04860763892443482
Epoch #30: loss=0.04514371205786117
Epoch #31: loss=0.06711045425429193
Epoch #32: loss=0.04999599961569439
Epoch #33: loss=0.042585814035852
Epoch #34: loss=0.057757953802744545
Epoch #35: loss=0.03376521537105132
Epoch #36: loss=0.04299655053929417
Epoch #37: loss=0.03891547828992405
Epoch #38: loss=0.03834040311596475
Epoch #39: loss=0.03766567937364928
Epoch #40: loss=0.03693726331965344
Epoch #41: loss=0.030892745696782933
Epoch #42: loss=0.04511379296438093
Epoch #43: loss=0.03478763193293175
Epoch #44: loss=0.03025347253879131
Epoch #45: loss=0.027488041116930213
Epoch #46: loss=0.027063386141841787
Epoch #47: loss=0.05132932789351758
Epoch #48: loss=0.030910281463083878
Epoch #49: loss=0.042007631598903104
Epoch #50: loss=0.03336783363428901
Epoch #51: loss=0.024193062623523196
Epoch #52: loss=0.028920020531055277
Epoch #53: loss=0.021768515903824132
Epoch #54: loss=0.025985063006964054
Epoch #55: loss=0.019741550732505643
Epoch #56: loss=0.03256307178586282
Epoch #57: loss=0.03033545175821391
Epoch #58: loss=0.03270960429780856
Epoch #59: loss=0.02497128132355721
Epoch #60: loss=0.023011319388211004
Epoch #61: loss=0.021263188541355848
Epoch #62: loss=0.020871949935356664
Epoch #63: loss=0.026525552462852372
Epoch #64: loss=0.02161105208828287
Epoch #65: loss=0.02120671747801798
Epoch #66: loss=0.022676191271411853
Epoch #67: loss=0.02417727863068547
Epoch #68: loss=0.029240213711279002
Epoch #69: loss=0.019546986454864277
Epoch #70: loss=0.02365884128106335
Epoch #71: loss=0.020602170438066145
Epoch #72: loss=0.017518151905882146
Epoch #73: loss=0.024460931174810095
Epoch #74: loss=0.023401300974360564
Epoch #75: loss=0.022056942634802356
Epoch #76: loss=0.025681646597423318
Epoch #77: loss=0.019645624638158707
Epoch #78: loss=0.02483804164946101
Epoch #79: loss=0.025361995219086796
Epoch #80: loss=0.03141344971041357
Epoch #81: loss=0.04806216381068525
Epoch #82: loss=0.02103781579117288
Epoch #83: loss=0.012588344863272522
Epoch #84: loss=0.019932794695786012
Epoch #85: loss=0.016081489881865987
Epoch #86: loss=0.02790508681261269
Epoch #87: loss=0.016297535223207798
Epoch #88: loss=0.0275702927914753
Epoch #89: loss=0.021799259585916313
Epoch #90: loss=0.01807368766934718
Epoch #91: loss=0.020222547553015384
Epoch #92: loss=0.01932744458860341
Epoch #93: loss=0.020035622989316538
Epoch #94: loss=0.015360640341128912
Epoch #95: loss=0.022867000040565248
Epoch #96: loss=0.01801977058698129
Epoch #97: loss=0.022352467096344756
Epoch #98: loss=0.019341867733032477
Epoch #99: loss=0.018280412784226756
Epoch #100: loss=0.015339124735045057
Epoch #101: loss=0.014203377934289508
Epoch #102: loss=0.01754980937630669
Epoch #103: loss=0.0168146555326401
Epoch #104: loss=0.02147567752202022
Epoch #105: loss=0.015641417301546338
Epoch #106: loss=0.013726029606710483
Epoch #107: loss=0.01662743414283777
Epoch #108: loss=0.02290658329343588
Epoch #109: loss=0.03583812902858041
Epoch #110: loss=0.013002190756773615
Epoch #111: loss=0.011129084881120375
Epoch #112: loss=0.030442664996757938
Epoch #113: loss=0.011969170366739442
Epoch #114: loss=0.01720059259587234
Epoch #115: loss=0.012277512853191808
Epoch #116: loss=0.012507971112443282
Epoch #117: loss=0.016911808869583055
Epoch #118: loss=0.032052372760313856
Epoch #119: loss=0.017533976409191424
Epoch #120: loss=0.014675026399613657
Epoch #121: loss=0.015103468391563535
Epoch #122: loss=0.013672016553819773
Epoch #123: loss=0.01199358918825659
Epoch #124: loss=0.012146928151904613
Epoch #125: loss=0.013206705492907438
Epoch #126: loss=0.01917531825279251
Epoch #127: loss=0.015292249039257808
Epoch #128: loss=0.011545578546850918
Epoch #129: loss=0.013111307763750047
Epoch #130: loss=0.012149063595412657
Epoch #131: loss=0.00965295804489011
Epoch #132: loss=0.016294407167377165
Epoch #133: loss=0.01665295587521552
Epoch #134: loss=0.018547837551034833
Epoch #135: loss=0.012975985238226927
Epoch #136: loss=0.013062812473280163
Epoch #137: loss=0.014503711233757557
Epoch #138: loss=0.012255458910036062
Epoch #139: loss=0.010409900653921205
Epoch #140: loss=0.017806683274145325
Epoch #141: loss=0.012779151778194262
Epoch #142: loss=0.01956140037775754
Epoch #143: loss=0.025530584392777937
Epoch #144: loss=0.01410023048042751
Epoch #145: loss=0.014582657967288882
Epoch #146: loss=0.013396165737278545
Epoch #147: loss=0.011855010371219098
Epoch #148: loss=0.014290819094814415
Epoch #149: loss=0.012318713138749477
Epoch #150: loss=0.008285738903033935
Epoch #151: loss=0.009455421893303846
Epoch #152: loss=0.011048001423770023
Epoch #153: loss=0.015630133324515644
Epoch #154: loss=0.013246979908866582
Epoch #155: loss=0.01401941233350975
Epoch #156: loss=0.01956253730301171
Epoch #157: loss=0.01238992325494555
Epoch #158: loss=0.010569593977752475
Epoch #159: loss=0.011679716677227055
Epoch #160: loss=0.01568546513532313
Epoch #161: loss=0.018542988730627482
Epoch #162: loss=0.015334129186174049
Epoch #163: loss=0.009334281384742306
Epoch #164: loss=0.01627379555768913
Epoch #165: loss=0.009811696374086954
Epoch #166: loss=0.01309609320856065
Epoch #167: loss=0.01077528364771282
Epoch #168: loss=0.009323794166536887
Epoch #169: loss=0.010753186222833408
Epoch #170: loss=0.013440288443964492
Epoch #171: loss=0.010533773850760859
Epoch #172: loss=0.04158817937530324
Epoch #173: loss=0.019822859634393907
Epoch #174: loss=0.014962024266273882
Epoch #175: loss=0.014152305972162129
Epoch #176: loss=0.009158566608718681
Epoch #177: loss=0.010026127983665555
Epoch #178: loss=0.010027658701603024
Epoch #179: loss=0.01888607134479359
Epoch #180: loss=0.013648780861218353
Epoch #181: loss=0.009645438993883327
Epoch #182: loss=0.009501342271738974
Epoch #183: loss=0.009113824657685808
Epoch #184: loss=0.010815446101407902
Epoch #185: loss=0.014365811348902364
Epoch #186: loss=0.010022336197038288
Epoch #187: loss=0.014664961028552909
Epoch #188: loss=0.01297671718479637
Epoch #189: loss=0.013453821685291542
Epoch #190: loss=0.01281807289986286
Epoch #191: loss=0.009486157037328056
Epoch #192: loss=0.013484264008809364
Epoch #193: loss=0.012330462288397851
Epoch #194: loss=0.020041145147274283
Epoch #195: loss=0.018132804904289677
Epoch #196: loss=0.01002880211331975
Epoch #197: loss=0.010291393395464532
Epoch #198: loss=0.009341388718454458
Epoch #199: loss=0.007071809655767632
Epoch #200: loss=0.027759536040347938
Epoch #201: loss=0.017517484648628463
Epoch #202: loss=0.010595099092701555
Epoch #203: loss=0.012019086321458703
Epoch #204: loss=0.01120061933950337
Epoch #205: loss=0.011050133020249622
Epoch #206: loss=0.010168756503329521
Epoch #207: loss=0.012455544428392328
Epoch #208: loss=0.010282219382611469
Epoch #209: loss=0.009204594401150233
Epoch #210: loss=0.01161865381455972
Epoch #211: loss=0.009398435596441905
Epoch #212: loss=0.019577091767014467
Epoch #213: loss=0.01190063439711041
Epoch #214: loss=0.011318621190799164
Epoch #215: loss=0.009433551223063979
Epoch #216: loss=0.00764592701184926
Epoch #217: loss=0.00886157208059126
Epoch #218: loss=0.017061862086150577
Epoch #219: loss=0.01947163768039857
Epoch #220: loss=0.029848323496056695
Epoch #221: loss=0.014142105438448434
Epoch #222: loss=0.012644545963084858
Epoch #223: loss=0.00838630271156574
Epoch #224: loss=0.010770156810861659
Epoch #225: loss=0.011246934953021369
Epoch #226: loss=0.009203580362312936
Epoch #227: loss=0.00925075400045147
Epoch #228: loss=0.011585596211135777
Epoch #229: loss=0.010455524512916215
Epoch #230: loss=0.013529987875605689
Epoch #231: loss=0.014492954122167697
Epoch #232: loss=0.013861041436824194
Epoch #233: loss=0.014573192012281319
Epoch #234: loss=0.01126437106158256
Epoch #235: loss=0.008989420948326204
Epoch #236: loss=0.010717258106164735
Epoch #237: loss=0.011572517114478523
Epoch #238: loss=0.02005190651987097
Epoch #239: loss=0.010504601988254614
Epoch #240: loss=0.007324135700288122
Epoch #241: loss=0.010768666970670625
Epoch #242: loss=0.00925181301998848
Epoch #243: loss=0.008739179123456077
Epoch #244: loss=0.01457476240045674
Epoch #245: loss=0.01432828717692659
Epoch #246: loss=0.03266189477350123
Epoch #247: loss=0.01063230412666738
Epoch #248: loss=0.014681590261101959
Epoch #249: loss=0.01002632081405614

Training time: 4:37:50.478175

Finished.
n2one setting etth1_ettm2_electricity -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm2_electricity_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_ettm2_electricity', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.14077e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.12211e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.16272e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.14077e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.5238661067409863, 'MAE': 0.5430920013712119}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm2_electricity -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm2_electricity_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_ettm2_electricity', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.35253e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.24524296429086298, 'MAE': 0.33880111236878185}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm2_traffic', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm2_traffic_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.0058543519370935
Epoch #1: loss=0.371610400470143
Epoch #2: loss=0.2518101196820763
Epoch #3: loss=0.19130946088751608
Epoch #4: loss=0.14981549913063646
Epoch #5: loss=0.13801193427167494
Epoch #6: loss=0.11108355731068348
Epoch #7: loss=0.09021483152914285
Epoch #8: loss=0.08486100991722197
Epoch #9: loss=0.07460627189562233
Epoch #10: loss=0.07114424447380853
Epoch #11: loss=0.055194705276517195
Epoch #12: loss=0.0540650444152892
Epoch #13: loss=0.05085368413710967
Epoch #14: loss=0.051690500377232884
Epoch #15: loss=0.048096060201218774
Epoch #16: loss=0.0487428871382938
Epoch #17: loss=0.050827784405026416
Epoch #18: loss=0.040686825624884064
Epoch #19: loss=0.03708941306897693
Epoch #20: loss=0.03852415125028611
Epoch #21: loss=0.040405901008158586
Epoch #22: loss=0.03535468053583331
Epoch #23: loss=0.039402000122407285
Epoch #24: loss=0.028517612596889112
Epoch #25: loss=0.02688771809877256
Epoch #26: loss=0.037230652682245076
Epoch #27: loss=0.026098218494735193
Epoch #28: loss=0.028425543060769665
Epoch #29: loss=0.025004060304027832
Epoch #30: loss=0.027562151608104945
Epoch #31: loss=0.024537354199459183
Epoch #32: loss=0.031492037620443045
Epoch #33: loss=0.03852353421852141
Epoch #34: loss=0.023876077031706123
Epoch #35: loss=0.02695428693345589
Epoch #36: loss=0.026761742412848188
Epoch #37: loss=0.028084935576374516
Epoch #38: loss=0.020696486884249184
Epoch #39: loss=0.021244487094505035
Epoch #40: loss=0.022298656177273106
Epoch #41: loss=0.01947842025216563
Epoch #42: loss=0.02398233754753495
Epoch #43: loss=0.02609381624504088
Epoch #44: loss=0.026448087325380502
Epoch #45: loss=0.020072684107997868
Epoch #46: loss=0.02155942448377821
Epoch #47: loss=0.03090826568216223
Epoch #48: loss=0.01793719434046414
Epoch #49: loss=0.0218195277297954
Epoch #50: loss=0.02104976853353781
Epoch #51: loss=0.03457142363721769
Epoch #52: loss=0.023435458233408014
Epoch #53: loss=0.018327357994580365
Epoch #54: loss=0.0167261944788565
Epoch #55: loss=0.01881183993346812
Epoch #56: loss=0.01827441000449736
Epoch #57: loss=0.017046255441759556
Epoch #58: loss=0.02475839546780414
Epoch #59: loss=0.018126451424442084
Epoch #60: loss=0.014532290676619266
Epoch #61: loss=0.018219296460301848
Epoch #62: loss=0.01867712875556952
Epoch #63: loss=0.016718927176473452
Epoch #64: loss=0.01866828288548277
Epoch #65: loss=0.016159411441483165
Epoch #66: loss=0.019407471732483826
Epoch #67: loss=0.018443362606988308
Epoch #68: loss=0.01899507382672296
Epoch #69: loss=0.021352260682297956
Epoch #70: loss=0.016292491479477825
Epoch #71: loss=0.015695922763552517
Epoch #72: loss=0.014489762376251747
Epoch #73: loss=0.015813580882902235
Epoch #74: loss=0.018399798337089702
Epoch #75: loss=0.017420331802317047
Epoch #76: loss=0.016962280044919516
Epoch #77: loss=0.017127980383322045
Epoch #78: loss=0.01210749553485419
Epoch #79: loss=0.015529199925202358
Epoch #80: loss=0.016588195957261964
Epoch #81: loss=0.011813389472180543
Epoch #82: loss=0.016179365857533413
Epoch #83: loss=0.014270336805467113
Epoch #84: loss=0.017422436252772143
Epoch #85: loss=0.012124321152176973
Epoch #86: loss=0.016383962498333526
Epoch #87: loss=0.015595008563369364
Epoch #88: loss=0.013509557987973412
Epoch #89: loss=0.015053676169025658
Epoch #90: loss=0.01481497729748133
Epoch #91: loss=0.01590101341318744
Epoch #92: loss=0.017334124567556005
Epoch #93: loss=0.0122864002833508
Epoch #94: loss=0.01448308655278445
Epoch #95: loss=0.021215628857813
Epoch #96: loss=0.013080327662167044
Epoch #97: loss=0.014236861931468328
Epoch #98: loss=0.01577388547011651
Epoch #99: loss=0.007864771182738133
Epoch #100: loss=0.015407519424843485
Epoch #101: loss=0.011675009727365581
Epoch #102: loss=0.013650652552116133
Epoch #103: loss=0.012951940885382514
Epoch #104: loss=0.007706420212443018
Epoch #105: loss=0.017033667104723545
Epoch #106: loss=0.014166199386553753
Epoch #107: loss=0.016555220818620663
Epoch #108: loss=0.010178969590164013
Epoch #109: loss=0.014866038920106142
Epoch #110: loss=0.009646632168253497
Epoch #111: loss=0.012222467245671643
Epoch #112: loss=0.01582095985273058
Epoch #113: loss=0.014681005648460334
Epoch #114: loss=0.01315364748907913
Epoch #115: loss=0.011278874555732314
Epoch #116: loss=0.01332772394687874
Epoch #117: loss=0.015465434340446584
Epoch #118: loss=0.01302039272638715
Epoch #119: loss=0.017123264377766068
Epoch #120: loss=0.010373610510743508
Epoch #121: loss=0.010804140444485131
Epoch #122: loss=0.012030296331200093
Epoch #123: loss=0.013793845105663588
Epoch #124: loss=0.01695689652169676
Epoch #125: loss=0.013280575958560803
Epoch #126: loss=0.01570878744598965
Epoch #127: loss=0.011669847614145759
Epoch #128: loss=0.011047690854452825
Epoch #129: loss=0.010350748213485613
Epoch #130: loss=0.01389153653720479
Epoch #131: loss=0.01678697652142463
Epoch #132: loss=0.01157904879549857
Epoch #133: loss=0.00892707603338336
Epoch #134: loss=0.011947878263097003
Epoch #135: loss=0.010746689775160948
Epoch #136: loss=0.012224148217898223
Epoch #137: loss=0.014329116764135754
Epoch #138: loss=0.015086193673083802
Epoch #139: loss=0.012385982802879881
Epoch #140: loss=0.011416837619419145
Epoch #141: loss=0.008998639716492108
Epoch #142: loss=0.010819300889389441
Epoch #143: loss=0.013588549900966675
Epoch #144: loss=0.011514746276622067
Epoch #145: loss=0.010119517977562447
Epoch #146: loss=0.013477371777216004
Epoch #147: loss=0.012933172523712115
Epoch #148: loss=0.010517753943940989
Epoch #149: loss=0.011720916867042516
Epoch #150: loss=0.01317967820653559
Epoch #151: loss=0.020551945087142733
Epoch #152: loss=0.011411866892012767
Epoch #153: loss=0.009839239354319447
Epoch #154: loss=0.017169536046640132
Epoch #155: loss=0.011790075510692655
Epoch #156: loss=0.012191894596964464
Epoch #157: loss=0.019006351380548122
Epoch #158: loss=0.010821932670660317
Epoch #159: loss=0.010592213185935345
Epoch #160: loss=0.011895431256735636
Epoch #161: loss=0.010690901087598997
Epoch #162: loss=0.011302479660017442
Epoch #163: loss=0.008226322669030527
Epoch #164: loss=0.0104270418678921
Epoch #165: loss=0.014987122224854169
Epoch #166: loss=0.01567006972175229
Epoch #167: loss=0.008968132336932203
Epoch #168: loss=0.009996009719097029
Epoch #169: loss=0.010789184706101712
Epoch #170: loss=0.013464112984035059
Epoch #171: loss=0.009906482073099389
Epoch #172: loss=0.01143715318946554
Epoch #173: loss=0.0124375004627144
Epoch #174: loss=0.008410924743425726
Epoch #175: loss=0.010222310497341493
Epoch #176: loss=0.014939753181600034
Epoch #177: loss=0.012019637452646168
Epoch #178: loss=0.013333033458878742
Epoch #179: loss=0.011939389548669252
Epoch #180: loss=0.012376077930755194
Epoch #181: loss=0.008337409088628853
Epoch #182: loss=0.012390396942877984
Epoch #183: loss=0.01834590825905748
Epoch #184: loss=0.00863991487987567
Epoch #185: loss=0.007482790799589235
Epoch #186: loss=0.012379435249749804
Epoch #187: loss=0.01970895342864506
Epoch #188: loss=0.010915512470356506
Epoch #189: loss=0.00986467155082871
Epoch #190: loss=0.0137186955418656
Epoch #191: loss=0.01074918827534103
Epoch #192: loss=0.01041029105158073
Epoch #193: loss=0.01205598845332464
Epoch #194: loss=0.009414245441687605
Epoch #195: loss=0.007697982633875323
Epoch #196: loss=0.012100869731748596
Epoch #197: loss=0.01195071318517116
Epoch #198: loss=0.013005827405454924
Epoch #199: loss=0.013767241227833437
Epoch #200: loss=0.009729006273317447
Epoch #201: loss=0.010052761174442409
Epoch #202: loss=0.0066663407998103965
Epoch #203: loss=0.008790766096750634
Epoch #204: loss=0.009466256449801138
Epoch #205: loss=0.009028404219233463
Epoch #206: loss=0.011245104877955533
Epoch #207: loss=0.013084463263211629
Epoch #208: loss=0.011380134212727584
Epoch #209: loss=0.010332848720134858
Epoch #210: loss=0.011642307891055349
Epoch #211: loss=0.010068823193498909
Epoch #212: loss=0.007019136685432221
Epoch #213: loss=0.010475282633904664
Epoch #214: loss=0.010093983097976888
Epoch #215: loss=0.011596815518565893
Epoch #216: loss=0.009589360056138089
Epoch #217: loss=0.00961400655492484
Epoch #218: loss=0.013062242437742747
Epoch #219: loss=0.008198876389658175
Epoch #220: loss=0.009487595802056603
Epoch #221: loss=0.013660226323918324
Epoch #222: loss=0.00921726880711834
Epoch #223: loss=0.010081612753922607
Epoch #224: loss=0.008449650127063665
Epoch #225: loss=0.009444689890154801
Epoch #226: loss=0.012935280753597247
Epoch #227: loss=0.009603064754139206
Epoch #228: loss=0.010942105588484
Epoch #229: loss=0.009729513229649456
Epoch #230: loss=0.01005469328410155
Epoch #231: loss=0.009535928255699714
Epoch #232: loss=0.010199148666387456
Epoch #233: loss=0.008599781992986458
Epoch #234: loss=0.0120452023337996
Epoch #235: loss=0.013947099588966177
Epoch #236: loss=0.009427543717356457
Epoch #237: loss=0.0065452368593634505
Epoch #238: loss=0.007879525711194385
Epoch #239: loss=0.01666289099355874
Epoch #240: loss=0.005706800319504427
Epoch #241: loss=0.006845707884795874
Epoch #242: loss=0.008902876615221348
Epoch #243: loss=0.009233301326763798
Epoch #244: loss=0.012740492795091995
Epoch #245: loss=0.01134073767076519
Epoch #246: loss=0.006578786257258881
Epoch #247: loss=0.008823598649244311
Epoch #248: loss=0.009302718427583883
Epoch #249: loss=0.016541082760886637

Training time: 10:32:09.141258

Finished.
n2one setting etth1_ettm2_traffic -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm2_traffic_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_ettm2_traffic', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.38213e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.98166e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.08475e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.38213e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4191442429191127, 'MAE': 0.46041857565940003}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm2_traffic -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm2_traffic_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_ettm2_traffic', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.19832e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.65233e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.5459263096522687, 'MAE': 0.569830988439776}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm2_traffic -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm2_traffic_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_ettm2_traffic', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.73012e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.24900968529721104, 'MAE': 0.3364767211390406}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm2_weather', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm2_weather_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=4.596618273041465
Epoch #1: loss=2.7686017589135603
Epoch #2: loss=2.2676368220285936
Epoch #3: loss=2.120320498943329
Epoch #4: loss=1.8655206046321176
Epoch #5: loss=1.660156873139468
Epoch #6: loss=1.5091418082063848
Epoch #7: loss=1.4299140951850198
Epoch #8: loss=1.3206445710225538
Epoch #9: loss=1.1476254923777147
Epoch #10: loss=1.1282839937643572
Epoch #11: loss=1.1566138132051988
Epoch #12: loss=1.0833657546476885
Epoch #13: loss=0.9581242095340382
Epoch #14: loss=0.8834136981855739
Epoch #15: loss=0.8943819390101866
Epoch #16: loss=0.8330819295211271
Epoch #17: loss=0.8612808111039075
Epoch #18: loss=0.8689173175530001
Epoch #19: loss=0.8049176105044105
Epoch #20: loss=0.7713703553784977
Epoch #21: loss=0.8145675022493709
Epoch #22: loss=0.8523270636796951
Epoch #23: loss=0.7932360077446158
Epoch #24: loss=0.6462027030912313
Epoch #25: loss=0.6637053855440833
Epoch #26: loss=0.6907322643832727
Epoch #27: loss=0.6373822451992468
Epoch #28: loss=0.6409710008989681
Epoch #29: loss=0.6589399616826664
Epoch #30: loss=0.6215578337961977
Epoch #31: loss=0.6083870374343612
Epoch #32: loss=0.5191204290498387
Epoch #33: loss=0.5262434584173289
Epoch #34: loss=0.5737254294482145
Epoch #35: loss=0.6052390499548479
Epoch #36: loss=0.5426053750244054
Epoch #37: loss=0.5561355487866835
Epoch #38: loss=0.5658875134858218
Epoch #39: loss=0.4729477295821363
Epoch #40: loss=0.4569157114760442
Epoch #41: loss=0.43408816917376086
Epoch #42: loss=0.4075257188894532
Epoch #43: loss=0.4635952352122827
Epoch #44: loss=0.42005759714679286
Epoch #45: loss=0.4664712602441961
Epoch #46: loss=0.433228308504278
Epoch #47: loss=0.528751487081701
Epoch #48: loss=0.49400139870968734
Epoch #49: loss=0.42116058245301247
Epoch #50: loss=0.3730046898126602
Epoch #51: loss=0.3891706178811463
Epoch #52: loss=0.3669507832012393
Epoch #53: loss=0.3789939863437956
Epoch #54: loss=0.4146916971287944
Epoch #55: loss=0.4320324943824248
Epoch #56: loss=0.3535786166109822
Epoch #57: loss=0.3353158618238839
Epoch #58: loss=0.3492467985911803
Epoch #59: loss=0.3449149517850442
Epoch #60: loss=0.3711263747377829
Epoch #61: loss=0.38538774915716867
Epoch #62: loss=0.41428110376000404
Epoch #63: loss=0.3407886854626916
Epoch #64: loss=0.3831581635908647
Epoch #65: loss=0.32697986540469254
Epoch #66: loss=0.2956374075941064
Epoch #67: loss=0.3052933896807107
Epoch #68: loss=0.4462445889684287
Epoch #69: loss=0.41524668579751794
Epoch #70: loss=0.268595985729586
Epoch #71: loss=0.2883089484477585
Epoch #72: loss=0.28665529072962026
Epoch #73: loss=0.2881956400180405
Epoch #74: loss=0.29347871260886843
Epoch #75: loss=0.2501876052807678
Epoch #76: loss=0.23693982511758804
Epoch #77: loss=0.26847617040303623
Epoch #78: loss=0.2631248804655942
Epoch #79: loss=0.25623842430385674
Epoch #80: loss=0.24435646730390462
Epoch #81: loss=0.20573850670321422
Epoch #82: loss=0.204272822053595
Epoch #83: loss=0.2201074002818628
Epoch #84: loss=0.19541111453012985
Epoch #85: loss=0.18105208179490132
Epoch #86: loss=0.2729104072363539
Epoch #87: loss=0.2330950266596946
Epoch #88: loss=0.212749682366848
Epoch #89: loss=0.2151325192641128
Epoch #90: loss=0.2222459606656974
Epoch #91: loss=0.19735836220735853
Epoch #92: loss=0.2414752882481976
Epoch #93: loss=0.22516374289989471
Epoch #94: loss=0.24669508534398946
Epoch #95: loss=0.20343214358118447
Epoch #96: loss=0.1909122262996706
Epoch #97: loss=0.14341183574023572
Epoch #98: loss=0.15204661712050438
Epoch #99: loss=0.21825077316977762
Epoch #100: loss=0.23460867958651346
Epoch #101: loss=0.20523772007701072
Epoch #102: loss=0.21030638485469602
Epoch #103: loss=0.19436234422028065
Epoch #104: loss=0.24016333997926928
Epoch #105: loss=0.20697804904458197
Epoch #106: loss=0.14170830637555232
Epoch #107: loss=0.14436903104863383
Epoch #108: loss=0.16653281822800636
Epoch #109: loss=0.19710862636566162
Epoch #110: loss=0.16470566747540777
Epoch #111: loss=0.17885119959034704
Epoch #112: loss=0.17879691567610612
Epoch #113: loss=0.2562875616448847
Epoch #114: loss=0.17079489288682287
Epoch #115: loss=0.2176616071638736
Epoch #116: loss=0.34474430817433377
Epoch #117: loss=0.21544917639006267
Epoch #118: loss=0.1755188037218018
Epoch #119: loss=0.13333646699108861
Epoch #120: loss=0.17035832670940596
Epoch #121: loss=0.2130491848696362
Epoch #122: loss=0.191434940492565
Epoch #123: loss=0.11649259374561635
Epoch #124: loss=0.15891326748004014
Epoch #125: loss=0.14230338208885354
Epoch #126: loss=0.17071136781437832
Epoch #127: loss=0.14612515241077
Epoch #128: loss=0.1590059484270486
Epoch #129: loss=0.18756924010813236
Epoch #130: loss=0.11546947942538695
Epoch #131: loss=0.09976848714392293
Epoch #132: loss=0.10401143243705685
Epoch #133: loss=0.1259376832961359
Epoch #134: loss=0.11988449206745083
Epoch #135: loss=0.1391984332268211
Epoch #136: loss=0.15806602102450348
Epoch #137: loss=0.14312496374953876
Epoch #138: loss=0.10605656427585265
Epoch #139: loss=0.11735645546154543
Epoch #140: loss=0.12030578531663526
Epoch #141: loss=0.12533656994558193
Epoch #142: loss=0.09406903297217055
Epoch #143: loss=0.1194419599222866
Epoch #144: loss=0.16440672960809685
Epoch #145: loss=0.1427694310603494
Epoch #146: loss=0.13021549815312028
Epoch #147: loss=0.1095176086845723
Epoch #148: loss=0.11098177333108404
Epoch #149: loss=0.11189680800519207
Epoch #150: loss=0.0914710641584613
Epoch #151: loss=0.09897184719077566
Epoch #152: loss=0.08747782714834268
Epoch #153: loss=0.12029887490313161
Epoch #154: loss=0.10907779633998871
Epoch #155: loss=0.10504590749571269
Epoch #156: loss=0.1300625981847671
Epoch #157: loss=0.137314349709248
Epoch #158: loss=0.15236734645441175
Epoch #159: loss=0.16164580821482974
Epoch #160: loss=0.11208216143264012
Epoch #161: loss=0.1299871218560094
Epoch #162: loss=0.11011195110834458
Epoch #163: loss=0.11385082652453672
Epoch #164: loss=0.2077633499337191
Epoch #165: loss=0.16991499565880408
Epoch #166: loss=0.11306037216193297
Epoch #167: loss=0.11139609148217873
Epoch #168: loss=0.08114920336414468
Epoch #169: loss=0.11351975476877256
Epoch #170: loss=0.1108087312260812
Epoch #171: loss=0.12013949449597434
Epoch #172: loss=0.11414006280458787
Epoch #173: loss=0.08436587143858726
Epoch #174: loss=0.08352784791283986
Epoch #175: loss=0.07099493326280605
Epoch #176: loss=0.07659422923726114
Epoch #177: loss=0.07071582833305001
Epoch #178: loss=0.07435300812887197
Epoch #179: loss=0.10899987101385539
Epoch #180: loss=0.08809051605534148
Epoch #181: loss=0.09662125306203961
Epoch #182: loss=0.10177510405297983
Epoch #183: loss=0.07048581265421076
Epoch #184: loss=0.08057607909325849
Epoch #185: loss=0.0881166805259206
Epoch #186: loss=0.08021736399016598
Epoch #187: loss=0.1408402441831475
Epoch #188: loss=0.0647122874348001
Epoch #189: loss=0.09044652648100798
Epoch #190: loss=0.09361194641414014
Epoch #191: loss=0.09111448807049204
Epoch #192: loss=0.14157216356728564
Epoch #193: loss=0.11346731601621617
Epoch #194: loss=0.06887327881783924
Epoch #195: loss=0.0613817947239361
Epoch #196: loss=0.07363500598479401
Epoch #197: loss=0.0880442962304435
Epoch #198: loss=0.0878564551980658
Epoch #199: loss=0.07229551480321045
Epoch #200: loss=0.0635789567604661
Epoch #201: loss=0.07449330941943283
Epoch #202: loss=0.06408151046542282
Epoch #203: loss=0.07476755233735523
Epoch #204: loss=0.06026141830212013
Epoch #205: loss=0.08255329152399843
Epoch #206: loss=0.07222329232503068
Epoch #207: loss=0.06821895527272401
Epoch #208: loss=0.05590398160910064
Epoch #209: loss=0.09824672914956781
Epoch #210: loss=0.07165467905261638
Epoch #211: loss=0.08992754016071558
Epoch #212: loss=0.07647169157016007
Epoch #213: loss=0.07175662677565758
Epoch #214: loss=0.09137337445281446
Epoch #215: loss=0.05934218004007231
Epoch #216: loss=0.05586219909177585
Epoch #217: loss=0.06811572825112804
Epoch #218: loss=0.07308283088390123
Epoch #219: loss=0.0677926081910052
Epoch #220: loss=0.06270926022394137
Epoch #221: loss=0.05647709588943557
Epoch #222: loss=0.08567546832967889
Epoch #223: loss=0.08222188034348867
Epoch #224: loss=0.06296340882016177
Epoch #225: loss=0.06932335304604335
Epoch #226: loss=0.05925120191055943
Epoch #227: loss=0.09230448087592694
Epoch #228: loss=0.09071056864393706
Epoch #229: loss=0.06596783224747262
Epoch #230: loss=0.07065218068997968
Epoch #231: loss=0.06310159122486683
Epoch #232: loss=0.10229741919531742
Epoch #233: loss=0.08315649726004763
Epoch #234: loss=0.06098726376975802
Epoch #235: loss=0.06025233104909686
Epoch #236: loss=0.053203218172050336
Epoch #237: loss=0.05470921539447524
Epoch #238: loss=0.06126986463046209
Epoch #239: loss=0.10467398454519836
Epoch #240: loss=0.0793032473037866
Epoch #241: loss=0.11007518698038025
Epoch #242: loss=0.1748678563797677
Epoch #243: loss=0.15348517954010854
Epoch #244: loss=0.16994133689017457
Epoch #245: loss=0.09805352361449464
Epoch #246: loss=0.06150419303131374
Epoch #247: loss=0.05754105338234116
Epoch #248: loss=0.0557640868302604
Epoch #249: loss=0.0935573272661052

Training time: 0:44:02.323885

Finished.
n2one setting etth1_ettm2_weather -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm2_weather_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_ettm2_weather', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.54069e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.93227e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.54069e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.35836246071681427, 'MAE': 0.4240960038826417}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm2_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm2_weather_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_ettm2_weather', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.96231e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.24672189468481945, 'MAE': 0.34150738270902264}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm2_exchange', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm2_exchange_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=4.442442834377289
Epoch #1: loss=2.3366311421761146
Epoch #2: loss=2.0821636273310733
Epoch #3: loss=1.9703232645988464
Epoch #4: loss=1.8818055207912738
Epoch #5: loss=1.7036030705158527
Epoch #6: loss=1.666868466597337
Epoch #7: loss=1.57634541621575
Epoch #8: loss=1.5211775440436144
Epoch #9: loss=1.424071389895219
Epoch #10: loss=1.3571705497228181
Epoch #11: loss=1.2786127283022954
Epoch #12: loss=1.25497672191033
Epoch #13: loss=1.3020165608479426
Epoch #14: loss=1.2442538371452918
Epoch #15: loss=1.0986021069379954
Epoch #16: loss=1.039163506948031
Epoch #17: loss=1.032993163053806
Epoch #18: loss=0.9852713942527771
Epoch #19: loss=1.0361154148211846
Epoch #20: loss=0.9577916814730718
Epoch #21: loss=1.0188192152059996
Epoch #22: loss=0.9728637956655942
Epoch #23: loss=0.9728278815746307
Epoch #24: loss=0.8824554658853091
Epoch #25: loss=0.8382673469873575
Epoch #26: loss=0.8468698927989373
Epoch #27: loss=0.8893480942799494
Epoch #28: loss=0.8278722029465896
Epoch #29: loss=0.8969761018569653
Epoch #30: loss=0.8812896402982565
Epoch #31: loss=0.7453363079291123
Epoch #32: loss=0.7314319610595703
Epoch #33: loss=0.7860872928912823
Epoch #34: loss=0.6816704777570871
Epoch #35: loss=0.7317940936638758
Epoch #36: loss=0.8721149609639094
Epoch #37: loss=0.7387912949690452
Epoch #38: loss=0.8223913976779351
Epoch #39: loss=0.7104080583040531
Epoch #40: loss=0.723678680566641
Epoch #41: loss=0.7536630045909148
Epoch #42: loss=0.7397416933224752
Epoch #43: loss=0.6924279022675294
Epoch #44: loss=0.6626143363805918
Epoch #45: loss=0.6744722299850904
Epoch #46: loss=0.5918765159753653
Epoch #47: loss=0.5494113851052064
Epoch #48: loss=0.5532735024507229
Epoch #49: loss=0.553567729317225
Epoch #50: loss=0.5411289804256879
Epoch #51: loss=0.592026140827399
Epoch #52: loss=0.557004662660452
Epoch #53: loss=0.7450714672987278
Epoch #54: loss=0.6571843154155291
Epoch #55: loss=0.5325732036278799
Epoch #56: loss=0.5225619272543833
Epoch #57: loss=0.5570293905643317
Epoch #58: loss=0.520607210122622
Epoch #59: loss=0.49985051785524076
Epoch #60: loss=0.5468881044250268
Epoch #61: loss=0.5328375330338111
Epoch #62: loss=0.4816410610309014
Epoch #63: loss=0.5880876263746848
Epoch #64: loss=0.5381330274618589
Epoch #65: loss=0.5446716718948804
Epoch #66: loss=0.6077721428412658
Epoch #67: loss=0.5084154067131189
Epoch #68: loss=0.46188371915083665
Epoch #69: loss=0.42363447008224636
Epoch #70: loss=0.5213147166829842
Epoch #71: loss=0.47182639745565563
Epoch #72: loss=0.4745024878245134
Epoch #73: loss=0.380839599439731
Epoch #74: loss=0.529847254546789
Epoch #75: loss=0.46138953130978805
Epoch #76: loss=0.5186203649410834
Epoch #77: loss=0.48874262892282927
Epoch #78: loss=0.48939699221115845
Epoch #79: loss=0.4217595108426534
Epoch #80: loss=0.4724506741532913
Epoch #81: loss=0.4250055402517319
Epoch #82: loss=0.3850525841116905
Epoch #83: loss=0.4203197222489577
Epoch #84: loss=0.43690618958610755
Epoch #85: loss=0.4511231046456557
Epoch #86: loss=0.42795414878771854
Epoch #87: loss=0.4318159388808104
Epoch #88: loss=0.355902231656588
Epoch #89: loss=0.39895063581374973
Epoch #90: loss=0.42959854809137493
Epoch #91: loss=0.477697029709816
Epoch #92: loss=0.3813240316051703
Epoch #93: loss=0.4458689150901941
Epoch #94: loss=0.4742250723334459
Epoch #95: loss=0.3732702646117944
Epoch #96: loss=0.3602529907455811
Epoch #97: loss=0.396840642278011
Epoch #98: loss=0.4053974902400604
Epoch #99: loss=0.3825840795269379
Epoch #100: loss=0.40930817046990764
Epoch #101: loss=0.38053191567842776
Epoch #102: loss=0.30347219568032485
Epoch #103: loss=0.32114933889645797
Epoch #104: loss=0.3057733332881561
Epoch #105: loss=0.32735953451349187
Epoch #106: loss=0.32168702867168647
Epoch #107: loss=0.33588354461468184
Epoch #108: loss=0.32744446110266906
Epoch #109: loss=0.2953609781196484
Epoch #110: loss=0.277824393258645
Epoch #111: loss=0.3561797614854116
Epoch #112: loss=0.3567392218571443
Epoch #113: loss=0.318293343942899
Epoch #114: loss=0.33013979259591836
Epoch #115: loss=0.3113386258482933
Epoch #116: loss=0.3484643961374576
Epoch #117: loss=0.3747715841119106
Epoch #118: loss=0.33022939700346726
Epoch #119: loss=0.2811275760714824
Epoch #120: loss=0.2832246216443869
Epoch #121: loss=0.2966619993631656
Epoch #122: loss=0.2749025836013831
Epoch #123: loss=0.27222219510720325
Epoch #124: loss=0.25283931682889277
Epoch #125: loss=0.24372578097077516
Epoch #126: loss=0.27241866061320674
Epoch #127: loss=0.24254960824663824
Epoch #128: loss=0.249865184036585
Epoch #129: loss=0.23086778533000213
Epoch #130: loss=0.2324240282177925
Epoch #131: loss=0.3699919251868358
Epoch #132: loss=0.2506735978218225
Epoch #133: loss=0.2563666239953958
Epoch #134: loss=0.3044546854037505
Epoch #135: loss=0.3021358922123909
Epoch #136: loss=0.27502158456123793
Epoch #137: loss=0.2458552523301198
Epoch #138: loss=0.2843976058065891
Epoch #139: loss=0.2787448477286559
Epoch #140: loss=0.25633715838193893
Epoch #141: loss=0.36902792235979665
Epoch #142: loss=0.27636477609093374
Epoch #143: loss=0.200148262656652
Epoch #144: loss=0.20392348101505867
Epoch #145: loss=0.26405814204078454
Epoch #146: loss=0.19088969551599944
Epoch #147: loss=0.18326079186338645
Epoch #148: loss=0.19123111894497505
Epoch #149: loss=0.19549682048650888
Epoch #150: loss=0.26533009484410286
Epoch #151: loss=0.23571383437285057
Epoch #152: loss=0.23939849550907427
Epoch #153: loss=0.18096599756525114
Epoch #154: loss=0.20519591667331183
Epoch #155: loss=0.18900515282383332
Epoch #156: loss=0.21916059289987272
Epoch #157: loss=0.26712653785943985
Epoch #158: loss=0.20429826671114334
Epoch #159: loss=0.2027561065669243
Epoch #160: loss=0.2532525804753487
Epoch #161: loss=0.24700646388989228
Epoch #162: loss=0.2936493063775393
Epoch #163: loss=0.28846143501309246
Epoch #164: loss=0.17589247685212356
Epoch #165: loss=0.22373934978475937
Epoch #166: loss=0.1893420612009672
Epoch #167: loss=0.17574446046581635
Epoch #168: loss=0.16454441329607597
Epoch #169: loss=0.1939121437473939
Epoch #170: loss=0.177272935039722
Epoch #171: loss=0.18237977088070834
Epoch #172: loss=0.21005415314665207
Epoch #173: loss=0.14951721765100956
Epoch #174: loss=0.16208756929979876
Epoch #175: loss=0.16592825648303217
Epoch #176: loss=0.21698283991561487
Epoch #177: loss=0.19622951416442028
Epoch #178: loss=0.2793828948185994
Epoch #179: loss=0.17876829035007036
Epoch #180: loss=0.16194734579095474
Epoch #181: loss=0.1391737452493264
Epoch #182: loss=0.25582654057787013
Epoch #183: loss=0.1680993909159532
Epoch #184: loss=0.21187297598673746
Epoch #185: loss=0.15254766622988078
Epoch #186: loss=0.20606702480178613
Epoch #187: loss=0.17700415563124877
Epoch #188: loss=0.13811818968791229
Epoch #189: loss=0.19768165725354964
Epoch #190: loss=0.1478344206340038
Epoch #191: loss=0.1500673801279985
Epoch #192: loss=0.16633203754631373
Epoch #193: loss=0.1328857419295953
Epoch #194: loss=0.15668120450125292
Epoch #195: loss=0.13656900894756502
Epoch #196: loss=0.15148858410807756
Epoch #197: loss=0.18042985851374957
Epoch #198: loss=0.17870340481973612
Epoch #199: loss=0.15479541870837027
Epoch #200: loss=0.12498919479548931
Epoch #201: loss=0.1344518824838675
Epoch #202: loss=0.1720388252288103
Epoch #203: loss=0.135321163930572
Epoch #204: loss=0.1437146169348405
Epoch #205: loss=0.2065141536295414
Epoch #206: loss=0.14507302914101344
Epoch #207: loss=0.2049975025539215
Epoch #208: loss=0.19770068302750587
Epoch #209: loss=0.1467839962301346
Epoch #210: loss=0.14313716154832107
Epoch #211: loss=0.2011058718825762
Epoch #212: loss=0.14265904991099468
Epoch #213: loss=0.1127628290022795
Epoch #214: loss=0.17633391544222832
Epoch #215: loss=0.1363868206166304
Epoch #216: loss=0.13301348628906104
Epoch #217: loss=0.1228896494095142
Epoch #218: loss=0.17194120127421159
Epoch #219: loss=0.12027731681099305
Epoch #220: loss=0.1387363960250066
Epoch #221: loss=0.1476508346028053
Epoch #222: loss=0.1507359710163795
Epoch #223: loss=0.121397803322627
Epoch #224: loss=0.1067084392819267
Epoch #225: loss=0.18419263884425163
Epoch #226: loss=0.1275655459612608
Epoch #227: loss=0.13871196370858413
Epoch #228: loss=0.13911328436090395
Epoch #229: loss=0.14101984194264963
Epoch #230: loss=0.1312634550894682
Epoch #231: loss=0.11105216323183133
Epoch #232: loss=0.10844935749012691
Epoch #233: loss=0.13877305030249631
Epoch #234: loss=0.13914501022260922
Epoch #235: loss=0.21081348666204855
Epoch #236: loss=0.15255716973199293
Epoch #237: loss=0.14691756386309862
Epoch #238: loss=0.13907826204712576
Epoch #239: loss=0.19682976976037025
Epoch #240: loss=0.211825377952594
Epoch #241: loss=0.1516224441046898
Epoch #242: loss=0.16372233872803357
Epoch #243: loss=0.13286910621592632
Epoch #244: loss=0.2733284131838725
Epoch #245: loss=0.1784075042949273
Epoch #246: loss=0.11863412378499141
Epoch #247: loss=0.11762312283882728
Epoch #248: loss=0.09704315304183044
Epoch #249: loss=0.11649527744604991

Training time: 0:22:10.281276

Finished.
n2one setting etth1_ettm2_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm2_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_ettm2_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.43719e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.79483e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.43719e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3782898750730046, 'MAE': 0.43542743182951704}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm2_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm2_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_ettm2_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.37602e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.64391e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4757221418584766, 'MAE': 0.5125978220883218}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_electricity_traffic', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_electricity_traffic_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.8025121810180801
Epoch #1: loss=0.28407557612331974
Epoch #2: loss=0.1818447374777884
Epoch #3: loss=0.1391112828110697
Epoch #4: loss=0.112495203671523
Epoch #5: loss=0.08305460489159372
Epoch #6: loss=0.07088681156786174
Epoch #7: loss=0.06395495642493126
Epoch #8: loss=0.05380872057617775
Epoch #9: loss=0.05115891135407283
Epoch #10: loss=0.041923469284298916
Epoch #11: loss=0.03891197026006783
Epoch #12: loss=0.03971920198188144
Epoch #13: loss=0.04239716255614737
Epoch #14: loss=0.030266063201178587
Epoch #15: loss=0.032682826913337557
Epoch #16: loss=0.03342725844200732
Epoch #17: loss=0.02708778744729768
Epoch #18: loss=0.028045108760051632
Epoch #19: loss=0.028945661327868168
Epoch #20: loss=0.027113576127047956
Epoch #21: loss=0.026913067137728595
Epoch #22: loss=0.023691313657831368
Epoch #23: loss=0.021441402106385427
Epoch #24: loss=0.025380798995430276
Epoch #25: loss=0.018887261600241442
Epoch #26: loss=0.023984685691734856
Epoch #27: loss=0.02371337176227214
Epoch #28: loss=0.018618027748199602
Epoch #29: loss=0.022955904692654037
Epoch #30: loss=0.017674016376943602
Epoch #31: loss=0.0358542130304747
Epoch #32: loss=0.014435489869111818
Epoch #33: loss=0.016083729439542213
Epoch #34: loss=0.019348367088388246
Epoch #35: loss=0.020201147677417954
Epoch #36: loss=0.02067512927641466
Epoch #37: loss=0.024148801234482296
Epoch #38: loss=0.01590814889230601
Epoch #39: loss=0.019621882765131275
Epoch #40: loss=0.016802371735366632
Epoch #41: loss=0.017319272058877015
Epoch #42: loss=0.025468584758370424
Epoch #43: loss=0.01865482964986317
Epoch #44: loss=0.014765882222989512
Epoch #45: loss=0.017857283616547096
Epoch #46: loss=0.015446561339463913
Epoch #47: loss=0.015768239762293596
Epoch #48: loss=0.014881109129348888
Epoch #49: loss=0.016517215673596514
Epoch #50: loss=0.023364529454691273
Epoch #51: loss=0.017917860602786835
Epoch #52: loss=0.013962329927175951
Epoch #53: loss=0.015729593294621307
Epoch #54: loss=0.015808400577090743
Epoch #55: loss=0.014133685403048577
Epoch #56: loss=0.014359169011591236
Epoch #57: loss=0.016536187469453487
Epoch #58: loss=0.014489210544566393
Epoch #59: loss=0.018676923995861048
Epoch #60: loss=0.011763775884198267
Epoch #61: loss=0.016352486574142865
Epoch #62: loss=0.016464314316282
Epoch #63: loss=0.01715731136307625
Epoch #64: loss=0.01618688662126543
Epoch #65: loss=0.015029379532832903
Epoch #66: loss=0.013106058242519487
Epoch #67: loss=0.015013879018751591
Epoch #68: loss=0.012179257495276445
Epoch #69: loss=0.01524034360748473
Epoch #70: loss=0.013167553392758382
Epoch #71: loss=0.013600541791363087
Epoch #72: loss=0.015569680757086162
Epoch #73: loss=0.012682626019290672
Epoch #74: loss=0.013829893042297228
Epoch #75: loss=0.011475047776098911
Epoch #76: loss=0.014084731240511262
Epoch #77: loss=0.012948170005507227
Epoch #78: loss=0.01557316267464267
Epoch #79: loss=0.01290732156568473
Epoch #80: loss=0.016238328958289236
Epoch #81: loss=0.015112703160369112
Epoch #82: loss=0.013841812667094989
Epoch #83: loss=0.012977440732845767
Epoch #84: loss=0.010542907576024593
Epoch #85: loss=0.014729783549550686
Epoch #86: loss=0.010625780780776209
Epoch #87: loss=0.014457429080644912
Epoch #88: loss=0.013730624836122132
Epoch #89: loss=0.011151763056248364
Epoch #90: loss=0.013335529196603389
Epoch #91: loss=0.015926496812180096
Epoch #92: loss=0.01366888586485058
Epoch #93: loss=0.008880640585682288
Epoch #94: loss=0.01379367732120083
Epoch #95: loss=0.014912199271410437
Epoch #96: loss=0.01627756696008048
Epoch #97: loss=0.010031051788258487
Epoch #98: loss=0.012784851346988653
Epoch #99: loss=0.007598429538031743
Epoch #100: loss=0.016031725115549726
Epoch #101: loss=0.010985771845170187
Epoch #102: loss=0.009933063134386208
Epoch #103: loss=0.010851350603412403
Epoch #104: loss=0.013473921437146012
Epoch #105: loss=0.010564934333885175
Epoch #106: loss=0.01188468875939676
Epoch #107: loss=0.011285067250621466
Epoch #108: loss=0.012388905775884926
Epoch #109: loss=0.020936557870703563
Epoch #110: loss=0.015547184098794168
Epoch #111: loss=0.011150136330833135
Epoch #112: loss=0.013235125750275877
Epoch #113: loss=0.010763976150686352
Epoch #114: loss=0.00943992873159738
Epoch #115: loss=0.014387908368249143
Epoch #116: loss=0.013508032766897661
Epoch #117: loss=0.009518484479932119
Epoch #118: loss=0.01337008340733748
Epoch #119: loss=0.011482280689820417
Epoch #120: loss=0.010299624954648668
Epoch #121: loss=0.012970609328623454
Epoch #122: loss=0.010144867272908161
Epoch #123: loss=0.009773198770862484
Epoch #124: loss=0.011527338521109948
Epoch #125: loss=0.011719280876490256
Epoch #126: loss=0.00883858618572278
Epoch #127: loss=0.010820793440250462
Epoch #128: loss=0.014439169829289434
Epoch #129: loss=0.01080589680338157
Epoch #130: loss=0.009685584830135248
Epoch #131: loss=0.012499670461204173
Epoch #132: loss=0.01349649866465714
Epoch #133: loss=0.007830798272114392
Epoch #134: loss=0.009605033064462604
Epoch #135: loss=0.010311027424739666
Epoch #136: loss=0.013448108376337396
Epoch #137: loss=0.010075809825099261
Epoch #138: loss=0.011187201451158988
Epoch #139: loss=0.008107581151400629
Epoch #140: loss=0.011662097300472279
Epoch #141: loss=0.00931303012214147
Epoch #142: loss=0.011663354472736554
Epoch #143: loss=0.00906841780857316
Epoch #144: loss=0.009527925998695192
Epoch #145: loss=0.013761782179955401
Epoch #146: loss=0.011364216651522189
Epoch #147: loss=0.010340040888463171
Epoch #148: loss=0.01063333567626385
Epoch #149: loss=0.009117177857585963
Epoch #150: loss=0.010559638279236798
Epoch #151: loss=0.008575824966877718
Epoch #152: loss=0.009674254318286009
Epoch #153: loss=0.015017853618025713
Epoch #154: loss=0.010191304999880078
Epoch #155: loss=0.007693699002600685
Epoch #156: loss=0.010591136948379175
Epoch #157: loss=0.010870388935876414
Epoch #158: loss=0.009955433868676396
Epoch #159: loss=0.009590520461135399
Epoch #160: loss=0.009244117826275221
Epoch #161: loss=0.020527026025938387
Epoch #162: loss=0.013606641231669199
Epoch #163: loss=0.010271563344748061
Epoch #164: loss=0.008585971432403923
Epoch #165: loss=0.014240743083480214
Epoch #166: loss=0.008378820762929933
Epoch #167: loss=0.01857587759705366
Epoch #168: loss=0.00840731527458643
Epoch #169: loss=0.008145633539071936
Epoch #170: loss=0.010819003821528467
Epoch #171: loss=0.010969012650108932
Epoch #172: loss=0.009694887297323361
Epoch #173: loss=0.00820669835809268
Epoch #174: loss=0.007927256537478578
Epoch #175: loss=0.008758442229914143
Epoch #176: loss=0.011772223379149419
Epoch #177: loss=0.013529162536700013
Epoch #178: loss=0.009334936167469087
Epoch #179: loss=0.009600107001100115
Epoch #180: loss=0.009406251394762158
Epoch #181: loss=0.009699601502873849
Epoch #182: loss=0.010532492580129098
Epoch #183: loss=0.0064204720188210575
Epoch #184: loss=0.010692935126250074
Epoch #185: loss=0.012036330054967542
Epoch #186: loss=0.0115056362590912
Epoch #187: loss=0.01188481845563255
Epoch #188: loss=0.007671003399293052
Epoch #189: loss=0.012825051183908191
Epoch #190: loss=0.007600804527256904
Epoch #191: loss=0.009768539463965215
Epoch #192: loss=0.010877267166115187
Epoch #193: loss=0.008321429674424126
Epoch #194: loss=0.013884276262178289
Epoch #195: loss=0.008084193253222004
Epoch #196: loss=0.008768120109016309
Epoch #197: loss=0.008766213989113895
Epoch #198: loss=0.0075113986617796535
Epoch #199: loss=0.008910098737451794
Epoch #200: loss=0.008732232258619913
Epoch #201: loss=0.008864616383511891
Epoch #202: loss=0.009287745485987422
Epoch #203: loss=0.007991575611995665
Epoch #204: loss=0.010547279557403953
Epoch #205: loss=0.01000115180915386
Epoch #206: loss=0.009560601467165426
Epoch #207: loss=0.007534535541179582
Epoch #208: loss=0.010943063331790907
Epoch #209: loss=0.0074784472708354565
Epoch #210: loss=0.009052155484285689
Epoch #211: loss=0.03310186529832652
Epoch #212: loss=0.010015116287691288
Epoch #213: loss=0.007915204597679613
Epoch #214: loss=0.007782585655642085
Epoch #215: loss=0.0073806336164492095
Epoch #216: loss=0.00822873592046295
Epoch #217: loss=0.010059178901636706
Epoch #218: loss=0.0069317781790920255
Epoch #219: loss=0.008471549980645287
Epoch #220: loss=0.008105314140944954
Epoch #221: loss=0.011044284154036368
Epoch #222: loss=0.007623607871692996
Epoch #223: loss=0.012352322986970182
Epoch #224: loss=0.009690333528863853
Epoch #225: loss=0.004666951252664974
Epoch #226: loss=0.010102175504821275
Epoch #227: loss=0.009322306535326818
Epoch #228: loss=0.007359476171325337
Epoch #229: loss=0.007241830793639817
Epoch #230: loss=0.009197780834765275
Epoch #231: loss=0.013264523984167574
Epoch #232: loss=0.0063971118622974535
Epoch #233: loss=0.0080992106193341
Epoch #234: loss=0.010909188668118366
Epoch #235: loss=0.010225895345697723
Epoch #236: loss=0.0065613564564244815
Epoch #237: loss=0.008861215814237362
Epoch #238: loss=0.009405423644720405
Epoch #239: loss=0.00882341020524491
Epoch #240: loss=0.007781335634815662
Epoch #241: loss=0.00941777842532904
Epoch #242: loss=0.009035038678347282
Epoch #243: loss=0.007564657041934458
Epoch #244: loss=0.0095575562714963
Epoch #245: loss=0.011800841817438129
Epoch #246: loss=0.007053863257059667
Epoch #247: loss=0.009899048467825593
Epoch #248: loss=0.007444685516696024
Epoch #249: loss=0.008500408075456146

Training time: 14:38:09.527987

Finished.
n2one setting etth1_electricity_traffic -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_electricity_traffic_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_electricity_traffic', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.62926e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.75332e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.52217e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.62926e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3235980751166523, 'MAE': 0.40934070718797905}
Finished.
------------------------- record done -------------------------
n2one setting etth1_electricity_traffic -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_electricity_traffic_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_electricity_traffic', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.06044e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3274776823449006, 'MAE': 0.3824160997777075}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_electricity_weather', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_electricity_weather_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.643967774628246
Epoch #1: loss=0.7118017891537671
Epoch #2: loss=0.5007138219425233
Epoch #3: loss=0.4389852899110923
Epoch #4: loss=0.3550281629892392
Epoch #5: loss=0.3140508943358384
Epoch #6: loss=0.2780171100492195
Epoch #7: loss=0.23973439551763615
Epoch #8: loss=0.23310093566943696
Epoch #9: loss=0.2181613830018178
Epoch #10: loss=0.17903595017848042
Epoch #11: loss=0.1745776465467814
Epoch #12: loss=0.17513724526990268
Epoch #13: loss=0.1539816670961636
Epoch #14: loss=0.13575897315296076
Epoch #15: loss=0.12895102450087415
Epoch #16: loss=0.12467643351288839
Epoch #17: loss=0.11578394270549386
Epoch #18: loss=0.10681138703820564
Epoch #19: loss=0.10509978819870006
Epoch #20: loss=0.08869013435728217
Epoch #21: loss=0.10845836414560928
Epoch #22: loss=0.0837128637779483
Epoch #23: loss=0.07062518776073462
Epoch #24: loss=0.08753732356800577
Epoch #25: loss=0.06987510265593054
Epoch #26: loss=0.06597580424099529
Epoch #27: loss=0.05945241642263481
Epoch #28: loss=0.06422034542649815
Epoch #29: loss=0.07335830112066814
Epoch #30: loss=0.07899432167500299
Epoch #31: loss=0.0655064257585291
Epoch #32: loss=0.039270797539844395
Epoch #33: loss=0.04330197240141783
Epoch #34: loss=0.04671413827579637
Epoch #35: loss=0.04452556736719936
Epoch #36: loss=0.0532342550919607
Epoch #37: loss=0.04144542014534128
Epoch #38: loss=0.05527778316320757
Epoch #39: loss=0.036923099101368484
Epoch #40: loss=0.03569785304141289
Epoch #41: loss=0.04181205349353453
Epoch #42: loss=0.033264386385421424
Epoch #43: loss=0.0462031050165589
Epoch #44: loss=0.035299603878928214
Epoch #45: loss=0.031420070491204995
Epoch #46: loss=0.03696819422845492
Epoch #47: loss=0.034907005969987456
Epoch #48: loss=0.04201266324275178
Epoch #49: loss=0.04065826369941466
Epoch #50: loss=0.03714651194181409
Epoch #51: loss=0.03314391559839649
Epoch #52: loss=0.04298752707680477
Epoch #53: loss=0.059005702705659226
Epoch #54: loss=0.035464961459270895
Epoch #55: loss=0.02544306563035885
Epoch #56: loss=0.03027668479556418
Epoch #57: loss=0.026613006644519203
Epoch #58: loss=0.0412855907030914
Epoch #59: loss=0.04410160530034958
Epoch #60: loss=0.02268706632207153
Epoch #61: loss=0.03356304686348149
Epoch #62: loss=0.02943117653564313
Epoch #63: loss=0.02224789966604183
Epoch #64: loss=0.03542991157977626
Epoch #65: loss=0.024234440161893935
Epoch #66: loss=0.02870562156244039
Epoch #67: loss=0.03250446072306042
Epoch #68: loss=0.04767498748224376
Epoch #69: loss=0.030879523506780065
Epoch #70: loss=0.03144883285776454
Epoch #71: loss=0.022858107154715365
Epoch #72: loss=0.03415715094921468
Epoch #73: loss=0.02045317088703672
Epoch #74: loss=0.018157978422280747
Epoch #75: loss=0.0232248021712945
Epoch #76: loss=0.03453954866999171
Epoch #77: loss=0.032333015446488006
Epoch #78: loss=0.02735196447820734
Epoch #79: loss=0.045074041649346676
Epoch #80: loss=0.02328727100804806
Epoch #81: loss=0.02890573706465384
Epoch #82: loss=0.015313001385249334
Epoch #83: loss=0.022062959160332143
Epoch #84: loss=0.017496762542701248
Epoch #85: loss=0.02097242027402745
Epoch #86: loss=0.02028470869981131
Epoch #87: loss=0.020746877243331935
Epoch #88: loss=0.030805062885411967
Epoch #89: loss=0.01822573825862327
Epoch #90: loss=0.018348902517845486
Epoch #91: loss=0.020640643570693156
Epoch #92: loss=0.02849206330661141
Epoch #93: loss=0.017184530534139587
Epoch #94: loss=0.019559693675669763
Epoch #95: loss=0.020026190042473364
Epoch #96: loss=0.05257128938009152
Epoch #97: loss=0.021959904747709928
Epoch #98: loss=0.025082106784243916
Epoch #99: loss=0.023921013502917112
Epoch #100: loss=0.019882235975474342
Epoch #101: loss=0.017356467104910237
Epoch #102: loss=0.016702011514370892
Epoch #103: loss=0.013640240303899745
Epoch #104: loss=0.01588241237059162
Epoch #105: loss=0.025084850095846496
Epoch #106: loss=0.01420975387087197
Epoch #107: loss=0.02439447859661275
Epoch #108: loss=0.01979186853520851
Epoch #109: loss=0.04305779733721398
Epoch #110: loss=0.01902225057530022
Epoch #111: loss=0.015383149307131725
Epoch #112: loss=0.04123247816164236
Epoch #113: loss=0.0167660824990684
Epoch #114: loss=0.02068444790705344
Epoch #115: loss=0.017573908691907482
Epoch #116: loss=0.022378641837421217
Epoch #117: loss=0.030970333501864962
Epoch #118: loss=0.03607531387301683
Epoch #119: loss=0.026217443088962733
Epoch #120: loss=0.02262926485394733
Epoch #121: loss=0.013966185027946545
Epoch #122: loss=0.015336033992984301
Epoch #123: loss=0.024120370351306906
Epoch #124: loss=0.015672587962409397
Epoch #125: loss=0.02392266881911973
Epoch #126: loss=0.01570823014480993
Epoch #127: loss=0.02027378514136772
Epoch #128: loss=0.01660982836291094
Epoch #129: loss=0.01230115833886936
Epoch #130: loss=0.014708264114839645
Epoch #131: loss=0.02276348461218423
Epoch #132: loss=0.0176109994862276
Epoch #133: loss=0.025352580994065052
Epoch #134: loss=0.03229214974164721
Epoch #135: loss=0.017814861277728685
Epoch #136: loss=0.018466257409812187
Epoch #137: loss=0.022689892041087834
Epoch #138: loss=0.025486104730168085
Epoch #139: loss=0.019971215737540286
Epoch #140: loss=0.015172484035108444
Epoch #141: loss=0.01335736864161254
Epoch #142: loss=0.01855851213943008
Epoch #143: loss=0.014326864053392625
Epoch #144: loss=0.013702800888341252
Epoch #145: loss=0.01615198144898355
Epoch #146: loss=0.016707254444133218
Epoch #147: loss=0.012808389488001233
Epoch #148: loss=0.01849583591749539
Epoch #149: loss=0.00992500890650797
Epoch #150: loss=0.023446930897301117
Epoch #151: loss=0.016153051834264087
Epoch #152: loss=0.019054514201065936
Epoch #153: loss=0.01344357661134695
Epoch #154: loss=0.015226223147579463
Epoch #155: loss=0.017218759096632737
Epoch #156: loss=0.021723497692840227
Epoch #157: loss=0.025170211206679626
Epoch #158: loss=0.02046321113978639
Epoch #159: loss=0.01716151085138284
Epoch #160: loss=0.016469743084866227
Epoch #161: loss=0.013118950492080228
Epoch #162: loss=0.01603756026004107
Epoch #163: loss=0.020185907776822668
Epoch #164: loss=0.01653200610525022
Epoch #165: loss=0.013111963767017695
Epoch #166: loss=0.014519776753840526
Epoch #167: loss=0.018410680892858865
Epoch #168: loss=0.015409394985395036
Epoch #169: loss=0.01389215843977129
Epoch #170: loss=0.015883155450248553
Epoch #171: loss=0.02406812968202156
Epoch #172: loss=0.013094476493628627
Epoch #173: loss=0.018473140089749623
Epoch #174: loss=0.017200168174833566
Epoch #175: loss=0.00967118013158538
Epoch #176: loss=0.016270306456135586
Epoch #177: loss=0.010855735730071352
Epoch #178: loss=0.019564153194607702
Epoch #179: loss=0.011724463398443366
Epoch #180: loss=0.018656573913423187
Epoch #181: loss=0.012427092047071474
Epoch #182: loss=0.025831580412472823
Epoch #183: loss=0.023393034559607475
Epoch #184: loss=0.012318167129747233
Epoch #185: loss=0.01275323808987725
Epoch #186: loss=0.012183027942002276
Epoch #187: loss=0.012776934792021931
Epoch #188: loss=0.013193018158215709
Epoch #189: loss=0.011485293343311996
Epoch #190: loss=0.032867480398091294
Epoch #191: loss=0.025779441658389034
Epoch #192: loss=0.011328091052700212
Epoch #193: loss=0.009021156486735474
Epoch #194: loss=0.008174357910546484
Epoch #195: loss=0.014390575282435501
Epoch #196: loss=0.013240794634931894
Epoch #197: loss=0.015148529439975801
Epoch #198: loss=0.010852201372246248
Epoch #199: loss=0.013344729543330758
Epoch #200: loss=0.01152322938143523
Epoch #201: loss=0.03997805898865727
Epoch #202: loss=0.02875710889370849
Epoch #203: loss=0.012083173223121992
Epoch #204: loss=0.009772595462762872
Epoch #205: loss=0.011117653727467635
Epoch #206: loss=0.014528162615955149
Epoch #207: loss=0.01792813380548762
Epoch #208: loss=0.016873269258520833
Epoch #209: loss=0.01459412183727685
Epoch #210: loss=0.012281866882116098
Epoch #211: loss=0.011803298857701695
Epoch #212: loss=0.010897491682362927
Epoch #213: loss=0.01070576318652148
Epoch #214: loss=0.010629652617703123
Epoch #215: loss=0.012236658227893046
Epoch #216: loss=0.013139462711715066
Epoch #217: loss=0.018554589912472268
Epoch #218: loss=0.0203216821149302
Epoch #219: loss=0.011725501351862209
Epoch #220: loss=0.007983445536754999
Epoch #221: loss=0.018628654554604662
Epoch #222: loss=0.015863198304869822
Epoch #223: loss=0.0083405723081511
Epoch #224: loss=0.011895768123081659
Epoch #225: loss=0.010549913334139323
Epoch #226: loss=0.013055663176195297
Epoch #227: loss=0.012654375690801759
Epoch #228: loss=0.014225964522249682
Epoch #229: loss=0.010899439541965665
Epoch #230: loss=0.01574852754425068
Epoch #231: loss=0.015116723496690498
Epoch #232: loss=0.010470908896314864
Epoch #233: loss=0.014124784385703247
Epoch #234: loss=0.010567702594052706
Epoch #235: loss=0.02257749106633703
Epoch #236: loss=0.02374503854703287
Epoch #237: loss=0.011876146559337795
Epoch #238: loss=0.015414512354820062
Epoch #239: loss=0.01251622634414665
Epoch #240: loss=0.015292809754583752
Epoch #241: loss=0.008262697585492059
Epoch #242: loss=0.009900777650609649
Epoch #243: loss=0.015232303423730073
Epoch #244: loss=0.019059260746912693
Epoch #245: loss=0.012354726294919818
Epoch #246: loss=0.014605167581986551
Epoch #247: loss=0.009350811524446896
Epoch #248: loss=0.009516705520448438
Epoch #249: loss=0.008785145327612945

Training time: 5:02:23.501358

Finished.
n2one setting etth1_electricity_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_electricity_weather_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_electricity_weather', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.1979e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.1979e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.2531103055760101, 'MAE': 0.34514842414520375}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_electricity_exchange', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_electricity_exchange_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.6089039471532618
Epoch #1: loss=0.6446309311404115
Epoch #2: loss=0.4510572063071387
Epoch #3: loss=0.3442656932221282
Epoch #4: loss=0.3371708169579506
Epoch #5: loss=0.2823848786896893
Epoch #6: loss=0.2733558711507136
Epoch #7: loss=0.22561728530785158
Epoch #8: loss=0.21435194495799287
Epoch #9: loss=0.1689554720318743
Epoch #10: loss=0.17254488833159917
Epoch #11: loss=0.15879330333943167
Epoch #12: loss=0.14449645747386275
Epoch #13: loss=0.12638196589735648
Epoch #14: loss=0.12173007368220992
Epoch #15: loss=0.10620377351352502
Epoch #16: loss=0.10680845456885263
Epoch #17: loss=0.10147535055875778
Epoch #18: loss=0.08741118972899303
Epoch #19: loss=0.08245198527306673
Epoch #20: loss=0.08377318140784544
Epoch #21: loss=0.08773456347019722
Epoch #22: loss=0.0704861692211125
Epoch #23: loss=0.06950170404577095
Epoch #24: loss=0.055315594865186585
Epoch #25: loss=0.06822282429008435
Epoch #26: loss=0.052256400227114294
Epoch #27: loss=0.05321202332907844
Epoch #28: loss=0.07060731255443811
Epoch #29: loss=0.07206508819390797
Epoch #30: loss=0.04499837547648765
Epoch #31: loss=0.0521827623708218
Epoch #32: loss=0.044247027545463335
Epoch #33: loss=0.05519792780562836
Epoch #34: loss=0.04354648025140965
Epoch #35: loss=0.04355867391721057
Epoch #36: loss=0.048544837501443304
Epoch #37: loss=0.046532106846349224
Epoch #38: loss=0.06291515147521361
Epoch #39: loss=0.051270271355557874
Epoch #40: loss=0.041282067112098
Epoch #41: loss=0.034500822681972444
Epoch #42: loss=0.039406208629121205
Epoch #43: loss=0.04094154425616753
Epoch #44: loss=0.042579869660022224
Epoch #45: loss=0.03808877405563613
Epoch #46: loss=0.046255031147406304
Epoch #47: loss=0.04829496321915593
Epoch #48: loss=0.041565696997817474
Epoch #49: loss=0.03191627491919678
Epoch #50: loss=0.035592399381649945
Epoch #51: loss=0.03778838659352567
Epoch #52: loss=0.037492373626307765
Epoch #53: loss=0.028519399198731185
Epoch #54: loss=0.025442256331319055
Epoch #55: loss=0.0373142193490085
Epoch #56: loss=0.036946350872832615
Epoch #57: loss=0.03807611406297101
Epoch #58: loss=0.0509913156960725
Epoch #59: loss=0.03226181957385658
Epoch #60: loss=0.025654221856148934
Epoch #61: loss=0.023428847016129156
Epoch #62: loss=0.03280836521367919
Epoch #63: loss=0.034786046134762556
Epoch #64: loss=0.027645160574355118
Epoch #65: loss=0.032930070044780484
Epoch #66: loss=0.024554437528076095
Epoch #67: loss=0.08109483220947108
Epoch #68: loss=0.03205660105560951
Epoch #69: loss=0.022276577231726453
Epoch #70: loss=0.02719083126950344
Epoch #71: loss=0.042214671735737716
Epoch #72: loss=0.029636785438231613
Epoch #73: loss=0.025742166529761606
Epoch #74: loss=0.02926699605519562
Epoch #75: loss=0.022090417084525273
Epoch #76: loss=0.027978724064139118
Epoch #77: loss=0.019367051631325877
Epoch #78: loss=0.022079457034297298
Epoch #79: loss=0.028588320631353695
Epoch #80: loss=0.029679024426080843
Epoch #81: loss=0.0272224456885375
Epoch #82: loss=0.021221685387336903
Epoch #83: loss=0.027977635684822286
Epoch #84: loss=0.02500243060300515
Epoch #85: loss=0.02159949856702172
Epoch #86: loss=0.023709108228753654
Epoch #87: loss=0.030301025662560106
Epoch #88: loss=0.019936073552560715
Epoch #89: loss=0.029079131604313652
Epoch #90: loss=0.026392503959262587
Epoch #91: loss=0.03156930727778845
Epoch #92: loss=0.04177185995337952
Epoch #93: loss=0.03363409027259054
Epoch #94: loss=0.024353082489445416
Epoch #95: loss=0.02018135709208547
Epoch #96: loss=0.017954162903541664
Epoch #97: loss=0.01924982153165426
Epoch #98: loss=0.02028579781264333
Epoch #99: loss=0.036818481347186856
Epoch #100: loss=0.02757473229697401
Epoch #101: loss=0.022776230689833893
Epoch #102: loss=0.03991693380954703
Epoch #103: loss=0.017768369685481525
Epoch #104: loss=0.021181572222260348
Epoch #105: loss=0.022442654355559387
Epoch #106: loss=0.0298407080775914
Epoch #107: loss=0.01913620527972983
Epoch #108: loss=0.016637574091007645
Epoch #109: loss=0.020452229062010746
Epoch #110: loss=0.02286910338270467
Epoch #111: loss=0.0206730138914801
Epoch #112: loss=0.031049954175874257
Epoch #113: loss=0.04308204506239798
Epoch #114: loss=0.020640320603498758
Epoch #115: loss=0.02361009722794517
Epoch #116: loss=0.018716604811613382
Epoch #117: loss=0.01245792383001355
Epoch #118: loss=0.021480401499762332
Epoch #119: loss=0.01429454262584581
Epoch #120: loss=0.026328599925147415
Epoch #121: loss=0.021688269675256118
Epoch #122: loss=0.038419570938068706
Epoch #123: loss=0.023498647801932834
Epoch #124: loss=0.03396711411672489
Epoch #125: loss=0.024852155502837075
Epoch #126: loss=0.018889049839344807
Epoch #127: loss=0.023041207096477074
Epoch #128: loss=0.021023541569039003
Epoch #129: loss=0.025182647092844405
Epoch #130: loss=0.020803702505439843
Epoch #131: loss=0.020573908703053825
Epoch #132: loss=0.022897722301249382
Epoch #133: loss=0.021031686103967894
Epoch #134: loss=0.019030539249624348
Epoch #135: loss=0.015892240242984763
Epoch #136: loss=0.015840849733822757
Epoch #137: loss=0.016474973655844917
Epoch #138: loss=0.014458084314572347
Epoch #139: loss=0.01516026402870401
Epoch #140: loss=0.028392842047261575
Epoch #141: loss=0.019533219510430216
Epoch #142: loss=0.017887221943792178
Epoch #143: loss=0.0164372747836058
Epoch #144: loss=0.018323559466807637
Epoch #145: loss=0.03536600943421252
Epoch #146: loss=0.022097248863463478
Epoch #147: loss=0.020894529183091697
Epoch #148: loss=0.020397084597962453
Epoch #149: loss=0.013080807204113669
Epoch #150: loss=0.014363601637125526
Epoch #151: loss=0.017813129364055515
Epoch #152: loss=0.013033577404885796
Epoch #153: loss=0.022023774921416633
Epoch #154: loss=0.021835406592886318
Epoch #155: loss=0.016786378802775982
Epoch #156: loss=0.012821009314696616
Epoch #157: loss=0.029746363329953358
Epoch #158: loss=0.016405324030659228
Epoch #159: loss=0.016756479690749466
Epoch #160: loss=0.019237639919343304
Epoch #161: loss=0.015203085666663745
Epoch #162: loss=0.012177936044584689
Epoch #163: loss=0.015080889375288583
Epoch #164: loss=0.028860127385477035
Epoch #165: loss=0.028784749865562412
Epoch #166: loss=0.0357993803779772
Epoch #167: loss=0.018706855454746846
Epoch #168: loss=0.01423786302014681
Epoch #169: loss=0.01639330212345244
Epoch #170: loss=0.020545994226267794
Epoch #171: loss=0.028433562821148717
Epoch #172: loss=0.023322037200462848
Epoch #173: loss=0.018536486598306857
Epoch #174: loss=0.01580033006809702
Epoch #175: loss=0.01620912316433359
Epoch #176: loss=0.011040237731711906
Epoch #177: loss=0.013090582597214961
Epoch #178: loss=0.012692449985869254
Epoch #179: loss=0.012810033286292483
Epoch #180: loss=0.023000436035155353
Epoch #181: loss=0.012888086480026166
Epoch #182: loss=0.023628567868789623
Epoch #183: loss=0.018241346098788892
Epoch #184: loss=0.011664071886636
Epoch #185: loss=0.01668734432288537
Epoch #186: loss=0.014216252700515767
Epoch #187: loss=0.020034256357446014
Epoch #188: loss=0.017719952792200882
Epoch #189: loss=0.028251882299844596
Epoch #190: loss=0.018023706107019928
Epoch #191: loss=0.0307143202827276
Epoch #192: loss=0.020644807353770982
Epoch #193: loss=0.015443665100021809
Epoch #194: loss=0.017350579480470123
Epoch #195: loss=0.050650933065515436
Epoch #196: loss=0.014675738090902866
Epoch #197: loss=0.01739305217433
Epoch #198: loss=0.016567999122170954
Epoch #199: loss=0.013243290916805216
Epoch #200: loss=0.011684093020795401
Epoch #201: loss=0.006990330750167708
Epoch #202: loss=0.009328894555697584
Epoch #203: loss=0.015593531737457462
Epoch #204: loss=0.020908149921957546
Epoch #205: loss=0.02273367786134865
Epoch #206: loss=0.019640815742258427
Epoch #207: loss=0.014383513576571463
Epoch #208: loss=0.013888306654691752
Epoch #209: loss=0.014123462922032645
Epoch #210: loss=0.01814821101764946
Epoch #211: loss=0.019191008647491497
Epoch #212: loss=0.015290024346974124
Epoch #213: loss=0.014103748376371749
Epoch #214: loss=0.014009619157063537
Epoch #215: loss=0.009164959366465891
Epoch #216: loss=0.014211307149924409
Epoch #217: loss=0.013366508030490618
Epoch #218: loss=0.011441806171812155
Epoch #219: loss=0.019570575972985744
Epoch #220: loss=0.01945717054868943
Epoch #221: loss=0.026802961550856708
Epoch #222: loss=0.02073007097871076
Epoch #223: loss=0.015249840882461285
Epoch #224: loss=0.008647306840127081
Epoch #225: loss=0.01028501541415088
Epoch #226: loss=0.011391448765477565
Epoch #227: loss=0.018107786037944607
Epoch #228: loss=0.014520282352653643
Epoch #229: loss=0.013144991497635298
Epoch #230: loss=0.009333758143319366
Epoch #231: loss=0.00932762460373245
Epoch #232: loss=0.014184470468535437
Epoch #233: loss=0.019651797462367022
Epoch #234: loss=0.011226845737404628
Epoch #235: loss=0.01836229710741983
Epoch #236: loss=0.01652293553221777
Epoch #237: loss=0.013970517385349098
Epoch #238: loss=0.013879364472120955
Epoch #239: loss=0.014587801290915758
Epoch #240: loss=0.01885451508184945
Epoch #241: loss=0.023969719045236985
Epoch #242: loss=0.01340351165171818
Epoch #243: loss=0.009365623028359204
Epoch #244: loss=0.01691571308020641
Epoch #245: loss=0.01085097762656265
Epoch #246: loss=0.013074547188287917
Epoch #247: loss=0.013888875690186285
Epoch #248: loss=0.010812977663244098
Epoch #249: loss=0.014378947421868188

Training time: 4:26:59.458777

Finished.
n2one setting etth1_electricity_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_electricity_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_electricity_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.31669e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.50673e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.31669e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.8495450925562009, 'MAE': 0.7186939734365253}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_traffic_weather', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_traffic_weather_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.0136092457191903
Epoch #1: loss=0.39291729614055354
Epoch #2: loss=0.27886510839342404
Epoch #3: loss=0.21399147372339025
Epoch #4: loss=0.17335998405957356
Epoch #5: loss=0.15048856421805626
Epoch #6: loss=0.1269160635915049
Epoch #7: loss=0.11734672072837805
Epoch #8: loss=0.09493707139565292
Epoch #9: loss=0.090785154895909
Epoch #10: loss=0.07605355156262993
Epoch #11: loss=0.06780904198544069
Epoch #12: loss=0.07182290920956508
Epoch #13: loss=0.058300572771360505
Epoch #14: loss=0.054912408911128786
Epoch #15: loss=0.06088220996563661
Epoch #16: loss=0.048900265335079345
Epoch #17: loss=0.04722821910777155
Epoch #18: loss=0.04937663173599575
Epoch #19: loss=0.04336790239552879
Epoch #20: loss=0.05378583018816279
Epoch #21: loss=0.05402996335256657
Epoch #22: loss=0.03654817412178131
Epoch #23: loss=0.032686266882797736
Epoch #24: loss=0.04046476355184119
Epoch #25: loss=0.02797389866812831
Epoch #26: loss=0.03285362746556128
Epoch #27: loss=0.03333068334252974
Epoch #28: loss=0.03636566536727377
Epoch #29: loss=0.028258691929858283
Epoch #30: loss=0.030540048406334522
Epoch #31: loss=0.03434636350981267
Epoch #32: loss=0.03210453771694704
Epoch #33: loss=0.03170753987024762
Epoch #34: loss=0.026146290266324437
Epoch #35: loss=0.02273141502190704
Epoch #36: loss=0.030197090475869433
Epoch #37: loss=0.026865214398573024
Epoch #38: loss=0.03553535658632036
Epoch #39: loss=0.03183552648523542
Epoch #40: loss=0.018731450827112004
Epoch #41: loss=0.02911458451576614
Epoch #42: loss=0.026483044375642074
Epoch #43: loss=0.02324951217332907
Epoch #44: loss=0.02738755973792172
Epoch #45: loss=0.017709338450323082
Epoch #46: loss=0.021057162353054843
Epoch #47: loss=0.02350803645348499
Epoch #48: loss=0.017804866883443283
Epoch #49: loss=0.024481661104422854
Epoch #50: loss=0.023955921385588136
Epoch #51: loss=0.018666139910031403
Epoch #52: loss=0.01879522736748816
Epoch #53: loss=0.021449848172494193
Epoch #54: loss=0.021707767676679136
Epoch #55: loss=0.01853499735719212
Epoch #56: loss=0.020813914858371894
Epoch #57: loss=0.020779576711941968
Epoch #58: loss=0.016680126526853453
Epoch #59: loss=0.0245580457779839
Epoch #60: loss=0.016657559037554552
Epoch #61: loss=0.019510890690703466
Epoch #62: loss=0.01964581511620765
Epoch #63: loss=0.020664560436901985
Epoch #64: loss=0.019852893192200093
Epoch #65: loss=0.022881260968929458
Epoch #66: loss=0.01474775589912136
Epoch #67: loss=0.01822788019650928
Epoch #68: loss=0.018802032291004044
Epoch #69: loss=0.018173068682253414
Epoch #70: loss=0.025097509404623557
Epoch #71: loss=0.025445123598065392
Epoch #72: loss=0.017650993815272027
Epoch #73: loss=0.011067016514872758
Epoch #74: loss=0.015583109026046356
Epoch #75: loss=0.014516565077560929
Epoch #76: loss=0.021460597364325595
Epoch #77: loss=0.017861440755210962
Epoch #78: loss=0.0230058505952647
Epoch #79: loss=0.014968027692260844
Epoch #80: loss=0.015050433455102565
Epoch #81: loss=0.017437087982345383
Epoch #82: loss=0.02572432001714475
Epoch #83: loss=0.017765227284519177
Epoch #84: loss=0.016030464577033346
Epoch #85: loss=0.013593822934498293
Epoch #86: loss=0.016129002085426437
Epoch #87: loss=0.015658734525539574
Epoch #88: loss=0.019253584126097685
Epoch #89: loss=0.01746387034108311
Epoch #90: loss=0.018346264552846603
Epoch #91: loss=0.02391184910269475
Epoch #92: loss=0.012846067423025645
Epoch #93: loss=0.018268218749481143
Epoch #94: loss=0.011972595215970182
Epoch #95: loss=0.014270759075320737
Epoch #96: loss=0.015810575619386768
Epoch #97: loss=0.012532688705146563
Epoch #98: loss=0.013816349515067048
Epoch #99: loss=0.01370693232064843
Epoch #100: loss=0.012435947613486261
Epoch #101: loss=0.017963523315961665
Epoch #102: loss=0.013663664385032522
Epoch #103: loss=0.01207808028925607
Epoch #104: loss=0.012965624252699742
Epoch #105: loss=0.022538509411905116
Epoch #106: loss=0.016610727198298387
Epoch #107: loss=0.015453682806132771
Epoch #108: loss=0.011557270010657525
Epoch #109: loss=0.011672137805092273
Epoch #110: loss=0.01243839428572156
Epoch #111: loss=0.01935101936076372
Epoch #112: loss=0.015162905516204804
Epoch #113: loss=0.01173068064947186
Epoch #114: loss=0.01039166772039282
Epoch #115: loss=0.012352730738299551
Epoch #116: loss=0.018141280060345256
Epoch #117: loss=0.010465450629470975
Epoch #118: loss=0.03141137090757214
Epoch #119: loss=0.01751208417394001
Epoch #120: loss=0.014765695482965994
Epoch #121: loss=0.014347472779245335
Epoch #122: loss=0.02587824348310222
Epoch #123: loss=0.01362768891589409
Epoch #124: loss=0.009800396588183524
Epoch #125: loss=0.018292637376242198
Epoch #126: loss=0.013895575213863894
Epoch #127: loss=0.0114453535580646
Epoch #128: loss=0.014321558439942187
Epoch #129: loss=0.01803818266029308
Epoch #130: loss=0.013045871986174441
Epoch #131: loss=0.012850451069625807
Epoch #132: loss=0.01140334336695199
Epoch #133: loss=0.011218606318606002
Epoch #134: loss=0.010758610452556536
Epoch #135: loss=0.014957959114186278
Epoch #136: loss=0.014132219573935526
Epoch #137: loss=0.01655179332007196
Epoch #138: loss=0.01608716505586154
Epoch #139: loss=0.015104080931470188
Epoch #140: loss=0.020235287229232648
Epoch #141: loss=0.012130469142318854
Epoch #142: loss=0.022848232054898214
Epoch #143: loss=0.015092062143128958
Epoch #144: loss=0.010991861732928966
Epoch #145: loss=0.019380013997323146
Epoch #146: loss=0.009224649615730185
Epoch #147: loss=0.012691981560165613
Epoch #148: loss=0.009805680848581667
Epoch #149: loss=0.014477085164428152
Epoch #150: loss=0.012292285492824516
Epoch #151: loss=0.010674445361322359
Epoch #152: loss=0.014636319158006948
Epoch #153: loss=0.012854086106214491
Epoch #154: loss=0.01108642464861184
Epoch #155: loss=0.016408391815822248
Epoch #156: loss=0.012737819399602071
Epoch #157: loss=0.015213525288006
Epoch #158: loss=0.00884003690201672
Epoch #159: loss=0.013139622983689857
Epoch #160: loss=0.02029593555265179
Epoch #161: loss=0.010673921237674973
Epoch #162: loss=0.011592501261026105
Epoch #163: loss=0.007725512035028143
Epoch #164: loss=0.010389083645852185
Epoch #165: loss=0.02151137060676337
Epoch #166: loss=0.01174586607831369
Epoch #167: loss=0.015439105704278807
Epoch #168: loss=0.0186476823216299
Epoch #169: loss=0.016612527500490096
Epoch #170: loss=0.014778528037850418
Epoch #171: loss=0.014001480241529852
Epoch #172: loss=0.01673255176211879
Epoch #173: loss=0.011970153554499912
Epoch #174: loss=0.013332885933822728
Epoch #175: loss=0.012972528347436615
Epoch #176: loss=0.007511670934044504
Epoch #177: loss=0.008305965833575334
Epoch #178: loss=0.011523544327707119
Epoch #179: loss=0.011769861084059162
Epoch #180: loss=0.018925186583327452
Epoch #181: loss=0.014051404131469759
Epoch #182: loss=0.011762540177302305
Epoch #183: loss=0.015428461555504388
Epoch #184: loss=0.01588526201164857
Epoch #185: loss=0.00924588451916404
Epoch #186: loss=0.00952290632929809
Epoch #187: loss=0.013343633039641147
Epoch #188: loss=0.014817855557685005
Epoch #189: loss=0.007108469825324488
Epoch #190: loss=0.010052870305898267
Epoch #191: loss=0.01175992378567322
Epoch #192: loss=0.014344097708199725
Epoch #193: loss=0.010185826817714719
Epoch #194: loss=0.014825522864930716
Epoch #195: loss=0.018138371340380252
Epoch #196: loss=0.01459099227762859
Epoch #197: loss=0.008262629838440536
Epoch #198: loss=0.019018410268895246
Epoch #199: loss=0.00835749062310918
Epoch #200: loss=0.013047069318978866
Epoch #201: loss=0.014892824449463925
Epoch #202: loss=0.0077946351047565605
Epoch #203: loss=0.012137092159561522
Epoch #204: loss=0.009613097374010103
Epoch #205: loss=0.008038309080686873
Epoch #206: loss=0.016331732829001227
Epoch #207: loss=0.009122443683890953
Epoch #208: loss=0.009769242415381869
Epoch #209: loss=0.017524416805485617
Epoch #210: loss=0.014339035714079962
Epoch #211: loss=0.013078756385997287
Epoch #212: loss=0.008912431541391305
Epoch #213: loss=0.011272449372043605
Epoch #214: loss=0.008513483299969536
Epoch #215: loss=0.011673737548040642
Epoch #216: loss=0.011186555987249998
Epoch #217: loss=0.009637692904973913
Epoch #218: loss=0.011105262537973162
Epoch #219: loss=0.010003664089996346
Epoch #220: loss=0.007866134577236976
Epoch #221: loss=0.018094248717908316
Epoch #222: loss=0.00982388259494071
Epoch #223: loss=0.014349080383187086
Epoch #224: loss=0.011385679643912704
Epoch #225: loss=0.006213599783905773
Epoch #226: loss=0.014096178388916992
Epoch #227: loss=0.007942698248980733
Epoch #228: loss=0.009706821055190544
Epoch #229: loss=0.00915714779898964
Epoch #230: loss=0.011905778898592836
Epoch #231: loss=0.009852894972414742
Epoch #232: loss=0.00923930469681847
Epoch #233: loss=0.020606208788315563
Epoch #234: loss=0.013732267689940587
Epoch #235: loss=0.011686004417814776
Epoch #236: loss=0.013934096989118057
Epoch #237: loss=0.016573651249106848
Epoch #238: loss=0.009148214426950645
Epoch #239: loss=0.007494245035979993
Epoch #240: loss=0.01182240858407725
Epoch #241: loss=0.011266090803927294
Epoch #242: loss=0.008614418684087391
Epoch #243: loss=0.011775815213884763
Epoch #244: loss=0.009592083787614501
Epoch #245: loss=0.009802510812956652
Epoch #246: loss=0.010730828945531495
Epoch #247: loss=0.010069736681919865
Epoch #248: loss=0.008249237540655369
Epoch #249: loss=0.013649194649200854

Training time: 10:43:13.518548

Finished.
n2one setting etth1_traffic_weather -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_traffic_weather_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_traffic_weather', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=6.14472e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.59877e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.41211e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=6.14472e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.41147778791736356, 'MAE': 0.45449177389576245}
Finished.
------------------------- record done -------------------------
n2one setting etth1_traffic_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_traffic_weather_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_traffic_weather', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.52972e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.39637340795776843, 'MAE': 0.4023340507936425}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_traffic_exchange', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_traffic_exchange_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.9808192887049308
Epoch #1: loss=0.3583191737379696
Epoch #2: loss=0.24656582770692853
Epoch #3: loss=0.1933164676245697
Epoch #4: loss=0.15256925384294212
Epoch #5: loss=0.13570431541936087
Epoch #6: loss=0.12106847093188912
Epoch #7: loss=0.10394997413598316
Epoch #8: loss=0.09185174000507886
Epoch #9: loss=0.07306711129130564
Epoch #10: loss=0.07089548746863021
Epoch #11: loss=0.06195997777782559
Epoch #12: loss=0.05830900431711528
Epoch #13: loss=0.05503203420068308
Epoch #14: loss=0.05560439601014904
Epoch #15: loss=0.053942959628491625
Epoch #16: loss=0.044857146535674054
Epoch #17: loss=0.05111732115722691
Epoch #18: loss=0.04170451546379895
Epoch #19: loss=0.04749908966507164
Epoch #20: loss=0.039729267993555355
Epoch #21: loss=0.03595171151273887
Epoch #22: loss=0.03641770733387646
Epoch #23: loss=0.03885884045308908
Epoch #24: loss=0.03904411993987705
Epoch #25: loss=0.03292290976060238
Epoch #26: loss=0.024801181225496915
Epoch #27: loss=0.03139195881599184
Epoch #28: loss=0.028473795719626344
Epoch #29: loss=0.02835133747662818
Epoch #30: loss=0.035504014022327626
Epoch #31: loss=0.02806318759176978
Epoch #32: loss=0.02788992587436084
Epoch #33: loss=0.03029198750658141
Epoch #34: loss=0.03023909377575318
Epoch #35: loss=0.02028804176035438
Epoch #36: loss=0.030235747284518222
Epoch #37: loss=0.03470699409988763
Epoch #38: loss=0.024205978550818647
Epoch #39: loss=0.027853049116714632
Epoch #40: loss=0.026502599246322603
Epoch #41: loss=0.027993316124519916
Epoch #42: loss=0.027601182137888366
Epoch #43: loss=0.01985436735085096
Epoch #44: loss=0.021127842007891966
Epoch #45: loss=0.02535746616954908
Epoch #46: loss=0.02497701251478717
Epoch #47: loss=0.01972809319419971
Epoch #48: loss=0.020843938866629136
Epoch #49: loss=0.02422022703294124
Epoch #50: loss=0.02478794178981472
Epoch #51: loss=0.01937056698247274
Epoch #52: loss=0.024757852844143672
Epoch #53: loss=0.026982032951310558
Epoch #54: loss=0.022588261969290896
Epoch #55: loss=0.026853847671754152
Epoch #56: loss=0.023601074970381476
Epoch #57: loss=0.02912682657923333
Epoch #58: loss=0.016901761253123853
Epoch #59: loss=0.02240478769288544
Epoch #60: loss=0.026987105958227987
Epoch #61: loss=0.02047927927824763
Epoch #62: loss=0.01711015500584373
Epoch #63: loss=0.02241535237969081
Epoch #64: loss=0.024169363546851032
Epoch #65: loss=0.01885451716717339
Epoch #66: loss=0.021366185392784072
Epoch #67: loss=0.017143113102629556
Epoch #68: loss=0.021686145174589184
Epoch #69: loss=0.021566502830627436
Epoch #70: loss=0.02513254287979484
Epoch #71: loss=0.020370314551486572
Epoch #72: loss=0.018729012632878454
Epoch #73: loss=0.019453229152566226
Epoch #74: loss=0.02106068220266705
Epoch #75: loss=0.01845314940858469
Epoch #76: loss=0.013728899280616309
Epoch #77: loss=0.017569589334489096
Epoch #78: loss=0.017441581720145136
Epoch #79: loss=0.03094882192554753
Epoch #80: loss=0.01891062505415268
Epoch #81: loss=0.01818360673808445
Epoch #82: loss=0.01994011175403655
Epoch #83: loss=0.021946805898851993
Epoch #84: loss=0.018058326032621724
Epoch #85: loss=0.016112318574104452
Epoch #86: loss=0.017665797673581483
Epoch #87: loss=0.01759030369763234
Epoch #88: loss=0.018527269367717456
Epoch #89: loss=0.015142121247455006
Epoch #90: loss=0.01615679512363768
Epoch #91: loss=0.014892869039687956
Epoch #92: loss=0.014897585499759853
Epoch #93: loss=0.019547779230322054
Epoch #94: loss=0.013806194703436076
Epoch #95: loss=0.020830853523350956
Epoch #96: loss=0.021741089297186673
Epoch #97: loss=0.015941619443806856
Epoch #98: loss=0.014462982571472497
Epoch #99: loss=0.02130342409372576
Epoch #100: loss=0.0140033552052502
Epoch #101: loss=0.018306706170657674
Epoch #102: loss=0.01508314369883263
Epoch #103: loss=0.01658323669160728
Epoch #104: loss=0.014755195166882205
Epoch #105: loss=0.01912137009617591
Epoch #106: loss=0.022127830371877367
Epoch #107: loss=0.01570900598420239
Epoch #108: loss=0.014441744706713187
Epoch #109: loss=0.02451527342098731
Epoch #110: loss=0.018886311563808274
Epoch #111: loss=0.02158771936586307
Epoch #112: loss=0.012760706653751055
Epoch #113: loss=0.013282955567780702
Epoch #114: loss=0.012377493728009056
Epoch #115: loss=0.01736308088622501
Epoch #116: loss=0.02355922050934716
Epoch #117: loss=0.015704873756480595
Epoch #118: loss=0.025448213720602856
Epoch #119: loss=0.019380695054708727
Epoch #120: loss=0.013172384578927308
Epoch #121: loss=0.013944740569479966
Epoch #122: loss=0.01424022848448268
Epoch #123: loss=0.01723349457511451
Epoch #124: loss=0.01635699141750026
Epoch #125: loss=0.016235298624822654
Epoch #126: loss=0.014083573477212105
Epoch #127: loss=0.01763280629274088
Epoch #128: loss=0.014728838660498867
Epoch #129: loss=0.014309105460040597
Epoch #130: loss=0.014410329034109015
Epoch #131: loss=0.01363908430386734
Epoch #132: loss=0.011922022827324578
Epoch #133: loss=0.018465463001011026
Epoch #134: loss=0.017135595001610573
Epoch #135: loss=0.016935132558519875
Epoch #136: loss=0.010919823102713956
Epoch #137: loss=0.01738174622026888
Epoch #138: loss=0.02324736292096717
Epoch #139: loss=0.016482639799617706
Epoch #140: loss=0.011980227154306324
Epoch #141: loss=0.014483997156987435
Epoch #142: loss=0.012483598566472057
Epoch #143: loss=0.012067829802097179
Epoch #144: loss=0.014118534879544375
Epoch #145: loss=0.014767142336707012
Epoch #146: loss=0.013033389423399348
Epoch #147: loss=0.017810007239121916
Epoch #148: loss=0.021088377897035753
Epoch #149: loss=0.016522187707188274
Epoch #150: loss=0.013217634191924277
Epoch #151: loss=0.013576117046691101
Epoch #152: loss=0.012797947503302985
Epoch #153: loss=0.013341440306584847
Epoch #154: loss=0.019101113913341308
Epoch #155: loss=0.012367021310534233
Epoch #156: loss=0.010514928884692082
Epoch #157: loss=0.010078814497437623
Epoch #158: loss=0.016757081062325884
Epoch #159: loss=0.013077867769670992
Epoch #160: loss=0.01319552338425258
Epoch #161: loss=0.01492824593058534
Epoch #162: loss=0.020842717083446052
Epoch #163: loss=0.014665013266170937
Epoch #164: loss=0.010478033636788361
Epoch #165: loss=0.013250039577169
Epoch #166: loss=0.013724348108481828
Epoch #167: loss=0.012229079755521637
Epoch #168: loss=0.016292961505901423
Epoch #169: loss=0.012683072118640813
Epoch #170: loss=0.012819943191619545
Epoch #171: loss=0.012867545454148012
Epoch #172: loss=0.007800774496264263
Epoch #173: loss=0.015392791885952174
Epoch #174: loss=0.012106289177318767
Epoch #175: loss=0.010081033743425467
Epoch #176: loss=0.010138489285414531
Epoch #177: loss=0.011548555241191511
Epoch #178: loss=0.020070208742971822
Epoch #179: loss=0.013732591051200274
Epoch #180: loss=0.01187755465239367
Epoch #181: loss=0.01570207883131705
Epoch #182: loss=0.009361437923089626
Epoch #183: loss=0.010206568321070295
Epoch #184: loss=0.01256833068766029
Epoch #185: loss=0.011192160656679944
Epoch #186: loss=0.01272636357961146
Epoch #187: loss=0.013255869863564659
Epoch #188: loss=0.014099633214523895
Epoch #189: loss=0.01095893633191632
Epoch #190: loss=0.01206544197379544
Epoch #191: loss=0.024491805836013833
Epoch #192: loss=0.014864107542821263
Epoch #193: loss=0.012627145086514404
Epoch #194: loss=0.017338924653516996
Epoch #195: loss=0.020006320057544345
Epoch #196: loss=0.013549993661724238
Epoch #197: loss=0.014933701771246552
Epoch #198: loss=0.013368064715975868
Epoch #199: loss=0.010619085722411357
Epoch #200: loss=0.01161276618780822
Epoch #201: loss=0.013434032851123868
Epoch #202: loss=0.012733528983596133
Epoch #203: loss=0.011818884059050341
Epoch #204: loss=0.015456314740495166
Epoch #205: loss=0.011753189632020777
Epoch #206: loss=0.009401631089793666
Epoch #207: loss=0.01370500792273211
Epoch #208: loss=0.012442558657189065
Epoch #209: loss=0.012685797483757979
Epoch #210: loss=0.008896273903430842
Epoch #211: loss=0.01566199524099928
Epoch #212: loss=0.011673479322386542
Epoch #213: loss=0.01879208700462858
Epoch #214: loss=0.013707307064276562
Epoch #215: loss=0.015444929813201558
Epoch #216: loss=0.011190590392378056
Epoch #217: loss=0.014165850663686409
Epoch #218: loss=0.014768744543026985
Epoch #219: loss=0.009222816327103454
Epoch #220: loss=0.011131027191855462
Epoch #221: loss=0.01198471478026792
Epoch #222: loss=0.015565343321110026
Epoch #223: loss=0.015762327903692645
Epoch #224: loss=0.01039048231810747
Epoch #225: loss=0.008202377844801913
Epoch #226: loss=0.011131977098121838
Epoch #227: loss=0.016934427446720246
Epoch #228: loss=0.010957161105083123
Epoch #229: loss=0.010471456938357774
Epoch #230: loss=0.01894346259845906
Epoch #231: loss=0.009643892997526961
Epoch #232: loss=0.01352193334695146
Epoch #233: loss=0.008444670765703047
Epoch #234: loss=0.0133241715758587
Epoch #235: loss=0.012152330682094196
Epoch #236: loss=0.010849818803872828
Epoch #237: loss=0.009473687665515894
Epoch #238: loss=0.012945626459240822
Epoch #239: loss=0.012716838997833064
Epoch #240: loss=0.009629612403869748
Epoch #241: loss=0.011827909555849662
Epoch #242: loss=0.009317209182484734
Epoch #243: loss=0.010895118104954204
Epoch #244: loss=0.01056979485727574
Epoch #245: loss=0.010282073042281407
Epoch #246: loss=0.011498991396021153
Epoch #247: loss=0.010678592564560952
Epoch #248: loss=0.011224597911067023
Epoch #249: loss=0.009053642509478339

Training time: 10:22:59.302462

Finished.
n2one setting etth1_traffic_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_traffic_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_traffic_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.1627e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.86087e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.40056e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.1627e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3897645716392696, 'MAE': 0.44323215460072535}
Finished.
------------------------- record done -------------------------
n2one setting etth1_traffic_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_traffic_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_traffic_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.26726e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.6667e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.6667e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.6630484275548822, 'MAE': 0.6559962435237026}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_weather_exchange', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_weather_exchange_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=4.964690557340297
Epoch #1: loss=3.0674407685675273
Epoch #2: loss=2.3566663730435256
Epoch #3: loss=2.189446728403975
Epoch #4: loss=1.9203467717984828
Epoch #5: loss=1.9025804676660678
Epoch #6: loss=1.8161440535289486
Epoch #7: loss=1.7003557362207553
Epoch #8: loss=1.642431378364563
Epoch #9: loss=1.5452333572434216
Epoch #10: loss=1.4131915511154547
Epoch #11: loss=1.3614621424093478
Epoch #12: loss=1.275586568727726
Epoch #13: loss=1.186704001775602
Epoch #14: loss=1.1849995764290415
Epoch #15: loss=1.2510591251094167
Epoch #16: loss=1.124777410088516
Epoch #17: loss=1.0585217606730577
Epoch #18: loss=1.1002598695638703
Epoch #19: loss=1.0175305663085565
Epoch #20: loss=0.9957363343820339
Epoch #21: loss=0.979921891921904
Epoch #22: loss=0.9781964493960869
Epoch #23: loss=0.8731420170970079
Epoch #24: loss=0.8956020416283026
Epoch #25: loss=0.8156643117346415
Epoch #26: loss=0.789879692763817
Epoch #27: loss=0.8238736972576235
Epoch #28: loss=0.8006429119807917
Epoch #29: loss=0.8065377299378558
Epoch #30: loss=0.7991779439333009
Epoch #31: loss=0.7155066743129637
Epoch #32: loss=0.7177271414093855
Epoch #33: loss=0.6906052675189042
Epoch #34: loss=0.7437635035049625
Epoch #35: loss=0.6390859084885295
Epoch #36: loss=0.7550097776622307
Epoch #37: loss=0.656264289850142
Epoch #38: loss=0.6833410648311057
Epoch #39: loss=0.6472205854043728
Epoch #40: loss=0.6181904440972863
Epoch #41: loss=0.6240279885326944
Epoch #42: loss=0.6298125524346422
Epoch #43: loss=0.6826519450036491
Epoch #44: loss=0.6051772171404304
Epoch #45: loss=0.6139776757577571
Epoch #46: loss=0.5724797982995103
Epoch #47: loss=0.674188923545
Epoch #48: loss=0.6037455055771804
Epoch #49: loss=0.5707379521393194
Epoch #50: loss=0.48953247433755454
Epoch #51: loss=0.5123685111359852
Epoch #52: loss=0.5318227148637539
Epoch #53: loss=0.6375009766439113
Epoch #54: loss=0.6034387073865751
Epoch #55: loss=0.4757138527021175
Epoch #56: loss=0.4369526527276853
Epoch #57: loss=0.46283282448605795
Epoch #58: loss=0.5119827062618442
Epoch #59: loss=0.4578949511051178
Epoch #60: loss=0.5334680632847112
Epoch #61: loss=0.44691708175147454
Epoch #62: loss=0.4331135677128303
Epoch #63: loss=0.3906302114085453
Epoch #64: loss=0.4920037795857685
Epoch #65: loss=0.38220113225099517
Epoch #66: loss=0.3887589937303124
Epoch #67: loss=0.48786727647955824
Epoch #68: loss=0.40493587313628776
Epoch #69: loss=0.3747707361855158
Epoch #70: loss=0.4641109130731443
Epoch #71: loss=0.40335511398024676
Epoch #72: loss=0.3838965267669864
Epoch #73: loss=0.39748506829506014
Epoch #74: loss=0.4571324870353792
Epoch #75: loss=0.34097122782614175
Epoch #76: loss=0.3034559121219123
Epoch #77: loss=0.3928275508124654
Epoch #78: loss=0.32982472748291203
Epoch #79: loss=0.39282896024424857
Epoch #80: loss=0.3692316736389951
Epoch #81: loss=0.35124529643756586
Epoch #82: loss=0.28736478308352026
Epoch #83: loss=0.2964946845682656
Epoch #84: loss=0.3432923668041462
Epoch #85: loss=0.29779835063509824
Epoch #86: loss=0.3654830101423147
Epoch #87: loss=0.3708776199236149
Epoch #88: loss=0.31216409657059646
Epoch #89: loss=0.31247172032187626
Epoch #90: loss=0.32053256180228257
Epoch #91: loss=0.288382079179694
Epoch #92: loss=0.2755607379282393
Epoch #93: loss=0.26771448043788354
Epoch #94: loss=0.2648759100858758
Epoch #95: loss=0.25202915308679025
Epoch #96: loss=0.3284095185922413
Epoch #97: loss=0.2713392876633784
Epoch #98: loss=0.23614526103909422
Epoch #99: loss=0.2947083502644446
Epoch #100: loss=0.305629972641061
Epoch #101: loss=0.28090793366839245
Epoch #102: loss=0.24424261781500606
Epoch #103: loss=0.2922819245879243
Epoch #104: loss=0.2666693462467775
Epoch #105: loss=0.25180715486043836
Epoch #106: loss=0.2848343603858134
Epoch #107: loss=0.23483952443774153
Epoch #108: loss=0.27036719442140766
Epoch #109: loss=0.24854412656731723
Epoch #110: loss=0.22087433570768775
Epoch #111: loss=0.20835792291455152
Epoch #112: loss=0.1924167333579645
Epoch #113: loss=0.2126748844436029
Epoch #114: loss=0.4613203449947078
Epoch #115: loss=0.24714407815438946
Epoch #116: loss=0.24881768898993004
Epoch #117: loss=0.28251501318158173
Epoch #118: loss=0.3429790958762169
Epoch #119: loss=0.25806294745061453
Epoch #120: loss=0.17319301933777043
Epoch #121: loss=0.20675615820942855
Epoch #122: loss=0.20473299866042485
Epoch #123: loss=0.20689410498229469
Epoch #124: loss=0.1919016321984733
Epoch #125: loss=0.2695620290753318
Epoch #126: loss=0.16798359619044675
Epoch #127: loss=0.18591652837831799
Epoch #128: loss=0.1763061879248154
Epoch #129: loss=0.175058128175939
Epoch #130: loss=0.18641789720916166
Epoch #131: loss=0.20013502231094896
Epoch #132: loss=0.18818093418348125
Epoch #133: loss=0.21913909403289236
Epoch #134: loss=0.2195361866274985
Epoch #135: loss=0.20881192876798352
Epoch #136: loss=0.17725879344634893
Epoch #137: loss=0.20661870063078114
Epoch #138: loss=0.20535600176308214
Epoch #139: loss=0.19049272886136684
Epoch #140: loss=0.24603072699250245
Epoch #141: loss=0.17241374603131923
Epoch #142: loss=0.24066727681130898
Epoch #143: loss=0.14264966338509466
Epoch #144: loss=0.16985599205988208
Epoch #145: loss=0.1727038072194995
Epoch #146: loss=0.20918408081662365
Epoch #147: loss=0.27618154447253157
Epoch #148: loss=0.20600422444503483
Epoch #149: loss=0.1658582802771068
Epoch #150: loss=0.14900074717475148
Epoch #151: loss=0.14634598668937276
Epoch #152: loss=0.1288803839465467
Epoch #153: loss=0.2126410379097229
Epoch #154: loss=0.20505465448993007
Epoch #155: loss=0.14890971080195614
Epoch #156: loss=0.16449036331074993
Epoch #157: loss=0.12728952684598724
Epoch #158: loss=0.12964500096149562
Epoch #159: loss=0.1281271848555018
Epoch #160: loss=0.1237566168079289
Epoch #161: loss=0.1322155268181388
Epoch #162: loss=0.23999482302404032
Epoch #163: loss=0.1810137943887129
Epoch #164: loss=0.1348642344336684
Epoch #165: loss=0.16406313166385744
Epoch #166: loss=0.16425788634252259
Epoch #167: loss=0.20889072201964332
Epoch #168: loss=0.16047810581399174
Epoch #169: loss=0.20415334521633824
Epoch #170: loss=0.14597399650913914
Epoch #171: loss=0.12870692343610088
Epoch #172: loss=0.12642088818659142
Epoch #173: loss=0.12367909606091859
Epoch #174: loss=0.1913719273558477
Epoch #175: loss=0.14703911320283647
Epoch #176: loss=0.12831047713393118
Epoch #177: loss=0.13335554846903172
Epoch #178: loss=0.15183119266861822
Epoch #179: loss=0.12984432788883768
Epoch #180: loss=0.08332823562185938
Epoch #181: loss=0.12613748895322405
Epoch #182: loss=0.11439833599256306
Epoch #183: loss=0.10913115962431198
Epoch #184: loss=0.14692404961622343
Epoch #185: loss=0.15124787644642154
Epoch #186: loss=0.18499920090160718
Epoch #187: loss=0.1443592299957101
Epoch #188: loss=0.18956781669360837
Epoch #189: loss=0.2072441609258332
Epoch #190: loss=0.15350478605889692
Epoch #191: loss=0.10348289927876578
Epoch #192: loss=0.13342142868332746
Epoch #193: loss=0.17871612010569107
Epoch #194: loss=0.11816340117011129
Epoch #195: loss=0.12686439371872238
Epoch #196: loss=0.10765415212003196
Epoch #197: loss=0.15013539904683101
Epoch #198: loss=0.11208906851527167
Epoch #199: loss=0.16536800745056895
Epoch #200: loss=0.10039440515201266
Epoch #201: loss=0.12194315616677447
Epoch #202: loss=0.15553601417781376
Epoch #203: loss=0.13518716703827788
Epoch #204: loss=0.15868049346637436
Epoch #205: loss=0.10500206403070833
Epoch #206: loss=0.15216286539486268
Epoch #207: loss=0.1427246183611271
Epoch #208: loss=0.12897184245833537
Epoch #209: loss=0.16724149573866914
Epoch #210: loss=0.127509967492121
Epoch #211: loss=0.1690175764989562
Epoch #212: loss=0.24283071216650126
Epoch #213: loss=0.17499285636515152
Epoch #214: loss=0.15584869900854623
Epoch #215: loss=0.12847555873960984
Epoch #216: loss=0.29920529796764617
Epoch #217: loss=0.13877604956307063
Epoch #218: loss=0.13589879079926304
Epoch #219: loss=0.0942981058231941
Epoch #220: loss=0.12452138047211053
Epoch #221: loss=0.13872359965632602
Epoch #222: loss=0.10389951580181354
Epoch #223: loss=0.12803041198995055
Epoch #224: loss=0.12603742397594742
Epoch #225: loss=0.09972715491383541
Epoch #226: loss=0.07486935900297106
Epoch #227: loss=0.0990730676482
Epoch #228: loss=0.10296597586172383
Epoch #229: loss=0.08770628146282057
Epoch #230: loss=0.08988949860923173
Epoch #231: loss=0.11881508478304235
Epoch #232: loss=0.09000299743762831
Epoch #233: loss=0.163301857188344
Epoch #234: loss=0.10800072605290063
Epoch #235: loss=0.1411607042409298
Epoch #236: loss=0.11396754328615782
Epoch #237: loss=0.08179938929473482
Epoch #238: loss=0.08081838056990286
Epoch #239: loss=0.0858005920379627
Epoch #240: loss=0.11602738013536465
Epoch #241: loss=0.06701300781583641
Epoch #242: loss=0.11907764362943608
Epoch #243: loss=0.10961328301487899
Epoch #244: loss=0.0887475864189427
Epoch #245: loss=0.08492932888883643
Epoch #246: loss=0.08938233222721553
Epoch #247: loss=0.10786709493798453
Epoch #248: loss=0.07476308914582903
Epoch #249: loss=0.06469778864212879

Training time: 0:37:05.055344

Finished.
n2one setting etth1_weather_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_weather_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_weather_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.32234e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.59889e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.32234e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.37032804978946704, 'MAE': 0.4335114653526647}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm1_ettm2', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm1_ettm2_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=4.295360351430959
Epoch #1: loss=2.4615217735027444
Epoch #2: loss=2.122560632639918
Epoch #3: loss=1.8645220008389702
Epoch #4: loss=1.657319710172456
Epoch #5: loss=1.5199568641596828
Epoch #6: loss=1.4335594670525913
Epoch #7: loss=1.280447898239925
Epoch #8: loss=1.2000682847253208
Epoch #9: loss=1.1442911892101681
Epoch #10: loss=1.1017128804634357
Epoch #11: loss=1.0161648947617103
Epoch #12: loss=0.9915195230779976
Epoch #13: loss=0.9534074992969118
Epoch #14: loss=0.9106168911374849
Epoch #15: loss=0.8374876688266623
Epoch #16: loss=0.7902934386812407
Epoch #17: loss=0.871909893792251
Epoch #18: loss=0.8419678498958719
Epoch #19: loss=0.8025928715179707
Epoch #20: loss=0.7212092280387878
Epoch #21: loss=0.7254645577792463
Epoch #22: loss=0.7261595027200107
Epoch #23: loss=0.6647421748473726
Epoch #24: loss=0.6465946076245144
Epoch #25: loss=0.6377359330654144
Epoch #26: loss=0.6418160693398838
Epoch #27: loss=0.5820954390640917
Epoch #28: loss=0.6033703006547073
Epoch #29: loss=0.6001432414712577
Epoch #30: loss=0.6748904606391644
Epoch #31: loss=0.5486481395261041
Epoch #32: loss=0.5681234269306578
Epoch #33: loss=0.5486754908643919
Epoch #34: loss=0.5322135337467852
Epoch #35: loss=0.45418675398004466
Epoch #36: loss=0.5282621558370262
Epoch #37: loss=0.46842767041305017
Epoch #38: loss=0.5260421952296948
Epoch #39: loss=0.47976462799927283
Epoch #40: loss=0.5510022496354992
Epoch #41: loss=0.5208847214435709
Epoch #42: loss=0.4300333734216361
Epoch #43: loss=0.4019537115919179
Epoch #44: loss=0.5737245658348347
Epoch #45: loss=0.4442972643622037
Epoch #46: loss=0.438276796505369
Epoch #47: loss=0.4301922583374484
Epoch #48: loss=0.34940770011523675
Epoch #49: loss=0.393199913974466
Epoch #50: loss=0.40630815101080925
Epoch #51: loss=0.44188703647975264
Epoch #52: loss=0.3862482699854621
Epoch #53: loss=0.31829859162199087
Epoch #54: loss=0.33929673556623785
Epoch #55: loss=0.40651104008329325
Epoch #56: loss=0.41464179908407145
Epoch #57: loss=0.35658838368695356
Epoch #58: loss=0.4279362754575137
Epoch #59: loss=0.4305034105120034
Epoch #60: loss=0.3716235541064164
Epoch #61: loss=0.3350644610051451
Epoch #62: loss=0.34529535575159664
Epoch #63: loss=0.30180250365158606
Epoch #64: loss=0.35778356471966055
Epoch #65: loss=0.3939321308300413
Epoch #66: loss=0.4051644550315265
Epoch #67: loss=0.369668530492947
Epoch #68: loss=0.2899687737226486
Epoch #69: loss=0.23495181007631893
Epoch #70: loss=0.24360523372888565
Epoch #71: loss=0.23308375092415973
Epoch #72: loss=0.2636264369919382
Epoch #73: loss=0.28218599383173315
Epoch #74: loss=0.23357067745307397
Epoch #75: loss=0.21833158258734078
Epoch #76: loss=0.2387071182501727
Epoch #77: loss=0.20453738446893363
Epoch #78: loss=0.19118934047633204
Epoch #79: loss=0.24724916163189659
Epoch #80: loss=0.2673394821327308
Epoch #81: loss=0.3022428861465947
Epoch #82: loss=0.22242771217535282
Epoch #83: loss=0.2369529448192695
Epoch #84: loss=0.22572291719502416
Epoch #85: loss=0.17025575529912423
Epoch #86: loss=0.1737449981015304
Epoch #87: loss=0.16561591638059453
Epoch #88: loss=0.20029817881255313
Epoch #89: loss=0.15883820002962803
Epoch #90: loss=0.1788625866174698
Epoch #91: loss=0.14326911098484335
Epoch #92: loss=0.13871962975325255
Epoch #93: loss=0.15039495712724224
Epoch #94: loss=0.1747082425602551
Epoch #95: loss=0.18776517759623199
Epoch #96: loss=0.1855935429961517
Epoch #97: loss=0.16353223447141976
Epoch #98: loss=0.1721137781338445
Epoch #99: loss=0.18352219796386257
Epoch #100: loss=0.14142369478940964
Epoch #101: loss=0.17520333775158586
Epoch #102: loss=0.14079771216573386
Epoch #103: loss=0.13539787831491437
Epoch #104: loss=0.15537616828906126
Epoch #105: loss=0.14155966422424235
Epoch #106: loss=0.13943447069875126
Epoch #107: loss=0.16780789132262097
Epoch #108: loss=0.12419315157779331
Epoch #109: loss=0.10653725671100206
Epoch #110: loss=0.14074979632579046
Epoch #111: loss=0.13552496453811383
Epoch #112: loss=0.13561561369690403
Epoch #113: loss=0.10950177291343952
Epoch #114: loss=0.15123014511733218
Epoch #115: loss=0.14727268740534782
Epoch #116: loss=0.1891543897318429
Epoch #117: loss=0.12157127620845005
Epoch #118: loss=0.13335315504207693
Epoch #119: loss=0.13086150599450902
Epoch #120: loss=0.171331145511619
Epoch #121: loss=0.09729718879379075
Epoch #122: loss=0.12496933456638763
Epoch #123: loss=0.14516064017240343
Epoch #124: loss=0.08505319174507568
Epoch #125: loss=0.0805043890943815
Epoch #126: loss=0.11089267838617851
Epoch #127: loss=0.09279285178616128
Epoch #128: loss=0.12318554045311336
Epoch #129: loss=0.17932078088151998
Epoch #130: loss=0.16291562577003035
Epoch #131: loss=0.1342447311456861
Epoch #132: loss=0.13290053233504295
Epoch #133: loss=0.10756798512462912
Epoch #134: loss=0.17475724875413137
Epoch #135: loss=0.14745293769600062
Epoch #136: loss=0.2159359376749088
Epoch #137: loss=0.11969928777423398
Epoch #138: loss=0.1077414675904759
Epoch #139: loss=0.13250606128110967
Epoch #140: loss=0.0941221977359262
Epoch #141: loss=0.08580590701051827
Epoch #142: loss=0.1470899205526401
Epoch #143: loss=0.1260104906456224
Epoch #144: loss=0.21252376862384123
Epoch #145: loss=0.09347631435455947
Epoch #146: loss=0.1034253192102087
Epoch #147: loss=0.1082855424811614
Epoch #148: loss=0.10729898416019719
Epoch #149: loss=0.08813703965781064
Epoch #150: loss=0.10099019026704903
Epoch #151: loss=0.08781661228116217
Epoch #152: loss=0.12586516206120624
Epoch #153: loss=0.10900642832034621
Epoch #154: loss=0.06776070710400055
Epoch #155: loss=0.1037966869129189
Epoch #156: loss=0.07845442138355353
Epoch #157: loss=0.09627835571380525
Epoch #158: loss=0.09420987170446536
Epoch #159: loss=0.10917820325442429
Epoch #160: loss=0.08670772631363623
Epoch #161: loss=0.07518028872537202
Epoch #162: loss=0.06906451554647808
Epoch #163: loss=0.07327863047349042
Epoch #164: loss=0.08416024126626294
Epoch #165: loss=0.06793258358435385
Epoch #166: loss=0.10834942122214827
Epoch #167: loss=0.12367457087183821
Epoch #168: loss=0.22303625273293462
Epoch #169: loss=0.09568470257238068
Epoch #170: loss=0.06922011578391338
Epoch #171: loss=0.10552510741198885
Epoch #172: loss=0.0785667821764946
Epoch #173: loss=0.08319595485026467
Epoch #174: loss=0.08585191685064085
Epoch #175: loss=0.12905952218791533
Epoch #176: loss=0.07902326800956808
Epoch #177: loss=0.08096819775628633
Epoch #178: loss=0.0864775288400465
Epoch #179: loss=0.07231767067749953
Epoch #180: loss=0.07789817609792125
Epoch #181: loss=0.07666699983308027
Epoch #182: loss=0.11618158375394755
Epoch #183: loss=0.09457936176452143
Epoch #184: loss=0.09901167850556045
Epoch #185: loss=0.09332540579910936
Epoch #186: loss=0.0886938146090713
Epoch #187: loss=0.073355362140413
Epoch #188: loss=0.07575870706731903
Epoch #189: loss=0.06636392777978346
Epoch #190: loss=0.11662275851543608
Epoch #191: loss=0.1210756666059124
Epoch #192: loss=0.0847817630796083
Epoch #193: loss=0.08893199984369607
Epoch #194: loss=0.09063271234004662
Epoch #195: loss=0.14388260640332412
Epoch #196: loss=0.08672611113509228
Epoch #197: loss=0.06542394862606607
Epoch #198: loss=0.051995955600306905
Epoch #199: loss=0.3112740895614542
Epoch #200: loss=0.10167888115192282
Epoch #201: loss=0.09022413810779309
Epoch #202: loss=0.14381259609142255
Epoch #203: loss=0.08479385700976026
Epoch #204: loss=0.11818910974623828
Epoch #205: loss=0.0577695323475476
Epoch #206: loss=0.06864492001076197
Epoch #207: loss=0.05759079510281826
Epoch #208: loss=0.05818924461973125
Epoch #209: loss=0.06828858653597276
Epoch #210: loss=0.04992284195433403
Epoch #211: loss=0.06420659026580638
Epoch #212: loss=0.05374508864920715
Epoch #213: loss=0.05474806660465125
Epoch #214: loss=0.05640853800136467
Epoch #215: loss=0.06454276410734346
Epoch #216: loss=0.0716420579701662
Epoch #217: loss=0.11394105880553353
Epoch #218: loss=0.18447290097588095
Epoch #219: loss=0.10965928852815053
Epoch #220: loss=0.07741415198763897
Epoch #221: loss=0.058621652745481194
Epoch #222: loss=0.07740986764687917
Epoch #223: loss=0.05302228998585508
Epoch #224: loss=0.06155504507879759
Epoch #225: loss=0.058997741290207566
Epoch #226: loss=0.08921233185663305
Epoch #227: loss=0.10989611069190092
Epoch #228: loss=0.19708344340324402
Epoch #229: loss=0.09333124114521618
Epoch #230: loss=0.05778606171751845
Epoch #231: loss=0.04855547466411673
Epoch #232: loss=0.07356786368222072
Epoch #233: loss=0.055272055051193154
Epoch #234: loss=0.04609268585798042
Epoch #235: loss=0.03978319324809929
Epoch #236: loss=0.05222203062269194
Epoch #237: loss=0.051735991483618474
Epoch #238: loss=0.05711825358970412
Epoch #239: loss=0.05686329823822297
Epoch #240: loss=0.04083533731192864
Epoch #241: loss=0.04954935391915256
Epoch #242: loss=0.04964440218012395
Epoch #243: loss=0.059463731767930864
Epoch #244: loss=0.06315775239711692
Epoch #245: loss=0.04249450938519219
Epoch #246: loss=0.06020937106925352
Epoch #247: loss=0.04414639522417866
Epoch #248: loss=0.037500192074040914
Epoch #249: loss=0.12062813733415358

Training time: 0:27:43.225295

Finished.
n2one setting etth2_ettm1_ettm2 -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_ettm2_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_ettm1_ettm2', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.485e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.49139e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.485e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.37000959241279235, 'MAE': 0.4297230797593059}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm1_ettm2 -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_ettm2_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_ettm1_ettm2', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.64454e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.05714e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.64454e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3788287691053273, 'MAE': 0.44476406210831393}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm1_ettm2 -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_ettm2_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_ettm1_ettm2', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.57049e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.2635477585435096, 'MAE': 0.340354152532912}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm1_electricity', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm1_electricity_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.6532790463934255
Epoch #1: loss=0.6725142463646104
Epoch #2: loss=0.4715360943722514
Epoch #3: loss=0.37814141994556494
Epoch #4: loss=0.30403068978174597
Epoch #5: loss=0.2543162760437414
Epoch #6: loss=0.24319711582498915
Epoch #7: loss=0.20770058686402695
Epoch #8: loss=0.18301157092889853
Epoch #9: loss=0.15865465239305762
Epoch #10: loss=0.1453832283418263
Epoch #11: loss=0.1462411292688509
Epoch #12: loss=0.12386701317575477
Epoch #13: loss=0.11011303515670749
Epoch #14: loss=0.11706018114907552
Epoch #15: loss=0.10366177524283396
Epoch #16: loss=0.0929603588583283
Epoch #17: loss=0.10762080767227661
Epoch #18: loss=0.08424212679179018
Epoch #19: loss=0.0894321986943879
Epoch #20: loss=0.07449383891646401
Epoch #21: loss=0.06744532223109563
Epoch #22: loss=0.06986918871546477
Epoch #23: loss=0.053258911610352955
Epoch #24: loss=0.060514821931939564
Epoch #25: loss=0.06534903457630041
Epoch #26: loss=0.05885218428365425
Epoch #27: loss=0.04799245988708374
Epoch #28: loss=0.05099858356650732
Epoch #29: loss=0.048602309921388254
Epoch #30: loss=0.045938560106601994
Epoch #31: loss=0.070429277637902
Epoch #32: loss=0.04772973295155594
Epoch #33: loss=0.050174657091948925
Epoch #34: loss=0.05149552833624074
Epoch #35: loss=0.03410539202183309
Epoch #36: loss=0.03969058117027062
Epoch #37: loss=0.036796163783372984
Epoch #38: loss=0.03659020323625005
Epoch #39: loss=0.03468963817437797
Epoch #40: loss=0.03220010115929871
Epoch #41: loss=0.03299916520780694
Epoch #42: loss=0.040134794479867876
Epoch #43: loss=0.02600370185720325
Epoch #44: loss=0.02972107736536667
Epoch #45: loss=0.026139918318812277
Epoch #46: loss=0.02607131053990297
Epoch #47: loss=0.05414760850334216
Epoch #48: loss=0.029663692096627392
Epoch #49: loss=0.03792588328489358
Epoch #50: loss=0.030892663100970618
Epoch #51: loss=0.02363453792191075
Epoch #52: loss=0.03290695466985789
Epoch #53: loss=0.01716149251586634
Epoch #54: loss=0.022874112101889884
Epoch #55: loss=0.023638618285808943
Epoch #56: loss=0.03633248439858115
Epoch #57: loss=0.02885238739117914
Epoch #58: loss=0.02564803730445065
Epoch #59: loss=0.02640843346466346
Epoch #60: loss=0.023324208284122457
Epoch #61: loss=0.019116998802606776
Epoch #62: loss=0.01835543584407535
Epoch #63: loss=0.027331670366741365
Epoch #64: loss=0.02158169954147047
Epoch #65: loss=0.019785776333251535
Epoch #66: loss=0.019103483104622294
Epoch #67: loss=0.020764259642105452
Epoch #68: loss=0.02271054603419044
Epoch #69: loss=0.01769554147711106
Epoch #70: loss=0.02491052335768301
Epoch #71: loss=0.024332263407704027
Epoch #72: loss=0.021538025130700474
Epoch #73: loss=0.023561831614020444
Epoch #74: loss=0.022634719480941715
Epoch #75: loss=0.02008849135833548
Epoch #76: loss=0.029837667249908238
Epoch #77: loss=0.02256202071909944
Epoch #78: loss=0.019588593831581166
Epoch #79: loss=0.018441994335388373
Epoch #80: loss=0.0313534829841108
Epoch #81: loss=0.040292061437443336
Epoch #82: loss=0.018484134404235974
Epoch #83: loss=0.017119677310155644
Epoch #84: loss=0.020722361898618397
Epoch #85: loss=0.0162230638327327
Epoch #86: loss=0.03315504885843205
Epoch #87: loss=0.016060365015396347
Epoch #88: loss=0.02351146561741296
Epoch #89: loss=0.02398512688922836
Epoch #90: loss=0.02197741651818277
Epoch #91: loss=0.019778996754601146
Epoch #92: loss=0.01523856191612934
Epoch #93: loss=0.017668923414600766
Epoch #94: loss=0.015095144888618961
Epoch #95: loss=0.024973905385351002
Epoch #96: loss=0.01997821908828783
Epoch #97: loss=0.013973868330102689
Epoch #98: loss=0.014806975940569334
Epoch #99: loss=0.01731834150002555
Epoch #100: loss=0.01319043372021466
Epoch #101: loss=0.011315812779333618
Epoch #102: loss=0.015398673651908912
Epoch #103: loss=0.013485566069025843
Epoch #104: loss=0.019846967089396508
Epoch #105: loss=0.012847352813387421
Epoch #106: loss=0.021459461967625645
Epoch #107: loss=0.018642670547405593
Epoch #108: loss=0.02050648308029415
Epoch #109: loss=0.028841041291721856
Epoch #110: loss=0.015509928319435621
Epoch #111: loss=0.013884509757544385
Epoch #112: loss=0.02840924686731655
Epoch #113: loss=0.01265366819730457
Epoch #114: loss=0.011227600763336917
Epoch #115: loss=0.011335367161731145
Epoch #116: loss=0.011349396381350674
Epoch #117: loss=0.033273138718852624
Epoch #118: loss=0.028229959008103968
Epoch #119: loss=0.017996816410838317
Epoch #120: loss=0.01563822008170748
Epoch #121: loss=0.013182859431167895
Epoch #122: loss=0.01202583703992663
Epoch #123: loss=0.011179707801020306
Epoch #124: loss=0.00959206898282914
Epoch #125: loss=0.011256241898178082
Epoch #126: loss=0.013183308634282005
Epoch #127: loss=0.01560085350997845
Epoch #128: loss=0.014003304368507248
Epoch #129: loss=0.011378564726414329
Epoch #130: loss=0.010940663133793205
Epoch #131: loss=0.010242688401422263
Epoch #132: loss=0.01268141774514245
Epoch #133: loss=0.015411481240305468
Epoch #134: loss=0.01863347542483173
Epoch #135: loss=0.01537809702691383
Epoch #136: loss=0.012198707130208755
Epoch #137: loss=0.011596322196479446
Epoch #138: loss=0.01694036213137487
Epoch #139: loss=0.015484450647509918
Epoch #140: loss=0.0186844331194828
Epoch #141: loss=0.012603749179729099
Epoch #142: loss=0.009002364167870107
Epoch #143: loss=0.02167881543054053
Epoch #144: loss=0.013558242165680651
Epoch #145: loss=0.017086085070138878
Epoch #146: loss=0.015237140343394021
Epoch #147: loss=0.01174515450615738
Epoch #148: loss=0.009841164385152645
Epoch #149: loss=0.012919140577173426
Epoch #150: loss=0.009645166351861021
Epoch #151: loss=0.013280795057095411
Epoch #152: loss=0.009856397079154134
Epoch #153: loss=0.013665318384764518
Epoch #154: loss=0.015394097639819205
Epoch #155: loss=0.014223691655884725
Epoch #156: loss=0.0164082749102163
Epoch #157: loss=0.023301461622583237
Epoch #158: loss=0.012775661371604356
Epoch #159: loss=0.010687163569686308
Epoch #160: loss=0.014385921997275715
Epoch #161: loss=0.014277779793223932
Epoch #162: loss=0.012360691024570184
Epoch #163: loss=0.008882010995790193
Epoch #164: loss=0.01728137695504583
Epoch #165: loss=0.011158628185426647
Epoch #166: loss=0.0094278119001359
Epoch #167: loss=0.009262970650981037
Epoch #168: loss=0.010595417623780736
Epoch #169: loss=0.014644999633121488
Epoch #170: loss=0.014148984305116906
Epoch #171: loss=0.011034228627870112
Epoch #172: loss=0.03469642918697039
Epoch #173: loss=0.022610419727916827
Epoch #174: loss=0.01391351655909275
Epoch #175: loss=0.0153225149074535
Epoch #176: loss=0.011971364764477454
Epoch #177: loss=0.011866109050943579
Epoch #178: loss=0.008040440016667219
Epoch #179: loss=0.010765580310789143
Epoch #180: loss=0.012698364587535718
Epoch #181: loss=0.008288670151723153
Epoch #182: loss=0.009583689860318262
Epoch #183: loss=0.010584315668845105
Epoch #184: loss=0.006452358302565506
Epoch #185: loss=0.008683486057103373
Epoch #186: loss=0.014672182086727424
Epoch #187: loss=0.01624409306229842
Epoch #188: loss=0.012506790654812762
Epoch #189: loss=0.013063573438343166
Epoch #190: loss=0.013356636414063303
Epoch #191: loss=0.009700584397575705
Epoch #192: loss=0.01313966964871161
Epoch #193: loss=0.014965253092099949
Epoch #194: loss=0.020454925009850303
Epoch #195: loss=0.016833422346498025
Epoch #196: loss=0.009447271734748068
Epoch #197: loss=0.009271014737020931
Epoch #198: loss=0.012214316156569862
Epoch #199: loss=0.009429671410399085
Epoch #200: loss=0.019926666761686678
Epoch #201: loss=0.01350727213710096
Epoch #202: loss=0.009374914826927597
Epoch #203: loss=0.010987944141800233
Epoch #204: loss=0.009230629254148305
Epoch #205: loss=0.01358014039810648
Epoch #206: loss=0.013942795384614825
Epoch #207: loss=0.009390590127174959
Epoch #208: loss=0.01587676326641236
Epoch #209: loss=0.011585325840156618
Epoch #210: loss=0.011843557262557605
Epoch #211: loss=0.00890730957107091
Epoch #212: loss=0.01539803050267153
Epoch #213: loss=0.01013230402101584
Epoch #214: loss=0.007792472935252161
Epoch #215: loss=0.007217171349524758
Epoch #216: loss=0.013876885487176038
Epoch #217: loss=0.013415358889886455
Epoch #218: loss=0.012225977831779757
Epoch #219: loss=0.01746789428704572
Epoch #220: loss=0.026736105157391738
Epoch #221: loss=0.012109266167196134
Epoch #222: loss=0.00701733311630681
Epoch #223: loss=0.00922913829238665
Epoch #224: loss=0.012397168162635976
Epoch #225: loss=0.011256676631537335
Epoch #226: loss=0.009956424600931687
Epoch #227: loss=0.010077566639805257
Epoch #228: loss=0.010103378326691835
Epoch #229: loss=0.0099552831711944
Epoch #230: loss=0.021894178795988827
Epoch #231: loss=0.008127863498632645
Epoch #232: loss=0.01120127537169296
Epoch #233: loss=0.014353681107774201
Epoch #234: loss=0.011194423729468654
Epoch #235: loss=0.007994719094594743
Epoch #236: loss=0.009495598704985203
Epoch #237: loss=0.013517448105722264
Epoch #238: loss=0.02282963267161448
Epoch #239: loss=0.010627337678536157
Epoch #240: loss=0.007595177076050908
Epoch #241: loss=0.012905695337915196
Epoch #242: loss=0.008310754537313853
Epoch #243: loss=0.0134105627032843
Epoch #244: loss=0.012470391588759469
Epoch #245: loss=0.010664089131708172
Epoch #246: loss=0.01484787220656968
Epoch #247: loss=0.010160371844909514
Epoch #248: loss=0.015117588364223849
Epoch #249: loss=0.00839542190851314

Training time: 4:41:16.187214

Finished.
n2one setting etth2_ettm1_electricity -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_electricity_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_ettm1_electricity', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.04449e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.11254e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.38887e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.04449e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4135757089187671, 'MAE': 0.4757804255010162}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm1_electricity -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_electricity_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_ettm1_electricity', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.40761e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.40761e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3505192070329266, 'MAE': 0.38778962745403206}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm1_traffic', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm1_traffic_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.9885765475982969
Epoch #1: loss=0.36714722993360327
Epoch #2: loss=0.24688340725207872
Epoch #3: loss=0.1898182122756473
Epoch #4: loss=0.1527442907702855
Epoch #5: loss=0.1421786483377218
Epoch #6: loss=0.1127633011921055
Epoch #7: loss=0.10019883988213471
Epoch #8: loss=0.08972065012838522
Epoch #9: loss=0.07498723087536002
Epoch #10: loss=0.07468462391777642
Epoch #11: loss=0.05570251833626323
Epoch #12: loss=0.05120057093101257
Epoch #13: loss=0.050568832831446676
Epoch #14: loss=0.05460265570039734
Epoch #15: loss=0.044438667871343734
Epoch #16: loss=0.05051486810870384
Epoch #17: loss=0.04881485669228079
Epoch #18: loss=0.040495355603211054
Epoch #19: loss=0.03506264772731811
Epoch #20: loss=0.03271212396489732
Epoch #21: loss=0.043021726869813974
Epoch #22: loss=0.03513182353437349
Epoch #23: loss=0.03963269528811163
Epoch #24: loss=0.034328435936450574
Epoch #25: loss=0.024852550606804222
Epoch #26: loss=0.03904731849086767
Epoch #27: loss=0.02540141167516016
Epoch #28: loss=0.02847657878010068
Epoch #29: loss=0.023845204307343177
Epoch #30: loss=0.023291570936536034
Epoch #31: loss=0.02403751282631261
Epoch #32: loss=0.02923945891584894
Epoch #33: loss=0.03320420033361932
Epoch #34: loss=0.024331716232832562
Epoch #35: loss=0.027764049213477516
Epoch #36: loss=0.031204319405051965
Epoch #37: loss=0.023540773618945174
Epoch #38: loss=0.02076400161386118
Epoch #39: loss=0.020376694248327772
Epoch #40: loss=0.022989385192076127
Epoch #41: loss=0.020746442736642414
Epoch #42: loss=0.02361429340804038
Epoch #43: loss=0.02496735990392732
Epoch #44: loss=0.019573200285230997
Epoch #45: loss=0.021337860399150733
Epoch #46: loss=0.01887501454965042
Epoch #47: loss=0.022690525604015088
Epoch #48: loss=0.01777973823789745
Epoch #49: loss=0.022001883295045196
Epoch #50: loss=0.023509740059142296
Epoch #51: loss=0.028708381581567334
Epoch #52: loss=0.021250021164980187
Epoch #53: loss=0.016010628177173202
Epoch #54: loss=0.015673517781661674
Epoch #55: loss=0.017666578788951236
Epoch #56: loss=0.01613616379462738
Epoch #57: loss=0.020770115900946125
Epoch #58: loss=0.024237313795906216
Epoch #59: loss=0.01981116410335579
Epoch #60: loss=0.014511755400863793
Epoch #61: loss=0.018068150469943332
Epoch #62: loss=0.014296852538344947
Epoch #63: loss=0.018564901743758872
Epoch #64: loss=0.015502336201031787
Epoch #65: loss=0.016833861487678157
Epoch #66: loss=0.016124425574129086
Epoch #67: loss=0.019332269116355084
Epoch #68: loss=0.015902489647520602
Epoch #69: loss=0.019453766540589806
Epoch #70: loss=0.020812029013904977
Epoch #71: loss=0.015738582842690946
Epoch #72: loss=0.018954187156817747
Epoch #73: loss=0.01211775643579048
Epoch #74: loss=0.015105974759320484
Epoch #75: loss=0.01796145728182058
Epoch #76: loss=0.01809920709942658
Epoch #77: loss=0.01533807808389776
Epoch #78: loss=0.012018112180389421
Epoch #79: loss=0.01938738691387698
Epoch #80: loss=0.013717179700027124
Epoch #81: loss=0.014030206585448467
Epoch #82: loss=0.016024056305799273
Epoch #83: loss=0.009543483395034193
Epoch #84: loss=0.015121529530469243
Epoch #85: loss=0.016653740392406358
Epoch #86: loss=0.015853845509726936
Epoch #87: loss=0.014796438659025378
Epoch #88: loss=0.013625834816411952
Epoch #89: loss=0.015932941082990676
Epoch #90: loss=0.01834453698040141
Epoch #91: loss=0.01726454772056472
Epoch #92: loss=0.015945251886097883
Epoch #93: loss=0.012946206671503287
Epoch #94: loss=0.01666612111297251
Epoch #95: loss=0.020072975150370355
Epoch #96: loss=0.010436919624407893
Epoch #97: loss=0.012328331105891266
Epoch #98: loss=0.01813258088275854
Epoch #99: loss=0.009909726597553263
Epoch #100: loss=0.016170221072157306
Epoch #101: loss=0.013258210127341127
Epoch #102: loss=0.010734756357818365
Epoch #103: loss=0.015892694822535056
Epoch #104: loss=0.011368789382322575
Epoch #105: loss=0.017098790841456237
Epoch #106: loss=0.015482042428166923
Epoch #107: loss=0.01916590544622688
Epoch #108: loss=0.011038925865829118
Epoch #109: loss=0.01095645789385096
Epoch #110: loss=0.013331922100968023
Epoch #111: loss=0.011605233434701486
Epoch #112: loss=0.011368682895863458
Epoch #113: loss=0.017386613260466467
Epoch #114: loss=0.011058627081200196
Epoch #115: loss=0.010744407189568764
Epoch #116: loss=0.014611680132623985
Epoch #117: loss=0.01436207343090659
Epoch #118: loss=0.010348622629581685
Epoch #119: loss=0.013502362490974272
Epoch #120: loss=0.0176543082902671
Epoch #121: loss=0.0136725055951088
Epoch #122: loss=0.01225687657236201
Epoch #123: loss=0.01546795863627763
Epoch #124: loss=0.014360543594110904
Epoch #125: loss=0.01336291369195599
Epoch #126: loss=0.015354341640076282
Epoch #127: loss=0.01417208276399668
Epoch #128: loss=0.01215128498552076
Epoch #129: loss=0.010904600073990878
Epoch #130: loss=0.014911912680558585
Epoch #131: loss=0.011228611032956078
Epoch #132: loss=0.011811278391277566
Epoch #133: loss=0.01075253281957306
Epoch #134: loss=0.011280655212976854
Epoch #135: loss=0.012264615493602998
Epoch #136: loss=0.012647795112372313
Epoch #137: loss=0.01335365636094304
Epoch #138: loss=0.014783207012700668
Epoch #139: loss=0.012198431473933107
Epoch #140: loss=0.013584021175287056
Epoch #141: loss=0.011260500934978072
Epoch #142: loss=0.011998606866783038
Epoch #143: loss=0.01132785214900981
Epoch #144: loss=0.012605807081325276
Epoch #145: loss=0.013113699017677309
Epoch #146: loss=0.010976845522517662
Epoch #147: loss=0.015001570188641464
Epoch #148: loss=0.011098786268286693
Epoch #149: loss=0.012608881844591286
Epoch #150: loss=0.013301492435560001
Epoch #151: loss=0.01685863744344467
Epoch #152: loss=0.011713064114684873
Epoch #153: loss=0.011316383611086745
Epoch #154: loss=0.013744219155374925
Epoch #155: loss=0.012177444101888051
Epoch #156: loss=0.01736642810246849
Epoch #157: loss=0.013209561123387009
Epoch #158: loss=0.012023906162076773
Epoch #159: loss=0.011302722099026141
Epoch #160: loss=0.009664670934960833
Epoch #161: loss=0.010318036480171858
Epoch #162: loss=0.009556495952281032
Epoch #163: loss=0.0096854247519249
Epoch #164: loss=0.010068765228838443
Epoch #165: loss=0.017438841297685442
Epoch #166: loss=0.014634162252571059
Epoch #167: loss=0.011090442948823859
Epoch #168: loss=0.009692357753672033
Epoch #169: loss=0.011552216291238437
Epoch #170: loss=0.010041192120744117
Epoch #171: loss=0.013654581977409014
Epoch #172: loss=0.011447175214346895
Epoch #173: loss=0.010378472447700914
Epoch #174: loss=0.010116404687935508
Epoch #175: loss=0.009898333559100468
Epoch #176: loss=0.014585171591335728
Epoch #177: loss=0.009948125903726825
Epoch #178: loss=0.01661521194156111
Epoch #179: loss=0.0093240893917358
Epoch #180: loss=0.010591222257260762
Epoch #181: loss=0.010470589225273712
Epoch #182: loss=0.01300954931497968
Epoch #183: loss=0.014746506846462249
Epoch #184: loss=0.008071132879922515
Epoch #185: loss=0.008102458856559348
Epoch #186: loss=0.011960579980206438
Epoch #187: loss=0.01634874406617283
Epoch #188: loss=0.010298714643299305
Epoch #189: loss=0.010393345140685349
Epoch #190: loss=0.011135410617845827
Epoch #191: loss=0.01012860537666711
Epoch #192: loss=0.00932793022892094
Epoch #193: loss=0.011413876385036433
Epoch #194: loss=0.014197947678923645
Epoch #195: loss=0.008101920731843909
Epoch #196: loss=0.009804774091737106
Epoch #197: loss=0.013552362979498866
Epoch #198: loss=0.011237375422999983
Epoch #199: loss=0.016569599304933614
Epoch #200: loss=0.010126592315579976
Epoch #201: loss=0.009709523837839448
Epoch #202: loss=0.009494469498763052
Epoch #203: loss=0.011186677822462859
Epoch #204: loss=0.010163556523283742
Epoch #205: loss=0.00969431791231314
Epoch #206: loss=0.011456720109361579
Epoch #207: loss=0.016610473910292387
Epoch #208: loss=0.011552747146891884
Epoch #209: loss=0.008422690758214396
Epoch #210: loss=0.011486053907240355
Epoch #211: loss=0.008898846941081668
Epoch #212: loss=0.009259502926579444
Epoch #213: loss=0.010010162547471488
Epoch #214: loss=0.009489053066549373
Epoch #215: loss=0.009863881322952362
Epoch #216: loss=0.011972619654459943
Epoch #217: loss=0.011072697313895994
Epoch #218: loss=0.01367300249325622
Epoch #219: loss=0.008999939414810466
Epoch #220: loss=0.011632911635751952
Epoch #221: loss=0.010073269832140465
Epoch #222: loss=0.010027055380173393
Epoch #223: loss=0.0076002516371070005
Epoch #224: loss=0.011145385205914366
Epoch #225: loss=0.007350832423187305
Epoch #226: loss=0.013822661072084554
Epoch #227: loss=0.009558488732642962
Epoch #228: loss=0.011272928470829025
Epoch #229: loss=0.01005148715542997
Epoch #230: loss=0.009180350246341814
Epoch #231: loss=0.010101745536801135
Epoch #232: loss=0.009324666286029655
Epoch #233: loss=0.008995203235347369
Epoch #234: loss=0.013961069847916136
Epoch #235: loss=0.013379042940802967
Epoch #236: loss=0.00941856417813886
Epoch #237: loss=0.009395217605395538
Epoch #238: loss=0.0061971822334354245
Epoch #239: loss=0.020816131535056313
Epoch #240: loss=0.008937344777090898
Epoch #241: loss=0.008130998399511471
Epoch #242: loss=0.008058162597808404
Epoch #243: loss=0.010756726096463932
Epoch #244: loss=0.0189364396526633
Epoch #245: loss=0.010929038549676823
Epoch #246: loss=0.007802727883939621
Epoch #247: loss=0.0077542654975828055
Epoch #248: loss=0.00461698321625425
Epoch #249: loss=0.010019427732787667

Training time: 10:35:15.449097

Finished.
n2one setting etth2_ettm1_traffic -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_traffic_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_ettm1_traffic', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.64106e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.77717e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.53544e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.64106e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.40725730321363574, 'MAE': 0.4540773538003534}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm1_traffic -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_traffic_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_ettm1_traffic', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.24785e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.54831e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.24785e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3741663069319588, 'MAE': 0.4453165181001334}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm1_traffic -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_traffic_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_ettm1_traffic', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.15502e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.38147612921889756, 'MAE': 0.4014877750684979}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm1_weather', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm1_weather_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=4.546543392268094
Epoch #1: loss=2.756325759670951
Epoch #2: loss=2.2629434059966695
Epoch #3: loss=2.120567416602915
Epoch #4: loss=1.854755455797369
Epoch #5: loss=1.6515691605481235
Epoch #6: loss=1.5207929719578137
Epoch #7: loss=1.4328356927091426
Epoch #8: loss=1.3205760202624581
Epoch #9: loss=1.142629791389812
Epoch #10: loss=1.1200970519672742
Epoch #11: loss=1.1642039797522805
Epoch #12: loss=1.072395290840756
Epoch #13: loss=0.9676532813093879
Epoch #14: loss=0.8766389069232073
Epoch #15: loss=0.8882346925410357
Epoch #16: loss=0.8095181042497809
Epoch #17: loss=0.8780827440998771
Epoch #18: loss=0.8728259165178646
Epoch #19: loss=0.7883493615822359
Epoch #20: loss=0.7972218462012031
Epoch #21: loss=0.8624740906737067
Epoch #22: loss=0.8339792313900861
Epoch #23: loss=0.780009077353911
Epoch #24: loss=0.6472462883049791
Epoch #25: loss=0.6678720184347846
Epoch #26: loss=0.6885438886555758
Epoch #27: loss=0.6336434063586321
Epoch #28: loss=0.6379648541862314
Epoch #29: loss=0.6610769040205262
Epoch #30: loss=0.6348691785877402
Epoch #31: loss=0.6172587478702719
Epoch #32: loss=0.5162519067525864
Epoch #33: loss=0.5339311578057029
Epoch #34: loss=0.5809336690740152
Epoch #35: loss=0.6045670136809349
Epoch #36: loss=0.5481415953148495
Epoch #37: loss=0.5538723983547904
Epoch #38: loss=0.5651187246496027
Epoch #39: loss=0.4761482693932273
Epoch #40: loss=0.46459498459642584
Epoch #41: loss=0.4279319339177825
Epoch #42: loss=0.4409669204191728
Epoch #43: loss=0.5110081420703367
Epoch #44: loss=0.5109105503017252
Epoch #45: loss=0.5034887120127678
Epoch #46: loss=0.41051575812426483
Epoch #47: loss=0.5008689791641452
Epoch #48: loss=0.45671001821756363
Epoch #49: loss=0.4381764114580371
Epoch #50: loss=0.41180857000025833
Epoch #51: loss=0.43555477871136233
Epoch #52: loss=0.41413675993680954
Epoch #53: loss=0.36857116053050215
Epoch #54: loss=0.38951055163686926
Epoch #55: loss=0.40788624774325977
Epoch #56: loss=0.35500593788244506
Epoch #57: loss=0.3386292054571889
Epoch #58: loss=0.3453349521891637
Epoch #59: loss=0.3351237594404004
Epoch #60: loss=0.369870990853418
Epoch #61: loss=0.3480540869588202
Epoch #62: loss=0.406483609567989
Epoch #63: loss=0.3112813677977432
Epoch #64: loss=0.36659693480892613
Epoch #65: loss=0.33700656044212257
Epoch #66: loss=0.31438643315976317
Epoch #67: loss=0.2803249833258716
Epoch #68: loss=0.30369149622592057
Epoch #69: loss=0.26973987370729446
Epoch #70: loss=0.2556672633032907
Epoch #71: loss=0.3673760367726738
Epoch #72: loss=0.30529863641343336
Epoch #73: loss=0.38139507513154636
Epoch #74: loss=0.3983586945317008
Epoch #75: loss=0.32482585446401074
Epoch #76: loss=0.24424154074354607
Epoch #77: loss=0.25567574138668453
Epoch #78: loss=0.2642163063653491
Epoch #79: loss=0.26383030346848746
Epoch #80: loss=0.2528911470012231
Epoch #81: loss=0.21609404479915445
Epoch #82: loss=0.21587592515755782
Epoch #83: loss=0.24626096202568573
Epoch #84: loss=0.20398635705086318
Epoch #85: loss=0.17901940990916707
Epoch #86: loss=0.2732208738611503
Epoch #87: loss=0.2165421432053501
Epoch #88: loss=0.21794780546968634
Epoch #89: loss=0.20990765653550625
Epoch #90: loss=0.26844779605215247
Epoch #91: loss=0.22077642008662224
Epoch #92: loss=0.25608151964843273
Epoch #93: loss=0.22799718701703983
Epoch #94: loss=0.2444782407785004
Epoch #95: loss=0.21325315594334493
Epoch #96: loss=0.2005309651351788
Epoch #97: loss=0.1559958065944639
Epoch #98: loss=0.1744030365212397
Epoch #99: loss=0.22470973076468165
Epoch #100: loss=0.23273855151439254
Epoch #101: loss=0.2094812145964666
Epoch #102: loss=0.22473030969161878
Epoch #103: loss=0.190202978185632
Epoch #104: loss=0.2112321901050481
Epoch #105: loss=0.17695571736178614
Epoch #106: loss=0.12720453552901745
Epoch #107: loss=0.12807751853357663
Epoch #108: loss=0.16361154040152376
Epoch #109: loss=0.1994258128953251
Epoch #110: loss=0.15214081989093262
Epoch #111: loss=0.14954159434207462
Epoch #112: loss=0.14514802108434113
Epoch #113: loss=0.16377849174155432
Epoch #114: loss=0.15450424506244334
Epoch #115: loss=0.19787014986981044
Epoch #116: loss=0.15364223794842308
Epoch #117: loss=0.1424976991150867
Epoch #118: loss=0.1392978366295045
Epoch #119: loss=0.11764288435436109
Epoch #120: loss=0.16599263962019573
Epoch #121: loss=0.20834799009290608
Epoch #122: loss=0.19283978852697395
Epoch #123: loss=0.13434298124841668
Epoch #124: loss=0.22241550933739002
Epoch #125: loss=0.16831977894021707
Epoch #126: loss=0.188668157143349
Epoch #127: loss=0.15441794490272348
Epoch #128: loss=0.19658368368717757
Epoch #129: loss=0.1954089825634252
Epoch #130: loss=0.1169905392029746
Epoch #131: loss=0.11143386647613211
Epoch #132: loss=0.10236129300160841
Epoch #133: loss=0.13013698850673708
Epoch #134: loss=0.16302888679572128
Epoch #135: loss=0.16172102737155827
Epoch #136: loss=0.1663938665931875
Epoch #137: loss=0.15904586482793093
Epoch #138: loss=0.11647376346147874
Epoch #139: loss=0.12386143182150343
Epoch #140: loss=0.14162907321852716
Epoch #141: loss=0.13374626729637384
Epoch #142: loss=0.10317853977903724
Epoch #143: loss=0.12123851482333108
Epoch #144: loss=0.15880346061153847
Epoch #145: loss=0.13370426126163115
Epoch #146: loss=0.12224837070838972
Epoch #147: loss=0.0977308831431649
Epoch #148: loss=0.10429858572950418
Epoch #149: loss=0.12124722366305915
Epoch #150: loss=0.099022104320201
Epoch #151: loss=0.10179972123693336
Epoch #152: loss=0.08338868588378484
Epoch #153: loss=0.1276332596740262
Epoch #154: loss=0.11181338110261342
Epoch #155: loss=0.10228309555995194
Epoch #156: loss=0.12372205656191165
Epoch #157: loss=0.14690506216985258
Epoch #158: loss=0.15034461927346207
Epoch #159: loss=0.12754554538564247
Epoch #160: loss=0.0943730054423213
Epoch #161: loss=0.12554640949449755
Epoch #162: loss=0.11041009955277498
Epoch #163: loss=0.12389602799984542
Epoch #164: loss=0.2076931121674451
Epoch #165: loss=0.15219503878192467
Epoch #166: loss=0.09635293907062574
Epoch #167: loss=0.09682508320970969
Epoch #168: loss=0.08519210420887578
Epoch #169: loss=0.09937656294046478
Epoch #170: loss=0.10265455356883732
Epoch #171: loss=0.1174680536443537
Epoch #172: loss=0.10340264498848807
Epoch #173: loss=0.0778614348435605
Epoch #174: loss=0.07897229077802463
Epoch #175: loss=0.06993509881960397
Epoch #176: loss=0.08271869627589529
Epoch #177: loss=0.06853720253672112
Epoch #178: loss=0.0690534694374285
Epoch #179: loss=0.10750061533921822
Epoch #180: loss=0.07989018186080185
Epoch #181: loss=0.09043060382828116
Epoch #182: loss=0.10248111196878282
Epoch #183: loss=0.08419153589585965
Epoch #184: loss=0.08816493114202538
Epoch #185: loss=0.10120750366794792
Epoch #186: loss=0.08718954477543858
Epoch #187: loss=0.1378843403760005
Epoch #188: loss=0.060333215102384034
Epoch #189: loss=0.07470879415896806
Epoch #190: loss=0.07862129997970028
Epoch #191: loss=0.10096656476062807
Epoch #192: loss=0.1404901774684814
Epoch #193: loss=0.10618584029461173
Epoch #194: loss=0.06167287995446135
Epoch #195: loss=0.059157854644581676
Epoch #196: loss=0.07836271085861055
Epoch #197: loss=0.08039698301052506
Epoch #198: loss=0.07704366108571942
Epoch #199: loss=0.07263857486065138
Epoch #200: loss=0.06251337195069274
Epoch #201: loss=0.0728292585646903
Epoch #202: loss=0.06322308530269022
Epoch #203: loss=0.07373462230051783
Epoch #204: loss=0.059552065520124
Epoch #205: loss=0.07707620007832619
Epoch #206: loss=0.061240400674498895
Epoch #207: loss=0.056205733150074426
Epoch #208: loss=0.05274571569382467
Epoch #209: loss=0.10458259081298654
Epoch #210: loss=0.07451955713755028
Epoch #211: loss=0.08968934061175043
Epoch #212: loss=0.0665127754169093
Epoch #213: loss=0.059391408121551977
Epoch #214: loss=0.08820145710540767
Epoch #215: loss=0.05243510926480998
Epoch #216: loss=0.0640157294163311
Epoch #217: loss=0.07585515723225068
Epoch #218: loss=0.0913703336422755
Epoch #219: loss=0.07857990415174175
Epoch #220: loss=0.0801831952677193
Epoch #221: loss=0.07324450255625627
Epoch #222: loss=0.09985154979354278
Epoch #223: loss=0.08796943148428743
Epoch #224: loss=0.05988853448070586
Epoch #225: loss=0.060737985292110934
Epoch #226: loss=0.062971312827854
Epoch #227: loss=0.0832801409997046
Epoch #228: loss=0.07338591258634221
Epoch #229: loss=0.06013014950704845
Epoch #230: loss=0.06513069987043062
Epoch #231: loss=0.06026157429865138
Epoch #232: loss=0.3066805516454307
Epoch #233: loss=0.10481300818818537
Epoch #234: loss=0.05958575746891173
Epoch #235: loss=0.061046446546573534
Epoch #236: loss=0.08512545317750085
Epoch #237: loss=0.06827118783257902
Epoch #238: loss=0.06417500591752204
Epoch #239: loss=0.11513132957572286
Epoch #240: loss=0.07557179653932425
Epoch #241: loss=0.10704788766716691
Epoch #242: loss=0.09634734190661799
Epoch #243: loss=0.06924261055378751
Epoch #244: loss=0.0831425512124869
Epoch #245: loss=0.07209661641073498
Epoch #246: loss=0.06179355101829225
Epoch #247: loss=0.0572554856559939
Epoch #248: loss=0.05664213279008188
Epoch #249: loss=0.07324538940817794

Training time: 0:43:43.019954

Finished.
n2one setting etth2_ettm1_weather -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_weather_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_ettm1_weather', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.44877e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.94986e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.44877e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.37676408210200163, 'MAE': 0.43376841151598666}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm1_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_weather_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_ettm1_weather', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.9593e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.23423531064638062, 'MAE': 0.3257310298359069}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm1_exchange', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm1_exchange_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=4.217589598435622
Epoch #1: loss=2.296498660857861
Epoch #2: loss=2.0436327434503117
Epoch #3: loss=1.944134689294375
Epoch #4: loss=1.8370502040936396
Epoch #5: loss=1.648071894278893
Epoch #6: loss=1.6098186098612273
Epoch #7: loss=1.5187570544389577
Epoch #8: loss=1.470069481776311
Epoch #9: loss=1.3949950566658607
Epoch #10: loss=1.3282430401215186
Epoch #11: loss=1.2366391236965473
Epoch #12: loss=1.2416074917866633
Epoch #13: loss=1.3156448809000163
Epoch #14: loss=1.2155609543506916
Epoch #15: loss=1.1100786580489233
Epoch #16: loss=1.020841536613611
Epoch #17: loss=1.013558947123014
Epoch #18: loss=0.9911847458435938
Epoch #19: loss=1.0223147250138795
Epoch #20: loss=0.932282961331881
Epoch #21: loss=0.9770912000766168
Epoch #22: loss=0.9158284595379462
Epoch #23: loss=0.9322282488529499
Epoch #24: loss=0.8181959321865668
Epoch #25: loss=0.7770223938501798
Epoch #26: loss=0.8187314524100378
Epoch #27: loss=0.8702530379478748
Epoch #28: loss=0.8087658286094666
Epoch #29: loss=0.8653333049554092
Epoch #30: loss=0.851717091523684
Epoch #31: loss=0.7365310123333564
Epoch #32: loss=0.7000727951526642
Epoch #33: loss=0.7592878020726718
Epoch #34: loss=0.651781901717186
Epoch #35: loss=0.751123824944863
Epoch #36: loss=0.8360388003862821
Epoch #37: loss=0.7241958792393024
Epoch #38: loss=0.7547170772002294
Epoch #39: loss=0.6452080722038562
Epoch #40: loss=0.6929702861950948
Epoch #41: loss=0.7533561002749664
Epoch #42: loss=0.729570094209451
Epoch #43: loss=0.6499768610184009
Epoch #44: loss=0.682045538838093
Epoch #45: loss=0.6669650169519278
Epoch #46: loss=0.5792612020785992
Epoch #47: loss=0.5456342846155167
Epoch #48: loss=0.5622977190292798
Epoch #49: loss=0.5534887439929522
Epoch #50: loss=0.5586846665694163
Epoch #51: loss=0.5928913927995242
Epoch #52: loss=0.5520426630973816
Epoch #53: loss=0.6915382341696665
Epoch #54: loss=0.6196117240649003
Epoch #55: loss=0.48503424800359285
Epoch #56: loss=0.49349626096395344
Epoch #57: loss=0.5236169111270171
Epoch #58: loss=0.48584391520573544
Epoch #59: loss=0.4386220941176781
Epoch #60: loss=0.5168670828525836
Epoch #61: loss=0.5089137737567608
Epoch #62: loss=0.5304067467267697
Epoch #63: loss=0.5991950562367072
Epoch #64: loss=0.582025177203692
Epoch #65: loss=0.541310151035969
Epoch #66: loss=0.5802280673613915
Epoch #67: loss=0.4543783189012454
Epoch #68: loss=0.44833536446094513
Epoch #69: loss=0.4107550967198152
Epoch #70: loss=0.5036404138574233
Epoch #71: loss=0.4731807215855672
Epoch #72: loss=0.4893965789904961
Epoch #73: loss=0.41298964619636536
Epoch #74: loss=0.5388432706777866
Epoch #75: loss=0.4668674302788881
Epoch #76: loss=0.5114739938424184
Epoch #77: loss=0.4743335608106393
Epoch #78: loss=0.49652658230983293
Epoch #79: loss=0.41291775038609135
Epoch #80: loss=0.4939912540408281
Epoch #81: loss=0.42222203887425935
Epoch #82: loss=0.35900797179112065
Epoch #83: loss=0.38789538695262027
Epoch #84: loss=0.4032255554428467
Epoch #85: loss=0.3930745835487659
Epoch #86: loss=0.3902833845752936
Epoch #87: loss=0.4046365194595777
Epoch #88: loss=0.31920267125734914
Epoch #89: loss=0.35613655814757716
Epoch #90: loss=0.3685966277351746
Epoch #91: loss=0.467454459804755
Epoch #92: loss=0.41887417206397426
Epoch #93: loss=0.5636110850251638
Epoch #94: loss=0.4955747631879953
Epoch #95: loss=0.3842446328355716
Epoch #96: loss=0.34963994587843233
Epoch #97: loss=0.3971739640602699
Epoch #98: loss=0.4157943003452741
Epoch #99: loss=0.39998801625691927
Epoch #100: loss=0.4630400211765216
Epoch #101: loss=0.430512224825529
Epoch #102: loss=0.3025592410793671
Epoch #103: loss=0.32263213338760227
Epoch #104: loss=0.2915094918929614
Epoch #105: loss=0.31321282111681426
Epoch #106: loss=0.2825806046334597
Epoch #107: loss=0.30327848431009513
Epoch #108: loss=0.3010428794301473
Epoch #109: loss=0.2849193582167992
Epoch #110: loss=0.2601287803397729
Epoch #111: loss=0.34048084226938397
Epoch #112: loss=0.32293226512578815
Epoch #113: loss=0.29185639035243255
Epoch #114: loss=0.3199331147166399
Epoch #115: loss=0.2674168474399127
Epoch #116: loss=0.318078693575584
Epoch #117: loss=0.2923338868870185
Epoch #118: loss=0.25418059069376725
Epoch #119: loss=0.2245455329807905
Epoch #120: loss=0.21418750859223878
Epoch #121: loss=0.22364816728692788
Epoch #122: loss=0.2230075216637208
Epoch #123: loss=0.25942128151655197
Epoch #124: loss=0.2550058276034318
Epoch #125: loss=0.2665741288891205
Epoch #126: loss=0.2866510201532107
Epoch #127: loss=0.2687131736714106
Epoch #128: loss=0.28116733810076344
Epoch #129: loss=0.24987750185223725
Epoch #130: loss=0.22705489568985426
Epoch #131: loss=0.3446184244866555
Epoch #132: loss=0.22083070759589857
Epoch #133: loss=0.2179602777155546
Epoch #134: loss=0.2900718974952514
Epoch #135: loss=0.2910204716026783
Epoch #136: loss=0.27331147400232464
Epoch #137: loss=0.29506708251742214
Epoch #138: loss=0.3229438897508841
Epoch #139: loss=0.2939180267544893
Epoch #140: loss=0.24125383565059075
Epoch #141: loss=0.35124556662944645
Epoch #142: loss=0.25868407780161273
Epoch #143: loss=0.16506081361037034
Epoch #144: loss=0.1860773145006253
Epoch #145: loss=0.2638226587038774
Epoch #146: loss=0.21187370757643992
Epoch #147: loss=0.18401379138231277
Epoch #148: loss=0.18964556633279875
Epoch #149: loss=0.1682202136860444
Epoch #150: loss=0.2357788126056011
Epoch #151: loss=0.22245693837220853
Epoch #152: loss=0.20644944361769235
Epoch #153: loss=0.1531062417018872
Epoch #154: loss=0.1672235424988545
Epoch #155: loss=0.15661370782898024
Epoch #156: loss=0.19013303289046654
Epoch #157: loss=0.23984338701344454
Epoch #158: loss=0.21154325885268357
Epoch #159: loss=0.20645661279559135
Epoch #160: loss=0.20554695221093985
Epoch #161: loss=0.20238767077143377
Epoch #162: loss=0.2282223033790405
Epoch #163: loss=0.2704426683485508
Epoch #164: loss=0.16076771800334638
Epoch #165: loss=0.21645072446419641
Epoch #166: loss=0.1984807659800236
Epoch #167: loss=0.17291734439249223
Epoch #168: loss=0.1730106556071685
Epoch #169: loss=0.22365372742597872
Epoch #170: loss=0.18776999628887728
Epoch #171: loss=0.15102528064296797
Epoch #172: loss=0.1989612954740341
Epoch #173: loss=0.14696605073717925
Epoch #174: loss=0.1571680953582892
Epoch #175: loss=0.1583127320672457
Epoch #176: loss=0.22768708146535432
Epoch #177: loss=0.21467434600568736
Epoch #178: loss=0.30176878118744266
Epoch #179: loss=0.19975349880181825
Epoch #180: loss=0.18954540645846954
Epoch #181: loss=0.19643569508424172
Epoch #182: loss=0.32044633621206653
Epoch #183: loss=0.19455345777364877
Epoch #184: loss=0.22025437681720808
Epoch #185: loss=0.161769124894188
Epoch #186: loss=0.23903738119854376
Epoch #187: loss=0.20158084424642417
Epoch #188: loss=0.15978090952222163
Epoch #189: loss=0.19415604838958153
Epoch #190: loss=0.13660921084766203
Epoch #191: loss=0.1506411526352167
Epoch #192: loss=0.14386359329980153
Epoch #193: loss=0.13517616803829485
Epoch #194: loss=0.15065338333638814
Epoch #195: loss=0.15410772195229164
Epoch #196: loss=0.18163056370730585
Epoch #197: loss=0.18321250694302413
Epoch #198: loss=0.16981105964917403
Epoch #199: loss=0.14041668276947278
Epoch #200: loss=0.12286610972995941
Epoch #201: loss=0.13652158370957926
Epoch #202: loss=0.15812926825422507
Epoch #203: loss=0.12231066565100963
Epoch #204: loss=0.13372680358588696
Epoch #205: loss=0.17211589632699123
Epoch #206: loss=0.11631746389544927
Epoch #207: loss=0.16048565148734129
Epoch #208: loss=0.15246007562829897
Epoch #209: loss=0.10918357588637334
Epoch #210: loss=0.12358110921027568
Epoch #211: loss=0.17789810057729483
Epoch #212: loss=0.1386341488418671
Epoch #213: loss=0.11097882673717462
Epoch #214: loss=0.18836627413447088
Epoch #215: loss=0.1527905369607302
Epoch #216: loss=0.14600603697964779
Epoch #217: loss=0.14715092801130736
Epoch #218: loss=0.16496724563722426
Epoch #219: loss=0.11163482872339395
Epoch #220: loss=0.14351184709140888
Epoch #221: loss=0.12608742327071154
Epoch #222: loss=0.11790434199456985
Epoch #223: loss=0.11557717993855476
Epoch #224: loss=0.1211889348207758
Epoch #225: loss=0.1927162566437171
Epoch #226: loss=0.13216954441024706
Epoch #227: loss=0.13206025857764941
Epoch #228: loss=0.13945606422538942
Epoch #229: loss=0.12637863695048368
Epoch #230: loss=0.13191041056639874
Epoch #231: loss=0.11557754286779807
Epoch #232: loss=0.12978735036001757
Epoch #233: loss=0.13142485071260196
Epoch #234: loss=0.14035591010290843
Epoch #235: loss=0.1936946713293974
Epoch #236: loss=0.1296028486238076
Epoch #237: loss=0.1183355963574006
Epoch #238: loss=0.11902109863093266
Epoch #239: loss=0.16896309388371614
Epoch #240: loss=0.161089989858178
Epoch #241: loss=0.11896746276089779
Epoch #242: loss=0.13629755148520836
Epoch #243: loss=0.1288981271477846
Epoch #244: loss=0.26012361300392794
Epoch #245: loss=0.19523370796098158
Epoch #246: loss=0.12385490737282313
Epoch #247: loss=0.1324209151073144
Epoch #248: loss=0.10080338204995944
Epoch #249: loss=0.11552538393208614

Training time: 0:22:01.528838

Finished.
n2one setting etth2_ettm1_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_ettm1_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.43378e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.76808e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.43378e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3812546387028395, 'MAE': 0.4388063634893009}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm1_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_ettm1_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.2821e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.41892e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.78593e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.5957829774202031, 'MAE': 0.5600562444027374}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm2_electricity', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm2_electricity_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.6890779840911032
Epoch #1: loss=0.6830139236640086
Epoch #2: loss=0.4844415181242259
Epoch #3: loss=0.3771941308426646
Epoch #4: loss=0.3053508913007106
Epoch #5: loss=0.2547717101234602
Epoch #6: loss=0.236905432534253
Epoch #7: loss=0.2069782207013935
Epoch #8: loss=0.18277928668313323
Epoch #9: loss=0.16527978574807664
Epoch #10: loss=0.14018267135968251
Epoch #11: loss=0.14156172488291355
Epoch #12: loss=0.12325740292404605
Epoch #13: loss=0.111065606419052
Epoch #14: loss=0.11342341830311096
Epoch #15: loss=0.10438388954177719
Epoch #16: loss=0.09322622665657407
Epoch #17: loss=0.10057337394198484
Epoch #18: loss=0.0825727897061579
Epoch #19: loss=0.0955078161203448
Epoch #20: loss=0.07392227003257447
Epoch #21: loss=0.06526705149731497
Epoch #22: loss=0.07596056119080051
Epoch #23: loss=0.05608331748479455
Epoch #24: loss=0.059270532998176716
Epoch #25: loss=0.07328932057066126
Epoch #26: loss=0.057332630712912586
Epoch #27: loss=0.05098854703553966
Epoch #28: loss=0.04943693453407569
Epoch #29: loss=0.05214354189821577
Epoch #30: loss=0.04675411583394208
Epoch #31: loss=0.07351224406575647
Epoch #32: loss=0.04632097499302223
Epoch #33: loss=0.0420934991233853
Epoch #34: loss=0.05321209140981831
Epoch #35: loss=0.03771078547841943
Epoch #36: loss=0.04105886387100284
Epoch #37: loss=0.03638886612191643
Epoch #38: loss=0.033314035454721
Epoch #39: loss=0.04351105777255553
Epoch #40: loss=0.03300515105013782
Epoch #41: loss=0.03337889869496842
Epoch #42: loss=0.03418526635848667
Epoch #43: loss=0.03372129441752678
Epoch #44: loss=0.0280156234958536
Epoch #45: loss=0.030426558812497773
Epoch #46: loss=0.031850568678883896
Epoch #47: loss=0.05132190389819663
Epoch #48: loss=0.03395645250428941
Epoch #49: loss=0.03208585856599145
Epoch #50: loss=0.03392707454906035
Epoch #51: loss=0.024951130448453193
Epoch #52: loss=0.029980600523078337
Epoch #53: loss=0.0187869024175222
Epoch #54: loss=0.028601897827550155
Epoch #55: loss=0.022151414815962844
Epoch #56: loss=0.029339965750534734
Epoch #57: loss=0.03657169147205036
Epoch #58: loss=0.030631562961735227
Epoch #59: loss=0.022773173716672007
Epoch #60: loss=0.02142281466744741
Epoch #61: loss=0.01991549652697557
Epoch #62: loss=0.018319941059875805
Epoch #63: loss=0.026711233346214776
Epoch #64: loss=0.023775631314278154
Epoch #65: loss=0.02490059954456293
Epoch #66: loss=0.02104087239804411
Epoch #67: loss=0.020517738086994253
Epoch #68: loss=0.026605327684393807
Epoch #69: loss=0.021485594521925007
Epoch #70: loss=0.021942454173537327
Epoch #71: loss=0.020154985920649713
Epoch #72: loss=0.020518213037983856
Epoch #73: loss=0.0218293085298707
Epoch #74: loss=0.01918034059554914
Epoch #75: loss=0.02871404494231726
Epoch #76: loss=0.027801896443392718
Epoch #77: loss=0.021227664084470445
Epoch #78: loss=0.022737545970549868
Epoch #79: loss=0.021643282280710132
Epoch #80: loss=0.030472021107973975
Epoch #81: loss=0.0366292014037421
Epoch #82: loss=0.02128638583887918
Epoch #83: loss=0.015188020203814767
Epoch #84: loss=0.01853974222770142
Epoch #85: loss=0.016615160764263708
Epoch #86: loss=0.023347356099811187
Epoch #87: loss=0.01774599617292176
Epoch #88: loss=0.02918762467103766
Epoch #89: loss=0.020966381036331683
Epoch #90: loss=0.018191036270659384
Epoch #91: loss=0.019211200437650008
Epoch #92: loss=0.01893103046251384
Epoch #93: loss=0.023530707395481697
Epoch #94: loss=0.017248327227599183
Epoch #95: loss=0.02576133119255568
Epoch #96: loss=0.021052270263342797
Epoch #97: loss=0.01756910000502607
Epoch #98: loss=0.014904367482319892
Epoch #99: loss=0.016970978726826576
Epoch #100: loss=0.014831308015844726
Epoch #101: loss=0.011616096088379775
Epoch #102: loss=0.01955124580594615
Epoch #103: loss=0.01854746191004143
Epoch #104: loss=0.020507149746886024
Epoch #105: loss=0.017363674206361118
Epoch #106: loss=0.016646646770200856
Epoch #107: loss=0.018926334174509247
Epoch #108: loss=0.020454447219219705
Epoch #109: loss=0.028784944982526157
Epoch #110: loss=0.013196615128782042
Epoch #111: loss=0.01294571905718652
Epoch #112: loss=0.029183550155378195
Epoch #113: loss=0.014211787508764912
Epoch #114: loss=0.015599979272979013
Epoch #115: loss=0.011766537552964558
Epoch #116: loss=0.013821153386577053
Epoch #117: loss=0.015402324052299524
Epoch #118: loss=0.03212180824477808
Epoch #119: loss=0.015023525436834644
Epoch #120: loss=0.013151097280704101
Epoch #121: loss=0.015003485544594995
Epoch #122: loss=0.021896761913329177
Epoch #123: loss=0.012486747837080111
Epoch #124: loss=0.009363071288405932
Epoch #125: loss=0.014749200506909177
Epoch #126: loss=0.016642929105277676
Epoch #127: loss=0.013229600142359261
Epoch #128: loss=0.011960401459717931
Epoch #129: loss=0.01125817042770301
Epoch #130: loss=0.015943481667059306
Epoch #131: loss=0.017435799558955356
Epoch #132: loss=0.009671491549822851
Epoch #133: loss=0.0157721796017044
Epoch #134: loss=0.020529174904550553
Epoch #135: loss=0.012210390070188175
Epoch #136: loss=0.01425097853489286
Epoch #137: loss=0.012110311928092555
Epoch #138: loss=0.012919362814881314
Epoch #139: loss=0.012251043048684532
Epoch #140: loss=0.014074916813995107
Epoch #141: loss=0.012041275166105588
Epoch #142: loss=0.012155568564055174
Epoch #143: loss=0.02782680547909858
Epoch #144: loss=0.015054380851880177
Epoch #145: loss=0.02502351074107266
Epoch #146: loss=0.014613419846057409
Epoch #147: loss=0.012836297501718549
Epoch #148: loss=0.010151763489383347
Epoch #149: loss=0.012428446038324622
Epoch #150: loss=0.01003492881561448
Epoch #151: loss=0.01297264370983494
Epoch #152: loss=0.009574571103963364
Epoch #153: loss=0.012280040841610074
Epoch #154: loss=0.013435502414685017
Epoch #155: loss=0.01883961259297117
Epoch #156: loss=0.020165796300662807
Epoch #157: loss=0.014462552959879634
Epoch #158: loss=0.007912642060717909
Epoch #159: loss=0.00959139042187092
Epoch #160: loss=0.015768067994372022
Epoch #161: loss=0.019213478914036203
Epoch #162: loss=0.014988116227168656
Epoch #163: loss=0.009481816162982994
Epoch #164: loss=0.01446790418520317
Epoch #165: loss=0.009722022339529948
Epoch #166: loss=0.012767690222210368
Epoch #167: loss=0.016025629261670674
Epoch #168: loss=0.008257568642156403
Epoch #169: loss=0.012895382797739751
Epoch #170: loss=0.018635047007122717
Epoch #171: loss=0.009653291069118823
Epoch #172: loss=0.03481641221911012
Epoch #173: loss=0.017662502235456873
Epoch #174: loss=0.0139773164748401
Epoch #175: loss=0.014692648518696609
Epoch #176: loss=0.011062507408088661
Epoch #177: loss=0.01052272215638046
Epoch #178: loss=0.011128255376794202
Epoch #179: loss=0.014894944083723062
Epoch #180: loss=0.014191243843213932
Epoch #181: loss=0.009258178319091082
Epoch #182: loss=0.008463355626053779
Epoch #183: loss=0.008248990941978167
Epoch #184: loss=0.012031192455858344
Epoch #185: loss=0.00877126008225811
Epoch #186: loss=0.013452509642461216
Epoch #187: loss=0.012521979061970459
Epoch #188: loss=0.014125333632672876
Epoch #189: loss=0.015124329413952866
Epoch #190: loss=0.012597413826321738
Epoch #191: loss=0.006169693043989824
Epoch #192: loss=0.012236700777079704
Epoch #193: loss=0.009550455448892143
Epoch #194: loss=0.011176741557550524
Epoch #195: loss=0.01702568173864554
Epoch #196: loss=0.014275052707304404
Epoch #197: loss=0.010892038344498998
Epoch #198: loss=0.010083108445681676
Epoch #199: loss=0.008568598075109124
Epoch #200: loss=0.019375852970914657
Epoch #201: loss=0.011671250757220775
Epoch #202: loss=0.014121131650735363
Epoch #203: loss=0.013066975220506956
Epoch #204: loss=0.007684110500884124
Epoch #205: loss=0.013141439373228578
Epoch #206: loss=0.008983788310081744
Epoch #207: loss=0.012240594264276457
Epoch #208: loss=0.011688485188900073
Epoch #209: loss=0.008657552320256027
Epoch #210: loss=0.012783282266271775
Epoch #211: loss=0.010112530467544125
Epoch #212: loss=0.014231077539954324
Epoch #213: loss=0.011358754150809825
Epoch #214: loss=0.0098875303254607
Epoch #215: loss=0.013103894072043596
Epoch #216: loss=0.008753311267355457
Epoch #217: loss=0.006668488531238482
Epoch #218: loss=0.013746338332405694
Epoch #219: loss=0.01622379888474095
Epoch #220: loss=0.028678201156830455
Epoch #221: loss=0.012525164101985049
Epoch #222: loss=0.010504490282430497
Epoch #223: loss=0.009622848002122616
Epoch #224: loss=0.014008671790756324
Epoch #225: loss=0.010219375955581029
Epoch #226: loss=0.007341811360760763
Epoch #227: loss=0.01136681219419687
Epoch #228: loss=0.009688179653497128
Epoch #229: loss=0.011443806207726111
Epoch #230: loss=0.009764831663493293
Epoch #231: loss=0.013330712580588402
Epoch #232: loss=0.01473638590440363
Epoch #233: loss=0.01567320567069803
Epoch #234: loss=0.013047263803198154
Epoch #235: loss=0.01245294254449001
Epoch #236: loss=0.010084846758569648
Epoch #237: loss=0.010040623686862917
Epoch #238: loss=0.022134677463456313
Epoch #239: loss=0.009119545811839446
Epoch #240: loss=0.008317162406048394
Epoch #241: loss=0.012769407363059714
Epoch #242: loss=0.007779907206812418
Epoch #243: loss=0.010555557976854597
Epoch #244: loss=0.012521612864011036
Epoch #245: loss=0.010145254424827416
Epoch #246: loss=0.015771096058541517
Epoch #247: loss=0.00897945004503674
Epoch #248: loss=0.012114172530512305
Epoch #249: loss=0.00796403774797091

Training time: 4:38:57.424506

Finished.
n2one setting etth2_ettm2_electricity -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm2_electricity_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_ettm2_electricity', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.15317e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.25535e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.54229e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.15317e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.579080103668526, 'MAE': 0.5843623196453058}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm2_electricity -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm2_electricity_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_ettm2_electricity', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.21138e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.21138e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.2727960029271659, 'MAE': 0.35692588244749435}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm2_traffic', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm2_traffic_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.996952189725231
Epoch #1: loss=0.3727135881612247
Epoch #2: loss=0.25697005914354865
Epoch #3: loss=0.18875574716790156
Epoch #4: loss=0.1522517796478827
Epoch #5: loss=0.13399169883394443
Epoch #6: loss=0.11046207937919958
Epoch #7: loss=0.09089626979019323
Epoch #8: loss=0.08803504546151751
Epoch #9: loss=0.07072872369952331
Epoch #10: loss=0.06751219033507037
Epoch #11: loss=0.05695755357314324
Epoch #12: loss=0.05232216687873006
Epoch #13: loss=0.05210569299154238
Epoch #14: loss=0.0496197201435941
Epoch #15: loss=0.04268672371531879
Epoch #16: loss=0.04756586026818364
Epoch #17: loss=0.04982452440520071
Epoch #18: loss=0.040295748334425625
Epoch #19: loss=0.03429771869864039
Epoch #20: loss=0.037997883066154
Epoch #21: loss=0.03919052537742325
Epoch #22: loss=0.03466813102383061
Epoch #23: loss=0.04066711220710369
Epoch #24: loss=0.02964335109615852
Epoch #25: loss=0.023512578034239017
Epoch #26: loss=0.031121657573120583
Epoch #27: loss=0.02740944901584457
Epoch #28: loss=0.031203801145867065
Epoch #29: loss=0.026694023118364964
Epoch #30: loss=0.022644062627196863
Epoch #31: loss=0.025232687548784518
Epoch #32: loss=0.03370792583816431
Epoch #33: loss=0.03247492836089805
Epoch #34: loss=0.023596874171264725
Epoch #35: loss=0.027057735584954074
Epoch #36: loss=0.02691240220433842
Epoch #37: loss=0.023407280463090336
Epoch #38: loss=0.02358760807884127
Epoch #39: loss=0.02161420185835926
Epoch #40: loss=0.02040426845461215
Epoch #41: loss=0.021419816957429495
Epoch #42: loss=0.022687225994542877
Epoch #43: loss=0.024373014303670393
Epoch #44: loss=0.018704664224258687
Epoch #45: loss=0.025850772012166668
Epoch #46: loss=0.01982773796989932
Epoch #47: loss=0.02391042849975003
Epoch #48: loss=0.019118022175495176
Epoch #49: loss=0.02156416798071322
Epoch #50: loss=0.017072262595320353
Epoch #51: loss=0.029821910946735773
Epoch #52: loss=0.020591175116648878
Epoch #53: loss=0.014541441405493639
Epoch #54: loss=0.023483603812862634
Epoch #55: loss=0.020700035064973317
Epoch #56: loss=0.014259679674928933
Epoch #57: loss=0.017801494679886013
Epoch #58: loss=0.02678074913647751
Epoch #59: loss=0.016838570940308273
Epoch #60: loss=0.012759834249829344
Epoch #61: loss=0.019075753342093032
Epoch #62: loss=0.014657518766034628
Epoch #63: loss=0.01865992900751404
Epoch #64: loss=0.019647225235729076
Epoch #65: loss=0.015637717601599765
Epoch #66: loss=0.013140634776011045
Epoch #67: loss=0.018131312452169368
Epoch #68: loss=0.01678361722859501
Epoch #69: loss=0.018450741791788128
Epoch #70: loss=0.020709303519966357
Epoch #71: loss=0.01561412264606836
Epoch #72: loss=0.016722217649823342
Epoch #73: loss=0.01709052283351246
Epoch #74: loss=0.016478073523235666
Epoch #75: loss=0.015538106610157146
Epoch #76: loss=0.014177157265790314
Epoch #77: loss=0.013848310701868368
Epoch #78: loss=0.011248334385560487
Epoch #79: loss=0.018115602494402663
Epoch #80: loss=0.015230647783226397
Epoch #81: loss=0.013792944790012288
Epoch #82: loss=0.018883085106029863
Epoch #83: loss=0.014499991761410704
Epoch #84: loss=0.011614516197633665
Epoch #85: loss=0.014121951662342657
Epoch #86: loss=0.016136158347341157
Epoch #87: loss=0.013394857723555602
Epoch #88: loss=0.014557693829523157
Epoch #89: loss=0.014067002556674363
Epoch #90: loss=0.014412633839376875
Epoch #91: loss=0.017979922888281926
Epoch #92: loss=0.014913385835858538
Epoch #93: loss=0.012063849997370694
Epoch #94: loss=0.0156909796052787
Epoch #95: loss=0.020617624802203367
Epoch #96: loss=0.009866313680471318
Epoch #97: loss=0.014656769596232069
Epoch #98: loss=0.01612144913874958
Epoch #99: loss=0.010021186952905157
Epoch #100: loss=0.014669002416518527
Epoch #101: loss=0.010860167367883894
Epoch #102: loss=0.01133745827445926
Epoch #103: loss=0.016720682343392666
Epoch #104: loss=0.009240026162925378
Epoch #105: loss=0.017540429115648626
Epoch #106: loss=0.011388678524731816
Epoch #107: loss=0.017834774287092098
Epoch #108: loss=0.013440979496855025
Epoch #109: loss=0.011557811920399466
Epoch #110: loss=0.009846927002581652
Epoch #111: loss=0.01389080535733559
Epoch #112: loss=0.016568374926762112
Epoch #113: loss=0.01601790437611767
Epoch #114: loss=0.012586734235909799
Epoch #115: loss=0.012062150933806234
Epoch #116: loss=0.014638042688552972
Epoch #117: loss=0.014973150552561326
Epoch #118: loss=0.009809069461175568
Epoch #119: loss=0.014948221806612722
Epoch #120: loss=0.014565959849311515
Epoch #121: loss=0.014237724168263164
Epoch #122: loss=0.010284761590049709
Epoch #123: loss=0.013026085822870796
Epoch #124: loss=0.016761790931367284
Epoch #125: loss=0.01619637214819456
Epoch #126: loss=0.014248740405442235
Epoch #127: loss=0.011044725548080433
Epoch #128: loss=0.008282461184303843
Epoch #129: loss=0.01313493951608755
Epoch #130: loss=0.012374267439880978
Epoch #131: loss=0.014601726581829346
Epoch #132: loss=0.014299478397780067
Epoch #133: loss=0.014611087959862991
Epoch #134: loss=0.010465992544645402
Epoch #135: loss=0.012215724903250123
Epoch #136: loss=0.012291354740723777
Epoch #137: loss=0.012098582975555805
Epoch #138: loss=0.011818506308720151
Epoch #139: loss=0.010415994584863338
Epoch #140: loss=0.00993496636863049
Epoch #141: loss=0.010497946173247705
Epoch #142: loss=0.010154072230877567
Epoch #143: loss=0.01099353007650114
Epoch #144: loss=0.011112648770507473
Epoch #145: loss=0.012296750307923916
Epoch #146: loss=0.011327375604014377
Epoch #147: loss=0.013491001356818412
Epoch #148: loss=0.010833014463258388
Epoch #149: loss=0.012090104727163138
Epoch #150: loss=0.01011730274860218
Epoch #151: loss=0.016713223343785187
Epoch #152: loss=0.009688637362275834
Epoch #153: loss=0.011603223162083768
Epoch #154: loss=0.013014596000919648
Epoch #155: loss=0.014650460093120769
Epoch #156: loss=0.011516540297353375
Epoch #157: loss=0.019004327432941698
Epoch #158: loss=0.014944221711795597
Epoch #159: loss=0.010208089241975606
Epoch #160: loss=0.007847221670553236
Epoch #161: loss=0.013573064652535488
Epoch #162: loss=0.00983041168555949
Epoch #163: loss=0.008551304071856562
Epoch #164: loss=0.009470246038488932
Epoch #165: loss=0.013896116593836765
Epoch #166: loss=0.01891567378446449
Epoch #167: loss=0.009150235513317801
Epoch #168: loss=0.00939713279281436
Epoch #169: loss=0.013851595022325372
Epoch #170: loss=0.011377932769937616
Epoch #171: loss=0.015215028624003356
Epoch #172: loss=0.009424923235945409
Epoch #173: loss=0.010150240172507355
Epoch #174: loss=0.01198018407237462
Epoch #175: loss=0.00974797168412558
Epoch #176: loss=0.01635716959205059
Epoch #177: loss=0.010562833744188538
Epoch #178: loss=0.014811579295399663
Epoch #179: loss=0.011398569833843132
Epoch #180: loss=0.01121867323884296
Epoch #181: loss=0.008152966438104738
Epoch #182: loss=0.013544641675550586
Epoch #183: loss=0.014305282357616472
Epoch #184: loss=0.00814282650949694
Epoch #185: loss=0.008405558419921858
Epoch #186: loss=0.012573729298161527
Epoch #187: loss=0.0169891235669969
Epoch #188: loss=0.011796123918619825
Epoch #189: loss=0.011111633716394531
Epoch #190: loss=0.011259528403587122
Epoch #191: loss=0.010748093288831032
Epoch #192: loss=0.010025882255430671
Epoch #193: loss=0.01227019276291437
Epoch #194: loss=0.010156919645900913
Epoch #195: loss=0.00804517224241863
Epoch #196: loss=0.009044737793374225
Epoch #197: loss=0.011071356618512338
Epoch #198: loss=0.0122320305068239
Epoch #199: loss=0.015239151136260757
Epoch #200: loss=0.009601480226361177
Epoch #201: loss=0.00927814047840498
Epoch #202: loss=0.00818655921150573
Epoch #203: loss=0.008236680095871468
Epoch #204: loss=0.012033069239822164
Epoch #205: loss=0.008248655152419815
Epoch #206: loss=0.01477153205932237
Epoch #207: loss=0.013953521239950946
Epoch #208: loss=0.01434483714166907
Epoch #209: loss=0.009536924140671876
Epoch #210: loss=0.008946627335816712
Epoch #211: loss=0.009325935898488586
Epoch #212: loss=0.010713339330785939
Epoch #213: loss=0.010965399837583722
Epoch #214: loss=0.011123221871995074
Epoch #215: loss=0.010418606844996247
Epoch #216: loss=0.009622300476720821
Epoch #217: loss=0.010221710516601557
Epoch #218: loss=0.009988405860134332
Epoch #219: loss=0.009117317469744276
Epoch #220: loss=0.00858706352052898
Epoch #221: loss=0.009345641409163363
Epoch #222: loss=0.00731614754027212
Epoch #223: loss=0.007655661481658171
Epoch #224: loss=0.014841964019268
Epoch #225: loss=0.007156121334160368
Epoch #226: loss=0.012231049116599025
Epoch #227: loss=0.009346497047979276
Epoch #228: loss=0.008405634042554249
Epoch #229: loss=0.010523970244238708
Epoch #230: loss=0.008768811273396501
Epoch #231: loss=0.011010482704095378
Epoch #232: loss=0.010261333918664274
Epoch #233: loss=0.007929813864385241
Epoch #234: loss=0.011905285117179367
Epoch #235: loss=0.013989921777308402
Epoch #236: loss=0.009657418485155424
Epoch #237: loss=0.0075834297669313275
Epoch #238: loss=0.009477461161945526
Epoch #239: loss=0.015796017275054263
Epoch #240: loss=0.006904381292009599
Epoch #241: loss=0.008636539103025082
Epoch #242: loss=0.009049543169257131
Epoch #243: loss=0.009835259399352998
Epoch #244: loss=0.015163689709548966
Epoch #245: loss=0.012017550746449243
Epoch #246: loss=0.005352058772206709
Epoch #247: loss=0.009173388531334323
Epoch #248: loss=0.012751298809301013
Epoch #249: loss=0.009804707452795727

Training time: 10:26:16.882671

Finished.
n2one setting etth2_ettm2_traffic -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm2_traffic_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_ettm2_traffic', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.95876e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.65779e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.30528e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.95876e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4171974341130627, 'MAE': 0.4598181748020282}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm2_traffic -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm2_traffic_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_ettm2_traffic', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.38636e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.75088e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.38636e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4820547722138711, 'MAE': 0.5095941481229734}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm2_traffic -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm2_traffic_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_ettm2_traffic', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.22086e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.31344348002423433, 'MAE': 0.37069410377027784}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm2_weather', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm2_weather_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=4.554128993641246
Epoch #1: loss=2.747613717209209
Epoch #2: loss=2.259882466359572
Epoch #3: loss=2.1182287741791117
Epoch #4: loss=1.8672722848978909
Epoch #5: loss=1.6562304442579097
Epoch #6: loss=1.4959450472484936
Epoch #7: loss=1.4150252558968284
Epoch #8: loss=1.3018287786028602
Epoch #9: loss=1.1311913660981439
Epoch #10: loss=1.1170051273974506
Epoch #11: loss=1.1497535759752446
Epoch #12: loss=1.0784250552004033
Epoch #13: loss=0.9547792077064514
Epoch #14: loss=0.8751724646850065
Epoch #15: loss=0.8879760598594492
Epoch #16: loss=0.8166524158282713
Epoch #17: loss=0.869443491101265
Epoch #18: loss=0.8668425516648726
Epoch #19: loss=0.7828502384099093
Epoch #20: loss=0.7564389990134672
Epoch #21: loss=0.8473064276305112
Epoch #22: loss=0.8653707734563134
Epoch #23: loss=0.773722081021829
Epoch #24: loss=0.645865068516948
Epoch #25: loss=0.660258331082084
Epoch #26: loss=0.7076272680000826
Epoch #27: loss=0.6382490884174
Epoch #28: loss=0.6551938917149197
Epoch #29: loss=0.6686441580002959
Epoch #30: loss=0.6213732734322548
Epoch #31: loss=0.6432008093053644
Epoch #32: loss=0.5236296694387089
Epoch #33: loss=0.5561505827036771
Epoch #34: loss=0.5815442177382383
Epoch #35: loss=0.6178046668117697
Epoch #36: loss=0.5493611564690416
Epoch #37: loss=0.5638997249982574
Epoch #38: loss=0.5634468956427141
Epoch #39: loss=0.4754084280946038
Epoch #40: loss=0.46234422210942616
Epoch #41: loss=0.43111113932999695
Epoch #42: loss=0.4370452395894311
Epoch #43: loss=0.49279640885916626
Epoch #44: loss=0.4851276596838778
Epoch #45: loss=0.5128198144110766
Epoch #46: loss=0.4184890701012178
Epoch #47: loss=0.5043399191715501
Epoch #48: loss=0.46569791300730273
Epoch #49: loss=0.44235738062045793
Epoch #50: loss=0.41668274795467203
Epoch #51: loss=0.43174645948139106
Epoch #52: loss=0.39405307884920726
Epoch #53: loss=0.36090403456579556
Epoch #54: loss=0.38874727860093117
Epoch #55: loss=0.41195731034333055
Epoch #56: loss=0.3618387437679551
Epoch #57: loss=0.3447652811353857
Epoch #58: loss=0.33963530646129086
Epoch #59: loss=0.33963786844502797
Epoch #60: loss=0.36710828204046597
Epoch #61: loss=0.36031224273822526
Epoch #62: loss=0.41834912076592445
Epoch #63: loss=0.3229431638663465
Epoch #64: loss=0.3577117830176245
Epoch #65: loss=0.32696735858917236
Epoch #66: loss=0.3124466272578998
Epoch #67: loss=0.27009911462664604
Epoch #68: loss=0.30400687422264705
Epoch #69: loss=0.26471032337708905
Epoch #70: loss=0.23461796648123048
Epoch #71: loss=0.2685287870805372
Epoch #72: loss=0.2662653558972207
Epoch #73: loss=0.2597255107354034
Epoch #74: loss=0.27607717940753157
Epoch #75: loss=0.2406737936491316
Epoch #76: loss=0.2152937613427639
Epoch #77: loss=0.24053944477980788
Epoch #78: loss=0.2334114316512238
Epoch #79: loss=0.2433094075796279
Epoch #80: loss=0.2511604363945397
Epoch #81: loss=0.21782511472702026
Epoch #82: loss=0.21222591349347072
Epoch #83: loss=0.23381044884974306
Epoch #84: loss=0.19585265303877267
Epoch #85: loss=0.17374961493028837
Epoch #86: loss=0.266363236206499
Epoch #87: loss=0.21154950838536024
Epoch #88: loss=0.19957936809144236
Epoch #89: loss=0.21895579451864416
Epoch #90: loss=0.24836143072355876
Epoch #91: loss=0.20379145959900183
Epoch #92: loss=0.2296685888008638
Epoch #93: loss=0.2085026784545996
Epoch #94: loss=0.24757388623600657
Epoch #95: loss=0.20323588902300055
Epoch #96: loss=0.18167147480628706
Epoch #97: loss=0.1500925590199503
Epoch #98: loss=0.16333438701588998
Epoch #99: loss=0.21555073762481863
Epoch #100: loss=0.22962455426088788
Epoch #101: loss=0.20109327306801622
Epoch #102: loss=0.2156650952317498
Epoch #103: loss=0.18118970536372878
Epoch #104: loss=0.20459890975193543
Epoch #105: loss=0.18898595513945277
Epoch #106: loss=0.13088506781919437
Epoch #107: loss=0.12693469696254892
Epoch #108: loss=0.1662362226369706
Epoch #109: loss=0.2048610056835142
Epoch #110: loss=0.15337738403203813
Epoch #111: loss=0.15180190686475148
Epoch #112: loss=0.1379671863449568
Epoch #113: loss=0.1384595831517469
Epoch #114: loss=0.14479707680981269
Epoch #115: loss=0.2017967047339136
Epoch #116: loss=0.1655101924288002
Epoch #117: loss=0.1506390257061205
Epoch #118: loss=0.1445487437092445
Epoch #119: loss=0.11220142774453218
Epoch #120: loss=0.15557564625685866
Epoch #121: loss=0.34711163372478704
Epoch #122: loss=0.2099497187036005
Epoch #123: loss=0.13969716988503933
Epoch #124: loss=0.37321399321610277
Epoch #125: loss=0.1910690338435498
Epoch #126: loss=0.19500397035682743
Epoch #127: loss=0.1610257602720098
Epoch #128: loss=0.2801209033720873
Epoch #129: loss=0.20830136791548945
Epoch #130: loss=0.12134514931081371
Epoch #131: loss=0.115574610800567
Epoch #132: loss=0.10022395705296235
Epoch #133: loss=0.12776956580240617
Epoch #134: loss=0.13702840366485444
Epoch #135: loss=0.15316694301807068
Epoch #136: loss=0.1587029745040292
Epoch #137: loss=0.14193342880091883
Epoch #138: loss=0.09987962643869898
Epoch #139: loss=0.11900638352910226
Epoch #140: loss=0.12785710851577195
Epoch #141: loss=0.12378647419708697
Epoch #142: loss=0.0867775170640512
Epoch #143: loss=0.10973361104896123
Epoch #144: loss=0.1471252360127189
Epoch #145: loss=0.12615216468376192
Epoch #146: loss=0.11676281284202229
Epoch #147: loss=0.09458376035432924
Epoch #148: loss=0.08973709045147354
Epoch #149: loss=0.10104196999137374
Epoch #150: loss=0.0898560462942855
Epoch #151: loss=0.10240282520482485
Epoch #152: loss=0.08148484063250097
Epoch #153: loss=0.12305643282492053
Epoch #154: loss=0.10408370158719746
Epoch #155: loss=0.09584752326323227
Epoch #156: loss=0.11910430312326009
Epoch #157: loss=0.10927402388981798
Epoch #158: loss=0.1276329068721018
Epoch #159: loss=0.11209055345336144
Epoch #160: loss=0.08238897650417956
Epoch #161: loss=0.10849064258350567
Epoch #162: loss=0.0907281930135055
Epoch #163: loss=0.09862795379012823
Epoch #164: loss=0.2200251482003792
Epoch #165: loss=0.20652408288283783
Epoch #166: loss=0.15484985501759432
Epoch #167: loss=0.1394685417075049
Epoch #168: loss=0.10321338864212687
Epoch #169: loss=0.10465107367120006
Epoch #170: loss=0.11065381071106954
Epoch #171: loss=0.12461470300331712
Epoch #172: loss=0.10107147185639902
Epoch #173: loss=0.0761389196427031
Epoch #174: loss=0.08458451947874644
Epoch #175: loss=0.07056599552743137
Epoch #176: loss=0.08451614200814882
Epoch #177: loss=0.0644424413330853
Epoch #178: loss=0.06906700754453513
Epoch #179: loss=0.10235211348415098
Epoch #180: loss=0.09082908272235231
Epoch #181: loss=0.09470764666118404
Epoch #182: loss=0.11483068662610921
Epoch #183: loss=0.08221159392798488
Epoch #184: loss=0.088954145046459
Epoch #185: loss=0.09913626014762981
Epoch #186: loss=0.08439911582337861
Epoch #187: loss=0.1404288636774502
Epoch #188: loss=0.061378884679553186
Epoch #189: loss=0.08279866428876465
Epoch #190: loss=0.08570223847742785
Epoch #191: loss=0.1028108502399515
Epoch #192: loss=0.14308079759674994
Epoch #193: loss=0.11996381289579651
Epoch #194: loss=0.06460867951285433
Epoch #195: loss=0.0594082377131351
Epoch #196: loss=0.07086536834355105
Epoch #197: loss=0.07950242107141424
Epoch #198: loss=0.07717191241681576
Epoch #199: loss=0.07099819185466251
Epoch #200: loss=0.06426580339162187
Epoch #201: loss=0.09099991898983717
Epoch #202: loss=0.09905143156224354
Epoch #203: loss=0.10369430334222587
Epoch #204: loss=0.08179759903048928
Epoch #205: loss=0.09648899678987535
Epoch #206: loss=0.07759683909402652
Epoch #207: loss=0.3017453068063002
Epoch #208: loss=0.13933920182965018
Epoch #209: loss=0.13176577754149382
Epoch #210: loss=0.08729087002575397
Epoch #211: loss=0.10455641884949397
Epoch #212: loss=0.07208851809528741
Epoch #213: loss=0.059534972893412814
Epoch #214: loss=0.08936337637715042
Epoch #215: loss=0.05490328318608755
Epoch #216: loss=0.06050381976687773
Epoch #217: loss=0.06776287053203718
Epoch #218: loss=0.06614385826767168
Epoch #219: loss=0.06231716493229297
Epoch #220: loss=0.05667768977582455
Epoch #221: loss=0.06130230681843717
Epoch #222: loss=0.09850461010567167
Epoch #223: loss=0.08852672399106351
Epoch #224: loss=0.06231655040755868
Epoch #225: loss=0.06562602771869437
Epoch #226: loss=0.052513802191242576
Epoch #227: loss=0.08241464391308413
Epoch #228: loss=0.06938476462594488
Epoch #229: loss=0.07021474148231474
Epoch #230: loss=0.08308006638915023
Epoch #231: loss=0.07254207483492792
Epoch #232: loss=0.1007202182134444
Epoch #233: loss=0.058948444964533504
Epoch #234: loss=0.05761515397832475
Epoch #235: loss=0.06286322469399734
Epoch #236: loss=0.06942751747556031
Epoch #237: loss=0.06786860864270818
Epoch #238: loss=0.07916601944122124
Epoch #239: loss=0.11045754861763933
Epoch #240: loss=0.07137782956388863
Epoch #241: loss=0.0658564111852849
Epoch #242: loss=0.07074661792086606
Epoch #243: loss=0.05598265504125844
Epoch #244: loss=0.06468597221696241
Epoch #245: loss=0.06846503987485035
Epoch #246: loss=0.047640993831340565
Epoch #247: loss=0.0504933060887693
Epoch #248: loss=0.05381641405719248
Epoch #249: loss=0.08910896823826162

Training time: 0:43:40.336943

Finished.
n2one setting etth2_ettm2_weather -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm2_weather_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_ettm2_weather', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.39343e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.72276e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.39343e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.36796152682464284, 'MAE': 0.42856165245514183}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm2_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm2_weather_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_ettm2_weather', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.88715e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.2294811812152664, 'MAE': 0.3291078480636395}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm2_exchange', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm2_exchange_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=4.430692507670476
Epoch #1: loss=2.321351032990676
Epoch #2: loss=2.0769883348391605
Epoch #3: loss=1.9727351069450378
Epoch #4: loss=1.876237960962149
Epoch #5: loss=1.7029291804020221
Epoch #6: loss=1.6630073464833772
Epoch #7: loss=1.5566883224707384
Epoch #8: loss=1.5063642676060016
Epoch #9: loss=1.4085439168489897
Epoch #10: loss=1.3521944009340727
Epoch #11: loss=1.2614943155875573
Epoch #12: loss=1.2557237904805403
Epoch #13: loss=1.310659374182041
Epoch #14: loss=1.2285451682714315
Epoch #15: loss=1.0960377821555505
Epoch #16: loss=1.0398334975426013
Epoch #17: loss=1.0323631006937761
Epoch #18: loss=0.992419231396455
Epoch #19: loss=1.0414296892973094
Epoch #20: loss=0.9465610041068151
Epoch #21: loss=1.0051082854087536
Epoch #22: loss=0.9546112441099607
Epoch #23: loss=0.9574509744460766
Epoch #24: loss=0.8697487299258893
Epoch #25: loss=0.8356707829695481
Epoch #26: loss=0.8909635520898379
Epoch #27: loss=0.9233563267267667
Epoch #28: loss=0.8296278669283941
Epoch #29: loss=0.8735851186972398
Epoch #30: loss=0.852316134251081
Epoch #31: loss=0.7490416444264926
Epoch #32: loss=0.725448917884093
Epoch #33: loss=0.7819862411572382
Epoch #34: loss=0.6638126304516425
Epoch #35: loss=0.7278536466451792
Epoch #36: loss=0.8752752806131656
Epoch #37: loss=0.7509516236873773
Epoch #38: loss=0.7993557040507977
Epoch #39: loss=0.7089036806271627
Epoch #40: loss=0.7180751860141754
Epoch #41: loss=0.7522427176053708
Epoch #42: loss=0.7365588855284911
Epoch #43: loss=0.6243299222909487
Epoch #44: loss=0.636176395874757
Epoch #45: loss=0.66607993382674
Epoch #46: loss=0.5763926013157918
Epoch #47: loss=0.543479975599509
Epoch #48: loss=0.5262230806625806
Epoch #49: loss=0.5296688905129066
Epoch #50: loss=0.5569706318470148
Epoch #51: loss=0.5936472450311367
Epoch #52: loss=0.5549465182882088
Epoch #53: loss=0.6575550975707861
Epoch #54: loss=0.6040355116128922
Epoch #55: loss=0.505068260889787
Epoch #56: loss=0.4983828766987874
Epoch #57: loss=0.5396306251104062
Epoch #58: loss=0.5365864141629293
Epoch #59: loss=0.4779442044404837
Epoch #60: loss=0.5357613769861368
Epoch #61: loss=0.5135984672949865
Epoch #62: loss=0.47333527872195613
Epoch #63: loss=0.5333315581083298
Epoch #64: loss=0.4489487111568451
Epoch #65: loss=0.47682808683468747
Epoch #66: loss=0.522050855251459
Epoch #67: loss=0.43870044442323536
Epoch #68: loss=0.44948449845497424
Epoch #69: loss=0.4166192435301267
Epoch #70: loss=0.504030008155566
Epoch #71: loss=0.47027228199518645
Epoch #72: loss=0.4901510591690357
Epoch #73: loss=0.4210514426231384
Epoch #74: loss=0.5557038428691717
Epoch #75: loss=0.4884026732582312
Epoch #76: loss=0.5635855473004855
Epoch #77: loss=0.5429806038737297
Epoch #78: loss=0.5194687327513328
Epoch #79: loss=0.4293457384292896
Epoch #80: loss=0.4715558605698439
Epoch #81: loss=0.4048375401359338
Epoch #82: loss=0.34511467814445496
Epoch #83: loss=0.37668702006340027
Epoch #84: loss=0.36448535036582214
Epoch #85: loss=0.3792423325089308
Epoch #86: loss=0.39118775725364685
Epoch #87: loss=0.43924753024027896
Epoch #88: loss=0.3694449496956972
Epoch #89: loss=0.394290240911337
Epoch #90: loss=0.42339671231233156
Epoch #91: loss=0.4792839764402463
Epoch #92: loss=0.4279874093257464
Epoch #93: loss=0.48742544651031494
Epoch #94: loss=0.44910074254641164
Epoch #95: loss=0.3516470423111549
Epoch #96: loss=0.3456710840647037
Epoch #97: loss=0.3962628881518657
Epoch #98: loss=0.38856388284609866
Epoch #99: loss=0.36854982949220216
Epoch #100: loss=0.3940183801146654
Epoch #101: loss=0.37025728391913265
Epoch #102: loss=0.29129618062422824
Epoch #103: loss=0.3245489912537428
Epoch #104: loss=0.3041342181655077
Epoch #105: loss=0.3125896963935632
Epoch #106: loss=0.2953282525906196
Epoch #107: loss=0.3211540637107996
Epoch #108: loss=0.31105742775476897
Epoch #109: loss=0.28289200680760235
Epoch #110: loss=0.25797834877784437
Epoch #111: loss=0.35264946806889313
Epoch #112: loss=0.3347081708220335
Epoch #113: loss=0.29490939986247283
Epoch #114: loss=0.3014860677604492
Epoch #115: loss=0.2665665100973386
Epoch #116: loss=0.3120945305205308
Epoch #117: loss=0.31497492583898395
Epoch #118: loss=0.2831034671801787
Epoch #119: loss=0.23820544865268928
Epoch #120: loss=0.2172312200642549
Epoch #121: loss=0.23459561770925155
Epoch #122: loss=0.22668100148439407
Epoch #123: loss=0.24692372146707314
Epoch #124: loss=0.24933322031910604
Epoch #125: loss=0.24531949769992095
Epoch #126: loss=0.3065938734664367
Epoch #127: loss=0.32252636895729947
Epoch #128: loss=0.3343150827747125
Epoch #129: loss=0.2709409431196176
Epoch #130: loss=0.2393496039395149
Epoch #131: loss=0.36671918401351344
Epoch #132: loss=0.2266137210222391
Epoch #133: loss=0.21398668392346457
Epoch #134: loss=0.27960148826241493
Epoch #135: loss=0.2841638383957056
Epoch #136: loss=0.26086927119355935
Epoch #137: loss=0.2581631684532532
Epoch #138: loss=0.29656050497522723
Epoch #139: loss=0.30415231075424415
Epoch #140: loss=0.2606176435947418
Epoch #141: loss=0.3540651457240948
Epoch #142: loss=0.263212987436698
Epoch #143: loss=0.18002655013249472
Epoch #144: loss=0.19271232159091875
Epoch #145: loss=0.2528938757112393
Epoch #146: loss=0.18315375997469976
Epoch #147: loss=0.17283880739257887
Epoch #148: loss=0.1756145590199874
Epoch #149: loss=0.1792939892755105
Epoch #150: loss=0.23580858054069373
Epoch #151: loss=0.231385472875375
Epoch #152: loss=0.21549188202390304
Epoch #153: loss=0.15936863508362037
Epoch #154: loss=0.17802051454782486
Epoch #155: loss=0.1784597231218448
Epoch #156: loss=0.2223075361779103
Epoch #157: loss=0.2623336606014233
Epoch #158: loss=0.22453645387521157
Epoch #159: loss=0.20730049048478788
Epoch #160: loss=0.21868072679409614
Epoch #161: loss=0.24080585315823555
Epoch #162: loss=0.27802058767813903
Epoch #163: loss=0.29549308894918513
Epoch #164: loss=0.19590523179907066
Epoch #165: loss=0.24665270344569132
Epoch #166: loss=0.1946978084743023
Epoch #167: loss=0.18704212657534158
Epoch #168: loss=0.16256635893995947
Epoch #169: loss=0.18888800204373324
Epoch #170: loss=0.16422918954720864
Epoch #171: loss=0.16405551722989634
Epoch #172: loss=0.18557228348576105
Epoch #173: loss=0.13634870645518488
Epoch #174: loss=0.15321326728623647
Epoch #175: loss=0.16180035142371288
Epoch #176: loss=0.21339499448927549
Epoch #177: loss=0.20282562019733283
Epoch #178: loss=0.2159959415976818
Epoch #179: loss=0.16029496447971234
Epoch #180: loss=0.13082171876270038
Epoch #181: loss=0.12824686516362888
Epoch #182: loss=0.21797626164670175
Epoch #183: loss=0.16807699418411806
Epoch #184: loss=0.21991863631858274
Epoch #185: loss=0.1494105108655416
Epoch #186: loss=0.22044180075709635
Epoch #187: loss=0.2050468445970462
Epoch #188: loss=0.13911997985381347
Epoch #189: loss=0.18240375988758528
Epoch #190: loss=0.14579232724813315
Epoch #191: loss=0.14098868160866773
Epoch #192: loss=0.15204389192737067
Epoch #193: loss=0.13347324141516134
Epoch #194: loss=0.15244239654678565
Epoch #195: loss=0.141632608926067
Epoch #196: loss=0.18672846916776437
Epoch #197: loss=0.19388778579349703
Epoch #198: loss=0.1963024606498388
Epoch #199: loss=0.15587030838315302
Epoch #200: loss=0.13048799894750118
Epoch #201: loss=0.14855821760228047
Epoch #202: loss=0.18190129172916597
Epoch #203: loss=0.14693663670466497
Epoch #204: loss=0.1411962337218798
Epoch #205: loss=0.19420612130600673
Epoch #206: loss=0.1371633539406153
Epoch #207: loss=0.1747884233123981
Epoch #208: loss=0.1722115150724466
Epoch #209: loss=0.12136056173879367
Epoch #210: loss=0.13942482666327402
Epoch #211: loss=0.18389409465285447
Epoch #212: loss=0.14515418702593216
Epoch #213: loss=0.15089113222291836
Epoch #214: loss=0.2322016438612571
Epoch #215: loss=0.17529079146110094
Epoch #216: loss=0.14893470733211592
Epoch #217: loss=0.11574013352107543
Epoch #218: loss=0.17222302908507678
Epoch #219: loss=0.12259602847580726
Epoch #220: loss=0.15299685542973188
Epoch #221: loss=0.1391566272538442
Epoch #222: loss=0.12816793399934584
Epoch #223: loss=0.11898062793681255
Epoch #224: loss=0.11148991980231725
Epoch #225: loss=0.1784332375973463
Epoch #226: loss=0.11244459872922072
Epoch #227: loss=0.11717682346128501
Epoch #228: loss=0.1395015834042659
Epoch #229: loss=0.16123120887921408
Epoch #230: loss=0.15084714972628996
Epoch #231: loss=0.1180600062585794
Epoch #232: loss=0.11650915859410396
Epoch #233: loss=0.12162023180952439
Epoch #234: loss=0.13837837284574142
Epoch #235: loss=0.18431078628278696
Epoch #236: loss=0.12931612929185995
Epoch #237: loss=0.1493541941476556
Epoch #238: loss=0.14891142799304083
Epoch #239: loss=0.2474908705514211
Epoch #240: loss=0.25047052580003554
Epoch #241: loss=0.16679349455695885
Epoch #242: loss=0.16873272594351035
Epoch #243: loss=0.16980858705937862
Epoch #244: loss=0.3062377776950598
Epoch #245: loss=0.17963721230626106
Epoch #246: loss=0.12097535984447369
Epoch #247: loss=0.1269590830287108
Epoch #248: loss=0.09412948357371184
Epoch #249: loss=0.09878289276877275

Training time: 0:21:36.658516

Finished.
n2one setting etth2_ettm2_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm2_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_ettm2_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.32566e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.67389e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.32566e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3990239578082014, 'MAE': 0.44590512642909913}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm2_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm2_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_ettm2_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.40925e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.63181e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3614190811841991, 'MAE': 0.43481200651006613}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_electricity_traffic', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_electricity_traffic_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.7965494293249956
Epoch #1: loss=0.2819064825898459
Epoch #2: loss=0.17913345865780064
Epoch #3: loss=0.13484210875667946
Epoch #4: loss=0.10625623638326881
Epoch #5: loss=0.07983878193376194
Epoch #6: loss=0.06469409720064337
Epoch #7: loss=0.06226652091987306
Epoch #8: loss=0.05606281794998951
Epoch #9: loss=0.047189567800407776
Epoch #10: loss=0.04333816493622677
Epoch #11: loss=0.036195931261788834
Epoch #12: loss=0.03517187694635461
Epoch #13: loss=0.0438421615429747
Epoch #14: loss=0.03026722837572119
Epoch #15: loss=0.032157566787541975
Epoch #16: loss=0.033433880225047
Epoch #17: loss=0.027433208412463394
Epoch #18: loss=0.02739197115136013
Epoch #19: loss=0.027656285395256847
Epoch #20: loss=0.025771653806759404
Epoch #21: loss=0.02330897302090918
Epoch #22: loss=0.021146135089210698
Epoch #23: loss=0.02280944992187472
Epoch #24: loss=0.023743635200760366
Epoch #25: loss=0.022668106126561838
Epoch #26: loss=0.020925526393278104
Epoch #27: loss=0.02429808687512614
Epoch #28: loss=0.01746388634039723
Epoch #29: loss=0.021414091887819276
Epoch #30: loss=0.018473889316532943
Epoch #31: loss=0.030023779217280964
Epoch #32: loss=0.019051016552350288
Epoch #33: loss=0.018781571170146883
Epoch #34: loss=0.020297213149170917
Epoch #35: loss=0.01930421013893763
Epoch #36: loss=0.020251268316882058
Epoch #37: loss=0.020932638721942644
Epoch #38: loss=0.017681450028942912
Epoch #39: loss=0.01930584852635861
Epoch #40: loss=0.016871114681741933
Epoch #41: loss=0.017720417640252163
Epoch #42: loss=0.027243133009574767
Epoch #43: loss=0.017474650612400312
Epoch #44: loss=0.014719146970933902
Epoch #45: loss=0.015540894753719824
Epoch #46: loss=0.017808846934618303
Epoch #47: loss=0.015284675867746764
Epoch #48: loss=0.016720590510301902
Epoch #49: loss=0.01501004964080463
Epoch #50: loss=0.016427585899051154
Epoch #51: loss=0.019359800539213278
Epoch #52: loss=0.01378269787000281
Epoch #53: loss=0.016988239135040935
Epoch #54: loss=0.015649264284992637
Epoch #55: loss=0.013465464579691316
Epoch #56: loss=0.0183388000592382
Epoch #57: loss=0.016002606088075466
Epoch #58: loss=0.013472352827803286
Epoch #59: loss=0.01836048907989454
Epoch #60: loss=0.011341267826126667
Epoch #61: loss=0.01387780502665017
Epoch #62: loss=0.014517377561032616
Epoch #63: loss=0.016213062865842533
Epoch #64: loss=0.014337164639693903
Epoch #65: loss=0.015165192181363843
Epoch #66: loss=0.011923028871430742
Epoch #67: loss=0.01352912067216058
Epoch #68: loss=0.01091939968370271
Epoch #69: loss=0.013165315887949452
Epoch #70: loss=0.014239995731500628
Epoch #71: loss=0.01659688340209448
Epoch #72: loss=0.015547054001920614
Epoch #73: loss=0.016158432546516825
Epoch #74: loss=0.01579578587288397
Epoch #75: loss=0.011346255393773161
Epoch #76: loss=0.01246993607166908
Epoch #77: loss=0.013460137368353014
Epoch #78: loss=0.011074991669004955
Epoch #79: loss=0.013598883011037906
Epoch #80: loss=0.015142025793521047
Epoch #81: loss=0.013765775366684328
Epoch #82: loss=0.01408084982078221
Epoch #83: loss=0.011926365625739349
Epoch #84: loss=0.00897724280980392
Epoch #85: loss=0.014745734815882957
Epoch #86: loss=0.013391627629870596
Epoch #87: loss=0.011926631690316027
Epoch #88: loss=0.012963115245075955
Epoch #89: loss=0.012121428935234354
Epoch #90: loss=0.015268836430828634
Epoch #91: loss=0.015935233650590144
Epoch #92: loss=0.013890725030747689
Epoch #93: loss=0.00913170596495165
Epoch #94: loss=0.010614767924825241
Epoch #95: loss=0.01528302526912873
Epoch #96: loss=0.015049050382288083
Epoch #97: loss=0.00926539314122765
Epoch #98: loss=0.011995587004333962
Epoch #99: loss=0.009138691924099553
Epoch #100: loss=0.015520875846860469
Epoch #101: loss=0.010387749382697766
Epoch #102: loss=0.010004019723131963
Epoch #103: loss=0.007735598941190274
Epoch #104: loss=0.01764701059752852
Epoch #105: loss=0.01008852976725286
Epoch #106: loss=0.010379990990415016
Epoch #107: loss=0.010993787094959481
Epoch #108: loss=0.010563990860559171
Epoch #109: loss=0.021919809931061553
Epoch #110: loss=0.013843473025960574
Epoch #111: loss=0.011225338247991089
Epoch #112: loss=0.012912799958398903
Epoch #113: loss=0.01652682417090943
Epoch #114: loss=0.009535138359261059
Epoch #115: loss=0.013326528025698113
Epoch #116: loss=0.012235039962844986
Epoch #117: loss=0.012038915538025566
Epoch #118: loss=0.01432518858940462
Epoch #119: loss=0.007906065883624618
Epoch #120: loss=0.012215975410903671
Epoch #121: loss=0.01373686583824221
Epoch #122: loss=0.010363700754022516
Epoch #123: loss=0.009203749614561803
Epoch #124: loss=0.012057630350911586
Epoch #125: loss=0.012002051746308365
Epoch #126: loss=0.008478565259147905
Epoch #127: loss=0.009805702811284109
Epoch #128: loss=0.010934978883181299
Epoch #129: loss=0.0150602334183631
Epoch #130: loss=0.01081601583218875
Epoch #131: loss=0.012157530164147508
Epoch #132: loss=0.011594842807323763
Epoch #133: loss=0.008498793847574227
Epoch #134: loss=0.011100313595120459
Epoch #135: loss=0.008524616067202374
Epoch #136: loss=0.01395770396849927
Epoch #137: loss=0.009282861675092135
Epoch #138: loss=0.011773618435750798
Epoch #139: loss=0.010651535459010502
Epoch #140: loss=0.011664202249561977
Epoch #141: loss=0.010721095254108654
Epoch #142: loss=0.00821519646399357
Epoch #143: loss=0.009138637795866303
Epoch #144: loss=0.009771569290867529
Epoch #145: loss=0.015381463951413606
Epoch #146: loss=0.01183490913298701
Epoch #147: loss=0.010171862219425091
Epoch #148: loss=0.007911564296931019
Epoch #149: loss=0.009222940809699706
Epoch #150: loss=0.012686122120947463
Epoch #151: loss=0.009620310572925428
Epoch #152: loss=0.010621850374938747
Epoch #153: loss=0.01409326781234567
Epoch #154: loss=0.012508796394617735
Epoch #155: loss=0.007618330753878948
Epoch #156: loss=0.009566339253907253
Epoch #157: loss=0.010565570689290968
Epoch #158: loss=0.006887824469656359
Epoch #159: loss=0.009987173040054823
Epoch #160: loss=0.011623461570584864
Epoch #161: loss=0.02418753896162947
Epoch #162: loss=0.009294526540320132
Epoch #163: loss=0.008303628797680061
Epoch #164: loss=0.010878675189769255
Epoch #165: loss=0.01274472454031088
Epoch #166: loss=0.011952846697221037
Epoch #167: loss=0.020033681677624305
Epoch #168: loss=0.00871749735868266
Epoch #169: loss=0.011002206598103297
Epoch #170: loss=0.008811570750855148
Epoch #171: loss=0.011253996115660162
Epoch #172: loss=0.006904432438591548
Epoch #173: loss=0.009798862634996098
Epoch #174: loss=0.00897822686669269
Epoch #175: loss=0.009986299974122379
Epoch #176: loss=0.01191802914583314
Epoch #177: loss=0.013035831058851812
Epoch #178: loss=0.009243611066502875
Epoch #179: loss=0.010781354163215738
Epoch #180: loss=0.012135872044623016
Epoch #181: loss=0.009305427396709604
Epoch #182: loss=0.007973927038794133
Epoch #183: loss=0.008961937680217818
Epoch #184: loss=0.011034848094717775
Epoch #185: loss=0.010665747065484982
Epoch #186: loss=0.012540184715645341
Epoch #187: loss=0.009683848571426708
Epoch #188: loss=0.007971768158160496
Epoch #189: loss=0.011529711192422899
Epoch #190: loss=0.008591062658695806
Epoch #191: loss=0.00862109503553967
Epoch #192: loss=0.010960267350151489
Epoch #193: loss=0.010460833816003042
Epoch #194: loss=0.010411085410910842
Epoch #195: loss=0.007184822644469496
Epoch #196: loss=0.009494532598476043
Epoch #197: loss=0.007487694701139003
Epoch #198: loss=0.008911675668029044
Epoch #199: loss=0.010893562334313786
Epoch #200: loss=0.00789076654567479
Epoch #201: loss=0.006263535394005701
Epoch #202: loss=0.009405582806589758
Epoch #203: loss=0.009099952768577956
Epoch #204: loss=0.010119544823435779
Epoch #205: loss=0.008817250420047879
Epoch #206: loss=0.008116738409774393
Epoch #207: loss=0.008725400422743772
Epoch #208: loss=0.008622127175346708
Epoch #209: loss=0.0073364038071120664
Epoch #210: loss=0.008740220169450925
Epoch #211: loss=0.03053687418125738
Epoch #212: loss=0.01108107067668564
Epoch #213: loss=0.006634822767557293
Epoch #214: loss=0.006710099738046964
Epoch #215: loss=0.007819714878114456
Epoch #216: loss=0.010122205692080746
Epoch #217: loss=0.008042520384388357
Epoch #218: loss=0.008687205186251653
Epoch #219: loss=0.009839212224558254
Epoch #220: loss=0.007118325024728757
Epoch #221: loss=0.009124365089348215
Epoch #222: loss=0.005676589249193638
Epoch #223: loss=0.011247184733148985
Epoch #224: loss=0.006277949474101393
Epoch #225: loss=0.007200519582467005
Epoch #226: loss=0.008677332661728014
Epoch #227: loss=0.008251559411524306
Epoch #228: loss=0.00894709693952982
Epoch #229: loss=0.0065461125475574115
Epoch #230: loss=0.009407558575643817
Epoch #231: loss=0.009759192943644902
Epoch #232: loss=0.008285497904190387
Epoch #233: loss=0.007121849135006689
Epoch #234: loss=0.011266484556935432
Epoch #235: loss=0.008390149682798881
Epoch #236: loss=0.008110851690049886
Epoch #237: loss=0.006233322701430117
Epoch #238: loss=0.008360764386707104
Epoch #239: loss=0.008475323126234599
Epoch #240: loss=0.007652692135008058
Epoch #241: loss=0.007918870830853695
Epoch #242: loss=0.009182510203721017
Epoch #243: loss=0.008169529313136463
Epoch #244: loss=0.013148536403898733
Epoch #245: loss=0.007154015086563363
Epoch #246: loss=0.006388395541861649
Epoch #247: loss=0.01142599938286764
Epoch #248: loss=0.008519447136018817
Epoch #249: loss=0.006112540919196004

Training time: 14:19:15.251739

Finished.
n2one setting etth2_electricity_traffic -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_electricity_traffic_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_electricity_traffic', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.28559e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.72175e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.49469e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.28559e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.42251625734345, 'MAE': 0.48798212928599116}
Finished.
------------------------- record done -------------------------
n2one setting etth2_electricity_traffic -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_electricity_traffic_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_electricity_traffic', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.66634e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.2281899879092899, 'MAE': 0.32279171594567646}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_electricity_weather', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_electricity_weather_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.6260843071560402
Epoch #1: loss=0.7077125457383818
Epoch #2: loss=0.4931364123851566
Epoch #3: loss=0.44538129870332566
Epoch #4: loss=0.3576718485877339
Epoch #5: loss=0.3173625284837464
Epoch #6: loss=0.2819718699797062
Epoch #7: loss=0.24260060943789402
Epoch #8: loss=0.2234418826167193
Epoch #9: loss=0.2106618505329062
Epoch #10: loss=0.17509461291092263
Epoch #11: loss=0.17143567427361417
Epoch #12: loss=0.1615566882057547
Epoch #13: loss=0.14807734045984045
Epoch #14: loss=0.13154246768582675
Epoch #15: loss=0.12337575153063583
Epoch #16: loss=0.11208703914541478
Epoch #17: loss=0.10723373694292739
Epoch #18: loss=0.09593227750353389
Epoch #19: loss=0.09873141089485864
Epoch #20: loss=0.09309888093884887
Epoch #21: loss=0.11984164970479695
Epoch #22: loss=0.07779708448376528
Epoch #23: loss=0.06536551421813372
Epoch #24: loss=0.07525431794393281
Epoch #25: loss=0.06218818731416585
Epoch #26: loss=0.06969582780506356
Epoch #27: loss=0.06278537005964814
Epoch #28: loss=0.0496314265923101
Epoch #29: loss=0.04890779925163014
Epoch #30: loss=0.06963975551290869
Epoch #31: loss=0.06726168253522177
Epoch #32: loss=0.035762361009436854
Epoch #33: loss=0.05133190144926815
Epoch #34: loss=0.04673473088144414
Epoch #35: loss=0.044188455885702395
Epoch #36: loss=0.05247823998797685
Epoch #37: loss=0.04217418070716815
Epoch #38: loss=0.04928410433411683
Epoch #39: loss=0.0637957149679841
Epoch #40: loss=0.07967030162341619
Epoch #41: loss=0.04675098714723888
Epoch #42: loss=0.03404482274505673
Epoch #43: loss=0.03918502219337023
Epoch #44: loss=0.029900291243023475
Epoch #45: loss=0.028607415687161273
Epoch #46: loss=0.03264938432481245
Epoch #47: loss=0.029067256706266923
Epoch #48: loss=0.03569410304179794
Epoch #49: loss=0.03644273649390766
Epoch #50: loss=0.036838717965177646
Epoch #51: loss=0.03418791150519004
Epoch #52: loss=0.03225264329486921
Epoch #53: loss=0.02682046465033739
Epoch #54: loss=0.04364049915286139
Epoch #55: loss=0.04591907014922991
Epoch #56: loss=0.037064214740843
Epoch #57: loss=0.026804546671025033
Epoch #58: loss=0.04558358769199553
Epoch #59: loss=0.04266543049394222
Epoch #60: loss=0.022872355953713952
Epoch #61: loss=0.034803217200307164
Epoch #62: loss=0.02543695153383075
Epoch #63: loss=0.01981969365302873
Epoch #64: loss=0.03245159704468376
Epoch #65: loss=0.027880564872320154
Epoch #66: loss=0.026503333715671977
Epoch #67: loss=0.03180246940573236
Epoch #68: loss=0.05357201648731374
Epoch #69: loss=0.031772376437037446
Epoch #70: loss=0.03279082872411552
Epoch #71: loss=0.025029523485263883
Epoch #72: loss=0.03215752202276888
Epoch #73: loss=0.021108167019730572
Epoch #74: loss=0.019684866538052948
Epoch #75: loss=0.024755252407479632
Epoch #76: loss=0.036027514461577884
Epoch #77: loss=0.04640864907884917
Epoch #78: loss=0.02776246574131172
Epoch #79: loss=0.04508528678900283
Epoch #80: loss=0.021802790865820366
Epoch #81: loss=0.024125569960099808
Epoch #82: loss=0.019478542309933167
Epoch #83: loss=0.022742247643043934
Epoch #84: loss=0.01579396530070295
Epoch #85: loss=0.018560542101842895
Epoch #86: loss=0.020199741302801315
Epoch #87: loss=0.018573034503089402
Epoch #88: loss=0.029402622760676036
Epoch #89: loss=0.019069450552901518
Epoch #90: loss=0.016081091013571278
Epoch #91: loss=0.027479804806624365
Epoch #92: loss=0.03133270722806669
Epoch #93: loss=0.01859463783642698
Epoch #94: loss=0.016029642728298092
Epoch #95: loss=0.01886018777054361
Epoch #96: loss=0.041227394395960376
Epoch #97: loss=0.018811996901239462
Epoch #98: loss=0.0242436153705345
Epoch #99: loss=0.023670969531926628
Epoch #100: loss=0.020684826211467132
Epoch #101: loss=0.018542223921740205
Epoch #102: loss=0.02319603396966359
Epoch #103: loss=0.015550376890302179
Epoch #104: loss=0.02511413488454859
Epoch #105: loss=0.02250318025307214
Epoch #106: loss=0.013454238722600058
Epoch #107: loss=0.020527868762666275
Epoch #108: loss=0.022869647899511045
Epoch #109: loss=0.04967747433495834
Epoch #110: loss=0.01835927205971879
Epoch #111: loss=0.014185496862441048
Epoch #112: loss=0.0436396194761027
Epoch #113: loss=0.017170972712857564
Epoch #114: loss=0.015032592898275503
Epoch #115: loss=0.01492538800861655
Epoch #116: loss=0.022023032324672755
Epoch #117: loss=0.02122102610768203
Epoch #118: loss=0.03227038067112095
Epoch #119: loss=0.0241748779432685
Epoch #120: loss=0.017930546395959448
Epoch #121: loss=0.012757786830471523
Epoch #122: loss=0.014073850946450911
Epoch #123: loss=0.019320988607669176
Epoch #124: loss=0.017390695365841664
Epoch #125: loss=0.02192331919457111
Epoch #126: loss=0.017880005010049844
Epoch #127: loss=0.019302986866609053
Epoch #128: loss=0.02376728505307235
Epoch #129: loss=0.014680288954030217
Epoch #130: loss=0.014455443381010897
Epoch #131: loss=0.0238587774071115
Epoch #132: loss=0.02442578513189719
Epoch #133: loss=0.0242160874760761
Epoch #134: loss=0.025367468598793328
Epoch #135: loss=0.020585095054255587
Epoch #136: loss=0.014502594709997513
Epoch #137: loss=0.025820426280330076
Epoch #138: loss=0.02007047465090156
Epoch #139: loss=0.017831343390727627
Epoch #140: loss=0.013879505608386708
Epoch #141: loss=0.014985855254587996
Epoch #142: loss=0.015078754580282412
Epoch #143: loss=0.01461967471899862
Epoch #144: loss=0.015910433743597602
Epoch #145: loss=0.017969332497776092
Epoch #146: loss=0.015206866635708138
Epoch #147: loss=0.011524424930944997
Epoch #148: loss=0.021674850472268165
Epoch #149: loss=0.016706564019225
Epoch #150: loss=0.015973460879130815
Epoch #151: loss=0.018800830013068696
Epoch #152: loss=0.015197887025526225
Epoch #153: loss=0.013998892811543998
Epoch #154: loss=0.018563333214678287
Epoch #155: loss=0.025498633330660256
Epoch #156: loss=0.02977133055722688
Epoch #157: loss=0.02079040838910614
Epoch #158: loss=0.02150057898799818
Epoch #159: loss=0.01582718326885774
Epoch #160: loss=0.016747632515774567
Epoch #161: loss=0.013832260129741777
Epoch #162: loss=0.015105011616110022
Epoch #163: loss=0.01756621797955174
Epoch #164: loss=0.014187032487661061
Epoch #165: loss=0.013656819079763198
Epoch #166: loss=0.014305456837943077
Epoch #167: loss=0.01795356502736087
Epoch #168: loss=0.015197546810298463
Epoch #169: loss=0.013477766792053793
Epoch #170: loss=0.015166518174994495
Epoch #171: loss=0.015862562325006973
Epoch #172: loss=0.01619781784537001
Epoch #173: loss=0.020284853535845724
Epoch #174: loss=0.014839428024317827
Epoch #175: loss=0.014828728049145722
Epoch #176: loss=0.018095143289732125
Epoch #177: loss=0.010883153170395884
Epoch #178: loss=0.015025091419724213
Epoch #179: loss=0.013471712476437738
Epoch #180: loss=0.020112721937758544
Epoch #181: loss=0.013760095938141089
Epoch #182: loss=0.013435649588055603
Epoch #183: loss=0.024208520645243484
Epoch #184: loss=0.011958924427333862
Epoch #185: loss=0.012266075106138379
Epoch #186: loss=0.014921458513511471
Epoch #187: loss=0.02340689745011784
Epoch #188: loss=0.014929560599631582
Epoch #189: loss=0.022634209583725223
Epoch #190: loss=0.03136230780648352
Epoch #191: loss=0.014570550261378436
Epoch #192: loss=0.00946716251094118
Epoch #193: loss=0.00755612964725114
Epoch #194: loss=0.007323633885630314
Epoch #195: loss=0.016681640478650814
Epoch #196: loss=0.012943706239079056
Epoch #197: loss=0.017813597609963806
Epoch #198: loss=0.009803370780464114
Epoch #199: loss=0.01192584750332967
Epoch #200: loss=0.017651534320431102
Epoch #201: loss=0.040619745242835605
Epoch #202: loss=0.020887057109647774
Epoch #203: loss=0.010573602142979886
Epoch #204: loss=0.009485398749209215
Epoch #205: loss=0.01594969473146481
Epoch #206: loss=0.015452873532326187
Epoch #207: loss=0.017173153248212385
Epoch #208: loss=0.012134098517659151
Epoch #209: loss=0.008918990895805202
Epoch #210: loss=0.010868797694841968
Epoch #211: loss=0.011289401626162425
Epoch #212: loss=0.011431044435978994
Epoch #213: loss=0.012224001037141066
Epoch #214: loss=0.011338081480678707
Epoch #215: loss=0.017681438846222263
Epoch #216: loss=0.015701042184024776
Epoch #217: loss=0.015888263575589985
Epoch #218: loss=0.01854069546337955
Epoch #219: loss=0.010477582423383433
Epoch #220: loss=0.01034927528563987
Epoch #221: loss=0.01767187854893358
Epoch #222: loss=0.012793700513627253
Epoch #223: loss=0.009839003563725053
Epoch #224: loss=0.012501664263542246
Epoch #225: loss=0.011474612293686681
Epoch #226: loss=0.013291014564923395
Epoch #227: loss=0.013286484893257493
Epoch #228: loss=0.014007771461853485
Epoch #229: loss=0.008138164680577436
Epoch #230: loss=0.015391747593994141
Epoch #231: loss=0.012931602871940619
Epoch #232: loss=0.012159908620391032
Epoch #233: loss=0.012897926204788366
Epoch #234: loss=0.010218924768699865
Epoch #235: loss=0.01888758261133272
Epoch #236: loss=0.014851410092445916
Epoch #237: loss=0.009378275450330233
Epoch #238: loss=0.010911354416542974
Epoch #239: loss=0.010589834518434997
Epoch #240: loss=0.010646143461933417
Epoch #241: loss=0.01127714643930348
Epoch #242: loss=0.010644136711223036
Epoch #243: loss=0.016569378965509276
Epoch #244: loss=0.016284717336421343
Epoch #245: loss=0.012682715475251424
Epoch #246: loss=0.018019807507385275
Epoch #247: loss=0.010183669353843836
Epoch #248: loss=0.00991823454288829
Epoch #249: loss=0.012672388727929954

Training time: 4:56:00.014447

Finished.
n2one setting etth2_electricity_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_electricity_weather_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_electricity_weather', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.60202e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.60202e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3685153621608598, 'MAE': 0.3999590389960159}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_electricity_exchange', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_electricity_exchange_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.5913745491277604
Epoch #1: loss=0.6332446524784678
Epoch #2: loss=0.4478085922254693
Epoch #3: loss=0.34669779369696263
Epoch #4: loss=0.33825468493714217
Epoch #5: loss=0.27957321685694514
Epoch #6: loss=0.26688857939803884
Epoch #7: loss=0.22945967219060376
Epoch #8: loss=0.21327381357107134
Epoch #9: loss=0.1696628881396637
Epoch #10: loss=0.16765491351751344
Epoch #11: loss=0.1525429463612714
Epoch #12: loss=0.14283245192131117
Epoch #13: loss=0.12094726242745917
Epoch #14: loss=0.12126072010003208
Epoch #15: loss=0.10355759043401729
Epoch #16: loss=0.1073916578232976
Epoch #17: loss=0.10129236394450777
Epoch #18: loss=0.09190184049518957
Epoch #19: loss=0.07454622089807388
Epoch #20: loss=0.08174086211615109
Epoch #21: loss=0.08486203892001261
Epoch #22: loss=0.0693640083606754
Epoch #23: loss=0.06315744048195138
Epoch #24: loss=0.0606520042790743
Epoch #25: loss=0.06290545265766836
Epoch #26: loss=0.05926085327241924
Epoch #27: loss=0.05640092196006749
Epoch #28: loss=0.06402602503658272
Epoch #29: loss=0.06449341035996829
Epoch #30: loss=0.049220648705072347
Epoch #31: loss=0.05746563582354048
Epoch #32: loss=0.04587114358617414
Epoch #33: loss=0.05587428924211833
Epoch #34: loss=0.04853249518990716
Epoch #35: loss=0.046068286720713204
Epoch #36: loss=0.0498491435414291
Epoch #37: loss=0.04042052450157436
Epoch #38: loss=0.051728499862725756
Epoch #39: loss=0.03968546625262769
Epoch #40: loss=0.03849166155781686
Epoch #41: loss=0.039866696977350374
Epoch #42: loss=0.040262495435031485
Epoch #43: loss=0.03967890189960599
Epoch #44: loss=0.03611741002740538
Epoch #45: loss=0.03208293892107793
Epoch #46: loss=0.044504504266244894
Epoch #47: loss=0.04724528290500443
Epoch #48: loss=0.03501569050145224
Epoch #49: loss=0.0401526700180035
Epoch #50: loss=0.039651372407596294
Epoch #51: loss=0.03310877520873744
Epoch #52: loss=0.03372593454523234
Epoch #53: loss=0.030144523566594302
Epoch #54: loss=0.029462833481375128
Epoch #55: loss=0.02788709141861459
Epoch #56: loss=0.033720562221354895
Epoch #57: loss=0.044702078066447506
Epoch #58: loss=0.042707420092137044
Epoch #59: loss=0.026392997001364295
Epoch #60: loss=0.024946975538374057
Epoch #61: loss=0.026815351309085685
Epoch #62: loss=0.03297414164037383
Epoch #63: loss=0.028542510864748953
Epoch #64: loss=0.02418893595105536
Epoch #65: loss=0.035363569865044804
Epoch #66: loss=0.027070258229893323
Epoch #67: loss=0.0986134625397556
Epoch #68: loss=0.032039825749788656
Epoch #69: loss=0.024796941732347477
Epoch #70: loss=0.025846910885731978
Epoch #71: loss=0.05029444354711034
Epoch #72: loss=0.026007532277920593
Epoch #73: loss=0.020007727383580504
Epoch #74: loss=0.02262391922635115
Epoch #75: loss=0.025280288999229447
Epoch #76: loss=0.022835511179263926
Epoch #77: loss=0.018714928355794178
Epoch #78: loss=0.029799837175579297
Epoch #79: loss=0.03182989853285974
Epoch #80: loss=0.025842898604120517
Epoch #81: loss=0.022144394721614107
Epoch #82: loss=0.016991777948229963
Epoch #83: loss=0.02135915596452486
Epoch #84: loss=0.03687467842003874
Epoch #85: loss=0.02894177547395451
Epoch #86: loss=0.01872258104724876
Epoch #87: loss=0.027929812543464192
Epoch #88: loss=0.02350003638396932
Epoch #89: loss=0.03248320330679971
Epoch #90: loss=0.024162440445382214
Epoch #91: loss=0.030793211768988322
Epoch #92: loss=0.03041837488091828
Epoch #93: loss=0.02296576068398454
Epoch #94: loss=0.023747926799669153
Epoch #95: loss=0.02559387794341698
Epoch #96: loss=0.02825611610474187
Epoch #97: loss=0.02629172985048388
Epoch #98: loss=0.019314022616267072
Epoch #99: loss=0.024029076551544546
Epoch #100: loss=0.021180959783426562
Epoch #101: loss=0.021512516883896233
Epoch #102: loss=0.03998055341140744
Epoch #103: loss=0.0198320137070758
Epoch #104: loss=0.019600570546788817
Epoch #105: loss=0.01680446094906074
Epoch #106: loss=0.020943754286106144
Epoch #107: loss=0.020114868182731914
Epoch #108: loss=0.03176603375288237
Epoch #109: loss=0.028973736208475504
Epoch #110: loss=0.020877774432890527
Epoch #111: loss=0.017407990691156425
Epoch #112: loss=0.02577945888056309
Epoch #113: loss=0.07400758698990796
Epoch #114: loss=0.025415984390184304
Epoch #115: loss=0.01968434882430648
Epoch #116: loss=0.017167580939712934
Epoch #117: loss=0.011898156834095494
Epoch #118: loss=0.01531865511978616
Epoch #119: loss=0.013237635390742937
Epoch #120: loss=0.022299124358098544
Epoch #121: loss=0.029184429896607373
Epoch #122: loss=0.04354003211916452
Epoch #123: loss=0.019569871958256477
Epoch #124: loss=0.019134607625476616
Epoch #125: loss=0.01619287329837486
Epoch #126: loss=0.021382776930598386
Epoch #127: loss=0.02585176885934613
Epoch #128: loss=0.017150198811231393
Epoch #129: loss=0.0207320968045332
Epoch #130: loss=0.017879347300376616
Epoch #131: loss=0.028809968012951902
Epoch #132: loss=0.03271468425563875
Epoch #133: loss=0.025308451050521052
Epoch #134: loss=0.03253641951215243
Epoch #135: loss=0.014749894615046546
Epoch #136: loss=0.016639838873483574
Epoch #137: loss=0.015933616403344786
Epoch #138: loss=0.02185872904980594
Epoch #139: loss=0.020426925560708957
Epoch #140: loss=0.026151684789770764
Epoch #141: loss=0.0171185268977535
Epoch #142: loss=0.015163047217702981
Epoch #143: loss=0.013277884691411774
Epoch #144: loss=0.016864537764506946
Epoch #145: loss=0.03376843536881054
Epoch #146: loss=0.023532133437367434
Epoch #147: loss=0.020047460128677943
Epoch #148: loss=0.017873520281898977
Epoch #149: loss=0.01430519911056243
Epoch #150: loss=0.014925400415016893
Epoch #151: loss=0.028995910526039854
Epoch #152: loss=0.0190412144525215
Epoch #153: loss=0.022106591651078946
Epoch #154: loss=0.02452781181273167
Epoch #155: loss=0.018211922020522513
Epoch #156: loss=0.018045378259211292
Epoch #157: loss=0.028445495629836972
Epoch #158: loss=0.015185575903506972
Epoch #159: loss=0.017906152394668123
Epoch #160: loss=0.02125228364543762
Epoch #161: loss=0.0170444392249573
Epoch #162: loss=0.01361571783473621
Epoch #163: loss=0.016251498249316466
Epoch #164: loss=0.025679962412617725
Epoch #165: loss=0.01802202382896212
Epoch #166: loss=0.01676161399782792
Epoch #167: loss=0.011826761528936913
Epoch #168: loss=0.015380297957606325
Epoch #169: loss=0.012137381669682716
Epoch #170: loss=0.01446397690545252
Epoch #171: loss=0.021220952704381835
Epoch #172: loss=0.026784453882663956
Epoch #173: loss=0.022856437436747087
Epoch #174: loss=0.018841070769710876
Epoch #175: loss=0.014955653713384112
Epoch #176: loss=0.017485447161085348
Epoch #177: loss=0.017668433013958356
Epoch #178: loss=0.015446770710522764
Epoch #179: loss=0.013415205134584713
Epoch #180: loss=0.022751782260283585
Epoch #181: loss=0.0144446438819917
Epoch #182: loss=0.0142552546435798
Epoch #183: loss=0.012099426306511825
Epoch #184: loss=0.01053002820178032
Epoch #185: loss=0.016980666471811543
Epoch #186: loss=0.015595603428144906
Epoch #187: loss=0.013755512025194807
Epoch #188: loss=0.01608590244012746
Epoch #189: loss=0.01640379546119047
Epoch #190: loss=0.021811799743383226
Epoch #191: loss=0.030081305905263263
Epoch #192: loss=0.025299446477306663
Epoch #193: loss=0.023947037857959957
Epoch #194: loss=0.025358857471257493
Epoch #195: loss=0.04024707269213866
Epoch #196: loss=0.011934013963885567
Epoch #197: loss=0.011582353677762771
Epoch #198: loss=0.013327194394237483
Epoch #199: loss=0.012172262308359634
Epoch #200: loss=0.015091806274756977
Epoch #201: loss=0.011129798520761099
Epoch #202: loss=0.01167522843336753
Epoch #203: loss=0.01475771521455456
Epoch #204: loss=0.02408007662060776
Epoch #205: loss=0.03177956753314079
Epoch #206: loss=0.019029914504374443
Epoch #207: loss=0.013864697811749508
Epoch #208: loss=0.016169799140958015
Epoch #209: loss=0.015250171698079655
Epoch #210: loss=0.01386446158617868
Epoch #211: loss=0.01578770562454814
Epoch #212: loss=0.01555168140060102
Epoch #213: loss=0.021922757565334905
Epoch #214: loss=0.016013521552806543
Epoch #215: loss=0.010122825049447351
Epoch #216: loss=0.012900815298659532
Epoch #217: loss=0.016108118812553585
Epoch #218: loss=0.01896838352885901
Epoch #219: loss=0.02295740189895566
Epoch #220: loss=0.020256831253694447
Epoch #221: loss=0.020073406485867702
Epoch #222: loss=0.012071638393622595
Epoch #223: loss=0.025414455587971525
Epoch #224: loss=0.012769199576377148
Epoch #225: loss=0.011530994963322883
Epoch #226: loss=0.012255159236485184
Epoch #227: loss=0.020611119004180573
Epoch #228: loss=0.013327044526487867
Epoch #229: loss=0.012117190826930233
Epoch #230: loss=0.01280120588559103
Epoch #231: loss=0.01040173916382108
Epoch #232: loss=0.009677528356535601
Epoch #233: loss=0.01229402785931944
Epoch #234: loss=0.013319161414637208
Epoch #235: loss=0.014982293088905863
Epoch #236: loss=0.016382654193529606
Epoch #237: loss=0.01809098826180118
Epoch #238: loss=0.015138528674253308
Epoch #239: loss=0.015085498072775885
Epoch #240: loss=0.017454194864036425
Epoch #241: loss=0.017711715640784643
Epoch #242: loss=0.012793046922005098
Epoch #243: loss=0.01746273473708286
Epoch #244: loss=0.021669988626291298
Epoch #245: loss=0.017852319875341242
Epoch #246: loss=0.012289207171956409
Epoch #247: loss=0.011408878736845162
Epoch #248: loss=0.014558784959306303
Epoch #249: loss=0.01622224168472929

Training time: 4:36:17.848611

Finished.
n2one setting etth2_electricity_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_electricity_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_electricity_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.17068e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.26516e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.8133298393740696, 'MAE': 0.7197651687452468}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_traffic_weather', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_traffic_weather_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.0170608742943024
Epoch #1: loss=0.4024486351279573
Epoch #2: loss=0.2850093729752402
Epoch #3: loss=0.2185728693890838
Epoch #4: loss=0.17365533762387722
Epoch #5: loss=0.15151022096169728
Epoch #6: loss=0.12902801635378566
Epoch #7: loss=0.1247123617148183
Epoch #8: loss=0.10212864436771117
Epoch #9: loss=0.08452539440743917
Epoch #10: loss=0.08487713936529014
Epoch #11: loss=0.06937215800745694
Epoch #12: loss=0.07217634661154373
Epoch #13: loss=0.05838765334181862
Epoch #14: loss=0.05603147361677286
Epoch #15: loss=0.05789795935611818
Epoch #16: loss=0.05511344877102896
Epoch #17: loss=0.045745888334964326
Epoch #18: loss=0.04765721741444613
Epoch #19: loss=0.04384734418825897
Epoch #20: loss=0.052045265853134445
Epoch #21: loss=0.04057513443888399
Epoch #22: loss=0.041360407984716685
Epoch #23: loss=0.03225849058112265
Epoch #24: loss=0.04164655211137077
Epoch #25: loss=0.029645977433323444
Epoch #26: loss=0.03344220706097802
Epoch #27: loss=0.028488479429457918
Epoch #28: loss=0.034375423289622134
Epoch #29: loss=0.0263917441471407
Epoch #30: loss=0.03235247615508881
Epoch #31: loss=0.02801958053026806
Epoch #32: loss=0.03155969892753361
Epoch #33: loss=0.030129712979067327
Epoch #34: loss=0.02446955729213507
Epoch #35: loss=0.026310508615888822
Epoch #36: loss=0.02780140207497684
Epoch #37: loss=0.02911855352297165
Epoch #38: loss=0.03628841880370743
Epoch #39: loss=0.02606839037522434
Epoch #40: loss=0.02049204340717084
Epoch #41: loss=0.02944054920961248
Epoch #42: loss=0.023576990258424704
Epoch #43: loss=0.026344522562914648
Epoch #44: loss=0.024351002639302642
Epoch #45: loss=0.022639249440662396
Epoch #46: loss=0.022104344850304592
Epoch #47: loss=0.020121441054803076
Epoch #48: loss=0.02011919343533832
Epoch #49: loss=0.0270886597862726
Epoch #50: loss=0.024759548797412625
Epoch #51: loss=0.019595914401436567
Epoch #52: loss=0.015351156808251214
Epoch #53: loss=0.020517238667924164
Epoch #54: loss=0.026170019271026506
Epoch #55: loss=0.018280909503595486
Epoch #56: loss=0.020324462614745402
Epoch #57: loss=0.020180937142290863
Epoch #58: loss=0.019268839624866467
Epoch #59: loss=0.022991978795223418
Epoch #60: loss=0.017070317893209685
Epoch #61: loss=0.018037634410546812
Epoch #62: loss=0.02212296627044376
Epoch #63: loss=0.017484226732387326
Epoch #64: loss=0.024027224849160325
Epoch #65: loss=0.016035141585480587
Epoch #66: loss=0.018640381827568064
Epoch #67: loss=0.017375520508589714
Epoch #68: loss=0.01923669580530015
Epoch #69: loss=0.014549625023559526
Epoch #70: loss=0.02218502319330745
Epoch #71: loss=0.022636243051331616
Epoch #72: loss=0.017730559215473802
Epoch #73: loss=0.015300164633582075
Epoch #74: loss=0.025064502970390957
Epoch #75: loss=0.017570676876546804
Epoch #76: loss=0.0166391823982219
Epoch #77: loss=0.026371049485689642
Epoch #78: loss=0.018239245269878107
Epoch #79: loss=0.014851637082805274
Epoch #80: loss=0.01640417340534151
Epoch #81: loss=0.015558682887147665
Epoch #82: loss=0.027315453323275476
Epoch #83: loss=0.015551039438783165
Epoch #84: loss=0.018962402064639387
Epoch #85: loss=0.018779142186833887
Epoch #86: loss=0.01540324706603726
Epoch #87: loss=0.020516500616294602
Epoch #88: loss=0.019036379571374527
Epoch #89: loss=0.018455431493280154
Epoch #90: loss=0.013123258755102691
Epoch #91: loss=0.025264579883299238
Epoch #92: loss=0.008419052857577842
Epoch #93: loss=0.01984350928378567
Epoch #94: loss=0.013074729407587292
Epoch #95: loss=0.015403060737363838
Epoch #96: loss=0.018430665111450178
Epoch #97: loss=0.013834805778610161
Epoch #98: loss=0.0160430779837998
Epoch #99: loss=0.012607466829511436
Epoch #100: loss=0.016205778556248933
Epoch #101: loss=0.019093713071286697
Epoch #102: loss=0.012546699035681222
Epoch #103: loss=0.016091206810578924
Epoch #104: loss=0.012856863930043582
Epoch #105: loss=0.016029936420099093
Epoch #106: loss=0.020423075740601038
Epoch #107: loss=0.018511665168194903
Epoch #108: loss=0.01583521409635302
Epoch #109: loss=0.011511066684196313
Epoch #110: loss=0.014253934992440877
Epoch #111: loss=0.018952921321635088
Epoch #112: loss=0.014309674906303752
Epoch #113: loss=0.011940330366913604
Epoch #114: loss=0.010823256558788727
Epoch #115: loss=0.01479821763688818
Epoch #116: loss=0.019248429610974067
Epoch #117: loss=0.013660824077279312
Epoch #118: loss=0.03203457230617495
Epoch #119: loss=0.014879612130579258
Epoch #120: loss=0.012890852924323168
Epoch #121: loss=0.015523371540657738
Epoch #122: loss=0.0252563095402965
Epoch #123: loss=0.01490201360745064
Epoch #124: loss=0.012342244215496925
Epoch #125: loss=0.018628834639175133
Epoch #126: loss=0.012328430672869472
Epoch #127: loss=0.014775743506694024
Epoch #128: loss=0.01264670700675095
Epoch #129: loss=0.016509391599062923
Epoch #130: loss=0.016783728633275045
Epoch #131: loss=0.014096026646097545
Epoch #132: loss=0.01755705299057514
Epoch #133: loss=0.01137568598174797
Epoch #134: loss=0.011562405994949555
Epoch #135: loss=0.0181236772118533
Epoch #136: loss=0.010986134676806116
Epoch #137: loss=0.012899775172739197
Epoch #138: loss=0.017291008216145515
Epoch #139: loss=0.01301810415708798
Epoch #140: loss=0.016161811846248576
Epoch #141: loss=0.013234294273476922
Epoch #142: loss=0.019393530143450882
Epoch #143: loss=0.013479963010833885
Epoch #144: loss=0.011231122050153393
Epoch #145: loss=0.021119894997370246
Epoch #146: loss=0.010608261833604759
Epoch #147: loss=0.015556234806417045
Epoch #148: loss=0.010480223017184525
Epoch #149: loss=0.012516267933783918
Epoch #150: loss=0.015127816153612176
Epoch #151: loss=0.01054715269257239
Epoch #152: loss=0.015407862579927776
Epoch #153: loss=0.009907889295065015
Epoch #154: loss=0.012431656535195873
Epoch #155: loss=0.014120798996212637
Epoch #156: loss=0.011665714416510162
Epoch #157: loss=0.01403953568959009
Epoch #158: loss=0.012583561043428029
Epoch #159: loss=0.014679940407108788
Epoch #160: loss=0.017871613643820235
Epoch #161: loss=0.013236846365021574
Epoch #162: loss=0.022088564778762667
Epoch #163: loss=0.0077334198759453805
Epoch #164: loss=0.008997956551442329
Epoch #165: loss=0.019136860346982212
Epoch #166: loss=0.01363285159433323
Epoch #167: loss=0.014609486380850183
Epoch #168: loss=0.014961265721007162
Epoch #169: loss=0.008472497364006645
Epoch #170: loss=0.01793950092038185
Epoch #171: loss=0.011399106492903656
Epoch #172: loss=0.016529303693405075
Epoch #173: loss=0.012391215292431217
Epoch #174: loss=0.018725950262935397
Epoch #175: loss=0.00951033807894561
Epoch #176: loss=0.009599449698730013
Epoch #177: loss=0.009879192372493142
Epoch #178: loss=0.011224473474365814
Epoch #179: loss=0.011841553909601331
Epoch #180: loss=0.015238927224186863
Epoch #181: loss=0.013213102700736364
Epoch #182: loss=0.013406688351255344
Epoch #183: loss=0.01794967399804408
Epoch #184: loss=0.014638848274418767
Epoch #185: loss=0.005605657363182659
Epoch #186: loss=0.0107446930285458
Epoch #187: loss=0.017216358478044487
Epoch #188: loss=0.01656143906735685
Epoch #189: loss=0.01255452692160427
Epoch #190: loss=0.010314097191166586
Epoch #191: loss=0.011000273095875687
Epoch #192: loss=0.010780875653993629
Epoch #193: loss=0.011755945554423256
Epoch #194: loss=0.012098645983366609
Epoch #195: loss=0.01437212647797017
Epoch #196: loss=0.013487040423027204
Epoch #197: loss=0.010647516424508178
Epoch #198: loss=0.017382911907693675
Epoch #199: loss=0.008952736055905092
Epoch #200: loss=0.013349723230134279
Epoch #201: loss=0.0158182877643839
Epoch #202: loss=0.01512981462220833
Epoch #203: loss=0.010850687633810288
Epoch #204: loss=0.008577617898711209
Epoch #205: loss=0.012538677423330044
Epoch #206: loss=0.011716539427662768
Epoch #207: loss=0.00968104481196952
Epoch #208: loss=0.011571322797632427
Epoch #209: loss=0.015544774413369622
Epoch #210: loss=0.01299195458768482
Epoch #211: loss=0.011638891573539445
Epoch #212: loss=0.015474854210845596
Epoch #213: loss=0.01399860076717486
Epoch #214: loss=0.008460002322388584
Epoch #215: loss=0.013094943362534014
Epoch #216: loss=0.011218524384299324
Epoch #217: loss=0.010273994237097376
Epoch #218: loss=0.008460390953527238
Epoch #219: loss=0.008113976393439908
Epoch #220: loss=0.012895717035223634
Epoch #221: loss=0.01631039024871129
Epoch #222: loss=0.011226874950872578
Epoch #223: loss=0.014735089585997356
Epoch #224: loss=0.009565203415663059
Epoch #225: loss=0.008340135531131875
Epoch #226: loss=0.013873649312459015
Epoch #227: loss=0.009190577180280907
Epoch #228: loss=0.009998812039345197
Epoch #229: loss=0.012401007537228607
Epoch #230: loss=0.012290116371495867
Epoch #231: loss=0.011815965748020931
Epoch #232: loss=0.009274993206911874
Epoch #233: loss=0.010216508380998466
Epoch #234: loss=0.01046814876617493
Epoch #235: loss=0.01143586640735612
Epoch #236: loss=0.018740445268790786
Epoch #237: loss=0.01001945185616018
Epoch #238: loss=0.007861736770290048
Epoch #239: loss=0.010361661069132855
Epoch #240: loss=0.01171550055318343
Epoch #241: loss=0.013138256481871094
Epoch #242: loss=0.009994051954253739
Epoch #243: loss=0.011402752406845733
Epoch #244: loss=0.013262776716894537
Epoch #245: loss=0.010844868328682453
Epoch #246: loss=0.009347225589578186
Epoch #247: loss=0.006316484540400769
Epoch #248: loss=0.013318303835613382
Epoch #249: loss=0.011399809489197062

Training time: 10:26:06.258475

Finished.
n2one setting etth2_traffic_weather -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_traffic_weather_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_traffic_weather', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.99335e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.90739e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.8766e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.99335e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.41250979545546435, 'MAE': 0.4556958433931287}
Finished.
------------------------- record done -------------------------
n2one setting etth2_traffic_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_traffic_weather_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_traffic_weather', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.14768e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.47233974274269325, 'MAE': 0.4452625352873284}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_traffic_exchange', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_traffic_exchange_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.9859778952775279
Epoch #1: loss=0.3630939905394714
Epoch #2: loss=0.25091147637727457
Epoch #3: loss=0.1971243994784124
Epoch #4: loss=0.1582072531143915
Epoch #5: loss=0.13451738090401977
Epoch #6: loss=0.11541411424206491
Epoch #7: loss=0.10722681416778432
Epoch #8: loss=0.09405231320255669
Epoch #9: loss=0.07334698049326087
Epoch #10: loss=0.07305275130604937
Epoch #11: loss=0.06189824808484523
Epoch #12: loss=0.05819857279486538
Epoch #13: loss=0.056534141802283146
Epoch #14: loss=0.05398439648858523
Epoch #15: loss=0.0542898370864182
Epoch #16: loss=0.04840398733312967
Epoch #17: loss=0.04981883984518916
Epoch #18: loss=0.04163106791478632
Epoch #19: loss=0.0407659703219987
Epoch #20: loss=0.04097014875151217
Epoch #21: loss=0.03638965698110923
Epoch #22: loss=0.03750549213620415
Epoch #23: loss=0.033075878441762796
Epoch #24: loss=0.039477676256722265
Epoch #25: loss=0.02829760162570241
Epoch #26: loss=0.02910136733046959
Epoch #27: loss=0.03067419154979947
Epoch #28: loss=0.029352193251607924
Epoch #29: loss=0.02582176030704278
Epoch #30: loss=0.0323682061400256
Epoch #31: loss=0.02543972358104912
Epoch #32: loss=0.025168073741653287
Epoch #33: loss=0.03395687658013192
Epoch #34: loss=0.027826891596638252
Epoch #35: loss=0.024008466008075744
Epoch #36: loss=0.03134065345800487
Epoch #37: loss=0.03339427122000675
Epoch #38: loss=0.02462616806485857
Epoch #39: loss=0.027799902873420653
Epoch #40: loss=0.02461193151780783
Epoch #41: loss=0.025270405748660997
Epoch #42: loss=0.026604881118149407
Epoch #43: loss=0.020351883976206825
Epoch #44: loss=0.022162029377974363
Epoch #45: loss=0.025073411183348382
Epoch #46: loss=0.023402270343207236
Epoch #47: loss=0.02146318545791999
Epoch #48: loss=0.024276084761733152
Epoch #49: loss=0.024870685369287115
Epoch #50: loss=0.020827976115973944
Epoch #51: loss=0.020679985602137272
Epoch #52: loss=0.026519212159559134
Epoch #53: loss=0.016795650179704445
Epoch #54: loss=0.018304938589404057
Epoch #55: loss=0.026116111587444712
Epoch #56: loss=0.019603502201067737
Epoch #57: loss=0.03378843478943426
Epoch #58: loss=0.013257146556914796
Epoch #59: loss=0.02200253805564557
Epoch #60: loss=0.02437403425723638
Epoch #61: loss=0.018346940523064976
Epoch #62: loss=0.015001812912874187
Epoch #63: loss=0.020040727990482718
Epoch #64: loss=0.022599289850892018
Epoch #65: loss=0.024270005074227198
Epoch #66: loss=0.016186918391651785
Epoch #67: loss=0.02005604847120344
Epoch #68: loss=0.022687539611393512
Epoch #69: loss=0.018870307296007964
Epoch #70: loss=0.02206079286575995
Epoch #71: loss=0.018069005819136317
Epoch #72: loss=0.019108679812473744
Epoch #73: loss=0.020961368320222537
Epoch #74: loss=0.016907088515683774
Epoch #75: loss=0.015352370596223722
Epoch #76: loss=0.012192907696530093
Epoch #77: loss=0.01630790355966953
Epoch #78: loss=0.01993803730026894
Epoch #79: loss=0.024333276138623683
Epoch #80: loss=0.017730763970336377
Epoch #81: loss=0.019422612271366956
Epoch #82: loss=0.017324343379957287
Epoch #83: loss=0.019894675496833436
Epoch #84: loss=0.017102973517006584
Epoch #85: loss=0.014553269853909949
Epoch #86: loss=0.014773438482209742
Epoch #87: loss=0.019020084550544755
Epoch #88: loss=0.018180383492611345
Epoch #89: loss=0.01573236934792759
Epoch #90: loss=0.012143834387760625
Epoch #91: loss=0.01711544253998261
Epoch #92: loss=0.016239383017478758
Epoch #93: loss=0.014046529394841542
Epoch #94: loss=0.017209876956645942
Epoch #95: loss=0.017605136354913682
Epoch #96: loss=0.0198527309982379
Epoch #97: loss=0.01794611744581591
Epoch #98: loss=0.014206941127003209
Epoch #99: loss=0.020481286180896435
Epoch #100: loss=0.014822119185217829
Epoch #101: loss=0.01610503887872216
Epoch #102: loss=0.017248579058087323
Epoch #103: loss=0.01757883935368449
Epoch #104: loss=0.016623869685933632
Epoch #105: loss=0.017403631115214372
Epoch #106: loss=0.01570502148423861
Epoch #107: loss=0.013355180756743794
Epoch #108: loss=0.013384525958507585
Epoch #109: loss=0.028426419632422272
Epoch #110: loss=0.014616880137421575
Epoch #111: loss=0.023425997207071336
Epoch #112: loss=0.015554806261024456
Epoch #113: loss=0.016552509647041948
Epoch #114: loss=0.010935646475772208
Epoch #115: loss=0.012555317304084107
Epoch #116: loss=0.016095115253295614
Epoch #117: loss=0.01339593721207424
Epoch #118: loss=0.030072858202748506
Epoch #119: loss=0.01763223283441643
Epoch #120: loss=0.012336257890246075
Epoch #121: loss=0.014468777781413993
Epoch #122: loss=0.011697178575874783
Epoch #123: loss=0.014808440017537824
Epoch #124: loss=0.01402625280660455
Epoch #125: loss=0.017447652978292413
Epoch #126: loss=0.018330539292308098
Epoch #127: loss=0.0167226209469164
Epoch #128: loss=0.01404086644604628
Epoch #129: loss=0.01710604782361073
Epoch #130: loss=0.017077374906724365
Epoch #131: loss=0.017505961414910745
Epoch #132: loss=0.01318163585670833
Epoch #133: loss=0.01841622513015765
Epoch #134: loss=0.01389140785724735
Epoch #135: loss=0.019641418805456865
Epoch #136: loss=0.010634560542653167
Epoch #137: loss=0.018178100771401577
Epoch #138: loss=0.022377690388718854
Epoch #139: loss=0.017827772695471363
Epoch #140: loss=0.014469039646695988
Epoch #141: loss=0.018868738446892276
Epoch #142: loss=0.017269963359814924
Epoch #143: loss=0.013030615996176742
Epoch #144: loss=0.011251849132798933
Epoch #145: loss=0.01440113031097896
Epoch #146: loss=0.015875331956724355
Epoch #147: loss=0.017160864260502715
Epoch #148: loss=0.020766640635671362
Epoch #149: loss=0.013343449212386917
Epoch #150: loss=0.012706851869872787
Epoch #151: loss=0.012186767563786402
Epoch #152: loss=0.01277233919082581
Epoch #153: loss=0.012508768920061638
Epoch #154: loss=0.016868299179177617
Epoch #155: loss=0.012917486675762086
Epoch #156: loss=0.017797153305311175
Epoch #157: loss=0.013882266776311023
Epoch #158: loss=0.011426127059198014
Epoch #159: loss=0.0146643890275362
Epoch #160: loss=0.011724956798419105
Epoch #161: loss=0.01282722438868648
Epoch #162: loss=0.016813047850284694
Epoch #163: loss=0.015862962226373265
Epoch #164: loss=0.013019643183768394
Epoch #165: loss=0.01364795691875965
Epoch #166: loss=0.012998578726699492
Epoch #167: loss=0.010429616271161889
Epoch #168: loss=0.01864995898069212
Epoch #169: loss=0.013208933756454447
Epoch #170: loss=0.012451957945799256
Epoch #171: loss=0.013702358217751173
Epoch #172: loss=0.010542233123431676
Epoch #173: loss=0.017755244634592875
Epoch #174: loss=0.013045399305872628
Epoch #175: loss=0.012312050401328711
Epoch #176: loss=0.013490053331248624
Epoch #177: loss=0.010044600625024384
Epoch #178: loss=0.016879674924760283
Epoch #179: loss=0.015769489205787766
Epoch #180: loss=0.013842159057822675
Epoch #181: loss=0.014042116444762462
Epoch #182: loss=0.012539425249785735
Epoch #183: loss=0.010867859461430264
Epoch #184: loss=0.012330376086171192
Epoch #185: loss=0.009581132106619176
Epoch #186: loss=0.015062260578240203
Epoch #187: loss=0.012283081326186614
Epoch #188: loss=0.014500135536433171
Epoch #189: loss=0.010187539302383508
Epoch #190: loss=0.010986068956783581
Epoch #191: loss=0.020663973470545025
Epoch #192: loss=0.015667230319383076
Epoch #193: loss=0.011714532975264863
Epoch #194: loss=0.013186981999407578
Epoch #195: loss=0.01393003844873549
Epoch #196: loss=0.010481091714456164
Epoch #197: loss=0.0179180943112861
Epoch #198: loss=0.013155764559679558
Epoch #199: loss=0.01009295364415582
Epoch #200: loss=0.010544932623490206
Epoch #201: loss=0.016160943823331064
Epoch #202: loss=0.01661357546233553
Epoch #203: loss=0.01263116892332494
Epoch #204: loss=0.014707269681659564
Epoch #205: loss=0.012132464913024669
Epoch #206: loss=0.01091890458517762
Epoch #207: loss=0.011188913177937257
Epoch #208: loss=0.010063148769956218
Epoch #209: loss=0.012249000488328185
Epoch #210: loss=0.012086242398701368
Epoch #211: loss=0.010017451302722115
Epoch #212: loss=0.009111270116266588
Epoch #213: loss=0.011178652312389672
Epoch #214: loss=0.01753789189360251
Epoch #215: loss=0.012357053215815362
Epoch #216: loss=0.01418886730236218
Epoch #217: loss=0.013564135801540757
Epoch #218: loss=0.009890447995229066
Epoch #219: loss=0.010976482876022946
Epoch #220: loss=0.010077622449906924
Epoch #221: loss=0.010978818491370466
Epoch #222: loss=0.01629819384450969
Epoch #223: loss=0.01756797422176522
Epoch #224: loss=0.009232050926993233
Epoch #225: loss=0.007630082351433542
Epoch #226: loss=0.009729964987736832
Epoch #227: loss=0.014723420343884137
Epoch #228: loss=0.012565759063560698
Epoch #229: loss=0.00923718393802791
Epoch #230: loss=0.019132820574222654
Epoch #231: loss=0.009608823516004705
Epoch #232: loss=0.012583748826300704
Epoch #233: loss=0.010757468837927156
Epoch #234: loss=0.012968443405397889
Epoch #235: loss=0.01216558874777875
Epoch #236: loss=0.012555637758994048
Epoch #237: loss=0.010465362975389794
Epoch #238: loss=0.013065594670462593
Epoch #239: loss=0.010025595389651013
Epoch #240: loss=0.007839462604504313
Epoch #241: loss=0.009456726772911254
Epoch #242: loss=0.01011236727448364
Epoch #243: loss=0.018752903106961955
Epoch #244: loss=0.009290498543795258
Epoch #245: loss=0.013295387355276217
Epoch #246: loss=0.012297848999803957
Epoch #247: loss=0.015768065833413076
Epoch #248: loss=0.010999504581801704
Epoch #249: loss=0.010358360288336824

Training time: 10:18:03.069422

Finished.
n2one setting etth2_traffic_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_traffic_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_traffic_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.12459e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.79241e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.68418e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.12459e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.40999548193295693, 'MAE': 0.45529797163979574}
Finished.
------------------------- record done -------------------------
n2one setting etth2_traffic_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_traffic_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_traffic_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.43803e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.84842e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.84842e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4502921918202736, 'MAE': 0.5126561286625105}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_weather_exchange', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_weather_exchange_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=4.842221780521114
Epoch #1: loss=3.0301539287334536
Epoch #2: loss=2.3501611657258943
Epoch #3: loss=2.1823592476728484
Epoch #4: loss=1.916176842480171
Epoch #5: loss=1.8903677143701694
Epoch #6: loss=1.7959491305234956
Epoch #7: loss=1.677353387925683
Epoch #8: loss=1.6298018664848515
Epoch #9: loss=1.5038458690410708
Epoch #10: loss=1.386788836339625
Epoch #11: loss=1.333527370197017
Epoch #12: loss=1.2633276538151066
Epoch #13: loss=1.1780989300913927
Epoch #14: loss=1.1719070498536273
Epoch #15: loss=1.242283960668052
Epoch #16: loss=1.120518915536927
Epoch #17: loss=1.0468095293859156
Epoch #18: loss=1.0988946527969548
Epoch #19: loss=0.9969589681160159
Epoch #20: loss=0.9911224144261058
Epoch #21: loss=0.9525610513803435
Epoch #22: loss=0.9305388331413269
Epoch #23: loss=0.862175159338044
Epoch #24: loss=0.8771848053466983
Epoch #25: loss=0.8046845982714397
Epoch #26: loss=0.7870289654266543
Epoch #27: loss=0.8257381392688286
Epoch #28: loss=0.8072101037676741
Epoch #29: loss=0.7777471426056652
Epoch #30: loss=0.799587789105206
Epoch #31: loss=0.7304078565865029
Epoch #32: loss=0.7325062344713908
Epoch #33: loss=0.7098978328995589
Epoch #34: loss=0.7538451748650249
Epoch #35: loss=0.6491302680678483
Epoch #36: loss=0.7697048485279083
Epoch #37: loss=0.6770598997430104
Epoch #38: loss=0.6696689063456001
Epoch #39: loss=0.6387360016020333
Epoch #40: loss=0.6115818815987285
Epoch #41: loss=0.593900269851452
Epoch #42: loss=0.5887634972246681
Epoch #43: loss=0.5624580732206019
Epoch #44: loss=0.5452058947667843
Epoch #45: loss=0.5812572640616719
Epoch #46: loss=0.5676271021366119
Epoch #47: loss=0.6149875303594078
Epoch #48: loss=0.5606014219726004
Epoch #49: loss=0.5564576721772915
Epoch #50: loss=0.4685216800468724
Epoch #51: loss=0.4798498117342228
Epoch #52: loss=0.4662098048663721
Epoch #53: loss=0.5719516051978599
Epoch #54: loss=0.6147791663321053
Epoch #55: loss=0.48540644674766353
Epoch #56: loss=0.4576777532333281
Epoch #57: loss=0.45627245016214324
Epoch #58: loss=0.453009430955096
Epoch #59: loss=0.3845016698284847
Epoch #60: loss=0.48343065090295745
Epoch #61: loss=0.45852289185291384
Epoch #62: loss=0.46905702098113733
Epoch #63: loss=0.43089995733121544
Epoch #64: loss=0.5555836907247218
Epoch #65: loss=0.4741052051142948
Epoch #66: loss=0.44213069829998947
Epoch #67: loss=0.5069851413732622
Epoch #68: loss=0.3899683330844088
Epoch #69: loss=0.3561947720079887
Epoch #70: loss=0.43747064398556224
Epoch #71: loss=0.49073206760534427
Epoch #72: loss=0.47603693095649163
Epoch #73: loss=0.40956222102409456
Epoch #74: loss=0.616148581955491
Epoch #75: loss=0.35284507928825004
Epoch #76: loss=0.31073923190919367
Epoch #77: loss=0.42636548527857154
Epoch #78: loss=0.3437491855243357
Epoch #79: loss=0.4304188417225349
Epoch #80: loss=0.34864913944791004
Epoch #81: loss=0.3220748914087691
Epoch #82: loss=0.273959742995297
Epoch #83: loss=0.2855109881337096
Epoch #84: loss=0.3323107352707444
Epoch #85: loss=0.28875434980159853
Epoch #86: loss=0.3475342932634237
Epoch #87: loss=0.33755050490542154
Epoch #88: loss=0.2787852358163857
Epoch #89: loss=0.31988007738822843
Epoch #90: loss=0.3457800186261898
Epoch #91: loss=0.3233206193985009
Epoch #92: loss=0.3083318611834107
Epoch #93: loss=0.25934530485694
Epoch #94: loss=0.29524590801901934
Epoch #95: loss=0.2729306855216259
Epoch #96: loss=0.33904002443319414
Epoch #97: loss=0.293867034156148
Epoch #98: loss=0.23439021717484404
Epoch #99: loss=0.2619850244827387
Epoch #100: loss=0.28576248538930243
Epoch #101: loss=0.2618323255602906
Epoch #102: loss=0.2313247873652272
Epoch #103: loss=0.2735078025881837
Epoch #104: loss=0.2241437233439306
Epoch #105: loss=0.2147085008824744
Epoch #106: loss=0.26711679995059967
Epoch #107: loss=0.20144275848458454
Epoch #108: loss=0.2620072986294584
Epoch #109: loss=0.25047600650932733
Epoch #110: loss=0.23507019568507265
Epoch #111: loss=0.21688183288021787
Epoch #112: loss=0.18498639962295207
Epoch #113: loss=0.20996534133829722
Epoch #114: loss=0.2096224155549596
Epoch #115: loss=0.18350925632729764
Epoch #116: loss=0.21609418848302306
Epoch #117: loss=0.2176419238491756
Epoch #118: loss=0.20344964878224744
Epoch #119: loss=0.20801139795562115
Epoch #120: loss=0.15208075631682466
Epoch #121: loss=0.19617536218791473
Epoch #122: loss=0.1877298879369003
Epoch #123: loss=0.21044364426194168
Epoch #124: loss=0.23272845485224958
Epoch #125: loss=0.22078797057634447
Epoch #126: loss=0.20723433692644283
Epoch #127: loss=0.20973860417924275
Epoch #128: loss=0.19250772811654138
Epoch #129: loss=0.18043789703671526
Epoch #130: loss=0.18227720596804853
Epoch #131: loss=0.19690256792961097
Epoch #132: loss=0.1835278454350262
Epoch #133: loss=0.23076561547634078
Epoch #134: loss=0.22170848753757594
Epoch #135: loss=0.19910473485545413
Epoch #136: loss=0.15726245894301227
Epoch #137: loss=0.1995572381448455
Epoch #138: loss=0.18409713830162838
Epoch #139: loss=0.14369083654771492
Epoch #140: loss=0.20015645626841522
Epoch #141: loss=0.14304685919750026
Epoch #142: loss=0.22521652562952624
Epoch #143: loss=0.14233828581324437
Epoch #144: loss=0.17385784963645587
Epoch #145: loss=0.18630352280125384
Epoch #146: loss=0.2672150885549987
Epoch #147: loss=0.32361915771190713
Epoch #148: loss=0.24013423519890484
Epoch #149: loss=0.18424122426204564
Epoch #150: loss=0.15602400817158746
Epoch #151: loss=0.1495879115309657
Epoch #152: loss=0.13348865699840756
Epoch #153: loss=0.21875661475265898
Epoch #154: loss=0.1818203672584964
Epoch #155: loss=0.13292742902185858
Epoch #156: loss=0.15355537059467014
Epoch #157: loss=0.11403417182949985
Epoch #158: loss=0.12273723577580802
Epoch #159: loss=0.13286783796076368
Epoch #160: loss=0.13350154350443585
Epoch #161: loss=0.13595415179322407
Epoch #162: loss=0.21741678297701406
Epoch #163: loss=0.15822050029911647
Epoch #164: loss=0.12078931237139352
Epoch #165: loss=0.17030745540268538
Epoch #166: loss=0.18180475443056443
Epoch #167: loss=0.2949776143380782
Epoch #168: loss=0.5495071801833991
Epoch #169: loss=0.39449778980598216
Epoch #170: loss=0.22790294785688564
Epoch #171: loss=0.21327055836232697
Epoch #172: loss=0.16889869212740805
Epoch #173: loss=0.1498604911129649
Epoch #174: loss=0.21857980002717273
Epoch #175: loss=0.17265723786521248
Epoch #176: loss=0.15722155634586404
Epoch #177: loss=0.14999643654176376
Epoch #178: loss=0.15994552468381276
Epoch #179: loss=0.1318630175437869
Epoch #180: loss=0.08842348934310239
Epoch #181: loss=0.13195271544703624
Epoch #182: loss=0.10619368413236083
Epoch #183: loss=0.09773145434333057
Epoch #184: loss=0.12591254347708167
Epoch #185: loss=0.11536684764049403
Epoch #186: loss=0.1489889916577717
Epoch #187: loss=0.11378292339604075
Epoch #188: loss=0.1260823189485364
Epoch #189: loss=0.13682172897203668
Epoch #190: loss=0.11894461180923915
Epoch #191: loss=0.12000951511649097
Epoch #192: loss=0.14438355745883977
Epoch #193: loss=0.19848072306230302
Epoch #194: loss=0.1362332173782151
Epoch #195: loss=0.14107624504987787
Epoch #196: loss=0.10633555926927706
Epoch #197: loss=0.138362424629854
Epoch #198: loss=0.10423487792836457
Epoch #199: loss=0.16194275475856734
Epoch #200: loss=0.09585549091783965
Epoch #201: loss=0.10892976238960173
Epoch #202: loss=0.12875614019973977
Epoch #203: loss=0.10702210074154342
Epoch #204: loss=0.1446073564541776
Epoch #205: loss=0.10329349048253966
Epoch #206: loss=0.14861911944136386
Epoch #207: loss=0.1410601001414584
Epoch #208: loss=0.1298615256006398
Epoch #209: loss=0.15626527555286884
Epoch #210: loss=0.11990078824867563
Epoch #211: loss=0.12842962772744457
Epoch #212: loss=0.15110700650186074
Epoch #213: loss=0.13180337083048937
Epoch #214: loss=0.1540326519255958
Epoch #215: loss=0.13154652978225453
Epoch #216: loss=0.14789898502754
Epoch #217: loss=0.13427498941196175
Epoch #218: loss=0.14145481836323331
Epoch #219: loss=0.10218887603500994
Epoch #220: loss=0.12047282406469671
Epoch #221: loss=0.11126413037319009
Epoch #222: loss=0.07691185980490069
Epoch #223: loss=0.10093701067494183
Epoch #224: loss=0.10490071178391212
Epoch #225: loss=0.08071419087851919
Epoch #226: loss=0.07742201836734283
Epoch #227: loss=0.09336290924196564
Epoch #228: loss=0.09855449417742287
Epoch #229: loss=0.08332070444778698
Epoch #230: loss=0.08983367234014156
Epoch #231: loss=0.1189044253764356
Epoch #232: loss=0.10610433372600776
Epoch #233: loss=0.15271331660631227
Epoch #234: loss=0.10068794521616727
Epoch #235: loss=0.1240070215994265
Epoch #236: loss=0.10441389838915045
Epoch #237: loss=0.0857458301569994
Epoch #238: loss=0.07946230268969041
Epoch #239: loss=0.08489956041207401
Epoch #240: loss=0.13334481399960635
Epoch #241: loss=0.09089989037957133
Epoch #242: loss=0.13608277409632757
Epoch #243: loss=0.12674455590000966
Epoch #244: loss=0.08688356416163648
Epoch #245: loss=0.08258340821215292
Epoch #246: loss=0.09660996219552145
Epoch #247: loss=0.12110270021437872
Epoch #248: loss=0.08629929910345775
Epoch #249: loss=0.0722445035353303

Training time: 0:37:13.494423

Finished.
n2one setting etth2_weather_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_weather_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_weather_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.25301e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.42825e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.25301e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.36799049262586364, 'MAE': 0.4337017442282579}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='ettm1_ettm2_electricity', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/ettm1_ettm2_electricity_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.6642005474852404
Epoch #1: loss=0.6818300589006774
Epoch #2: loss=0.4848213499471676
Epoch #3: loss=0.39917505152371463
Epoch #4: loss=0.3179120097754648
Epoch #5: loss=0.2884590925089472
Epoch #6: loss=0.25071897220854855
Epoch #7: loss=0.208211297652638
Epoch #8: loss=0.19562719330061282
Epoch #9: loss=0.18862268742467156
Epoch #10: loss=0.15512459701247536
Epoch #11: loss=0.14649046508937466
Epoch #12: loss=0.13474822053061283
Epoch #13: loss=0.12908784398923115
Epoch #14: loss=0.12419554060080656
Epoch #15: loss=0.09676517095992412
Epoch #16: loss=0.10819299052586187
Epoch #17: loss=0.09877959960316778
Epoch #18: loss=0.08660777689720729
Epoch #19: loss=0.09695989274726664
Epoch #20: loss=0.07804958760988173
Epoch #21: loss=0.0661945627342486
Epoch #22: loss=0.06898384065972776
Epoch #23: loss=0.06226873119652228
Epoch #24: loss=0.06283750404324111
Epoch #25: loss=0.05387714751602392
Epoch #26: loss=0.04971381402425142
Epoch #27: loss=0.035456211154102066
Epoch #28: loss=0.053133718530937984
Epoch #29: loss=0.04347522998752708
Epoch #30: loss=0.04679310296556258
Epoch #31: loss=0.04194243042118869
Epoch #32: loss=0.03906400888240502
Epoch #33: loss=0.03508040276335677
Epoch #34: loss=0.034327804725943
Epoch #35: loss=0.04353688120822973
Epoch #36: loss=0.03444813219653904
Epoch #37: loss=0.03682578133647235
Epoch #38: loss=0.04913544558998708
Epoch #39: loss=0.025932557567269827
Epoch #40: loss=0.03407733610888221
Epoch #41: loss=0.03675020948247903
Epoch #42: loss=0.029635438091412142
Epoch #43: loss=0.023365947232940085
Epoch #44: loss=0.03220241408015848
Epoch #45: loss=0.028497535013797374
Epoch #46: loss=0.03167753962395338
Epoch #47: loss=0.044064682769879654
Epoch #48: loss=0.02081119130163945
Epoch #49: loss=0.025350369580915473
Epoch #50: loss=0.03810481382764702
Epoch #51: loss=0.027401987790420607
Epoch #52: loss=0.02834778392698301
Epoch #53: loss=0.03285156267338077
Epoch #54: loss=0.02563400874314857
Epoch #55: loss=0.023557795844999285
Epoch #56: loss=0.03565268647336366
Epoch #57: loss=0.026485858790226195
Epoch #58: loss=0.027421362950254786
Epoch #59: loss=0.018032471429245713
Epoch #60: loss=0.021167161122016043
Epoch #61: loss=0.018454072880049566
Epoch #62: loss=0.017514258258604056
Epoch #63: loss=0.028426651422710923
Epoch #64: loss=0.01752468913151413
Epoch #65: loss=0.022272365823124723
Epoch #66: loss=0.024511295331047397
Epoch #67: loss=0.02141390416300082
Epoch #68: loss=0.019117085987249927
Epoch #69: loss=0.026453212972352983
Epoch #70: loss=0.027070327847924507
Epoch #71: loss=0.027370104344077027
Epoch #72: loss=0.024612067684255615
Epoch #73: loss=0.022644158771279222
Epoch #74: loss=0.016908393367553405
Epoch #75: loss=0.02278873580287322
Epoch #76: loss=0.011924185447833358
Epoch #77: loss=0.017748240598697358
Epoch #78: loss=0.022295106014928512
Epoch #79: loss=0.023884224177286594
Epoch #80: loss=0.02868786786103203
Epoch #81: loss=0.015280137363612195
Epoch #82: loss=0.01628214898539582
Epoch #83: loss=0.019103785953009312
Epoch #84: loss=0.021297913754043923
Epoch #85: loss=0.018471240729016167
Epoch #86: loss=0.016151566284100468
Epoch #87: loss=0.014150971234009027
Epoch #88: loss=0.02414324357321638
Epoch #89: loss=0.031179771077433607
Epoch #90: loss=0.02622611788895698
Epoch #91: loss=0.01693740672752283
Epoch #92: loss=0.018536626841057006
Epoch #93: loss=0.016148287739635937
Epoch #94: loss=0.019747194906007008
Epoch #95: loss=0.01864057308407066
Epoch #96: loss=0.014796294269739833
Epoch #97: loss=0.013985635686439051
Epoch #98: loss=0.013796593924494237
Epoch #99: loss=0.02431450805741528
Epoch #100: loss=0.017974200712465315
Epoch #101: loss=0.017573413404645587
Epoch #102: loss=0.019260375680905596
Epoch #103: loss=0.012245060914194717
Epoch #104: loss=0.017301725500274135
Epoch #105: loss=0.01651310492133852
Epoch #106: loss=0.015752869305701835
Epoch #107: loss=0.014933670592818778
Epoch #108: loss=0.01352044164695921
Epoch #109: loss=0.01611342923338973
Epoch #110: loss=0.020706900761669107
Epoch #111: loss=0.026211469732961446
Epoch #112: loss=0.024557367270458055
Epoch #113: loss=0.034467880046280215
Epoch #114: loss=0.01581003813143635
Epoch #115: loss=0.009991838340002652
Epoch #116: loss=0.013993034351741998
Epoch #117: loss=0.01168244898352506
Epoch #118: loss=0.01663298395536324
Epoch #119: loss=0.013644541176775899
Epoch #120: loss=0.013640357006382626
Epoch #121: loss=0.015896879254759536
Epoch #122: loss=0.014798364520572538
Epoch #123: loss=0.014571628175233288
Epoch #124: loss=0.011653855381229398
Epoch #125: loss=0.010897509411415873
Epoch #126: loss=0.019042154074729346
Epoch #127: loss=0.014402960453918286
Epoch #128: loss=0.016766267370448906
Epoch #129: loss=0.010764331979413705
Epoch #130: loss=0.013723040279611923
Epoch #131: loss=0.01785244113418108
Epoch #132: loss=0.009405671755318956
Epoch #133: loss=0.014743964002910953
Epoch #134: loss=0.01182001205485344
Epoch #135: loss=0.014684976917065669
Epoch #136: loss=0.014749295409221022
Epoch #137: loss=0.012981862833033759
Epoch #138: loss=0.014319713786702586
Epoch #139: loss=0.010294487587014707
Epoch #140: loss=0.011612120393321526
Epoch #141: loss=0.011295933969136947
Epoch #142: loss=0.015190658587286977
Epoch #143: loss=0.00953869723825873
Epoch #144: loss=0.01193596126950202
Epoch #145: loss=0.01794278916055011
Epoch #146: loss=0.017332669464109666
Epoch #147: loss=0.011142119480013228
Epoch #148: loss=0.017692263684023046
Epoch #149: loss=0.014040632771786965
Epoch #150: loss=0.010592926048392664
Epoch #151: loss=0.013218276912201218
Epoch #152: loss=0.016567556805394144
Epoch #153: loss=0.015232632816742031
Epoch #154: loss=0.011943266144274862
Epoch #155: loss=0.016123355671413157
Epoch #156: loss=0.01633089774783087
Epoch #157: loss=0.01033958413454218
Epoch #158: loss=0.00961621701646102
Epoch #159: loss=0.007667323237523618
Epoch #160: loss=0.02697119655348252
Epoch #161: loss=0.013837634130318598
Epoch #162: loss=0.014080154469559843
Epoch #163: loss=0.012575080127994267
Epoch #164: loss=0.011221457508568443
Epoch #165: loss=0.011035539925135075
Epoch #166: loss=0.011101216866662617
Epoch #167: loss=0.014593033107563056
Epoch #168: loss=0.030085726969660893
Epoch #169: loss=0.011787540184974713
Epoch #170: loss=0.0070543051931502045
Epoch #171: loss=0.008957288766268955
Epoch #172: loss=0.015086091950307695
Epoch #173: loss=0.008195406709566547
Epoch #174: loss=0.013051794966955672
Epoch #175: loss=0.010585912648227294
Epoch #176: loss=0.01055358459140546
Epoch #177: loss=0.009165974884903541
Epoch #178: loss=0.012799236099894156
Epoch #179: loss=0.017237576451043953
Epoch #180: loss=0.011784440660886549
Epoch #181: loss=0.009152984580923817
Epoch #182: loss=0.013152034254574948
Epoch #183: loss=0.012526937025944016
Epoch #184: loss=0.010143999243027845
Epoch #185: loss=0.014358559801207947
Epoch #186: loss=0.013742031730133117
Epoch #187: loss=0.013716537816536208
Epoch #188: loss=0.010698236759416705
Epoch #189: loss=0.007945822871012856
Epoch #190: loss=0.02357370829930578
Epoch #191: loss=0.009198777866091596
Epoch #192: loss=0.010847148468341873
Epoch #193: loss=0.014844480785573055
Epoch #194: loss=0.008673173458751226
Epoch #195: loss=0.012312373065297375
Epoch #196: loss=0.01107303071162954
Epoch #197: loss=0.01430369510485739
Epoch #198: loss=0.015640636288653243
Epoch #199: loss=0.007159578325783524
Epoch #200: loss=0.008692933963949429
Epoch #201: loss=0.014941518391318262
Epoch #202: loss=0.0170712120848492
Epoch #203: loss=0.011537831410818924
Epoch #204: loss=0.009570430380457866
Epoch #205: loss=0.008830327962853731
Epoch #206: loss=0.008240908078435923
Epoch #207: loss=0.0059379369535336795
Epoch #208: loss=0.013618839179106605
Epoch #209: loss=0.010229398052509516
Epoch #210: loss=0.02722315144037513
Epoch #211: loss=0.009544197176365893
Epoch #212: loss=0.010172586148557573
Epoch #213: loss=0.030459383452879997
Epoch #214: loss=0.00955270280153287
Epoch #215: loss=0.007970884576223997
Epoch #216: loss=0.011649721255678678
Epoch #217: loss=0.006566223398148986
Epoch #218: loss=0.010420273777566519
Epoch #219: loss=0.016066218400679518
Epoch #220: loss=0.011600150908570894
Epoch #221: loss=0.01759717022650875
Epoch #222: loss=0.009042162855451726
Epoch #223: loss=0.008299117750568321
Epoch #224: loss=0.012331888480139108
Epoch #225: loss=0.010370571806476351
Epoch #226: loss=0.007374719938578263
Epoch #227: loss=0.014820724655042536
Epoch #228: loss=0.008165487209684555
Epoch #229: loss=0.008188580127694961
Epoch #230: loss=0.005706357595172395
Epoch #231: loss=0.008937982200938834
Epoch #232: loss=0.008657122124020422
Epoch #233: loss=0.014657283793902704
Epoch #234: loss=0.009596937402890067
Epoch #235: loss=0.010092488293445726
Epoch #236: loss=0.01186820538290274
Epoch #237: loss=0.01964642521151431
Epoch #238: loss=0.010461341384604828
Epoch #239: loss=0.009170878843552673
Epoch #240: loss=0.010749167668342633
Epoch #241: loss=0.007868169281416527
Epoch #242: loss=0.01849863344831708
Epoch #243: loss=0.012730296749897224
Epoch #244: loss=0.013730176134271216
Epoch #245: loss=0.006270174409616494
Epoch #246: loss=0.012611111686103394
Epoch #247: loss=0.00926132553992535
Epoch #248: loss=0.008406211778439402
Epoch #249: loss=0.008117655216296727

Training time: 4:44:00.166379

Finished.
n2one setting ettm1_ettm2_electricity -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm1_ettm2_electricity_epochs_250_seed_2022/model.pkl', muti_dataset='ettm1_ettm2_electricity', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.53728e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.95786e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.10297e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.53728e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.6270375971838363, 'MAE': 0.6093855590227076}
Finished.
------------------------- record done -------------------------
n2one setting ettm1_ettm2_electricity -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm1_ettm2_electricity_epochs_250_seed_2022/model.pkl', muti_dataset='ettm1_ettm2_electricity', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.10772e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3080474774286061, 'MAE': 0.3795478635061154}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='ettm1_ettm2_traffic', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/ettm1_ettm2_traffic_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.0205166923446893
Epoch #1: loss=0.3926793513187456
Epoch #2: loss=0.2685021721838017
Epoch #3: loss=0.19744162200802592
Epoch #4: loss=0.15424050874080997
Epoch #5: loss=0.13701586937742535
Epoch #6: loss=0.12105646750750652
Epoch #7: loss=0.0995200766994285
Epoch #8: loss=0.0960346398668625
Epoch #9: loss=0.07753030516573847
Epoch #10: loss=0.06760707857430706
Epoch #11: loss=0.059965323435028854
Epoch #12: loss=0.059634928857566306
Epoch #13: loss=0.05151661101315693
Epoch #14: loss=0.04931563435847201
Epoch #15: loss=0.05552402452504625
Epoch #16: loss=0.04666001788615481
Epoch #17: loss=0.04368206869697038
Epoch #18: loss=0.03879098912013054
Epoch #19: loss=0.042151127770444066
Epoch #20: loss=0.04639386310088301
Epoch #21: loss=0.031249435447584163
Epoch #22: loss=0.032748696949476234
Epoch #23: loss=0.03569237193397175
Epoch #24: loss=0.030959255404046596
Epoch #25: loss=0.026751821680517016
Epoch #26: loss=0.030365590826683043
Epoch #27: loss=0.029546768276934296
Epoch #28: loss=0.02839086020451747
Epoch #29: loss=0.0306980488699391
Epoch #30: loss=0.02175631413792789
Epoch #31: loss=0.02515182012694201
Epoch #32: loss=0.033986356588606235
Epoch #33: loss=0.0249033613688559
Epoch #34: loss=0.027959394300165818
Epoch #35: loss=0.023961949522361557
Epoch #36: loss=0.02273389139624599
Epoch #37: loss=0.028040329031003598
Epoch #38: loss=0.019417285376603845
Epoch #39: loss=0.02289128774812348
Epoch #40: loss=0.0224068480071283
Epoch #41: loss=0.019974365419741378
Epoch #42: loss=0.02432485149827748
Epoch #43: loss=0.022682498133719194
Epoch #44: loss=0.02733699667903045
Epoch #45: loss=0.030654219704800246
Epoch #46: loss=0.017434743595703576
Epoch #47: loss=0.019151778576972766
Epoch #48: loss=0.02105182052297071
Epoch #49: loss=0.023532378982975912
Epoch #50: loss=0.019654725995575863
Epoch #51: loss=0.023453636110599082
Epoch #52: loss=0.011903048251445798
Epoch #53: loss=0.0242018840819986
Epoch #54: loss=0.03319627824467259
Epoch #55: loss=0.018883674782515153
Epoch #56: loss=0.018472161664150374
Epoch #57: loss=0.01924149765772903
Epoch #58: loss=0.018361403613383682
Epoch #59: loss=0.02972340813471316
Epoch #60: loss=0.017404210584153097
Epoch #61: loss=0.015749795646971668
Epoch #62: loss=0.02077283135822572
Epoch #63: loss=0.021486859764283252
Epoch #64: loss=0.015944785081791455
Epoch #65: loss=0.022721765758091747
Epoch #66: loss=0.01751205285224111
Epoch #67: loss=0.01564172247615477
Epoch #68: loss=0.014375856760491584
Epoch #69: loss=0.02020260580949437
Epoch #70: loss=0.021828958881614367
Epoch #71: loss=0.017380138381441732
Epoch #72: loss=0.015786632553598426
Epoch #73: loss=0.01541002995193129
Epoch #74: loss=0.016497869633861958
Epoch #75: loss=0.015147405110665164
Epoch #76: loss=0.017126764067925005
Epoch #77: loss=0.016996369562926966
Epoch #78: loss=0.01830023070551061
Epoch #79: loss=0.014891785786352047
Epoch #80: loss=0.018105140494496658
Epoch #81: loss=0.012727431442056007
Epoch #82: loss=0.012660758717956676
Epoch #83: loss=0.01916509710271512
Epoch #84: loss=0.01879236276901661
Epoch #85: loss=0.01689707850164268
Epoch #86: loss=0.015542369816959015
Epoch #87: loss=0.020956599653018448
Epoch #88: loss=0.014031583152410345
Epoch #89: loss=0.014140832410612758
Epoch #90: loss=0.01333101994223151
Epoch #91: loss=0.018671874848602138
Epoch #92: loss=0.017452248148130237
Epoch #93: loss=0.011987330505850395
Epoch #94: loss=0.017173743171631086
Epoch #95: loss=0.013193018295922279
Epoch #96: loss=0.014184325720247817
Epoch #97: loss=0.013630015680315426
Epoch #98: loss=0.016427996604333577
Epoch #99: loss=0.010411970281346102
Epoch #100: loss=0.014569775432926904
Epoch #101: loss=0.01128793852851182
Epoch #102: loss=0.018230881034559887
Epoch #103: loss=0.009594101269969
Epoch #104: loss=0.009265246541563677
Epoch #105: loss=0.011917856098277476
Epoch #106: loss=0.013982095695190275
Epoch #107: loss=0.015862844260375236
Epoch #108: loss=0.015707844144854866
Epoch #109: loss=0.016111267672583557
Epoch #110: loss=0.0156405891320901
Epoch #111: loss=0.012259837967576459
Epoch #112: loss=0.01647439240934949
Epoch #113: loss=0.010004823237483846
Epoch #114: loss=0.016773972153060226
Epoch #115: loss=0.013136347624690828
Epoch #116: loss=0.012505177004163773
Epoch #117: loss=0.012668695402911356
Epoch #118: loss=0.011391852408035434
Epoch #119: loss=0.010492481332645241
Epoch #120: loss=0.011261147813559658
Epoch #121: loss=0.013836115941636284
Epoch #122: loss=0.01594619940044132
Epoch #123: loss=0.013464607543024136
Epoch #124: loss=0.015274512801221645
Epoch #125: loss=0.013792258604450469
Epoch #126: loss=0.011646783506909014
Epoch #127: loss=0.011254899391190837
Epoch #128: loss=0.014882673414633977
Epoch #129: loss=0.011687205608282817
Epoch #130: loss=0.013098408522748442
Epoch #131: loss=0.014617698833507557
Epoch #132: loss=0.011341898786301758
Epoch #133: loss=0.0183801483793956
Epoch #134: loss=0.010073800620976393
Epoch #135: loss=0.013508255830770375
Epoch #136: loss=0.013354167595461729
Epoch #137: loss=0.011332078684326546
Epoch #138: loss=0.018120855518234304
Epoch #139: loss=0.010070808558656077
Epoch #140: loss=0.007788503948808288
Epoch #141: loss=0.009918715915897106
Epoch #142: loss=0.012440397105079246
Epoch #143: loss=0.012413976699825243
Epoch #144: loss=0.009238096007263937
Epoch #145: loss=0.01456567809325211
Epoch #146: loss=0.013076972788797925
Epoch #147: loss=0.012804762155985158
Epoch #148: loss=0.01018849837996908
Epoch #149: loss=0.01133332792983619
Epoch #150: loss=0.012853649377254495
Epoch #151: loss=0.016118508983470343
Epoch #152: loss=0.011422780521731029
Epoch #153: loss=0.01117676582473975
Epoch #154: loss=0.01109199349711536
Epoch #155: loss=0.010188696713240004
Epoch #156: loss=0.012399237574405001
Epoch #157: loss=0.007301666699186583
Epoch #158: loss=0.014330347714328468
Epoch #159: loss=0.01017142513056236
Epoch #160: loss=0.012666041559562913
Epoch #161: loss=0.013030292268119999
Epoch #162: loss=0.00767361887557352
Epoch #163: loss=0.013753654511049006
Epoch #164: loss=0.015305980841706378
Epoch #165: loss=0.01018321846622897
Epoch #166: loss=0.012766316954518075
Epoch #167: loss=0.013550304656474834
Epoch #168: loss=0.006985966171928401
Epoch #169: loss=0.013368212941936094
Epoch #170: loss=0.010887918562623193
Epoch #171: loss=0.013428582174223332
Epoch #172: loss=0.01642007772331795
Epoch #173: loss=0.011319967379035113
Epoch #174: loss=0.013591409761455212
Epoch #175: loss=0.011986763146688641
Epoch #176: loss=0.010039136435955602
Epoch #177: loss=0.012834705989789407
Epoch #178: loss=0.010533450406980522
Epoch #179: loss=0.01282823516419542
Epoch #180: loss=0.012108081084021843
Epoch #181: loss=0.011789003639430997
Epoch #182: loss=0.008918187574665056
Epoch #183: loss=0.008726568109091101
Epoch #184: loss=0.01087243759850758
Epoch #185: loss=0.012326980686800005
Epoch #186: loss=0.016559010205733245
Epoch #187: loss=0.0103313766695913
Epoch #188: loss=0.01158112804208183
Epoch #189: loss=0.010896550437491609
Epoch #190: loss=0.012833459554643083
Epoch #191: loss=0.013112245026156223
Epoch #192: loss=0.007161744119355725
Epoch #193: loss=0.011301655068790632
Epoch #194: loss=0.013907858554104093
Epoch #195: loss=0.010614713785333777
Epoch #196: loss=0.011859498030916425
Epoch #197: loss=0.010422170364067599
Epoch #198: loss=0.012993992167711403
Epoch #199: loss=0.008229928940858685
Epoch #200: loss=0.012908688829572397
Epoch #201: loss=0.00826297065373697
Epoch #202: loss=0.009982821120403426
Epoch #203: loss=0.012830209522916329
Epoch #204: loss=0.00825608892122385
Epoch #205: loss=0.008329020698996771
Epoch #206: loss=0.013687434625941986
Epoch #207: loss=0.0115673793463668
Epoch #208: loss=0.008751644516492204
Epoch #209: loss=0.008655190210114128
Epoch #210: loss=0.020535264554608936
Epoch #211: loss=0.008200111657628835
Epoch #212: loss=0.005595151897817713
Epoch #213: loss=0.010731860468180811
Epoch #214: loss=0.012451999231021192
Epoch #215: loss=0.011366282063988048
Epoch #216: loss=0.013331151494146083
Epoch #217: loss=0.005050473778970314
Epoch #218: loss=0.013141691525343214
Epoch #219: loss=0.010337563039729297
Epoch #220: loss=0.006584962469243313
Epoch #221: loss=0.012628176289696692
Epoch #222: loss=0.010474219779135386
Epoch #223: loss=0.016510404637276998
Epoch #224: loss=0.0072497816633269015
Epoch #225: loss=0.012485746702315522
Epoch #226: loss=0.012231865195068636
Epoch #227: loss=0.00929185176216597
Epoch #228: loss=0.008153251293764886
Epoch #229: loss=0.008721787060259958
Epoch #230: loss=0.007806533224376169
Epoch #231: loss=0.009970466047082594
Epoch #232: loss=0.010254008890353765
Epoch #233: loss=0.008825314049499043
Epoch #234: loss=0.009799594972719206
Epoch #235: loss=0.010698596971587286
Epoch #236: loss=0.00964380890295677
Epoch #237: loss=0.016422285481557046
Epoch #238: loss=0.007048931743012535
Epoch #239: loss=0.01042308702420486
Epoch #240: loss=0.01174308711038539
Epoch #241: loss=0.00877148128365579
Epoch #242: loss=0.008590911634484853
Epoch #243: loss=0.01167540018589563
Epoch #244: loss=0.007741230590366026
Epoch #245: loss=0.0120174907541247
Epoch #246: loss=0.013696410461912055
Epoch #247: loss=0.010622268856846915
Epoch #248: loss=0.007259016253403915
Epoch #249: loss=0.00819805504389433

Training time: 10:15:17.410626

Finished.
n2one setting ettm1_ettm2_traffic -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm1_ettm2_traffic_epochs_250_seed_2022/model.pkl', muti_dataset='ettm1_ettm2_traffic', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.21002e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.80879e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.57495e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.21002e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4191390777507952, 'MAE': 0.4613539985750196}
Finished.
------------------------- record done -------------------------
n2one setting ettm1_ettm2_traffic -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm1_ettm2_traffic_epochs_250_seed_2022/model.pkl', muti_dataset='ettm1_ettm2_traffic', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.07066e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.30509e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.76239e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.5954119644435926, 'MAE': 0.6115470947468961}
Finished.
------------------------- record done -------------------------
n2one setting ettm1_ettm2_traffic -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm1_ettm2_traffic_epochs_250_seed_2022/model.pkl', muti_dataset='ettm1_ettm2_traffic', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.87145e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.27476949770491793, 'MAE': 0.35224098822299876}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='ettm1_ettm2_weather', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/ettm1_ettm2_weather_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=4.319706713159879
Epoch #1: loss=2.727940564354261
Epoch #2: loss=2.1741163109739623
Epoch #3: loss=1.9065298264225323
Epoch #4: loss=1.7719485784570377
Epoch #5: loss=1.586985357105732
Epoch #6: loss=1.3525165518124898
Epoch #7: loss=1.32966148853302
Epoch #8: loss=1.1827647909522057
Epoch #9: loss=1.1126209137340386
Epoch #10: loss=0.994994423041741
Epoch #11: loss=0.9970008445282778
Epoch #12: loss=0.8948697994152705
Epoch #13: loss=1.0199077675739925
Epoch #14: loss=0.8288833213349184
Epoch #15: loss=0.7799655025204023
Epoch #16: loss=0.7566661226252714
Epoch #17: loss=0.7451330150167147
Epoch #18: loss=0.73738540088137
Epoch #19: loss=0.7096203242739042
Epoch #20: loss=0.6682240317265192
Epoch #21: loss=0.6956801805645227
Epoch #22: loss=0.6758748019735018
Epoch #23: loss=0.6629216720660528
Epoch #24: loss=0.7908400222659111
Epoch #25: loss=0.5933525245636702
Epoch #26: loss=0.5886043968300024
Epoch #27: loss=0.5768951829522848
Epoch #28: loss=0.5978566681345304
Epoch #29: loss=0.5649142184605201
Epoch #30: loss=0.501962640012304
Epoch #31: loss=0.46097068550686043
Epoch #32: loss=0.4622196430961291
Epoch #33: loss=0.48610287718474865
Epoch #34: loss=0.4750835448503494
Epoch #35: loss=0.49260493988792103
Epoch #36: loss=0.5174435482670864
Epoch #37: loss=0.4381703200439612
Epoch #38: loss=0.40315027814358473
Epoch #39: loss=0.4400763312975566
Epoch #40: loss=0.38599500556786853
Epoch #41: loss=0.38210460140059394
Epoch #42: loss=0.36671414598822594
Epoch #43: loss=0.4299894630288084
Epoch #44: loss=0.3394084790100654
Epoch #45: loss=0.36130316896984976
Epoch #46: loss=0.36268880404531956
Epoch #47: loss=0.3452199225624402
Epoch #48: loss=0.4165406993900736
Epoch #49: loss=0.4031891003251076
Epoch #50: loss=0.28530346509069204
Epoch #51: loss=0.3180291010066867
Epoch #52: loss=0.279367928703626
Epoch #53: loss=0.2720122477039695
Epoch #54: loss=0.3024975123504798
Epoch #55: loss=0.267346588584284
Epoch #56: loss=0.25599854718893766
Epoch #57: loss=0.2966775038900475
Epoch #58: loss=0.27553778265913326
Epoch #59: loss=0.23312974286576113
Epoch #60: loss=0.20531043705220023
Epoch #61: loss=0.2489286786876619
Epoch #62: loss=0.25790951726958156
Epoch #63: loss=0.2443453815455238
Epoch #64: loss=0.22183129393185178
Epoch #65: loss=0.25471348005036515
Epoch #66: loss=0.22002113703638315
Epoch #67: loss=0.2634983123280108
Epoch #68: loss=0.21768191208442053
Epoch #69: loss=0.2578833792358637
Epoch #70: loss=0.22831012960523367
Epoch #71: loss=0.187047372572124
Epoch #72: loss=0.15326511270056167
Epoch #73: loss=0.17019221698865294
Epoch #74: loss=0.16208882241820297
Epoch #75: loss=0.13498065946623683
Epoch #76: loss=0.12817850421803692
Epoch #77: loss=0.16333637107163668
Epoch #78: loss=0.13577754492871463
Epoch #79: loss=0.14973479385177293
Epoch #80: loss=0.15162570254566768
Epoch #81: loss=0.14016400673426688
Epoch #82: loss=0.1257979953661561
Epoch #83: loss=0.15468958299607038
Epoch #84: loss=0.19092143575350443
Epoch #85: loss=0.1718044118800511
Epoch #86: loss=0.10699887853115797
Epoch #87: loss=0.15055635610284904
Epoch #88: loss=0.15591399845046303
Epoch #89: loss=0.15743997475753227
Epoch #90: loss=0.12408580568929513
Epoch #91: loss=0.15298451265941063
Epoch #92: loss=0.11843433269920449
Epoch #93: loss=0.1319776156451553
Epoch #94: loss=0.1138953009309868
Epoch #95: loss=0.17613942036405206
Epoch #96: loss=0.13362643270132443
Epoch #97: loss=0.1751473016726474
Epoch #98: loss=0.10103013350938757
Epoch #99: loss=0.26444291641625267
Epoch #100: loss=0.24581582370835045
Epoch #101: loss=0.15292046257915595
Epoch #102: loss=0.14835979137569666
Epoch #103: loss=0.16655089162910977
Epoch #104: loss=0.10324888109850387
Epoch #105: loss=0.1074513328106453
Epoch #106: loss=0.0989483657758683
Epoch #107: loss=0.12220081566677739
Epoch #108: loss=0.07862422712302457
Epoch #109: loss=0.11379643875019003
Epoch #110: loss=0.10760316093607496
Epoch #111: loss=0.08415142283774912
Epoch #112: loss=0.08490687519467126
Epoch #113: loss=0.07690224245501061
Epoch #114: loss=0.10495672503020614
Epoch #115: loss=0.10234746107986818
Epoch #116: loss=0.06653285430123408
Epoch #117: loss=0.09355806353657196
Epoch #118: loss=0.06877084371323387
Epoch #119: loss=0.08028572630913307
Epoch #120: loss=0.06414704746566713
Epoch #121: loss=0.09767193929292262
Epoch #122: loss=0.0670126734379058
Epoch #123: loss=0.07629823164703946
Epoch #124: loss=0.07435423748878141
Epoch #125: loss=0.07803450819725792
Epoch #126: loss=0.06291580223478377
Epoch #127: loss=0.056034656804210194
Epoch #128: loss=0.05725989168665061
Epoch #129: loss=0.07581328297965229
Epoch #130: loss=0.15298175901019326
Epoch #131: loss=0.14187278598546982
Epoch #132: loss=0.0778219075097392
Epoch #133: loss=0.11182642848386119
Epoch #134: loss=0.07223733169181894
Epoch #135: loss=0.06581343985938777
Epoch #136: loss=0.059640303428750485
Epoch #137: loss=0.09251386544201523
Epoch #138: loss=0.09188355264874797
Epoch #139: loss=0.07312235500042637
Epoch #140: loss=0.04982816158250595
Epoch #141: loss=0.06812592875212431
Epoch #142: loss=0.14371087211960307
Epoch #143: loss=0.07278622104786336
Epoch #144: loss=0.05346097407164052
Epoch #145: loss=0.05708268383750692
Epoch #146: loss=0.0521089886703218
Epoch #147: loss=0.14445734990295023
Epoch #148: loss=0.13168246027392647
Epoch #149: loss=0.0940157149064665
Epoch #150: loss=0.05565241017999748
Epoch #151: loss=0.05976062205930551
Epoch #152: loss=0.05164416586436952
Epoch #153: loss=0.04203756297162423
Epoch #154: loss=0.12335843920785312
Epoch #155: loss=0.06923142591646562
Epoch #156: loss=0.04328420754366865
Epoch #157: loss=0.056917309605826936
Epoch #158: loss=0.1204566714198639
Epoch #159: loss=0.04144321562489495
Epoch #160: loss=0.0575383425069352
Epoch #161: loss=0.08442203739347558
Epoch #162: loss=0.04817718381915862
Epoch #163: loss=0.07735155183278646
Epoch #164: loss=0.05088733020238578
Epoch #165: loss=0.07617718759380902
Epoch #166: loss=0.06071550088624159
Epoch #167: loss=0.05117402728258943
Epoch #168: loss=0.05110243828191111
Epoch #169: loss=0.05200416825634117
Epoch #170: loss=0.05477755836909637
Epoch #171: loss=0.04267472077238684
Epoch #172: loss=0.1150399634304146
Epoch #173: loss=0.0823858201620169
Epoch #174: loss=0.10181819864859183
Epoch #175: loss=0.07978372826861839
Epoch #176: loss=0.11891564493998885
Epoch #177: loss=0.056244405005903296
Epoch #178: loss=0.04159323842031881
Epoch #179: loss=0.037440843298099935
Epoch #180: loss=0.0711602385272272
Epoch #181: loss=0.09003891982138157
Epoch #182: loss=0.041589668369852006
Epoch #183: loss=0.037236030718001224
Epoch #184: loss=0.05921625380869955
Epoch #185: loss=0.08020083889520417
Epoch #186: loss=0.06343378314826016
Epoch #187: loss=0.04681992299932366
Epoch #188: loss=0.08550641592592001
Epoch #189: loss=0.05371146796581646
Epoch #190: loss=0.05636380948514367
Epoch #191: loss=0.0818430528161116
Epoch #192: loss=0.09058231451005365
Epoch #193: loss=0.05743587721372023
Epoch #194: loss=0.07685504861486454
Epoch #195: loss=0.08475427436254297
Epoch #196: loss=0.0951870441980039
Epoch #197: loss=0.045983561275837324
Epoch #198: loss=0.039850656078973166
Epoch #199: loss=0.03837945432557414
Epoch #200: loss=0.042587638386369996
Epoch #201: loss=0.04035959824492844
Epoch #202: loss=0.043432523224813245
Epoch #203: loss=0.0534853267405803
Epoch #204: loss=0.034252791316248477
Epoch #205: loss=0.02467382378138912
Epoch #206: loss=0.04084475829343622
Epoch #207: loss=0.05197594557345534
Epoch #208: loss=0.05934132005010421
Epoch #209: loss=0.026252982061123475
Epoch #210: loss=0.0397867053882995
Epoch #211: loss=0.02208638988668099
Epoch #212: loss=0.026492267885866266
Epoch #213: loss=0.04239288417738862
Epoch #214: loss=0.0478818760990786
Epoch #215: loss=0.035377649134413026
Epoch #216: loss=0.038537752096696444
Epoch #217: loss=0.03347833894076757
Epoch #218: loss=0.037919909499275185
Epoch #219: loss=0.033230396918952465
Epoch #220: loss=0.04397677788316893
Epoch #221: loss=0.0349081830548433
Epoch #222: loss=0.03468624775026304
Epoch #223: loss=0.18059985764557496
Epoch #224: loss=0.046270937755859144
Epoch #225: loss=0.026905486059452716
Epoch #226: loss=0.028177953548341367
Epoch #227: loss=0.034610545447018616
Epoch #228: loss=0.025124178268015385
Epoch #229: loss=0.04378927235181133
Epoch #230: loss=0.04389223527202072
Epoch #231: loss=0.03777459907966355
Epoch #232: loss=0.02536625343297298
Epoch #233: loss=0.029103404105020065
Epoch #234: loss=0.03382368015203004
Epoch #235: loss=0.03893325009266846
Epoch #236: loss=0.03664398751182792
Epoch #237: loss=0.027291699196211994
Epoch #238: loss=0.024936698891300086
Epoch #239: loss=0.028690032593052212
Epoch #240: loss=0.04368841336690821
Epoch #241: loss=0.05492769491199093
Epoch #242: loss=0.04817351193438905
Epoch #243: loss=0.030589303506227832
Epoch #244: loss=0.0337836640731742
Epoch #245: loss=0.02964663213545767
Epoch #246: loss=0.033069241452418886
Epoch #247: loss=0.07801491044422922
Epoch #248: loss=0.043588700684874006
Epoch #249: loss=0.0671564686538962

Training time: 0:49:04.947252

Finished.
n2one setting ettm1_ettm2_weather -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm1_ettm2_weather_epochs_250_seed_2022/model.pkl', muti_dataset='ettm1_ettm2_weather', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.27723e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.61303e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.27723e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.36693337537787335, 'MAE': 0.42551748947390755}
Finished.
------------------------- record done -------------------------
n2one setting ettm1_ettm2_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm1_ettm2_weather_epochs_250_seed_2022/model.pkl', muti_dataset='ettm1_ettm2_weather', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.48804e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.24760282539435566, 'MAE': 0.3430409019477683}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='ettm1_ettm2_exchange', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/ettm1_ettm2_exchange_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=4.266811247666677
Epoch #1: loss=2.4254014690717063
Epoch #2: loss=2.057761025428772
Epoch #3: loss=1.8909900148709615
Epoch #4: loss=1.7496180216471353
Epoch #5: loss=1.6548596143722534
Epoch #6: loss=1.4999338507652282
Epoch #7: loss=1.3560050010681153
Epoch #8: loss=1.312322167555491
Epoch #9: loss=1.2583267331123351
Epoch #10: loss=1.2614962299664816
Epoch #11: loss=1.155817731221517
Epoch #12: loss=1.0704058388868967
Epoch #13: loss=1.007336324453354
Epoch #14: loss=0.9377982517083486
Epoch #15: loss=0.9788873155911764
Epoch #16: loss=0.9753917316595714
Epoch #17: loss=1.069862006107966
Epoch #18: loss=0.919987819592158
Epoch #19: loss=0.8363911588986714
Epoch #20: loss=0.896696521838506
Epoch #21: loss=0.8584986845652263
Epoch #22: loss=0.7530007759730021
Epoch #23: loss=0.7751562515894572
Epoch #24: loss=0.7621050079663595
Epoch #25: loss=0.6619085709253947
Epoch #26: loss=0.6595754146575927
Epoch #27: loss=0.6901579449574152
Epoch #28: loss=0.6257953365643819
Epoch #29: loss=0.691833707690239
Epoch #30: loss=0.650131477912267
Epoch #31: loss=0.6462397128343582
Epoch #32: loss=0.712443134188652
Epoch #33: loss=0.7155409753322601
Epoch #34: loss=0.6745494405428568
Epoch #35: loss=0.6241650938987732
Epoch #36: loss=0.5927226891120275
Epoch #37: loss=0.7077174683411916
Epoch #38: loss=0.553098318974177
Epoch #39: loss=0.625396990776062
Epoch #40: loss=0.5870036860307057
Epoch #41: loss=0.5648464173078537
Epoch #42: loss=0.5670815298954646
Epoch #43: loss=0.5180331299702327
Epoch #44: loss=0.477446253101031
Epoch #45: loss=0.5930349002281825
Epoch #46: loss=0.5646909197171529
Epoch #47: loss=0.6454582671324413
Epoch #48: loss=0.47921126981576284
Epoch #49: loss=0.4186912437280019
Epoch #50: loss=0.4061804493268331
Epoch #51: loss=0.4326883802811305
Epoch #52: loss=0.4151705657442411
Epoch #53: loss=0.3672600497802099
Epoch #54: loss=0.39471462815999986
Epoch #55: loss=0.3840919921795527
Epoch #56: loss=0.39097658594449364
Epoch #57: loss=0.36850262035926185
Epoch #58: loss=0.32898437082767484
Epoch #59: loss=0.4638736913601557
Epoch #60: loss=0.3752931212385496
Epoch #61: loss=0.44019990414381027
Epoch #62: loss=0.34011887113253275
Epoch #63: loss=0.3121499260266622
Epoch #64: loss=0.471379650135835
Epoch #65: loss=0.35285467555125555
Epoch #66: loss=0.35408914188543955
Epoch #67: loss=0.3546605572104454
Epoch #68: loss=0.3141051590442657
Epoch #69: loss=0.3511342247327169
Epoch #70: loss=0.3362034261226654
Epoch #71: loss=0.3494570851325989
Epoch #72: loss=0.3137464861075083
Epoch #73: loss=0.3592845477163792
Epoch #74: loss=0.28025441666444145
Epoch #75: loss=0.2800051838159561
Epoch #76: loss=0.2373293807109197
Epoch #77: loss=0.2762256662050883
Epoch #78: loss=0.26548626100023587
Epoch #79: loss=0.24753911569714546
Epoch #80: loss=0.19143328219652175
Epoch #81: loss=0.21781834041078885
Epoch #82: loss=0.22725179096062978
Epoch #83: loss=0.2789351520438989
Epoch #84: loss=0.23541561836997668
Epoch #85: loss=0.2510107050339381
Epoch #86: loss=0.2957295313477516
Epoch #87: loss=0.30617786596218743
Epoch #88: loss=0.2523935116827488
Epoch #89: loss=0.19927776033679645
Epoch #90: loss=0.2233728797485431
Epoch #91: loss=0.17588679815332095
Epoch #92: loss=0.17846278299887974
Epoch #93: loss=0.20340928969283897
Epoch #94: loss=0.17835501531759898
Epoch #95: loss=0.3272554529209932
Epoch #96: loss=0.26141988138357797
Epoch #97: loss=0.27822498853007954
Epoch #98: loss=0.2845634140074253
Epoch #99: loss=0.2535594015071789
Epoch #100: loss=0.22327884485324223
Epoch #101: loss=0.242198180158933
Epoch #102: loss=0.17113049340744813
Epoch #103: loss=0.19514502647022405
Epoch #104: loss=0.14821853525936604
Epoch #105: loss=0.2571284543722868
Epoch #106: loss=0.16401180724302927
Epoch #107: loss=0.19106233132382233
Epoch #108: loss=0.19874507437149683
Epoch #109: loss=0.33460795506834984
Epoch #110: loss=0.28621834715207417
Epoch #111: loss=0.23225540816783904
Epoch #112: loss=0.199003799756368
Epoch #113: loss=0.14992895163595676
Epoch #114: loss=0.14292023554444314
Epoch #115: loss=0.1331170914073785
Epoch #116: loss=0.11837603735427062
Epoch #117: loss=0.1607481292138497
Epoch #118: loss=0.12970487239460152
Epoch #119: loss=0.13936089475949606
Epoch #120: loss=0.13893427085131407
Epoch #121: loss=0.14496874051789443
Epoch #122: loss=0.15044941219190758
Epoch #123: loss=0.31323472696046034
Epoch #124: loss=0.2213742544253667
Epoch #125: loss=0.1314297800262769
Epoch #126: loss=0.2065534150848786
Epoch #127: loss=0.18661260182658831
Epoch #128: loss=0.13212817162275314
Epoch #129: loss=0.18730656566719214
Epoch #130: loss=0.16712679428358873
Epoch #131: loss=0.1917422732959191
Epoch #132: loss=0.18628077693283557
Epoch #133: loss=0.10206829545398553
Epoch #134: loss=0.128394973402222
Epoch #135: loss=0.12689465855558713
Epoch #136: loss=0.12880465630441904
Epoch #137: loss=0.12575931437313556
Epoch #138: loss=0.19701328054070472
Epoch #139: loss=0.14921925819168488
Epoch #140: loss=0.1189475500335296
Epoch #141: loss=0.10786245750884214
Epoch #142: loss=0.10394054396698872
Epoch #143: loss=0.11628190521150827
Epoch #144: loss=0.10897993097702662
Epoch #145: loss=0.1978308107703924
Epoch #146: loss=0.13721117128928503
Epoch #147: loss=0.16250263353188832
Epoch #148: loss=0.13098812140524388
Epoch #149: loss=0.10987293273210526
Epoch #150: loss=0.171418134868145
Epoch #151: loss=0.166086816166838
Epoch #152: loss=0.16661589841047922
Epoch #153: loss=0.13721763857950767
Epoch #154: loss=0.14825163955489795
Epoch #155: loss=0.13669644345839818
Epoch #156: loss=0.09566991881777843
Epoch #157: loss=0.09336220466842254
Epoch #158: loss=0.12513105298082033
Epoch #159: loss=0.08493765133122604
Epoch #160: loss=0.09570361239214738
Epoch #161: loss=0.11359378465761741
Epoch #162: loss=0.0988701792123417
Epoch #163: loss=0.0840599810704589
Epoch #164: loss=0.10560271504024664
Epoch #165: loss=0.11027813768014312
Epoch #166: loss=0.12298154961317778
Epoch #167: loss=0.15885199302186567
Epoch #168: loss=0.1440919851884246
Epoch #169: loss=0.21181923883656661
Epoch #170: loss=0.14789794199168682
Epoch #171: loss=0.11632726086924473
Epoch #172: loss=0.10309107080101967
Epoch #173: loss=0.12090509726355474
Epoch #174: loss=0.18016176621119182
Epoch #175: loss=0.12364727649837733
Epoch #176: loss=0.11449688319116831
Epoch #177: loss=0.1477097565929095
Epoch #178: loss=0.0997046485543251
Epoch #179: loss=0.08989913892000914
Epoch #180: loss=0.09049807544797658
Epoch #181: loss=0.09574422019844255
Epoch #182: loss=0.09026961509759228
Epoch #183: loss=0.11076401704922319
Epoch #184: loss=0.122633323383828
Epoch #185: loss=0.07710617991785208
Epoch #186: loss=0.08974050177882115
Epoch #187: loss=0.08372244083633025
Epoch #188: loss=0.10519031143436829
Epoch #189: loss=0.1263213252648711
Epoch #190: loss=0.17299462668597698
Epoch #191: loss=0.15335499768455824
Epoch #192: loss=0.2384083549802502
Epoch #193: loss=0.1525391135364771
Epoch #194: loss=0.10204450711607933
Epoch #195: loss=0.11978876832872629
Epoch #196: loss=0.1250989569971959
Epoch #197: loss=0.08648699826250474
Epoch #198: loss=0.11169411477943261
Epoch #199: loss=0.1213134977966547
Epoch #200: loss=0.07655013473704457
Epoch #201: loss=0.08071121849740545
Epoch #202: loss=0.07765238011876742
Epoch #203: loss=0.07663743219648798
Epoch #204: loss=0.09842405275752147
Epoch #205: loss=0.05356146302074194
Epoch #206: loss=0.06653583751370509
Epoch #207: loss=0.0939482705357174
Epoch #208: loss=0.06359284290422997
Epoch #209: loss=0.09697223358477156
Epoch #210: loss=0.1169266501131157
Epoch #211: loss=0.0754523189427952
Epoch #212: loss=0.06564712819332878
Epoch #213: loss=0.06358105589946111
Epoch #214: loss=0.08893321348975101
Epoch #215: loss=0.16266280533745886
Epoch #216: loss=0.10236261319369078
Epoch #217: loss=0.09221744233121475
Epoch #218: loss=0.0736698725571235
Epoch #219: loss=0.06937773932392398
Epoch #220: loss=0.06713330259857078
Epoch #221: loss=0.059506732039153576
Epoch #222: loss=0.08991390050699313
Epoch #223: loss=0.15665050909544032
Epoch #224: loss=0.07948527516176303
Epoch #225: loss=0.06945197843015194
Epoch #226: loss=0.07619547384480635
Epoch #227: loss=0.07251509974400203
Epoch #228: loss=0.09898429879297813
Epoch #229: loss=0.05887186247855425
Epoch #230: loss=0.04844740175952514
Epoch #231: loss=0.05836461391299963
Epoch #232: loss=0.07395674319316943
Epoch #233: loss=0.06256127879023551
Epoch #234: loss=0.07852788359547655
Epoch #235: loss=0.06647442504763604
Epoch #236: loss=0.07512148087844253
Epoch #237: loss=0.07105920041600863
Epoch #238: loss=0.05431656815732519
Epoch #239: loss=0.07362121309464177
Epoch #240: loss=0.14103750577196478
Epoch #241: loss=0.10113106758023302
Epoch #242: loss=0.07312142929683128
Epoch #243: loss=0.06563343924159805
Epoch #244: loss=0.11622965844968955
Epoch #245: loss=0.07829314631720384
Epoch #246: loss=0.06274695883815487
Epoch #247: loss=0.0787455581749479
Epoch #248: loss=0.11991556119173766
Epoch #249: loss=0.10324546108022332

Training time: 0:27:40.753118

Finished.
n2one setting ettm1_ettm2_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm1_ettm2_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='ettm1_ettm2_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.32534e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.61271e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.32534e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.37335103704201794, 'MAE': 0.4339533857015143}
Finished.
------------------------- record done -------------------------
n2one setting ettm1_ettm2_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm1_ettm2_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='ettm1_ettm2_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.29964e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.86894e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.39824036898635123, 'MAE': 0.44899983994570497}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=3, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='ettm1_electricity_traffic', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/ettm1_electricity_traffic_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.820353259680359
Epoch #1: loss=0.29286485980927845
Epoch #2: loss=0.18650589108005342
Epoch #3: loss=0.1431150574461749
Epoch #4: loss=0.11842357018148181
Epoch #5: loss=0.08669667173616925
Epoch #6: loss=0.07751760541865449
Epoch #7: loss=0.06815211632455913
Epoch #8: loss=0.056746830659882605
Epoch #9: loss=0.052311605766261156
Epoch #10: loss=0.047349064397567905
Epoch #11: loss=0.050775454408673246
Epoch #12: loss=0.04115868154897587
Epoch #13: loss=0.03878611998194384
Epoch #14: loss=0.038498526558606035
Epoch #15: loss=0.04779322643561906
Epoch #16: loss=0.038065574964558334
Epoch #17: loss=0.026932803618622603
Epoch #18: loss=0.028761926407506924
Epoch #19: loss=0.031717994259424676
Epoch #20: loss=0.02714292103326388
Epoch #21: loss=0.031840301125518625
Epoch #22: loss=0.024882748360231587
Epoch #23: loss=0.028979186423281223
Epoch #24: loss=0.023874984321908297
Epoch #25: loss=0.025661844350142137
Epoch #26: loss=0.02207864505534062
Epoch #27: loss=0.023526868573116946
Epoch #28: loss=0.023217203687674444
Epoch #29: loss=0.024910313903463894
Epoch #30: loss=0.025885961577081756
Epoch #31: loss=0.019283871785729774
Epoch #32: loss=0.01766140436611475
Epoch #33: loss=0.021967873781585247
Epoch #34: loss=0.020512720334895075
Epoch #35: loss=0.02179291324486794
Epoch #36: loss=0.017929471974852736
Epoch #37: loss=0.019158764142249405
Epoch #38: loss=0.019198493645010205
Epoch #39: loss=0.022757460525205945
Epoch #40: loss=0.019342983175715325
Epoch #41: loss=0.01575161927469173
Epoch #42: loss=0.0168572772144425
Epoch #43: loss=0.01988971625148378
Epoch #44: loss=0.01772182659501283
Epoch #45: loss=0.020180693826033855
Epoch #46: loss=0.017415539430907945
Epoch #47: loss=0.016923997509692035
Epoch #48: loss=0.01910285778907034
Epoch #49: loss=0.020638424055170156
Epoch #50: loss=0.017376007720813626
Epoch #51: loss=0.01536440673577026
Epoch #52: loss=0.012368446124812266
Epoch #53: loss=0.01838787596526913
Epoch #54: loss=0.01766327732033311
Epoch #55: loss=0.015887838521179816
Epoch #56: loss=0.01572287781817302
Epoch #57: loss=0.016072695826437094
Epoch #58: loss=0.016605969508088052
Epoch #59: loss=0.015708814444498335
Epoch #60: loss=0.014784719851880039
Epoch #61: loss=0.012831933303858806
Epoch #62: loss=0.013574207517769074
Epoch #63: loss=0.014408471857502029
Epoch #64: loss=0.01438608482990268
Epoch #65: loss=0.020629923457510486
Epoch #66: loss=0.014963296451171981
Epoch #67: loss=0.0136457923187939
Epoch #68: loss=0.013325165430759742
Epoch #69: loss=0.010796831687302968
Epoch #70: loss=0.01364532911927871
Epoch #71: loss=0.013436253038313984
Epoch #72: loss=0.010308940795110227
Epoch #73: loss=0.014714479376722815
Epoch #74: loss=0.014608991719964482
Epoch #75: loss=0.014363316828456171
Epoch #76: loss=0.013088793286277992
Epoch #77: loss=0.014175513688031462
Epoch #78: loss=0.013225710164354662
Epoch #79: loss=0.013212065759319769
Epoch #80: loss=0.015656145298315317
Epoch #81: loss=0.013093698884407194
Epoch #82: loss=0.009492321537562956
Epoch #83: loss=0.013332860756862321
Epoch #84: loss=0.011548042266553196
Epoch #85: loss=0.0149961441100678
Epoch #86: loss=0.011993437614422557
Epoch #87: loss=0.015348822350614846
Epoch #88: loss=0.01431553296500244
Epoch #89: loss=0.01156067420945979
Epoch #90: loss=0.013732081833301374
Epoch #91: loss=0.01740217423392148
Epoch #92: loss=0.012938200681960468
Epoch #93: loss=0.011046816447255728
Epoch #94: loss=0.024667251171219325
Epoch #95: loss=0.013930180257872111
Epoch #96: loss=0.010484117249818499
Epoch #97: loss=0.009260473806834837
Epoch #98: loss=0.012733436292162168
Epoch #99: loss=0.011005769478772584
Epoch #100: loss=0.024063663853767642
Epoch #101: loss=0.012366943375572674
Epoch #102: loss=0.012395680729010013
Epoch #103: loss=0.00837779291920819
Epoch #104: loss=0.01375890474060006
Epoch #105: loss=0.013052523714608015
Epoch #106: loss=0.012391481573946565
Epoch #107: loss=0.012182182842914141
Epoch #108: loss=0.017815916585556382
Epoch #109: loss=0.010668987503928137
Epoch #110: loss=0.010033013176647213
Epoch #111: loss=0.014636893569170247
Epoch #112: loss=0.01096728672398745
Epoch #113: loss=0.013811930694650091
Epoch #114: loss=0.010255737113510435
Epoch #115: loss=0.014220793228543312
Epoch #116: loss=0.01297251359717351
Epoch #117: loss=0.009584956067482924
Epoch #118: loss=0.011789958240444147
Epoch #119: loss=0.013669640164865923
Epoch #120: loss=0.01609927502559643
Epoch #121: loss=0.009784539136875343
Epoch #122: loss=0.01335329626812354
Epoch #123: loss=0.010706504871518861
Epoch #124: loss=0.011088914804502723
Epoch #125: loss=0.01243081814696487
Epoch #126: loss=0.010697917472349078
Epoch #127: loss=0.012863872869009849
Epoch #128: loss=0.011712195085873183
Epoch #129: loss=0.010193545614106255
Epoch #130: loss=0.00950908989109923
Epoch #131: loss=0.012973903043192096
Epoch #132: loss=0.010646719475040037
Epoch #133: loss=0.012479499338853927
Epoch #134: loss=0.009642203583328348
Epoch #135: loss=0.009758056784157877
Epoch #136: loss=0.011176964408123102
Epoch #137: loss=0.011009371360968951
Epoch #138: loss=0.010722697319192643
Epoch #139: loss=0.010694338481978965
Epoch #140: loss=0.012423538151706087
Epoch #141: loss=0.011139243733774718
Epoch #142: loss=0.009575854334580499
Epoch #143: loss=0.011312308107553263
Epoch #144: loss=0.013216690926661855
Epoch #145: loss=0.012961411548655955
Epoch #146: loss=0.008833385892625792
Epoch #147: loss=0.011229133432732644
Epoch #148: loss=0.01109339197198631
Epoch #149: loss=0.008195820144873243
Epoch #150: loss=0.008933129737635203
Epoch #151: loss=0.011342015905184648
Epoch #152: loss=0.011048543301211196
Epoch #153: loss=0.010936135707317888
Epoch #154: loss=0.00965490444149733
Epoch #155: loss=0.013205698542718088
Epoch #156: loss=0.012698047606664877
Epoch #157: loss=0.00799225519751563
Epoch #158: loss=0.01126777125054298
Epoch #159: loss=0.01045008690849725
Epoch #160: loss=0.009809534031934053
Epoch #161: loss=0.008895501725538137
Epoch #162: loss=0.011540400998536622
Epoch #163: loss=0.008097573626560805
Epoch #164: loss=0.01013365590112624
Epoch #165: loss=0.009239011999622624
Epoch #166: loss=0.010808332654748638
Epoch #167: loss=0.013167027723343678
Epoch #168: loss=0.007594206905872596
Epoch #169: loss=0.009628115912549935
Epoch #170: loss=0.008122253239650507
Epoch #171: loss=0.010325016428585245
Epoch #172: loss=0.009697926362122427
Epoch #173: loss=0.009980469922934092
Epoch #174: loss=0.010892101908517983
Epoch #175: loss=0.009143145861901817
Epoch #176: loss=0.01102348911706933
Epoch #177: loss=0.008579542647350667
Epoch #178: loss=0.008292371225934785
Epoch #179: loss=0.010021484633236873
Epoch #180: loss=0.009437014018681225
Epoch #181: loss=0.009231066384831567
