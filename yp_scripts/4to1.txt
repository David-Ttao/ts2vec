Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_ettm1_ettm2', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_ettm1_ettm2_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=4.129771292209625
Epoch #1: loss=2.3326739933755665
Epoch #2: loss=2.0207322041193643
Epoch #3: loss=1.8342429366376665
Epoch #4: loss=1.63952546649509
Epoch #5: loss=1.4594121476014454
Epoch #6: loss=1.3396425909466214
Epoch #7: loss=1.211612383524577
Epoch #8: loss=1.1049360467327967
Epoch #9: loss=1.064425410495864
Epoch #10: loss=1.0339151240057416
Epoch #11: loss=0.9727871119976044
Epoch #12: loss=0.9555205255746841
Epoch #13: loss=0.927994140320354
Epoch #14: loss=0.8025840322176615
Epoch #15: loss=0.7421010235945383
Epoch #16: loss=0.7623084949122535
Epoch #17: loss=0.7571674394938681
Epoch #18: loss=0.7371437499920527
Epoch #19: loss=0.6751042753458023
Epoch #20: loss=0.6859112630287806
Epoch #21: loss=0.6277412134740088
Epoch #22: loss=0.6040665201014943
Epoch #23: loss=0.6722520680891143
Epoch #24: loss=0.5493308943178918
Epoch #25: loss=0.6237873956561089
Epoch #26: loss=0.5754076557026969
Epoch #27: loss=0.5417476205362214
Epoch #28: loss=0.5266474948989021
Epoch #29: loss=0.5356408341063393
Epoch #30: loss=0.5124572424425019
Epoch #31: loss=0.5025934047169156
Epoch #32: loss=0.4598935859070884
Epoch #33: loss=0.5123066132267317
Epoch #34: loss=0.5084722348385387
Epoch #35: loss=0.4819658233059777
Epoch #36: loss=0.4361710415946113
Epoch #37: loss=0.437722144027551
Epoch #38: loss=0.5773268524143431
Epoch #39: loss=0.4782557454374101
Epoch #40: loss=0.4276835744579633
Epoch #41: loss=0.4791038723455535
Epoch #42: loss=0.39065905660390854
Epoch #43: loss=0.39347009774711394
Epoch #44: loss=0.4333604897061984
Epoch #45: loss=0.3511960001455413
Epoch #46: loss=0.38457653630110955
Epoch #47: loss=0.34847893855637974
Epoch #48: loss=0.43922459872232544
Epoch #49: loss=0.4055454937948121
Epoch #50: loss=0.39467356395390296
Epoch #51: loss=0.3590557815300094
Epoch #52: loss=0.3929976655377282
Epoch #53: loss=0.31313323395119774
Epoch #54: loss=0.4165747869345877
Epoch #55: loss=0.34499767588244545
Epoch #56: loss=0.3046230946977933
Epoch #57: loss=0.34500983357429504
Epoch #58: loss=0.3475566746460067
Epoch #59: loss=0.2580699192153083
Epoch #60: loss=0.2871890602012475
Epoch #61: loss=0.3440406893690427
Epoch #62: loss=0.2630601239701112
Epoch #63: loss=0.30642449566059643
Epoch #64: loss=0.3464570980932977
Epoch #65: loss=0.23289883550670412
Epoch #66: loss=0.19744622086485228
Epoch #67: loss=0.320797732927733
Epoch #68: loss=0.21080121232403648
Epoch #69: loss=0.21939643658697605
Epoch #70: loss=0.20475595444440842
Epoch #71: loss=0.18241268437769678
Epoch #72: loss=0.21576396003365517
Epoch #73: loss=0.19114219418002498
Epoch #74: loss=0.29242795560922885
Epoch #75: loss=0.23548622450066936
Epoch #76: loss=0.2053494109875626
Epoch #77: loss=0.19682131997413105
Epoch #78: loss=0.4012305291576518
Epoch #79: loss=0.2741463327159484
Epoch #80: loss=0.19711296032700273
Epoch #81: loss=0.2182573920322789
Epoch #82: loss=0.1762710197104348
Epoch #83: loss=0.1830383808248573
Epoch #84: loss=0.198471509748035
Epoch #85: loss=0.20636159202290905
Epoch #86: loss=0.1889609099469251
Epoch #87: loss=0.19080844004121092
Epoch #88: loss=0.1401761962721745
Epoch #89: loss=0.16449965433114105
Epoch #90: loss=0.21792227329893243
Epoch #91: loss=0.1672577317804098
Epoch #92: loss=0.23287739335662788
Epoch #93: loss=0.22755361286302409
Epoch #94: loss=0.22745350344727436
Epoch #95: loss=0.1455041222895185
Epoch #96: loss=0.15786755799005428
Epoch #97: loss=0.1958361348758141
Epoch #98: loss=0.16705263188729683
Epoch #99: loss=0.16807812462664312
Epoch #100: loss=0.1767440134038528
Epoch #101: loss=0.12908503501158622
Epoch #102: loss=0.125193252435161
Epoch #103: loss=0.11877951729628775
Epoch #104: loss=0.14719053264707327
Epoch #105: loss=0.16553934125436676
Epoch #106: loss=0.15116051853530937
Epoch #107: loss=0.11907436357190211
Epoch #108: loss=0.10215718842421968
Epoch #109: loss=0.10999567180665003
Epoch #110: loss=0.08970432195605503
Epoch #111: loss=0.1234127717713515
Epoch #112: loss=0.12946611234090394
Epoch #113: loss=0.11820967836926381
Epoch #114: loss=0.10642369940049118
Epoch #115: loss=0.11091342283826736
Epoch #116: loss=0.12116987211629748
Epoch #117: loss=0.10244006441078252
Epoch #118: loss=0.12897917654158342
Epoch #119: loss=0.14362684544175863
Epoch #120: loss=0.1363479250835048
Epoch #121: loss=0.11415734995777409
Epoch #122: loss=0.10270232671043938
Epoch #123: loss=0.0818439560631911
Epoch #124: loss=0.08170710731711653
Epoch #125: loss=0.10717341914359066
Epoch #126: loss=0.1344851702451706
Epoch #127: loss=0.12089056190517214
Epoch #128: loss=0.09570579996539487
Epoch #129: loss=0.10587042332109478
Epoch #130: loss=0.11759052927502328
Epoch #131: loss=0.09588416665792465
Epoch #132: loss=0.12796172965317965
Epoch #133: loss=0.1019013757403526
Epoch #134: loss=0.10238459835656816
Epoch #135: loss=0.10827912100487286
Epoch #136: loss=0.0883369273506105
Epoch #137: loss=0.10345846983707613
Epoch #138: loss=0.19370455796726876
Epoch #139: loss=0.13534352209212053
Epoch #140: loss=0.11570061939871973
Epoch #141: loss=0.13272386608231398
Epoch #142: loss=0.1232329507668813
Epoch #143: loss=0.18871764647256997
Epoch #144: loss=0.0817086652904335
Epoch #145: loss=0.10325905478869875
Epoch #146: loss=0.0921909826186796
Epoch #147: loss=0.08422606552226676
Epoch #148: loss=0.08415185085808237
Epoch #149: loss=0.08199918433092535
Epoch #150: loss=0.09389975845503311
Epoch #151: loss=0.09861986318396197
Epoch #152: loss=0.09316526154159671
Epoch #153: loss=0.07481367363490993
Epoch #154: loss=0.08126653285904063
Epoch #155: loss=0.06126155065269106
Epoch #156: loss=0.12517971749831405
Epoch #157: loss=0.15632373663700289
Epoch #158: loss=0.09725514002558258
Epoch #159: loss=0.1124448684665064
Epoch #160: loss=0.07828447729763058
Epoch #161: loss=0.07660651346668601
Epoch #162: loss=0.07010387727576825
Epoch #163: loss=0.12523925974447694
Epoch #164: loss=0.07400685140035218
Epoch #165: loss=0.08637870806786749
Epoch #166: loss=0.07420349180594915
Epoch #167: loss=0.08705155810134278
Epoch #168: loss=0.0684250355956869
Epoch #169: loss=0.09398769235445394
Epoch #170: loss=0.07550404458824131
Epoch #171: loss=0.06566475111887687
Epoch #172: loss=0.10892232197026412
Epoch #173: loss=0.1087145262863487
Epoch #174: loss=0.15634142524666256
Epoch #175: loss=0.09788071113224658
Epoch #176: loss=0.07056667484963934
Epoch #177: loss=0.08081594890811378
Epoch #178: loss=0.09155707977091272
Epoch #179: loss=0.06369951460510492
Epoch #180: loss=0.06904209130961034
Epoch #181: loss=0.060060709986525275
Epoch #182: loss=0.06828731000940833
Epoch #183: loss=0.11565862958216006
Epoch #184: loss=0.10599316221972306
Epoch #185: loss=0.13492047781538632
Epoch #186: loss=0.08578641275461349
Epoch #187: loss=0.1013721528256105
Epoch #188: loss=0.11203985011929439
Epoch #189: loss=0.07413635752163827
Epoch #190: loss=0.07676920369784865
Epoch #191: loss=0.04991890945368343
Epoch #192: loss=0.05899083650567465
Epoch #193: loss=0.061330630482795336
Epoch #194: loss=0.0907684772585829
Epoch #195: loss=0.06488412370284398
Epoch #196: loss=0.0715232338083701
Epoch #197: loss=0.09833876946423617
Epoch #198: loss=0.12205265079521471
Epoch #199: loss=0.09373647021129727
Epoch #200: loss=0.06660368505658375
Epoch #201: loss=0.07253873824245399
Epoch #202: loss=0.050231862632143826
Epoch #203: loss=0.11054222363357742
Epoch #204: loss=0.055162754427227706
Epoch #205: loss=0.057031472912058234
Epoch #206: loss=0.05984452413395047
Epoch #207: loss=0.07354556049944626
Epoch #208: loss=0.07806701994397575
Epoch #209: loss=0.05127055000048131
Epoch #210: loss=0.05749723183301588
Epoch #211: loss=0.050804550125677556
Epoch #212: loss=0.05050552152614626
Epoch #213: loss=0.05213541371954812
Epoch #214: loss=0.06665741071467185
Epoch #215: loss=0.08525321754213008
Epoch #216: loss=0.06832988133343558
Epoch #217: loss=0.14163560671214429
Epoch #218: loss=0.09741749241948128
Epoch #219: loss=0.09909937564387089
Epoch #220: loss=0.053329229458338685
Epoch #221: loss=0.05468705565565162
Epoch #222: loss=0.05745039629336032
Epoch #223: loss=0.05567286621468762
Epoch #224: loss=0.049566824842865266
Epoch #225: loss=0.05912372740244286
Epoch #226: loss=0.0832495888074239
Epoch #227: loss=0.05890157660986814
Epoch #228: loss=0.07022940339003172
Epoch #229: loss=0.040635675256554454
Epoch #230: loss=0.057251746843879424
Epoch #231: loss=0.05731183409483896
Epoch #232: loss=0.0576962683763769
Epoch #233: loss=0.048947992682870894
Epoch #234: loss=0.06658216071729031
Epoch #235: loss=0.07827388769429591
Epoch #236: loss=0.06904881838191715
Epoch #237: loss=0.059401067051415644
Epoch #238: loss=0.1744269877154794
Epoch #239: loss=0.07765716518689361
Epoch #240: loss=0.06656275531794462
Epoch #241: loss=0.04749704674921102
Epoch #242: loss=0.04889106718150692
Epoch #243: loss=0.058927214148247406
Epoch #244: loss=0.04245463289165249
Epoch #245: loss=0.08051167154270741
Epoch #246: loss=0.05631751269619498
Epoch #247: loss=0.0540356998745766
Epoch #248: loss=0.04419629693600453
Epoch #249: loss=0.053422210815673075

Training time: 0:13:34.621749

Finished.
n2one setting etth1_etth2_ettm1_ettm2 -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm1_ettm2_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_etth2_ettm1_ettm2', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.62229e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.9905e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.62229e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.38114949392870306, 'MAE': 0.4356193057183713}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_ettm1_ettm2 -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm1_ettm2_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_etth2_ettm1_ettm2', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.46625e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.9171e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.7186929769113756, 'MAE': 0.7063990361654793}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_ettm1_ettm2 -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm1_ettm2_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_etth2_ettm1_ettm2', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.53896e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.21541944317386844, 'MAE': 0.315092828264689}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_ettm1_electricity', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_ettm1_electricity_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.72467991106772
Epoch #1: loss=0.7184105607643293
Epoch #2: loss=0.4991365759875733
Epoch #3: loss=0.3690010571066355
Epoch #4: loss=0.33273649874622424
Epoch #5: loss=0.30075025993447774
Epoch #6: loss=0.26627779762782805
Epoch #7: loss=0.21303074893062515
Epoch #8: loss=0.18466592291531536
Epoch #9: loss=0.18500122519457615
Epoch #10: loss=0.1547063661986865
Epoch #11: loss=0.16209421612623798
Epoch #12: loss=0.1500106845266385
Epoch #13: loss=0.14049575096696099
Epoch #14: loss=0.11981365171858685
Epoch #15: loss=0.10147089480470887
Epoch #16: loss=0.1009806750417617
Epoch #17: loss=0.10680606575801194
Epoch #18: loss=0.08298759463894574
Epoch #19: loss=0.07497124450894967
Epoch #20: loss=0.06708080030310189
Epoch #21: loss=0.07158003091499898
Epoch #22: loss=0.06980626923005188
Epoch #23: loss=0.0746013995023132
Epoch #24: loss=0.05490407036520498
Epoch #25: loss=0.05198664835390414
Epoch #26: loss=0.05571222926403875
Epoch #27: loss=0.061119774789845496
Epoch #28: loss=0.053645947066571754
Epoch #29: loss=0.047581770997009956
Epoch #30: loss=0.09837056453894243
Epoch #31: loss=0.050198858504242806
Epoch #32: loss=0.039229309887522996
Epoch #33: loss=0.03941589157296226
Epoch #34: loss=0.048668097533727056
Epoch #35: loss=0.03684939940882621
Epoch #36: loss=0.039973812333222024
Epoch #37: loss=0.03250017847678748
Epoch #38: loss=0.04403839166803727
Epoch #39: loss=0.03863109731535303
Epoch #40: loss=0.03405743734668833
Epoch #41: loss=0.033481708505040175
Epoch #42: loss=0.04243856013854804
Epoch #43: loss=0.026958200669742454
Epoch #44: loss=0.04495109725242879
Epoch #45: loss=0.036215270263468574
Epoch #46: loss=0.03688085009545798
Epoch #47: loss=0.03582720282168607
Epoch #48: loss=0.02671065769189258
Epoch #49: loss=0.03285594567598646
Epoch #50: loss=0.031998799858760155
Epoch #51: loss=0.04194903971473929
Epoch #52: loss=0.03261693666562589
Epoch #53: loss=0.029208869667928343
Epoch #54: loss=0.0299805688269361
Epoch #55: loss=0.02569759348703473
Epoch #56: loss=0.03018076414029744
Epoch #57: loss=0.03774799828416253
Epoch #58: loss=0.02541373302484459
Epoch #59: loss=0.022579812638884183
Epoch #60: loss=0.03052170565748867
Epoch #61: loss=0.02469027025094848
Epoch #62: loss=0.023864012739131215
Epoch #63: loss=0.026816592048086507
Epoch #64: loss=0.019612569339045812
Epoch #65: loss=0.021918338697573245
Epoch #66: loss=0.02058039357276052
Epoch #67: loss=0.02053816774251031
Epoch #68: loss=0.017070742242907663
Epoch #69: loss=0.02607525759874547
Epoch #70: loss=0.02164115730186553
Epoch #71: loss=0.01752566669951866
Epoch #72: loss=0.023605284340460272
Epoch #73: loss=0.021457406725852907
Epoch #74: loss=0.03222734802819767
Epoch #75: loss=0.0174000636999821
Epoch #76: loss=0.015350192650005954
Epoch #77: loss=0.06182929415442857
Epoch #78: loss=0.021252937501530577
Epoch #79: loss=0.019671673086711416
Epoch #80: loss=0.021018936370117213
Epoch #81: loss=0.02719959564274177
Epoch #82: loss=0.014045414891002451
Epoch #83: loss=0.015138179507420123
Epoch #84: loss=0.020671595021041992
Epoch #85: loss=0.028690224302787268
Epoch #86: loss=0.05564785105845153
Epoch #87: loss=0.01746561087538741
Epoch #88: loss=0.014648262551828217
Epoch #89: loss=0.017350108142184482
Epoch #90: loss=0.014425478486983157
Epoch #91: loss=0.012116818090078469
Epoch #92: loss=0.017687857364179202
Epoch #93: loss=0.02948061711453655
Epoch #94: loss=0.0233613507515304
Epoch #95: loss=0.018612503931242596
Epoch #96: loss=0.026624250359970517
Epoch #97: loss=0.013787412210138827
Epoch #98: loss=0.014736937669528423
Epoch #99: loss=0.013558364053885318
Epoch #100: loss=0.02136789524700288
Epoch #101: loss=0.02111686751276061
Epoch #102: loss=0.016467748014687027
Epoch #103: loss=0.020442157566905386
Epoch #104: loss=0.024708277223203762
Epoch #105: loss=0.01123501221441416
Epoch #106: loss=0.010515089810713507
Epoch #107: loss=0.033391336930614246
Epoch #108: loss=0.016082608690613214
Epoch #109: loss=0.014500185785710143
Epoch #110: loss=0.01120220588650043
Epoch #111: loss=0.020145591009257502
Epoch #112: loss=0.01562739829559719
Epoch #113: loss=0.01423180144249241
Epoch #114: loss=0.017046744660999237
Epoch #115: loss=0.018031152317871075
Epoch #116: loss=0.017194105420063784
Epoch #117: loss=0.018478692462465945
Epoch #118: loss=0.018699496318794775
Epoch #119: loss=0.011951505198786735
Epoch #120: loss=0.011456119962594461
Epoch #121: loss=0.01996625431512504
Epoch #122: loss=0.01722088481556635
Epoch #123: loss=0.011814971080970429
Epoch #124: loss=0.016587673433258256
Epoch #125: loss=0.015656002400499483
Epoch #126: loss=0.01571562899259118
Epoch #127: loss=0.015216515950974336
Epoch #128: loss=0.018350377432582093
Epoch #129: loss=0.020074083312512835
Epoch #130: loss=0.055296752738801365
Epoch #131: loss=0.021348699514829483
Epoch #132: loss=0.013540496206435246
Epoch #133: loss=0.012761865572760291
Epoch #134: loss=0.007378758198946359
Epoch #135: loss=0.011305833705081847
Epoch #136: loss=0.01319044978467874
Epoch #137: loss=0.013705212523120408
Epoch #138: loss=0.015440554814473753
Epoch #139: loss=0.013761281529932707
Epoch #140: loss=0.022836075831410566
Epoch #141: loss=0.015288720592268275
Epoch #142: loss=0.015102497683289579
Epoch #143: loss=0.017865313770184885
Epoch #144: loss=0.00937265004147439
Epoch #145: loss=0.0071988633475999885
Epoch #146: loss=0.016037724528601662
Epoch #147: loss=0.012949604920422486
Epoch #148: loss=0.016973444554218592
Epoch #149: loss=0.021094748128381843
Epoch #150: loss=0.015525937429629266
Epoch #151: loss=0.03451748933499098
Epoch #152: loss=0.027087698123489126
Epoch #153: loss=0.015525284488894035
Epoch #154: loss=0.011605825424739402
Epoch #155: loss=0.01216168529961347
Epoch #156: loss=0.00994738763105057
Epoch #157: loss=0.009678813139807077
Epoch #158: loss=0.017142139827244447
Epoch #159: loss=0.016033236898960964
Epoch #160: loss=0.011172584040077656
Epoch #161: loss=0.014321738392426875
Epoch #162: loss=0.012450869991228717
Epoch #163: loss=0.011967190458389494
Epoch #164: loss=0.01581907571612042
Epoch #165: loss=0.017079651008684436
Epoch #166: loss=0.007578405731114036
Epoch #167: loss=0.008170761213929937
Epoch #168: loss=0.012567826997922098
Epoch #169: loss=0.014732846244294842
Epoch #170: loss=0.011877775980924078
Epoch #171: loss=0.02017030043754931
Epoch #172: loss=0.012171734143011514
Epoch #173: loss=0.01567703135452244
Epoch #174: loss=0.011669874754182543
Epoch #175: loss=0.011581593713786378
Epoch #176: loss=0.006505475240568442
Epoch #177: loss=0.014753827090358976
Epoch #178: loss=0.012229208884265468
Epoch #179: loss=0.013724178526058626
Epoch #180: loss=0.007341248144441408
Epoch #181: loss=0.013195939312337068
Epoch #182: loss=0.011165221992491831
Epoch #183: loss=0.015247814261389499
Epoch #184: loss=0.012815367399157708
Epoch #185: loss=0.015159175553590577
Epoch #186: loss=0.015320066961350803
Epoch #187: loss=0.016321854642154972
Epoch #188: loss=0.008408880668320165
Epoch #189: loss=0.00773625754466283
Epoch #190: loss=0.01161914540039553
Epoch #191: loss=0.01266141051969577
Epoch #192: loss=0.017583745493886003
Epoch #193: loss=0.009004259367713657
Epoch #194: loss=0.014918684211460002
Epoch #195: loss=0.014965938070181333
Epoch #196: loss=0.011113763705092466
Epoch #197: loss=0.01770171320158046
Epoch #198: loss=0.017695474178621794
Epoch #199: loss=0.013283317662187384
Epoch #200: loss=0.008528687013615989
Epoch #201: loss=0.011181686179064055
Epoch #202: loss=0.00896494297513932
Epoch #203: loss=0.01355373896449815
Epoch #204: loss=0.00960850783299407
Epoch #205: loss=0.016158275680873555
Epoch #206: loss=0.010288303580694977
Epoch #207: loss=0.012551045064939552
Epoch #208: loss=0.01085058492901089
Epoch #209: loss=0.01420967888756254
Epoch #210: loss=0.011620432997426567
Epoch #211: loss=0.013800738156790646
Epoch #212: loss=0.008890402130681666
Epoch #213: loss=0.007995486303452655
Epoch #214: loss=0.011174964358171481
Epoch #215: loss=0.009418502927426723
Epoch #216: loss=0.009918889636527128
Epoch #217: loss=0.006651827710969347
Epoch #218: loss=0.014044261953357413
Epoch #219: loss=0.012700963400407274
Epoch #220: loss=0.008911234795770641
Epoch #221: loss=0.018720549072685378
Epoch #222: loss=0.016864472303022713
Epoch #223: loss=0.008976440006635566
Epoch #224: loss=0.01048579725932809
Epoch #225: loss=0.00842890814052709
Epoch #226: loss=0.013391969759135662
Epoch #227: loss=0.013236659789603268
Epoch #228: loss=0.010880050341251462
Epoch #229: loss=0.014306009884195597
Epoch #230: loss=0.009251274483166016
Epoch #231: loss=0.009451886686944602
Epoch #232: loss=0.009402994933535446
Epoch #233: loss=0.009873150690977536
Epoch #234: loss=0.031459185005619186
Epoch #235: loss=0.009958690949428
Epoch #236: loss=0.008813898148239897
Epoch #237: loss=0.011361138594778917
Epoch #238: loss=0.01307672353961365
Epoch #239: loss=0.010459206185627977
Epoch #240: loss=0.011578275292850708
Epoch #241: loss=0.013827506649964677
Epoch #242: loss=0.008914077798149555
Epoch #243: loss=0.005769480068468411
Epoch #244: loss=0.00715352874127253
Epoch #245: loss=0.013898659196367347
Epoch #246: loss=0.010967285814257662
Epoch #247: loss=0.01035739177297276
Epoch #248: loss=0.009289965262240192
Epoch #249: loss=0.008833987916438878

Training time: 1:40:53.422061

Finished.
n2one setting etth1_etth2_ettm1_electricity -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm1_electricity_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_etth2_ettm1_electricity', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.43567e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.80341e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.43567e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3990681190869328, 'MAE': 0.4632732073817217}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_ettm1_electricity -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm1_electricity_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_etth2_ettm1_electricity', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.24605e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.24605e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.17899464620436406, 'MAE': 0.29173943313796036}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_ettm1_traffic', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_ettm1_traffic_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.0239445475069753
Epoch #1: loss=0.37148620255434256
Epoch #2: loss=0.2720797689549684
Epoch #3: loss=0.214112682114728
Epoch #4: loss=0.17531203671769063
Epoch #5: loss=0.1390905310279084
Epoch #6: loss=0.10830918537177725
Epoch #7: loss=0.09756688112361522
Epoch #8: loss=0.08556016261784911
Epoch #9: loss=0.07611738435457867
Epoch #10: loss=0.07410044542050752
Epoch #11: loss=0.06399589069838622
Epoch #12: loss=0.06156652710288175
Epoch #13: loss=0.056730451397786784
Epoch #14: loss=0.05645244413610913
Epoch #15: loss=0.05405110122085777
Epoch #16: loss=0.04098925288643776
Epoch #17: loss=0.0467124611938324
Epoch #18: loss=0.04159854145814049
Epoch #19: loss=0.035124648734612185
Epoch #20: loss=0.034498681846886384
Epoch #21: loss=0.047585234523980786
Epoch #22: loss=0.03816877825793589
Epoch #23: loss=0.03286529987448829
Epoch #24: loss=0.034171779770215106
Epoch #25: loss=0.03280191582991409
Epoch #26: loss=0.05818660737812233
Epoch #27: loss=0.028411774449060925
Epoch #28: loss=0.029464107072280074
Epoch #29: loss=0.030829676114581317
Epoch #30: loss=0.026967311321428045
Epoch #31: loss=0.030083296354991313
Epoch #32: loss=0.0263350758439612
Epoch #33: loss=0.029420606648258595
Epoch #34: loss=0.0294927220581322
Epoch #35: loss=0.023064978831731676
Epoch #36: loss=0.025078387682999692
Epoch #37: loss=0.02356822043722926
Epoch #38: loss=0.0243422908612906
Epoch #39: loss=0.018377085063901018
Epoch #40: loss=0.02150146439388025
Epoch #41: loss=0.028753997058948353
Epoch #42: loss=0.02396788881666929
Epoch #43: loss=0.028272854690474122
Epoch #44: loss=0.022808300472144064
Epoch #45: loss=0.018541923056597052
Epoch #46: loss=0.023779795522496563
Epoch #47: loss=0.022100455796683634
Epoch #48: loss=0.022058219008482132
Epoch #49: loss=0.023401109262064033
Epoch #50: loss=0.028964495594970767
Epoch #51: loss=0.020336949747116667
Epoch #52: loss=0.019780061892029046
Epoch #53: loss=0.018106596101232383
Epoch #54: loss=0.019279320817952608
Epoch #55: loss=0.019681731147679533
Epoch #56: loss=0.022938670969427498
Epoch #57: loss=0.019357249755430714
Epoch #58: loss=0.015024287526629888
Epoch #59: loss=0.021796788783925623
Epoch #60: loss=0.020984819266861653
Epoch #61: loss=0.021290400689163297
Epoch #62: loss=0.018118910732237557
Epoch #63: loss=0.018681956407666025
Epoch #64: loss=0.019016909474922235
Epoch #65: loss=0.018171002436980496
Epoch #66: loss=0.015877262587260597
Epoch #67: loss=0.018369883541154267
Epoch #68: loss=0.01999453749588251
Epoch #69: loss=0.015338630900388056
Epoch #70: loss=0.026576549652255147
Epoch #71: loss=0.019185362046026954
Epoch #72: loss=0.02030666375909685
Epoch #73: loss=0.018469482468903904
Epoch #74: loss=0.01440938063255399
Epoch #75: loss=0.017149100817538895
Epoch #76: loss=0.020549542782985708
Epoch #77: loss=0.015142723872024973
Epoch #78: loss=0.018396093320634944
Epoch #79: loss=0.013100392991330962
Epoch #80: loss=0.02199129449743557
Epoch #81: loss=0.01848711312873569
Epoch #82: loss=0.02174475708130638
Epoch #83: loss=0.026151001955875487
Epoch #84: loss=0.01617179583229719
Epoch #85: loss=0.014298820974706361
Epoch #86: loss=0.01425440106008059
Epoch #87: loss=0.013860180303338902
Epoch #88: loss=0.0194847737698516
Epoch #89: loss=0.016811632057833
Epoch #90: loss=0.01472909304834015
Epoch #91: loss=0.012970442849579147
Epoch #92: loss=0.013787356688713328
Epoch #93: loss=0.016736061955298684
Epoch #94: loss=0.015012723622894021
Epoch #95: loss=0.01852536692357283
Epoch #96: loss=0.011837334497115158
Epoch #97: loss=0.012313545145789475
Epoch #98: loss=0.02316796856424682
Epoch #99: loss=0.015119209587340386
Epoch #100: loss=0.011113618474708042
Epoch #101: loss=0.01306572972723097
Epoch #102: loss=0.015133288606075757
Epoch #103: loss=0.011567245406180562
Epoch #104: loss=0.015124836502562087
Epoch #105: loss=0.023145047609772786
Epoch #106: loss=0.014183058454027755
Epoch #107: loss=0.010702719545723417
Epoch #108: loss=0.01585796923747259
Epoch #109: loss=0.01441439696296387
Epoch #110: loss=0.018810473954410836
Epoch #111: loss=0.020794180129064622
Epoch #112: loss=0.017733113882778918
Epoch #113: loss=0.014022434352592747
Epoch #114: loss=0.014596271347921245
Epoch #115: loss=0.013144295042536348
Epoch #116: loss=0.01600179828189181
Epoch #117: loss=0.012468779729962718
Epoch #118: loss=0.015699367862721206
Epoch #119: loss=0.013620836221313224
Epoch #120: loss=0.01457295620955974
Epoch #121: loss=0.013643499188589876
Epoch #122: loss=0.02044848918987899
Epoch #123: loss=0.011348278442315816
Epoch #124: loss=0.018683873095445697
Epoch #125: loss=0.018977951595411803
Epoch #126: loss=0.012390491261645436
Epoch #127: loss=0.008963630330489514
Epoch #128: loss=0.014266978551911504
Epoch #129: loss=0.012892302583314828
Epoch #130: loss=0.019431595180033765
Epoch #131: loss=0.013359350219150804
Epoch #132: loss=0.011326165247327519
Epoch #133: loss=0.027187267683757198
Epoch #134: loss=0.010440267987630415
Epoch #135: loss=0.010068605212528068
Epoch #136: loss=0.01325797233452969
Epoch #137: loss=0.010621745474399
Epoch #138: loss=0.018209986210188576
Epoch #139: loss=0.012528615607624126
Epoch #140: loss=0.009792387687934908
Epoch #141: loss=0.012318542623020165
Epoch #142: loss=0.01837257251282314
Epoch #143: loss=0.017016877232039644
Epoch #144: loss=0.01564041899391904
Epoch #145: loss=0.01220471607286902
Epoch #146: loss=0.011517590598957645
Epoch #147: loss=0.012052148384141306
Epoch #148: loss=0.015097314699893144
Epoch #149: loss=0.014082486517699814
Epoch #150: loss=0.015440579623635176
Epoch #151: loss=0.009081260896177086
Epoch #152: loss=0.010361375602854946
Epoch #153: loss=0.01623595725862297
Epoch #154: loss=0.011610561475843368
Epoch #155: loss=0.01443398849845847
Epoch #156: loss=0.011608124610340225
Epoch #157: loss=0.012379685573230246
Epoch #158: loss=0.015753996561112336
Epoch #159: loss=0.008935070785252443
Epoch #160: loss=0.017050332128559317
Epoch #161: loss=0.01658158694172652
Epoch #162: loss=0.011465245569076913
Epoch #163: loss=0.014304355196951413
Epoch #164: loss=0.015691337964030008
Epoch #165: loss=0.012089455401416755
Epoch #166: loss=0.01695851218686392
Epoch #167: loss=0.010904043077473112
Epoch #168: loss=0.011784713578162654
Epoch #169: loss=0.014986091937616219
Epoch #170: loss=0.010608733963920066
Epoch #171: loss=0.010862746729072274
Epoch #172: loss=0.013751794785131746
Epoch #173: loss=0.013196372439662334
Epoch #174: loss=0.016704338809499977
Epoch #175: loss=0.01430189079952714
Epoch #176: loss=0.012447242528788658
Epoch #177: loss=0.011330344634721993
Epoch #178: loss=0.014452526914472918
Epoch #179: loss=0.012926858213361748
Epoch #180: loss=0.0149564214965621
Epoch #181: loss=0.010683119182777827
Epoch #182: loss=0.009372628624901425
Epoch #183: loss=0.011514651231794395
Epoch #184: loss=0.008358206738366245
Epoch #185: loss=0.014925726168416755
Epoch #186: loss=0.012064477296793106
Epoch #187: loss=0.006504350595981809
Epoch #188: loss=0.015049425081067467
Epoch #189: loss=0.010579310929902231
Epoch #190: loss=0.013021147372905877
Epoch #191: loss=0.011738883798523033
Epoch #192: loss=0.010099617680405444
Epoch #193: loss=0.00974473224983266
Epoch #194: loss=0.010494988524897567
Epoch #195: loss=0.011424583774059027
Epoch #196: loss=0.014546226723008844
Epoch #197: loss=0.013727525975111569
Epoch #198: loss=0.009590550086844509
Epoch #199: loss=0.008735516785260636
Epoch #200: loss=0.010538832083112942
Epoch #201: loss=0.010525985426310683
Epoch #202: loss=0.010110716232742532
Epoch #203: loss=0.014627644537220706
Epoch #204: loss=0.006690855455389793
Epoch #205: loss=0.01544152360947468
Epoch #206: loss=0.011469869880914465
Epoch #207: loss=0.01804933208812118
Epoch #208: loss=0.013425138946060877
Epoch #209: loss=0.011225813303708195
Epoch #210: loss=0.007989181618694701
Epoch #211: loss=0.01126708678616129
Epoch #212: loss=0.008740560761471767
Epoch #213: loss=0.009659164504358322
Epoch #214: loss=0.00949978934030816
Epoch #215: loss=0.011337295471050902
Epoch #216: loss=0.010956945956106903
Epoch #217: loss=0.010135874479671349
Epoch #218: loss=0.0088150092237734
Epoch #219: loss=0.013526107680994603
Epoch #220: loss=0.012299985294634521
Epoch #221: loss=0.007284277548147008
Epoch #222: loss=0.009943548447411537
Epoch #223: loss=0.009692650864940512
Epoch #224: loss=0.008214442925047987
Epoch #225: loss=0.01403456629325978
Epoch #226: loss=0.01164403525682803
Epoch #227: loss=0.008676663088068111
Epoch #228: loss=0.009525146426481017
Epoch #229: loss=0.009836902653210085
Epoch #230: loss=0.017197389092923458
Epoch #231: loss=0.012561971458804997
Epoch #232: loss=0.009020243769799272
Epoch #233: loss=0.007474457103272258
Epoch #234: loss=0.011860383429892388
Epoch #235: loss=0.00904601917456373
Epoch #236: loss=0.010677135685030129
Epoch #237: loss=0.01078936659141085
Epoch #238: loss=0.010652819742215781
Epoch #239: loss=0.012708297333044993
Epoch #240: loss=0.009466226786521254
Epoch #241: loss=0.008613378781877934
Epoch #242: loss=0.013802387174557836
Epoch #243: loss=0.01008985231162546
Epoch #244: loss=0.011700701572318202
Epoch #245: loss=0.012647164772246153
Epoch #246: loss=0.007392976084416165
Epoch #247: loss=0.011142062448404688
Epoch #248: loss=0.008282983641015741
Epoch #249: loss=0.021047730950853633

Training time: 3:30:48.794635

Finished.
n2one setting etth1_etth2_ettm1_traffic -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm1_traffic_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_etth2_ettm1_traffic', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.97689e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.14566e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.52576e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.97689e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4235296144251113, 'MAE': 0.46329621041185814}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_ettm1_traffic -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm1_traffic_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_etth2_ettm1_traffic', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.64541e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.55047e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.7703786903014924, 'MAE': 0.7095599240356432}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_ettm1_traffic -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm1_traffic_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_etth2_ettm1_traffic', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.96625e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.33400684424629873, 'MAE': 0.3853334221876329}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_ettm1_weather', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_ettm1_weather_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=4.103881270277734
Epoch #1: loss=2.3466300917606726
Epoch #2: loss=2.476237224597557
Epoch #3: loss=2.0423741200390984
Epoch #4: loss=1.9034759460711013
Epoch #5: loss=1.6645828976350672
Epoch #6: loss=1.4989006355697034
Epoch #7: loss=1.4503534307666854
Epoch #8: loss=1.3123237630900215
Epoch #9: loss=1.214062767870286
Epoch #10: loss=1.1769006824960895
Epoch #11: loss=1.0600714169296563
Epoch #12: loss=0.9752648157231948
Epoch #13: loss=0.9808305057824827
Epoch #14: loss=0.881934667334837
Epoch #15: loss=0.8379006280618555
Epoch #16: loss=0.8813619777268055
Epoch #17: loss=0.783322274684906
Epoch #18: loss=0.8024656831049451
Epoch #19: loss=0.7315782518947825
Epoch #20: loss=0.7416878903613371
Epoch #21: loss=0.7898314782217437
Epoch #22: loss=0.7492812959586873
Epoch #23: loss=0.7471270976113338
Epoch #24: loss=0.7293742217269599
Epoch #25: loss=0.7894786210621104
Epoch #26: loss=0.7392491791762558
Epoch #27: loss=0.6648394810218438
Epoch #28: loss=0.6428606562754687
Epoch #29: loss=0.5723441938559214
Epoch #30: loss=0.6215856256438237
Epoch #31: loss=0.5674516126221302
Epoch #32: loss=0.5356314334214902
Epoch #33: loss=0.5454286009657616
Epoch #34: loss=0.5075316423294591
Epoch #35: loss=0.525444966320898
Epoch #36: loss=0.49914776519233106
Epoch #37: loss=0.46519041236709147
Epoch #38: loss=0.5017777991061118
Epoch #39: loss=0.43843645850817364
Epoch #40: loss=0.43525387434398427
Epoch #41: loss=0.40214527296084984
Epoch #42: loss=0.40072698715855093
Epoch #43: loss=0.43447039349406374
Epoch #44: loss=0.4313482884682861
Epoch #45: loss=0.42172835825705063
Epoch #46: loss=0.39469621052929
Epoch #47: loss=0.4325538067256703
Epoch #48: loss=0.4011763103452383
Epoch #49: loss=0.3693877508242925
Epoch #50: loss=0.3592500385700488
Epoch #51: loss=0.3547682724162644
Epoch #52: loss=0.33463528226403627
Epoch #53: loss=0.34907711224228727
Epoch #54: loss=0.37247369248493045
Epoch #55: loss=0.30588415118993495
Epoch #56: loss=0.33013010317204045
Epoch #57: loss=0.4404440720876058
Epoch #58: loss=0.3481796264064078
Epoch #59: loss=0.3792469825814752
Epoch #60: loss=0.4892287806552999
Epoch #61: loss=0.4631282368711397
Epoch #62: loss=0.4102800397896299
Epoch #63: loss=0.2969271488049451
Epoch #64: loss=0.26925375020387127
Epoch #65: loss=0.2701035404906553
Epoch #66: loss=0.2627122536593792
Epoch #67: loss=0.26907476958106546
Epoch #68: loss=0.26418964959242763
Epoch #69: loss=0.23081151293773278
Epoch #70: loss=0.25252199567416134
Epoch #71: loss=0.2618313763363689
Epoch #72: loss=0.23059402698395298
Epoch #73: loss=0.2714668905325964
Epoch #74: loss=0.297392290158599
Epoch #75: loss=0.2699025845995136
Epoch #76: loss=0.30512571875371186
Epoch #77: loss=0.23112337627247267
Epoch #78: loss=0.24888155638587242
Epoch #79: loss=0.19671173371812878
Epoch #80: loss=0.25775491884526086
Epoch #81: loss=0.21787569540388443
Epoch #82: loss=0.24555166577007256
Epoch #83: loss=0.2075741539398829
Epoch #84: loss=0.1730993324342896
Epoch #85: loss=0.15370949554969282
Epoch #86: loss=0.21416200989601658
Epoch #87: loss=0.18382308763616226
Epoch #88: loss=0.18687208354765295
Epoch #89: loss=0.19236096973512687
Epoch #90: loss=0.19325385914713727
Epoch #91: loss=0.1423464535059882
Epoch #92: loss=0.23649091258937238
Epoch #93: loss=0.34197256158964306
Epoch #94: loss=0.2269171816753406
Epoch #95: loss=0.1754589061818871
Epoch #96: loss=0.1507698144836753
Epoch #97: loss=0.1749298720821446
Epoch #98: loss=0.15483607936139201
Epoch #99: loss=0.17056683352326646
Epoch #100: loss=0.13113549139861966
Epoch #101: loss=0.13141531694461317
Epoch #102: loss=0.13692360853447633
Epoch #103: loss=0.14448801990525395
Epoch #104: loss=0.13670946014862434
Epoch #105: loss=0.17688361095154986
Epoch #106: loss=0.18005727786643833
Epoch #107: loss=0.15702984493006678
Epoch #108: loss=0.14589282417414234
Epoch #109: loss=0.15024323841812565
Epoch #110: loss=0.11676184865919982
Epoch #111: loss=0.11609552691088003
Epoch #112: loss=0.14912201394783517
Epoch #113: loss=0.1419633058283259
Epoch #114: loss=0.12172830543097328
Epoch #115: loss=0.12108014363284204
Epoch #116: loss=0.12345487843541537
Epoch #117: loss=0.1767477534492226
Epoch #118: loss=0.15398886624504537
Epoch #119: loss=0.11309697409616966
Epoch #120: loss=0.19001548182146222
Epoch #121: loss=0.17157537979530355
Epoch #122: loss=0.14008564998706183
Epoch #123: loss=0.15348053866011255
Epoch #124: loss=0.11936384370075721
Epoch #125: loss=0.10361899778831239
Epoch #126: loss=0.1293666473790711
Epoch #127: loss=0.2058318602834262
Epoch #128: loss=0.1762588339693406
Epoch #129: loss=0.22147814111382352
Epoch #130: loss=0.1218353915667417
Epoch #131: loss=0.08749387789444596
Epoch #132: loss=0.16405235946762795
Epoch #133: loss=0.1128133027357798
Epoch #134: loss=0.09355363750136365
Epoch #135: loss=0.10801449465547122
Epoch #136: loss=0.09924234858914918
Epoch #137: loss=0.09848136589953713
Epoch #138: loss=0.10338585082368523
Epoch #139: loss=0.10938310005939474
Epoch #140: loss=0.11052807719976294
Epoch #141: loss=0.13395872124123806
Epoch #142: loss=0.11924582197531766
Epoch #143: loss=0.12235717782202889
Epoch #144: loss=0.11184871877890591
Epoch #145: loss=0.09874669236003183
Epoch #146: loss=0.12689143196478778
Epoch #147: loss=0.11683533957921992
Epoch #148: loss=0.08949976275656737
Epoch #149: loss=0.08286952831800662
Epoch #150: loss=0.10746102181135439
Epoch #151: loss=0.13913363287700156
Epoch #152: loss=0.1350361801610858
Epoch #153: loss=0.2583397957039814
Epoch #154: loss=0.22427471971833238
Epoch #155: loss=0.1306217942825135
Epoch #156: loss=0.0930538464556722
Epoch #157: loss=0.15113343773227111
Epoch #158: loss=0.12474470636716076
Epoch #159: loss=0.10829951511878594
Epoch #160: loss=0.08089180330873705
Epoch #161: loss=0.09239774526042097
Epoch #162: loss=0.07603205590709752
Epoch #163: loss=0.08065929519487362
Epoch #164: loss=0.1084761866094435
Epoch #165: loss=0.09344188801432941
Epoch #166: loss=0.08772890076187312
Epoch #167: loss=0.0726883998323305
Epoch #168: loss=0.11025727310163133
Epoch #169: loss=0.0681507210521137
Epoch #170: loss=0.1028989017484527
Epoch #171: loss=0.07846786028833366
Epoch #172: loss=0.06343363727643794
Epoch #173: loss=0.05974951532541537
Epoch #174: loss=0.06571434536839232
Epoch #175: loss=0.07144386781489148
Epoch #176: loss=0.08211535472861108
Epoch #177: loss=0.10847778461289172
Epoch #178: loss=0.09923146161086419
Epoch #179: loss=0.09892306319784884
Epoch #180: loss=0.1573337620379878
Epoch #181: loss=0.1610280321728365
Epoch #182: loss=0.14573734103902883
Epoch #183: loss=0.11740674692041733
Epoch #184: loss=0.07846558605339013
Epoch #185: loss=0.10350377284282562
Epoch #186: loss=0.10930903759949348
Epoch #187: loss=0.11181674948802181
Epoch #188: loss=0.08906725067280087
Epoch #189: loss=0.09628329029781561
Epoch #190: loss=0.07711356166092788
Epoch #191: loss=0.1255363842070687
Epoch #192: loss=0.08546083993917587
Epoch #193: loss=0.06632015662377372
Epoch #194: loss=0.0806947918791397
Epoch #195: loss=0.05496453554095591
Epoch #196: loss=0.05544978186634241
Epoch #197: loss=0.05639239858982025
Epoch #198: loss=0.0629692771563343
Epoch #199: loss=0.09684918652854714
Epoch #200: loss=0.08470816073902682
Epoch #201: loss=0.0721363888176925
Epoch #202: loss=0.0530373410632213
Epoch #203: loss=0.1034169596455553
Epoch #204: loss=0.0962711156838957
Epoch #205: loss=0.11758420974308369
Epoch #206: loss=0.07380783185362816
Epoch #207: loss=0.06742934442545269
Epoch #208: loss=0.06295309411179201
Epoch #209: loss=0.06386623246704831
Epoch #210: loss=0.06500884307110134
Epoch #211: loss=0.052223296233398074
Epoch #212: loss=0.05518305420364235
Epoch #213: loss=0.05426320979627324
Epoch #214: loss=0.04249143989428001
Epoch #215: loss=0.11077581389861949
Epoch #216: loss=0.0694702298508263
Epoch #217: loss=0.09598159696906805
Epoch #218: loss=0.08521736572113107
Epoch #219: loss=0.06071569200824289
Epoch #220: loss=0.07297203647812792
Epoch #221: loss=0.05355255217200108
Epoch #222: loss=0.06504322115477978
Epoch #223: loss=0.06892893317283369
Epoch #224: loss=0.07526069395609346
Epoch #225: loss=0.08699203923563747
Epoch #226: loss=0.08358377939564925
Epoch #227: loss=0.04349955563963044
Epoch #228: loss=0.04398130215521829
Epoch #229: loss=0.050068199479331575
Epoch #230: loss=0.05332097741683908
Epoch #231: loss=0.04615162311158344
Epoch #232: loss=0.057906862092660924
Epoch #233: loss=0.14116772483376896
Epoch #234: loss=0.055014304561065694
Epoch #235: loss=0.06731021773143142
Epoch #236: loss=0.05670272925978198
Epoch #237: loss=0.09111105720056038
Epoch #238: loss=0.09710797893942572
Epoch #239: loss=0.0643959750476129
Epoch #240: loss=0.08690118464623012
Epoch #241: loss=0.0871660213040955
Epoch #242: loss=0.1978010755287958
Epoch #243: loss=0.13077581527770735
Epoch #244: loss=0.1310492486272957
Epoch #245: loss=0.14831513838440763
Epoch #246: loss=0.07215479345006101
Epoch #247: loss=0.06658506369693022
Epoch #248: loss=0.05104585537942601
Epoch #249: loss=0.04839467239000049

Training time: 0:16:20.296188

Finished.
n2one setting etth1_etth2_ettm1_weather -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm1_weather_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_etth2_ettm1_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.50119e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.82743e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.50119e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.36766864215793327, 'MAE': 0.4307941177738909}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_ettm1_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm1_weather_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_etth2_ettm1_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.27838e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.18787079957082273, 'MAE': 0.29761601433796875}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_ettm1_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_ettm1_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=4.005073157223788
Epoch #1: loss=2.241326017813249
Epoch #2: loss=2.0479758327657525
Epoch #3: loss=1.916576584180196
Epoch #4: loss=1.7945684483557036
Epoch #5: loss=1.6094739075863
Epoch #6: loss=1.5192166277856538
Epoch #7: loss=1.4265935529362073
Epoch #8: loss=1.2869648536046345
Epoch #9: loss=1.2439513152295893
Epoch #10: loss=1.2346450541958665
Epoch #11: loss=1.1482308814019868
Epoch #12: loss=1.172627492384477
Epoch #13: loss=1.120371932333166
Epoch #14: loss=1.04448053150466
Epoch #15: loss=1.0057816433184075
Epoch #16: loss=1.022448176687414
Epoch #17: loss=0.9682911363514987
Epoch #18: loss=0.8992476761341095
Epoch #19: loss=0.9147352305325595
Epoch #20: loss=0.8141313827399052
Epoch #21: loss=0.8549324147629015
Epoch #22: loss=0.8302756015098456
Epoch #23: loss=0.8169152772787845
Epoch #24: loss=0.7582263305331721
Epoch #25: loss=0.7629234438592737
Epoch #26: loss=0.922595663504167
Epoch #27: loss=0.7250766149072936
Epoch #28: loss=0.6741017997264862
Epoch #29: loss=0.7027965431863611
Epoch #30: loss=0.729511536432035
Epoch #31: loss=0.6645609068148064
Epoch #32: loss=0.7333079838391506
Epoch #33: loss=0.7167931271321846
Epoch #34: loss=0.6581330985733957
Epoch #35: loss=0.6828926160480037
Epoch #36: loss=0.7205656649488391
Epoch #37: loss=0.689924932790525
Epoch #38: loss=0.6223056442809828
Epoch #39: loss=0.5354434531746488
Epoch #40: loss=0.5554259446534243
Epoch #41: loss=0.4975471045031692
Epoch #42: loss=0.5843456802946149
Epoch #43: loss=0.5884657249306188
Epoch #44: loss=0.6117494639122125
Epoch #45: loss=0.5933133833336107
Epoch #46: loss=0.5208505915872979
Epoch #47: loss=0.49498987107565906
Epoch #48: loss=0.5039440294106802
Epoch #49: loss=0.49383703867594403
Epoch #50: loss=0.5201195189447114
Epoch #51: loss=0.5807085335254669
Epoch #52: loss=0.6278055256063287
Epoch #53: loss=0.5088430606957638
Epoch #54: loss=0.48138069880731177
Epoch #55: loss=0.4309209774840962
Epoch #56: loss=0.46094329248775134
Epoch #57: loss=0.5268162263162208
Epoch #58: loss=0.49663544062412146
Epoch #59: loss=0.4105972196116592
Epoch #60: loss=0.43518293671535724
Epoch #61: loss=0.4361524220668908
Epoch #62: loss=0.422020749612288
Epoch #63: loss=0.400274169715968
Epoch #64: loss=0.44173199660850293
Epoch #65: loss=0.5190674784508619
Epoch #66: loss=0.5414095259074009
Epoch #67: loss=0.5099236784559308
Epoch #68: loss=0.44795175619197614
Epoch #69: loss=0.45817054040504224
Epoch #70: loss=0.3602846206137628
Epoch #71: loss=0.39467030176610657
Epoch #72: loss=0.36240707066926087
Epoch #73: loss=0.35698443967284577
Epoch #74: loss=0.49150327796285803
Epoch #75: loss=0.44164566695690155
Epoch #76: loss=0.3535134345293045
Epoch #77: loss=0.3594643360737598
Epoch #78: loss=0.3807936906814575
Epoch #79: loss=0.35322830171296093
Epoch #80: loss=0.3576147009929021
Epoch #81: loss=0.3476826458266287
Epoch #82: loss=0.34162385219877417
Epoch #83: loss=0.4169795142881798
Epoch #84: loss=0.3399522697383707
Epoch #85: loss=0.3906461564880429
Epoch #86: loss=0.3417706855318763
Epoch #87: loss=0.34728314434037066
Epoch #88: loss=0.3251808294744203
Epoch #89: loss=0.4288579076528549
Epoch #90: loss=0.43668502524043573
Epoch #91: loss=0.37285152077674866
Epoch #92: loss=0.3973791201909383
Epoch #93: loss=0.3863294440688509
Epoch #94: loss=0.3681378626462185
Epoch #95: loss=0.40510220554741944
Epoch #96: loss=0.3994155377149582
Epoch #97: loss=0.3133181356119387
Epoch #98: loss=0.30978730050000275
Epoch #99: loss=0.3568486842242154
Epoch #100: loss=0.2694490034923409
Epoch #101: loss=0.3192275356162678
Epoch #102: loss=0.4643856914657535
Epoch #103: loss=0.32834002962618164
Epoch #104: loss=0.29635592753236945
Epoch #105: loss=0.29249568870573334
Epoch #106: loss=0.3152489689263431
Epoch #107: loss=0.2746804555257161
Epoch #108: loss=0.24764758664550204
Epoch #109: loss=0.29052615120555414
Epoch #110: loss=0.36679132598819153
Epoch #111: loss=0.29477200589396735
Epoch #112: loss=0.2912459314772577
Epoch #113: loss=0.2603632825793642
Epoch #114: loss=0.2686271690057986
Epoch #115: loss=0.22601791764750626
Epoch #116: loss=0.24586932203083328
Epoch #117: loss=0.26607254960320215
Epoch #118: loss=0.27088158148707764
Epoch #119: loss=0.25352640653198416
Epoch #120: loss=0.3117095171050592
Epoch #121: loss=0.2811543173862226
Epoch #122: loss=0.23852624947374518
Epoch #123: loss=0.2580733003489899
Epoch #124: loss=0.23594235380490622
Epoch #125: loss=0.24066458213509936
Epoch #126: loss=0.2043006153720798
Epoch #127: loss=0.21271797608245502
Epoch #128: loss=0.2114293324676427
Epoch #129: loss=0.16564787698514533
Epoch #130: loss=0.17133361055995477
Epoch #131: loss=0.26403864360216894
Epoch #132: loss=0.27607691897587344
Epoch #133: loss=0.1977023956450549
Epoch #134: loss=0.18425542093587643
Epoch #135: loss=0.17298384642962253
Epoch #136: loss=0.1903733450806502
Epoch #137: loss=0.3058543713255362
Epoch #138: loss=0.22249189086935736
Epoch #139: loss=0.18679013125824206
Epoch #140: loss=0.21566643182075385
Epoch #141: loss=0.17424810203638944
Epoch #142: loss=0.2293268884673263
Epoch #143: loss=0.21043905796426715
Epoch #144: loss=0.14456983429915976
Epoch #145: loss=0.1745251055919763
Epoch #146: loss=0.20159757046988516
Epoch #147: loss=0.19279089095917615
Epoch #148: loss=0.1774701223228917
Epoch #149: loss=0.18337435049541068
Epoch #150: loss=0.18774098394946617
Epoch #151: loss=0.20855958895249802
Epoch #152: loss=0.2196924654823361
Epoch #153: loss=0.17000073533166538
Epoch #154: loss=0.20297601288466743
Epoch #155: loss=0.15055950731039047
Epoch #156: loss=0.17921406425761455
Epoch #157: loss=0.16490083594213834
Epoch #158: loss=0.170212110786727
Epoch #159: loss=0.1405485486893943
Epoch #160: loss=0.17334163211511844
Epoch #161: loss=0.13594036504174722
Epoch #162: loss=0.15017086719021652
Epoch #163: loss=0.17315143222610155
Epoch #164: loss=0.20910666837836756
Epoch #165: loss=0.20525965771891855
Epoch #166: loss=0.26782910932194104
Epoch #167: loss=0.1810201582583514
Epoch #168: loss=0.1378830038011074
Epoch #169: loss=0.14646288808999638
Epoch #170: loss=0.1584160321138122
Epoch #171: loss=0.17453709346326915
Epoch #172: loss=0.2037755474448204
Epoch #173: loss=0.15601029935659785
Epoch #174: loss=0.1947744573381814
Epoch #175: loss=0.1847888520269683
Epoch #176: loss=0.15719765119931914
Epoch #177: loss=0.16027409109202298
Epoch #178: loss=0.17163004714882735
Epoch #179: loss=0.1222637164773363
Epoch #180: loss=0.15042791910695308
Epoch #181: loss=0.2213974493471059
Epoch #182: loss=0.19043338005289887
Epoch #183: loss=0.14764885943044315
Epoch #184: loss=0.17021919335379745
Epoch #185: loss=0.14266794682903725
Epoch #186: loss=0.11153250526298177
Epoch #187: loss=0.24052756923166188
Epoch #188: loss=0.13112645663998343
Epoch #189: loss=0.15182639647162322
Epoch #190: loss=0.1317800937051123
Epoch #191: loss=0.15769232899853677
Epoch #192: loss=0.22812117004033292
Epoch #193: loss=0.15429019103899147
Epoch #194: loss=0.22392136614882585
Epoch #195: loss=0.1952651287570144
Epoch #196: loss=0.20498910173773766
Epoch #197: loss=0.22315085205164822
Epoch #198: loss=0.1785921510873419
Epoch #199: loss=0.14234760855183456
Epoch #200: loss=0.14283833505980897
Epoch #201: loss=0.11799469578898314
Epoch #202: loss=0.09531888964049744
Epoch #203: loss=0.16055629899104437
Epoch #204: loss=0.10437783226370811
Epoch #205: loss=0.08751905190222191
Epoch #206: loss=0.1272578646965099
Epoch #207: loss=0.10560134933753447
Epoch #208: loss=0.17019742636969595
Epoch #209: loss=0.13307998035893295
Epoch #210: loss=0.13461688014142442
Epoch #211: loss=0.13101463335933108
Epoch #212: loss=0.12490366579908313
Epoch #213: loss=0.14625918210455865
Epoch #214: loss=0.1813638386401263
Epoch #215: loss=0.15762489571264296
Epoch #216: loss=0.20566709452506268
Epoch #217: loss=0.1461571574662671
Epoch #218: loss=0.11259054911859108
Epoch #219: loss=0.1078627175566825
Epoch #220: loss=0.0812878878504941
Epoch #221: loss=0.10263468652512088
Epoch #222: loss=0.11193926553383018
Epoch #223: loss=0.11594422900992812
Epoch #224: loss=0.10366068131318598
Epoch #225: loss=0.1248147367979541
Epoch #226: loss=0.17393198485175768
Epoch #227: loss=0.09411782681038885
Epoch #228: loss=0.09019017637227521
Epoch #229: loss=0.08360594962582443
Epoch #230: loss=0.1111894752830267
Epoch #231: loss=0.1076184699706959
Epoch #232: loss=0.09496823805525448
Epoch #233: loss=0.08550034819001501
Epoch #234: loss=0.08858026840695829
Epoch #235: loss=0.12268251366913319
Epoch #236: loss=0.11172234978188168
Epoch #237: loss=0.08360756205564196
Epoch #238: loss=0.08732049522752111
Epoch #239: loss=0.08442745047310989
Epoch #240: loss=0.10428868967926863
Epoch #241: loss=0.13698567207338233
Epoch #242: loss=0.11800439537248829
Epoch #243: loss=0.10101128030907024
Epoch #244: loss=0.1364661848003214
Epoch #245: loss=0.11047697778452527
Epoch #246: loss=0.2584784632605134
Epoch #247: loss=0.15243027031873213
Epoch #248: loss=0.09900638201471532
Epoch #249: loss=0.0940187828558864

Training time: 0:09:00.858554

Finished.
n2one setting etth1_etth2_ettm1_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm1_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_etth2_ettm1_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.24681e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.28835e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.24681e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.36155412860970937, 'MAE': 0.4298929238367959}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_ettm1_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm1_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_etth2_ettm1_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.62457e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.1521e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.62457e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.7713140748128754, 'MAE': 0.660897349096226}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_ettm2_electricity', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_ettm2_electricity_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.7460254180982622
Epoch #1: loss=0.7259492692403021
Epoch #2: loss=0.5052227263333481
Epoch #3: loss=0.38157208612716265
Epoch #4: loss=0.3319897538406311
Epoch #5: loss=0.29297695412284375
Epoch #6: loss=0.2626187148250941
Epoch #7: loss=0.21164787353980058
Epoch #8: loss=0.18885507731768436
Epoch #9: loss=0.19255341197541684
Epoch #10: loss=0.15239791526873678
Epoch #11: loss=0.16294405745030138
Epoch #12: loss=0.16037757645194242
Epoch #13: loss=0.14357713611010528
Epoch #14: loss=0.12453100823856503
Epoch #15: loss=0.10011224506821247
Epoch #16: loss=0.09978236689237673
Epoch #17: loss=0.10611305864947725
Epoch #18: loss=0.0865327765239198
Epoch #19: loss=0.07481947258071747
Epoch #20: loss=0.08180624074060362
Epoch #21: loss=0.06951441905445102
Epoch #22: loss=0.062403969353635534
Epoch #23: loss=0.08081266908324997
Epoch #24: loss=0.05560707677602553
Epoch #25: loss=0.053290550656229084
Epoch #26: loss=0.05835751766968798
Epoch #27: loss=0.0537428942904673
Epoch #28: loss=0.06103272748858038
Epoch #29: loss=0.04803004362378162
Epoch #30: loss=0.09901827361806151
Epoch #31: loss=0.04919482596929191
Epoch #32: loss=0.04269553542896201
Epoch #33: loss=0.04234939672367787
Epoch #34: loss=0.046832708559117434
Epoch #35: loss=0.03789662893974583
Epoch #36: loss=0.04028516470567684
Epoch #37: loss=0.03724957662944095
Epoch #38: loss=0.04405386344061336
Epoch #39: loss=0.037373879618237515
Epoch #40: loss=0.03864768237370804
Epoch #41: loss=0.03883079803519145
Epoch #42: loss=0.04024273589740621
Epoch #43: loss=0.030557723602850657
Epoch #44: loss=0.04582478260389944
Epoch #45: loss=0.03513404274409142
Epoch #46: loss=0.03353464971747346
Epoch #47: loss=0.03707292946217033
Epoch #48: loss=0.02470873188660776
Epoch #49: loss=0.028548623166367346
Epoch #50: loss=0.03511605801052721
Epoch #51: loss=0.04278438114372723
Epoch #52: loss=0.0352150164887772
Epoch #53: loss=0.033359905832037975
Epoch #54: loss=0.0307677111422207
Epoch #55: loss=0.020742120139833776
Epoch #56: loss=0.026432704815379952
Epoch #57: loss=0.04094005796810709
Epoch #58: loss=0.024919582609924343
Epoch #59: loss=0.022642548214859528
Epoch #60: loss=0.03090666134816842
Epoch #61: loss=0.024895353132732362
Epoch #62: loss=0.021907684972107336
Epoch #63: loss=0.025442074725910417
Epoch #64: loss=0.023011625085612813
Epoch #65: loss=0.022622141578958796
Epoch #66: loss=0.021860590808879518
Epoch #67: loss=0.026893765695872204
Epoch #68: loss=0.015849596938196396
Epoch #69: loss=0.02142312738915227
Epoch #70: loss=0.017707186952270998
Epoch #71: loss=0.02083478390469318
Epoch #72: loss=0.024153514609758262
Epoch #73: loss=0.02125899911510914
Epoch #74: loss=0.023872449950347357
Epoch #75: loss=0.021020708934705423
Epoch #76: loss=0.016360334792602377
Epoch #77: loss=0.059758774118936715
Epoch #78: loss=0.022592058840323496
Epoch #79: loss=0.018948995311760662
Epoch #80: loss=0.0156204328620591
Epoch #81: loss=0.02576031453683407
Epoch #82: loss=0.018160617124185645
Epoch #83: loss=0.021327721030213142
Epoch #84: loss=0.018840309398853075
Epoch #85: loss=0.034502977714604685
Epoch #86: loss=0.05619756373101738
Epoch #87: loss=0.018928529186284633
Epoch #88: loss=0.015421765739020132
Epoch #89: loss=0.021084742466151996
Epoch #90: loss=0.015844779533052796
Epoch #91: loss=0.015107728267691469
Epoch #92: loss=0.021874982589112885
Epoch #93: loss=0.02128851554939265
Epoch #94: loss=0.01504952116530238
Epoch #95: loss=0.02272513160316174
Epoch #96: loss=0.034574825976466536
Epoch #97: loss=0.014026559785518505
Epoch #98: loss=0.02209893033423897
Epoch #99: loss=0.012813057365826084
Epoch #100: loss=0.015813399855898035
Epoch #101: loss=0.016142537359436274
Epoch #102: loss=0.015736408339378644
Epoch #103: loss=0.016789081486748167
Epoch #104: loss=0.028609075648454423
Epoch #105: loss=0.01718796720806337
Epoch #106: loss=0.014606101875801738
Epoch #107: loss=0.03550427824506439
Epoch #108: loss=0.015864699230915623
Epoch #109: loss=0.014762742709835474
Epoch #110: loss=0.016052817819657537
Epoch #111: loss=0.015761661655007125
Epoch #112: loss=0.016296871364903313
Epoch #113: loss=0.01535253800405324
Epoch #114: loss=0.01919350354068218
Epoch #115: loss=0.017377307532877376
Epoch #116: loss=0.01366667908692404
Epoch #117: loss=0.013991404379949491
Epoch #118: loss=0.01616925012550419
Epoch #119: loss=0.01954549654791363
Epoch #120: loss=0.01688769642220584
Epoch #121: loss=0.01566610576437229
Epoch #122: loss=0.01739851060451945
Epoch #123: loss=0.013393459269626207
Epoch #124: loss=0.020458204819783138
Epoch #125: loss=0.01992161983739843
Epoch #126: loss=0.019694223477454007
Epoch #127: loss=0.01400145498219463
Epoch #128: loss=0.012418764894202385
Epoch #129: loss=0.015318476071452043
Epoch #130: loss=0.04392886052017149
Epoch #131: loss=0.020233747489465066
Epoch #132: loss=0.013995030335930574
Epoch #133: loss=0.012164442104016931
Epoch #134: loss=0.009650139584417341
Epoch #135: loss=0.013883648314069139
Epoch #136: loss=0.013225554903118596
Epoch #137: loss=0.016809325228341603
Epoch #138: loss=0.014892103417720673
Epoch #139: loss=0.015975494065417536
Epoch #140: loss=0.01596776152993929
Epoch #141: loss=0.01874564619814961
Epoch #142: loss=0.017813706330028416
Epoch #143: loss=0.0153177112375919
Epoch #144: loss=0.010126365896033775
Epoch #145: loss=0.011876447368520877
Epoch #146: loss=0.014260631270647436
Epoch #147: loss=0.014836941986860213
Epoch #148: loss=0.018249975774279725
Epoch #149: loss=0.017954584502990523
Epoch #150: loss=0.01681386164315193
Epoch #151: loss=0.029478466360644044
Epoch #152: loss=0.02618551216168313
Epoch #153: loss=0.015875983214970798
Epoch #154: loss=0.01263344237201368
Epoch #155: loss=0.01214113633571976
Epoch #156: loss=0.014947545191648584
Epoch #157: loss=0.010814355058808182
Epoch #158: loss=0.01597278825841128
Epoch #159: loss=0.013538154756506996
Epoch #160: loss=0.011781016126227286
Epoch #161: loss=0.014450770637762027
Epoch #162: loss=0.013727873282485528
Epoch #163: loss=0.016669794998782406
Epoch #164: loss=0.01381891045899055
Epoch #165: loss=0.022520650234382943
Epoch #166: loss=0.014571447973307814
Epoch #167: loss=0.010476442502836449
Epoch #168: loss=0.013534665893025783
Epoch #169: loss=0.011979613760422317
Epoch #170: loss=0.010562835114528936
Epoch #171: loss=0.019140514430073172
Epoch #172: loss=0.013755420285291873
Epoch #173: loss=0.01484621451266589
Epoch #174: loss=0.010729468661102042
Epoch #175: loss=0.016450571654649786
Epoch #176: loss=0.008010184359696365
Epoch #177: loss=0.015185943467547912
Epoch #178: loss=0.011801404002690526
Epoch #179: loss=0.012914787512020251
Epoch #180: loss=0.013505003709619262
Epoch #181: loss=0.014718380654223985
Epoch #182: loss=0.01243913086910794
Epoch #183: loss=0.01161289123251006
Epoch #184: loss=0.01483920845438624
Epoch #185: loss=0.016661850186946367
Epoch #186: loss=0.013296051906769009
Epoch #187: loss=0.015783500421766697
Epoch #188: loss=0.012155191075848146
Epoch #189: loss=0.008287570540721911
Epoch #190: loss=0.010590093394383422
Epoch #191: loss=0.013593066645573523
Epoch #192: loss=0.0252617310467304
Epoch #193: loss=0.013958855063252076
Epoch #194: loss=0.011589046152570349
Epoch #195: loss=0.010421704015569395
Epoch #196: loss=0.009586725203738268
Epoch #197: loss=0.016595667774178022
Epoch #198: loss=0.020388895489367644
Epoch #199: loss=0.016385182299054998
Epoch #200: loss=0.012501583821234438
Epoch #201: loss=0.01131613944958952
Epoch #202: loss=0.009928462227451147
Epoch #203: loss=0.013386681713426291
Epoch #204: loss=0.012807502421904409
Epoch #205: loss=0.01598171849659041
Epoch #206: loss=0.012829930491602812
Epoch #207: loss=0.014047107012266821
Epoch #208: loss=0.013833129084975233
Epoch #209: loss=0.010473432234687613
Epoch #210: loss=0.01389787459814641
Epoch #211: loss=0.012905526439286837
Epoch #212: loss=0.01046227587303187
Epoch #213: loss=0.012764217346977991
Epoch #214: loss=0.014843748973425467
Epoch #215: loss=0.010918712689247887
Epoch #216: loss=0.0120202113583723
Epoch #217: loss=0.006407087029081048
Epoch #218: loss=0.010170505697552297
Epoch #219: loss=0.010952463503247342
Epoch #220: loss=0.01247810842109322
Epoch #221: loss=0.019384489057759212
Epoch #222: loss=0.013936958540697996
Epoch #223: loss=0.010207968276307643
Epoch #224: loss=0.013781423349407195
Epoch #225: loss=0.010338031150692687
Epoch #226: loss=0.010307977565347534
Epoch #227: loss=0.01021387862340033
Epoch #228: loss=0.011836823810166491
Epoch #229: loss=0.015012361886648656
Epoch #230: loss=0.011335201627494467
Epoch #231: loss=0.011041348995378435
Epoch #232: loss=0.012279556722584116
Epoch #233: loss=0.012217183174286845
Epoch #234: loss=0.03348696913696002
Epoch #235: loss=0.013506927783870155
Epoch #236: loss=0.009193474923817689
Epoch #237: loss=0.008411164114061969
Epoch #238: loss=0.013187458611418483
Epoch #239: loss=0.011792624619506122
Epoch #240: loss=0.009507798842616067
Epoch #241: loss=0.011683761096015072
Epoch #242: loss=0.011453376697864911
Epoch #243: loss=0.0063164800983709635
Epoch #244: loss=0.00872247982132612
Epoch #245: loss=0.032834873463157055
Epoch #246: loss=0.01825240464277789
Epoch #247: loss=0.011779240400845326
Epoch #248: loss=0.009949439071233902
Epoch #249: loss=0.010332177914820363

Training time: 1:36:46.376910

Finished.
n2one setting etth1_etth2_ettm2_electricity -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm2_electricity_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_etth2_ettm2_electricity', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.49106e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.10285e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.365646705930558, 'MAE': 0.44131696568182427}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_ettm2_electricity -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm2_electricity_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_etth2_ettm2_electricity', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.0455e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.30001751919392067, 'MAE': 0.36704743514107274}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_ettm2_traffic', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_ettm2_traffic_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.0340273675614844
Epoch #1: loss=0.3739758249972826
Epoch #2: loss=0.27395536210450944
Epoch #3: loss=0.21297159983347072
Epoch #4: loss=0.16777601817112495
Epoch #5: loss=0.14396216776830972
Epoch #6: loss=0.11047290908351222
Epoch #7: loss=0.10131280931823686
Epoch #8: loss=0.08656146154626616
Epoch #9: loss=0.07607246074182944
Epoch #10: loss=0.07861219763256012
Epoch #11: loss=0.06430364088517569
Epoch #12: loss=0.059046033304184675
Epoch #13: loss=0.06306289119557756
Epoch #14: loss=0.056583149730056743
Epoch #15: loss=0.05610011187628785
Epoch #16: loss=0.04133524814396971
Epoch #17: loss=0.04712034417594559
Epoch #18: loss=0.04037723322690327
Epoch #19: loss=0.03531285120673549
Epoch #20: loss=0.034944938570827984
Epoch #21: loss=0.05157330900240635
Epoch #22: loss=0.0407824557003688
Epoch #23: loss=0.034823211243459086
Epoch #24: loss=0.034384082437134866
Epoch #25: loss=0.034400928524173716
Epoch #26: loss=0.0556048224806122
Epoch #27: loss=0.03132507726082866
Epoch #28: loss=0.027757242074437867
Epoch #29: loss=0.02858402240095322
Epoch #30: loss=0.02918795453990351
Epoch #31: loss=0.02783850283037006
Epoch #32: loss=0.02689638879455168
Epoch #33: loss=0.032054750596067064
Epoch #34: loss=0.026686414450474226
Epoch #35: loss=0.02272642305478603
Epoch #36: loss=0.02635954569089683
Epoch #37: loss=0.02328048279617095
Epoch #38: loss=0.025406364218493044
Epoch #39: loss=0.018763639883709424
Epoch #40: loss=0.022382163652008884
Epoch #41: loss=0.024050665457980767
Epoch #42: loss=0.023879159898604785
Epoch #43: loss=0.02938776586844986
Epoch #44: loss=0.022345386135650184
Epoch #45: loss=0.020574534938722144
Epoch #46: loss=0.019869277135264537
Epoch #47: loss=0.025315642043588035
Epoch #48: loss=0.02091796396157401
Epoch #49: loss=0.024320656623417803
Epoch #50: loss=0.03009469950114395
Epoch #51: loss=0.01850733929966669
Epoch #52: loss=0.020108542528177748
Epoch #53: loss=0.017558489128445372
Epoch #54: loss=0.021531349174408482
Epoch #55: loss=0.020552794467077695
Epoch #56: loss=0.0212272814870182
Epoch #57: loss=0.01869441308505075
Epoch #58: loss=0.01596542708781782
Epoch #59: loss=0.01861210157876239
Epoch #60: loss=0.01890500267701677
Epoch #61: loss=0.017685851156852013
Epoch #62: loss=0.021034234387733424
Epoch #63: loss=0.021705835770824536
Epoch #64: loss=0.021523635042188197
Epoch #65: loss=0.017934341543525238
Epoch #66: loss=0.016851949206660496
Epoch #67: loss=0.01723587538989517
Epoch #68: loss=0.01938157410241701
Epoch #69: loss=0.014903661246089162
Epoch #70: loss=0.026395879155381875
Epoch #71: loss=0.0217467115402144
Epoch #72: loss=0.01722597634020023
Epoch #73: loss=0.016473785093030026
Epoch #74: loss=0.013991501178577219
Epoch #75: loss=0.018968688745853272
Epoch #76: loss=0.02287336402401284
Epoch #77: loss=0.012305498547717382
Epoch #78: loss=0.014407201429813932
Epoch #79: loss=0.015897559695316713
Epoch #80: loss=0.023535162217420524
Epoch #81: loss=0.01718435418329295
Epoch #82: loss=0.01919846514061675
Epoch #83: loss=0.023318573206467838
Epoch #84: loss=0.0169781904273615
Epoch #85: loss=0.01473509240793794
Epoch #86: loss=0.015820177603063354
Epoch #87: loss=0.015620964735926453
Epoch #88: loss=0.012797987642354125
Epoch #89: loss=0.017036743427436746
Epoch #90: loss=0.012383438919588458
Epoch #91: loss=0.01612069650130292
Epoch #92: loss=0.016046646114369473
Epoch #93: loss=0.012418023692167037
Epoch #94: loss=0.0197975229320792
Epoch #95: loss=0.016761558114043347
Epoch #96: loss=0.014254057879294317
Epoch #97: loss=0.01453101154027786
Epoch #98: loss=0.01752670845974606
Epoch #99: loss=0.013631743712827412
Epoch #100: loss=0.012628087139836215
Epoch #101: loss=0.01265756931310003
Epoch #102: loss=0.01694180346951109
Epoch #103: loss=0.010492140641638757
Epoch #104: loss=0.013593977784319007
Epoch #105: loss=0.021392891814887866
Epoch #106: loss=0.015366380058308766
Epoch #107: loss=0.012970124018953939
Epoch #108: loss=0.012199954600174456
Epoch #109: loss=0.016455049071981486
Epoch #110: loss=0.015079038526748413
Epoch #111: loss=0.019134468615413125
Epoch #112: loss=0.01655704739094468
Epoch #113: loss=0.014543285097247262
Epoch #114: loss=0.01196827010851114
Epoch #115: loss=0.010403324529859884
Epoch #116: loss=0.013048784331950909
Epoch #117: loss=0.013674413467099336
Epoch #118: loss=0.017190249893388302
Epoch #119: loss=0.01652983397078987
Epoch #120: loss=0.01567686241466065
Epoch #121: loss=0.009030924578616107
Epoch #122: loss=0.022915828781960513
Epoch #123: loss=0.009512476254322303
Epoch #124: loss=0.020974374064593446
Epoch #125: loss=0.01769239246448751
Epoch #126: loss=0.010751465905982457
Epoch #127: loss=0.009505771655101632
Epoch #128: loss=0.012319528199990859
Epoch #129: loss=0.014233822151675995
Epoch #130: loss=0.018950249542467237
Epoch #131: loss=0.011339538634969698
Epoch #132: loss=0.013519425715366799
Epoch #133: loss=0.03566623085504319
Epoch #134: loss=0.011364677318566996
Epoch #135: loss=0.009909599784196258
Epoch #136: loss=0.012000180229391344
Epoch #137: loss=0.011429466155869256
Epoch #138: loss=0.018051446781004437
Epoch #139: loss=0.014095123551521878
Epoch #140: loss=0.010399272755924859
Epoch #141: loss=0.010924799919970756
Epoch #142: loss=0.011734544674324445
Epoch #143: loss=0.015285012852376916
Epoch #144: loss=0.017642242756438324
Epoch #145: loss=0.01196576946382458
Epoch #146: loss=0.009979640071697925
Epoch #147: loss=0.012940683067115308
Epoch #148: loss=0.011974075846706744
Epoch #149: loss=0.014373410244522461
Epoch #150: loss=0.013316677752119702
Epoch #151: loss=0.011742936968572412
Epoch #152: loss=0.013580712466571655
Epoch #153: loss=0.012951964183663005
Epoch #154: loss=0.009914054062416706
Epoch #155: loss=0.016312675450439223
Epoch #156: loss=0.014975686476382415
Epoch #157: loss=0.010243748014485946
Epoch #158: loss=0.013083349400875343
Epoch #159: loss=0.01163045802341854
Epoch #160: loss=0.017215277952177626
Epoch #161: loss=0.014209138192510727
Epoch #162: loss=0.010567267723615138
Epoch #163: loss=0.010729304805502722
Epoch #164: loss=0.018049858896259433
Epoch #165: loss=0.010329773460841385
Epoch #166: loss=0.01978667562439898
Epoch #167: loss=0.010678020387402606
Epoch #168: loss=0.011579021296737949
Epoch #169: loss=0.011455862800941909
Epoch #170: loss=0.012487011779338046
Epoch #171: loss=0.011653010717446401
Epoch #172: loss=0.012951914579891694
Epoch #173: loss=0.011084409635235779
Epoch #174: loss=0.012504891994508485
Epoch #175: loss=0.01338458218716905
Epoch #176: loss=0.013872629450935987
Epoch #177: loss=0.010331229893247211
Epoch #178: loss=0.012101031031043256
Epoch #179: loss=0.013374710680516301
Epoch #180: loss=0.013025979658566719
Epoch #181: loss=0.014614853041495639
Epoch #182: loss=0.009174689627600322
Epoch #183: loss=0.01284310274213167
Epoch #184: loss=0.00857468573449378
Epoch #185: loss=0.012952947243103146
Epoch #186: loss=0.009907218103861151
Epoch #187: loss=0.008299715609179196
Epoch #188: loss=0.012285750211464433
Epoch #189: loss=0.013997613112316199
Epoch #190: loss=0.015069607651031634
Epoch #191: loss=0.00914750578074339
Epoch #192: loss=0.00751117823630773
Epoch #193: loss=0.011966877422139853
Epoch #194: loss=0.016144180487685972
Epoch #195: loss=0.009108651169104446
Epoch #196: loss=0.010755618886847318
Epoch #197: loss=0.014353788727292005
Epoch #198: loss=0.008379263459826088
Epoch #199: loss=0.009824892137103306
Epoch #200: loss=0.009529592848488281
Epoch #201: loss=0.010443568874963323
Epoch #202: loss=0.012229485414437151
Epoch #203: loss=0.015059773011575111
Epoch #204: loss=0.007505260146400322
Epoch #205: loss=0.009055443559232204
Epoch #206: loss=0.011501820932083113
Epoch #207: loss=0.016680333683891442
Epoch #208: loss=0.010296486239035623
Epoch #209: loss=0.011715058582983733
Epoch #210: loss=0.009548636711333283
Epoch #211: loss=0.01112433667832134
Epoch #212: loss=0.009652312858165514
Epoch #213: loss=0.011169072364717082
Epoch #214: loss=0.011088692064427712
Epoch #215: loss=0.00952242663994223
Epoch #216: loss=0.012178270641147088
Epoch #217: loss=0.010053996526980835
Epoch #218: loss=0.011034340026932522
Epoch #219: loss=0.011302608378657288
Epoch #220: loss=0.00992683830275699
Epoch #221: loss=0.009563717431250462
Epoch #222: loss=0.009568648815273544
Epoch #223: loss=0.010124259776827694
Epoch #224: loss=0.009953207767887063
Epoch #225: loss=0.010303084101122904
Epoch #226: loss=0.009012047362532477
Epoch #227: loss=0.009568197297643957
Epoch #228: loss=0.012361715461741429
Epoch #229: loss=0.008097541029108956
Epoch #230: loss=0.010674100486926389
Epoch #231: loss=0.010564593073065166
Epoch #232: loss=0.010094631226324364
Epoch #233: loss=0.0063840996092035755
Epoch #234: loss=0.011647296715886074
Epoch #235: loss=0.009418769874899405
Epoch #236: loss=0.010636379153492258
Epoch #237: loss=0.012333077532375098
Epoch #238: loss=0.009561384170797308
Epoch #239: loss=0.006849795130146179
Epoch #240: loss=0.009583463144099266
Epoch #241: loss=0.01002052490404356
Epoch #242: loss=0.016931751562692457
Epoch #243: loss=0.009366065407561122
Epoch #244: loss=0.009516961150986417
Epoch #245: loss=0.008458757219576774
Epoch #246: loss=0.011864995814540546
Epoch #247: loss=0.011129553181251427
Epoch #248: loss=0.008404266487516588
Epoch #249: loss=0.021878926392103648

Training time: 3:30:07.901959

Finished.
n2one setting etth1_etth2_ettm2_traffic -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm2_traffic_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_etth2_ettm2_traffic', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.02993e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.97201e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.06159e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.02993e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4302730204297339, 'MAE': 0.46829436870129576}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_ettm2_traffic -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm2_traffic_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_etth2_ettm2_traffic', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.43112e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.97985e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.43112e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.48896878578588415, 'MAE': 0.5341552289937443}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_ettm2_traffic -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm2_traffic_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_etth2_ettm2_traffic', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.01677e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.28919390047470456, 'MAE': 0.35347182097172924}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_ettm2_weather', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_ettm2_weather_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=4.062900697483736
Epoch #1: loss=2.3290697172576307
Epoch #2: loss=2.457470265089297
Epoch #3: loss=2.067270178420871
Epoch #4: loss=1.8681750694910686
Epoch #5: loss=1.6533651936287974
Epoch #6: loss=1.4935184249690934
Epoch #7: loss=1.4448462374070112
Epoch #8: loss=1.2753298200812995
Epoch #9: loss=1.1907572641092188
Epoch #10: loss=1.1583559629963893
Epoch #11: loss=1.0499316477308087
Epoch #12: loss=0.9577014364448249
Epoch #13: loss=0.9595835290703119
Epoch #14: loss=0.8771136952381507
Epoch #15: loss=0.8223606546719869
Epoch #16: loss=0.8704009675512127
Epoch #17: loss=0.7636140666755975
Epoch #18: loss=0.7796010106217628
Epoch #19: loss=0.7294717863494274
Epoch #20: loss=0.7387605718537873
Epoch #21: loss=0.7757072857781953
Epoch #22: loss=0.7277425773003522
Epoch #23: loss=0.7182162643647662
Epoch #24: loss=0.721658817693299
Epoch #25: loss=0.9080384987242082
Epoch #26: loss=0.7040138022572386
Epoch #27: loss=0.645330595035179
Epoch #28: loss=0.6521740327863133
Epoch #29: loss=0.5794509047386693
Epoch #30: loss=0.6376020727204341
Epoch #31: loss=0.5713728648774764
Epoch #32: loss=0.5386411208732456
Epoch #33: loss=0.5381909065386828
Epoch #34: loss=0.5093819183461806
Epoch #35: loss=0.5292178497594946
Epoch #36: loss=0.4895447667907266
Epoch #37: loss=0.46774334767285514
Epoch #38: loss=0.5004561566839031
Epoch #39: loss=0.43501900866919874
Epoch #40: loss=0.4347006804218479
Epoch #41: loss=0.4072363040610856
Epoch #42: loss=0.4106033400577657
Epoch #43: loss=0.44072653616175933
Epoch #44: loss=0.4240345034529181
Epoch #45: loss=0.42028995267316405
Epoch #46: loss=0.3922814092799729
Epoch #47: loss=0.4327447627689324
Epoch #48: loss=0.3744242612053366
Epoch #49: loss=0.36787762945773556
Epoch #50: loss=0.361005060228647
Epoch #51: loss=0.35861994209242803
Epoch #52: loss=0.34754742068402905
Epoch #53: loss=0.36009303699521455
Epoch #54: loss=0.3729330976219738
Epoch #55: loss=0.30777619662238104
Epoch #56: loss=0.32202181892067777
Epoch #57: loss=0.40481141910833474
Epoch #58: loss=0.2898445069497707
Epoch #59: loss=0.34154151496933954
Epoch #60: loss=0.2569879768233673
Epoch #61: loss=0.3951031187293576
Epoch #62: loss=0.29621998790432424
Epoch #63: loss=0.27326612715043275
Epoch #64: loss=0.25224502340835686
Epoch #65: loss=0.2474881448582107
Epoch #66: loss=0.2565203662596497
Epoch #67: loss=0.267788905869512
Epoch #68: loss=0.24081014900230893
Epoch #69: loss=0.21779286057925692
Epoch #70: loss=0.23960171596092336
Epoch #71: loss=0.2400483460549046
Epoch #72: loss=0.21065673933309667
Epoch #73: loss=0.24973845102039038
Epoch #74: loss=0.2762879746801713
Epoch #75: loss=0.27094072161936295
Epoch #76: loss=0.3085319516705532
Epoch #77: loss=0.23002193868160248
Epoch #78: loss=0.28009426009421257
Epoch #79: loss=0.29431381880068314
Epoch #80: loss=0.29516661240189684
Epoch #81: loss=0.26351430383967417
Epoch #82: loss=0.2890644069103634
Epoch #83: loss=0.22612097070497625
Epoch #84: loss=0.179992411139549
Epoch #85: loss=0.2004764897420126
Epoch #86: loss=0.24268967570627437
Epoch #87: loss=0.17928307503461838
Epoch #88: loss=0.18192586697199764
Epoch #89: loss=0.19095856499146013
Epoch #90: loss=0.1920515806505493
Epoch #91: loss=0.13466383136954962
Epoch #92: loss=0.1863892415136683
Epoch #93: loss=0.19857849903842983
Epoch #94: loss=0.1953850712115858
Epoch #95: loss=0.15762971071343795
Epoch #96: loss=0.1363451539301405
Epoch #97: loss=0.16911220601668545
Epoch #98: loss=0.15976151758257082
Epoch #99: loss=0.17625532551285097
Epoch #100: loss=0.13255862982980177
Epoch #101: loss=0.133485097438097
Epoch #102: loss=0.14185359314376234
Epoch #103: loss=0.1455843428186342
Epoch #104: loss=0.13913550081790663
Epoch #105: loss=0.1928660853528509
Epoch #106: loss=0.18963758749704734
Epoch #107: loss=0.15599683456707233
Epoch #108: loss=0.14228841786583266
Epoch #109: loss=0.13911428715230204
Epoch #110: loss=0.11055146632533447
Epoch #111: loss=0.10906532300891829
Epoch #112: loss=0.1297229514183367
Epoch #113: loss=0.1407983299417823
Epoch #114: loss=0.14119174959612826
Epoch #115: loss=0.12800413863185575
Epoch #116: loss=0.11181293731080551
Epoch #117: loss=0.14506827612571857
Epoch #118: loss=0.14204217847801892
Epoch #119: loss=0.10736625681759096
Epoch #120: loss=0.19932085735832944
Epoch #121: loss=0.1736881025135517
Epoch #122: loss=0.13996673631025294
Epoch #123: loss=0.15100739841513774
Epoch #124: loss=0.11783129820490584
Epoch #125: loss=0.10074081900073033
Epoch #126: loss=0.11132518278763574
Epoch #127: loss=0.17393161049660513
Epoch #128: loss=0.14769780760010084
Epoch #129: loss=0.20315436500252462
Epoch #130: loss=0.11517486761451937
Epoch #131: loss=0.07755874597704877
Epoch #132: loss=0.1662442638885741
Epoch #133: loss=0.12059477614421471
Epoch #134: loss=0.09573896616405132
Epoch #135: loss=0.11170981711178433
Epoch #136: loss=0.09721358083918982
Epoch #137: loss=0.09874587367270507
Epoch #138: loss=0.10097013192945252
Epoch #139: loss=0.09767856996725588
Epoch #140: loss=0.08470799762974768
Epoch #141: loss=0.12189757473328534
Epoch #142: loss=0.1137493734850603
Epoch #143: loss=0.1136605544563602
Epoch #144: loss=0.11220929716878078
Epoch #145: loss=0.08917887567305098
Epoch #146: loss=0.1188969117424944
Epoch #147: loss=0.11322187124660202
Epoch #148: loss=0.09202244388414364
Epoch #149: loss=0.08489306559603588
Epoch #150: loss=0.12495770586618021
Epoch #151: loss=0.13857677681188957
Epoch #152: loss=0.12669139041327962
Epoch #153: loss=0.23810217671972864
Epoch #154: loss=0.21271887560393296
Epoch #155: loss=0.12944764866694516
Epoch #156: loss=0.10326362068892694
Epoch #157: loss=0.12364362728069811
Epoch #158: loss=0.09403679925290977
Epoch #159: loss=0.10426526162408147
Epoch #160: loss=0.0755061912624275
Epoch #161: loss=0.09291459777045484
Epoch #162: loss=0.078928072462041
Epoch #163: loss=0.07834373829046301
Epoch #164: loss=0.09850530877855479
Epoch #165: loss=0.09230055698357961
Epoch #166: loss=0.09537397675654467
Epoch #167: loss=0.08126392489408746
Epoch #168: loss=0.11301425113981846
Epoch #169: loss=0.07753601851051345
Epoch #170: loss=0.11017386768670644
Epoch #171: loss=0.076358056791565
Epoch #172: loss=0.06694353548992499
Epoch #173: loss=0.0606816973646774
Epoch #174: loss=0.07391690807964872
Epoch #175: loss=0.07264140242820277
Epoch #176: loss=0.08241503130571515
Epoch #177: loss=0.09689782061340178
Epoch #178: loss=0.08142027879754703
Epoch #179: loss=0.07988063441406862
Epoch #180: loss=0.1397760597733306
Epoch #181: loss=0.17283521030171245
Epoch #182: loss=0.1533189805626285
Epoch #183: loss=0.13313808562416657
Epoch #184: loss=0.09184627293371687
Epoch #185: loss=0.12076809114831336
Epoch #186: loss=0.1017635180888807
Epoch #187: loss=0.10893143830346126
Epoch #188: loss=0.09296135757775868
Epoch #189: loss=0.10013846065118617
Epoch #190: loss=0.081378756200566
Epoch #191: loss=0.12735440052461391
Epoch #192: loss=0.08868793186311628
Epoch #193: loss=0.06942226692084588
Epoch #194: loss=0.08418068136362468
Epoch #195: loss=0.062494805794866645
Epoch #196: loss=0.0547416277558488
Epoch #197: loss=0.05523424988210786
Epoch #198: loss=0.051527006825541746
Epoch #199: loss=0.09245095816532187
Epoch #200: loss=0.06808805719529297
Epoch #201: loss=0.06670475413328876
Epoch #202: loss=0.05704095585308239
Epoch #203: loss=0.10338037201732982
Epoch #204: loss=0.09786644349714704
Epoch #205: loss=0.11230503048236463
Epoch #206: loss=0.07174429313882309
Epoch #207: loss=0.060312780204649065
Epoch #208: loss=0.06638958341642923
Epoch #209: loss=0.06753532378477793
Epoch #210: loss=0.06401826733467626
Epoch #211: loss=0.06046583760968026
Epoch #212: loss=0.061324465563338176
Epoch #213: loss=0.057309827584700254
Epoch #214: loss=0.04362625380357107
Epoch #215: loss=0.10572480304422331
Epoch #216: loss=0.06296088268943861
Epoch #217: loss=0.07865339128629249
Epoch #218: loss=0.08995007267039196
Epoch #219: loss=0.07008601217439361
Epoch #220: loss=0.08255363102344905
Epoch #221: loss=0.05674385567944424
Epoch #222: loss=0.07293474418567676
Epoch #223: loss=0.07183148209736043
Epoch #224: loss=0.06603275440341118
Epoch #225: loss=0.07453352227514866
Epoch #226: loss=0.07410564810475882
Epoch #227: loss=0.044612954306763174
Epoch #228: loss=0.04826554869685103
Epoch #229: loss=0.043094511025165226
Epoch #230: loss=0.05505025558465836
Epoch #231: loss=0.05839991396037387
Epoch #232: loss=0.059144174862726065
Epoch #233: loss=0.11909633303316784
Epoch #234: loss=0.05211526217559973
Epoch #235: loss=0.06587327737361193
Epoch #236: loss=0.05297165219763331
Epoch #237: loss=0.07264272203924609
Epoch #238: loss=0.09641112578923211
Epoch #239: loss=0.06221600846551797
Epoch #240: loss=0.05763006666857822
Epoch #241: loss=0.048637088287767825
Epoch #242: loss=0.0567403510030286
Epoch #243: loss=0.0719647068603366
Epoch #244: loss=0.10026469222251691
Epoch #245: loss=0.05764451170084523
Epoch #246: loss=0.06169943880362838
Epoch #247: loss=0.0539800284302556
Epoch #248: loss=0.04763811109039713
Epoch #249: loss=0.04630574843316686

Training time: 0:16:36.672712

Finished.
n2one setting etth1_etth2_ettm2_weather -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm2_weather_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_etth2_ettm2_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.83314e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.18325e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.83314e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3724020253904736, 'MAE': 0.43309657859619993}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_ettm2_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm2_weather_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_etth2_ettm2_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.08751e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.19563602996806176, 'MAE': 0.30628773310346286}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_ettm2_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_ettm2_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=4.111144347624346
Epoch #1: loss=2.252863551631118
Epoch #2: loss=2.0763847972407485
Epoch #3: loss=1.9444905591733528
Epoch #4: loss=1.8116189566525547
Epoch #5: loss=1.6516831318537395
Epoch #6: loss=1.5488305778214426
Epoch #7: loss=1.465274539860812
Epoch #8: loss=1.3194160371115713
Epoch #9: loss=1.263119769818855
Epoch #10: loss=1.2470774560263662
Epoch #11: loss=1.1709978887529084
Epoch #12: loss=1.1760401490962866
Epoch #13: loss=1.131849973490744
Epoch #14: loss=1.0562722755200935
Epoch #15: loss=1.0192431644959883
Epoch #16: loss=1.0290768218762947
Epoch #17: loss=0.9545182152227922
Epoch #18: loss=0.8887320910439347
Epoch #19: loss=0.9248130429874767
Epoch #20: loss=0.8431061054721023
Epoch #21: loss=0.8686179446451592
Epoch #22: loss=0.833812828316833
Epoch #23: loss=0.8831280921444749
Epoch #24: loss=0.7962817486488458
Epoch #25: loss=0.7556247810522715
Epoch #26: loss=0.9178999734647346
Epoch #27: loss=0.7120132915901415
Epoch #28: loss=0.6718879441420237
Epoch #29: loss=0.7424341973030206
Epoch #30: loss=0.7328012377926798
Epoch #31: loss=0.6644284788406256
Epoch #32: loss=0.7467049179655133
Epoch #33: loss=0.7176781874714475
Epoch #34: loss=0.6586240042339672
Epoch #35: loss=0.6564755674564478
Epoch #36: loss=0.706546114249663
Epoch #37: loss=0.6616498891151312
Epoch #38: loss=0.6087597175077959
Epoch #39: loss=0.5520271785331495
Epoch #40: loss=0.5526300470034281
Epoch #41: loss=0.49620135805823584
Epoch #42: loss=0.5791853016073053
Epoch #43: loss=0.5832742208784277
Epoch #44: loss=0.6001498301823934
Epoch #45: loss=0.5709882830128525
Epoch #46: loss=0.5255496131651329
Epoch #47: loss=0.5126435612187241
Epoch #48: loss=0.5124937304944703
Epoch #49: loss=0.5175523532159401
Epoch #50: loss=0.5468085480458809
Epoch #51: loss=0.5586703275189255
Epoch #52: loss=0.6165336379499147
Epoch #53: loss=0.5258013705412546
Epoch #54: loss=0.48893246415889624
Epoch #55: loss=0.44824850739854755
Epoch #56: loss=0.5015620607318301
Epoch #57: loss=0.5634203878316012
Epoch #58: loss=0.49142367189580743
Epoch #59: loss=0.40390024130994623
Epoch #60: loss=0.44408613578839734
Epoch #61: loss=0.43803468436905835
Epoch #62: loss=0.4540426351807334
Epoch #63: loss=0.40281155344211694
Epoch #64: loss=0.43634541874582117
Epoch #65: loss=0.49457316281217517
Epoch #66: loss=0.5133037016247258
Epoch #67: loss=0.4383588789990454
Epoch #68: loss=0.40111320398070593
Epoch #69: loss=0.4181425833340847
Epoch #70: loss=0.37868628357395984
Epoch #71: loss=0.39610472456975415
Epoch #72: loss=0.3378062934586496
Epoch #73: loss=0.3636422667539481
Epoch #74: loss=0.5073734833435579
Epoch #75: loss=0.4599631771896825
Epoch #76: loss=0.3719425368489641
Epoch #77: loss=0.3979267757950407
Epoch #78: loss=0.39124419066039
Epoch #79: loss=0.38859938536629535
Epoch #80: loss=0.36831806193698535
Epoch #81: loss=0.3490113245718407
Epoch #82: loss=0.33917384256016125
Epoch #83: loss=0.4114302658673489
Epoch #84: loss=0.32584457099437714
Epoch #85: loss=0.37487049310496356
Epoch #86: loss=0.3266091924725157
Epoch #87: loss=0.3484151038256558
Epoch #88: loss=0.3327271875106927
Epoch #89: loss=0.4531774091901201
Epoch #90: loss=0.4444182799621062
Epoch #91: loss=0.3754451609019077
Epoch #92: loss=0.3916113223090316
Epoch #93: loss=0.3686949366872961
Epoch #94: loss=0.3710972413872228
Epoch #95: loss=0.41695409019788104
Epoch #96: loss=0.38357638635418634
Epoch #97: loss=0.30929716608741065
Epoch #98: loss=0.2990002167044264
Epoch #99: loss=0.35977020227547846
Epoch #100: loss=0.27256434455965506
Epoch #101: loss=0.33541275741476
Epoch #102: loss=0.47493111364769214
Epoch #103: loss=0.33285044810988684
Epoch #104: loss=0.28754172496723407
Epoch #105: loss=0.29743471109505853
Epoch #106: loss=0.3186835280873559
Epoch #107: loss=0.27736341253374563
Epoch #108: loss=0.25887134039040766
Epoch #109: loss=0.3163328518470128
Epoch #110: loss=0.34444186046268
Epoch #111: loss=0.2716243840528257
Epoch #112: loss=0.2851691663716779
Epoch #113: loss=0.2683856435345881
Epoch #114: loss=0.27631445093588397
Epoch #115: loss=0.24591748732509036
Epoch #116: loss=0.2781217915542198
Epoch #117: loss=0.27631544705593225
Epoch #118: loss=0.2858845826351281
Epoch #119: loss=0.268919659157594
Epoch #120: loss=0.3191827702702898
Epoch #121: loss=0.2819433821873231
Epoch #122: loss=0.25851895344076736
Epoch #123: loss=0.257664640518752
Epoch #124: loss=0.23107372901656412
Epoch #125: loss=0.22555080327120694
Epoch #126: loss=0.18456495959650387
Epoch #127: loss=0.21187326605572845
Epoch #128: loss=0.20808826161153388
Epoch #129: loss=0.16025095387841715
Epoch #130: loss=0.16912683076930768
Epoch #131: loss=0.26557591331727576
Epoch #132: loss=0.25621314098437625
Epoch #133: loss=0.1895484926574158
Epoch #134: loss=0.18735285825801617
Epoch #135: loss=0.1769883492679307
Epoch #136: loss=0.185552267639926
Epoch #137: loss=0.31069692450039316
Epoch #138: loss=0.2212305488911542
Epoch #139: loss=0.21125819172823068
Epoch #140: loss=0.22954666975772742
Epoch #141: loss=0.2037728742668123
Epoch #142: loss=0.2598198236841144
Epoch #143: loss=0.24384119271328955
Epoch #144: loss=0.16490843530857202
Epoch #145: loss=0.18065789183883957
Epoch #146: loss=0.2056516088319547
Epoch #147: loss=0.20082151754335922
Epoch #148: loss=0.20282019607045434
Epoch #149: loss=0.2143539120302056
Epoch #150: loss=0.20820667843023935
Epoch #151: loss=0.22141672964348938
Epoch #152: loss=0.22597883167591962
Epoch #153: loss=0.17783877005179724
Epoch #154: loss=0.20476424344109767
Epoch #155: loss=0.16894422900496106
Epoch #156: loss=0.19794008135795593
Epoch #157: loss=0.1896632584658536
Epoch #158: loss=0.183422289788723
Epoch #159: loss=0.16387847923871243
Epoch #160: loss=0.18949766434503323
Epoch #161: loss=0.15466636554761368
Epoch #162: loss=0.15787445866700375
Epoch #163: loss=0.18368463094035783
Epoch #164: loss=0.18187197038170064
Epoch #165: loss=0.1516608993212382
Epoch #166: loss=0.20744457682876877
Epoch #167: loss=0.1555084731768478
Epoch #168: loss=0.12780535492030057
Epoch #169: loss=0.13872104860616452
Epoch #170: loss=0.18437164118795685
Epoch #171: loss=0.1950833142706842
Epoch #172: loss=0.1918037018992684
Epoch #173: loss=0.16873242796370477
Epoch #174: loss=0.19146217642859978
Epoch #175: loss=0.1794744562922102
Epoch #176: loss=0.1624342416497794
Epoch #177: loss=0.1794419511023796
Epoch #178: loss=0.19015736448945422
Epoch #179: loss=0.1460281918671998
Epoch #180: loss=0.15905366149364095
Epoch #181: loss=0.21288353091839587
Epoch #182: loss=0.16772220012816516
Epoch #183: loss=0.12857976950930827
Epoch #184: loss=0.15315577376520995
Epoch #185: loss=0.12364920770580118
Epoch #186: loss=0.10182913652423656
Epoch #187: loss=0.24222145319888086
Epoch #188: loss=0.13760237587672292
Epoch #189: loss=0.15071517420989095
Epoch #190: loss=0.12377994643016295
Epoch #191: loss=0.15875635871833021
Epoch #192: loss=0.19995313103903423
Epoch #193: loss=0.12201739757349997
Epoch #194: loss=0.1962882893329317
Epoch #195: loss=0.18500094443108095
Epoch #196: loss=0.22374801405451514
Epoch #197: loss=0.24999042431061919
Epoch #198: loss=0.19569150460037318
Epoch #199: loss=0.14523188453732114
Epoch #200: loss=0.15078997510400685
Epoch #201: loss=0.13339515290025508
Epoch #202: loss=0.13319861324447574
Epoch #203: loss=0.19619729336012492
Epoch #204: loss=0.13018907685623024
Epoch #205: loss=0.10377827083522623
Epoch #206: loss=0.1419362619970784
Epoch #207: loss=0.11567237386197755
Epoch #208: loss=0.16506033198851527
Epoch #209: loss=0.1387639989455541
Epoch #210: loss=0.13684693836804593
Epoch #211: loss=0.12187114425680855
Epoch #212: loss=0.11304346991307808
Epoch #213: loss=0.12280732511796734
Epoch #214: loss=0.14829722853998342
Epoch #215: loss=0.15001828889503624
Epoch #216: loss=0.19883860252571828
Epoch #217: loss=0.11109037663448941
Epoch #218: loss=0.11703744372635176
Epoch #219: loss=0.13271734903030324
Epoch #220: loss=0.1444096965997508
Epoch #221: loss=0.18682772812969756
Epoch #222: loss=0.19088334567619092
Epoch #223: loss=0.15365824712948364
Epoch #224: loss=0.11900343751591264
Epoch #225: loss=0.13277941716439795
Epoch #226: loss=0.16807061896631212
Epoch #227: loss=0.09676602618260817
Epoch #228: loss=0.08899580800172055
Epoch #229: loss=0.0855820407582955
Epoch #230: loss=0.11325333989930875
Epoch #231: loss=0.09388055691890644
Epoch #232: loss=0.08459437508700472
Epoch #233: loss=0.08424595184624195
Epoch #234: loss=0.08024241668031071
Epoch #235: loss=0.10268847046024872
Epoch #236: loss=0.10144225056424286
Epoch #237: loss=0.08230077368066166
Epoch #238: loss=0.07868012272273049
Epoch #239: loss=0.09258603784396793
Epoch #240: loss=0.09771239864781048
Epoch #241: loss=0.1517493776751287
Epoch #242: loss=0.12979694015600465
Epoch #243: loss=0.11356001115883842
Epoch #244: loss=0.12337059550213092
Epoch #245: loss=0.09141553294929591
Epoch #246: loss=0.2455788040251443
Epoch #247: loss=0.1704798455942761
Epoch #248: loss=0.11570550298148935
Epoch #249: loss=0.10271800303775253

Training time: 0:08:51.589880

Finished.
n2one setting etth1_etth2_ettm2_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm2_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_etth2_ettm2_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.42806e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.09601e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.42806e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3867792622633723, 'MAE': 0.44444482222653864}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_ettm2_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm2_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_etth2_ettm2_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.7021e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.20541e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.5126483991593769, 'MAE': 0.5323910110816235}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_electricity_traffic', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_electricity_traffic_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.8536394902986592
Epoch #1: loss=0.31269168606651954
Epoch #2: loss=0.21753138027394325
Epoch #3: loss=0.14375843383440298
Epoch #4: loss=0.10897978699128878
Epoch #5: loss=0.08716013639972374
Epoch #6: loss=0.06624074536239544
Epoch #7: loss=0.06759873219612447
Epoch #8: loss=0.05412074081084645
Epoch #9: loss=0.060463444192083854
Epoch #10: loss=0.04792686896620407
Epoch #11: loss=0.04497801975320648
Epoch #12: loss=0.04171171741141512
Epoch #13: loss=0.03344675443900023
Epoch #14: loss=0.03763630857116192
Epoch #15: loss=0.036216599830179635
Epoch #16: loss=0.028641140901595634
Epoch #17: loss=0.03136708526418886
Epoch #18: loss=0.04081171578801577
Epoch #19: loss=0.029169343067733798
Epoch #20: loss=0.03024610179760816
Epoch #21: loss=0.021744407354295798
Epoch #22: loss=0.036874666502318014
Epoch #23: loss=0.032359255898417864
Epoch #24: loss=0.022546870463713304
Epoch #25: loss=0.02358650727724266
Epoch #26: loss=0.026594986137807596
Epoch #27: loss=0.022477406632807184
Epoch #28: loss=0.022533777658642815
Epoch #29: loss=0.021958378719120406
Epoch #30: loss=0.024166278849097566
Epoch #31: loss=0.02297602480371952
Epoch #32: loss=0.023513446528584763
Epoch #33: loss=0.01798941734708486
Epoch #34: loss=0.02155409939971277
Epoch #35: loss=0.019453110383806396
Epoch #36: loss=0.02238329980112363
Epoch #37: loss=0.020635961894562144
Epoch #38: loss=0.02153633849886141
Epoch #39: loss=0.019823385545137396
Epoch #40: loss=0.020680452636729012
Epoch #41: loss=0.015370752621670047
Epoch #42: loss=0.025434380171907273
Epoch #43: loss=0.020827510077685255
Epoch #44: loss=0.019420571711133976
Epoch #45: loss=0.01592273756268134
Epoch #46: loss=0.0189078295010717
Epoch #47: loss=0.022689651223557004
Epoch #48: loss=0.01515747460418201
Epoch #49: loss=0.01575805124418838
Epoch #50: loss=0.01830977563477458
Epoch #51: loss=0.0154644868777868
Epoch #52: loss=0.02226198743131621
Epoch #53: loss=0.018152194835202622
Epoch #54: loss=0.019305933962534442
Epoch #55: loss=0.014057871396984025
Epoch #56: loss=0.017927829178254202
Epoch #57: loss=0.014123465081724691
Epoch #58: loss=0.014881771910121997
Epoch #59: loss=0.014721645757416838
Epoch #60: loss=0.01884471732479619
Epoch #61: loss=0.014911053692898654
Epoch #62: loss=0.013956633084085042
Epoch #63: loss=0.015552070105008574
Epoch #64: loss=0.014155429946120561
Epoch #65: loss=0.01285662504204618
Epoch #66: loss=0.013906509371757594
Epoch #67: loss=0.015740600326654804
Epoch #68: loss=0.01229139143683144
Epoch #69: loss=0.012467490918672728
Epoch #70: loss=0.01427161928832608
Epoch #71: loss=0.018923240523639858
Epoch #72: loss=0.012722603431485598
Epoch #73: loss=0.012910376187795563
Epoch #74: loss=0.011356707266050469
Epoch #75: loss=0.02097166761713248
Epoch #76: loss=0.017916318145677845
Epoch #77: loss=0.01016223083750898
Epoch #78: loss=0.014881852361205934
Epoch #79: loss=0.014266609584742655
Epoch #80: loss=0.012636458811101385
Epoch #81: loss=0.01663002144836501
Epoch #82: loss=0.012230701129777519
Epoch #83: loss=0.01704346773347101
Epoch #84: loss=0.01487653928384054
Epoch #85: loss=0.016020203733852923
Epoch #86: loss=0.010577916576248517
Epoch #87: loss=0.012642641890437694
Epoch #88: loss=0.010268795310176129
Epoch #89: loss=0.013681870488340615
Epoch #90: loss=0.013979126613853816
Epoch #91: loss=0.012167163839953334
Epoch #92: loss=0.012197255891830294
Epoch #93: loss=0.013429604297152346
Epoch #94: loss=0.012730562968271781
Epoch #95: loss=0.01308283689455917
Epoch #96: loss=0.013498749049125028
Epoch #97: loss=0.011955074885103775
Epoch #98: loss=0.018375813771817684
Epoch #99: loss=0.015963043805073483
Epoch #100: loss=0.010298348135758757
Epoch #101: loss=0.00862837405520179
Epoch #102: loss=0.015415195800446101
Epoch #103: loss=0.01153313512769944
Epoch #104: loss=0.013190376114259912
Epoch #105: loss=0.011196433431859873
Epoch #106: loss=0.011585419744513027
Epoch #107: loss=0.008814770771579937
Epoch #108: loss=0.011976207328682925
Epoch #109: loss=0.015176973207292568
Epoch #110: loss=0.00935662948827595
Epoch #111: loss=0.013103627059555693
Epoch #112: loss=0.013826217921795992
Epoch #113: loss=0.009364962262613427
Epoch #114: loss=0.008269810485274767
Epoch #115: loss=0.009922476569773003
Epoch #116: loss=0.013929760141180301
Epoch #117: loss=0.010149534225380763
Epoch #118: loss=0.008725039586900652
Epoch #119: loss=0.014360469009808642
Epoch #120: loss=0.01100327281741178
Epoch #121: loss=0.011087771360595137
Epoch #122: loss=0.013410970920407227
Epoch #123: loss=0.010866639480967721
Epoch #124: loss=0.00897416531980231
Epoch #125: loss=0.011887900578631275
Epoch #126: loss=0.010443434501318696
Epoch #127: loss=0.01361237052350936
Epoch #128: loss=0.01321315333368091
Epoch #129: loss=0.008578189179841421
Epoch #130: loss=0.013661506533817837
Epoch #131: loss=0.013171816860886218
Epoch #132: loss=0.011832077621214179
Epoch #133: loss=0.009559992301701268
Epoch #134: loss=0.010153083305075845
Epoch #135: loss=0.009436314528643975
Epoch #136: loss=0.011627846533009929
Epoch #137: loss=0.012675538728001576
Epoch #138: loss=0.01142552991190232
Epoch #139: loss=0.008404170318415043
Epoch #140: loss=0.01260765090034481
Epoch #141: loss=0.009959435919371205
Epoch #142: loss=0.015614913541595268
Epoch #143: loss=0.01577770300376316
Epoch #144: loss=0.008436458485762946
Epoch #145: loss=0.014413097120520761
Epoch #146: loss=0.013246384145305497
Epoch #147: loss=0.019954521562454964
Epoch #148: loss=0.008146656526137087
Epoch #149: loss=0.009551184530542664
Epoch #150: loss=0.008417695031915468
Epoch #151: loss=0.009928155452750312
Epoch #152: loss=0.009517977289940967
Epoch #153: loss=0.010213526961309139
Epoch #154: loss=0.011644733178038531
Epoch #155: loss=0.008152949411514699
Epoch #156: loss=0.013748623975532195
Epoch #157: loss=0.012678457801105764
Epoch #158: loss=0.011343850998021973
Epoch #159: loss=0.010041927808037046
Epoch #160: loss=0.007163448327036992
Epoch #161: loss=0.012039212526425987
Epoch #162: loss=0.015436724033562171
Epoch #163: loss=0.010882583838024755
Epoch #164: loss=0.008624636605329448
Epoch #165: loss=0.009722039152755955
Epoch #166: loss=0.008869726091718422
Epoch #167: loss=0.036377271550689816
Epoch #168: loss=0.011710135543482676
Epoch #169: loss=0.006745614457873351
Epoch #170: loss=0.0057469262223764275
Epoch #171: loss=0.015017694429916628
Epoch #172: loss=0.012285119764803058
Epoch #173: loss=0.009134872735039068
Epoch #174: loss=0.010020217964069338
Epoch #175: loss=0.008310308565905764
Epoch #176: loss=0.007264850235736906
Epoch #177: loss=0.01252572229176794
Epoch #178: loss=0.008845865189873632
Epoch #179: loss=0.009875572739552092
Epoch #180: loss=0.011634350466516076
Epoch #181: loss=0.008860082117107922
Epoch #182: loss=0.008711907019006733
Epoch #183: loss=0.009649033597093282
Epoch #184: loss=0.00873447411576488
Epoch #185: loss=0.010689846788142646
Epoch #186: loss=0.010945487085353652
Epoch #187: loss=0.00741075490912677
Epoch #188: loss=0.009959031281400603
Epoch #189: loss=0.011693644944666522
Epoch #190: loss=0.008944460363218712
Epoch #191: loss=0.009351151117067061
Epoch #192: loss=0.009477376235532672
Epoch #193: loss=0.010560831300421784
Epoch #194: loss=0.011149135673994979
Epoch #195: loss=0.008201437234683931
Epoch #196: loss=0.009393900290262184
Epoch #197: loss=0.009001788003805872
Epoch #198: loss=0.011850076709722645
Epoch #199: loss=0.009944208465262632
Epoch #200: loss=0.017418929808740033
Epoch #201: loss=0.018499913980524772
Epoch #202: loss=0.007568575670072613
Epoch #203: loss=0.005970715419092434
Epoch #204: loss=0.007796955184473009
Epoch #205: loss=0.010632394649398483
Epoch #206: loss=0.009861022804964606
Epoch #207: loss=0.008162342268793569
Epoch #208: loss=0.008405011283856588
Epoch #209: loss=0.012021572982700119
Epoch #210: loss=0.009767424778140122
Epoch #211: loss=0.010658071439879256
Epoch #212: loss=0.008842956747210971
Epoch #213: loss=0.011558859123857715
Epoch #214: loss=0.007985996936344147
Epoch #215: loss=0.007862024611399863
Epoch #216: loss=0.014166132418152505
Epoch #217: loss=0.007797530554557871
Epoch #218: loss=0.008701304299139309
Epoch #219: loss=0.0110067463622027
Epoch #220: loss=0.00783997944408907
Epoch #221: loss=0.010783543358980963
Epoch #222: loss=0.008995818336123333
Epoch #223: loss=0.010152545203280917
Epoch #224: loss=0.008377265941647116
Epoch #225: loss=0.010710963434633068
Epoch #226: loss=0.008126000083309253
Epoch #227: loss=0.008033381664016091
Epoch #228: loss=0.007437028105203128
Epoch #229: loss=0.011435616753835724
Epoch #230: loss=0.009677211663041127
Epoch #231: loss=0.010379904457983587
Epoch #232: loss=0.008806351626477095
Epoch #233: loss=0.008642000421730103
Epoch #234: loss=0.010464715632483494
Epoch #235: loss=0.007216836455515014
Epoch #236: loss=0.008990319231869307
Epoch #237: loss=0.005508678605235227
Epoch #238: loss=0.010363651685753528
Epoch #239: loss=0.014813553514047067
Epoch #240: loss=0.005543516468672821
Epoch #241: loss=0.00855463621885525
Epoch #242: loss=0.012496436446368867
Epoch #243: loss=0.009911144455308763
Epoch #244: loss=0.008402971355690436
Epoch #245: loss=0.0160271677750605
Epoch #246: loss=0.009096070494788569
Epoch #247: loss=0.006008634186249538
Epoch #248: loss=0.010534854946359829
Epoch #249: loss=0.007016504028069599

Training time: 5:04:49.530845

Finished.
n2one setting etth1_etth2_electricity_traffic -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_electricity_traffic_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_etth2_electricity_traffic', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.1282e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.29782e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.87628e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.888997158332511, 'MAE': 0.7863975785565551}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_electricity_traffic -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_electricity_traffic_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_etth2_electricity_traffic', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.12013e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.2359874718789217, 'MAE': 0.33924353116214145}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_electricity_weather', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_electricity_weather_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.7387529562054578
Epoch #1: loss=0.7737980120069763
Epoch #2: loss=0.5669365029916209
Epoch #3: loss=0.4498511203603401
Epoch #4: loss=0.37713638703413616
Epoch #5: loss=0.3314703020197533
Epoch #6: loss=0.3168532887158962
Epoch #7: loss=0.28577777549335504
Epoch #8: loss=0.25335273478912845
Epoch #9: loss=0.23730605545549183
Epoch #10: loss=0.20334503353880384
Epoch #11: loss=0.19371657306715392
Epoch #12: loss=0.17066986594669045
Epoch #13: loss=0.15219228525860157
Epoch #14: loss=0.15421264520601222
Epoch #15: loss=0.13496871494850624
Epoch #16: loss=0.1475878814209531
Epoch #17: loss=0.13465315563258537
Epoch #18: loss=0.1026712963744544
Epoch #19: loss=0.09390381497132316
Epoch #20: loss=0.11199482925329099
Epoch #21: loss=0.10966655380838135
Epoch #22: loss=0.08562685176214188
Epoch #23: loss=0.06975542106910755
Epoch #24: loss=0.09646438515469061
Epoch #25: loss=0.07583376249798943
Epoch #26: loss=0.08043340191379231
Epoch #27: loss=0.059389533250595226
Epoch #28: loss=0.06924216491054135
Epoch #29: loss=0.07897865324257937
Epoch #30: loss=0.07982709197007594
Epoch #31: loss=0.06275988300266441
Epoch #32: loss=0.058681895912539764
Epoch #33: loss=0.055725491110369604
Epoch #34: loss=0.04175496294996456
Epoch #35: loss=0.05573608577728705
Epoch #36: loss=0.05344466554901338
Epoch #37: loss=0.05025148022548396
Epoch #38: loss=0.06315770561721723
Epoch #39: loss=0.044089141079944424
Epoch #40: loss=0.052887891345061465
Epoch #41: loss=0.06305909400142812
Epoch #42: loss=0.052211017845781554
Epoch #43: loss=0.038716640966425846
Epoch #44: loss=0.030325898053150346
Epoch #45: loss=0.0415035593916773
Epoch #46: loss=0.04514775242607452
Epoch #47: loss=0.035685689189184945
Epoch #48: loss=0.04059381844215301
Epoch #49: loss=0.03547564366834955
Epoch #50: loss=0.05400865042899475
Epoch #51: loss=0.03542876414699258
Epoch #52: loss=0.031589131451784595
Epoch #53: loss=0.027032989372984297
Epoch #54: loss=0.05664754309884977
Epoch #55: loss=0.032752828219121226
Epoch #56: loss=0.04087266995677327
Epoch #57: loss=0.039237031930479685
Epoch #58: loss=0.03924897671457886
Epoch #59: loss=0.04298381826587517
Epoch #60: loss=0.041781134177850676
Epoch #61: loss=0.03615433621475695
Epoch #62: loss=0.028018139590705305
Epoch #63: loss=0.029477473717296386
Epoch #64: loss=0.04427241767212294
Epoch #65: loss=0.039060342197185204
Epoch #66: loss=0.02602830911545377
Epoch #67: loss=0.030505049282973866
Epoch #68: loss=0.02396487419743741
Epoch #69: loss=0.03084430114173916
Epoch #70: loss=0.027684910928796966
Epoch #71: loss=0.02381524168841097
Epoch #72: loss=0.033452674224256816
Epoch #73: loss=0.021492607924452574
Epoch #74: loss=0.027261579041291863
Epoch #75: loss=0.028006384401050733
Epoch #76: loss=0.021758505532781174
Epoch #77: loss=0.023292756719073576
Epoch #78: loss=0.02395511065562026
Epoch #79: loss=0.03160779827311145
Epoch #80: loss=0.023592783883085004
Epoch #81: loss=0.01887768734158778
Epoch #82: loss=0.029472864959666303
Epoch #83: loss=0.02237164964570491
Epoch #84: loss=0.039539159055337454
Epoch #85: loss=0.01863937049690077
Epoch #86: loss=0.03162116841367933
Epoch #87: loss=0.02695893927366367
Epoch #88: loss=0.07904878658386995
Epoch #89: loss=0.03845952360837919
Epoch #90: loss=0.025900275012093837
Epoch #91: loss=0.019502730707481885
Epoch #92: loss=0.020147395663355525
Epoch #93: loss=0.0315490583223265
Epoch #94: loss=0.027135042569127934
Epoch #95: loss=0.01531828473882564
Epoch #96: loss=0.015064357523709649
Epoch #97: loss=0.021344846818006632
Epoch #98: loss=0.01893923760355009
Epoch #99: loss=0.020746673113076982
Epoch #100: loss=0.02844360596635779
Epoch #101: loss=0.023415536866097653
Epoch #102: loss=0.01709178638666445
Epoch #103: loss=0.019841958680306238
Epoch #104: loss=0.015601132462836977
Epoch #105: loss=0.030959379854270223
Epoch #106: loss=0.039726054269776594
Epoch #107: loss=0.033786872533727905
Epoch #108: loss=0.024089336007642573
Epoch #109: loss=0.020195855462725
Epoch #110: loss=0.014101902358820842
Epoch #111: loss=0.015713523134219632
Epoch #112: loss=0.03281768725477443
Epoch #113: loss=0.023118634787555836
Epoch #114: loss=0.02346831667069294
Epoch #115: loss=0.01718816343485958
Epoch #116: loss=0.016194469106307518
Epoch #117: loss=0.01674387279663808
Epoch #118: loss=0.015444416699994232
Epoch #119: loss=0.030160551699822628
Epoch #120: loss=0.016468792537342077
Epoch #121: loss=0.01574431395934059
Epoch #122: loss=0.01769667705056616
Epoch #123: loss=0.015365028220655814
Epoch #124: loss=0.011450833794815657
Epoch #125: loss=0.020252081029113238
Epoch #126: loss=0.034510885493654414
Epoch #127: loss=0.01716454970954151
Epoch #128: loss=0.02111838221288134
Epoch #129: loss=0.01467859331041786
Epoch #130: loss=0.01768156841163165
Epoch #131: loss=0.020291571199495366
Epoch #132: loss=0.0173121764040178
Epoch #133: loss=0.019378105356161923
Epoch #134: loss=0.019755491529593962
Epoch #135: loss=0.019954447877668154
Epoch #136: loss=0.04163293772486072
Epoch #137: loss=0.020560268547458165
Epoch #138: loss=0.018589070029563202
Epoch #139: loss=0.021053257787218345
Epoch #140: loss=0.015705020806089126
Epoch #141: loss=0.013475341636105764
Epoch #142: loss=0.014615340770974915
Epoch #143: loss=0.02283211597908995
Epoch #144: loss=0.01538838175660092
Epoch #145: loss=0.01625575017444583
Epoch #146: loss=0.03376951573192145
Epoch #147: loss=0.013268401328225328
Epoch #148: loss=0.015951306925805344
Epoch #149: loss=0.011364758335546671
Epoch #150: loss=0.015512482293138482
Epoch #151: loss=0.03666907041546453
Epoch #152: loss=0.019429588554797234
Epoch #153: loss=0.01654636155790714
Epoch #154: loss=0.012977173886812677
Epoch #155: loss=0.018016086757947997
Epoch #156: loss=0.018023529283314108
Epoch #157: loss=0.013691543545744865
Epoch #158: loss=0.016272857404214656
Epoch #159: loss=0.013029125851735091
Epoch #160: loss=0.01344082160827696
Epoch #161: loss=0.024241172553135543
Epoch #162: loss=0.016026783571868795
Epoch #163: loss=0.022584713766173332
Epoch #164: loss=0.014925486591020264
Epoch #165: loss=0.014858001646220715
Epoch #166: loss=0.011500507140392824
Epoch #167: loss=0.01471531480640093
Epoch #168: loss=0.013777252150908463
Epoch #169: loss=0.016048532216345317
Epoch #170: loss=0.02068043520194904
Epoch #171: loss=0.014047032858405025
Epoch #172: loss=0.03290039984769913
Epoch #173: loss=0.01556828713777844
Epoch #174: loss=0.010155471884277895
Epoch #175: loss=0.008194351455708192
Epoch #176: loss=0.014995458619211158
Epoch #177: loss=0.02129837012155771
Epoch #178: loss=0.012427642618994799
Epoch #179: loss=0.07055464516560885
Epoch #180: loss=0.021597568338177067
Epoch #181: loss=0.020538932330380105
Epoch #182: loss=0.01043434786054672
Epoch #183: loss=0.018318232983947986
Epoch #184: loss=0.011883466410350024
Epoch #185: loss=0.010594849615974398
Epoch #186: loss=0.012634415071943924
Epoch #187: loss=0.012461063418365819
Epoch #188: loss=0.018344051069502623
Epoch #189: loss=0.015443508074698851
Epoch #190: loss=0.01330941030344477
Epoch #191: loss=0.010721756388830573
Epoch #192: loss=0.011072231875780913
Epoch #193: loss=0.017731316071784076
Epoch #194: loss=0.031612591155963675
Epoch #195: loss=0.017198800542740113
Epoch #196: loss=0.010122377229525534
Epoch #197: loss=0.008909817649502374
Epoch #198: loss=0.014055711687763397
Epoch #199: loss=0.016919503484432098
Epoch #200: loss=0.009285725712749741
Epoch #201: loss=0.022260107139997452
Epoch #202: loss=0.016906103463582255
Epoch #203: loss=0.016877034002653172
Epoch #204: loss=0.022280460609241784
Epoch #205: loss=0.01759944041243463
Epoch #206: loss=0.012047333033917307
Epoch #207: loss=0.018930377078696006
Epoch #208: loss=0.018800927475149616
Epoch #209: loss=0.015188679056596191
Epoch #210: loss=0.014993046500998707
Epoch #211: loss=0.023023514496130285
Epoch #212: loss=0.012521789683650798
Epoch #213: loss=0.012517315105804684
Epoch #214: loss=0.009803325539810191
Epoch #215: loss=0.00897390917691704
Epoch #216: loss=0.016182737003951727
Epoch #217: loss=0.014084254979856384
Epoch #218: loss=0.012910169829602205
Epoch #219: loss=0.025226940745307222
Epoch #220: loss=0.018111866903671905
Epoch #221: loss=0.014708366128616035
Epoch #222: loss=0.011953406129477295
Epoch #223: loss=0.008624598937360003
Epoch #224: loss=0.011563406391743277
Epoch #225: loss=0.022050027258422
Epoch #226: loss=0.014995094764251468
Epoch #227: loss=0.014976974696029297
Epoch #228: loss=0.011410261171955713
Epoch #229: loss=0.013975029339797156
Epoch #230: loss=0.012905691314757597
Epoch #231: loss=0.014937527603830967
Epoch #232: loss=0.012918097103208721
Epoch #233: loss=0.011608600667084456
Epoch #234: loss=0.04366732268723842
Epoch #235: loss=0.01361586783278651
Epoch #236: loss=0.010492380120091068
Epoch #237: loss=0.011553924088866173
Epoch #238: loss=0.016193475373027396
Epoch #239: loss=0.016165779935375987
Epoch #240: loss=0.010849033468586736
Epoch #241: loss=0.014510251836911866
Epoch #242: loss=0.016765784801076194
Epoch #243: loss=0.012373202439743273
Epoch #244: loss=0.009467816723160752
Epoch #245: loss=0.014627017971877024
Epoch #246: loss=0.015184265250772872
Epoch #247: loss=0.013990467211339298
Epoch #248: loss=0.017713457876442316
Epoch #249: loss=0.012680192915687255

Training time: 1:45:13.552108

Finished.
n2one setting etth1_etth2_electricity_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_electricity_weather_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_etth2_electricity_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.43687e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.30634472960825454, 'MAE': 0.37628287303669294}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_electricity_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_electricity_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.6886633757947138
Epoch #1: loss=0.7255772418252928
Epoch #2: loss=0.4749300055879198
Epoch #3: loss=0.3836067467927933
Epoch #4: loss=0.34938307940612384
Epoch #5: loss=0.2991027546172239
Epoch #6: loss=0.25407556503055395
Epoch #7: loss=0.23422158835320014
Epoch #8: loss=0.21523766147933965
Epoch #9: loss=0.19434707739957915
Epoch #10: loss=0.16168028181391625
Epoch #11: loss=0.15146258669978677
Epoch #12: loss=0.14976563444768373
Epoch #13: loss=0.15155200630904286
Epoch #14: loss=0.1300093497505341
Epoch #15: loss=0.12767180988331578
Epoch #16: loss=0.09739342730481493
Epoch #17: loss=0.11202989113530681
Epoch #18: loss=0.09228980603136405
Epoch #19: loss=0.08713824079038016
Epoch #20: loss=0.09600348413023153
Epoch #21: loss=0.07130571144684585
Epoch #22: loss=0.07817178727847146
Epoch #23: loss=0.07346722613694281
Epoch #24: loss=0.09581626315245476
Epoch #25: loss=0.0660871087312807
Epoch #26: loss=0.06001660791999571
Epoch #27: loss=0.05862949261137722
Epoch #28: loss=0.06957455940881294
Epoch #29: loss=0.05677052352946719
Epoch #30: loss=0.057094947415955215
Epoch #31: loss=0.06231170728851555
Epoch #32: loss=0.057908137627597625
Epoch #33: loss=0.049262843625592856
Epoch #34: loss=0.050610881373449164
Epoch #35: loss=0.05025721641471908
Epoch #36: loss=0.042628338658888945
Epoch #37: loss=0.05503274110531429
Epoch #38: loss=0.0534059561791751
Epoch #39: loss=0.04924866248332181
Epoch #40: loss=0.0475059512041444
Epoch #41: loss=0.05347106592192073
Epoch #42: loss=0.04084568923005275
Epoch #43: loss=0.040710026447854
Epoch #44: loss=0.03894774555690239
Epoch #45: loss=0.03220516387403755
Epoch #46: loss=0.05332756461100463
Epoch #47: loss=0.03880921969327359
Epoch #48: loss=0.04622065475001475
Epoch #49: loss=0.035970417496886745
Epoch #50: loss=0.03560914881337358
Epoch #51: loss=0.0321330442120465
Epoch #52: loss=0.0350317689685189
Epoch #53: loss=0.0558797522691016
Epoch #54: loss=0.03234255110502851
Epoch #55: loss=0.03427213572750395
Epoch #56: loss=0.0364635675421267
Epoch #57: loss=0.028137067860635894
Epoch #58: loss=0.03104033538801514
Epoch #59: loss=0.032352195853780165
Epoch #60: loss=0.047709035837843625
Epoch #61: loss=0.048644751297111787
Epoch #62: loss=0.031141566916683867
Epoch #63: loss=0.028421239462768002
Epoch #64: loss=0.03431380862429868
Epoch #65: loss=0.03773413068593178
Epoch #66: loss=0.03147921817846944
Epoch #67: loss=0.023012384966948497
Epoch #68: loss=0.0283858749184638
Epoch #69: loss=0.022803209903622834
Epoch #70: loss=0.02601379007318277
Epoch #71: loss=0.030693288587723418
Epoch #72: loss=0.033091110184805
Epoch #73: loss=0.029061777834541575
Epoch #74: loss=0.03988862167446502
Epoch #75: loss=0.02093843499496552
Epoch #76: loss=0.022970406774026897
Epoch #77: loss=0.02226799280883652
Epoch #78: loss=0.02985022231086589
Epoch #79: loss=0.03506142741446614
Epoch #80: loss=0.022600065950716983
Epoch #81: loss=0.017976237030607533
Epoch #82: loss=0.021559449177304603
Epoch #83: loss=0.03913996002294731
Epoch #84: loss=0.03129351025436389
Epoch #85: loss=0.027578862065262007
Epoch #86: loss=0.0269782799599847
Epoch #87: loss=0.03070207996193439
Epoch #88: loss=0.03171483000435625
Epoch #89: loss=0.03299732054054259
Epoch #90: loss=0.02564682290667353
Epoch #91: loss=0.030127639097905563
Epoch #92: loss=0.022618430263753816
Epoch #93: loss=0.0324989268746303
Epoch #94: loss=0.029589806755654428
Epoch #95: loss=0.024418608096439077
Epoch #96: loss=0.02294279330982976
Epoch #97: loss=0.026614662865142857
Epoch #98: loss=0.019760823099597008
Epoch #99: loss=0.020905165513400423
Epoch #100: loss=0.017770023092643816
Epoch #101: loss=0.02430020487540111
Epoch #102: loss=0.02657717798833814
Epoch #103: loss=0.03640750488918003
Epoch #104: loss=0.01867186873638731
Epoch #105: loss=0.026521945550071167
Epoch #106: loss=0.02316707088109703
Epoch #107: loss=0.027665925526322185
Epoch #108: loss=0.023761161916302762
Epoch #109: loss=0.018311797728783753
Epoch #110: loss=0.018124284388181148
Epoch #111: loss=0.02393498105531879
Epoch #112: loss=0.021346104310780666
Epoch #113: loss=0.01353850655811608
Epoch #114: loss=0.024485299832024
Epoch #115: loss=0.025207002087375394
Epoch #116: loss=0.021959722136098446
Epoch #117: loss=0.020626705970225513
Epoch #118: loss=0.019279263201054272
Epoch #119: loss=0.03464706609556424
Epoch #120: loss=0.016725095316975407
Epoch #121: loss=0.05503529248319284
Epoch #122: loss=0.02334798416007397
Epoch #123: loss=0.025000796330218414
Epoch #124: loss=0.025421749726453738
Epoch #125: loss=0.040196724782111365
Epoch #126: loss=0.021356811832145137
Epoch #127: loss=0.015227230481936463
Epoch #128: loss=0.016630497855933943
Epoch #129: loss=0.015185113969199908
Epoch #130: loss=0.019581372274354688
Epoch #131: loss=0.030287328865570857
Epoch #132: loss=0.014566055940920296
Epoch #133: loss=0.013087479242716941
Epoch #134: loss=0.02269683844978723
Epoch #135: loss=0.02064998120150282
Epoch #136: loss=0.020794175519932432
Epoch #137: loss=0.014252257039879092
Epoch #138: loss=0.019773475834780778
Epoch #139: loss=0.021460869812994447
Epoch #140: loss=0.02419762231433987
Epoch #141: loss=0.01325274736417862
Epoch #142: loss=0.023428771992549356
Epoch #143: loss=0.03440100186994522
Epoch #144: loss=0.026257921834666357
Epoch #145: loss=0.015736465735541542
Epoch #146: loss=0.01583641769181877
Epoch #147: loss=0.012848143855791333
Epoch #148: loss=0.014260680638572727
Epoch #149: loss=0.017652990192286236
Epoch #150: loss=0.014799120719883993
Epoch #151: loss=0.01225169666398944
Epoch #152: loss=0.024589648277671197
Epoch #153: loss=0.019024007240108026
Epoch #154: loss=0.016372813163196217
Epoch #155: loss=0.02448925045563272
Epoch #156: loss=0.021083412984516416
Epoch #157: loss=0.014489015130565091
Epoch #158: loss=0.019841141826775245
Epoch #159: loss=0.03660097470202921
Epoch #160: loss=0.029398317242607355
Epoch #161: loss=0.021561375605492275
Epoch #162: loss=0.013946138027581623
Epoch #163: loss=0.022231320432066895
Epoch #164: loss=0.01667072227833597
Epoch #165: loss=0.018987910464302836
Epoch #166: loss=0.017387178908584166
Epoch #167: loss=0.014139420509850198
Epoch #168: loss=0.02427081796632531
Epoch #169: loss=0.025196877289013583
Epoch #170: loss=0.03180678143049251
Epoch #171: loss=0.02264512171147462
Epoch #172: loss=0.023415184221379785
Epoch #173: loss=0.023615479709087728
Epoch #174: loss=0.021779537773840455
Epoch #175: loss=0.020281487623258133
Epoch #176: loss=0.017800053009446357
Epoch #177: loss=0.026895179756904843
Epoch #178: loss=0.021735068084129047
Epoch #179: loss=0.02124548243099427
Epoch #180: loss=0.025067335549428374
Epoch #181: loss=0.023583370098320133
Epoch #182: loss=0.01897582065235313
Epoch #183: loss=0.013271875253287293
Epoch #184: loss=0.01662787015898745
Epoch #185: loss=0.014951883569840374
Epoch #186: loss=0.015466007641102553
Epoch #187: loss=0.016980791280152
Epoch #188: loss=0.022498245269559736
Epoch #189: loss=0.021232606291074478
Epoch #190: loss=0.01927942252153145
Epoch #191: loss=0.016951459096205004
Epoch #192: loss=0.01749539916093377
Epoch #193: loss=0.014790290766721455
Epoch #194: loss=0.0154957878275453
Epoch #195: loss=0.012769023271287051
Epoch #196: loss=0.014794380976543585
Epoch #197: loss=0.010627878177843162
Epoch #198: loss=0.009217728448852845
Epoch #199: loss=0.01761708380118197
Epoch #200: loss=0.015183942066726163
Epoch #201: loss=0.011365189648751963
Epoch #202: loss=0.017247073558015264
Epoch #203: loss=0.02461025723949911
Epoch #204: loss=0.0222643015706985
Epoch #205: loss=0.012959784923371473
Epoch #206: loss=0.015071193561868867
Epoch #207: loss=0.014438745723874376
Epoch #208: loss=0.014521150329793769
Epoch #209: loss=0.011563702934128355
Epoch #210: loss=0.012826437172571566
Epoch #211: loss=0.025788928638857248
Epoch #212: loss=0.02062345683810901
Epoch #213: loss=0.01872833184208911
Epoch #214: loss=0.023940574048723722
Epoch #215: loss=0.019706907969765073
Epoch #216: loss=0.014793221261107931
Epoch #217: loss=0.01790049673993488
Epoch #218: loss=0.017222284333937892
Epoch #219: loss=0.02870738104226084
Epoch #220: loss=0.024417163608507483
Epoch #221: loss=0.01241122852364669
Epoch #222: loss=0.016358025611986463
Epoch #223: loss=0.0206989838481058
Epoch #224: loss=0.012580831218836692
Epoch #225: loss=0.014986904599682127
Epoch #226: loss=0.014039326521619589
Epoch #227: loss=0.01336807149812666
Epoch #228: loss=0.013313497026191628
Epoch #229: loss=0.02005231128167225
Epoch #230: loss=0.01191740426288866
Epoch #231: loss=0.011330648131329843
Epoch #232: loss=0.018512458701206658
Epoch #233: loss=0.01732119812663039
Epoch #234: loss=0.015873713225975455
Epoch #235: loss=0.025250416828737576
Epoch #236: loss=0.028517637372630546
Epoch #237: loss=0.016521338863860348
Epoch #238: loss=0.010823016694703468
Epoch #239: loss=0.024972411400181006
Epoch #240: loss=0.012480700639709179
Epoch #241: loss=0.013192865243229103
Epoch #242: loss=0.01264794892716322
Epoch #243: loss=0.014981088791593758
Epoch #244: loss=0.011947981196706137
Epoch #245: loss=0.014621172321596489
Epoch #246: loss=0.023078723928046687
Epoch #247: loss=0.012804346133645287
Epoch #248: loss=0.019582998081016743
Epoch #249: loss=0.01574519719675987

Training time: 1:33:52.731760

Finished.
n2one setting etth1_etth2_electricity_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_electricity_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_etth2_electricity_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.65156e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.24902e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.65156e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.5489353362331237, 'MAE': 0.5428387772449103}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_traffic_weather', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_traffic_weather_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.1413005648920118
Epoch #1: loss=0.46194467804252176
Epoch #2: loss=0.321282577091733
Epoch #3: loss=0.27098132788870655
Epoch #4: loss=0.21630201510209465
Epoch #5: loss=0.17632113627990306
Epoch #6: loss=0.15191631626230387
Epoch #7: loss=0.12163270849470223
Epoch #8: loss=0.11615550781945035
Epoch #9: loss=0.11429400842000799
Epoch #10: loss=0.08683079861810725
Epoch #11: loss=0.09809457301110558
Epoch #12: loss=0.0782041968256359
Epoch #13: loss=0.06943325008040588
Epoch #14: loss=0.06833181182849747
Epoch #15: loss=0.06674927152732507
Epoch #16: loss=0.07521526526996325
Epoch #17: loss=0.04993034680059052
Epoch #18: loss=0.05359254446331858
Epoch #19: loss=0.05714107484648628
Epoch #20: loss=0.042737126451588656
Epoch #21: loss=0.05251531317229166
Epoch #22: loss=0.04573336293344735
Epoch #23: loss=0.037565769234304616
Epoch #24: loss=0.03719153063706827
Epoch #25: loss=0.03878916169417621
Epoch #26: loss=0.044104541348476176
Epoch #27: loss=0.034124114862725784
Epoch #28: loss=0.03381569640793034
Epoch #29: loss=0.03423603325491119
Epoch #30: loss=0.035112989950639106
Epoch #31: loss=0.0338516123116609
Epoch #32: loss=0.03160591527781947
Epoch #33: loss=0.024696642036824396
Epoch #34: loss=0.03451681501592691
Epoch #35: loss=0.03129390407298917
Epoch #36: loss=0.024867162819819613
Epoch #37: loss=0.03873374301280946
Epoch #38: loss=0.02387897861967103
Epoch #39: loss=0.033877677537468336
Epoch #40: loss=0.02750940138724232
Epoch #41: loss=0.024533516573156965
Epoch #42: loss=0.030779886308813804
Epoch #43: loss=0.029510040062545755
Epoch #44: loss=0.02767568139779844
Epoch #45: loss=0.03310680205817851
Epoch #46: loss=0.024203644772258972
Epoch #47: loss=0.030918408427366827
Epoch #48: loss=0.037644025272490486
Epoch #49: loss=0.022091003076509963
Epoch #50: loss=0.02044243915298202
Epoch #51: loss=0.026507420332027503
Epoch #52: loss=0.022653971654683053
Epoch #53: loss=0.020899561199423097
Epoch #54: loss=0.021528584306670907
Epoch #55: loss=0.02086539711945684
Epoch #56: loss=0.02350932307527948
Epoch #57: loss=0.021645906860134803
Epoch #58: loss=0.03252655864111664
Epoch #59: loss=0.022647654398733195
Epoch #60: loss=0.019568622312838926
Epoch #61: loss=0.02754359958583552
Epoch #62: loss=0.019926417252643058
Epoch #63: loss=0.022107394116088138
Epoch #64: loss=0.023162536226982715
Epoch #65: loss=0.019665344060577263
Epoch #66: loss=0.02153453183039804
Epoch #67: loss=0.03281920543437392
Epoch #68: loss=0.01672770318052754
Epoch #69: loss=0.02064537758164716
Epoch #70: loss=0.012660515857248684
Epoch #71: loss=0.021885723177926458
Epoch #72: loss=0.02281045587991515
Epoch #73: loss=0.020784825042744287
Epoch #74: loss=0.017081230136101494
Epoch #75: loss=0.01682362399453002
Epoch #76: loss=0.02240579274117517
Epoch #77: loss=0.013185829970658603
Epoch #78: loss=0.025190087001806357
Epoch #79: loss=0.022977511057185686
Epoch #80: loss=0.015347213330503115
Epoch #81: loss=0.016324039234043082
Epoch #82: loss=0.01571840831435966
Epoch #83: loss=0.01872917238635552
Epoch #84: loss=0.018137197902822606
Epoch #85: loss=0.020946262587173407
Epoch #86: loss=0.022463759942788954
Epoch #87: loss=0.017096798370189358
Epoch #88: loss=0.025010199573242308
Epoch #89: loss=0.01412859277126272
Epoch #90: loss=0.018336403111944247
Epoch #91: loss=0.02719932304945761
Epoch #92: loss=0.01566239475640943
Epoch #93: loss=0.01908848007889635
Epoch #94: loss=0.01534984807597815
Epoch #95: loss=0.01599900366769672
Epoch #96: loss=0.017513849968011926
Epoch #97: loss=0.013722086843768364
Epoch #98: loss=0.021046560162908352
Epoch #99: loss=0.016506426146449087
Epoch #100: loss=0.015225073157807351
Epoch #101: loss=0.014310092761859136
Epoch #102: loss=0.013480360351271613
Epoch #103: loss=0.01414403242743476
Epoch #104: loss=0.016290584907770474
Epoch #105: loss=0.012843877306170296
Epoch #106: loss=0.022691007303397306
Epoch #107: loss=0.024592953199873566
Epoch #108: loss=0.013034068776660872
Epoch #109: loss=0.012313376105567436
Epoch #110: loss=0.01785838812578804
Epoch #111: loss=0.019775899701781195
Epoch #112: loss=0.017421932331327154
Epoch #113: loss=0.011903076218754752
Epoch #114: loss=0.01607985452419336
Epoch #115: loss=0.014265354814050727
Epoch #116: loss=0.016804405714306095
Epoch #117: loss=0.014150485911026097
Epoch #118: loss=0.011922146005427828
Epoch #119: loss=0.012974682156810436
Epoch #120: loss=0.011279726227816528
Epoch #121: loss=0.015420941978242834
Epoch #122: loss=0.013607588039442408
Epoch #123: loss=0.015312732718631981
Epoch #124: loss=0.020828996745588416
Epoch #125: loss=0.014559121414371266
Epoch #126: loss=0.01108605111610354
Epoch #127: loss=0.012769347086366567
Epoch #128: loss=0.015090352320121968
Epoch #129: loss=0.011252532539589273
Epoch #130: loss=0.02205247145115866
Epoch #131: loss=0.02308447408506532
Epoch #132: loss=0.015508474899944282
Epoch #133: loss=0.011792846070241158
Epoch #134: loss=0.010667112731472115
Epoch #135: loss=0.013195044034201457
Epoch #136: loss=0.015692773057282602
Epoch #137: loss=0.013569572476130403
Epoch #138: loss=0.012118357559798327
Epoch #139: loss=0.013061012451643044
Epoch #140: loss=0.014913558262017526
Epoch #141: loss=0.008247993344613614
Epoch #142: loss=0.017636052595527363
Epoch #143: loss=0.014123564005709107
Epoch #144: loss=0.011610250643990364
Epoch #145: loss=0.015239969289781859
Epoch #146: loss=0.015589826797725512
Epoch #147: loss=0.010915909012322837
Epoch #148: loss=0.01244853953915757
Epoch #149: loss=0.01397889443610146
Epoch #150: loss=0.017567074747480316
Epoch #151: loss=0.014282318749786416
Epoch #152: loss=0.01689147088027695
Epoch #153: loss=0.010805465606806406
Epoch #154: loss=0.011888708937452423
Epoch #155: loss=0.015886142035402118
Epoch #156: loss=0.011316247191260767
Epoch #157: loss=0.011237398974605262
Epoch #158: loss=0.009574776604886351
Epoch #159: loss=0.015670197053070715
Epoch #160: loss=0.013294993862914987
Epoch #161: loss=0.01130907827000092
Epoch #162: loss=0.02274065921268299
Epoch #163: loss=0.01443559234404829
Epoch #164: loss=0.006833033157644707
Epoch #165: loss=0.01509683324360808
Epoch #166: loss=0.01125181527883359
Epoch #167: loss=0.013815036932546739
Epoch #168: loss=0.013868593673612572
Epoch #169: loss=0.011835736994768526
Epoch #170: loss=0.011675118619157673
Epoch #171: loss=0.014765456977821504
Epoch #172: loss=0.01045808433712524
Epoch #173: loss=0.020363779645250116
Epoch #174: loss=0.012514928237106827
Epoch #175: loss=0.0083864372667078
Epoch #176: loss=0.019799928419382835
Epoch #177: loss=0.022906978483096425
Epoch #178: loss=0.010485621023545132
Epoch #179: loss=0.012164242920524362
Epoch #180: loss=0.010282633016746803
Epoch #181: loss=0.0185071031584344
Epoch #182: loss=0.010349161419745156
Epoch #183: loss=0.011250777413785471
Epoch #184: loss=0.011266722206118983
Epoch #185: loss=0.008380804371415983
Epoch #186: loss=0.02501167285037583
Epoch #187: loss=0.012415493823614482
Epoch #188: loss=0.012828856739966057
Epoch #189: loss=0.006544576007470464
Epoch #190: loss=0.011465255437869202
Epoch #191: loss=0.013387896928453803
Epoch #192: loss=0.011840567181176355
Epoch #193: loss=0.015582398513502115
Epoch #194: loss=0.018469694845835025
Epoch #195: loss=0.011762800905782526
Epoch #196: loss=0.00881710992584613
Epoch #197: loss=0.013807534237992134
Epoch #198: loss=0.013281314927051329
Epoch #199: loss=0.01155867816678619
Epoch #200: loss=0.01560768536904423
Epoch #201: loss=0.012319176205035228
Epoch #202: loss=0.027950521130048325
Epoch #203: loss=0.01738041311903457
Epoch #204: loss=0.012641296537208139
Epoch #205: loss=0.02456439690132798
Epoch #206: loss=0.012807281611901821
Epoch #207: loss=0.012649576132897671
Epoch #208: loss=0.012465330174236663
Epoch #209: loss=0.013239971843429123
Epoch #210: loss=0.0077410618033151015
Epoch #211: loss=0.012601796757546874
Epoch #212: loss=0.015010987713275026
Epoch #213: loss=0.013941963218738989
Epoch #214: loss=0.009372663520165681
Epoch #215: loss=0.019066990947967863
Epoch #216: loss=0.011938680901981094
Epoch #217: loss=0.010484749637808736
Epoch #218: loss=0.0072664057180471175
Epoch #219: loss=0.012831095036079472
Epoch #220: loss=0.008558266456920562
Epoch #221: loss=0.022218558098753022
Epoch #222: loss=0.012720005995003628
Epoch #223: loss=0.009151576536052195
Epoch #224: loss=0.01644728783768306
Epoch #225: loss=0.010351927069732363
Epoch #226: loss=0.010786439096843532
Epoch #227: loss=0.006978639301890662
Epoch #228: loss=0.012238832812783661
Epoch #229: loss=0.008885367466423011
Epoch #230: loss=0.010005448262927126
Epoch #231: loss=0.016521867627676518
Epoch #232: loss=0.01387906107769083
Epoch #233: loss=0.00814706546427014
Epoch #234: loss=0.014196887439204083
Epoch #235: loss=0.017875379884172593
Epoch #236: loss=0.006255494200315031
Epoch #237: loss=0.024368829915314597
Epoch #238: loss=0.008801647854981554
Epoch #239: loss=0.00777827277401423
Epoch #240: loss=0.01131773080506172
Epoch #241: loss=0.011036966978345802
Epoch #242: loss=0.011880064611075375
Epoch #243: loss=0.010578695323325728
Epoch #244: loss=0.015555163749735394
Epoch #245: loss=0.011043544719079581
Epoch #246: loss=0.007319507539123434
Epoch #247: loss=0.011240078986305154
Epoch #248: loss=0.006450665672371002
Epoch #249: loss=0.013864581317174211

Training time: 3:34:03.226591

Finished.
n2one setting etth1_etth2_traffic_weather -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_traffic_weather_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_etth2_traffic_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.9381e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.0291e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.07385e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.9381e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4255169738815389, 'MAE': 0.46561078052156957}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_traffic_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_traffic_weather_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_etth2_traffic_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.46818e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3447647759661569, 'MAE': 0.38589846305412406}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_traffic_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_traffic_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.0235169546771372
Epoch #1: loss=0.38622198388722145
Epoch #2: loss=0.26391535570078034
Epoch #3: loss=0.20621201212252427
Epoch #4: loss=0.1543340217027122
Epoch #5: loss=0.14233690211380837
Epoch #6: loss=0.1093997644467018
Epoch #7: loss=0.09686473162098876
Epoch #8: loss=0.0846218306958945
Epoch #9: loss=0.08290352988082124
Epoch #10: loss=0.0730553106778845
Epoch #11: loss=0.07764477271226349
Epoch #12: loss=0.07629000214592246
Epoch #13: loss=0.058870543338615466
Epoch #14: loss=0.06205946357490925
Epoch #15: loss=0.05085660880631704
Epoch #16: loss=0.05467731769568586
Epoch #17: loss=0.05618421451217069
Epoch #18: loss=0.048415129301580706
Epoch #19: loss=0.04681322509075233
Epoch #20: loss=0.047095503820827
Epoch #21: loss=0.048787382361268394
Epoch #22: loss=0.036274974060042584
Epoch #23: loss=0.04078544329665391
Epoch #24: loss=0.037412561470699573
Epoch #25: loss=0.03997988193201078
Epoch #26: loss=0.04140834164609753
Epoch #27: loss=0.055017828846263925
Epoch #28: loss=0.02984004633815125
Epoch #29: loss=0.030916517543658085
Epoch #30: loss=0.032066733265170254
Epoch #31: loss=0.029685433557608935
Epoch #32: loss=0.03419096214099939
Epoch #33: loss=0.026803790318923982
Epoch #34: loss=0.03070174352509787
Epoch #35: loss=0.02884144103747152
Epoch #36: loss=0.02922240670202026
Epoch #37: loss=0.029743098328245607
Epoch #38: loss=0.041130395552956785
Epoch #39: loss=0.02219501542507163
Epoch #40: loss=0.03097093256023961
Epoch #41: loss=0.028135274529269564
Epoch #42: loss=0.03281562649384162
Epoch #43: loss=0.02262893928308672
Epoch #44: loss=0.023059623665308025
Epoch #45: loss=0.03557424075960506
Epoch #46: loss=0.03802885784245016
Epoch #47: loss=0.02127420285948957
Epoch #48: loss=0.022933459248037153
Epoch #49: loss=0.021147793664156336
Epoch #50: loss=0.023646068545066273
Epoch #51: loss=0.028895304027346396
Epoch #52: loss=0.019294701279517646
Epoch #53: loss=0.02696180903205039
Epoch #54: loss=0.02465014413455596
Epoch #55: loss=0.024250335567665066
Epoch #56: loss=0.02271963221886737
Epoch #57: loss=0.02623695700152301
Epoch #58: loss=0.02075172339425998
Epoch #59: loss=0.020603446334869626
Epoch #60: loss=0.020732549806146534
Epoch #61: loss=0.02682039949562816
Epoch #62: loss=0.021044377545979952
Epoch #63: loss=0.02667499317868117
Epoch #64: loss=0.020247052405482555
Epoch #65: loss=0.02390067842563802
Epoch #66: loss=0.017171677091562955
Epoch #67: loss=0.022734254369737656
Epoch #68: loss=0.02420799782443307
Epoch #69: loss=0.020157141727461202
Epoch #70: loss=0.01739956783909062
Epoch #71: loss=0.040371226885014135
Epoch #72: loss=0.02137148333687074
Epoch #73: loss=0.01700402146535325
Epoch #74: loss=0.015470213458066852
Epoch #75: loss=0.0255828156741494
Epoch #76: loss=0.02194435138036618
Epoch #77: loss=0.0208011471917729
Epoch #78: loss=0.02168426364474578
Epoch #79: loss=0.01966196767987401
Epoch #80: loss=0.019125954066737706
Epoch #81: loss=0.027621441001227397
Epoch #82: loss=0.017729667431321438
Epoch #83: loss=0.018628146472859524
Epoch #84: loss=0.020182412449253104
Epoch #85: loss=0.016824133208361812
Epoch #86: loss=0.01996481129414996
Epoch #87: loss=0.014952247762933468
Epoch #88: loss=0.024069513050192438
Epoch #89: loss=0.02026598911793145
Epoch #90: loss=0.04072393413823534
Epoch #91: loss=0.02509468463645896
Epoch #92: loss=0.016778279625353977
Epoch #93: loss=0.045927185870955144
Epoch #94: loss=0.019010728993861328
Epoch #95: loss=0.016717856772477335
Epoch #96: loss=0.014296206073533655
Epoch #97: loss=0.019109030619826762
Epoch #98: loss=0.01879530466390548
Epoch #99: loss=0.022181501855367342
Epoch #100: loss=0.018494582364158664
Epoch #101: loss=0.01532806472774338
Epoch #102: loss=0.016994081594103132
Epoch #103: loss=0.016036641627068925
Epoch #104: loss=0.024730792790477487
Epoch #105: loss=0.02081909628817219
Epoch #106: loss=0.017863749171334858
Epoch #107: loss=0.013777767789948624
Epoch #108: loss=0.015393945700539027
Epoch #109: loss=0.015191470152473002
Epoch #110: loss=0.01894951158807517
Epoch #111: loss=0.01714578261894592
Epoch #112: loss=0.018018783646231683
Epoch #113: loss=0.016837097603896983
Epoch #114: loss=0.01671958711665051
Epoch #115: loss=0.01565751818892898
Epoch #116: loss=0.02510026140732831
Epoch #117: loss=0.012795203521308316
Epoch #118: loss=0.01651715716984222
Epoch #119: loss=0.014385537916072224
Epoch #120: loss=0.018919671883068322
Epoch #121: loss=0.01482441439089203
Epoch #122: loss=0.019209760623100494
Epoch #123: loss=0.01987023431612458
Epoch #124: loss=0.015508187767080024
Epoch #125: loss=0.01614416408537844
Epoch #126: loss=0.015934733976310407
Epoch #127: loss=0.015114097150316044
Epoch #128: loss=0.019313264141181626
Epoch #129: loss=0.01186701073954243
Epoch #130: loss=0.02129326463922989
Epoch #131: loss=0.015754307956699222
Epoch #132: loss=0.017154674527139986
Epoch #133: loss=0.013920198374145244
Epoch #134: loss=0.027022981449734626
Epoch #135: loss=0.017401068977331027
Epoch #136: loss=0.01156336921551336
Epoch #137: loss=0.01501751743028956
Epoch #138: loss=0.01704721236436199
Epoch #139: loss=0.022261594889732395
Epoch #140: loss=0.013256045285109546
Epoch #141: loss=0.015021743139124853
Epoch #142: loss=0.01291510485271948
Epoch #143: loss=0.016254568476587055
Epoch #144: loss=0.015252810665190313
Epoch #145: loss=0.01642545258873395
Epoch #146: loss=0.011315722213416703
Epoch #147: loss=0.014315415966930685
Epoch #148: loss=0.018383768334231766
Epoch #149: loss=0.011897344742642027
Epoch #150: loss=0.014345972395459363
Epoch #151: loss=0.013801982866952299
Epoch #152: loss=0.018853468864569355
Epoch #153: loss=0.0145950851556953
Epoch #154: loss=0.013933356773476718
Epoch #155: loss=0.016639944542517014
Epoch #156: loss=0.01167414278711579
Epoch #157: loss=0.015501763715687402
Epoch #158: loss=0.012006248892565432
Epoch #159: loss=0.020045824192065458
Epoch #160: loss=0.012958955071796452
Epoch #161: loss=0.015537641379190503
Epoch #162: loss=0.017785539296039536
Epoch #163: loss=0.013230600695980964
Epoch #164: loss=0.011758292703835316
Epoch #165: loss=0.012492242217298577
Epoch #166: loss=0.01681053919915997
Epoch #167: loss=0.013978209930025114
Epoch #168: loss=0.009757867441137982
Epoch #169: loss=0.012440817752732933
Epoch #170: loss=0.01273056913276674
Epoch #171: loss=0.014460439501509093
Epoch #172: loss=0.014984076386255716
Epoch #173: loss=0.012406062546289
Epoch #174: loss=0.017097160182564707
Epoch #175: loss=0.015998804746754705
Epoch #176: loss=0.022742712222317833
Epoch #177: loss=0.014777492542733486
Epoch #178: loss=0.011038441514534184
Epoch #179: loss=0.010154650153576953
Epoch #180: loss=0.014588357945610793
Epoch #181: loss=0.015599311350198722
Epoch #182: loss=0.012378580024282472
Epoch #183: loss=0.014948565639566385
Epoch #184: loss=0.011459447800929024
Epoch #185: loss=0.013476604980122134
Epoch #186: loss=0.011634326921592227
Epoch #187: loss=0.01540724860921205
Epoch #188: loss=0.011725546012533823
Epoch #189: loss=0.011876191683167569
Epoch #190: loss=0.018738702833669615
Epoch #191: loss=0.01343023951683716
Epoch #192: loss=0.009955813466042266
Epoch #193: loss=0.014059286798242263
Epoch #194: loss=0.01587181716923743
Epoch #195: loss=0.012104401269429695
Epoch #196: loss=0.015620975674428172
Epoch #197: loss=0.013991691413941547
Epoch #198: loss=0.012009479990406795
Epoch #199: loss=0.010128708349752722
Epoch #200: loss=0.012487883975619582
Epoch #201: loss=0.012099797343140232
Epoch #202: loss=0.01167195294649847
Epoch #203: loss=0.01410363320814608
Epoch #204: loss=0.012040657826441334
Epoch #205: loss=0.011332408212710275
Epoch #206: loss=0.01356331403007045
Epoch #207: loss=0.010884457381997401
Epoch #208: loss=0.010972537640513794
Epoch #209: loss=0.013887671925852073
Epoch #210: loss=0.011877320010739307
Epoch #211: loss=0.015128908567577
Epoch #212: loss=0.012146273329793433
Epoch #213: loss=0.013097662932593197
Epoch #214: loss=0.014470886625527306
Epoch #215: loss=0.011560072606184248
Epoch #216: loss=0.01858781953161183
Epoch #217: loss=0.02729289363479722
Epoch #218: loss=0.023051049829584735
Epoch #219: loss=0.014851799067960551
Epoch #220: loss=0.008743431517524183
Epoch #221: loss=0.011294092611768978
Epoch #222: loss=0.009062926943640555
Epoch #223: loss=0.011130412725611364
Epoch #224: loss=0.012824842127801732
Epoch #225: loss=0.010749448378603563
Epoch #226: loss=0.015694051549139266
Epoch #227: loss=0.014256221968017553
Epoch #228: loss=0.009755443503333617
Epoch #229: loss=0.01066496424090272
Epoch #230: loss=0.011915878627545541
Epoch #231: loss=0.01102238589785419
Epoch #232: loss=0.017672650978138787
Epoch #233: loss=0.01640098719962723
Epoch #234: loss=0.010000888851620846
Epoch #235: loss=0.012293203601824216
Epoch #236: loss=0.011743935821589101
Epoch #237: loss=0.010244058437523752
Epoch #238: loss=0.013470860609429288
Epoch #239: loss=0.011413970817832858
Epoch #240: loss=0.023397689348786523
Epoch #241: loss=0.011394005736695762
Epoch #242: loss=0.00856336155066852
Epoch #243: loss=0.013985430355193262
Epoch #244: loss=0.013490793005639634
Epoch #245: loss=0.015230589282155833
Epoch #246: loss=0.010216680218476689
Epoch #247: loss=0.011671456473209734
Epoch #248: loss=0.01162710567081689
Epoch #249: loss=0.009852905442027693

Training time: 3:25:23.203295

Finished.
n2one setting etth1_etth2_traffic_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_traffic_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_etth2_traffic_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.0439e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.0985e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.46508e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.0439e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.40229070877512374, 'MAE': 0.45148375470129015}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_traffic_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_traffic_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_etth2_traffic_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.7636e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.52379e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.7636e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.42242077374459164, 'MAE': 0.46552722508439726}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_weather_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_weather_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=6.567132449398438
Epoch #1: loss=2.957166808346907
Epoch #2: loss=2.3828321446975074
Epoch #3: loss=2.1323377241690955
Epoch #4: loss=2.121283416946729
Epoch #5: loss=1.915585070848465
Epoch #6: loss=1.8308759207526843
Epoch #7: loss=1.8533965547879536
Epoch #8: loss=1.6782471761107445
Epoch #9: loss=1.6138431678215663
Epoch #10: loss=1.600211593012015
Epoch #11: loss=1.4431888187925022
Epoch #12: loss=1.42708374808232
Epoch #13: loss=1.2624551082650821
Epoch #14: loss=1.2296507035692532
Epoch #15: loss=1.1370108959575493
Epoch #16: loss=1.109107930213213
Epoch #17: loss=1.1305476737519105
Epoch #18: loss=1.0281354673206806
Epoch #19: loss=0.9700820830961069
Epoch #20: loss=0.9181450195610523
Epoch #21: loss=0.9850370002289613
Epoch #22: loss=0.9191376765569051
Epoch #23: loss=0.9806952513754368
Epoch #24: loss=1.0008843491474788
Epoch #25: loss=0.9971548852821192
Epoch #26: loss=0.9188963112731775
Epoch #27: loss=0.9000271372497082
Epoch #28: loss=0.8778538443148136
Epoch #29: loss=0.8295799580713114
Epoch #30: loss=0.7974111586809158
Epoch #31: loss=0.7617108126481374
Epoch #32: loss=0.7548850936194261
Epoch #33: loss=0.7377772231896719
Epoch #34: loss=0.751054992278417
Epoch #35: loss=0.6564863591144482
Epoch #36: loss=0.654885392015179
Epoch #37: loss=0.6529942930986484
Epoch #38: loss=0.6940873538454374
Epoch #39: loss=0.6541554567714533
Epoch #40: loss=0.6489812570313612
Epoch #41: loss=0.5960945052405199
Epoch #42: loss=0.5980661753565073
Epoch #43: loss=0.6553553380072117
Epoch #44: loss=0.5449345788607994
Epoch #45: loss=0.6037310026586056
Epoch #46: loss=0.6084839248408874
Epoch #47: loss=0.5314548214276632
Epoch #48: loss=0.5495310239493847
Epoch #49: loss=0.6038297234723965
Epoch #50: loss=0.6045955612013737
Epoch #51: loss=0.5797961708158255
Epoch #52: loss=0.521754685168465
Epoch #53: loss=0.5156599370141824
Epoch #54: loss=0.5357215243081251
Epoch #55: loss=0.49433595438798267
Epoch #56: loss=0.4442806902031104
Epoch #57: loss=0.5050969788183769
Epoch #58: loss=0.46785787492990494
Epoch #59: loss=0.3899417727564772
Epoch #60: loss=0.4211599665383498
Epoch #61: loss=0.3844840256497264
Epoch #62: loss=0.3936632989595334
Epoch #63: loss=0.49497293836126727
Epoch #64: loss=0.4053667827198903
Epoch #65: loss=0.40310598133752745
Epoch #66: loss=0.4336495414997141
Epoch #67: loss=0.4125565638144811
Epoch #68: loss=0.44680409661183756
Epoch #69: loss=0.40488968261828023
Epoch #70: loss=0.4467339174201091
Epoch #71: loss=0.48766389085600775
Epoch #72: loss=0.4130537534753482
Epoch #73: loss=0.40945590132226545
Epoch #74: loss=0.4296657694503665
Epoch #75: loss=0.4595392591630419
Epoch #76: loss=0.3902494615564744
Epoch #77: loss=0.40070350002497435
Epoch #78: loss=0.33186484066148597
Epoch #79: loss=0.32259899533043307
Epoch #80: loss=0.30265364920099574
Epoch #81: loss=0.30034867332627374
Epoch #82: loss=0.2870688062782089
Epoch #83: loss=0.3300439889232318
Epoch #84: loss=0.3078148141503334
Epoch #85: loss=0.3449805624162157
Epoch #86: loss=0.3035585987381637
Epoch #87: loss=0.3387432772045334
Epoch #88: loss=0.34681395286073285
Epoch #89: loss=0.3876484362408519
Epoch #90: loss=0.25808625388890505
Epoch #91: loss=0.34111618995666504
Epoch #92: loss=0.3928075139410794
Epoch #93: loss=0.3900771575669448
Epoch #94: loss=0.3064380938497682
Epoch #95: loss=0.3422870469900469
Epoch #96: loss=0.25321405303354066
Epoch #97: loss=0.26546180713921785
Epoch #98: loss=0.3192454168262581
Epoch #99: loss=0.360137568321079
Epoch #100: loss=0.3508768482133746
Epoch #101: loss=0.26494051919629175
Epoch #102: loss=0.3508372415478031
Epoch #103: loss=0.29992656596004963
Epoch #104: loss=0.29307412666579086
Epoch #105: loss=0.30456575953091186
Epoch #106: loss=0.26530630482981604
Epoch #107: loss=0.2479664678685367
Epoch #108: loss=0.25321986464162666
Epoch #109: loss=0.23815297024945417
Epoch #110: loss=0.22316388227045536
Epoch #111: loss=0.22221071102345982
Epoch #112: loss=0.200984526037549
Epoch #113: loss=0.19115889995979765
Epoch #114: loss=0.19259278980704644
Epoch #115: loss=0.22434553255637488
Epoch #116: loss=0.19255191033395627
Epoch #117: loss=0.1990006333993127
Epoch #118: loss=0.22928684507496655
Epoch #119: loss=0.21747148999323448
Epoch #120: loss=0.19697577428693572
Epoch #121: loss=0.2549225843977183
Epoch #122: loss=0.17544554802589118
Epoch #123: loss=0.16424857887128988
Epoch #124: loss=0.1671431240004798
Epoch #125: loss=0.18557052539351085
Epoch #126: loss=0.18604316849571964
Epoch #127: loss=0.193328704762583
Epoch #128: loss=0.19208176232253513
Epoch #129: loss=0.2690722818175952
Epoch #130: loss=0.2041124285509189
Epoch #131: loss=0.19277604296803474
Epoch #132: loss=0.23694601111734906
Epoch #133: loss=0.18368772774313888
Epoch #134: loss=0.15227881337826452
Epoch #135: loss=0.1671142993339648
Epoch #136: loss=0.15472773811779916
Epoch #137: loss=0.179643625083069
Epoch #138: loss=0.18187662563286722
Epoch #139: loss=0.1483450735298296
Epoch #140: loss=0.20962859534968933
Epoch #141: loss=0.19703422494543096
Epoch #142: loss=0.170323253221189
Epoch #143: loss=0.1607279002200812
Epoch #144: loss=0.17542159014071027
Epoch #145: loss=0.16010653871732453
Epoch #146: loss=0.15717071651791534
Epoch #147: loss=0.14718103754178932
Epoch #148: loss=0.13396840612404048
Epoch #149: loss=0.17844018922187388
Epoch #150: loss=0.17732073700365922
Epoch #151: loss=0.16397252620663494
Epoch #152: loss=0.18454965576529503
Epoch #153: loss=0.15131773749211183
Epoch #154: loss=0.15820618633491298
Epoch #155: loss=0.146423489243413
Epoch #156: loss=0.13848318074208996
Epoch #157: loss=0.1333189809229225
Epoch #158: loss=0.17125931851721057
Epoch #159: loss=0.16730012116022408
Epoch #160: loss=0.14168378431349993
Epoch #161: loss=0.13415926811285317
Epoch #162: loss=0.13354428279368827
Epoch #163: loss=0.24978571152314544
Epoch #164: loss=0.14129599113948643
Epoch #165: loss=0.14806569697490582
Epoch #166: loss=0.15821201839329055
Epoch #167: loss=0.16184465462962785
Epoch #168: loss=0.24120304252331456
Epoch #169: loss=0.18991913568849364
Epoch #170: loss=0.18708043502798924
Epoch #171: loss=0.1694191804078097
Epoch #172: loss=0.16016200634961328
Epoch #173: loss=0.11943192966282368
Epoch #174: loss=0.12149052713842441
Epoch #175: loss=0.15785870289740464
Epoch #176: loss=0.13155971273469427
Epoch #177: loss=0.1650443848532935
Epoch #178: loss=0.10572211801384886
Epoch #179: loss=0.14475619253547242
Epoch #180: loss=0.12437405809760094
Epoch #181: loss=0.1372812419819335
Epoch #182: loss=0.11349505135634293
Epoch #183: loss=0.09812974988017231
Epoch #184: loss=0.11004939232952893
Epoch #185: loss=0.11975702265044674
Epoch #186: loss=0.10948499614217629
Epoch #187: loss=0.1115479051368311
Epoch #188: loss=0.10886849866559108
Epoch #189: loss=0.22027832607273012
Epoch #190: loss=0.12116414921668668
Epoch #191: loss=0.13169622731705508
Epoch #192: loss=0.16490040727270147
Epoch #193: loss=0.19864374061580747
Epoch #194: loss=0.21708818428063145
Epoch #195: loss=0.4793901907590528
Epoch #196: loss=0.20775724668055773
Epoch #197: loss=0.19211585346298912
Epoch #198: loss=0.14456709598501524
Epoch #199: loss=0.1411498844002684
Epoch #200: loss=0.12965216010343283
Epoch #201: loss=0.12453622460210075
Epoch #202: loss=0.10736454355840881
Epoch #203: loss=0.11144871862294774
Epoch #204: loss=0.12881423144911727
Epoch #205: loss=0.14532200161678097
Epoch #206: loss=0.10813892136017482
Epoch #207: loss=0.09303009502279262
Epoch #208: loss=0.10216551514652868
Epoch #209: loss=0.10984954800611983
Epoch #210: loss=0.11795418876378487
Epoch #211: loss=0.1240347040972362
Epoch #212: loss=0.13467882251522192
Epoch #213: loss=0.10929710934093843
Epoch #214: loss=0.10601740551646799
Epoch #215: loss=0.15231591335032135
Epoch #216: loss=0.13117012742441148
Epoch #217: loss=0.12402559525799006
Epoch #218: loss=0.10219751601107419
Epoch #219: loss=0.09257939263867836
Epoch #220: loss=0.0904824086658967
Epoch #221: loss=0.09719151231305052
Epoch #222: loss=0.11371203822394212
Epoch #223: loss=0.09372064331546426
Epoch #224: loss=0.0716724648567227
Epoch #225: loss=0.07178037974517792
Epoch #226: loss=0.07586839407061537
Epoch #227: loss=0.1412660481679874
Epoch #228: loss=0.09359895880334079
Epoch #229: loss=0.1467419396697854
Epoch #230: loss=0.09720302082132548
Epoch #231: loss=0.12192449875874445
Epoch #232: loss=0.09257381430749471
Epoch #233: loss=0.08968174244121958
Epoch #234: loss=0.11917317918657015
Epoch #235: loss=0.1081731211937343
Epoch #236: loss=0.09061406599357724
Epoch #237: loss=0.09047589059143017
Epoch #238: loss=0.07943704212084413
Epoch #239: loss=0.07348259711094822
Epoch #240: loss=0.0753677390748635
Epoch #241: loss=0.06536983227124438
Epoch #242: loss=0.10904168665486698
Epoch #243: loss=0.09437634966646631
Epoch #244: loss=0.0994914013814802
Epoch #245: loss=0.12448264305324604
Epoch #246: loss=0.08870364069783439
Epoch #247: loss=0.10339216676463063
Epoch #248: loss=0.117674687372831
Epoch #249: loss=0.07505661414082472

Training time: 0:14:00.185638

Finished.
n2one setting etth1_etth2_weather_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_weather_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_etth2_weather_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.77593e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.46739e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.77593e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.37567190437811826, 'MAE': 0.4374354961773058}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm1_ettm2_electricity', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm1_ettm2_electricity_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.7264817234448024
Epoch #1: loss=0.7329569041728974
Epoch #2: loss=0.5000801592639514
Epoch #3: loss=0.4023534532955715
Epoch #4: loss=0.3353247718725886
Epoch #5: loss=0.30903534029211316
Epoch #6: loss=0.251891187195267
Epoch #7: loss=0.23912179629717553
Epoch #8: loss=0.21366191942776952
Epoch #9: loss=0.18464191762464388
Epoch #10: loss=0.17379436599356787
Epoch #11: loss=0.1460156146224056
Epoch #12: loss=0.13900140671857766
Epoch #13: loss=0.12301663569041661
Epoch #14: loss=0.11587304145097732
Epoch #15: loss=0.1151659112636532
Epoch #16: loss=0.09692333791937147
Epoch #17: loss=0.08695757965956416
Epoch #18: loss=0.0872251806674259
Epoch #19: loss=0.08553863050948296
Epoch #20: loss=0.09221505529114178
Epoch #21: loss=0.07398589357467635
Epoch #22: loss=0.0734042272264404
Epoch #23: loss=0.0692125230761511
Epoch #24: loss=0.05714753199767854
Epoch #25: loss=0.05638653783127665
Epoch #26: loss=0.07483757089158254
Epoch #27: loss=0.05651136645781142
Epoch #28: loss=0.044081080637073944
Epoch #29: loss=0.04505145166268838
Epoch #30: loss=0.04982120350136288
Epoch #31: loss=0.04291681927495769
Epoch #32: loss=0.049732600835018924
Epoch #33: loss=0.037835516092101375
Epoch #34: loss=0.05171608932116734
Epoch #35: loss=0.039730238331082676
Epoch #36: loss=0.038317854161640366
Epoch #37: loss=0.04312442848259317
Epoch #38: loss=0.036241901639316766
Epoch #39: loss=0.027680001302090074
Epoch #40: loss=0.0614569821461503
Epoch #41: loss=0.0340738031534212
Epoch #42: loss=0.02702370486687869
Epoch #43: loss=0.02831574436543243
Epoch #44: loss=0.0347192166379786
Epoch #45: loss=0.03500711089133152
Epoch #46: loss=0.03871779670606234
Epoch #47: loss=0.031179534388439997
Epoch #48: loss=0.024974528814532927
Epoch #49: loss=0.02028329251832994
Epoch #50: loss=0.036509600794275426
Epoch #51: loss=0.02565629575933729
Epoch #52: loss=0.02297181685887543
Epoch #53: loss=0.0253082548391207
Epoch #54: loss=0.03133070254897965
Epoch #55: loss=0.024485975766687523
Epoch #56: loss=0.026438863596413283
Epoch #57: loss=0.021720101850306883
Epoch #58: loss=0.026675359765067696
Epoch #59: loss=0.02119563148988943
Epoch #60: loss=0.027305771466344594
Epoch #61: loss=0.0202946630176822
Epoch #62: loss=0.02478205586218142
Epoch #63: loss=0.02407521867858512
Epoch #64: loss=0.02945390076709113
Epoch #65: loss=0.02600735175855724
Epoch #66: loss=0.026096342706587165
Epoch #67: loss=0.02090932974957728
Epoch #68: loss=0.020769851020470794
Epoch #69: loss=0.02321757005826969
Epoch #70: loss=0.028999115241624948
Epoch #71: loss=0.019788286064951015
Epoch #72: loss=0.020369496623918945
Epoch #73: loss=0.018652827198883254
Epoch #74: loss=0.01651374719388384
Epoch #75: loss=0.022943992982951127
Epoch #76: loss=0.028554119756112672
Epoch #77: loss=0.019644873945840767
Epoch #78: loss=0.02013242196657562
Epoch #79: loss=0.02454998695274948
Epoch #80: loss=0.019285839625933606
Epoch #81: loss=0.018867145738830523
Epoch #82: loss=0.02401003926526755
Epoch #83: loss=0.019157540540743086
Epoch #84: loss=0.011370992065473859
Epoch #85: loss=0.020342140340944753
Epoch #86: loss=0.03964446629131479
Epoch #87: loss=0.029012428501820457
Epoch #88: loss=0.015572473704814911
Epoch #89: loss=0.01801908458608003
Epoch #90: loss=0.019838027626475584
Epoch #91: loss=0.03295529949295867
Epoch #92: loss=0.029432834123726933
Epoch #93: loss=0.020969120168260167
Epoch #94: loss=0.019974602975915853
Epoch #95: loss=0.018583909900958782
Epoch #96: loss=0.01748407451469185
Epoch #97: loss=0.01914124230105829
Epoch #98: loss=0.012726469217367205
Epoch #99: loss=0.0228008733121013
Epoch #100: loss=0.02109595894913322
Epoch #101: loss=0.017207929073899453
Epoch #102: loss=0.013967821864145143
Epoch #103: loss=0.013347898860395486
Epoch #104: loss=0.01875265417304555
Epoch #105: loss=0.013461863520289106
Epoch #106: loss=0.012827758887849216
Epoch #107: loss=0.018018260872590224
Epoch #108: loss=0.016599682882328385
Epoch #109: loss=0.018025757187777863
Epoch #110: loss=0.015003670431241126
Epoch #111: loss=0.013964015980101456
Epoch #112: loss=0.013572201514949225
Epoch #113: loss=0.01757772031190273
Epoch #114: loss=0.014257626075996087
Epoch #115: loss=0.022937109168186517
Epoch #116: loss=0.01416967528872192
Epoch #117: loss=0.014798301562051554
Epoch #118: loss=0.015315940177034852
Epoch #119: loss=0.011623915883080501
Epoch #120: loss=0.020401835876816352
Epoch #121: loss=0.021162517502837416
Epoch #122: loss=0.016782033778727053
Epoch #123: loss=0.015226149941528482
Epoch #124: loss=0.012072951237039109
Epoch #125: loss=0.010219795809825882
Epoch #126: loss=0.012579220981403653
Epoch #127: loss=0.0195976667049607
Epoch #128: loss=0.0251936734121825
Epoch #129: loss=0.014450400248668822
Epoch #130: loss=0.011212811810962323
Epoch #131: loss=0.015670320749715236
Epoch #132: loss=0.013650194574812693
Epoch #133: loss=0.023525138188020458
Epoch #134: loss=0.01254289740006373
Epoch #135: loss=0.012261695041088387
Epoch #136: loss=0.0134921206384232
Epoch #137: loss=0.011123118139304488
Epoch #138: loss=0.012611306581446635
Epoch #139: loss=0.01485772794678009
Epoch #140: loss=0.01554780881752127
Epoch #141: loss=0.01675791218161716
Epoch #142: loss=0.013988827412748444
Epoch #143: loss=0.018545572698349132
Epoch #144: loss=0.009946546394078593
Epoch #145: loss=0.015526675109369016
Epoch #146: loss=0.029247464201180264
Epoch #147: loss=0.017014084042790013
Epoch #148: loss=0.008805403825660635
Epoch #149: loss=0.009608749929299977
Epoch #150: loss=0.009523788951503645
Epoch #151: loss=0.016072764017153532
Epoch #152: loss=0.02075153896701522
Epoch #153: loss=0.011863668149869357
Epoch #154: loss=0.01377878516180707
Epoch #155: loss=0.011650852778776815
Epoch #156: loss=0.01251064115203917
Epoch #157: loss=0.010543898515669363
Epoch #158: loss=0.010678538887129564
Epoch #159: loss=0.017024316116502243
Epoch #160: loss=0.012588735432530354
Epoch #161: loss=0.015082249052440082
Epoch #162: loss=0.018364351958734915
Epoch #163: loss=0.020096765933308884
Epoch #164: loss=0.016082338977305752
Epoch #165: loss=0.01229986471988793
Epoch #166: loss=0.015455020832596346
Epoch #167: loss=0.015704941756266636
Epoch #168: loss=0.010117116785009525
Epoch #169: loss=0.03605886098662658
Epoch #170: loss=0.01773432848659078
Epoch #171: loss=0.01120537350686001
Epoch #172: loss=0.0122797274084795
Epoch #173: loss=0.013701927770245155
Epoch #174: loss=0.016538698299721415
Epoch #175: loss=0.011840090976163212
Epoch #176: loss=0.016098380852989588
Epoch #177: loss=0.012968911480857059
Epoch #178: loss=0.01389443257790325
Epoch #179: loss=0.010703556341052587
Epoch #180: loss=0.008194243282112958
Epoch #181: loss=0.011945154871957908
Epoch #182: loss=0.011193361114377954
Epoch #183: loss=0.01471386865687756
Epoch #184: loss=0.02106542376585172
Epoch #185: loss=0.012809103835939563
Epoch #186: loss=0.011922683917551434
Epoch #187: loss=0.012641883336306949
Epoch #188: loss=0.010304930101847276
Epoch #189: loss=0.011759700099521849
Epoch #190: loss=0.017095950089860708
Epoch #191: loss=0.008703270275561538
Epoch #192: loss=0.01733271490383361
Epoch #193: loss=0.01764306294099827
Epoch #194: loss=0.014240987691030438
Epoch #195: loss=0.01160451249169585
Epoch #196: loss=0.009387975530428645
Epoch #197: loss=0.009247276054146434
Epoch #198: loss=0.007698831379945789
Epoch #199: loss=0.014079136200515287
Epoch #200: loss=0.010018838540251766
Epoch #201: loss=0.017355467362296102
Epoch #202: loss=0.012122910644559722
Epoch #203: loss=0.008858988718628617
Epoch #204: loss=0.014962617998743164
Epoch #205: loss=0.014060592904154743
Epoch #206: loss=0.020228960550822583
Epoch #207: loss=0.01943657153053209
Epoch #208: loss=0.011417701580129298
Epoch #209: loss=0.009943772281902576
Epoch #210: loss=0.0071676867434455616
Epoch #211: loss=0.007363229194306768
Epoch #212: loss=0.009954708293828714
Epoch #213: loss=0.018751414988239828
Epoch #214: loss=0.011979057554188849
Epoch #215: loss=0.013098606215374144
Epoch #216: loss=0.008856624941191903
Epoch #217: loss=0.00788620661727951
Epoch #218: loss=0.006864349819287392
Epoch #219: loss=0.01042954713862855
Epoch #220: loss=0.01654419778837889
Epoch #221: loss=0.016253361679513807
Epoch #222: loss=0.009833348123689314
Epoch #223: loss=0.006667003660861935
Epoch #224: loss=0.00800499261306998
Epoch #225: loss=0.01382060374399381
Epoch #226: loss=0.008968954783964103
Epoch #227: loss=0.009702515930403024
Epoch #228: loss=0.011261163242826505
Epoch #229: loss=0.009047582522200953
Epoch #230: loss=0.016408315636716516
Epoch #231: loss=0.014583897045979809
Epoch #232: loss=0.010266032879174289
Epoch #233: loss=0.009018614068024492
Epoch #234: loss=0.010134730103018227
Epoch #235: loss=0.007529369872894936
Epoch #236: loss=0.01222548415476922
Epoch #237: loss=0.01369637452598129
Epoch #238: loss=0.011502892307138869
Epoch #239: loss=0.009048391704896599
Epoch #240: loss=0.0060334519271106855
Epoch #241: loss=0.014485314793086478
Epoch #242: loss=0.011775794534062568
Epoch #243: loss=0.007306814115976782
Epoch #244: loss=0.009701498570086967
Epoch #245: loss=0.012942077721859927
Epoch #246: loss=0.014652734024483444
Epoch #247: loss=0.010815346899492267
Epoch #248: loss=0.007941152039316616
Epoch #249: loss=0.012751541943663531

Training time: 1:38:19.625060

Finished.
n2one setting etth1_ettm1_ettm2_electricity -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_ettm2_electricity_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_ettm1_ettm2_electricity', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.23718e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.53428e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.94051e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.23718e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.5464958074738199, 'MAE': 0.5613487569893459}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm1_ettm2_electricity -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_ettm2_electricity_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_ettm1_ettm2_electricity', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.68201e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.29497691710374463, 'MAE': 0.36466901779858146}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm1_ettm2_traffic', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm1_ettm2_traffic_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.0431340912777165
Epoch #1: loss=0.3894483297227074
Epoch #2: loss=0.2769005943746144
Epoch #3: loss=0.20128898258612613
Epoch #4: loss=0.1720566943990261
Epoch #5: loss=0.13998140736486173
Epoch #6: loss=0.10795091375432632
Epoch #7: loss=0.11014422905285384
Epoch #8: loss=0.08598479716573433
Epoch #9: loss=0.0817041766655231
Epoch #10: loss=0.07058745622269048
Epoch #11: loss=0.06735642793965678
Epoch #12: loss=0.060416465289639905
Epoch #13: loss=0.055810209011447884
Epoch #14: loss=0.05940657946480779
Epoch #15: loss=0.056906982082518195
Epoch #16: loss=0.055678855648941615
Epoch #17: loss=0.04881458273303813
Epoch #18: loss=0.05464428127246807
Epoch #19: loss=0.041006623049487184
Epoch #20: loss=0.035903299172481
Epoch #21: loss=0.03750692563474818
Epoch #22: loss=0.036525154684635776
Epoch #23: loss=0.030529280990941238
Epoch #24: loss=0.02974832911534584
Epoch #25: loss=0.033296066551656366
Epoch #26: loss=0.030403031917930687
Epoch #27: loss=0.0316364331080502
Epoch #28: loss=0.032927000474949876
Epoch #29: loss=0.02917881768879373
Epoch #30: loss=0.027689888896985038
Epoch #31: loss=0.035783048920575364
Epoch #32: loss=0.02475578460607711
Epoch #33: loss=0.030016205951808737
Epoch #34: loss=0.024182891953468958
Epoch #35: loss=0.02519303928719291
Epoch #36: loss=0.02749741917050639
Epoch #37: loss=0.025564313705032742
Epoch #38: loss=0.022333867660818744
Epoch #39: loss=0.01748734927178579
Epoch #40: loss=0.024648575664510456
Epoch #41: loss=0.0215475859686102
Epoch #42: loss=0.021355159678700244
Epoch #43: loss=0.025779335125632727
Epoch #44: loss=0.023830052382298603
Epoch #45: loss=0.017957447914029843
Epoch #46: loss=0.023159372929157533
Epoch #47: loss=0.01815040631668682
Epoch #48: loss=0.02060056072030024
Epoch #49: loss=0.01780948606020521
Epoch #50: loss=0.017445961532209644
Epoch #51: loss=0.02302434504643348
Epoch #52: loss=0.018927083456550132
Epoch #53: loss=0.021580251594759757
Epoch #54: loss=0.020425843402213394
Epoch #55: loss=0.026017306433017466
Epoch #56: loss=0.01866148105128323
Epoch #57: loss=0.02064316363280152
Epoch #58: loss=0.01677223097266578
Epoch #59: loss=0.016439971228332156
Epoch #60: loss=0.020712038972004767
Epoch #61: loss=0.019820434110896092
Epoch #62: loss=0.016439286545303144
Epoch #63: loss=0.016695137674676976
Epoch #64: loss=0.023838802462448412
Epoch #65: loss=0.01805544582019324
Epoch #66: loss=0.021474912764536433
Epoch #67: loss=0.017444711546046456
Epoch #68: loss=0.01755156729806227
Epoch #69: loss=0.01358683639343574
Epoch #70: loss=0.014588085898817762
Epoch #71: loss=0.016532394064541468
Epoch #72: loss=0.018191057789487257
Epoch #73: loss=0.017103631290064668
Epoch #74: loss=0.01686464966531931
Epoch #75: loss=0.017987775735245595
Epoch #76: loss=0.014858605392581933
Epoch #77: loss=0.017366610894616753
Epoch #78: loss=0.015457632473691373
Epoch #79: loss=0.018967397500291534
Epoch #80: loss=0.016598153220399207
Epoch #81: loss=0.013253501633567083
Epoch #82: loss=0.018489889408773757
Epoch #83: loss=0.014583587478263582
Epoch #84: loss=0.016642631026477197
Epoch #85: loss=0.018274148939335228
Epoch #86: loss=0.01573204301073196
Epoch #87: loss=0.018743255125673847
Epoch #88: loss=0.013585240247978973
Epoch #89: loss=0.01725683656220296
Epoch #90: loss=0.011113206204529966
Epoch #91: loss=0.01371492295585809
Epoch #92: loss=0.021512071282884283
Epoch #93: loss=0.010486669767187809
Epoch #94: loss=0.017715021724180047
Epoch #95: loss=0.016177876131879803
Epoch #96: loss=0.01142484813385202
Epoch #97: loss=0.011928592201316568
Epoch #98: loss=0.016317988768079883
Epoch #99: loss=0.014728891268898038
Epoch #100: loss=0.015922969784083287
Epoch #101: loss=0.017190961387863187
Epoch #102: loss=0.013824105507966734
Epoch #103: loss=0.013862572873619309
Epoch #104: loss=0.011761695059918795
Epoch #105: loss=0.015168329893317916
Epoch #106: loss=0.018459209107441615
Epoch #107: loss=0.014764249002925245
Epoch #108: loss=0.014970432337148504
Epoch #109: loss=0.017837922413484326
Epoch #110: loss=0.032299396140441715
Epoch #111: loss=0.014458927654081905
Epoch #112: loss=0.01238285228355911
Epoch #113: loss=0.011906373204709648
Epoch #114: loss=0.012234379007361096
Epoch #115: loss=0.010762451422575462
Epoch #116: loss=0.012231013826922934
Epoch #117: loss=0.013490787771748385
Epoch #118: loss=0.009980923079491172
Epoch #119: loss=0.016688681545606727
Epoch #120: loss=0.010828412948864174
Epoch #121: loss=0.0105611598280011
Epoch #122: loss=0.013317552384904315
Epoch #123: loss=0.016333069333532384
Epoch #124: loss=0.010358307754093578
Epoch #125: loss=0.014517803212626985
Epoch #126: loss=0.017247738399197673
Epoch #127: loss=0.013041423819162156
Epoch #128: loss=0.013069364310229955
Epoch #129: loss=0.0125326666258841
Epoch #130: loss=0.01078788439262926
Epoch #131: loss=0.010476231633023882
Epoch #132: loss=0.012362393577032808
Epoch #133: loss=0.01671558903410297
Epoch #134: loss=0.014559854947471642
Epoch #135: loss=0.00957544974162262
Epoch #136: loss=0.014189552432345213
Epoch #137: loss=0.01193707702301472
Epoch #138: loss=0.010578040785248172
Epoch #139: loss=0.01973306453755694
Epoch #140: loss=0.01130190719171272
Epoch #141: loss=0.013484604075730294
Epoch #142: loss=0.0147325117190658
Epoch #143: loss=0.010247367734641062
Epoch #144: loss=0.011581290648164
Epoch #145: loss=0.01681367678560385
Epoch #146: loss=0.018109203516209066
Epoch #147: loss=0.012195848399052274
Epoch #148: loss=0.011860936277913918
Epoch #149: loss=0.012840486602349061
Epoch #150: loss=0.01911413736172218
Epoch #151: loss=0.011429053452783776
Epoch #152: loss=0.007135172315546759
Epoch #153: loss=0.008992730897089428
Epoch #154: loss=0.016488723243415167
Epoch #155: loss=0.014544439047994928
Epoch #156: loss=0.013296022473064363
Epoch #157: loss=0.014112339958841674
Epoch #158: loss=0.008653798251713222
Epoch #159: loss=0.011711699906304138
Epoch #160: loss=0.009470905823328383
Epoch #161: loss=0.013136245092109481
Epoch #162: loss=0.011999559057675257
Epoch #163: loss=0.010544563974196345
Epoch #164: loss=0.015953637660431647
Epoch #165: loss=0.010544578204042247
Epoch #166: loss=0.014024641695734183
Epoch #167: loss=0.012163417300632862
Epoch #168: loss=0.009700684400185719
Epoch #169: loss=0.011649458364891379
Epoch #170: loss=0.009800554602684565
Epoch #171: loss=0.014918672216196563
Epoch #172: loss=0.012032928620817873
Epoch #173: loss=0.01185648291066091
Epoch #174: loss=0.011910230763196186
Epoch #175: loss=0.01116800346743568
Epoch #176: loss=0.0121113371528833
Epoch #177: loss=0.007704424288905959
Epoch #178: loss=0.012216751341040739
Epoch #179: loss=0.009413267954052245
Epoch #180: loss=0.01082220905357917
Epoch #181: loss=0.014735926801271372
Epoch #182: loss=0.008106073296722834
Epoch #183: loss=0.014682470948659312
Epoch #184: loss=0.0077261923108970865
Epoch #185: loss=0.013171289257465978
Epoch #186: loss=0.014289502335561274
Epoch #187: loss=0.009239420548611734
Epoch #188: loss=0.011137933591819723
Epoch #189: loss=0.013638124377155121
Epoch #190: loss=0.01160790265977655
Epoch #191: loss=0.00913843610108055
Epoch #192: loss=0.012011534055161465
Epoch #193: loss=0.008875996676654771
Epoch #194: loss=0.012317459631699355
Epoch #195: loss=0.006362655146233529
Epoch #196: loss=0.013437974334412683
Epoch #197: loss=0.009314837379112038
Epoch #198: loss=0.01120601184260467
Epoch #199: loss=0.009295769277392174
Epoch #200: loss=0.01029484354156493
Epoch #201: loss=0.007925198344185515
Epoch #202: loss=0.012986349343577914
Epoch #203: loss=0.010060799835746538
Epoch #204: loss=0.016508132016551356
Epoch #205: loss=0.011298126421004374
Epoch #206: loss=0.009112374632523925
Epoch #207: loss=0.008077020943992864
Epoch #208: loss=0.013259454418095791
Epoch #209: loss=0.011501124731811677
Epoch #210: loss=0.00986029507012073
Epoch #211: loss=0.011010326414626964
Epoch #212: loss=0.010109955070550892
Epoch #213: loss=0.010305473450021887
Epoch #214: loss=0.007914119856272678
Epoch #215: loss=0.012223896853865922
Epoch #216: loss=0.008895213790026892
Epoch #217: loss=0.010560563921363404
Epoch #218: loss=0.010542877482904401
Epoch #219: loss=0.008883681480616528
Epoch #220: loss=0.010238421153210263
Epoch #221: loss=0.00914728559460726
Epoch #222: loss=0.015264897002831627
Epoch #223: loss=0.00833048450703185
Epoch #224: loss=0.015206546511767092
Epoch #225: loss=0.010880635485650688
Epoch #226: loss=0.015407845146022345
Epoch #227: loss=0.01289267435581183
Epoch #228: loss=0.010946729606165505
Epoch #229: loss=0.00886339409017881
Epoch #230: loss=0.01011362355956327
Epoch #231: loss=0.007358868743839656
Epoch #232: loss=0.009092039354258546
Epoch #233: loss=0.013073993938789242
Epoch #234: loss=0.009765765434050019
Epoch #235: loss=0.011161618027061943
Epoch #236: loss=0.011274198401138823
Epoch #237: loss=0.008340570502877905
Epoch #238: loss=0.008729266219191106
Epoch #239: loss=0.006566003384561838
Epoch #240: loss=0.008741239751065902
Epoch #241: loss=0.010781556262883138
Epoch #242: loss=0.012548959243923215
Epoch #243: loss=0.008599128245273518
Epoch #244: loss=0.012801874593517238
Epoch #245: loss=0.014965765941093046
Epoch #246: loss=0.008787813399878592
Epoch #247: loss=0.010458309799328882
Epoch #248: loss=0.007361274224815223
Epoch #249: loss=0.007450182808716072

Training time: 3:28:36.144284

Finished.
n2one setting etth1_ettm1_ettm2_traffic -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_ettm2_traffic_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_ettm1_ettm2_traffic', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.9474e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.83205e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.75654e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.9474e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4131654997797414, 'MAE': 0.45756821161674943}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm1_ettm2_traffic -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_ettm2_traffic_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_ettm1_ettm2_traffic', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.2688e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.9847e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.9288e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.9268357582171858, 'MAE': 0.7928625188906255}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm1_ettm2_traffic -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_ettm2_traffic_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_ettm1_ettm2_traffic', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
Evaluation result: {'MSE': 0.21461810087282085, 'MAE': 0.3204337490145801}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm1_ettm2_weather', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm1_ettm2_weather_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=4.048460578918457
Epoch #1: loss=2.449372900616039
Epoch #2: loss=2.0763246774673463
Epoch #3: loss=2.07365506995808
Epoch #4: loss=1.6828620520505038
Epoch #5: loss=1.4979647029529919
Epoch #6: loss=1.362602383440191
Epoch #7: loss=1.2378422238610007
Epoch #8: loss=1.14691401720047
Epoch #9: loss=1.1834668213670905
Epoch #10: loss=1.080175478891893
Epoch #11: loss=0.9513278668577021
Epoch #12: loss=0.9654236695983193
Epoch #13: loss=0.8824938817457719
Epoch #14: loss=0.8406254941766912
Epoch #15: loss=0.7950812556526877
Epoch #16: loss=0.7972422892397101
Epoch #17: loss=0.7430462587963451
Epoch #18: loss=0.7721209341829474
Epoch #19: loss=0.7693472743034363
Epoch #20: loss=0.7494598236950961
Epoch #21: loss=0.7535776409235868
Epoch #22: loss=0.6749535045840523
Epoch #23: loss=0.6608419743451205
Epoch #24: loss=0.5966147910464894
Epoch #25: loss=0.654266132549806
Epoch #26: loss=0.5365315242247148
Epoch #27: loss=0.6097609536214308
Epoch #28: loss=0.5282899688590657
Epoch #29: loss=0.5456071772358634
Epoch #30: loss=0.5480099168690769
Epoch #31: loss=0.44815745787187056
Epoch #32: loss=0.5029839418151162
Epoch #33: loss=0.4814878371628848
Epoch #34: loss=0.6359402813694693
Epoch #35: loss=0.49027855613014915
Epoch #36: loss=0.4699132409962741
Epoch #37: loss=0.4231351890347221
Epoch #38: loss=0.3900540303100239
Epoch #39: loss=0.4397618678483096
Epoch #40: loss=0.46923882311040704
Epoch #41: loss=0.4108034832911058
Epoch #42: loss=0.4259722476655787
Epoch #43: loss=0.42168573276563126
Epoch #44: loss=0.3420971382747997
Epoch #45: loss=0.4013978974385695
Epoch #46: loss=0.38586781512607227
Epoch #47: loss=0.4212276575240222
Epoch #48: loss=0.35761540044437756
Epoch #49: loss=0.31721352230418814
Epoch #50: loss=0.31592078154737296
Epoch #51: loss=0.30938525037332015
Epoch #52: loss=0.34119843136180533
Epoch #53: loss=0.27682477506724273
Epoch #54: loss=0.3150679588317871
Epoch #55: loss=0.31597832075574184
Epoch #56: loss=0.2909304545684294
Epoch #57: loss=0.3520926228978417
Epoch #58: loss=0.27911448668349875
Epoch #59: loss=0.23301196599548513
Epoch #60: loss=0.2974521254951304
Epoch #61: loss=0.21269504942677236
Epoch #62: loss=0.240759409151294
Epoch #63: loss=0.24341041472825137
Epoch #64: loss=0.2386727423830466
Epoch #65: loss=0.2621998014775189
Epoch #66: loss=0.21217698563228954
Epoch #67: loss=0.2175498974594203
Epoch #68: loss=0.24065760563720356
Epoch #69: loss=0.28271670111201025
Epoch #70: loss=0.18792182058095933
Epoch #71: loss=0.1828905999660492
Epoch #72: loss=0.22315408302979037
Epoch #73: loss=0.19041075164621526
Epoch #74: loss=0.17524342333728618
Epoch #75: loss=0.1766318760134957
Epoch #76: loss=0.23414865921844136
Epoch #77: loss=0.21551331105557356
Epoch #78: loss=0.18391285321929238
Epoch #79: loss=0.14424423771825703
Epoch #80: loss=0.14628206423737786
Epoch #81: loss=0.16948324259031902
Epoch #82: loss=0.1454201889309016
Epoch #83: loss=0.1425394928590818
Epoch #84: loss=0.1303818953308192
Epoch #85: loss=0.1373765266077085
Epoch #86: loss=0.36513784073970534
Epoch #87: loss=0.2089168296618895
Epoch #88: loss=0.16745468540625139
Epoch #89: loss=0.16150494969703935
Epoch #90: loss=0.12853642275387592
Epoch #91: loss=0.16626441099426964
Epoch #92: loss=0.37010593285614796
Epoch #93: loss=0.23988748145374386
Epoch #94: loss=0.2560389228842475
Epoch #95: loss=0.2682589853351766
Epoch #96: loss=0.18006924085996368
Epoch #97: loss=0.14358842609958214
Epoch #98: loss=0.10819675946100192
Epoch #99: loss=0.13948115865615282
Epoch #100: loss=0.1289367937906222
Epoch #101: loss=0.11250011416321451
Epoch #102: loss=0.11720529486509887
Epoch #103: loss=0.1017333446578546
Epoch #104: loss=0.14691449051553554
Epoch #105: loss=0.21986942379312083
Epoch #106: loss=0.13754589469595388
Epoch #107: loss=0.11962513879618862
Epoch #108: loss=0.12621132192963905
Epoch #109: loss=0.12627053961835125
Epoch #110: loss=0.09463339962742545
Epoch #111: loss=0.09558883973143317
Epoch #112: loss=0.0915325137024576
Epoch #113: loss=0.13722220395099033
Epoch #114: loss=0.08876221020790663
Epoch #115: loss=0.08945846141062
Epoch #116: loss=0.09080069481649182
Epoch #117: loss=0.09205950844016943
Epoch #118: loss=0.09732200367884203
Epoch #119: loss=0.12146215449002656
Epoch #120: loss=0.11499294577674432
Epoch #121: loss=0.10859300213103945
Epoch #122: loss=0.10349445007741451
Epoch #123: loss=0.14641384702514518
Epoch #124: loss=0.10307620425115932
Epoch #125: loss=0.07803182290358977
Epoch #126: loss=0.1154397233643315
Epoch #127: loss=0.20727080276066606
Epoch #128: loss=0.12250055958601562
Epoch #129: loss=0.1457248511978171
Epoch #130: loss=0.13115938421000134
Epoch #131: loss=0.11713699752634221
Epoch #132: loss=0.12984702807258475
Epoch #133: loss=0.0833406559784304
Epoch #134: loss=0.08613753179934892
Epoch #135: loss=0.09629667137156833
Epoch #136: loss=0.09531297859820452
Epoch #137: loss=0.07657413436946543
Epoch #138: loss=0.08197888352654197
Epoch #139: loss=0.08034252978184006
Epoch #140: loss=0.06582174956459891
Epoch #141: loss=0.09070889553563162
Epoch #142: loss=0.07853776350278746
Epoch #143: loss=0.10897936211390928
Epoch #144: loss=0.07100067758424715
Epoch #145: loss=0.0776062508706342
Epoch #146: loss=0.07001463535495779
Epoch #147: loss=0.0631739375774156
Epoch #148: loss=0.09028453715145587
Epoch #149: loss=0.11937398874962872
Epoch #150: loss=0.0835384701801972
Epoch #151: loss=0.09807949790900404
Epoch #152: loss=0.08089269421656023
Epoch #153: loss=0.06864641591567885
Epoch #154: loss=0.07184430203315886
Epoch #155: loss=0.08929290461607954
Epoch #156: loss=0.0661113394254988
Epoch #157: loss=0.05309198894961314
Epoch #158: loss=0.0740408491004597
Epoch #159: loss=0.09833789030936631
Epoch #160: loss=0.155639385194941
Epoch #161: loss=0.07468648437749256
Epoch #162: loss=0.07530337983573025
Epoch #163: loss=0.10216960783370517
Epoch #164: loss=0.19036771763454785
Epoch #165: loss=0.09771941321139986
Epoch #166: loss=0.1312088565562259
Epoch #167: loss=0.12030904252420772
Epoch #168: loss=0.06421187691051852
Epoch #169: loss=0.05794951795515689
Epoch #170: loss=0.0889333908192136
Epoch #171: loss=0.11840217692608183
Epoch #172: loss=0.07437974277206442
Epoch #173: loss=0.05958208240229975
Epoch #174: loss=0.04932978488504887
Epoch #175: loss=0.06952228016135367
Epoch #176: loss=0.08179781861941923
Epoch #177: loss=0.06166888632896272
Epoch #178: loss=0.07751812609759244
Epoch #179: loss=0.06188631100072102
Epoch #180: loss=0.08418135104531592
Epoch #181: loss=0.06432305337353186
Epoch #182: loss=0.0645137583836913
Epoch #183: loss=0.04536830222403461
Epoch #184: loss=0.06315019649707458
Epoch #185: loss=0.05557194368236444
Epoch #186: loss=0.04786947596479546
Epoch #187: loss=0.07259614653885364
Epoch #188: loss=0.12451791304417632
Epoch #189: loss=0.07868664327331565
Epoch #190: loss=0.062748357670551
Epoch #191: loss=0.05963779479603876
Epoch #192: loss=0.08276548358527097
Epoch #193: loss=0.053031422350216996
Epoch #194: loss=0.08954506176100537
Epoch #195: loss=0.043348665323785764
Epoch #196: loss=0.07104475452479991
Epoch #197: loss=0.06517487632280046
Epoch #198: loss=0.07536483528092504
Epoch #199: loss=0.08270333983342756
Epoch #200: loss=0.060134583593092185
Epoch #201: loss=0.09671583874997768
Epoch #202: loss=0.12103742428801277
Epoch #203: loss=0.22378225462003187
Epoch #204: loss=0.1974566561254588
Epoch #205: loss=0.17626428312876008
Epoch #206: loss=0.07576505479148843
Epoch #207: loss=0.09501211196184159
Epoch #208: loss=0.07235391888428819
Epoch #209: loss=0.066510145874186
Epoch #210: loss=0.06047242839228023
Epoch #211: loss=0.05619660508395596
Epoch #212: loss=0.07968461621044712
Epoch #213: loss=0.06645041533153165
Epoch #214: loss=0.06402420088310133
Epoch #215: loss=0.09902740141207522
Epoch #216: loss=0.06650165522640401
Epoch #217: loss=0.0638486241244457
Epoch #218: loss=0.06973500595512715
Epoch #219: loss=0.04435658183118159
Epoch #220: loss=0.04356349313800985
Epoch #221: loss=0.11143585718660191
Epoch #222: loss=0.07833606092767283
Epoch #223: loss=0.05053971147334034
Epoch #224: loss=0.04605177539316091
Epoch #225: loss=0.04238361486826431
Epoch #226: loss=0.04344858969985084
Epoch #227: loss=0.07653330269862305
Epoch #228: loss=0.08142761493271047
Epoch #229: loss=0.059479930429634724
Epoch #230: loss=0.04360619634389877
Epoch #231: loss=0.07094364032487978
Epoch #232: loss=0.058441828631541945
Epoch #233: loss=0.04895557213405317
Epoch #234: loss=0.0499347264285792
Epoch #235: loss=0.05967198197983883
Epoch #236: loss=0.04108474175869064
Epoch #237: loss=0.03743285664611242
Epoch #238: loss=0.04439500875940377
Epoch #239: loss=0.05049350126223131
Epoch #240: loss=0.05742778500372713
Epoch #241: loss=0.05019657530567863
Epoch #242: loss=0.05651781767268072
Epoch #243: loss=0.030530670733953064
Epoch #244: loss=0.04432697787203572
Epoch #245: loss=0.10289443208074028
Epoch #246: loss=0.05804151612418619
Epoch #247: loss=0.05942129394547506
Epoch #248: loss=0.04642847829752348
Epoch #249: loss=0.03424215559762987

Training time: 0:19:35.442086

Finished.
n2one setting etth1_ettm1_ettm2_weather -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_ettm2_weather_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_ettm1_ettm2_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.62956e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.09793e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.62956e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.36527366017291885, 'MAE': 0.42946775637972606}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm1_ettm2_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_ettm2_weather_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_ettm1_ettm2_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.09932e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.20596954814733165, 'MAE': 0.31379998126928477}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm1_ettm2_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm1_ettm2_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=4.038439380156027
Epoch #1: loss=2.2404346143877185
Epoch #2: loss=2.0967491800720626
Epoch #3: loss=1.890238246402225
Epoch #4: loss=1.697562056618768
Epoch #5: loss=1.613321742495975
Epoch #6: loss=1.433277507086058
Epoch #7: loss=1.3672411667334068
Epoch #8: loss=1.3143659797874656
Epoch #9: loss=1.1602013884363949
Epoch #10: loss=1.135855640913989
Epoch #11: loss=1.0415193696279783
Epoch #12: loss=1.0235065962817218
Epoch #13: loss=0.9969699447219437
Epoch #14: loss=0.903463471580196
Epoch #15: loss=1.005335276191299
Epoch #16: loss=0.9302900981258702
Epoch #17: loss=0.9165086440137915
Epoch #18: loss=0.871155779103975
Epoch #19: loss=0.874676488541268
Epoch #20: loss=0.843224407853307
Epoch #21: loss=0.7993544452899212
Epoch #22: loss=0.8452353219728213
Epoch #23: loss=0.74323993437999
Epoch #24: loss=0.7923081098376094
Epoch #25: loss=0.7256767926989375
Epoch #26: loss=0.7080711972069096
Epoch #27: loss=0.8435023523665763
Epoch #28: loss=0.7907800368360571
Epoch #29: loss=0.7299673670047039
Epoch #30: loss=0.6799322479480022
Epoch #31: loss=0.6591381293696326
Epoch #32: loss=0.5881315751655681
Epoch #33: loss=0.6281785852200276
Epoch #34: loss=0.6118325389720298
Epoch #35: loss=0.5395359703012415
Epoch #36: loss=0.515051464776735
Epoch #37: loss=0.5879654674916654
Epoch #38: loss=0.5558515827398043
Epoch #39: loss=0.5153451561927795
Epoch #40: loss=0.5781810452809205
Epoch #41: loss=0.6436354944834838
Epoch #42: loss=0.645248265685262
Epoch #43: loss=0.5660332892392133
Epoch #44: loss=0.6036243809236063
Epoch #45: loss=0.47865631532024694
Epoch #46: loss=0.46308874600642436
Epoch #47: loss=0.4711927537982528
Epoch #48: loss=0.5432589223255982
Epoch #49: loss=0.48478101475818736
Epoch #50: loss=0.4935650889937942
Epoch #51: loss=0.6140707239911363
Epoch #52: loss=0.5339461718056653
Epoch #53: loss=0.5344690519410211
Epoch #54: loss=0.4907915205568881
Epoch #55: loss=0.4362550667814306
Epoch #56: loss=0.4488264016202978
Epoch #57: loss=0.39452733341101054
Epoch #58: loss=0.3514615232880051
Epoch #59: loss=0.3431522391132406
Epoch #60: loss=0.38772738785357086
Epoch #61: loss=0.3468987245011974
Epoch #62: loss=0.42005320175273997
Epoch #63: loss=0.3246243370545877
Epoch #64: loss=0.46638201297940435
Epoch #65: loss=0.4064625417058532
Epoch #66: loss=0.397269620685964
Epoch #67: loss=0.4853686166776193
Epoch #68: loss=0.4437286942391782
Epoch #69: loss=0.42330514740299535
Epoch #70: loss=0.3298829814066758
Epoch #71: loss=0.3231036018680882
Epoch #72: loss=0.30464799802851034
Epoch #73: loss=0.2946426012628787
Epoch #74: loss=0.33398455099479574
Epoch #75: loss=0.3706573896311425
Epoch #76: loss=0.28222707920783274
Epoch #77: loss=0.35834288315193075
Epoch #78: loss=0.2989505130696941
Epoch #79: loss=0.32136883647055237
Epoch #80: loss=0.3172446525580174
Epoch #81: loss=0.2935268069441254
Epoch #82: loss=0.257621901462207
Epoch #83: loss=0.323984299761218
Epoch #84: loss=0.2511288644494237
Epoch #85: loss=0.22757779363844846
Epoch #86: loss=0.2234698455478694
Epoch #87: loss=0.21728300081717
Epoch #88: loss=0.2032490915341957
Epoch #89: loss=0.2388047116833764
Epoch #90: loss=0.2759561516545914
Epoch #91: loss=0.2815261811420724
Epoch #92: loss=0.2754784625124287
Epoch #93: loss=0.24917989989390243
Epoch #94: loss=0.19802490480848262
Epoch #95: loss=0.256768085867972
Epoch #96: loss=0.23386062238667463
Epoch #97: loss=0.22053854721220764
Epoch #98: loss=0.2431439813729879
Epoch #99: loss=0.22161802800523267
Epoch #100: loss=0.20377492300561956
Epoch #101: loss=0.1889430079105738
Epoch #102: loss=0.2132188342511654
Epoch #103: loss=0.2741939650999533
Epoch #104: loss=0.28735502507235555
Epoch #105: loss=0.1882303069169457
Epoch #106: loss=0.25145598219053167
Epoch #107: loss=0.23087165414078817
Epoch #108: loss=0.23217393427684502
Epoch #109: loss=0.24950019874282786
Epoch #110: loss=0.24346779639253746
Epoch #111: loss=0.19439962415679082
Epoch #112: loss=0.176551915705204
Epoch #113: loss=0.19862582353321281
Epoch #114: loss=0.1709614149420648
Epoch #115: loss=0.17080143224951383
Epoch #116: loss=0.21101634003020622
Epoch #117: loss=0.1456607180471356
Epoch #118: loss=0.18939229392924825
Epoch #119: loss=0.15112078260328318
Epoch #120: loss=0.1671919209026807
Epoch #121: loss=0.17872967852933988
Epoch #122: loss=0.1613547290499146
Epoch #123: loss=0.1587945668882615
Epoch #124: loss=0.2605397801946949
Epoch #125: loss=0.19653663250642853
Epoch #126: loss=0.288282402765912
Epoch #127: loss=0.22431630510333422
Epoch #128: loss=0.2204031970452618
Epoch #129: loss=0.15969458182115812
Epoch #130: loss=0.15431386866682284
Epoch #131: loss=0.14019844912596652
Epoch #132: loss=0.1675396100492091
Epoch #133: loss=0.154348169478613
Epoch #134: loss=0.14885515548490189
Epoch #135: loss=0.1512385777927734
Epoch #136: loss=0.15886692446027254
Epoch #137: loss=0.14945078918055907
Epoch #138: loss=0.1757990505445648
Epoch #139: loss=0.15291407377131888
Epoch #140: loss=0.12124266475439072
Epoch #141: loss=0.11951792084083364
Epoch #142: loss=0.14510082005447633
Epoch #143: loss=0.12231612331359773
Epoch #144: loss=0.14076292323502335
Epoch #145: loss=0.1956144326643364
Epoch #146: loss=0.17445394235688286
Epoch #147: loss=0.1774333138522264
Epoch #148: loss=0.18165233922568527
Epoch #149: loss=0.17218886839376912
Epoch #150: loss=0.12552370458237222
Epoch #151: loss=0.10216310001104265
Epoch #152: loss=0.1307066910572954
Epoch #153: loss=0.13032381911132787
Epoch #154: loss=0.2060026898476723
Epoch #155: loss=0.16992908585313204
Epoch #156: loss=0.16478756659135624
Epoch #157: loss=0.10732511647448346
Epoch #158: loss=0.13052284777969927
Epoch #159: loss=0.1966918273954778
Epoch #160: loss=0.15644980413285461
Epoch #161: loss=0.15235707898800438
Epoch #162: loss=0.13988910917494748
Epoch #163: loss=0.13565330338236448
Epoch #164: loss=0.13433576531305508
Epoch #165: loss=0.15913847728154143
Epoch #166: loss=0.13527963058771314
Epoch #167: loss=0.20193504642795873
Epoch #168: loss=0.154738286912844
Epoch #169: loss=0.09521022177225835
Epoch #170: loss=0.09893185297983724
Epoch #171: loss=0.10863542365464005
Epoch #172: loss=0.13691945278362647
Epoch #173: loss=0.09799846307047315
Epoch #174: loss=0.09518950175796007
Epoch #175: loss=0.11626131913146458
Epoch #176: loss=0.15105480212416197
Epoch #177: loss=0.12401478078115631
Epoch #178: loss=0.10045671704653147
Epoch #179: loss=0.10821918073437505
Epoch #180: loss=0.1377177167482473
Epoch #181: loss=0.10032739258698516
Epoch #182: loss=0.08208929563595636
Epoch #183: loss=0.08540078058738161
Epoch #184: loss=0.08815404065456744
Epoch #185: loss=0.10082112079033174
Epoch #186: loss=0.12557860332969073
Epoch #187: loss=0.09524532238877303
Epoch #188: loss=0.13606082197480104
Epoch #189: loss=0.1096330040663078
Epoch #190: loss=0.08923171807986659
Epoch #191: loss=0.11817095428705215
Epoch #192: loss=0.0981684418747554
Epoch #193: loss=0.10679277173570685
Epoch #194: loss=0.12674930072515397
Epoch #195: loss=0.09132331146581753
Epoch #196: loss=0.16084763359882542
Epoch #197: loss=0.14163282060542623
Epoch #198: loss=0.10677023755537497
Epoch #199: loss=0.11254777457263018
Epoch #200: loss=0.09896701946854591
Epoch #201: loss=0.17490814530567542
Epoch #202: loss=0.11501248714488906
Epoch #203: loss=0.12182955358278107
Epoch #204: loss=0.09368558884975878
Epoch #205: loss=0.11152097396552563
Epoch #206: loss=0.10420513968612696
Epoch #207: loss=0.12898118640422016
Epoch #208: loss=0.16907105237446926
Epoch #209: loss=0.09079266274096193
Epoch #210: loss=0.11144990919510255
Epoch #211: loss=0.11114069054255614
Epoch #212: loss=0.11658940167241805
Epoch #213: loss=0.08181142399238574
Epoch #214: loss=0.09011036316184579
Epoch #215: loss=0.09847025102558168
Epoch #216: loss=0.12535265163594
Epoch #217: loss=0.1129460528593611
Epoch #218: loss=0.10797693097108119
Epoch #219: loss=0.15324382937035044
Epoch #220: loss=0.1009244515837447
Epoch #221: loss=0.12750637893741196
Epoch #222: loss=0.2054469785778909
Epoch #223: loss=0.17717713892862602
Epoch #224: loss=0.10671679670544895
Epoch #225: loss=0.07351330811208165
Epoch #226: loss=0.09719781099340401
Epoch #227: loss=0.05859854981001165
Epoch #228: loss=0.06101262227103517
Epoch #229: loss=0.073174576514174
Epoch #230: loss=0.13067307079059853
Epoch #231: loss=0.08814006313882969
Epoch #232: loss=0.10517934332224163
Epoch #233: loss=0.085935228403557
Epoch #234: loss=0.13182600524679228
Epoch #235: loss=0.09366242401301861
Epoch #236: loss=0.08088147750980146
Epoch #237: loss=0.0840256022339737
Epoch #238: loss=0.11940768066592314
Epoch #239: loss=0.09742482369010513
Epoch #240: loss=0.09141389680774631
Epoch #241: loss=0.07628867369950623
Epoch #242: loss=0.0735943687173563
Epoch #243: loss=0.05719040857779013
Epoch #244: loss=0.07562543750060974
Epoch #245: loss=0.062143643449589205
Epoch #246: loss=0.06589866703929934
Epoch #247: loss=0.07888339230841077
Epoch #248: loss=0.09108019705761124
Epoch #249: loss=0.08411813250465973

Training time: 0:11:09.376763

Finished.
n2one setting etth1_ettm1_ettm2_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_ettm2_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_ettm1_ettm2_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.37324e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.89024e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.37324e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3684132816183337, 'MAE': 0.43225703961159334}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm1_ettm2_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_ettm2_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_ettm1_ettm2_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.32835e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.70852e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.32835e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.951517895505408, 'MAE': 0.8049605945830071}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm1_electricity_traffic', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm1_electricity_traffic_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.8674835860232926
Epoch #1: loss=0.32683750401428596
Epoch #2: loss=0.21188397067199638
Epoch #3: loss=0.1550449051015656
Epoch #4: loss=0.12353776070249765
Epoch #5: loss=0.09350737296106863
Epoch #6: loss=0.07522295476895115
Epoch #7: loss=0.07276818364684925
Epoch #8: loss=0.0638798876870253
Epoch #9: loss=0.06031383182403696
Epoch #10: loss=0.049561435139220796
Epoch #11: loss=0.04505850918758521
Epoch #12: loss=0.0428076778444695
Epoch #13: loss=0.04602200246978626
Epoch #14: loss=0.0547287861563011
Epoch #15: loss=0.039435238466729146
Epoch #16: loss=0.03380250597020206
Epoch #17: loss=0.03197779193073495
Epoch #18: loss=0.04220361906071996
Epoch #19: loss=0.03566443430357531
Epoch #20: loss=0.03394129822770448
Epoch #21: loss=0.03163463172528406
Epoch #22: loss=0.02616612387241764
Epoch #23: loss=0.02826190645443772
Epoch #24: loss=0.027321653044772885
Epoch #25: loss=0.029151851918992683
Epoch #26: loss=0.025625011858328335
Epoch #27: loss=0.02562328282050435
Epoch #28: loss=0.02723992439657667
Epoch #29: loss=0.025425267639365607
Epoch #30: loss=0.021475182094626347
Epoch #31: loss=0.02589113568087256
Epoch #32: loss=0.024539746177705744
Epoch #33: loss=0.02146083996858026
Epoch #34: loss=0.02258432029429893
Epoch #35: loss=0.022139697400411027
Epoch #36: loss=0.02518671565712604
Epoch #37: loss=0.020145063668774048
Epoch #38: loss=0.02103282452536813
Epoch #39: loss=0.019917583672894316
Epoch #40: loss=0.022180442696748973
Epoch #41: loss=0.024127138601278703
Epoch #42: loss=0.02266015569192065
Epoch #43: loss=0.01914005317295057
Epoch #44: loss=0.016319388780579747
Epoch #45: loss=0.018391962634530586
Epoch #46: loss=0.021300135774450293
Epoch #47: loss=0.016550660694283018
Epoch #48: loss=0.0179629443225654
Epoch #49: loss=0.02153492816346818
Epoch #50: loss=0.018054899287434895
Epoch #51: loss=0.01601362029513341
Epoch #52: loss=0.01801395589994609
Epoch #53: loss=0.01902843238755814
Epoch #54: loss=0.013126993458965237
Epoch #55: loss=0.01711487130815597
Epoch #56: loss=0.015900871430781144
Epoch #57: loss=0.014655091860790084
Epoch #58: loss=0.018981528781011482
Epoch #59: loss=0.02194054562965936
Epoch #60: loss=0.013295305461235434
Epoch #61: loss=0.01959737327002566
Epoch #62: loss=0.01462928975678726
Epoch #63: loss=0.014457041127662478
Epoch #64: loss=0.01998934179461475
Epoch #65: loss=0.01526951677390614
Epoch #66: loss=0.015595226339802433
Epoch #67: loss=0.01578460882121149
Epoch #68: loss=0.01346911792966216
Epoch #69: loss=0.016228324962143232
Epoch #70: loss=0.014946755866378975
Epoch #71: loss=0.023450116098808593
Epoch #72: loss=0.015121399573058
Epoch #73: loss=0.014813500676862624
Epoch #74: loss=0.01231039817291149
Epoch #75: loss=0.014455035006275383
Epoch #76: loss=0.01504825159740521
Epoch #77: loss=0.014529823212273016
Epoch #78: loss=0.014082744232768373
Epoch #79: loss=0.016877483456170878
Epoch #80: loss=0.014406142866191067
Epoch #81: loss=0.011575112015696757
Epoch #82: loss=0.0134574005943787
Epoch #83: loss=0.01231596662020652
Epoch #84: loss=0.011923958274174182
Epoch #85: loss=0.013758864649387307
Epoch #86: loss=0.012100204521180252
Epoch #87: loss=0.017010847191197595
Epoch #88: loss=0.010321217328830052
Epoch #89: loss=0.014413255072726797
Epoch #90: loss=0.012076441683659336
Epoch #91: loss=0.0180097740052373
Epoch #92: loss=0.011380471528422371
Epoch #93: loss=0.012558794901971872
Epoch #94: loss=0.017284243273394465
Epoch #95: loss=0.013999049661390841
Epoch #96: loss=0.010213180585310415
Epoch #97: loss=0.016050248532499777
Epoch #98: loss=0.011787230975353636
Epoch #99: loss=0.02031995142524776
Epoch #100: loss=0.0100746165036199
Epoch #101: loss=0.015822357671108712
Epoch #102: loss=0.012686191771689687
Epoch #103: loss=0.014186107067766985
Epoch #104: loss=0.013052924991361207
Epoch #105: loss=0.012600824939093624
Epoch #106: loss=0.015842495946591442
Epoch #107: loss=0.012446481017508296
Epoch #108: loss=0.014998606889939817
Epoch #109: loss=0.010403516150641291
Epoch #110: loss=0.011472338042910181
Epoch #111: loss=0.01511999795356898
Epoch #112: loss=0.008908359888663049
Epoch #113: loss=0.01109657107161662
Epoch #114: loss=0.011685841496717642
Epoch #115: loss=0.010856077949088811
Epoch #116: loss=0.013217579917913398
Epoch #117: loss=0.02376608377374704
Epoch #118: loss=0.015916227306708264
Epoch #119: loss=0.008090759440826992
Epoch #120: loss=0.009454499516655713
Epoch #121: loss=0.018158892413887618
Epoch #122: loss=0.01222219702661298
Epoch #123: loss=0.011562159734229083
Epoch #124: loss=0.010368302242462442
Epoch #125: loss=0.011042243150364997
Epoch #126: loss=0.015030130447392747
Epoch #127: loss=0.013753865629100751
Epoch #128: loss=0.01001209888367987
Epoch #129: loss=0.010071385878781
Epoch #130: loss=0.02370069752594329
Epoch #131: loss=0.017568824995789607
Epoch #132: loss=0.00869891497099794
Epoch #133: loss=0.011845276138264853
Epoch #134: loss=0.01313571856974808
Epoch #135: loss=0.011391632517215818
Epoch #136: loss=0.012249940381091489
Epoch #137: loss=0.015732732681408453
Epoch #138: loss=0.010999523673633457
Epoch #139: loss=0.01363187532336994
Epoch #140: loss=0.009248904592895936
Epoch #141: loss=0.0087675146704541
Epoch #142: loss=0.010767475323421807
Epoch #143: loss=0.015827147578822524
Epoch #144: loss=0.010672875274235726
Epoch #145: loss=0.011480100320636231
Epoch #146: loss=0.012042281848294537
Epoch #147: loss=0.00963191163324271
Epoch #148: loss=0.009959173002165915
Epoch #149: loss=0.011057788008065207
Epoch #150: loss=0.0124759874451896
Epoch #151: loss=0.008659003731657691
Epoch #152: loss=0.009905362786562996
Epoch #153: loss=0.014186722126940218
Epoch #154: loss=0.010092785133884301
Epoch #155: loss=0.010659020004904892
Epoch #156: loss=0.010948738233318326
Epoch #157: loss=0.011394421513055487
Epoch #158: loss=0.011260530885589986
Epoch #159: loss=0.009579678612747047
Epoch #160: loss=0.010302486661852137
Epoch #161: loss=0.01988315888780406
Epoch #162: loss=0.010755798483228073
Epoch #163: loss=0.011624944548984892
Epoch #164: loss=0.008219913325246717
Epoch #165: loss=0.011169695613960457
Epoch #166: loss=0.01621154396669258
Epoch #167: loss=0.012871301345483843
Epoch #168: loss=0.01080744104635038
Epoch #169: loss=0.012450538124697404
Epoch #170: loss=0.011833159172935388
Epoch #171: loss=0.009588043012048604
Epoch #172: loss=0.009913393407991251
Epoch #173: loss=0.010993048489957639
Epoch #174: loss=0.01118104958721242
Epoch #175: loss=0.00939921323945424
Epoch #176: loss=0.00984837838623934
Epoch #177: loss=0.00903537371174526
Epoch #178: loss=0.012054282053393916
Epoch #179: loss=0.009229013165230853
Epoch #180: loss=0.011951674397439261
Epoch #181: loss=0.010581345910793943
Epoch #182: loss=0.008705623704280168
Epoch #183: loss=0.012891426914248737
Epoch #184: loss=0.008621583723505381
Epoch #185: loss=0.015632609625433325
Epoch #186: loss=0.008790596458665135
Epoch #187: loss=0.008649469885100214
Epoch #188: loss=0.010321432912249347
Epoch #189: loss=0.010547738133121353
Epoch #190: loss=0.013613002328434765
Epoch #191: loss=0.008340986026254705
Epoch #192: loss=0.009350967834161096
Epoch #193: loss=0.00791628416542103
Epoch #194: loss=0.012709271422950152
Epoch #195: loss=0.00838447525315008
Epoch #196: loss=0.011195545957719776
Epoch #197: loss=0.009666301064436741
Epoch #198: loss=0.010545839560238511
Epoch #199: loss=0.007379123795617427
Epoch #200: loss=0.012293487082720756
Epoch #201: loss=0.009970338744700361
Epoch #202: loss=0.010547103461649809
Epoch #203: loss=0.008539009457141965
Epoch #204: loss=0.010661525595713163
Epoch #205: loss=0.008580345744100383
Epoch #206: loss=0.014075586627516469
Epoch #207: loss=0.011185251449251874
Epoch #208: loss=0.017278644164050866
Epoch #209: loss=0.009311460332735035
Epoch #210: loss=0.008729140641671613
Epoch #211: loss=0.0061035721784589245
Epoch #212: loss=0.014189910318769924
Epoch #213: loss=0.010609905348322412
Epoch #214: loss=0.010595204367248657
Epoch #215: loss=0.009332041275528256
Epoch #216: loss=0.012269695183631734
Epoch #217: loss=0.0109538013917589
Epoch #218: loss=0.010544466509951549
Epoch #219: loss=0.008976172353877694
Epoch #220: loss=0.008443543450845189
Epoch #221: loss=0.01526492601246306
Epoch #222: loss=0.010482966070824619
Epoch #223: loss=0.007391141338681627
Epoch #224: loss=0.009054916519040166
Epoch #225: loss=0.008870554967346664
Epoch #226: loss=0.007813771475549893
Epoch #227: loss=0.013210505409331776
Epoch #228: loss=0.007739103158425945
Epoch #229: loss=0.008085563627963236
Epoch #230: loss=0.01186234775032956
Epoch #231: loss=0.008126364209580685
Epoch #232: loss=0.010202222362909822
Epoch #233: loss=0.009152368522836279
Epoch #234: loss=0.012198742519415334
Epoch #235: loss=0.008166816769771473
Epoch #236: loss=0.009513760146502211
Epoch #237: loss=0.010114296128079943
Epoch #238: loss=0.008113107253561274
Epoch #239: loss=0.008222393438874412
Epoch #240: loss=0.009124878171021405
Epoch #241: loss=0.01001281098804908
Epoch #242: loss=0.009517207089712208
Epoch #243: loss=0.008123190606080829
Epoch #244: loss=0.01151170565470323
Epoch #245: loss=0.007668194240411309
Epoch #246: loss=0.008261722171572805
Epoch #247: loss=0.008812054862923724
Epoch #248: loss=0.011311882879871322
Epoch #249: loss=0.008517522798383144

Training time: 5:21:27.360361

Finished.
n2one setting etth1_ettm1_electricity_traffic -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_electricity_traffic_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_ettm1_electricity_traffic', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.44769e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.86153e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.44769e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.36405934318758365, 'MAE': 0.4367536215590706}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm1_electricity_traffic -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_electricity_traffic_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_ettm1_electricity_traffic', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
Evaluation result: {'MSE': 0.25987415816842113, 'MAE': 0.3490732305056123}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm1_electricity_weather', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm1_electricity_weather_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.8370908291372534
Epoch #1: loss=0.8268977995604685
Epoch #2: loss=0.5674410045963444
Epoch #3: loss=0.46366432933774715
Epoch #4: loss=0.43831254378573536
Epoch #5: loss=0.3809162845350292
Epoch #6: loss=0.3281568661128005
Epoch #7: loss=0.3123342869216449
Epoch #8: loss=0.2619655772023005
Epoch #9: loss=0.2565726754191804
Epoch #10: loss=0.2267419086131331
Epoch #11: loss=0.2168544299798469
Epoch #12: loss=0.1913342991818304
Epoch #13: loss=0.18168907003247575
Epoch #14: loss=0.16639444812724036
Epoch #15: loss=0.1861034791253201
Epoch #16: loss=0.15910395937014932
Epoch #17: loss=0.1262732228391791
Epoch #18: loss=0.12485927178537193
Epoch #19: loss=0.12012010965853522
Epoch #20: loss=0.11140596832926959
Epoch #21: loss=0.09733053293232231
Epoch #22: loss=0.09371199381780135
Epoch #23: loss=0.08569454214191191
Epoch #24: loss=0.11987064857903408
Epoch #25: loss=0.08794192884576647
Epoch #26: loss=0.07965102685640936
Epoch #27: loss=0.07919746036960246
Epoch #28: loss=0.07247079951331428
Epoch #29: loss=0.07907563126709771
Epoch #30: loss=0.0614843824801788
Epoch #31: loss=0.05976278498411587
Epoch #32: loss=0.05946770703598653
Epoch #33: loss=0.05274494080357764
Epoch #34: loss=0.06121888202934028
Epoch #35: loss=0.042936112632184
Epoch #36: loss=0.05698953426302704
Epoch #37: loss=0.05655955497609222
Epoch #38: loss=0.05175199843113859
Epoch #39: loss=0.047867791051657435
Epoch #40: loss=0.05804963344708085
Epoch #41: loss=0.058594427740660635
Epoch #42: loss=0.054865187564737176
Epoch #43: loss=0.04024604241146821
Epoch #44: loss=0.04267301985624004
Epoch #45: loss=0.027796142933928496
Epoch #46: loss=0.04646659185408219
Epoch #47: loss=0.03453098329562337
Epoch #48: loss=0.04230185271151466
Epoch #49: loss=0.03492161131285335
Epoch #50: loss=0.038199223274658495
Epoch #51: loss=0.0377577179137056
Epoch #52: loss=0.03304442715614218
Epoch #53: loss=0.03269802746650036
Epoch #54: loss=0.0360329227034028
Epoch #55: loss=0.03112389644646175
Epoch #56: loss=0.041932735137309725
Epoch #57: loss=0.030037890728052758
Epoch #58: loss=0.032648061561615094
Epoch #59: loss=0.02573172398364452
Epoch #60: loss=0.027565800845750596
Epoch #61: loss=0.0435761116081466
Epoch #62: loss=0.02808161689549021
Epoch #63: loss=0.033801065851640825
Epoch #64: loss=0.03774501873492837
Epoch #65: loss=0.0441457477822415
Epoch #66: loss=0.026482827651269785
Epoch #67: loss=0.031909492207461435
Epoch #68: loss=0.026359294838756833
Epoch #69: loss=0.021441999589705406
Epoch #70: loss=0.02801797563522697
Epoch #71: loss=0.02288369410320453
Epoch #72: loss=0.025565858467877525
Epoch #73: loss=0.02262506023757415
Epoch #74: loss=0.02055288041233761
Epoch #75: loss=0.03161051210513568
Epoch #76: loss=0.027132036665467266
Epoch #77: loss=0.0289272924457766
Epoch #78: loss=0.02531756465881425
Epoch #79: loss=0.02903784291375403
Epoch #80: loss=0.03541149071095613
Epoch #81: loss=0.0371651444520342
Epoch #82: loss=0.0380805071019121
Epoch #83: loss=0.02081776366709438
Epoch #84: loss=0.026138459903519755
Epoch #85: loss=0.020425348008236505
Epoch #86: loss=0.019583289352347693
Epoch #87: loss=0.022661190410144628
Epoch #88: loss=0.020228401531803435
Epoch #89: loss=0.025433790498757606
Epoch #90: loss=0.01515621922013975
Epoch #91: loss=0.021084659900803323
Epoch #92: loss=0.02693039726622224
Epoch #93: loss=0.028401956235836835
Epoch #94: loss=0.0366035625269981
Epoch #95: loss=0.014194459603837858
Epoch #96: loss=0.02458500048936638
Epoch #97: loss=0.02622971382942561
Epoch #98: loss=0.031792632289460464
Epoch #99: loss=0.02485160236422304
Epoch #100: loss=0.025152189972210828
Epoch #101: loss=0.03442061833865073
Epoch #102: loss=0.019568723887811123
Epoch #103: loss=0.023386071170265595
Epoch #104: loss=0.03906870790173567
Epoch #105: loss=0.03195851803310726
Epoch #106: loss=0.022874132092812496
Epoch #107: loss=0.018581623515777596
Epoch #108: loss=0.015676702268274934
Epoch #109: loss=0.018206502205360527
Epoch #110: loss=0.018821801479956875
Epoch #111: loss=0.021369378518772453
Epoch #112: loss=0.019185329481404376
Epoch #113: loss=0.021024691562602067
Epoch #114: loss=0.023413960218959015
Epoch #115: loss=0.020837391352867836
Epoch #116: loss=0.018575243805120507
Epoch #117: loss=0.03382839582627639
Epoch #118: loss=0.01811415302879751
Epoch #119: loss=0.016356070386963475
Epoch #120: loss=0.01833670548313259
Epoch #121: loss=0.01831721925632773
Epoch #122: loss=0.017848773565054044
Epoch #123: loss=0.026102761850271324
Epoch #124: loss=0.025402418666276825
Epoch #125: loss=0.017019677038738273
Epoch #126: loss=0.01938200266154687
Epoch #127: loss=0.025022558923427984
Epoch #128: loss=0.02138102943163799
Epoch #129: loss=0.016860100744955548
Epoch #130: loss=0.02085315761720915
Epoch #131: loss=0.01566922615747899
Epoch #132: loss=0.02039877333365738
Epoch #133: loss=0.018022440382509098
Epoch #134: loss=0.018180446824288533
Epoch #135: loss=0.016614063000083223
Epoch #136: loss=0.04186500379790182
Epoch #137: loss=0.028436820027546012
Epoch #138: loss=0.018498602172532054
Epoch #139: loss=0.02409727987976847
Epoch #140: loss=0.016029170985422926
Epoch #141: loss=0.014625902460371336
Epoch #142: loss=0.017493343757854597
Epoch #143: loss=0.018567704571863918
Epoch #144: loss=0.019496081039398806
Epoch #145: loss=0.012870189722959105
Epoch #146: loss=0.02517698560761645
Epoch #147: loss=0.020870547363222004
Epoch #148: loss=0.015887955729753954
Epoch #149: loss=0.015333471195580923
Epoch #150: loss=0.020037575009157753
Epoch #151: loss=0.01476233474693376
Epoch #152: loss=0.01957995144551467
Epoch #153: loss=0.012278812045505755
Epoch #154: loss=0.055285098188722584
Epoch #155: loss=0.02386872366753292
Epoch #156: loss=0.017783021565035546
Epoch #157: loss=0.012224982633121466
Epoch #158: loss=0.015263823322451048
Epoch #159: loss=0.018038131088841298
Epoch #160: loss=0.014787566865960212
Epoch #161: loss=0.013938704545431044
Epoch #162: loss=0.014683142504080721
Epoch #163: loss=0.055424315191180226
Epoch #164: loss=0.01328930738669093
Epoch #165: loss=0.013107024501428671
Epoch #166: loss=0.025857056965509252
Epoch #167: loss=0.018814141216228576
Epoch #168: loss=0.018474682571991564
Epoch #169: loss=0.013520770870015178
Epoch #170: loss=0.014150022768992803
Epoch #171: loss=0.015414194953277043
Epoch #172: loss=0.014735683428653043
Epoch #173: loss=0.013899619553129712
Epoch #174: loss=0.019304635997683013
Epoch #175: loss=0.012859047422016498
Epoch #176: loss=0.012104510315151706
Epoch #177: loss=0.013521617520217822
Epoch #178: loss=0.01625018083818946
Epoch #179: loss=0.02337878421570927
Epoch #180: loss=0.01521875361293197
Epoch #181: loss=0.014114943116246276
Epoch #182: loss=0.011623971715524845
Epoch #183: loss=0.015589397238592987
Epoch #184: loss=0.02169162550062413
Epoch #185: loss=0.011190026370036632
Epoch #186: loss=0.012688261098132711
Epoch #187: loss=0.01418837227823519
Epoch #188: loss=0.01605955899791945
Epoch #189: loss=0.017369510897448006
Epoch #190: loss=0.019250870302992502
Epoch #191: loss=0.023518561567849646
Epoch #192: loss=0.0213039603964617
Epoch #193: loss=0.010915114164860937
Epoch #194: loss=0.01817313497056802
Epoch #195: loss=0.011944783617716843
Epoch #196: loss=0.015367242797718013
Epoch #197: loss=0.014701375516756654
Epoch #198: loss=0.014505465111491105
Epoch #199: loss=0.01068369265404938
Epoch #200: loss=0.042978086616933246
Epoch #201: loss=0.023353822934377478
Epoch #202: loss=0.012050758803196327
Epoch #203: loss=0.012163634504485007
Epoch #204: loss=0.011550947267814119
Epoch #205: loss=0.014125280882780478
Epoch #206: loss=0.01704341949837614
Epoch #207: loss=0.021968330659629293
Epoch #208: loss=0.01402833951949716
Epoch #209: loss=0.01749411445614971
Epoch #210: loss=0.013239653635218306
Epoch #211: loss=0.020568023284750492
Epoch #212: loss=0.014791803346940456
Epoch #213: loss=0.012154397427436117
Epoch #214: loss=0.019830172335767275
Epoch #215: loss=0.012914845671453705
Epoch #216: loss=0.01816708495671389
Epoch #217: loss=0.013965687297495108
Epoch #218: loss=0.011644560084614444
Epoch #219: loss=0.014462157214069994
Epoch #220: loss=0.021854931122801995
Epoch #221: loss=0.011166069802687797
Epoch #222: loss=0.021321358242429384
Epoch #223: loss=0.012312274793488266
Epoch #224: loss=0.014847231919044782
Epoch #225: loss=0.013649384329200735
Epoch #226: loss=0.012510589333506275
Epoch #227: loss=0.016974282732523646
Epoch #228: loss=0.0245873228826222
Epoch #229: loss=0.010963866334051301
Epoch #230: loss=0.014312663703378647
Epoch #231: loss=0.01942842284357813
Epoch #232: loss=0.01330876325828036
Epoch #233: loss=0.026219082808868373
Epoch #234: loss=0.012609822603184984
Epoch #235: loss=0.011697443881891796
Epoch #236: loss=0.010015824388103457
Epoch #237: loss=0.015008270907397573
Epoch #238: loss=0.014482154669909904
Epoch #239: loss=0.01076245694644494
Epoch #240: loss=0.009143343615291436
Epoch #241: loss=0.010962193690189352
Epoch #242: loss=0.021288737291087434
Epoch #243: loss=0.013907181475333845
Epoch #244: loss=0.013455503644088398
Epoch #245: loss=0.01202848820814748
Epoch #246: loss=0.014042187517481755
Epoch #247: loss=0.02101232126930869
Epoch #248: loss=0.02060133768038263
Epoch #249: loss=0.01701759772960492

Training time: 1:52:43.348158

Finished.
n2one setting etth1_ettm1_electricity_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_electricity_weather_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_ettm1_electricity_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.30107e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.30107e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.2144617924509566, 'MAE': 0.31577328403282906}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm1_electricity_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm1_electricity_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.7481677448028103
Epoch #1: loss=0.7564448275380588
Epoch #2: loss=0.5164324711653959
Epoch #3: loss=0.420542111142568
Epoch #4: loss=0.3510595797118261
Epoch #5: loss=0.30770196437148606
Epoch #6: loss=0.29661354809054724
Epoch #7: loss=0.25265169822173433
Epoch #8: loss=0.23967770257325954
Epoch #9: loss=0.21387640786188136
Epoch #10: loss=0.1938557420409035
Epoch #11: loss=0.19678106420923036
Epoch #12: loss=0.17150502199956594
Epoch #13: loss=0.15576204115938214
Epoch #14: loss=0.1532747191122011
Epoch #15: loss=0.1458486557189343
Epoch #16: loss=0.14336988561241873
Epoch #17: loss=0.10368977826335588
Epoch #18: loss=0.10386411257367313
Epoch #19: loss=0.08937651463260912
Epoch #20: loss=0.11290608212802698
Epoch #21: loss=0.09223735325510804
Epoch #22: loss=0.09055852413886047
Epoch #23: loss=0.10967260034438168
Epoch #24: loss=0.09187461394999144
Epoch #25: loss=0.08605695341818399
Epoch #26: loss=0.06316161152614168
Epoch #27: loss=0.06134527463798736
Epoch #28: loss=0.06499260519456752
Epoch #29: loss=0.07276194877063678
Epoch #30: loss=0.08032143853674575
Epoch #31: loss=0.07041422080151973
Epoch #32: loss=0.059706566317855064
Epoch #33: loss=0.07410381716791466
Epoch #34: loss=0.04723430004759936
Epoch #35: loss=0.1023795030888986
Epoch #36: loss=0.05255311042451506
Epoch #37: loss=0.05437892808925135
Epoch #38: loss=0.04959376345345649
Epoch #39: loss=0.04661768640362005
Epoch #40: loss=0.05204009054019317
Epoch #41: loss=0.05727209542107685
Epoch #42: loss=0.051630219146716665
Epoch #43: loss=0.056682147403711976
Epoch #44: loss=0.05446506810632215
Epoch #45: loss=0.04302158500322863
Epoch #46: loss=0.05126027910438734
Epoch #47: loss=0.0398690247309719
Epoch #48: loss=0.044214151214582775
Epoch #49: loss=0.04615206894819069
Epoch #50: loss=0.05214015671631767
Epoch #51: loss=0.04540790922058108
Epoch #52: loss=0.046032080245982605
Epoch #53: loss=0.04251638443916446
Epoch #54: loss=0.04592976058693737
Epoch #55: loss=0.05600384052813332
Epoch #56: loss=0.03584946005709835
Epoch #57: loss=0.03461958925704061
Epoch #58: loss=0.037748329690993045
Epoch #59: loss=0.0327039924987004
Epoch #60: loss=0.02807732771140032
Epoch #61: loss=0.03263136744398559
Epoch #62: loss=0.03902960578261496
Epoch #63: loss=0.027144678584863607
Epoch #64: loss=0.03624265631446105
Epoch #65: loss=0.033106939619546624
Epoch #66: loss=0.02835489572857853
Epoch #67: loss=0.043610548667652634
Epoch #68: loss=0.031379039525805896
Epoch #69: loss=0.026880404805249242
Epoch #70: loss=0.03544255624953335
Epoch #71: loss=0.053259873340008326
Epoch #72: loss=0.036164553422327834
Epoch #73: loss=0.03490248114885145
Epoch #74: loss=0.028767768675072244
Epoch #75: loss=0.039965043312088944
Epoch #76: loss=0.030618518219874255
Epoch #77: loss=0.04141257307827687
Epoch #78: loss=0.030849264121429205
Epoch #79: loss=0.026168079654248673
Epoch #80: loss=0.03927049168951874
Epoch #81: loss=0.029852078209016527
Epoch #82: loss=0.03182677199637319
Epoch #83: loss=0.025449664797633886
Epoch #84: loss=0.033833337634377805
Epoch #85: loss=0.03769678351659226
Epoch #86: loss=0.02463330697437335
Epoch #87: loss=0.0407371893729773
Epoch #88: loss=0.02585174680133256
Epoch #89: loss=0.022119938011444913
Epoch #90: loss=0.023681836936962374
Epoch #91: loss=0.032532362559923006
Epoch #92: loss=0.0354874186581457
Epoch #93: loss=0.027328909507292384
Epoch #94: loss=0.030921603050096343
Epoch #95: loss=0.047356206519121265
Epoch #96: loss=0.025171543155818297
Epoch #97: loss=0.028561896084598467
Epoch #98: loss=0.028922063236625366
Epoch #99: loss=0.03246077638446898
Epoch #100: loss=0.028806188955845347
Epoch #101: loss=0.02897811855386771
Epoch #102: loss=0.03620138466666836
Epoch #103: loss=0.02714744360945711
Epoch #104: loss=0.02956875139694414
Epoch #105: loss=0.03852854584583943
Epoch #106: loss=0.02079163278756336
Epoch #107: loss=0.02025300818723586
Epoch #108: loss=0.024405403566608468
Epoch #109: loss=0.02099273901705171
Epoch #110: loss=0.025361829898447624
Epoch #111: loss=0.026465058974554007
Epoch #112: loss=0.02072579030035418
Epoch #113: loss=0.025538665840170085
Epoch #114: loss=0.029517169488071912
Epoch #115: loss=0.027055791656517555
Epoch #116: loss=0.0309980566434224
Epoch #117: loss=0.05007210687931455
Epoch #118: loss=0.044796904854634806
Epoch #119: loss=0.034051981790163034
Epoch #120: loss=0.024512486045868795
Epoch #121: loss=0.02396115717902157
Epoch #122: loss=0.014965144314743465
Epoch #123: loss=0.018841364449802625
Epoch #124: loss=0.023293439894364422
Epoch #125: loss=0.020102588716835342
Epoch #126: loss=0.02364899723650351
Epoch #127: loss=0.016199774893707938
Epoch #128: loss=0.019122379676637477
Epoch #129: loss=0.01683653721076595
Epoch #130: loss=0.02452172474081491
Epoch #131: loss=0.0158650313860667
Epoch #132: loss=0.019585014971091226
Epoch #133: loss=0.0288746139121521
Epoch #134: loss=0.037922838478522264
Epoch #135: loss=0.025521392846125732
Epoch #136: loss=0.0233373276896705
Epoch #137: loss=0.0224823264270264
Epoch #138: loss=0.01645045284408625
Epoch #139: loss=0.015708845288738317
Epoch #140: loss=0.019127550288989218
Epoch #141: loss=0.015125069961485906
Epoch #142: loss=0.030012813154862983
Epoch #143: loss=0.0247234495427803
Epoch #144: loss=0.021906200537534556
Epoch #145: loss=0.015981438582640957
Epoch #146: loss=0.022258186697763974
Epoch #147: loss=0.028198492255495318
Epoch #148: loss=0.026056610710747132
Epoch #149: loss=0.019792920327326016
Epoch #150: loss=0.02130389944680427
Epoch #151: loss=0.020829459430880694
Epoch #152: loss=0.027611080765783228
Epoch #153: loss=0.023031553686482385
Epoch #154: loss=0.01707766852905217
Epoch #155: loss=0.020153976259927563
Epoch #156: loss=0.025422272036222455
Epoch #157: loss=0.02475559896714341
Epoch #158: loss=0.023124326518515356
Epoch #159: loss=0.03088861073686685
Epoch #160: loss=0.014043727730382745
Epoch #161: loss=0.015468672579000047
Epoch #162: loss=0.0297638161429298
Epoch #163: loss=0.021620983610322875
Epoch #164: loss=0.018079044142676255
Epoch #165: loss=0.01889433814511267
Epoch #166: loss=0.01493642874498535
Epoch #167: loss=0.01534463230219216
Epoch #168: loss=0.019058024048099365
Epoch #169: loss=0.027261805553720615
Epoch #170: loss=0.014402042111846208
Epoch #171: loss=0.021371577232297757
Epoch #172: loss=0.025584986721070197
Epoch #173: loss=0.020173797278392587
Epoch #174: loss=0.020513056437733185
Epoch #175: loss=0.01287392762446674
Epoch #176: loss=0.018990312456368046
Epoch #177: loss=0.02654435902012657
Epoch #178: loss=0.015129348345339749
Epoch #179: loss=0.025053594524264925
Epoch #180: loss=0.02105735731361466
Epoch #181: loss=0.032815201485781834
Epoch #182: loss=0.020329203263565264
Epoch #183: loss=0.024748784670256003
Epoch #184: loss=0.02202177006162177
Epoch #185: loss=0.031011633617066717
Epoch #186: loss=0.026277161084225547
Epoch #187: loss=0.02013008853857424
Epoch #188: loss=0.017231879520675526
Epoch #189: loss=0.01571583581728705
Epoch #190: loss=0.013359940007277993
Epoch #191: loss=0.01777643914965534
Epoch #192: loss=0.016296095220319745
Epoch #193: loss=0.020760100938598505
Epoch #194: loss=0.019430661846760136
Epoch #195: loss=0.016936950988950802
Epoch #196: loss=0.019741164188917932
Epoch #197: loss=0.019783773686789158
Epoch #198: loss=0.016486290131557346
Epoch #199: loss=0.02000629636445633
Epoch #200: loss=0.015007014610631505
Epoch #201: loss=0.021358462438887785
Epoch #202: loss=0.01575663309461794
Epoch #203: loss=0.019655731920138142
Epoch #204: loss=0.029443153279990506
Epoch #205: loss=0.017227161257837763
Epoch #206: loss=0.02620869850111127
Epoch #207: loss=0.018612422429995414
Epoch #208: loss=0.018402863094604625
Epoch #209: loss=0.01288717089828791
Epoch #210: loss=0.014539019792120614
Epoch #211: loss=0.03385437980041939
Epoch #212: loss=0.033233751310035586
Epoch #213: loss=0.022650054105260928
Epoch #214: loss=0.013210174956299251
Epoch #215: loss=0.016189636322750202
Epoch #216: loss=0.014667742436594713
Epoch #217: loss=0.014322466792012713
Epoch #218: loss=0.015349792968246935
Epoch #219: loss=0.02277822879740904
Epoch #220: loss=0.012770337371778961
Epoch #221: loss=0.014200241059270856
Epoch #222: loss=0.017759995409542484
Epoch #223: loss=0.019365736560728965
Epoch #224: loss=0.018368417412909527
Epoch #225: loss=0.025417677891911718
Epoch #226: loss=0.021769842264606144
Epoch #227: loss=0.01399647768839163
Epoch #228: loss=0.017569432280416217
Epoch #229: loss=0.039144681481126514
Epoch #230: loss=0.023847320517296943
Epoch #231: loss=0.01576015776374192
Epoch #232: loss=0.012401294753945805
Epoch #233: loss=0.020119202606244446
Epoch #234: loss=0.02265916771311796
Epoch #235: loss=0.020030182790815004
Epoch #236: loss=0.020165566102533148
Epoch #237: loss=0.024989260255086694
Epoch #238: loss=0.015598911453613485
Epoch #239: loss=0.012697881034988727
Epoch #240: loss=0.016068918854756392
Epoch #241: loss=0.013257946142717466
Epoch #242: loss=0.013734562481855518
Epoch #243: loss=0.012326830405754007
Epoch #244: loss=0.012034871303798465
Epoch #245: loss=0.013906344906336384
Epoch #246: loss=0.025812751054629598
Epoch #247: loss=0.019764832316418728
Epoch #248: loss=0.02051021325157389
Epoch #249: loss=0.021593624052272234

Training time: 1:46:03.309984

Finished.
n2one setting etth1_ettm1_electricity_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_electricity_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_ettm1_electricity_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.58309e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.18868e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.18868e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.669813998000122, 'MAE': 0.6309627939882697}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm1_traffic_weather', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm1_traffic_weather_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.0818927412067292
Epoch #1: loss=0.4589979576551362
Epoch #2: loss=0.3162901387704129
Epoch #3: loss=0.24678231882667437
Epoch #4: loss=0.19575757524677065
Epoch #5: loss=0.1709033901295388
Epoch #6: loss=0.1505432552257121
Epoch #7: loss=0.13852510041666216
Epoch #8: loss=0.12423618522289705
Epoch #9: loss=0.10005378686138336
Epoch #10: loss=0.07894698198613347
Epoch #11: loss=0.08378121639636836
Epoch #12: loss=0.07922466530333012
Epoch #13: loss=0.06780215049168675
Epoch #14: loss=0.06776721047229292
Epoch #15: loss=0.06196937315827996
Epoch #16: loss=0.04868545068533799
Epoch #17: loss=0.053625532448297944
Epoch #18: loss=0.05476304972464646
Epoch #19: loss=0.05058941353476353
Epoch #20: loss=0.04463384827474547
Epoch #21: loss=0.0410662291876799
Epoch #22: loss=0.03813120973249949
Epoch #23: loss=0.04580895447212829
Epoch #24: loss=0.07406351430442855
Epoch #25: loss=0.04258175073941927
Epoch #26: loss=0.026676018964437557
Epoch #27: loss=0.029129337541122714
Epoch #28: loss=0.034461954792691124
Epoch #29: loss=0.04168643365769851
Epoch #30: loss=0.043710103026302384
Epoch #31: loss=0.03532388248962965
Epoch #32: loss=0.03068061228972607
Epoch #33: loss=0.03886611190512489
Epoch #34: loss=0.03979922556525218
Epoch #35: loss=0.023703445848316535
Epoch #36: loss=0.03298274487941619
Epoch #37: loss=0.030466506235937794
Epoch #38: loss=0.028534241732663248
Epoch #39: loss=0.027424812549146953
Epoch #40: loss=0.028243922750981088
Epoch #41: loss=0.03318865671176947
Epoch #42: loss=0.027231116507577074
Epoch #43: loss=0.03338870814002775
Epoch #44: loss=0.023704791506706114
Epoch #45: loss=0.03374984685520983
Epoch #46: loss=0.025824754246408798
Epoch #47: loss=0.020900539598848144
Epoch #48: loss=0.03207659181071215
Epoch #49: loss=0.023010187937117902
Epoch #50: loss=0.02625054946088563
Epoch #51: loss=0.025365200042444493
Epoch #52: loss=0.023759988934342866
Epoch #53: loss=0.033877954926114597
Epoch #54: loss=0.02673126567867235
Epoch #55: loss=0.025358252562353772
Epoch #56: loss=0.022979273140599034
Epoch #57: loss=0.027048322274194153
Epoch #58: loss=0.01933116714847089
Epoch #59: loss=0.02009639124351705
Epoch #60: loss=0.025830852062013267
Epoch #61: loss=0.019840090488359666
Epoch #62: loss=0.02109925402206303
Epoch #63: loss=0.02648220850838601
Epoch #64: loss=0.017550583112824023
Epoch #65: loss=0.02319000989893065
Epoch #66: loss=0.014667220215965114
Epoch #67: loss=0.01913978929895338
Epoch #68: loss=0.020329828596928067
Epoch #69: loss=0.02922661522779589
Epoch #70: loss=0.014717376640860081
Epoch #71: loss=0.019548506330979872
Epoch #72: loss=0.022382998687526617
Epoch #73: loss=0.019378045089152245
Epoch #74: loss=0.01765814580978768
Epoch #75: loss=0.019302244270662416
Epoch #76: loss=0.021799105271261707
Epoch #77: loss=0.025231412620896322
Epoch #78: loss=0.026111456910564584
Epoch #79: loss=0.018224970509157317
Epoch #80: loss=0.015479449181656597
Epoch #81: loss=0.013906363588714126
Epoch #82: loss=0.03047305090700083
Epoch #83: loss=0.021609092918730897
Epoch #84: loss=0.013499437425976616
Epoch #85: loss=0.01594723493185112
Epoch #86: loss=0.02166265195400596
Epoch #87: loss=0.020437743446353317
Epoch #88: loss=0.020902531058932285
Epoch #89: loss=0.017927261824671036
Epoch #90: loss=0.014458163022631615
Epoch #91: loss=0.021020235720329693
Epoch #92: loss=0.01894664656006984
Epoch #93: loss=0.017771796562662527
Epoch #94: loss=0.020420101702212774
Epoch #95: loss=0.018458770929118934
Epoch #96: loss=0.024177296421165263
Epoch #97: loss=0.016601320685042432
Epoch #98: loss=0.019913427426900446
Epoch #99: loss=0.015588486045133836
Epoch #100: loss=0.015533064358766708
Epoch #101: loss=0.01852066080480666
Epoch #102: loss=0.01657989147508817
Epoch #103: loss=0.017320736302606398
Epoch #104: loss=0.017427449886482538
Epoch #105: loss=0.01398226588015022
Epoch #106: loss=0.018037491554993658
Epoch #107: loss=0.029953697389774242
Epoch #108: loss=0.019933265378660414
Epoch #109: loss=0.01303403932004617
Epoch #110: loss=0.011448073435832271
Epoch #111: loss=0.01897554245422657
Epoch #112: loss=0.014099680280517715
Epoch #113: loss=0.02123749953639775
Epoch #114: loss=0.015882881659069707
Epoch #115: loss=0.013617615636313364
Epoch #116: loss=0.01774648362361424
Epoch #117: loss=0.013433137219048426
Epoch #118: loss=0.016443774138020617
Epoch #119: loss=0.01786350617894882
Epoch #120: loss=0.01670401198832523
Epoch #121: loss=0.009105766146383006
Epoch #122: loss=0.025072875178188278
Epoch #123: loss=0.015135888136235487
Epoch #124: loss=0.015941928966230687
Epoch #125: loss=0.01710520850993188
Epoch #126: loss=0.02225524121292797
Epoch #127: loss=0.013445844738160838
Epoch #128: loss=0.012171467114927373
Epoch #129: loss=0.013129543011066726
Epoch #130: loss=0.015798704076884596
Epoch #131: loss=0.016383887829638608
Epoch #132: loss=0.017188111423125704
Epoch #133: loss=0.01279268771614679
Epoch #134: loss=0.016122463315896993
Epoch #135: loss=0.012104528604347591
Epoch #136: loss=0.01371776887101186
Epoch #137: loss=0.014962706990391232
Epoch #138: loss=0.018375823783218476
Epoch #139: loss=0.013269610502220029
Epoch #140: loss=0.019764558839247815
Epoch #141: loss=0.017736418884508127
Epoch #142: loss=0.013445935495227712
Epoch #143: loss=0.015246435443235451
Epoch #144: loss=0.01677797060550155
Epoch #145: loss=0.0105688530782223
Epoch #146: loss=0.014926504866910325
Epoch #147: loss=0.017382217646822143
Epoch #148: loss=0.014067977644946677
Epoch #149: loss=0.01420672206215434
Epoch #150: loss=0.016536140736700913
Epoch #151: loss=0.015271471559963596
Epoch #152: loss=0.01564345509225038
Epoch #153: loss=0.01208953592315533
Epoch #154: loss=0.014507956690380863
Epoch #155: loss=0.013039069438983314
Epoch #156: loss=0.00918521848876645
Epoch #157: loss=0.014354470297875623
Epoch #158: loss=0.014297804705886387
Epoch #159: loss=0.012038543555876816
Epoch #160: loss=0.013117850264655138
Epoch #161: loss=0.015941100215288002
Epoch #162: loss=0.010462062343496703
Epoch #163: loss=0.03141648876588693
Epoch #164: loss=0.017893503192253593
Epoch #165: loss=0.010345442195865737
Epoch #166: loss=0.0238805086979366
Epoch #167: loss=0.012354365183645962
Epoch #168: loss=0.013760659382422866
Epoch #169: loss=0.01438387134330857
Epoch #170: loss=0.014545375576236894
Epoch #171: loss=0.014220795555414927
Epoch #172: loss=0.011208854794230366
Epoch #173: loss=0.009658346032761948
Epoch #174: loss=0.017753956614546096
Epoch #175: loss=0.008184592948940472
Epoch #176: loss=0.012064055512587553
Epoch #177: loss=0.017326570974626792
Epoch #178: loss=0.01845812308460692
Epoch #179: loss=0.012153104866385716
Epoch #180: loss=0.011672302402465227
Epoch #181: loss=0.012738230930738049
Epoch #182: loss=0.025746487365889355
Epoch #183: loss=0.007721562029305068
Epoch #184: loss=0.0156710558485449
Epoch #185: loss=0.011830406647152935
Epoch #186: loss=0.012885338456740513
Epoch #187: loss=0.013946645194857337
Epoch #188: loss=0.0178541725037363
Epoch #189: loss=0.012876639065086517
Epoch #190: loss=0.013970481418574304
Epoch #191: loss=0.011027595717328854
Epoch #192: loss=0.013094963651062061
Epoch #193: loss=0.011145084737074715
Epoch #194: loss=0.013080649404940976
Epoch #195: loss=0.01668636991880643
Epoch #196: loss=0.010593426446053898
Epoch #197: loss=0.008142713196021834
Epoch #198: loss=0.01216755734139048
Epoch #199: loss=0.012116128650112166
Epoch #200: loss=0.016386243447642897
Epoch #201: loss=0.016751641734818277
Epoch #202: loss=0.011802810845612887
Epoch #203: loss=0.012497640641074151
Epoch #204: loss=0.009774838489665733
Epoch #205: loss=0.014150996760082421
Epoch #206: loss=0.013895725254436506
Epoch #207: loss=0.010980254146155452
Epoch #208: loss=0.02135009738501258
Epoch #209: loss=0.012560229419061665
Epoch #210: loss=0.009137027945431031
Epoch #211: loss=0.010661507753631415
Epoch #212: loss=0.013044212827506906
Epoch #213: loss=0.012798685701147635
Epoch #214: loss=0.008483260693347153
Epoch #215: loss=0.01319637054035676
Epoch #216: loss=0.014536602713777885
Epoch #217: loss=0.013658084323404616
Epoch #218: loss=0.011934813103058054
Epoch #219: loss=0.010801942637791573
Epoch #220: loss=0.012172437822120014
Epoch #221: loss=0.006272392691408654
Epoch #222: loss=0.017123703485159215
Epoch #223: loss=0.009808042349269928
Epoch #224: loss=0.006802392232114353
Epoch #225: loss=0.009689343767744982
Epoch #226: loss=0.013986316129139153
Epoch #227: loss=0.012475430000564145
Epoch #228: loss=0.011828593926380386
Epoch #229: loss=0.009710947727276419
Epoch #230: loss=0.013704668667760295
Epoch #231: loss=0.016241877800430363
Epoch #232: loss=0.009116902222929992
Epoch #233: loss=0.009883881475178682
Epoch #234: loss=0.01237035146633744
Epoch #235: loss=0.01162709206733021
Epoch #236: loss=0.009384495708668039
Epoch #237: loss=0.013107634300953774
Epoch #238: loss=0.00977473119902116
Epoch #239: loss=0.012710937353010494
Epoch #240: loss=0.00961567825338303
Epoch #241: loss=0.012403425933166394
Epoch #242: loss=0.013040248650886054
Epoch #243: loss=0.013859121091589311
Epoch #244: loss=0.010663990016182973
Epoch #245: loss=0.008624130002106732
Epoch #246: loss=0.015213447832977851
Epoch #247: loss=0.009724536611198471
Epoch #248: loss=0.014524712179501301
Epoch #249: loss=0.013007891458196042

Training time: 3:47:49.756887

Finished.
n2one setting etth1_ettm1_traffic_weather -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_traffic_weather_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_ettm1_traffic_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.38186e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.05238e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.46539e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.38186e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4177132767864708, 'MAE': 0.46005665808388746}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm1_traffic_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_traffic_weather_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_ettm1_traffic_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.11781e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.34424572438061807, 'MAE': 0.38527895757812497}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm1_traffic_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm1_traffic_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.0452615586487022
Epoch #1: loss=0.3886616160539356
Epoch #2: loss=0.28288448915758113
Epoch #3: loss=0.23065955177587164
Epoch #4: loss=0.17660291912873183
Epoch #5: loss=0.15204969367750729
Epoch #6: loss=0.13053773651906364
Epoch #7: loss=0.10392479009628464
Epoch #8: loss=0.09246082543416435
Epoch #9: loss=0.09990804642753524
Epoch #10: loss=0.08367943559324385
Epoch #11: loss=0.0720767172605118
Epoch #12: loss=0.07791380720896865
Epoch #13: loss=0.0632327354354742
Epoch #14: loss=0.06284272887582497
Epoch #15: loss=0.06934386785435784
Epoch #16: loss=0.05321039319398125
Epoch #17: loss=0.05400113572171461
Epoch #18: loss=0.048310279153861095
Epoch #19: loss=0.04141389000699394
Epoch #20: loss=0.05338643361874101
Epoch #21: loss=0.04515386410036569
Epoch #22: loss=0.047226200509907654
Epoch #23: loss=0.039169195710643624
Epoch #24: loss=0.042181547428913904
Epoch #25: loss=0.03863886335215989
Epoch #26: loss=0.04289826243090116
Epoch #27: loss=0.039918777061577024
Epoch #28: loss=0.03875038346922264
Epoch #29: loss=0.037109731808504055
Epoch #30: loss=0.03136878062421372
Epoch #31: loss=0.03450779458472499
Epoch #32: loss=0.04073449684021709
Epoch #33: loss=0.03646591662071112
Epoch #34: loss=0.029076564589804794
Epoch #35: loss=0.03576591013427845
Epoch #36: loss=0.027711960991534095
Epoch #37: loss=0.031749674740920227
Epoch #38: loss=0.03079211421972686
Epoch #39: loss=0.030387465267857485
Epoch #40: loss=0.03037693504262967
Epoch #41: loss=0.034102047965961495
Epoch #42: loss=0.033350894337484345
Epoch #43: loss=0.025372245120485564
Epoch #44: loss=0.03154153889215547
Epoch #45: loss=0.026947337364896434
Epoch #46: loss=0.03248533063100416
Epoch #47: loss=0.031009514733382315
Epoch #48: loss=0.0224258562233084
Epoch #49: loss=0.023186721617978922
Epoch #50: loss=0.02245101382888262
Epoch #51: loss=0.02612823174809114
Epoch #52: loss=0.02129080440322837
Epoch #53: loss=0.0246511445279015
Epoch #54: loss=0.025506260622146452
Epoch #55: loss=0.030396756042358215
Epoch #56: loss=0.03329721026324199
Epoch #57: loss=0.026190538762117892
Epoch #58: loss=0.023865401744514785
Epoch #59: loss=0.021711652800346398
Epoch #60: loss=0.020065939279447775
Epoch #61: loss=0.022794160574752215
Epoch #62: loss=0.02677533802462832
Epoch #63: loss=0.03745434696460719
Epoch #64: loss=0.01973317411158188
Epoch #65: loss=0.023037686434789165
Epoch #66: loss=0.025033755392714
Epoch #67: loss=0.02014775204457561
Epoch #68: loss=0.02255997350330126
Epoch #69: loss=0.028544353489262715
Epoch #70: loss=0.01971060581736556
Epoch #71: loss=0.019776741995359247
Epoch #72: loss=0.021820256763611403
Epoch #73: loss=0.026995824681983544
Epoch #74: loss=0.022587147934508073
Epoch #75: loss=0.01832821602881456
Epoch #76: loss=0.018665075732552633
Epoch #77: loss=0.0172330300460794
Epoch #78: loss=0.018055419359124907
Epoch #79: loss=0.019368897854620044
Epoch #80: loss=0.02260635261854413
Epoch #81: loss=0.02462618641505754
Epoch #82: loss=0.018456634353119502
Epoch #83: loss=0.01681540506094304
Epoch #84: loss=0.021862455101228563
Epoch #85: loss=0.017401702446108714
Epoch #86: loss=0.02154656967861622
Epoch #87: loss=0.015386794084422962
Epoch #88: loss=0.016175956385465012
Epoch #89: loss=0.023640186524635856
Epoch #90: loss=0.01903369217020431
Epoch #91: loss=0.019587144299851037
Epoch #92: loss=0.02161674052934416
Epoch #93: loss=0.018810082804020977
Epoch #94: loss=0.022860293034174393
Epoch #95: loss=0.027845862439609667
Epoch #96: loss=0.01459423267409842
Epoch #97: loss=0.013121053197628007
Epoch #98: loss=0.023085637426324742
Epoch #99: loss=0.019547275212742306
Epoch #100: loss=0.01691834075150378
Epoch #101: loss=0.017175426385513566
Epoch #102: loss=0.0218618579152413
Epoch #103: loss=0.01812635328429793
Epoch #104: loss=0.022156356710282224
Epoch #105: loss=0.015606100840241279
Epoch #106: loss=0.017686321599670395
Epoch #107: loss=0.015164153840118702
Epoch #108: loss=0.018829232849908818
Epoch #109: loss=0.01686904201936134
Epoch #110: loss=0.013163779016640792
Epoch #111: loss=0.017101122171907634
Epoch #112: loss=0.013552011257726574
Epoch #113: loss=0.01299035062480913
Epoch #114: loss=0.04449165711661293
Epoch #115: loss=0.016453325230867375
Epoch #116: loss=0.014935148417436296
Epoch #117: loss=0.016887125371746102
Epoch #118: loss=0.01727249963975434
Epoch #119: loss=0.013994260590881642
Epoch #120: loss=0.014662858956996986
Epoch #121: loss=0.014650026712859488
Epoch #122: loss=0.01616932551407776
Epoch #123: loss=0.014310629905414136
Epoch #124: loss=0.011111662897960044
Epoch #125: loss=0.02012642242475481
Epoch #126: loss=0.01268739613114703
Epoch #127: loss=0.014368670021376765
Epoch #128: loss=0.01943443661766323
Epoch #129: loss=0.019254748136960632
Epoch #130: loss=0.015887147979941934
Epoch #131: loss=0.016724980267050292
Epoch #132: loss=0.012239296608517965
Epoch #133: loss=0.013882022027180871
Epoch #134: loss=0.014089607229769105
Epoch #135: loss=0.015924035724638415
Epoch #136: loss=0.01712839874446283
Epoch #137: loss=0.017505020833784517
Epoch #138: loss=0.015779843331090903
Epoch #139: loss=0.013313231269028227
Epoch #140: loss=0.017644273070546408
Epoch #141: loss=0.023930536120747706
Epoch #142: loss=0.013096692363523378
Epoch #143: loss=0.015033312531339287
Epoch #144: loss=0.02004044132106198
Epoch #145: loss=0.01775062128456796
Epoch #146: loss=0.012258683990473179
Epoch #147: loss=0.017812720378666807
Epoch #148: loss=0.013330414838885583
Epoch #149: loss=0.014265144952750651
Epoch #150: loss=0.01628446789190757
Epoch #151: loss=0.015772503932673425
Epoch #152: loss=0.017130530997173418
Epoch #153: loss=0.013083553877558196
Epoch #154: loss=0.021292643928317628
Epoch #155: loss=0.014711036136538274
Epoch #156: loss=0.014963738799689291
Epoch #157: loss=0.017200273396123487
Epoch #158: loss=0.013172283662017665
Epoch #159: loss=0.014305211509578454
Epoch #160: loss=0.015278813815802185
Epoch #161: loss=0.015898357541200395
Epoch #162: loss=0.013416029171403844
Epoch #163: loss=0.014134081862459163
Epoch #164: loss=0.016614055691378953
Epoch #165: loss=0.016023109734059952
Epoch #166: loss=0.018158854457323213
Epoch #167: loss=0.011074908983114706
Epoch #168: loss=0.015124971067364042
Epoch #169: loss=0.00946510496191672
Epoch #170: loss=0.017084685454638267
Epoch #171: loss=0.014851482611406895
Epoch #172: loss=0.012900446319035181
Epoch #173: loss=0.015976159159395098
Epoch #174: loss=0.019680719636059482
Epoch #175: loss=0.012787092009062149
Epoch #176: loss=0.012685643788597543
Epoch #177: loss=0.014171778615933805
Epoch #178: loss=0.010968919253935235
Epoch #179: loss=0.01371003596083225
Epoch #180: loss=0.010193526880986101
Epoch #181: loss=0.015490619685970323
Epoch #182: loss=0.017096518388489704
Epoch #183: loss=0.012511674430267728
Epoch #184: loss=0.01091241225767262
Epoch #185: loss=0.01602749056532834
Epoch #186: loss=0.01743426636184685
Epoch #187: loss=0.01713259897276346
Epoch #188: loss=0.011461030518394427
Epoch #189: loss=0.00936899720021232
Epoch #190: loss=0.016671527345450257
Epoch #191: loss=0.01722448927578191
Epoch #192: loss=0.011184116141029753
Epoch #193: loss=0.013207945427311971
Epoch #194: loss=0.013931856800555325
Epoch #195: loss=0.013438468597922946
Epoch #196: loss=0.011518636123337029
Epoch #197: loss=0.012846093865338335
Epoch #198: loss=0.014592574107368122
Epoch #199: loss=0.012579078918889763
Epoch #200: loss=0.015539277455687412
Epoch #201: loss=0.010589481869173396
Epoch #202: loss=0.02304330197277834
Epoch #203: loss=0.011673879107842662
Epoch #204: loss=0.01080401463233913
Epoch #205: loss=0.01983259378563174
Epoch #206: loss=0.012194793696933728
Epoch #207: loss=0.011874744817465104
Epoch #208: loss=0.020459355989481304
Epoch #209: loss=0.015163455011506219
Epoch #210: loss=0.017135962620159262
Epoch #211: loss=0.015371899242824371
Epoch #212: loss=0.014353724351511462
Epoch #213: loss=0.014307644453855663
Epoch #214: loss=0.012163471665124168
Epoch #215: loss=0.015592592149619737
Epoch #216: loss=0.012870463013429003
Epoch #217: loss=0.009433805862778451
Epoch #218: loss=0.01221089319798167
Epoch #219: loss=0.019811713606818434
Epoch #220: loss=0.009953805298996362
Epoch #221: loss=0.015632830865273194
Epoch #222: loss=0.013246078766724578
Epoch #223: loss=0.01315450290414512
Epoch #224: loss=0.012773453700123486
Epoch #225: loss=0.013567952070376565
Epoch #226: loss=0.014639987131050549
Epoch #227: loss=0.016426188485212635
Epoch #228: loss=0.012131657673389864
Epoch #229: loss=0.01032102620898546
Epoch #230: loss=0.013443154495927284
Epoch #231: loss=0.010977591407346473
Epoch #232: loss=0.020074504623497323
Epoch #233: loss=0.018840037730491907
Epoch #234: loss=0.010967821412229675
Epoch #235: loss=0.01632753913535297
Epoch #236: loss=0.01582348939500826
Epoch #237: loss=0.014812946566471018
Epoch #238: loss=0.017447223321289278
Epoch #239: loss=0.012387649121412143
Epoch #240: loss=0.010507302333657586
Epoch #241: loss=0.011811188373563332
Epoch #242: loss=0.013951250090391474
Epoch #243: loss=0.01025295740957419
Epoch #244: loss=0.009712726413163602
Epoch #245: loss=0.012769570368454716
Epoch #246: loss=0.01182928871478473
Epoch #247: loss=0.016217800104936328
Epoch #248: loss=0.01286136127942587
Epoch #249: loss=0.010776106015295195

Training time: 3:36:50.539394

Finished.
n2one setting etth1_ettm1_traffic_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_traffic_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_ettm1_traffic_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.16096e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.35278e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.16096e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.41273000732805426, 'MAE': 0.45890004902345194}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm1_traffic_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_traffic_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_ettm1_traffic_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.73625e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.46036e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.73625e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.9578745643363905, 'MAE': 0.81517995354395}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm1_weather_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm1_weather_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=6.029198353107159
Epoch #1: loss=2.795547746695005
Epoch #2: loss=2.2525623853390035
Epoch #3: loss=2.1618992938445163
Epoch #4: loss=1.9926865032086005
Epoch #5: loss=1.9791450248314784
Epoch #6: loss=1.8902528033806727
Epoch #7: loss=1.7577266922363868
Epoch #8: loss=1.6293868651756873
Epoch #9: loss=1.513445340670072
Epoch #10: loss=1.5030557054739733
Epoch #11: loss=1.3281895380753737
Epoch #12: loss=1.2583793115157347
Epoch #13: loss=1.2122277388205895
Epoch #14: loss=1.2503764377190516
Epoch #15: loss=1.073650292479075
Epoch #16: loss=1.0641202112803092
Epoch #17: loss=1.0303891794039652
Epoch #18: loss=1.0257517844438553
Epoch #19: loss=0.9988404420705942
Epoch #20: loss=0.9362792991674863
Epoch #21: loss=1.010933803824278
Epoch #22: loss=0.9413098073922671
Epoch #23: loss=0.9962275910835999
Epoch #24: loss=0.9127872643562464
Epoch #25: loss=0.8115137781088169
Epoch #26: loss=0.7954410669895319
Epoch #27: loss=0.8503299974478208
Epoch #28: loss=0.7699844436003611
Epoch #29: loss=0.749523774935649
Epoch #30: loss=0.7236680869872754
Epoch #31: loss=0.6967447789815756
Epoch #32: loss=0.6556023984001234
Epoch #33: loss=0.7214375333144114
Epoch #34: loss=0.7179473816202238
Epoch #35: loss=0.6461838157131121
Epoch #36: loss=0.7029356125455636
Epoch #37: loss=0.6789568255727108
Epoch #38: loss=0.6407603529783396
Epoch #39: loss=0.6597160484928352
Epoch #40: loss=0.6382312608452944
Epoch #41: loss=0.6200851396872447
Epoch #42: loss=0.6245632326373687
Epoch #43: loss=0.5591884272602888
Epoch #44: loss=0.5159335314081266
Epoch #45: loss=0.578481915478523
Epoch #46: loss=0.5045870427901928
Epoch #47: loss=0.5417421534657478
Epoch #48: loss=0.5455858501104208
Epoch #49: loss=0.5532026778046901
Epoch #50: loss=0.5115674820083839
Epoch #51: loss=0.5187934705844293
Epoch #52: loss=0.5026918747104131
Epoch #53: loss=0.48205064552334637
Epoch #54: loss=0.5063779984529202
Epoch #55: loss=0.46117741471299756
Epoch #56: loss=0.507423463349159
Epoch #57: loss=0.47181366899838817
Epoch #58: loss=0.4203751731950503
Epoch #59: loss=0.45967002127033013
Epoch #60: loss=0.4812327273763143
Epoch #61: loss=0.4591292403638363
Epoch #62: loss=0.39244731773550695
Epoch #63: loss=0.4068008933502894
Epoch #64: loss=0.4061565740177265
Epoch #65: loss=0.49333984376146245
Epoch #66: loss=0.374213865170112
Epoch #67: loss=0.3720610634638713
Epoch #68: loss=0.37653682868068034
Epoch #69: loss=0.42194168069041693
Epoch #70: loss=0.3908009950358134
Epoch #71: loss=0.3678054640499445
Epoch #72: loss=0.3603935167193413
Epoch #73: loss=0.3590645380318165
Epoch #74: loss=0.3463597291937241
Epoch #75: loss=0.3239750883613641
Epoch #76: loss=0.3116829621677215
Epoch #77: loss=0.30640684268795526
Epoch #78: loss=0.3524434600885098
Epoch #79: loss=0.3045452101012835
Epoch #80: loss=0.2720523483764667
Epoch #81: loss=0.303263542170708
Epoch #82: loss=0.3166854252608923
Epoch #83: loss=0.313139151638517
Epoch #84: loss=0.2678527015332992
Epoch #85: loss=0.3084630832935755
Epoch #86: loss=0.3207088162979254
Epoch #87: loss=0.24188577039883688
Epoch #88: loss=0.34109605089403117
Epoch #89: loss=0.3277956541054524
Epoch #90: loss=0.2605015179858758
Epoch #91: loss=0.2263884458404321
Epoch #92: loss=0.235560848735846
Epoch #93: loss=0.4114110775005359
Epoch #94: loss=0.3471861993177579
Epoch #95: loss=0.38550764637497753
Epoch #96: loss=0.3499830402433872
Epoch #97: loss=0.27163652359293056
Epoch #98: loss=0.3137143530811255
Epoch #99: loss=0.25388315764184183
Epoch #100: loss=0.32742521123817336
Epoch #101: loss=0.2261781274842528
Epoch #102: loss=0.2686298925859424
Epoch #103: loss=0.22037222451315477
Epoch #104: loss=0.21360080130398273
Epoch #105: loss=0.22385164335943186
Epoch #106: loss=0.2833595721480938
Epoch #107: loss=0.19621585596066254
Epoch #108: loss=0.26356214557129604
Epoch #109: loss=0.28560260869562626
Epoch #110: loss=0.20510866686415213
Epoch #111: loss=0.22560224775224924
Epoch #112: loss=0.2193970218873941
Epoch #113: loss=0.18926796252624348
Epoch #114: loss=0.20147070181197846
Epoch #115: loss=0.19022665910709363
Epoch #116: loss=0.20342288023004165
Epoch #117: loss=0.18967432335305673
Epoch #118: loss=0.1539521381402245
Epoch #119: loss=0.2204233227440944
Epoch #120: loss=0.18420963684240213
Epoch #121: loss=0.1864979054348973
Epoch #122: loss=0.16247768191477427
Epoch #123: loss=0.19782646820665553
Epoch #124: loss=0.17743172131192225
Epoch #125: loss=0.17117399987406456
Epoch #126: loss=0.16472572818971598
Epoch #127: loss=0.17948615071005547
Epoch #128: loss=0.24187112484986967
Epoch #129: loss=0.24552715906443504
Epoch #130: loss=0.2034117108067641
Epoch #131: loss=0.17132089308534676
Epoch #132: loss=0.16737834357011777
Epoch #133: loss=0.15611599726029313
Epoch #134: loss=0.1255518107030254
Epoch #135: loss=0.14169344588970909
Epoch #136: loss=0.11773922960632123
Epoch #137: loss=0.15715692475294837
Epoch #138: loss=0.13161541980046493
Epoch #139: loss=0.14263813745660278
Epoch #140: loss=0.1813447567849205
Epoch #141: loss=0.13562741001638082
Epoch #142: loss=0.25356147065758705
Epoch #143: loss=0.14541829764269865
Epoch #144: loss=0.13271547535147804
Epoch #145: loss=0.12451135252530758
Epoch #146: loss=0.11782565401293911
Epoch #147: loss=0.14587881007733253
Epoch #148: loss=0.14434811376178494
Epoch #149: loss=0.13963580396599495
Epoch #150: loss=0.14927640607437262
Epoch #151: loss=0.1418716830846209
Epoch #152: loss=0.37347956445927805
Epoch #153: loss=0.17143109175734794
Epoch #154: loss=0.20100134439193285
Epoch #155: loss=0.20838197263387534
Epoch #156: loss=0.1755839865296506
Epoch #157: loss=0.15476997934568387
Epoch #158: loss=0.13860332493025523
Epoch #159: loss=0.1487239200550203
Epoch #160: loss=0.14854192665706462
Epoch #161: loss=0.1095783282071352
Epoch #162: loss=0.149350173628101
Epoch #163: loss=0.1503836031859884
Epoch #164: loss=0.161936993459956
Epoch #165: loss=0.13120494012792522
Epoch #166: loss=0.12525776376088077
Epoch #167: loss=0.11481194889459473
Epoch #168: loss=0.13343345527895367
Epoch #169: loss=0.11397237685294105
Epoch #170: loss=0.13536866782949522
Epoch #171: loss=0.11774391849310352
Epoch #172: loss=0.13189888439284495
Epoch #173: loss=0.16414673192999685
Epoch #174: loss=0.14761032429165566
Epoch #175: loss=0.15447569083279142
Epoch #176: loss=0.15288040822801682
Epoch #177: loss=0.10280585494967034
Epoch #178: loss=0.10934248806622165
Epoch #179: loss=0.11857668496668339
Epoch #180: loss=0.12472929225231592
Epoch #181: loss=0.10357248901317899
Epoch #182: loss=0.11608050828083204
Epoch #183: loss=0.09105224975456412
Epoch #184: loss=0.10337588384460944
Epoch #185: loss=0.09582058913432635
Epoch #186: loss=0.11543666211386713
Epoch #187: loss=0.0919923866704966
Epoch #188: loss=0.09328532756234591
Epoch #189: loss=0.11747153683637197
Epoch #190: loss=0.10623834446932261
Epoch #191: loss=0.10883346604756437
Epoch #192: loss=0.19646315076030219
Epoch #193: loss=0.12494352219912869
Epoch #194: loss=0.20743152542183033
Epoch #195: loss=0.15356315264048484
Epoch #196: loss=0.16751209277516374
Epoch #197: loss=0.11059234511608687
Epoch #198: loss=0.1344763281611869
Epoch #199: loss=0.11112250040213649
Epoch #200: loss=0.09471219586423384
Epoch #201: loss=0.1245953873372995
Epoch #202: loss=0.08007130066219431
Epoch #203: loss=0.08168545736071582
Epoch #204: loss=0.09859548817173792
Epoch #205: loss=0.0843835855440165
Epoch #206: loss=0.09305406268686056
Epoch #207: loss=0.09238373144314839
Epoch #208: loss=0.08335034423865952
Epoch #209: loss=0.12340735896633795
Epoch #210: loss=0.13239885164568058
Epoch #211: loss=0.18077292415098503
Epoch #212: loss=0.21764654755735627
Epoch #213: loss=0.5942238040554982
Epoch #214: loss=0.16805601908037296
Epoch #215: loss=0.16437392158863637
Epoch #216: loss=0.1296035277012449
Epoch #217: loss=0.11382507156723967
Epoch #218: loss=0.11164199876097533
Epoch #219: loss=0.10042531917301509
Epoch #220: loss=0.10598896339965555
Epoch #221: loss=0.09746830052552888
Epoch #222: loss=0.09890170762530313
Epoch #223: loss=0.08930670923123565
Epoch #224: loss=0.08359388211885324
Epoch #225: loss=0.07187581606782399
Epoch #226: loss=0.07905635171426603
Epoch #227: loss=0.0731377298048196
Epoch #228: loss=0.06698939764800553
Epoch #229: loss=0.08646668486583692
Epoch #230: loss=0.10287102087973975
Epoch #231: loss=0.08679733291053428
Epoch #232: loss=0.113195024502392
Epoch #233: loss=0.08421284961514175
Epoch #234: loss=0.1251186984591186
Epoch #235: loss=0.08940076498458019
Epoch #236: loss=0.08310251511060275
Epoch #237: loss=0.09662593308334741
Epoch #238: loss=0.07517804044227187
Epoch #239: loss=0.07516994557450883
Epoch #240: loss=0.09172013251540753
Epoch #241: loss=0.07056602661927733
Epoch #242: loss=0.10429836385166989
Epoch #243: loss=0.07431879652162585
Epoch #244: loss=0.08569931435900238
Epoch #245: loss=0.08202847489155829
Epoch #246: loss=0.11536019992154951
Epoch #247: loss=0.0985763322096318
Epoch #248: loss=0.10243431097254731
Epoch #249: loss=0.1270601034988291

Training time: 0:16:22.471643

Finished.
n2one setting etth1_ettm1_weather_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_weather_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_ettm1_weather_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.47295e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.91352e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.47295e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3685481985409558, 'MAE': 0.4332903618056074}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm2_electricity_traffic', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm2_electricity_traffic_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.8750846187563165
Epoch #1: loss=0.32930084243478824
Epoch #2: loss=0.21324268144731418
Epoch #3: loss=0.16013579020628724
Epoch #4: loss=0.12689055920850725
Epoch #5: loss=0.09727327987322154
Epoch #6: loss=0.08034074769512774
Epoch #7: loss=0.07477208724529245
Epoch #8: loss=0.0662659203174596
Epoch #9: loss=0.055666657936853124
Epoch #10: loss=0.051774934226946345
Epoch #11: loss=0.04559362456873276
Epoch #12: loss=0.04307267428658822
Epoch #13: loss=0.04954359676362442
Epoch #14: loss=0.0585732604865509
Epoch #15: loss=0.035262482840417386
Epoch #16: loss=0.03373127732271612
Epoch #17: loss=0.03296079347239688
Epoch #18: loss=0.04836408089657161
Epoch #19: loss=0.0360484374221802
Epoch #20: loss=0.03301977386841005
Epoch #21: loss=0.03422885840536901
Epoch #22: loss=0.025551051063386322
Epoch #23: loss=0.027158635936667376
Epoch #24: loss=0.02845289899954428
Epoch #25: loss=0.027415740784671745
Epoch #26: loss=0.025028822676375195
Epoch #27: loss=0.02724684635148175
Epoch #28: loss=0.028141089281486772
Epoch #29: loss=0.028403892175610068
Epoch #30: loss=0.021957658662557288
Epoch #31: loss=0.027846811690152958
Epoch #32: loss=0.02526644306787779
Epoch #33: loss=0.018010135902112024
Epoch #34: loss=0.022120548617021087
Epoch #35: loss=0.023176701829916442
Epoch #36: loss=0.029633529756311637
Epoch #37: loss=0.022910262284275815
Epoch #38: loss=0.02335555061599477
Epoch #39: loss=0.01941033322918543
Epoch #40: loss=0.019822030552030138
Epoch #41: loss=0.027289033834364956
Epoch #42: loss=0.02440950361677181
Epoch #43: loss=0.01644827837208216
Epoch #44: loss=0.021042752990390188
Epoch #45: loss=0.01845246719770858
Epoch #46: loss=0.02079107743888771
Epoch #47: loss=0.016103832719600964
Epoch #48: loss=0.02039940361047728
Epoch #49: loss=0.01970702309812226
Epoch #50: loss=0.017611406426773914
Epoch #51: loss=0.01664979295630813
Epoch #52: loss=0.018698817772760157
Epoch #53: loss=0.01904889413193031
Epoch #54: loss=0.017470721920004595
Epoch #55: loss=0.019447877232632256
Epoch #56: loss=0.014267079586404136
Epoch #57: loss=0.016807073168558333
Epoch #58: loss=0.014838927947713696
Epoch #59: loss=0.0213368580894276
Epoch #60: loss=0.014088612198754043
Epoch #61: loss=0.016518975536781576
Epoch #62: loss=0.01767956771278912
Epoch #63: loss=0.014144536703958764
Epoch #64: loss=0.018271645576616348
Epoch #65: loss=0.014297859173410667
Epoch #66: loss=0.014406519037173932
Epoch #67: loss=0.016032662509407828
Epoch #68: loss=0.01705325488968005
Epoch #69: loss=0.011948957248124838
Epoch #70: loss=0.015088064898363587
Epoch #71: loss=0.02735945941333843
Epoch #72: loss=0.014991147830604663
Epoch #73: loss=0.014476487130637386
Epoch #74: loss=0.010400474428103365
Epoch #75: loss=0.016888170691709548
Epoch #76: loss=0.018119806049528883
Epoch #77: loss=0.01590079407408414
Epoch #78: loss=0.01082998179968448
Epoch #79: loss=0.024709710683619338
Epoch #80: loss=0.01460695334641456
Epoch #81: loss=0.011750553267873005
Epoch #82: loss=0.012215575659897669
Epoch #83: loss=0.013805657906931198
Epoch #84: loss=0.011575974355480648
Epoch #85: loss=0.011021923395451452
Epoch #86: loss=0.016079467483606193
Epoch #87: loss=0.0146122232260066
Epoch #88: loss=0.011674819959194394
Epoch #89: loss=0.013779848660858074
Epoch #90: loss=0.010367853294528375
Epoch #91: loss=0.015521683748287081
Epoch #92: loss=0.012569661278232901
Epoch #93: loss=0.013239154099644962
Epoch #94: loss=0.01715896501274974
Epoch #95: loss=0.013922221360348753
Epoch #96: loss=0.012791378057289823
Epoch #97: loss=0.014615877570677858
Epoch #98: loss=0.01278214902470864
Epoch #99: loss=0.02020971031476539
Epoch #100: loss=0.010854261012753313
Epoch #101: loss=0.014080323192901052
Epoch #102: loss=0.012290057634106887
Epoch #103: loss=0.01633930227396076
Epoch #104: loss=0.012105409029825086
Epoch #105: loss=0.012250214191106754
Epoch #106: loss=0.01583557883637153
Epoch #107: loss=0.011355504101376087
Epoch #108: loss=0.01331103690813639
Epoch #109: loss=0.011495933456369269
Epoch #110: loss=0.010841804691914122
Epoch #111: loss=0.015478213904906285
Epoch #112: loss=0.009199080843748444
Epoch #113: loss=0.013925655910081375
Epoch #114: loss=0.012006038622249518
Epoch #115: loss=0.010538934198636399
Epoch #116: loss=0.014669645013040293
Epoch #117: loss=0.021436318468473475
Epoch #118: loss=0.01565532670459081
Epoch #119: loss=0.011425689773961318
Epoch #120: loss=0.012503344113587616
Epoch #121: loss=0.025969967865354097
Epoch #122: loss=0.012762262882373228
Epoch #123: loss=0.010098741708390145
Epoch #124: loss=0.010585166627378727
Epoch #125: loss=0.011897737678838506
Epoch #126: loss=0.012196224305850859
Epoch #127: loss=0.01342099354835324
Epoch #128: loss=0.010465123983980975
Epoch #129: loss=0.010963169338800913
Epoch #130: loss=0.019014589286596977
Epoch #131: loss=0.013939670157862313
Epoch #132: loss=0.010507306124093972
Epoch #133: loss=0.00909169737875939
Epoch #134: loss=0.014636238766501664
Epoch #135: loss=0.012931534247130531
Epoch #136: loss=0.011535314637998959
Epoch #137: loss=0.01906414255431018
Epoch #138: loss=0.012929023912220691
Epoch #139: loss=0.013031166387113357
Epoch #140: loss=0.010317225852959595
Epoch #141: loss=0.00798209299718686
Epoch #142: loss=0.011450272355108274
Epoch #143: loss=0.01628687148142647
Epoch #144: loss=0.010976600058004183
Epoch #145: loss=0.010871147186212128
Epoch #146: loss=0.010460610957048542
Epoch #147: loss=0.010051211028991924
Epoch #148: loss=0.009781587814840858
Epoch #149: loss=0.012545361389018976
Epoch #150: loss=0.010973760974242082
Epoch #151: loss=0.008492013892026747
Epoch #152: loss=0.009465014761763367
Epoch #153: loss=0.019522857282174632
Epoch #154: loss=0.009943889309905626
Epoch #155: loss=0.012641813498913938
Epoch #156: loss=0.010174439511861696
Epoch #157: loss=0.009549854717460055
Epoch #158: loss=0.012949754581220609
Epoch #159: loss=0.0082490642807517
Epoch #160: loss=0.01100783371829653
Epoch #161: loss=0.024841018442554902
Epoch #162: loss=0.010324153680719596
Epoch #163: loss=0.012243690876974349
Epoch #164: loss=0.00801515295661814
Epoch #165: loss=0.009659308423197534
Epoch #166: loss=0.016432191557427332
Epoch #167: loss=0.013369511403363442
Epoch #168: loss=0.01157699564490161
Epoch #169: loss=0.012179056286681358
Epoch #170: loss=0.0124554885354198
Epoch #171: loss=0.008876554918409826
Epoch #172: loss=0.012937698127940525
Epoch #173: loss=0.013202417946268814
Epoch #174: loss=0.010550988958878085
Epoch #175: loss=0.009751567943471177
Epoch #176: loss=0.010959110664681929
Epoch #177: loss=0.011066247198842446
Epoch #178: loss=0.01311292581611195
Epoch #179: loss=0.009302750438021194
Epoch #180: loss=0.013245055819337189
Epoch #181: loss=0.01057943974043007
Epoch #182: loss=0.009019407463694444
Epoch #183: loss=0.010163389471940707
Epoch #184: loss=0.009334520625840751
Epoch #185: loss=0.013869736583359256
Epoch #186: loss=0.010310268987331355
Epoch #187: loss=0.01144209788507488
Epoch #188: loss=0.008907417650140673
Epoch #189: loss=0.01226366343731838
Epoch #190: loss=0.00991300769177592
Epoch #191: loss=0.00910863539904432
Epoch #192: loss=0.011378962162518207
Epoch #193: loss=0.010975004229030137
Epoch #194: loss=0.010377958771940084
Epoch #195: loss=0.00851854720660305
Epoch #196: loss=0.010786678739439066
Epoch #197: loss=0.009990547896247202
Epoch #198: loss=0.008463981573523165
Epoch #199: loss=0.010869142725221582
Epoch #200: loss=0.012451203447706456
Epoch #201: loss=0.010558776224241805
Epoch #202: loss=0.010205597245955137
Epoch #203: loss=0.011255117393449471
Epoch #204: loss=0.00950222161043986
Epoch #205: loss=0.008422852778705697
Epoch #206: loss=0.012830352368342077
Epoch #207: loss=0.009425975315493426
Epoch #208: loss=0.01678953773016527
Epoch #209: loss=0.008848747566413502
Epoch #210: loss=0.00999846523784911
Epoch #211: loss=0.007549790205431736
Epoch #212: loss=0.011998197224747128
Epoch #213: loss=0.010557371078681961
Epoch #214: loss=0.00897604880352525
Epoch #215: loss=0.009609389504385111
Epoch #216: loss=0.012449162525050598
Epoch #217: loss=0.012912422800869901
Epoch #218: loss=0.011831390799975956
Epoch #219: loss=0.007828293877680489
Epoch #220: loss=0.009129948047248837
Epoch #221: loss=0.00750256467157174
Epoch #222: loss=0.01046076920604906
Epoch #223: loss=0.009294102446742777
Epoch #224: loss=0.008136153980216913
Epoch #225: loss=0.009213124327617485
Epoch #226: loss=0.007970398578791454
Epoch #227: loss=0.013904124083789183
Epoch #228: loss=0.009023214989852578
Epoch #229: loss=0.008118518417667975
Epoch #230: loss=0.007779410063450691
Epoch #231: loss=0.012710899083638993
Epoch #232: loss=0.008508160951695437
Epoch #233: loss=0.013933340621289009
Epoch #234: loss=0.01147853978079168
Epoch #235: loss=0.00832267428387141
Epoch #236: loss=0.014553693183050618
Epoch #237: loss=0.00882306391478254
Epoch #238: loss=0.009262779343848641
Epoch #239: loss=0.00835043755955837
Epoch #240: loss=0.008120258370833898
Epoch #241: loss=0.008918917624103052
Epoch #242: loss=0.010328467901724663
Epoch #243: loss=0.010901191933790097
Epoch #244: loss=0.010475754865925398
Epoch #245: loss=0.008720346472672842
Epoch #246: loss=0.00784870930119443
Epoch #247: loss=0.009047215807800303
Epoch #248: loss=0.014613611030046944
Epoch #249: loss=0.013447084357943789

Training time: 4:57:54.410468

Finished.
n2one setting etth1_ettm2_electricity_traffic -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm2_electricity_traffic_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_ettm2_electricity_traffic', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.66107e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.50945e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4701781916600614, 'MAE': 0.5260953277617061}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm2_electricity_traffic -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm2_electricity_traffic_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_ettm2_electricity_traffic', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
Evaluation result: {'MSE': 0.28743813344141855, 'MAE': 0.35878123315175364}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm2_electricity_weather', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm2_electricity_weather_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.847629992765923
Epoch #1: loss=0.8317680357253715
Epoch #2: loss=0.5685574694855572
Epoch #3: loss=0.4694824856438049
Epoch #4: loss=0.4379107088258822
Epoch #5: loss=0.37987298267344904
Epoch #6: loss=0.324455579176341
Epoch #7: loss=0.31629085779598315
Epoch #8: loss=0.264883579497468
Epoch #9: loss=0.2546532337796198
Epoch #10: loss=0.22290499855394233
Epoch #11: loss=0.20767961422058
Epoch #12: loss=0.18885457066640463
Epoch #13: loss=0.18170933623428215
Epoch #14: loss=0.17023520368623407
Epoch #15: loss=0.18178174105817324
Epoch #16: loss=0.1581498767925452
Epoch #17: loss=0.1250905343471733
Epoch #18: loss=0.13269674051808167
Epoch #19: loss=0.1227419218073969
Epoch #20: loss=0.10733059529368191
Epoch #21: loss=0.10108070180636562
Epoch #22: loss=0.08646891575612842
Epoch #23: loss=0.07332829972091194
Epoch #24: loss=0.11490571773419642
Epoch #25: loss=0.0930694916323848
Epoch #26: loss=0.07982923582655518
Epoch #27: loss=0.08120251526060986
Epoch #28: loss=0.06332037650074249
Epoch #29: loss=0.0697343930984809
Epoch #30: loss=0.05457710912451148
Epoch #31: loss=0.059761121788712804
Epoch #32: loss=0.055444424957904505
Epoch #33: loss=0.05564733159485949
Epoch #34: loss=0.06290556542983611
Epoch #35: loss=0.0454347853038511
Epoch #36: loss=0.05373125806106382
Epoch #37: loss=0.05384665114792345
Epoch #38: loss=0.04701122523553363
Epoch #39: loss=0.04704580934565157
Epoch #40: loss=0.05486623443254869
Epoch #41: loss=0.05681639634685157
Epoch #42: loss=0.055153867857505194
Epoch #43: loss=0.045036422040900345
Epoch #44: loss=0.04812824695613491
Epoch #45: loss=0.031187982301942186
Epoch #46: loss=0.04594144921826377
Epoch #47: loss=0.03461719267644396
Epoch #48: loss=0.04107715248844701
Epoch #49: loss=0.052184446104355665
Epoch #50: loss=0.04916281307575433
Epoch #51: loss=0.04052685057578532
Epoch #52: loss=0.03196141721731792
Epoch #53: loss=0.03160786363934103
Epoch #54: loss=0.03602833345608964
Epoch #55: loss=0.027724551899703093
Epoch #56: loss=0.036353694665411565
Epoch #57: loss=0.031771815155173515
Epoch #58: loss=0.03017600074455091
Epoch #59: loss=0.027968990506463978
Epoch #60: loss=0.026972358285813045
Epoch #61: loss=0.04432263493008452
Epoch #62: loss=0.031196323930515513
Epoch #63: loss=0.026579220264780094
Epoch #64: loss=0.024107366842728056
Epoch #65: loss=0.040334867336468336
Epoch #66: loss=0.026976658635109358
Epoch #67: loss=0.032236882087723545
Epoch #68: loss=0.03282834600070364
Epoch #69: loss=0.022670800974018464
Epoch #70: loss=0.021699843938264688
Epoch #71: loss=0.02587650593478641
Epoch #72: loss=0.02421290877559031
Epoch #73: loss=0.02980816300562902
Epoch #74: loss=0.021010225332240024
Epoch #75: loss=0.03495203554247544
Epoch #76: loss=0.027041302605257816
Epoch #77: loss=0.0336045855909031
Epoch #78: loss=0.02583016083186671
Epoch #79: loss=0.023241048547509444
Epoch #80: loss=0.02976738618900489
Epoch #81: loss=0.03837085561763036
Epoch #82: loss=0.0387219746456775
Epoch #83: loss=0.020497300259749825
Epoch #84: loss=0.025329640212991875
Epoch #85: loss=0.02026499385661637
Epoch #86: loss=0.01779408094597572
Epoch #87: loss=0.01799084235218749
Epoch #88: loss=0.01896134364906673
Epoch #89: loss=0.02360931683924968
Epoch #90: loss=0.01542230986827372
Epoch #91: loss=0.021791700644845986
Epoch #92: loss=0.027433208317642597
Epoch #93: loss=0.02914340315539747
Epoch #94: loss=0.032353133020271894
Epoch #95: loss=0.015444755620380533
Epoch #96: loss=0.026828232209504366
Epoch #97: loss=0.022547262422230145
Epoch #98: loss=0.032587751732144045
Epoch #99: loss=0.028815036371018586
Epoch #100: loss=0.024466135919936103
Epoch #101: loss=0.05041312523320164
Epoch #102: loss=0.025737261564840803
Epoch #103: loss=0.020685408504166294
Epoch #104: loss=0.029981181503286304
Epoch #105: loss=0.02773075743741037
Epoch #106: loss=0.0186607189967667
Epoch #107: loss=0.022181909467565687
Epoch #108: loss=0.01958200702832833
Epoch #109: loss=0.017937759272211983
Epoch #110: loss=0.0189549708745302
Epoch #111: loss=0.022906606228964736
Epoch #112: loss=0.015004423458275882
Epoch #113: loss=0.01640437936214156
Epoch #114: loss=0.022293437488077286
Epoch #115: loss=0.021045148050833545
Epoch #116: loss=0.016413806456345298
Epoch #117: loss=0.034776353366730406
Epoch #118: loss=0.016598029431332005
Epoch #119: loss=0.017755097512965893
Epoch #120: loss=0.017260246003391093
Epoch #121: loss=0.02212139114255902
Epoch #122: loss=0.016838031140959834
Epoch #123: loss=0.018038307698379743
Epoch #124: loss=0.022034130786060778
Epoch #125: loss=0.018844953912775964
Epoch #126: loss=0.023595944969366265
Epoch #127: loss=0.027196848531547066
Epoch #128: loss=0.013192481207757014
Epoch #129: loss=0.015079920939951242
Epoch #130: loss=0.0224043754699691
Epoch #131: loss=0.01382016577225255
Epoch #132: loss=0.016467067237053552
Epoch #133: loss=0.017072383179616388
Epoch #134: loss=0.015179601358807939
Epoch #135: loss=0.018666854508106328
Epoch #136: loss=0.045716847088953405
Epoch #137: loss=0.03212955829221755
Epoch #138: loss=0.017832902324073373
Epoch #139: loss=0.02319985823275215
Epoch #140: loss=0.013493954330485008
Epoch #141: loss=0.01472915298008832
Epoch #142: loss=0.02014580699232445
Epoch #143: loss=0.013971141775853116
Epoch #144: loss=0.016046900265811855
Epoch #145: loss=0.01610003271951876
Epoch #146: loss=0.026616155961050002
Epoch #147: loss=0.013582073761890195
Epoch #148: loss=0.019942093427988306
Epoch #149: loss=0.0194576724703513
Epoch #150: loss=0.019016723218533427
Epoch #151: loss=0.012670330662194206
Epoch #152: loss=0.017874531013163903
Epoch #153: loss=0.013223303014361492
Epoch #154: loss=0.04693282952353563
Epoch #155: loss=0.021743893204256893
Epoch #156: loss=0.017742889712736878
Epoch #157: loss=0.013205596676561982
Epoch #158: loss=0.01604166821096641
Epoch #159: loss=0.01630945076563153
Epoch #160: loss=0.014398530699083046
Epoch #161: loss=0.010804684260821812
Epoch #162: loss=0.015669298683108176
Epoch #163: loss=0.060057412769026694
Epoch #164: loss=0.013549269699134342
Epoch #165: loss=0.013392065025145214
Epoch #166: loss=0.04247407916796151
Epoch #167: loss=0.016299500955070993
Epoch #168: loss=0.01813400368092977
Epoch #169: loss=0.01611203953794408
Epoch #170: loss=0.013910684578777737
Epoch #171: loss=0.015300276723039682
Epoch #172: loss=0.01397460549336233
Epoch #173: loss=0.015403244363651165
Epoch #174: loss=0.01411658321756053
Epoch #175: loss=0.012507873391716625
Epoch #176: loss=0.014320793111684209
Epoch #177: loss=0.012239323711430985
Epoch #178: loss=0.014090261482059547
Epoch #179: loss=0.021960398461669684
Epoch #180: loss=0.013003664051919333
Epoch #181: loss=0.020468056397050082
Epoch #182: loss=0.014230778085367678
Epoch #183: loss=0.013975664722328139
Epoch #184: loss=0.021989680720933342
Epoch #185: loss=0.012220181198471724
Epoch #186: loss=0.015036020032927547
Epoch #187: loss=0.013545177644437613
Epoch #188: loss=0.018506188824938687
Epoch #189: loss=0.01322067363677253
Epoch #190: loss=0.02156444698116066
Epoch #191: loss=0.01912074404360395
Epoch #192: loss=0.02367804573373614
Epoch #193: loss=0.013666338248063542
Epoch #194: loss=0.014389592568766428
Epoch #195: loss=0.015302691413791314
Epoch #196: loss=0.012163185309028662
Epoch #197: loss=0.015441399665823691
Epoch #198: loss=0.02044736151647282
Epoch #199: loss=0.01561571608029612
Epoch #200: loss=0.04068648651264582
Epoch #201: loss=0.029736409448438056
Epoch #202: loss=0.01198767774988744
Epoch #203: loss=0.010904399519036715
Epoch #204: loss=0.010129511691645833
Epoch #205: loss=0.014653761283740121
Epoch #206: loss=0.012731936185426168
Epoch #207: loss=0.023570906177118472
Epoch #208: loss=0.012609407705835334
Epoch #209: loss=0.01681212639126748
Epoch #210: loss=0.016208179634501392
Epoch #211: loss=0.026395429840330546
Epoch #212: loss=0.012996056498257979
Epoch #213: loss=0.009836416781484468
Epoch #214: loss=0.02050251040427486
Epoch #215: loss=0.017640093901698566
Epoch #216: loss=0.01386362360559136
Epoch #217: loss=0.010914712396772476
Epoch #218: loss=0.009896354712242874
Epoch #219: loss=0.014794282505626803
Epoch #220: loss=0.022697856134658502
Epoch #221: loss=0.013966101257701417
Epoch #222: loss=0.015995620291884224
Epoch #223: loss=0.012314032143769684
Epoch #224: loss=0.014109418174006325
Epoch #225: loss=0.013372774358857933
Epoch #226: loss=0.017377069408762946
Epoch #227: loss=0.01720165881449484
Epoch #228: loss=0.01952228788166843
Epoch #229: loss=0.011003265274953327
Epoch #230: loss=0.016684457854358223
Epoch #231: loss=0.017858692366878617
Epoch #232: loss=0.012167508773942643
Epoch #233: loss=0.01785171116065961
Epoch #234: loss=0.015953121358394776
Epoch #235: loss=0.015114045202610886
Epoch #236: loss=0.010074594879542056
Epoch #237: loss=0.010354882657802216
Epoch #238: loss=0.022099164238658875
Epoch #239: loss=0.016060687006492654
Epoch #240: loss=0.013380193649647655
Epoch #241: loss=0.013261439288813463
Epoch #242: loss=0.025726205963252292
Epoch #243: loss=0.00996414019278895
Epoch #244: loss=0.016007643927539353
Epoch #245: loss=0.008736624208690395
Epoch #246: loss=0.008317196360160916
Epoch #247: loss=0.017890207312940557
Epoch #248: loss=0.014527233378652304
Epoch #249: loss=0.011761147616676706

Training time: 1:42:30.228864

Finished.
n2one setting etth1_ettm2_electricity_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm2_electricity_weather_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_ettm2_electricity_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.3463e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.25320926543490396, 'MAE': 0.3493134610517016}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm2_electricity_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm2_electricity_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.7611284764424524
Epoch #1: loss=0.7599878056935687
Epoch #2: loss=0.5117237638757277
Epoch #3: loss=0.4209857737210711
Epoch #4: loss=0.34944069930902477
Epoch #5: loss=0.30906806224876593
Epoch #6: loss=0.2971590651301211
Epoch #7: loss=0.25039770537906836
Epoch #8: loss=0.23750284807998095
Epoch #9: loss=0.2195213324999603
Epoch #10: loss=0.1931413733091753
Epoch #11: loss=0.1985713681501339
Epoch #12: loss=0.16813625938524773
Epoch #13: loss=0.15833030446762653
Epoch #14: loss=0.15291571304717394
Epoch #15: loss=0.13814653242033736
Epoch #16: loss=0.14244953485511738
Epoch #17: loss=0.10660339752883148
Epoch #18: loss=0.10580207689286825
Epoch #19: loss=0.09044181782569768
Epoch #20: loss=0.10411758363107354
Epoch #21: loss=0.10337141323136836
Epoch #22: loss=0.10102799282240163
Epoch #23: loss=0.10973628482617631
Epoch #24: loss=0.08862906790765201
Epoch #25: loss=0.07578845757062437
Epoch #26: loss=0.07031124069084352
Epoch #27: loss=0.0607097697999833
Epoch #28: loss=0.07578211231962362
Epoch #29: loss=0.08511097292799599
Epoch #30: loss=0.07765618665278044
Epoch #31: loss=0.06907643476281025
Epoch #32: loss=0.051388235154805936
Epoch #33: loss=0.0647468639977856
Epoch #34: loss=0.05085393413096151
Epoch #35: loss=0.10275079748762359
Epoch #36: loss=0.053278117762712136
Epoch #37: loss=0.06270695815496254
Epoch #38: loss=0.052944218439267415
Epoch #39: loss=0.046695325710818775
Epoch #40: loss=0.04439718602090988
Epoch #41: loss=0.04592245179953145
Epoch #42: loss=0.048580971795405326
Epoch #43: loss=0.045490735600989644
Epoch #44: loss=0.0495983551572391
Epoch #45: loss=0.04691303474291816
Epoch #46: loss=0.06522658333163547
Epoch #47: loss=0.052535405200006983
Epoch #48: loss=0.04435032251376863
Epoch #49: loss=0.03596845894356819
Epoch #50: loss=0.0518911678393664
Epoch #51: loss=0.05104084691081078
Epoch #52: loss=0.050057988529300226
Epoch #53: loss=0.04352847672562767
Epoch #54: loss=0.04710547038339218
Epoch #55: loss=0.04716987516234497
Epoch #56: loss=0.03826774638790304
Epoch #57: loss=0.03679904876134603
Epoch #58: loss=0.041059496487096295
Epoch #59: loss=0.03113744648707553
Epoch #60: loss=0.03351572000586645
Epoch #61: loss=0.030419197007986887
Epoch #62: loss=0.03801557148326328
Epoch #63: loss=0.025015665993888887
Epoch #64: loss=0.028953953273057595
Epoch #65: loss=0.03247738638168109
Epoch #66: loss=0.02572300174590254
Epoch #67: loss=0.0513727829918421
Epoch #68: loss=0.03642986313425144
Epoch #69: loss=0.028997146541598958
Epoch #70: loss=0.037897213135533285
Epoch #71: loss=0.05626249739897547
Epoch #72: loss=0.03598489183751378
Epoch #73: loss=0.03382978287038342
Epoch #74: loss=0.028843572191150607
Epoch #75: loss=0.03765739205760361
Epoch #76: loss=0.029564303041017086
Epoch #77: loss=0.03677321275862562
Epoch #78: loss=0.026584585848625383
Epoch #79: loss=0.022801942232612425
Epoch #80: loss=0.045831335569605745
Epoch #81: loss=0.038221592471736246
Epoch #82: loss=0.0397650281471262
Epoch #83: loss=0.03787167188651076
Epoch #84: loss=0.039937665723586285
Epoch #85: loss=0.045623950387474674
Epoch #86: loss=0.027313911543906767
Epoch #87: loss=0.05214875069398551
Epoch #88: loss=0.02870592547202166
Epoch #89: loss=0.023000560056415497
Epoch #90: loss=0.02328189361641876
Epoch #91: loss=0.031913388847918264
Epoch #92: loss=0.03513505233865049
Epoch #93: loss=0.025207408353611183
Epoch #94: loss=0.024669377670371074
Epoch #95: loss=0.038494164628373934
Epoch #96: loss=0.02757359521264903
Epoch #97: loss=0.02685963699523016
Epoch #98: loss=0.03319310873457679
Epoch #99: loss=0.033456304645023555
Epoch #100: loss=0.024856203446374073
Epoch #101: loss=0.027207754257971135
Epoch #102: loss=0.036129047743900966
Epoch #103: loss=0.02406720075369155
Epoch #104: loss=0.03124216512336747
Epoch #105: loss=0.034466446797371514
Epoch #106: loss=0.02279998793623005
Epoch #107: loss=0.01704918780623766
Epoch #108: loss=0.019197307884195276
Epoch #109: loss=0.01649905912499601
Epoch #110: loss=0.024632860462064518
Epoch #111: loss=0.02849267856137403
Epoch #112: loss=0.02073554820059034
Epoch #113: loss=0.018365638326217425
Epoch #114: loss=0.026590181464968138
Epoch #115: loss=0.03044541768131842
Epoch #116: loss=0.031054180485172257
Epoch #117: loss=0.03485045800326387
Epoch #118: loss=0.043387128323181035
Epoch #119: loss=0.03341984707574958
Epoch #120: loss=0.024760343228676155
Epoch #121: loss=0.02878192931689424
Epoch #122: loss=0.01454642404898094
Epoch #123: loss=0.021219080660769968
Epoch #124: loss=0.021215910217637513
Epoch #125: loss=0.02453495490969285
Epoch #126: loss=0.022785304680195576
Epoch #127: loss=0.021301898563157243
Epoch #128: loss=0.024571950523912776
Epoch #129: loss=0.021216472862617138
Epoch #130: loss=0.021935289470520494
Epoch #131: loss=0.02019193099633192
Epoch #132: loss=0.016113698034633157
Epoch #133: loss=0.016837560738804574
Epoch #134: loss=0.02225902393193223
Epoch #135: loss=0.021144703627088958
Epoch #136: loss=0.0260386548113408
Epoch #137: loss=0.020105477192496845
Epoch #138: loss=0.017312648942323688
Epoch #139: loss=0.016358084628433633
Epoch #140: loss=0.022913134840695504
Epoch #141: loss=0.025090051988362515
Epoch #142: loss=0.027751576042699195
Epoch #143: loss=0.01627289721521184
Epoch #144: loss=0.016488255282158772
Epoch #145: loss=0.018850233719009176
Epoch #146: loss=0.018663082379506906
Epoch #147: loss=0.020174475317124428
Epoch #148: loss=0.020654878709921533
Epoch #149: loss=0.021269371328970704
Epoch #150: loss=0.02204461366653453
Epoch #151: loss=0.01944822496690946
Epoch #152: loss=0.032156114123952216
Epoch #153: loss=0.02284141069060723
Epoch #154: loss=0.025558319755176334
Epoch #155: loss=0.02566167969348564
Epoch #156: loss=0.02416339064062565
Epoch #157: loss=0.023549544026468604
Epoch #158: loss=0.020649317802622462
Epoch #159: loss=0.0293635338895769
Epoch #160: loss=0.02177427625431215
Epoch #161: loss=0.021966479186261184
Epoch #162: loss=0.04277550545772699
Epoch #163: loss=0.025649680875299462
Epoch #164: loss=0.016147704691671757
Epoch #165: loss=0.02519861425397923
Epoch #166: loss=0.01675260260589461
Epoch #167: loss=0.014351348143227947
Epoch #168: loss=0.021650234403381236
Epoch #169: loss=0.0368811806896366
Epoch #170: loss=0.014941931655311753
Epoch #171: loss=0.015207027129242491
Epoch #172: loss=0.024089726153090168
Epoch #173: loss=0.020540863667549
Epoch #174: loss=0.018285773216273036
Epoch #175: loss=0.018705102037259322
Epoch #176: loss=0.025172635552745785
Epoch #177: loss=0.02850581016706877
Epoch #178: loss=0.014294616113029695
Epoch #179: loss=0.02015229569639345
Epoch #180: loss=0.016295097483475008
Epoch #181: loss=0.032055786873216634
Epoch #182: loss=0.025634665494403595
Epoch #183: loss=0.0286594431770842
Epoch #184: loss=0.021562250149627524
Epoch #185: loss=0.019704331322646932
Epoch #186: loss=0.013685034729053216
Epoch #187: loss=0.01881915131605281
Epoch #188: loss=0.02136512024355623
Epoch #189: loss=0.018582432427908555
Epoch #190: loss=0.01589429588308719
Epoch #191: loss=0.01866401196340024
Epoch #192: loss=0.017844709769942763
Epoch #193: loss=0.017401891279853584
Epoch #194: loss=0.013654728231700648
Epoch #195: loss=0.017947509980365307
Epoch #196: loss=0.021001227274174757
Epoch #197: loss=0.020965253880250157
Epoch #198: loss=0.018079408283931838
Epoch #199: loss=0.017209762701313802
Epoch #200: loss=0.013498126686166876
Epoch #201: loss=0.017421393697009145
Epoch #202: loss=0.018014340011955853
Epoch #203: loss=0.02370850051758591
Epoch #204: loss=0.03273535847512238
Epoch #205: loss=0.018956191840639302
Epoch #206: loss=0.02611000341298166
Epoch #207: loss=0.02244992898787192
Epoch #208: loss=0.018868168347625208
Epoch #209: loss=0.017033314564274035
Epoch #210: loss=0.015359033562155086
Epoch #211: loss=0.0251542915670122
Epoch #212: loss=0.026472840409843997
Epoch #213: loss=0.03085280004341923
Epoch #214: loss=0.016388614681282318
Epoch #215: loss=0.014070450386581996
Epoch #216: loss=0.013999144997335676
Epoch #217: loss=0.01213056523340616
Epoch #218: loss=0.0165278682652465
Epoch #219: loss=0.019303794024124344
Epoch #220: loss=0.010314199594315813
Epoch #221: loss=0.01377230309567586
Epoch #222: loss=0.016121047344061792
Epoch #223: loss=0.018411671724177157
Epoch #224: loss=0.023659464293085738
Epoch #225: loss=0.02291367234600445
Epoch #226: loss=0.01598302989403693
Epoch #227: loss=0.011897694625286519
Epoch #228: loss=0.01762459706397652
Epoch #229: loss=0.034305682759436774
Epoch #230: loss=0.017196904427723512
Epoch #231: loss=0.013433131243884617
Epoch #232: loss=0.009501647504676611
Epoch #233: loss=0.020104730342412825
Epoch #234: loss=0.021448835612627642
Epoch #235: loss=0.01746978728041611
Epoch #236: loss=0.020090938636849257
Epoch #237: loss=0.02616776564907986
Epoch #238: loss=0.017052750256243338
Epoch #239: loss=0.014335752148295267
Epoch #240: loss=0.011974057942220903
Epoch #241: loss=0.016109712986189666
Epoch #242: loss=0.010902162571672501
Epoch #243: loss=0.008431204131023384
Epoch #244: loss=0.012973009362435693
Epoch #245: loss=0.011730862088952352
Epoch #246: loss=0.027778524858809963
Epoch #247: loss=0.02367032034710447
Epoch #248: loss=0.014913282842024415
Epoch #249: loss=0.013840065679498827

Training time: 1:34:41.489360

Finished.
n2one setting etth1_ettm2_electricity_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm2_electricity_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_ettm2_electricity_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.44302e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.04009e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4920514034255537, 'MAE': 0.5180116730062825}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm2_traffic_weather', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm2_traffic_weather_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.0892956623967909
Epoch #1: loss=0.48085283984740573
Epoch #2: loss=0.3283043314782989
Epoch #3: loss=0.2525613640268512
Epoch #4: loss=0.19913001628654287
Epoch #5: loss=0.17382529016510145
Epoch #6: loss=0.15071251925500417
Epoch #7: loss=0.1360543945405394
Epoch #8: loss=0.12233820380170153
Epoch #9: loss=0.10234725298606698
Epoch #10: loss=0.08087808625756149
Epoch #11: loss=0.08281760394190814
Epoch #12: loss=0.07882181792746136
Epoch #13: loss=0.06908164459802868
Epoch #14: loss=0.06835012157318114
Epoch #15: loss=0.06325715925558892
Epoch #16: loss=0.04839618959197894
Epoch #17: loss=0.05338320175183744
Epoch #18: loss=0.05413972394732105
Epoch #19: loss=0.0514401961218208
Epoch #20: loss=0.04889252379888188
Epoch #21: loss=0.04023493058382272
Epoch #22: loss=0.0380023927105309
Epoch #23: loss=0.04651465618039253
Epoch #24: loss=0.07509200102788402
Epoch #25: loss=0.04028051318605914
Epoch #26: loss=0.03013390390470698
Epoch #27: loss=0.030769437371478695
Epoch #28: loss=0.03134776669951201
Epoch #29: loss=0.0414211784199571
Epoch #30: loss=0.0393327936350479
Epoch #31: loss=0.031088913881630334
Epoch #32: loss=0.03254749047082682
Epoch #33: loss=0.03496491760115713
Epoch #34: loss=0.036826757706571206
Epoch #35: loss=0.023825205883787837
Epoch #36: loss=0.03216284573435111
Epoch #37: loss=0.03145440478108116
Epoch #38: loss=0.03178947099582673
Epoch #39: loss=0.025639678436965182
Epoch #40: loss=0.025727803283126894
Epoch #41: loss=0.029191338658067098
Epoch #42: loss=0.02870781854975652
Epoch #43: loss=0.031790406469134384
Epoch #44: loss=0.025783752113843858
Epoch #45: loss=0.0353324779398764
Epoch #46: loss=0.02381332314953056
Epoch #47: loss=0.02966076407637334
Epoch #48: loss=0.029961813161063274
Epoch #49: loss=0.026248438816536095
Epoch #50: loss=0.024424930465571884
Epoch #51: loss=0.021338694501155782
Epoch #52: loss=0.025561250849302126
Epoch #53: loss=0.030594868904902758
Epoch #54: loss=0.023552791886023917
Epoch #55: loss=0.021497693086540526
Epoch #56: loss=0.02694626485108589
Epoch #57: loss=0.026629860444939087
Epoch #58: loss=0.019650290156527018
Epoch #59: loss=0.019641564127222778
Epoch #60: loss=0.022728813734976164
Epoch #61: loss=0.022518954770786023
Epoch #62: loss=0.018397048835359437
Epoch #63: loss=0.025037337208519306
Epoch #64: loss=0.019638252940165624
Epoch #65: loss=0.027589863476782387
Epoch #66: loss=0.02045348635290042
Epoch #67: loss=0.019246572349014925
Epoch #68: loss=0.016972230529159752
Epoch #69: loss=0.026785767936198118
Epoch #70: loss=0.014844747437983977
Epoch #71: loss=0.017847553025260383
Epoch #72: loss=0.019983215511364814
Epoch #73: loss=0.021134287290515124
Epoch #74: loss=0.0166184269150405
Epoch #75: loss=0.019964763094386072
Epoch #76: loss=0.019863248750167563
Epoch #77: loss=0.023631122780707562
Epoch #78: loss=0.020133779636910855
Epoch #79: loss=0.01851678976374596
Epoch #80: loss=0.01603200031142727
Epoch #81: loss=0.019390295148925048
Epoch #82: loss=0.027895854975823642
Epoch #83: loss=0.021434204015962032
Epoch #84: loss=0.015503070836837421
Epoch #85: loss=0.014479781918953149
Epoch #86: loss=0.016878862975388313
Epoch #87: loss=0.021046604546250583
Epoch #88: loss=0.020811913461725343
Epoch #89: loss=0.015795131711008912
Epoch #90: loss=0.01784430060706052
Epoch #91: loss=0.02857204905773948
Epoch #92: loss=0.016500373582124903
Epoch #93: loss=0.019365963543994995
Epoch #94: loss=0.01876356262320737
Epoch #95: loss=0.01946754457729598
Epoch #96: loss=0.025220448295143794
Epoch #97: loss=0.012760465262938551
Epoch #98: loss=0.021372170940570423
Epoch #99: loss=0.015903987705230323
Epoch #100: loss=0.0168592206759275
Epoch #101: loss=0.017402624254004805
Epoch #102: loss=0.022184120842159795
Epoch #103: loss=0.020619062169531573
Epoch #104: loss=0.016375509847292705
Epoch #105: loss=0.014292584878721976
Epoch #106: loss=0.018452922323165886
Epoch #107: loss=0.025081762739019797
Epoch #108: loss=0.015382596303647945
Epoch #109: loss=0.014887271931817166
Epoch #110: loss=0.01519047656498318
Epoch #111: loss=0.021096093198757365
Epoch #112: loss=0.013096211888715851
Epoch #113: loss=0.016356991466357756
Epoch #114: loss=0.019613599286092933
Epoch #115: loss=0.018216457312021282
Epoch #116: loss=0.012755076251561685
Epoch #117: loss=0.017080342942356927
Epoch #118: loss=0.019149388544231646
Epoch #119: loss=0.016477632312354412
Epoch #120: loss=0.013808524822014452
Epoch #121: loss=0.014333591881295755
Epoch #122: loss=0.025241770538787726
Epoch #123: loss=0.012783966886357504
Epoch #124: loss=0.015401436691744218
Epoch #125: loss=0.019656432538158897
Epoch #126: loss=0.01789145115027965
Epoch #127: loss=0.017492492053813313
Epoch #128: loss=0.013603727396595072
Epoch #129: loss=0.011313912805779395
Epoch #130: loss=0.019699636668184528
Epoch #131: loss=0.014705589751748443
Epoch #132: loss=0.017216531781637248
Epoch #133: loss=0.016677298452026697
Epoch #134: loss=0.014994841944635743
Epoch #135: loss=0.01720745586219632
Epoch #136: loss=0.013618362729761968
Epoch #137: loss=0.013262053420427964
Epoch #138: loss=0.01699402245777586
Epoch #139: loss=0.01408101710477776
Epoch #140: loss=0.02113710691936897
Epoch #141: loss=0.0222544301473808
Epoch #142: loss=0.009779003063046165
Epoch #143: loss=0.013352978043081512
Epoch #144: loss=0.0143884179518039
Epoch #145: loss=0.013256290881110975
Epoch #146: loss=0.014933208991692733
Epoch #147: loss=0.01589535404303549
Epoch #148: loss=0.018233110304758937
Epoch #149: loss=0.016535274040000977
Epoch #150: loss=0.01574698649838317
Epoch #151: loss=0.015015583411972908
Epoch #152: loss=0.018012980363335845
Epoch #153: loss=0.015955442674135508
Epoch #154: loss=0.013604404755418804
Epoch #155: loss=0.014670569154320318
Epoch #156: loss=0.009490266545832715
Epoch #157: loss=0.015524542918821969
Epoch #158: loss=0.013892991734806358
Epoch #159: loss=0.011040141402552172
Epoch #160: loss=0.019022548817422973
Epoch #161: loss=0.01283898428854071
Epoch #162: loss=0.008932021133017404
Epoch #163: loss=0.017532469586340225
Epoch #164: loss=0.017998711970106905
Epoch #165: loss=0.009891844566407891
Epoch #166: loss=0.024973514938883012
Epoch #167: loss=0.012843409340063349
Epoch #168: loss=0.014057076661946472
Epoch #169: loss=0.013677429176771151
Epoch #170: loss=0.014939720196691578
Epoch #171: loss=0.017088617347800185
Epoch #172: loss=0.010547276216922878
Epoch #173: loss=0.012802490459021492
Epoch #174: loss=0.017043411079036057
Epoch #175: loss=0.010190300038961358
Epoch #176: loss=0.012114906277267003
Epoch #177: loss=0.015585699747000123
Epoch #178: loss=0.019909495611147104
Epoch #179: loss=0.013945157400105728
Epoch #180: loss=0.01111090556166143
Epoch #181: loss=0.01110496541923868
Epoch #182: loss=0.026044956466825406
Epoch #183: loss=0.009492320824639612
Epoch #184: loss=0.021043490843620474
Epoch #185: loss=0.01566739534626013
Epoch #186: loss=0.014937875023863132
Epoch #187: loss=0.010210607839314212
Epoch #188: loss=0.0170804185859749
Epoch #189: loss=0.012851411821640603
Epoch #190: loss=0.013853971636025328
Epoch #191: loss=0.014521146270532055
Epoch #192: loss=0.010771574206453919
Epoch #193: loss=0.012519805398495985
Epoch #194: loss=0.009721378235345055
Epoch #195: loss=0.015710072836665326
Epoch #196: loss=0.011492772772953184
Epoch #197: loss=0.011653628391523386
Epoch #198: loss=0.01457514191315166
Epoch #199: loss=0.011916656341870412
Epoch #200: loss=0.009694701243031517
Epoch #201: loss=0.01974283103244153
Epoch #202: loss=0.013176938724343277
Epoch #203: loss=0.012701536879666478
Epoch #204: loss=0.010698329094770646
Epoch #205: loss=0.013286922733049128
Epoch #206: loss=0.012763698081764502
Epoch #207: loss=0.011566210689964225
Epoch #208: loss=0.019348118430864175
Epoch #209: loss=0.01777760520018226
Epoch #210: loss=0.009931713314398004
Epoch #211: loss=0.02113154162124039
Epoch #212: loss=0.009350873240478908
Epoch #213: loss=0.017096580858687916
Epoch #214: loss=0.011391188031403378
Epoch #215: loss=0.00937161551365448
Epoch #216: loss=0.012699834659131248
Epoch #217: loss=0.014763848767719934
Epoch #218: loss=0.009213112149371601
Epoch #219: loss=0.009239097718441362
Epoch #220: loss=0.01066804334227557
Epoch #221: loss=0.009753178582866867
Epoch #222: loss=0.011269120223133797
Epoch #223: loss=0.009526163344754618
Epoch #224: loss=0.008321528541128881
Epoch #225: loss=0.01511679081229617
Epoch #226: loss=0.014863386735058992
Epoch #227: loss=0.010830276382918199
Epoch #228: loss=0.017180458533933036
Epoch #229: loss=0.009174456719538324
Epoch #230: loss=0.015206327790494136
Epoch #231: loss=0.020437153111692908
Epoch #232: loss=0.008849189638804534
Epoch #233: loss=0.011454125951322627
Epoch #234: loss=0.010208107262615179
Epoch #235: loss=0.010658473759677121
Epoch #236: loss=0.008104863782759208
Epoch #237: loss=0.013905185557466008
Epoch #238: loss=0.013313487789619464
Epoch #239: loss=0.012540844841745233
Epoch #240: loss=0.009626926716395102
Epoch #241: loss=0.012283426084062013
Epoch #242: loss=0.013611618281638524
Epoch #243: loss=0.010070784537779027
Epoch #244: loss=0.013191499721942336
Epoch #245: loss=0.011707739152946992
Epoch #246: loss=0.015595813804530569
Epoch #247: loss=0.010399219422397115
Epoch #248: loss=0.014912150544316789
Epoch #249: loss=0.01303994451534983

Training time: 3:47:55.433255

Finished.
n2one setting etth1_ettm2_traffic_weather -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm2_traffic_weather_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_ettm2_traffic_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.18863e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.32936e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.65874e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.18863e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.42727440299715275, 'MAE': 0.46641071648391497}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm2_traffic_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm2_traffic_weather_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_ettm2_traffic_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.64658e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.2746727938484885, 'MAE': 0.347900343720465}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm2_traffic_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm2_traffic_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.051157102660016
Epoch #1: loss=0.3859995647862151
Epoch #2: loss=0.2790127857797989
Epoch #3: loss=0.22870178270648728
Epoch #4: loss=0.1763285013326855
Epoch #5: loss=0.1553847186418401
Epoch #6: loss=0.13540798203960933
Epoch #7: loss=0.10683920766596121
Epoch #8: loss=0.09943869714163714
Epoch #9: loss=0.10047250706912228
Epoch #10: loss=0.07891022374010268
Epoch #11: loss=0.07309185417771742
Epoch #12: loss=0.07984477624943194
Epoch #13: loss=0.06351424840924975
Epoch #14: loss=0.06042230693672716
Epoch #15: loss=0.06506650789949187
Epoch #16: loss=0.05752153007412195
Epoch #17: loss=0.05060993616683157
Epoch #18: loss=0.05128267904017792
Epoch #19: loss=0.04259118706689044
Epoch #20: loss=0.04202052728594952
Epoch #21: loss=0.04728383091902402
Epoch #22: loss=0.04529307626459437
Epoch #23: loss=0.04380805252960501
Epoch #24: loss=0.03952513682537477
Epoch #25: loss=0.03701022873789404
Epoch #26: loss=0.04229077899084963
Epoch #27: loss=0.03457886044883593
Epoch #28: loss=0.03749033985690944
Epoch #29: loss=0.03582645030909843
Epoch #30: loss=0.03405844029678905
Epoch #31: loss=0.03454935314843792
Epoch #32: loss=0.04545633454941085
Epoch #33: loss=0.03296906058086598
Epoch #34: loss=0.027893013604232297
Epoch #35: loss=0.03264930771940665
Epoch #36: loss=0.03246838459650823
Epoch #37: loss=0.0314618298940692
Epoch #38: loss=0.03213563909210623
Epoch #39: loss=0.029863934061067337
Epoch #40: loss=0.031005409982753918
Epoch #41: loss=0.03832229565402182
Epoch #42: loss=0.037014962891237346
Epoch #43: loss=0.0254009356026759
Epoch #44: loss=0.03163692054927647
Epoch #45: loss=0.029478274957541174
Epoch #46: loss=0.026754351453000872
Epoch #47: loss=0.02835003608721833
Epoch #48: loss=0.023112119083659333
Epoch #49: loss=0.02402516909100709
Epoch #50: loss=0.024718510263048776
Epoch #51: loss=0.028243808836549276
Epoch #52: loss=0.024556834089044306
Epoch #53: loss=0.020979124957644212
Epoch #54: loss=0.02721909141634184
Epoch #55: loss=0.02833862083915281
Epoch #56: loss=0.029262450217559875
Epoch #57: loss=0.029222924558239726
Epoch #58: loss=0.02526846635648965
Epoch #59: loss=0.027083549174275103
Epoch #60: loss=0.02123331203888934
Epoch #61: loss=0.023079366342793586
Epoch #62: loss=0.023963257866722282
Epoch #63: loss=0.0368181105634551
Epoch #64: loss=0.020452048210728692
Epoch #65: loss=0.02209358704767346
Epoch #66: loss=0.026575427020869537
Epoch #67: loss=0.02085299917025049
Epoch #68: loss=0.026489654373100156
Epoch #69: loss=0.02841055975187447
Epoch #70: loss=0.019967623276865163
Epoch #71: loss=0.021586627090089693
Epoch #72: loss=0.026170745274948212
Epoch #73: loss=0.0194679900789754
Epoch #74: loss=0.024395982490229496
Epoch #75: loss=0.02101698071376771
Epoch #76: loss=0.02022822025957122
Epoch #77: loss=0.021007298194760823
Epoch #78: loss=0.021897417646025197
Epoch #79: loss=0.019012115982010844
Epoch #80: loss=0.025633128823215345
Epoch #81: loss=0.021438549083901668
Epoch #82: loss=0.018195850542044582
Epoch #83: loss=0.021518886100664956
Epoch #84: loss=0.021002882721332907
Epoch #85: loss=0.01837130395840693
Epoch #86: loss=0.021006834153324546
Epoch #87: loss=0.016806363329689357
Epoch #88: loss=0.01731436268046555
Epoch #89: loss=0.02314430734698256
Epoch #90: loss=0.021231860024862406
Epoch #91: loss=0.0214832218219083
Epoch #92: loss=0.021729306695461827
Epoch #93: loss=0.019903892741068203
Epoch #94: loss=0.021840737289830367
Epoch #95: loss=0.02663027758260157
Epoch #96: loss=0.016798767696355254
Epoch #97: loss=0.013844706781529968
Epoch #98: loss=0.022488351992652898
Epoch #99: loss=0.021142068678592616
Epoch #100: loss=0.019235491729485656
Epoch #101: loss=0.017424976950473844
Epoch #102: loss=0.02375482847783788
Epoch #103: loss=0.018382405376132328
Epoch #104: loss=0.021063543293306022
Epoch #105: loss=0.015349548402564079
Epoch #106: loss=0.015934712275830442
Epoch #107: loss=0.01866383725395248
Epoch #108: loss=0.01720638828123196
Epoch #109: loss=0.01868992354794246
Epoch #110: loss=0.015666278209824372
Epoch #111: loss=0.016754177618339954
Epoch #112: loss=0.014620837318550519
Epoch #113: loss=0.012214362164233026
Epoch #114: loss=0.05203873236170185
Epoch #115: loss=0.017141781085884506
Epoch #116: loss=0.017247024863061122
Epoch #117: loss=0.01858622232897245
Epoch #118: loss=0.020228131384043932
Epoch #119: loss=0.015452463553260345
Epoch #120: loss=0.01589870983324389
Epoch #121: loss=0.015918544809202094
Epoch #122: loss=0.020916278263423405
Epoch #123: loss=0.013472997469884954
Epoch #124: loss=0.01572728639051068
Epoch #125: loss=0.0174286756589133
Epoch #126: loss=0.017374910334838862
Epoch #127: loss=0.01976297395054103
Epoch #128: loss=0.0208280227154712
Epoch #129: loss=0.017851859688439494
Epoch #130: loss=0.014686197534641135
Epoch #131: loss=0.0158527959777751
Epoch #132: loss=0.012426696822421125
Epoch #133: loss=0.018564604115667165
Epoch #134: loss=0.01114133135821363
Epoch #135: loss=0.016422836532099708
Epoch #136: loss=0.016336961262782057
Epoch #137: loss=0.01807461772805582
Epoch #138: loss=0.013534345351873272
Epoch #139: loss=0.013740684249946221
Epoch #140: loss=0.016115721727941377
Epoch #141: loss=0.02412466903111996
Epoch #142: loss=0.011761444206124063
Epoch #143: loss=0.013843283751206449
Epoch #144: loss=0.016366438505871418
Epoch #145: loss=0.020592959170154156
Epoch #146: loss=0.012665045820556787
Epoch #147: loss=0.014342772247301083
Epoch #148: loss=0.015429806912826272
Epoch #149: loss=0.01828449190925148
Epoch #150: loss=0.015918527538241842
Epoch #151: loss=0.015999883959667133
Epoch #152: loss=0.016753808228558074
Epoch #153: loss=0.01664899409923499
Epoch #154: loss=0.02477510830857506
Epoch #155: loss=0.019733150172829186
Epoch #156: loss=0.01392865681446966
Epoch #157: loss=0.013240302635962065
Epoch #158: loss=0.015873775940817396
Epoch #159: loss=0.015345956623629742
Epoch #160: loss=0.014380526538835503
Epoch #161: loss=0.01406593552314302
Epoch #162: loss=0.013833049645417067
Epoch #163: loss=0.015790558717436308
Epoch #164: loss=0.012678727674020585
Epoch #165: loss=0.015871810418740334
Epoch #166: loss=0.020232429430580925
Epoch #167: loss=0.010170156026589695
Epoch #168: loss=0.017733473280853243
Epoch #169: loss=0.010388503101264202
Epoch #170: loss=0.014954782669913068
Epoch #171: loss=0.013406207946523486
Epoch #172: loss=0.012288046018364036
Epoch #173: loss=0.017294994123084186
Epoch #174: loss=0.019545486774953682
Epoch #175: loss=0.010380238233804587
Epoch #176: loss=0.013646732052858407
Epoch #177: loss=0.0220834966817124
Epoch #178: loss=0.011153586894399088
Epoch #179: loss=0.011718469383292055
Epoch #180: loss=0.01485402487542324
Epoch #181: loss=0.01665026177540091
Epoch #182: loss=0.015100448194946669
Epoch #183: loss=0.01445705669930822
Epoch #184: loss=0.012405684567843186
Epoch #185: loss=0.012640558035510932
Epoch #186: loss=0.013966278741947037
Epoch #187: loss=0.01321969828195752
Epoch #188: loss=0.013172301628507846
Epoch #189: loss=0.011915306583014663
Epoch #190: loss=0.01812262587236559
Epoch #191: loss=0.015210017918450848
Epoch #192: loss=0.012777278079754996
Epoch #193: loss=0.013588008833811817
Epoch #194: loss=0.01713991136706239
Epoch #195: loss=0.012045654280505537
Epoch #196: loss=0.010995453040023832
Epoch #197: loss=0.011628565146770803
Epoch #198: loss=0.01655619709125047
Epoch #199: loss=0.01128930658671117
Epoch #200: loss=0.016147919649737812
Epoch #201: loss=0.01377354703672117
Epoch #202: loss=0.02058120258719485
Epoch #203: loss=0.011703192450351035
Epoch #204: loss=0.01142663751519862
Epoch #205: loss=0.021979142868125613
Epoch #206: loss=0.01586455863874001
Epoch #207: loss=0.0109968785266877
Epoch #208: loss=0.02084990216472589
Epoch #209: loss=0.011290584580768273
Epoch #210: loss=0.011755827819748398
Epoch #211: loss=0.0100191648116297
Epoch #212: loss=0.01538666573898874
Epoch #213: loss=0.01277715590264494
Epoch #214: loss=0.013806852590655049
Epoch #215: loss=0.01664182679736326
Epoch #216: loss=0.009535806485825913
Epoch #217: loss=0.010818884777305554
Epoch #218: loss=0.01286194868392871
Epoch #219: loss=0.01426395291778422
Epoch #220: loss=0.014885915190412512
Epoch #221: loss=0.014555931792684688
Epoch #222: loss=0.01239672365304327
Epoch #223: loss=0.010231078704204232
Epoch #224: loss=0.017227157414799056
Epoch #225: loss=0.015439033309490155
Epoch #226: loss=0.012738244726115063
Epoch #227: loss=0.012990004531742228
Epoch #228: loss=0.012403133449751507
Epoch #229: loss=0.013774129089126274
Epoch #230: loss=0.011336575359621804
Epoch #231: loss=0.010806025753489856
Epoch #232: loss=0.01593171922206181
Epoch #233: loss=0.013504818243532796
Epoch #234: loss=0.011913173512824017
Epoch #235: loss=0.012751801970856881
Epoch #236: loss=0.015759618408853246
Epoch #237: loss=0.011423143909613262
Epoch #238: loss=0.0181690245836754
Epoch #239: loss=0.012591426074904702
Epoch #240: loss=0.013105924618267218
Epoch #241: loss=0.013009529203939335
Epoch #242: loss=0.011451002871753362
Epoch #243: loss=0.0130251265737398
Epoch #244: loss=0.012037114882840396
Epoch #245: loss=0.010661046631932616
Epoch #246: loss=0.010092909930208735
Epoch #247: loss=0.015888781348302152
Epoch #248: loss=0.011468867753661995
Epoch #249: loss=0.010941695288680863

Training time: 3:26:51.246761

Finished.
n2one setting etth1_ettm2_traffic_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm2_traffic_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_ettm2_traffic_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.02211e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.36509e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.70839e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.02211e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4188549396200123, 'MAE': 0.4612223199885412}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm2_traffic_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm2_traffic_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_ettm2_traffic_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.2548e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.60618e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.9514679612296585, 'MAE': 0.7690367017876218}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm2_weather_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm2_weather_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=6.247650598104183
Epoch #1: loss=2.8030888736248016
Epoch #2: loss=2.258143585461837
Epoch #3: loss=2.1766963050915646
Epoch #4: loss=2.0126021206378937
Epoch #5: loss=2.001624536055785
Epoch #6: loss=1.903411945471397
Epoch #7: loss=1.7748487454194288
Epoch #8: loss=1.6626256612630992
Epoch #9: loss=1.5604343460156367
Epoch #10: loss=1.5097911472503955
Epoch #11: loss=1.341440152663451
Epoch #12: loss=1.2771513943488781
Epoch #13: loss=1.2210293102722902
Epoch #14: loss=1.2615187557844014
Epoch #15: loss=1.0882147149397776
Epoch #16: loss=1.0764576907341297
Epoch #17: loss=1.0436846659733698
Epoch #18: loss=1.0248294037121992
Epoch #19: loss=0.9922269399349506
Epoch #20: loss=0.9221461529915149
Epoch #21: loss=0.9704100741789892
Epoch #22: loss=0.9289425015449524
Epoch #23: loss=0.9631989208551553
Epoch #24: loss=0.9410398946358607
Epoch #25: loss=0.8174630586917584
Epoch #26: loss=0.793787881731987
Epoch #27: loss=0.8478111693492303
Epoch #28: loss=0.7742550143828759
Epoch #29: loss=0.7590130922886041
Epoch #30: loss=0.7201688576203126
Epoch #31: loss=0.7018245235085487
Epoch #32: loss=0.6529764320987922
Epoch #33: loss=0.7146880632409682
Epoch #34: loss=0.7149239629507065
Epoch #35: loss=0.6474631050458322
Epoch #36: loss=0.6953532879169171
Epoch #37: loss=0.6854196712374687
Epoch #38: loss=0.6483818292617798
Epoch #39: loss=0.6614164217160299
Epoch #40: loss=0.6373512595891953
Epoch #41: loss=0.6260833906439635
Epoch #42: loss=0.6578920626869569
Epoch #43: loss=0.5714112560336406
Epoch #44: loss=0.5309547460996188
Epoch #45: loss=0.5758127902562802
Epoch #46: loss=0.5028017403987738
Epoch #47: loss=0.5545322149991989
Epoch #48: loss=0.5443534908386377
Epoch #49: loss=0.5319047415485749
Epoch #50: loss=0.5188707256546388
Epoch #51: loss=0.5325198723719671
Epoch #52: loss=0.5420343388731663
Epoch #53: loss=0.5258394680344142
Epoch #54: loss=0.5703487287347133
Epoch #55: loss=0.478420248398414
Epoch #56: loss=0.5127342137006613
Epoch #57: loss=0.49051648206435716
Epoch #58: loss=0.4330452588888315
Epoch #59: loss=0.4991487026787721
Epoch #60: loss=0.5011125986392682
Epoch #61: loss=0.4508818562787313
Epoch #62: loss=0.40903086501818436
Epoch #63: loss=0.4224861063636266
Epoch #64: loss=0.3996958159483396
Epoch #65: loss=0.45864099407425296
Epoch #66: loss=0.37351657106326175
Epoch #67: loss=0.3826264254748821
Epoch #68: loss=0.3852541231765197
Epoch #69: loss=0.43370575916308624
Epoch #70: loss=0.4113103555372128
Epoch #71: loss=0.37605699552939487
Epoch #72: loss=0.3671819352759765
Epoch #73: loss=0.31850164154401195
Epoch #74: loss=0.32931854790793014
Epoch #75: loss=0.3022863634217244
Epoch #76: loss=0.3136519675071423
Epoch #77: loss=0.3536215447462522
Epoch #78: loss=0.3588645395178061
Epoch #79: loss=0.3452667189905277
Epoch #80: loss=0.3142889995987599
Epoch #81: loss=0.3526362430017728
Epoch #82: loss=0.3816238965552587
Epoch #83: loss=0.417645090761093
Epoch #84: loss=0.34016937705186695
Epoch #85: loss=0.3333046423414579
Epoch #86: loss=0.3454215078113171
Epoch #87: loss=0.25605902233375955
Epoch #88: loss=0.3542637178817621
Epoch #89: loss=0.32468917163518757
Epoch #90: loss=0.25280745270160526
Epoch #91: loss=0.23275338672101498
Epoch #92: loss=0.2605911339991368
Epoch #93: loss=0.29136050392228824
Epoch #94: loss=0.31115333205805373
Epoch #95: loss=0.3648279570043087
Epoch #96: loss=0.32235463636998946
Epoch #97: loss=0.22162061456877452
Epoch #98: loss=0.20857257768511772
Epoch #99: loss=0.2029536793438288
Epoch #100: loss=0.23643477261066437
Epoch #101: loss=0.20984554269279426
Epoch #102: loss=0.24007920734584332
Epoch #103: loss=0.20158058476562685
Epoch #104: loss=0.21310513380628365
Epoch #105: loss=0.20904494571284607
Epoch #106: loss=0.2770801501778456
Epoch #107: loss=0.20162432920187712
Epoch #108: loss=0.25175432660258734
Epoch #109: loss=0.27090455262133706
Epoch #110: loss=0.17971387340758854
Epoch #111: loss=0.2040209609012191
Epoch #112: loss=0.2240641167244086
Epoch #113: loss=0.18525424126822215
Epoch #114: loss=0.20654273462983277
Epoch #115: loss=0.21573592471675232
Epoch #116: loss=0.2136578531935811
Epoch #117: loss=0.2129209185592257
Epoch #118: loss=0.16933014602042162
Epoch #119: loss=0.24549080352657116
Epoch #120: loss=0.21528794480344424
Epoch #121: loss=0.21362276561558247
Epoch #122: loss=0.17573475106977499
Epoch #123: loss=0.20587742894601363
Epoch #124: loss=0.17771479494583148
Epoch #125: loss=0.18471787569041437
Epoch #126: loss=0.18982434982004073
Epoch #127: loss=0.22368742110064396
Epoch #128: loss=0.2748358744698075
Epoch #129: loss=0.2423173848969432
Epoch #130: loss=0.20288914033713248
Epoch #131: loss=0.16126938436466914
Epoch #132: loss=0.16841120108102375
Epoch #133: loss=0.1621156853193847
Epoch #134: loss=0.134259491155927
Epoch #135: loss=0.18580125243617937
Epoch #136: loss=0.23791636848965517
Epoch #137: loss=0.2696729348256038
Epoch #138: loss=0.15653299715799782
Epoch #139: loss=0.1539242699599037
Epoch #140: loss=0.19128506594839004
Epoch #141: loss=0.14386941496139535
Epoch #142: loss=0.24296289660896248
Epoch #143: loss=0.1939899016959736
Epoch #144: loss=0.22558761696116283
Epoch #145: loss=0.16684450961362857
Epoch #146: loss=0.10894580343021797
Epoch #147: loss=0.14310349316264576
Epoch #148: loss=0.1544263117516843
Epoch #149: loss=0.1512687662974573
Epoch #150: loss=0.15106706614964283
Epoch #151: loss=0.13068649631280166
Epoch #152: loss=0.3314182882985243
Epoch #153: loss=0.1431380440122806
Epoch #154: loss=0.13666356899417365
Epoch #155: loss=0.1772125637373672
Epoch #156: loss=0.16118860939660898
Epoch #157: loss=0.14873443479434803
Epoch #158: loss=0.12883491577723852
Epoch #159: loss=0.1422576020615032
Epoch #160: loss=0.14277969118064412
Epoch #161: loss=0.10415787822925128
Epoch #162: loss=0.16249636105763224
Epoch #163: loss=0.17056256862213978
Epoch #164: loss=0.18548354456344476
Epoch #165: loss=0.15989090444949958
Epoch #166: loss=0.1502056001470639
Epoch #167: loss=0.14119493219858179
Epoch #168: loss=0.15669489798780817
Epoch #169: loss=0.1146185677498579
Epoch #170: loss=0.13945443301389998
Epoch #171: loss=0.11267318096584998
Epoch #172: loss=0.11182501600482143
Epoch #173: loss=0.13884237175807357
Epoch #174: loss=0.10906787352779737
Epoch #175: loss=0.10395742265077737
Epoch #176: loss=0.11682682652742817
Epoch #177: loss=0.08962393765194485
Epoch #178: loss=0.101190950972243
Epoch #179: loss=0.13293255156335923
Epoch #180: loss=0.15142128294190535
Epoch #181: loss=0.13294178892213565
Epoch #182: loss=0.1334725134432889
Epoch #183: loss=0.10009208353809439
Epoch #184: loss=0.11559422489685509
Epoch #185: loss=0.11601731507107615
Epoch #186: loss=0.12304056165381692
Epoch #187: loss=0.08749530786791673
Epoch #188: loss=0.0878380427423578
Epoch #189: loss=0.1102338528368049
Epoch #190: loss=0.09694357896940066
Epoch #191: loss=0.10534337739675091
Epoch #192: loss=0.19717301306529686
Epoch #193: loss=0.12070622800204617
Epoch #194: loss=0.2052337942430033
Epoch #195: loss=0.15060499106318906
Epoch #196: loss=0.16584460584160227
Epoch #197: loss=0.1042335655611868
Epoch #198: loss=0.13065756846649143
Epoch #199: loss=0.10828904728763379
Epoch #200: loss=0.09543339972599195
Epoch #201: loss=0.12067798113163847
Epoch #202: loss=0.07363312186386722
Epoch #203: loss=0.09243443619030026
Epoch #204: loss=0.11408133303316739
Epoch #205: loss=0.08635090287918082
Epoch #206: loss=0.08730932181844345
Epoch #207: loss=0.08965522772632539
Epoch #208: loss=0.07651321989340851
Epoch #209: loss=0.11704217723140922
Epoch #210: loss=0.13873807672196284
Epoch #211: loss=0.17746827715577987
Epoch #212: loss=0.1719632184204574
Epoch #213: loss=0.12030132242048588
Epoch #214: loss=0.15083122711915237
Epoch #215: loss=0.16596102306189445
Epoch #216: loss=0.15691608989324707
Epoch #217: loss=0.12248637269322689
Epoch #218: loss=0.1411503957083019
Epoch #219: loss=0.10766225992343746
Epoch #220: loss=0.12571552170153993
Epoch #221: loss=0.10162443098110649
Epoch #222: loss=0.09364122363667075
Epoch #223: loss=0.0963648534917201
Epoch #224: loss=0.07877721735992683
Epoch #225: loss=0.06904863725559643
Epoch #226: loss=0.07483707991643594
Epoch #227: loss=0.07567433457678327
Epoch #228: loss=0.07411572535952124
Epoch #229: loss=0.08770597346413594
Epoch #230: loss=0.1034698908109791
Epoch #231: loss=0.07587784200978394
Epoch #232: loss=0.10776929465982203
Epoch #233: loss=0.08374223290369488
Epoch #234: loss=0.14224786350790125
Epoch #235: loss=0.10686572707401445
Epoch #236: loss=0.09162465748018943
Epoch #237: loss=0.09399744203815666
Epoch #238: loss=0.07719826132345659
Epoch #239: loss=0.0774229963381703
Epoch #240: loss=0.10064112147889458
Epoch #241: loss=0.07576056483846444
Epoch #242: loss=0.10242684171176873
Epoch #243: loss=0.0678749550671245
Epoch #244: loss=0.07432728871488227
Epoch #245: loss=0.07339340043612398
Epoch #246: loss=0.11594278410148735
Epoch #247: loss=0.12447938448391281
Epoch #248: loss=0.17898499897609538
Epoch #249: loss=0.17790955161819091

Training time: 0:16:40.187348

Finished.
n2one setting etth1_ettm2_weather_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm2_weather_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_ettm2_weather_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.53512e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.04727e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.53512e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.37235974661491655, 'MAE': 0.43241506858050743}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_electricity_traffic_weather', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_electricity_traffic_weather_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.8808878521974149
Epoch #1: loss=0.35408423284044194
Epoch #2: loss=0.24196467894178472
Epoch #3: loss=0.1887511174549888
Epoch #4: loss=0.1464325168574425
Epoch #5: loss=0.12785603795323128
Epoch #6: loss=0.10054740696643039
Epoch #7: loss=0.09823795903158546
Epoch #8: loss=0.07913948880243545
Epoch #9: loss=0.08308572792922955
Epoch #10: loss=0.06691083632521393
Epoch #11: loss=0.05389683995025208
Epoch #12: loss=0.05322742197198462
Epoch #13: loss=0.04722685921182059
Epoch #14: loss=0.051047988406744
Epoch #15: loss=0.08618297275844318
Epoch #16: loss=0.04992417279572692
Epoch #17: loss=0.038564590731096506
Epoch #18: loss=0.03567390567676691
Epoch #19: loss=0.03911215530464879
Epoch #20: loss=0.04060351573829585
Epoch #21: loss=0.038130787131146794
Epoch #22: loss=0.028138239205298687
Epoch #23: loss=0.03837900914990505
Epoch #24: loss=0.026938123624380462
Epoch #25: loss=0.03017356151519236
Epoch #26: loss=0.02982817445349371
Epoch #27: loss=0.03329614168591146
Epoch #28: loss=0.029859532765170258
Epoch #29: loss=0.03152646768783023
Epoch #30: loss=0.030430387357084424
Epoch #31: loss=0.03740663603342622
Epoch #32: loss=0.022101513589069855
Epoch #33: loss=0.02365287347047821
Epoch #34: loss=0.02677854724582798
Epoch #35: loss=0.022863224777785563
Epoch #36: loss=0.022854974569303233
Epoch #37: loss=0.022230481386031897
Epoch #38: loss=0.02519213212436673
Epoch #39: loss=0.02162479218666129
Epoch #40: loss=0.023986805054655155
Epoch #41: loss=0.028694867955796087
Epoch #42: loss=0.029387767608807878
Epoch #43: loss=0.03037302000551503
Epoch #44: loss=0.018296470678825772
Epoch #45: loss=0.018502294261572006
Epoch #46: loss=0.018578408584912005
Epoch #47: loss=0.01762292198054638
Epoch #48: loss=0.030385084466591872
Epoch #49: loss=0.017764527199352943
Epoch #50: loss=0.018611145356771885
Epoch #51: loss=0.02172895162238762
Epoch #52: loss=0.016759150253500065
Epoch #53: loss=0.018123263625990437
Epoch #54: loss=0.020308651210765867
Epoch #55: loss=0.028859817762263686
Epoch #56: loss=0.015939117224733262
Epoch #57: loss=0.02394382015379386
Epoch #58: loss=0.015799921720300564
Epoch #59: loss=0.01645324081889492
Epoch #60: loss=0.020964037731142814
Epoch #61: loss=0.013396779823240553
Epoch #62: loss=0.019252501740766093
Epoch #63: loss=0.01953360452199903
Epoch #64: loss=0.01827658898285958
Epoch #65: loss=0.013658592808736247
Epoch #66: loss=0.020861456778938622
Epoch #67: loss=0.014396286725035392
Epoch #68: loss=0.022696422351792103
Epoch #69: loss=0.02173709058776072
Epoch #70: loss=0.014884300145001217
Epoch #71: loss=0.018189663445402977
Epoch #72: loss=0.018279393458621934
Epoch #73: loss=0.018747636300615437
Epoch #74: loss=0.024871253742850586
Epoch #75: loss=0.018043193994057412
Epoch #76: loss=0.011666791883798348
Epoch #77: loss=0.021474542793696042
Epoch #78: loss=0.013496529681632589
Epoch #79: loss=0.013946282046976864
Epoch #80: loss=0.013210477733441382
Epoch #81: loss=0.017301966687323568
Epoch #82: loss=0.018588609683918452
Epoch #83: loss=0.01476055380167383
Epoch #84: loss=0.014781725350411236
Epoch #85: loss=0.01251318862669474
Epoch #86: loss=0.013987555148225127
Epoch #87: loss=0.014882170973889611
Epoch #88: loss=0.015295876671260837
Epoch #89: loss=0.012185716081364118
Epoch #90: loss=0.01714739078036138
Epoch #91: loss=0.017021390468375773
Epoch #92: loss=0.017203020492256894
Epoch #93: loss=0.013790578105774904
Epoch #94: loss=0.017274405901724476
Epoch #95: loss=0.010955769796749481
Epoch #96: loss=0.02524596104618276
Epoch #97: loss=0.020290066102030612
Epoch #98: loss=0.013274442570012692
Epoch #99: loss=0.015176458181605611
Epoch #100: loss=0.011918475303350294
Epoch #101: loss=0.011278849797116365
Epoch #102: loss=0.016396689000430342
Epoch #103: loss=0.017230541507064788
Epoch #104: loss=0.012406463744211674
Epoch #105: loss=0.012208310704169745
Epoch #106: loss=0.014335319317380805
Epoch #107: loss=0.01331865635924451
Epoch #108: loss=0.02314722085350839
Epoch #109: loss=0.013687682478400862
Epoch #110: loss=0.013143871194690866
Epoch #111: loss=0.011679598932579737
Epoch #112: loss=0.016459325756661775
Epoch #113: loss=0.012381630806586193
Epoch #114: loss=0.011263024789549922
Epoch #115: loss=0.015339410266565929
Epoch #116: loss=0.011723772666085241
Epoch #117: loss=0.013815314051067904
Epoch #118: loss=0.011989805604679006
Epoch #119: loss=0.016414135981832306
Epoch #120: loss=0.012207418705130342
Epoch #121: loss=0.01381237885624686
Epoch #122: loss=0.011402696454752004
Epoch #123: loss=0.01140671660969498
Epoch #124: loss=0.023556618238564243
Epoch #125: loss=0.0160030657453047
Epoch #126: loss=0.01829935758867482
Epoch #127: loss=0.011998615869862604
Epoch #128: loss=0.013602611022466399
Epoch #129: loss=0.01038245382316841
Epoch #130: loss=0.012150102898718424
Epoch #131: loss=0.013359052557270365
Epoch #132: loss=0.01511680925725494
Epoch #133: loss=0.012557462743476017
Epoch #134: loss=0.011278582657580142
Epoch #135: loss=0.012277347344994078
Epoch #136: loss=0.011233726455776903
Epoch #137: loss=0.020608892041393215
Epoch #138: loss=0.009158183177470093
Epoch #139: loss=0.014264695599398405
Epoch #140: loss=0.009370756668700827
Epoch #141: loss=0.019173456543644295
Epoch #142: loss=0.019184401805217164
Epoch #143: loss=0.010486634107134083
Epoch #144: loss=0.012603221861043398
Epoch #145: loss=0.012532684587696215
Epoch #146: loss=0.011757529511477946
Epoch #147: loss=0.007190016717058107
Epoch #148: loss=0.011659024039569263
Epoch #149: loss=0.019827475985541815
Epoch #150: loss=0.009971016593549632
Epoch #151: loss=0.012916615951230358
Epoch #152: loss=0.010586861347028867
Epoch #153: loss=0.0285180285140517
Epoch #154: loss=0.014449518712461596
Epoch #155: loss=0.010094677395871162
Epoch #156: loss=0.010667134954737298
Epoch #157: loss=0.010804721533053166
Epoch #158: loss=0.01432778314608042
Epoch #159: loss=0.010581746758948372
Epoch #160: loss=0.011355147851011344
Epoch #161: loss=0.009282461119674304
Epoch #162: loss=0.01065691498329694
Epoch #163: loss=0.013792804228638775
Epoch #164: loss=0.0111139369132137
Epoch #165: loss=0.02998808914923613
Epoch #166: loss=0.01808476032029878
Epoch #167: loss=0.008602508657059173
Epoch #168: loss=0.011087046147682295
Epoch #169: loss=0.014956192541591773
Epoch #170: loss=0.008995576585232956
Epoch #171: loss=0.013034809193581359
Epoch #172: loss=0.013066094370353647
Epoch #173: loss=0.012114515139872214
Epoch #174: loss=0.011099494731261553
Epoch #175: loss=0.008506343361300663
Epoch #176: loss=0.01152058493064607
Epoch #177: loss=0.01083247270807868
Epoch #178: loss=0.013097496225423368
Epoch #179: loss=0.01263052713385916
Epoch #180: loss=0.010609357778105876
Epoch #181: loss=0.013290011337247913
Epoch #182: loss=0.011954333756420965
Epoch #183: loss=0.00870870607641456
Epoch #184: loss=0.009035009745467074
Epoch #185: loss=0.011918564228596407
Epoch #186: loss=0.011228639691993473
Epoch #187: loss=0.012234701923716784
Epoch #188: loss=0.00793183162036377
Epoch #189: loss=0.016885843522644745
Epoch #190: loss=0.008160975212149424
Epoch #191: loss=0.011845015347976048
Epoch #192: loss=0.011441253094936224
Epoch #193: loss=0.008185335516384984
Epoch #194: loss=0.009038743522140928
Epoch #195: loss=0.012444233441053592
Epoch #196: loss=0.009195037909409476
Epoch #197: loss=0.013608820223764365
Epoch #198: loss=0.012758450836978335
Epoch #199: loss=0.00959115438178359
Epoch #200: loss=0.010835063958372877
Epoch #201: loss=0.010516502543491936
Epoch #202: loss=0.01311536789031427
Epoch #203: loss=0.013814833645567074
Epoch #204: loss=0.009909560335211603
Epoch #205: loss=0.012138330458936397
Epoch #206: loss=0.016316297832274455
Epoch #207: loss=0.009065231287841494
Epoch #208: loss=0.01050821889379892
Epoch #209: loss=0.010224303136855488
Epoch #210: loss=0.014231736206583216
Epoch #211: loss=0.00856144261823781
Epoch #212: loss=0.010988213256962953
Epoch #213: loss=0.013378087140543022
Epoch #214: loss=0.008502346002772828
Epoch #215: loss=0.01543262083956913
Epoch #216: loss=0.011794162706971627
Epoch #217: loss=0.009250021860605341
Epoch #218: loss=0.013276753096521899
Epoch #219: loss=0.007582299059436082
Epoch #220: loss=0.006148168403770246
Epoch #221: loss=0.01234799490110785
Epoch #222: loss=0.009497078751792287
Epoch #223: loss=0.009713382164914276
Epoch #224: loss=0.011471473482180571
Epoch #225: loss=0.022320172023464643
Epoch #226: loss=0.009758837621431763
Epoch #227: loss=0.009249721411032098
Epoch #228: loss=0.006563080308500216
Epoch #229: loss=0.013405554167248786
Epoch #230: loss=0.013378150938646477
Epoch #231: loss=0.01815471935950834
Epoch #232: loss=0.009684242276630596
Epoch #233: loss=0.007379433058375932
Epoch #234: loss=0.012133214080677135
Epoch #235: loss=0.01402380617682746
Epoch #236: loss=0.008165583610961173
Epoch #237: loss=0.008831083493203695
Epoch #238: loss=0.013929728407351592
Epoch #239: loss=0.009186174636098306
Epoch #240: loss=0.00835938862931734
Epoch #241: loss=0.013503162258033578
Epoch #242: loss=0.008710913200508529
Epoch #243: loss=0.012161722378586523
Epoch #244: loss=0.010337314688100426
Epoch #245: loss=0.00862010691713821
Epoch #246: loss=0.009894695256949299
Epoch #247: loss=0.008664577769075933
Epoch #248: loss=0.011422109484807439
Epoch #249: loss=0.011116944936499127

Training time: 4:57:56.914197

Finished.
n2one setting etth1_electricity_traffic_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_electricity_traffic_weather_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_electricity_traffic_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
Evaluation result: {'MSE': 0.32365089886697684, 'MAE': 0.37369327419601533}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_electricity_traffic_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_electricity_traffic_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.8560449003004073
Epoch #1: loss=0.3056662825802232
Epoch #2: loss=0.2182360086434572
Epoch #3: loss=0.16024724811390167
Epoch #4: loss=0.11237782373159924
Epoch #5: loss=0.09971372700157966
Epoch #6: loss=0.09242197495725049
Epoch #7: loss=0.0645725381489103
Epoch #8: loss=0.06780450175188245
Epoch #9: loss=0.06611053837472589
Epoch #10: loss=0.06244211721537986
Epoch #11: loss=0.05322687161751309
Epoch #12: loss=0.04336250838061766
Epoch #13: loss=0.054570141213616426
Epoch #14: loss=0.0491303864888651
Epoch #15: loss=0.039455592123098134
Epoch #16: loss=0.041983647867088796
Epoch #17: loss=0.04148788740570798
Epoch #18: loss=0.03782554218240039
Epoch #19: loss=0.0319910574037207
Epoch #20: loss=0.03637947601303909
Epoch #21: loss=0.032641109117798085
Epoch #22: loss=0.034567418065017716
Epoch #23: loss=0.030627823846985296
Epoch #24: loss=0.02967936733254824
Epoch #25: loss=0.03967341001573888
Epoch #26: loss=0.03500510192756465
Epoch #27: loss=0.025572992533500552
Epoch #28: loss=0.02736547394913741
Epoch #29: loss=0.03244035797079369
Epoch #30: loss=0.03006649857475084
Epoch #31: loss=0.025729422555322554
Epoch #32: loss=0.02933815074015645
Epoch #33: loss=0.02435671507562814
Epoch #34: loss=0.018678257697278777
Epoch #35: loss=0.026799393375248698
Epoch #36: loss=0.021144734047106834
Epoch #37: loss=0.025030366387233785
Epoch #38: loss=0.028077362695829756
Epoch #39: loss=0.021668939094992484
Epoch #40: loss=0.02707261779308257
Epoch #41: loss=0.026508650953413256
Epoch #42: loss=0.024691519255746773
Epoch #43: loss=0.022090102101634188
Epoch #44: loss=0.02080130582509752
Epoch #45: loss=0.021401771568499456
Epoch #46: loss=0.029128375632903353
Epoch #47: loss=0.01981774287522601
Epoch #48: loss=0.023273678979535552
Epoch #49: loss=0.016713557207785106
Epoch #50: loss=0.019903263110859486
Epoch #51: loss=0.018735855965063098
Epoch #52: loss=0.02040009538153107
Epoch #53: loss=0.01873818550710057
Epoch #54: loss=0.017990873712443442
Epoch #55: loss=0.01977414955264144
Epoch #56: loss=0.027182511048076032
Epoch #57: loss=0.018337684914413163
Epoch #58: loss=0.015263892490836949
Epoch #59: loss=0.01629821598348196
Epoch #60: loss=0.017826260408605816
Epoch #61: loss=0.020163145476071016
Epoch #62: loss=0.017042923272124418
Epoch #63: loss=0.018782979760962097
Epoch #64: loss=0.018024492688223995
Epoch #65: loss=0.021155875240618172
Epoch #66: loss=0.01927766789156397
Epoch #67: loss=0.01733488847456098
Epoch #68: loss=0.018976257590451455
Epoch #69: loss=0.014590107836217957
Epoch #70: loss=0.015711464052448495
Epoch #71: loss=0.01596260366122062
Epoch #72: loss=0.019065757783232624
Epoch #73: loss=0.014586843012343122
Epoch #74: loss=0.01833859248070679
Epoch #75: loss=0.016159294908636955
Epoch #76: loss=0.021585782633422687
Epoch #77: loss=0.014122295738621544
Epoch #78: loss=0.017884848219719956
Epoch #79: loss=0.017100389502899417
Epoch #80: loss=0.013935186915722122
Epoch #81: loss=0.016488316275516775
Epoch #82: loss=0.014342068581857824
Epoch #83: loss=0.018262366755185874
Epoch #84: loss=0.015318783501290229
Epoch #85: loss=0.021187329349324352
Epoch #86: loss=0.021558202668815155
Epoch #87: loss=0.0172553037769703
Epoch #88: loss=0.016169424790052157
Epoch #89: loss=0.017436259808510508
Epoch #90: loss=0.02023758214414186
Epoch #91: loss=0.016082209959839593
Epoch #92: loss=0.015228037242183422
Epoch #93: loss=0.017037769211163685
Epoch #94: loss=0.016432365102722397
Epoch #95: loss=0.012906852187434302
Epoch #96: loss=0.02315045330201956
Epoch #97: loss=0.015186919005191613
Epoch #98: loss=0.014672524155633472
Epoch #99: loss=0.013324116387116914
Epoch #100: loss=0.018730094311669474
Epoch #101: loss=0.01315651961606352
Epoch #102: loss=0.012767785707252911
Epoch #103: loss=0.01327731664108271
Epoch #104: loss=0.01695110656434306
Epoch #105: loss=0.014256822162252216
Epoch #106: loss=0.01621058387408781
Epoch #107: loss=0.012781201563035067
Epoch #108: loss=0.012322955584085122
Epoch #109: loss=0.01884398349501132
Epoch #110: loss=0.011330042878422965
Epoch #111: loss=0.011695402023099804
Epoch #112: loss=0.011286772511388234
Epoch #113: loss=0.012999357015918901
Epoch #114: loss=0.015771910807010733
Epoch #115: loss=0.014365070532640646
Epoch #116: loss=0.018785622918078303
Epoch #117: loss=0.015443736600088272
Epoch #118: loss=0.012540080198310058
Epoch #119: loss=0.013402974157562952
Epoch #120: loss=0.01892134758161042
Epoch #121: loss=0.01542116646636052
Epoch #122: loss=0.013247793873352036
Epoch #123: loss=0.013495374928204847
Epoch #124: loss=0.01356240285476724
Epoch #125: loss=0.01594362009756593
Epoch #126: loss=0.015400604116464862
Epoch #127: loss=0.014333059160964515
Epoch #128: loss=0.016527246925873932
Epoch #129: loss=0.012177416632985478
Epoch #130: loss=0.01700439636936825
Epoch #131: loss=0.019527373792663276
Epoch #132: loss=0.012270797855739259
Epoch #133: loss=0.015512786704252197
Epoch #134: loss=0.009956965327138204
Epoch #135: loss=0.012482430133426843
Epoch #136: loss=0.015156830168347254
Epoch #137: loss=0.015169820040485294
Epoch #138: loss=0.012397653546843827
Epoch #139: loss=0.010266296422284991
Epoch #140: loss=0.01516820226076587
Epoch #141: loss=0.013146592674832107
Epoch #142: loss=0.01276876956870362
Epoch #143: loss=0.015825368441193453
Epoch #144: loss=0.011721908322828729
Epoch #145: loss=0.013273688659162003
Epoch #146: loss=0.01353034059833535
Epoch #147: loss=0.010228913899797814
Epoch #148: loss=0.013964633148061572
Epoch #149: loss=0.012796732044954845
Epoch #150: loss=0.013007601839696731
Epoch #151: loss=0.009716884394987033
Epoch #152: loss=0.012868286402616572
Epoch #153: loss=0.011946981859278071
Epoch #154: loss=0.010637815827704952
Epoch #155: loss=0.014343001411873597
Epoch #156: loss=0.013314671997251634
Epoch #157: loss=0.015437610934652991
Epoch #158: loss=0.011299340051878418
Epoch #159: loss=0.010451096880866205
Epoch #160: loss=0.014422320666126203
Epoch #161: loss=0.013782072025861727
Epoch #162: loss=0.015624522139191086
Epoch #163: loss=0.009792944118247417
Epoch #164: loss=0.010215003662306845
Epoch #165: loss=0.012351282343568373
Epoch #166: loss=0.017359507567487706
Epoch #167: loss=0.012746493960261864
Epoch #168: loss=0.013969701969775896
Epoch #169: loss=0.013175230130884806
Epoch #170: loss=0.01629497215659962
Epoch #171: loss=0.017204633067522627
Epoch #172: loss=0.022353866114606654
Epoch #173: loss=0.014349664842467642
Epoch #174: loss=0.015203824680160481
Epoch #175: loss=0.009307290662986883
Epoch #176: loss=0.011546227882508552
Epoch #177: loss=0.012380561104152862
Epoch #178: loss=0.011327636508674471
Epoch #179: loss=0.01050490203831908
Epoch #180: loss=0.013167130769308796
Epoch #181: loss=0.008970810672042242
Epoch #182: loss=0.009754858988212397
Epoch #183: loss=0.012852991063443
Epoch #184: loss=0.01263832864338695
Epoch #185: loss=0.014730135498046392
Epoch #186: loss=0.009930558104410321
Epoch #187: loss=0.011753978279883934
Epoch #188: loss=0.01098521373410867
Epoch #189: loss=0.01487433914237427
Epoch #190: loss=0.012460656052139779
Epoch #191: loss=0.010229132540653928
Epoch #192: loss=0.009407979527696597
Epoch #193: loss=0.010413518610849817
Epoch #194: loss=0.009965766946281204
Epoch #195: loss=0.013507627634717271
Epoch #196: loss=0.010179993142177567
Epoch #197: loss=0.008843613772002264
Epoch #198: loss=0.010006461929777118
Epoch #199: loss=0.012495291297931732
Epoch #200: loss=0.010427961976880376
Epoch #201: loss=0.011756978551209262
Epoch #202: loss=0.01769699283850454
Epoch #203: loss=0.010215975581931176
Epoch #204: loss=0.01045864154918501
Epoch #205: loss=0.013161576108934897
Epoch #206: loss=0.011723575580578285
Epoch #207: loss=0.009182111144732767
Epoch #208: loss=0.01082497573688837
Epoch #209: loss=0.015628479165557086
Epoch #210: loss=0.011101891798381123
Epoch #211: loss=0.012400640324097994
Epoch #212: loss=0.013105235595864842
Epoch #213: loss=0.011005858329066639
Epoch #214: loss=0.012047817775561204
Epoch #215: loss=0.013907154834332126
Epoch #216: loss=0.010729973408415815
Epoch #217: loss=0.010574667659000834
Epoch #218: loss=0.008625094707861783
Epoch #219: loss=0.009451146872042394
Epoch #220: loss=0.013858951544783659
Epoch #221: loss=0.011157516365232784
Epoch #222: loss=0.009797374937105252
Epoch #223: loss=0.008342153809016524
Epoch #224: loss=0.010962361398854413
Epoch #225: loss=0.011921670852542
Epoch #226: loss=0.008639691343488206
Epoch #227: loss=0.017715764935081504
Epoch #228: loss=0.008238253808022653
Epoch #229: loss=0.011089962024145191
Epoch #230: loss=0.01002868321663599
Epoch #231: loss=0.01318500369112775
Epoch #232: loss=0.009226999308322444
Epoch #233: loss=0.012280493441633709
Epoch #234: loss=0.011432426793643433
Epoch #235: loss=0.010448385434193037
Epoch #236: loss=0.011029739680388851
Epoch #237: loss=0.012312206731978513
Epoch #238: loss=0.01114171136234931
Epoch #239: loss=0.012883922855542912
Epoch #240: loss=0.009112677113077243
Epoch #241: loss=0.009645040886241983
Epoch #242: loss=0.012383468533411792
Epoch #243: loss=0.00991168196203956
Epoch #244: loss=0.011021166689495595
Epoch #245: loss=0.01086592362840741
Epoch #246: loss=0.008632629676375562
Epoch #247: loss=0.011674507609351837
Epoch #248: loss=0.011639435242696118
Epoch #249: loss=0.010481863848894477

Training time: 4:47:17.280147

Finished.
n2one setting etth1_electricity_traffic_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_electricity_traffic_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_electricity_traffic_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.51665e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.24608e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.51665e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.6260559588542338, 'MAE': 0.6043933360860501}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_electricity_weather_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_electricity_weather_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.8412768881953223
Epoch #1: loss=0.865373085628557
Epoch #2: loss=0.6007076903601378
Epoch #3: loss=0.5021057795753795
Epoch #4: loss=0.4366266682579372
Epoch #5: loss=0.3693408726081664
Epoch #6: loss=0.35944853513115677
Epoch #7: loss=0.32393400642753306
Epoch #8: loss=0.28283712018836926
Epoch #9: loss=0.2505649006333799
Epoch #10: loss=0.22182656036309115
Epoch #11: loss=0.2371226763404206
Epoch #12: loss=0.21433017660158774
Epoch #13: loss=0.19448749778679061
Epoch #14: loss=0.16944454594911462
Epoch #15: loss=0.17900513861719416
Epoch #16: loss=0.16515804540098372
Epoch #17: loss=0.1538527046963161
Epoch #18: loss=0.14759749103111128
Epoch #19: loss=0.13742319818647855
Epoch #20: loss=0.10985333924773484
Epoch #21: loss=0.11841878802798565
Epoch #22: loss=0.10533466656790089
Epoch #23: loss=0.1043938602454631
Epoch #24: loss=0.10997252942459113
Epoch #25: loss=0.08137687107867134
Epoch #26: loss=0.0903815058811223
Epoch #27: loss=0.07916740668186331
Epoch #28: loss=0.1006715347789722
Epoch #29: loss=0.09276381440753971
Epoch #30: loss=0.0879786972725733
Epoch #31: loss=0.06924722215819343
Epoch #32: loss=0.090220546400051
Epoch #33: loss=0.06818026382970052
Epoch #34: loss=0.06040860903809536
Epoch #35: loss=0.07502544478343501
Epoch #36: loss=0.07598862092869964
Epoch #37: loss=0.07158911499858561
Epoch #38: loss=0.0634438002145031
Epoch #39: loss=0.06854421087252542
Epoch #40: loss=0.055840160553626596
Epoch #41: loss=0.06555391460765174
Epoch #42: loss=0.049609453014731
Epoch #43: loss=0.05216564455916024
Epoch #44: loss=0.0556483126691805
Epoch #45: loss=0.05686190442339059
Epoch #46: loss=0.04406036012188547
Epoch #47: loss=0.04984850237192329
Epoch #48: loss=0.039155886297561844
Epoch #49: loss=0.05834408071874873
Epoch #50: loss=0.06049767605643925
Epoch #51: loss=0.06554034710874607
Epoch #52: loss=0.0418632886647787
Epoch #53: loss=0.03437737505001824
Epoch #54: loss=0.05036435759200545
Epoch #55: loss=0.04787911788543727
Epoch #56: loss=0.04967508816034199
Epoch #57: loss=0.04312557898794985
Epoch #58: loss=0.058874140456267404
Epoch #59: loss=0.042211427034305936
Epoch #60: loss=0.03702374766947372
Epoch #61: loss=0.031894198842976985
Epoch #62: loss=0.03614601524912068
Epoch #63: loss=0.055430555710368354
Epoch #64: loss=0.034785193250931344
Epoch #65: loss=0.03581858713672501
Epoch #66: loss=0.030523880321830923
Epoch #67: loss=0.03898119658215012
Epoch #68: loss=0.04625315222058198
Epoch #69: loss=0.03880290996838999
Epoch #70: loss=0.04409206767234622
Epoch #71: loss=0.05754408034854903
Epoch #72: loss=0.0547321706091167
Epoch #73: loss=0.0429488994407555
Epoch #74: loss=0.039430846301298485
Epoch #75: loss=0.04204972412466787
Epoch #76: loss=0.029046865407819988
Epoch #77: loss=0.024951038732918915
Epoch #78: loss=0.028211027475457267
Epoch #79: loss=0.023561040887728757
Epoch #80: loss=0.03694988406187397
Epoch #81: loss=0.053908166005752094
Epoch #82: loss=0.036872762904337796
Epoch #83: loss=0.031419351248994205
Epoch #84: loss=0.032537637152374614
Epoch #85: loss=0.04147940777526469
Epoch #86: loss=0.03671972814674659
Epoch #87: loss=0.027549861956520254
Epoch #88: loss=0.032218420523178935
Epoch #89: loss=0.028788102974019205
Epoch #90: loss=0.02752198967346227
Epoch #91: loss=0.03466662509143044
Epoch #92: loss=0.03154019444254073
Epoch #93: loss=0.03645227337416869
Epoch #94: loss=0.04058568640766429
Epoch #95: loss=0.041242880739968846
Epoch #96: loss=0.0330147712596934
Epoch #97: loss=0.02284631362501326
Epoch #98: loss=0.02235840531342627
Epoch #99: loss=0.027438222615399466
Epoch #100: loss=0.02998782896458619
Epoch #101: loss=0.03410010235171858
Epoch #102: loss=0.025684738104959734
Epoch #103: loss=0.02650123421689341
Epoch #104: loss=0.028403842388456096
Epoch #105: loss=0.02597737270156539
Epoch #106: loss=0.02393818584345384
Epoch #107: loss=0.028023154380408408
Epoch #108: loss=0.03930705783403741
Epoch #109: loss=0.033445664691785094
Epoch #110: loss=0.02427774208317413
Epoch #111: loss=0.031860613027614546
Epoch #112: loss=0.03239729733560723
Epoch #113: loss=0.02732552037585928
Epoch #114: loss=0.03168428966805123
Epoch #115: loss=0.024746736895083322
Epoch #116: loss=0.02620248300764962
Epoch #117: loss=0.02548995918821986
Epoch #118: loss=0.03332620720074831
Epoch #119: loss=0.05696503081450944
Epoch #120: loss=0.030199412484486068
Epoch #121: loss=0.037924884228377975
Epoch #122: loss=0.02255705150068758
Epoch #123: loss=0.01960138624256801
Epoch #124: loss=0.02242198305684322
Epoch #125: loss=0.019864404435913998
Epoch #126: loss=0.028782343863990693
Epoch #127: loss=0.025845506599299014
Epoch #128: loss=0.02701532004660932
Epoch #129: loss=0.025406717421173102
Epoch #130: loss=0.026703685667116235
Epoch #131: loss=0.017481441763441918
Epoch #132: loss=0.02411292334558643
Epoch #133: loss=0.026886971723526273
Epoch #134: loss=0.02614956790435344
Epoch #135: loss=0.022683769169273834
Epoch #136: loss=0.0213196417209062
Epoch #137: loss=0.03427942661737035
Epoch #138: loss=0.01969836309207449
Epoch #139: loss=0.01869470630023109
Epoch #140: loss=0.021799631239119557
Epoch #141: loss=0.038089383688423455
Epoch #142: loss=0.03416273272445153
Epoch #143: loss=0.026024152397259154
Epoch #144: loss=0.02499311069317306
Epoch #145: loss=0.03320436928281689
Epoch #146: loss=0.016567482934455587
Epoch #147: loss=0.01908489161036595
Epoch #148: loss=0.01712438065313621
Epoch #149: loss=0.024988983998503484
Epoch #150: loss=0.027326372385511267
Epoch #151: loss=0.01641122095520963
Epoch #152: loss=0.015953811110821888
Epoch #153: loss=0.016849502523137688
Epoch #154: loss=0.02888109201764127
Epoch #155: loss=0.03128128842121371
Epoch #156: loss=0.03326539528679658
Epoch #157: loss=0.030859050968371188
Epoch #158: loss=0.027845023507676835
Epoch #159: loss=0.033788448965333874
Epoch #160: loss=0.021027255188789507
Epoch #161: loss=0.02342787714246069
Epoch #162: loss=0.021520260274757563
Epoch #163: loss=0.018683498848383367
Epoch #164: loss=0.03063129039930864
Epoch #165: loss=0.021958237723978005
Epoch #166: loss=0.01791492652229049
Epoch #167: loss=0.029862730394989684
Epoch #168: loss=0.033399898486256276
Epoch #169: loss=0.016059096401411968
Epoch #170: loss=0.016330509397036588
Epoch #171: loss=0.014439502221568184
Epoch #172: loss=0.026727579106500844
Epoch #173: loss=0.01801662083957357
Epoch #174: loss=0.016965397764097008
Epoch #175: loss=0.022552576281296897
Epoch #176: loss=0.019435884585045794
Epoch #177: loss=0.018311724054192333
Epoch #178: loss=0.015067684522766276
Epoch #179: loss=0.022080015703052982
Epoch #180: loss=0.019703926825034045
Epoch #181: loss=0.015764734131002347
Epoch #182: loss=0.018932788453604486
Epoch #183: loss=0.021914244103161822
Epoch #184: loss=0.02048849423920211
Epoch #185: loss=0.02256807155755364
Epoch #186: loss=0.030787112794942558
Epoch #187: loss=0.021442503147232422
Epoch #188: loss=0.03468055660400324
Epoch #189: loss=0.032949753010128396
Epoch #190: loss=0.019573008376289447
Epoch #191: loss=0.02012275332422253
Epoch #192: loss=0.027103909012348295
Epoch #193: loss=0.024870269066134456
Epoch #194: loss=0.022666328849054833
Epoch #195: loss=0.016756789247394096
Epoch #196: loss=0.019299311053010415
Epoch #197: loss=0.017099164215364178
Epoch #198: loss=0.014392175829553853
Epoch #199: loss=0.021389323252221717
Epoch #200: loss=0.024595430871093574
Epoch #201: loss=0.024995571926933358
Epoch #202: loss=0.020361269222191683
Epoch #203: loss=0.030702452476487563
Epoch #204: loss=0.027340840752325304
Epoch #205: loss=0.02204625651713728
Epoch #206: loss=0.022981652818656866
Epoch #207: loss=0.021717322069829334
Epoch #208: loss=0.02192148970242574
Epoch #209: loss=0.06784093698090488
Epoch #210: loss=0.027403125574475266
Epoch #211: loss=0.019509177790853087
Epoch #212: loss=0.030301408979846216
Epoch #213: loss=0.045175131845149055
Epoch #214: loss=0.02173887608985761
Epoch #215: loss=0.01870666349062938
Epoch #216: loss=0.01347510217879037
Epoch #217: loss=0.02146353021033175
Epoch #218: loss=0.02212263925871889
Epoch #219: loss=0.017324432977896508
Epoch #220: loss=0.017709950791692453
Epoch #221: loss=0.016479186550810553
Epoch #222: loss=0.01921023231402338
Epoch #223: loss=0.028416278361306186
Epoch #224: loss=0.016288797066705198
Epoch #225: loss=0.01622992784839036
Epoch #226: loss=0.01564306742141862
Epoch #227: loss=0.01551913887967268
Epoch #228: loss=0.022019706173312403
Epoch #229: loss=0.022877901881606478
Epoch #230: loss=0.03020627233321979
Epoch #231: loss=0.021395665907236048
Epoch #232: loss=0.019463159333260406
Epoch #233: loss=0.026260002599662498
Epoch #234: loss=0.01611036381803875
Epoch #235: loss=0.022414936109070374
Epoch #236: loss=0.020357966073788702
Epoch #237: loss=0.018410845303191488
Epoch #238: loss=0.025870206622080106
Epoch #239: loss=0.014192441930043773
Epoch #240: loss=0.016818533099442333
Epoch #241: loss=0.027090225245408682
Epoch #242: loss=0.019530776931385854
Epoch #243: loss=0.018624242684351748
Epoch #244: loss=0.015534821391965582
Epoch #245: loss=0.015836960327112404
Epoch #246: loss=0.01203571380780449
Epoch #247: loss=0.017909692608167993
Epoch #248: loss=0.014344626435790035
Epoch #249: loss=0.01995322814768242

Training time: 1:38:49.191402

Finished.
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_traffic_weather_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_traffic_weather_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.137091646921859
Epoch #1: loss=0.4429017318080562
Epoch #2: loss=0.31261233067921756
Epoch #3: loss=0.25529770979684585
Epoch #4: loss=0.2122709979927157
Epoch #5: loss=0.16623103379345153
Epoch #6: loss=0.15598474257106862
Epoch #7: loss=0.13444823813588583
Epoch #8: loss=0.11608798617284626
Epoch #9: loss=0.09734176678721229
Epoch #10: loss=0.09901121085982023
Epoch #11: loss=0.08451103212637776
Epoch #12: loss=0.07263285561092404
Epoch #13: loss=0.08817104492099298
Epoch #14: loss=0.09057533602897544
Epoch #15: loss=0.06380037858913078
Epoch #16: loss=0.0629260843972431
Epoch #17: loss=0.05947427832184242
Epoch #18: loss=0.053156248351831324
Epoch #19: loss=0.05394809508290356
Epoch #20: loss=0.04712328411213814
Epoch #21: loss=0.05325349791265265
Epoch #22: loss=0.04802836319880306
Epoch #23: loss=0.04636411579812599
Epoch #24: loss=0.049216926649134456
Epoch #25: loss=0.04274579048170146
Epoch #26: loss=0.04155481385223357
Epoch #27: loss=0.055295889930421095
Epoch #28: loss=0.040222990819189085
Epoch #29: loss=0.04548693717375361
Epoch #30: loss=0.037601775811565624
Epoch #31: loss=0.0328400409047529
Epoch #32: loss=0.029812136756520252
Epoch #33: loss=0.047414767893535575
Epoch #34: loss=0.03144625860895778
Epoch #35: loss=0.04015871758004475
Epoch #36: loss=0.041992493952569834
Epoch #37: loss=0.04043253601228577
Epoch #38: loss=0.03758293443183071
Epoch #39: loss=0.03372128707054303
Epoch #40: loss=0.03015931995833346
Epoch #41: loss=0.0333216294852794
Epoch #42: loss=0.03196132583715123
Epoch #43: loss=0.024631171868683445
Epoch #44: loss=0.026405211499786977
Epoch #45: loss=0.03490971887622396
Epoch #46: loss=0.0375353908308102
Epoch #47: loss=0.03738901725188176
Epoch #48: loss=0.024344369983104606
Epoch #49: loss=0.02944521378842569
Epoch #50: loss=0.025412637094964746
Epoch #51: loss=0.03483045401525037
Epoch #52: loss=0.02973878986959202
Epoch #53: loss=0.02110316731523803
Epoch #54: loss=0.02832871388916905
Epoch #55: loss=0.03456636274128777
Epoch #56: loss=0.02814222739920214
Epoch #57: loss=0.026998575530254726
Epoch #58: loss=0.022180355571293924
Epoch #59: loss=0.031762140001281726
Epoch #60: loss=0.023854885982341263
Epoch #61: loss=0.028240805565805514
Epoch #62: loss=0.03436118666148563
Epoch #63: loss=0.025949295743751204
Epoch #64: loss=0.028373932508648097
Epoch #65: loss=0.024309346365398426
Epoch #66: loss=0.026066012105480114
Epoch #67: loss=0.021816767047619364
Epoch #68: loss=0.029811016337302487
Epoch #69: loss=0.023010734881308954
Epoch #70: loss=0.01978357968986517
Epoch #71: loss=0.024768764736424257
Epoch #72: loss=0.02179066740278854
Epoch #73: loss=0.02790717732618694
Epoch #74: loss=0.02248672430018316
Epoch #75: loss=0.026478622182279338
Epoch #76: loss=0.02755432282814267
Epoch #77: loss=0.029802713688276812
Epoch #78: loss=0.02513315744473339
Epoch #79: loss=0.023308254202238903
Epoch #80: loss=0.01809866934218511
Epoch #81: loss=0.023402380279737452
Epoch #82: loss=0.02843091473134713
Epoch #83: loss=0.019627856691306043
Epoch #84: loss=0.022186815540849284
Epoch #85: loss=0.022320718371732457
Epoch #86: loss=0.017391698276054253
Epoch #87: loss=0.022717191688309022
Epoch #88: loss=0.02097072223411406
Epoch #89: loss=0.01751531748574125
Epoch #90: loss=0.023052293846588932
Epoch #91: loss=0.019121219541825683
Epoch #92: loss=0.018521221670974974
Epoch #93: loss=0.020787690603200053
Epoch #94: loss=0.026185827027854963
Epoch #95: loss=0.01753107507961698
Epoch #96: loss=0.01639775665655989
Epoch #97: loss=0.018347430030223814
Epoch #98: loss=0.01883623021589551
Epoch #99: loss=0.02368488844874978
Epoch #100: loss=0.03811091732341798
Epoch #101: loss=0.02013331050356718
Epoch #102: loss=0.02301902833900333
Epoch #103: loss=0.013718971174717225
Epoch #104: loss=0.014886673236703979
Epoch #105: loss=0.0228922848060757
Epoch #106: loss=0.01792229044387542
Epoch #107: loss=0.019892908157424945
Epoch #108: loss=0.018913819884528393
Epoch #109: loss=0.020651406552183626
Epoch #110: loss=0.021943459067669525
Epoch #111: loss=0.016676427509731345
Epoch #112: loss=0.023117982562871675
Epoch #113: loss=0.035657428441195856
Epoch #114: loss=0.020513680999918613
Epoch #115: loss=0.02139593321341554
Epoch #116: loss=0.017413797669263778
Epoch #117: loss=0.019420015435401044
Epoch #118: loss=0.01711280852230575
Epoch #119: loss=0.019673348458162546
Epoch #120: loss=0.018192354749884572
Epoch #121: loss=0.017873633469278064
Epoch #122: loss=0.017782642276197514
Epoch #123: loss=0.01767029489682815
Epoch #124: loss=0.017662456961055874
Epoch #125: loss=0.02385388554558225
Epoch #126: loss=0.017837557347302774
Epoch #127: loss=0.014458281944201554
Epoch #128: loss=0.015733665557237084
Epoch #129: loss=0.019685782541086175
Epoch #130: loss=0.015333816974460181
Epoch #131: loss=0.013639473815360658
Epoch #132: loss=0.02105811009184042
Epoch #133: loss=0.022683179798675124
Epoch #134: loss=0.019903122439502468
Epoch #135: loss=0.017683968438116104
Epoch #136: loss=0.011405578577265211
Epoch #137: loss=0.01411308969469903
Epoch #138: loss=0.01870949469050168
Epoch #139: loss=0.020125528185488864
Epoch #140: loss=0.01960828153725666
Epoch #141: loss=0.01488601766920036
Epoch #142: loss=0.017180188822606166
Epoch #143: loss=0.02277730122311216
Epoch #144: loss=0.014437243683281838
Epoch #145: loss=0.017474773257353537
Epoch #146: loss=0.016311297755553577
Epoch #147: loss=0.026218555384670855
Epoch #148: loss=0.021255384393475726
Epoch #149: loss=0.013296169836422457
Epoch #150: loss=0.014281291592728753
Epoch #151: loss=0.01655344914850327
Epoch #152: loss=0.023370745058668055
Epoch #153: loss=0.01663174327335409
Epoch #154: loss=0.022072247472306267
Epoch #155: loss=0.019656090260990498
Epoch #156: loss=0.016155184322114928
Epoch #157: loss=0.012986692806708668
Epoch #158: loss=0.020800477644003945
Epoch #159: loss=0.02584226354259811
Epoch #160: loss=0.019751961253583947
Epoch #161: loss=0.015366207474448428
Epoch #162: loss=0.02372125414669914
Epoch #163: loss=0.015670370267711092
Epoch #164: loss=0.014353101119608427
Epoch #165: loss=0.017344368626541484
Epoch #166: loss=0.018308969128052865
Epoch #167: loss=0.015867554369904172
Epoch #168: loss=0.014884607411977363
Epoch #169: loss=0.02019119782324384
Epoch #170: loss=0.017729173048500205
Epoch #171: loss=0.017282691514758954
Epoch #172: loss=0.016059084865129226
Epoch #173: loss=0.011546619073932594
Epoch #174: loss=0.013145798509124437
Epoch #175: loss=0.014281564161736066
Epoch #176: loss=0.018973492723156092
Epoch #177: loss=0.017760724885097074
Epoch #178: loss=0.01824859081275216
Epoch #179: loss=0.013194000731069045
Epoch #180: loss=0.021178779294470672
Epoch #181: loss=0.016191233654675004
Epoch #182: loss=0.012680045792858497
Epoch #183: loss=0.01594812588363727
Epoch #184: loss=0.018291573292517245
Epoch #185: loss=0.01425129144686761
Epoch #186: loss=0.014486013171885725
Epoch #187: loss=0.017079553921114713
Epoch #188: loss=0.015147298814223874
Epoch #189: loss=0.017020274683076875
Epoch #190: loss=0.021448087317913932
Epoch #191: loss=0.014513488221876963
Epoch #192: loss=0.01498932787049603
Epoch #193: loss=0.0161135985545599
Epoch #194: loss=0.018504445293259727
Epoch #195: loss=0.013206942389855973
Epoch #196: loss=0.014560773593932402
Epoch #197: loss=0.014964812725764604
Epoch #198: loss=0.016514203194227143
Epoch #199: loss=0.019468799582005716
Epoch #200: loss=0.021048374285002638
Epoch #201: loss=0.016692786621220423
Epoch #202: loss=0.014802480648324404
Epoch #203: loss=0.013923381878489037
Epoch #204: loss=0.016735084848321154
Epoch #205: loss=0.013998553403365067
Epoch #206: loss=0.016022056541675062
Epoch #207: loss=0.012553214464914648
Epoch #208: loss=0.012872699044583854
Epoch #209: loss=0.012067526487756318
Epoch #210: loss=0.01827036820216453
Epoch #211: loss=0.016127570155572382
Epoch #212: loss=0.009506719197683033
Epoch #213: loss=0.015961279668415932
Epoch #214: loss=0.019202880640944144
Epoch #215: loss=0.017201822197224877
Epoch #216: loss=0.012207960412074484
Epoch #217: loss=0.03121492384351439
Epoch #218: loss=0.015894111890312552
Epoch #219: loss=0.010137071631761339
Epoch #220: loss=0.01374039073358161
Epoch #221: loss=0.012472405099990166
Epoch #222: loss=0.03137207059541631
Epoch #223: loss=0.01804667149186583
Epoch #224: loss=0.011346673552589032
Epoch #225: loss=0.010724476391612912
Epoch #226: loss=0.01515797732362074
Epoch #227: loss=0.014321456796743372
Epoch #228: loss=0.019422612630354514
Epoch #229: loss=0.020397570767068093
Epoch #230: loss=0.018160464231722604
Epoch #231: loss=0.012636611653535957
Epoch #232: loss=0.0109648979011006
Epoch #233: loss=0.013195466103195573
Epoch #234: loss=0.015248590063639935
Epoch #235: loss=0.02396673391290666
Epoch #236: loss=0.013661364862619724
Epoch #237: loss=0.011626568360646475
Epoch #238: loss=0.015024474520536122
Epoch #239: loss=0.010622975392852762
Epoch #240: loss=0.014450647888392116
Epoch #241: loss=0.011227138499186547
Epoch #242: loss=0.012557725981599831
Epoch #243: loss=0.014943906161136118
Epoch #244: loss=0.011804834874208907
Epoch #245: loss=0.019344339910387975
Epoch #246: loss=0.01409741110550776
Epoch #247: loss=0.01962566495083911
Epoch #248: loss=0.015969457409731633
Epoch #249: loss=0.010816280379340132

Training time: 3:30:57.400130

Finished.
n2one setting etth1_traffic_weather_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_traffic_weather_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='etth1_traffic_weather_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.07313e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.46193e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.07313e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4124994319553183, 'MAE': 0.4583957368019841}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm1_ettm2_electricity', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm1_ettm2_electricity_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.6960530599525996
Epoch #1: loss=0.722116880927767
Epoch #2: loss=0.4946829952086721
Epoch #3: loss=0.39889539778232574
Epoch #4: loss=0.3330862640483039
Epoch #5: loss=0.304806980405535
Epoch #6: loss=0.24361458631498473
Epoch #7: loss=0.2312946169929845
Epoch #8: loss=0.21332121061427253
Epoch #9: loss=0.1840821362393243
Epoch #10: loss=0.16338392236403057
Epoch #11: loss=0.14322705344430037
Epoch #12: loss=0.149971293253558
Epoch #13: loss=0.1204245367965528
Epoch #14: loss=0.11501046084931918
Epoch #15: loss=0.11262965361986842
Epoch #16: loss=0.09317351277917624
Epoch #17: loss=0.08349309446290136
Epoch #18: loss=0.0961998631618917
Epoch #19: loss=0.09462874290932502
Epoch #20: loss=0.09425718029694898
Epoch #21: loss=0.06845592048684401
Epoch #22: loss=0.08150175094870585
Epoch #23: loss=0.06460837635610785
Epoch #24: loss=0.06230368467047811
Epoch #25: loss=0.05670404702957187
Epoch #26: loss=0.06977088594143944
Epoch #27: loss=0.05863560248831553
Epoch #28: loss=0.04288380439060607
Epoch #29: loss=0.04313881863108171
Epoch #30: loss=0.04451496546023658
Epoch #31: loss=0.044500749095210006
Epoch #32: loss=0.05000771517599267
Epoch #33: loss=0.044094283218894685
Epoch #34: loss=0.05580092908282365
Epoch #35: loss=0.03339587922873242
Epoch #36: loss=0.036997372981027836
Epoch #37: loss=0.042494483878170806
Epoch #38: loss=0.03590846911139254
Epoch #39: loss=0.027420722761723613
Epoch #40: loss=0.05183940591290593
Epoch #41: loss=0.03057552802509495
Epoch #42: loss=0.030475452133853522
Epoch #43: loss=0.030301800489292614
Epoch #44: loss=0.029263969521437373
Epoch #45: loss=0.028156646937131883
Epoch #46: loss=0.038634118769717
Epoch #47: loss=0.03125829154658796
Epoch #48: loss=0.02668404813190656
Epoch #49: loss=0.023591014836648744
Epoch #50: loss=0.0291899583209306
Epoch #51: loss=0.026721906145768505
Epoch #52: loss=0.025583042491759574
Epoch #53: loss=0.021554858670902573
Epoch #54: loss=0.02940485662847225
Epoch #55: loss=0.020612734626047312
Epoch #56: loss=0.024398352468186724
Epoch #57: loss=0.027809213366625566
Epoch #58: loss=0.02346117128385231
Epoch #59: loss=0.02873092867134671
Epoch #60: loss=0.0244189326347883
Epoch #61: loss=0.015644894868268498
Epoch #62: loss=0.021120818749934968
Epoch #63: loss=0.021627279917842576
Epoch #64: loss=0.03746538250241429
Epoch #65: loss=0.021838450295285187
Epoch #66: loss=0.021900913180018376
Epoch #67: loss=0.022565161593956874
Epoch #68: loss=0.021332998968926924
Epoch #69: loss=0.02244719787633845
Epoch #70: loss=0.02546526348950075
Epoch #71: loss=0.022071534651996835
Epoch #72: loss=0.021200145997240075
Epoch #73: loss=0.01581972236013306
Epoch #74: loss=0.02229056959240032
Epoch #75: loss=0.022173398289430355
Epoch #76: loss=0.021840935929711643
Epoch #77: loss=0.017349691997182424
Epoch #78: loss=0.01338895099104515
Epoch #79: loss=0.02218201438680158
Epoch #80: loss=0.021587561546226167
Epoch #81: loss=0.021714540922216006
Epoch #82: loss=0.02072260611590796
Epoch #83: loss=0.019702999204995908
Epoch #84: loss=0.01861521593827222
Epoch #85: loss=0.02022626295353153
Epoch #86: loss=0.041039914666741555
Epoch #87: loss=0.020558959788177164
Epoch #88: loss=0.014215347621357068
Epoch #89: loss=0.016907695161062292
Epoch #90: loss=0.018062637317925692
Epoch #91: loss=0.0359092609857076
Epoch #92: loss=0.029908083383925258
Epoch #93: loss=0.02590477819255154
Epoch #94: loss=0.027561894253262186
Epoch #95: loss=0.02574968302722222
Epoch #96: loss=0.0167363847188452
Epoch #97: loss=0.01795644860714674
Epoch #98: loss=0.01536980439110526
Epoch #99: loss=0.017502208986552432
Epoch #100: loss=0.019742631897097452
Epoch #101: loss=0.014374845851478833
Epoch #102: loss=0.013816660679959958
Epoch #103: loss=0.020720342756914242
Epoch #104: loss=0.02051852544619968
Epoch #105: loss=0.010955801101268403
Epoch #106: loss=0.016478633150192244
Epoch #107: loss=0.01614752423783232
Epoch #108: loss=0.017138538664107077
Epoch #109: loss=0.024627444423801666
Epoch #110: loss=0.018444847013368938
Epoch #111: loss=0.017140707353662167
Epoch #112: loss=0.013559023161485259
Epoch #113: loss=0.015813082347657267
Epoch #114: loss=0.011418564767809584
Epoch #115: loss=0.019502236562548205
Epoch #116: loss=0.010898982222923743
Epoch #117: loss=0.017604392673321333
Epoch #118: loss=0.020527484542357602
Epoch #119: loss=0.01660566890379414
Epoch #120: loss=0.019853519791836985
Epoch #121: loss=0.017534111446168805
Epoch #122: loss=0.012474371857408966
Epoch #123: loss=0.013318475630782943
Epoch #124: loss=0.014205045974065017
Epoch #125: loss=0.016560479864045713
Epoch #126: loss=0.018718828782106615
Epoch #127: loss=0.013700430825119838
Epoch #128: loss=0.03111871581790703
Epoch #129: loss=0.015335925447621516
Epoch #130: loss=0.01314518382348719
Epoch #131: loss=0.01396227404475212
Epoch #132: loss=0.012437679034566307
Epoch #133: loss=0.019078613686308796
Epoch #134: loss=0.012753575563380894
Epoch #135: loss=0.012485675722959319
Epoch #136: loss=0.011547037068272143
Epoch #137: loss=0.011347566199671876
Epoch #138: loss=0.017970489842950233
Epoch #139: loss=0.013091848322656006
Epoch #140: loss=0.010404281496220002
Epoch #141: loss=0.01293533105120462
Epoch #142: loss=0.01402068956804994
Epoch #143: loss=0.025612440299508828
Epoch #144: loss=0.01105754592796854
Epoch #145: loss=0.016828123391439607
Epoch #146: loss=0.033128296252107246
Epoch #147: loss=0.019757087755216552
Epoch #148: loss=0.010991185381010706
Epoch #149: loss=0.011578640589058133
Epoch #150: loss=0.011847787308839283
Epoch #151: loss=0.012570320003017384
Epoch #152: loss=0.014558280279327715
Epoch #153: loss=0.011971335936188033
Epoch #154: loss=0.009839312944428196
Epoch #155: loss=0.009609464301361835
Epoch #156: loss=0.018886313906488275
Epoch #157: loss=0.011507484449123565
Epoch #158: loss=0.010753454206444855
Epoch #159: loss=0.01601017072015176
Epoch #160: loss=0.013069025109289215
Epoch #161: loss=0.012881110093523083
Epoch #162: loss=0.014502863157041636
Epoch #163: loss=0.023367375703195907
Epoch #164: loss=0.013455296185981881
Epoch #165: loss=0.013322352799004875
Epoch #166: loss=0.012199480780483489
Epoch #167: loss=0.011056627845350055
Epoch #168: loss=0.01142576818903243
Epoch #169: loss=0.03173740236554295
Epoch #170: loss=0.01915518663740451
Epoch #171: loss=0.010421916680310719
Epoch #172: loss=0.011233118187103952
Epoch #173: loss=0.013769356882216276
Epoch #174: loss=0.013115653068442562
Epoch #175: loss=0.01539265520704378
Epoch #176: loss=0.014131825971916052
Epoch #177: loss=0.016238467250285403
Epoch #178: loss=0.010258144774707035
Epoch #179: loss=0.01345809415074265
Epoch #180: loss=0.008973534779922505
Epoch #181: loss=0.012063867744956432
Epoch #182: loss=0.01068674830312375
Epoch #183: loss=0.010940239995584956
Epoch #184: loss=0.021315646754810586
Epoch #185: loss=0.008574244787949803
Epoch #186: loss=0.01112785250089863
Epoch #187: loss=0.009843582747936515
Epoch #188: loss=0.010962818458875907
Epoch #189: loss=0.011595363037195057
Epoch #190: loss=0.010734963563403912
Epoch #191: loss=0.007767742943417813
Epoch #192: loss=0.022432921177075644
Epoch #193: loss=0.017709583038397664
Epoch #194: loss=0.01642589388515002
Epoch #195: loss=0.01103829625794398
Epoch #196: loss=0.005957950916573671
Epoch #197: loss=0.010036357776012405
Epoch #198: loss=0.009800865708467816
Epoch #199: loss=0.011103675087049071
Epoch #200: loss=0.009019639678632042
Epoch #201: loss=0.016798198219288938
Epoch #202: loss=0.014808909295326364
Epoch #203: loss=0.013616876958154275
Epoch #204: loss=0.013653462797852366
Epoch #205: loss=0.013926557059166953
Epoch #206: loss=0.014573217598954216
Epoch #207: loss=0.019448633958652085
Epoch #208: loss=0.017549674721334927
Epoch #209: loss=0.011123192000502189
Epoch #210: loss=0.01353389716008678
Epoch #211: loss=0.011978141510958917
Epoch #212: loss=0.00983522339258343
Epoch #213: loss=0.02223189528216608
Epoch #214: loss=0.012753272618034056
Epoch #215: loss=0.010770530616199332
Epoch #216: loss=0.012366103490348905
Epoch #217: loss=0.008345583994523622
Epoch #218: loss=0.009040824540674553
Epoch #219: loss=0.013741846828488634
Epoch #220: loss=0.011591755276313051
Epoch #221: loss=0.012065125563115413
Epoch #222: loss=0.014465700156288222
Epoch #223: loss=0.00788557944727862
Epoch #224: loss=0.0092893242845977
Epoch #225: loss=0.00972162202000618
Epoch #226: loss=0.0100801075045352
Epoch #227: loss=0.007982012195778744
Epoch #228: loss=0.012840296208908383
Epoch #229: loss=0.009488186470656988
Epoch #230: loss=0.01010432345085844
Epoch #231: loss=0.015762522481381894
Epoch #232: loss=0.00985631227010994
Epoch #233: loss=0.011640091779575285
Epoch #234: loss=0.011708761725874086
Epoch #235: loss=0.015852544574632442
Epoch #236: loss=0.013039909537848351
Epoch #237: loss=0.01319052016761686
Epoch #238: loss=0.008103586865888376
Epoch #239: loss=0.010585826054864031
Epoch #240: loss=0.005912511396122032
Epoch #241: loss=0.010770532885965491
Epoch #242: loss=0.011727268890577501
Epoch #243: loss=0.010116605311632157
Epoch #244: loss=0.013541999287803525
Epoch #245: loss=0.016132289287925233
Epoch #246: loss=0.01217842752280246
Epoch #247: loss=0.009968908061439704
Epoch #248: loss=0.00828106346244957
Epoch #249: loss=0.01338590878361304

Training time: 1:51:38.582233

Finished.
n2one setting etth2_ettm1_ettm2_electricity -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_ettm2_electricity_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_ettm1_ettm2_electricity', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.21918e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.53793e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.81083e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.21918e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3551060002303937, 'MAE': 0.4303551029349889}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm1_ettm2_electricity -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_ettm2_electricity_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_ettm1_ettm2_electricity', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.53942e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.53942e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.2820160128015285, 'MAE': 0.3595094861437351}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm1_ettm2_traffic', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm1_ettm2_traffic_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.0264468209109323
Epoch #1: loss=0.39063214069999563
Epoch #2: loss=0.27107123420160895
Epoch #3: loss=0.20304521325009842
Epoch #4: loss=0.1744423672916445
Epoch #5: loss=0.14056990337667843
Epoch #6: loss=0.10920089323964183
Epoch #7: loss=0.10970552993768995
Epoch #8: loss=0.08806124116962004
Epoch #9: loss=0.08361610967883323
Epoch #10: loss=0.0710216160397454
Epoch #11: loss=0.06595849791880358
Epoch #12: loss=0.06063794563017476
Epoch #13: loss=0.05744081951874307
Epoch #14: loss=0.05513160760482035
Epoch #15: loss=0.05930141550692595
Epoch #16: loss=0.054136334703116774
Epoch #17: loss=0.052359185416479284
Epoch #18: loss=0.05053153546243764
Epoch #19: loss=0.04367756787985438
Epoch #20: loss=0.03750638158936535
Epoch #21: loss=0.03741175214280233
Epoch #22: loss=0.036114393434368126
Epoch #23: loss=0.0337890569963644
Epoch #24: loss=0.03396242036205621
Epoch #25: loss=0.03118726811342999
Epoch #26: loss=0.029609077250376953
Epoch #27: loss=0.03428727466684654
Epoch #28: loss=0.030253482967882713
Epoch #29: loss=0.027724154110094816
Epoch #30: loss=0.02652286763726833
Epoch #31: loss=0.04190150818797445
Epoch #32: loss=0.02360254400485539
Epoch #33: loss=0.03156703452397541
Epoch #34: loss=0.024337525130772187
Epoch #35: loss=0.021510059973597045
Epoch #36: loss=0.026961058125790423
Epoch #37: loss=0.023492497991583407
Epoch #38: loss=0.02841822252928684
Epoch #39: loss=0.02094375406119891
Epoch #40: loss=0.023927198926195416
Epoch #41: loss=0.024492025915893917
Epoch #42: loss=0.020909515448336885
Epoch #43: loss=0.02621689633150424
Epoch #44: loss=0.026128490030356315
Epoch #45: loss=0.018924053962664902
Epoch #46: loss=0.023719818642460682
Epoch #47: loss=0.02026830341833655
Epoch #48: loss=0.01955980497010483
Epoch #49: loss=0.02169823705963689
Epoch #50: loss=0.015200847705228277
Epoch #51: loss=0.02704273885524676
Epoch #52: loss=0.019020038884625414
Epoch #53: loss=0.022163687759838416
Epoch #54: loss=0.01888470840385585
Epoch #55: loss=0.021435447147461782
Epoch #56: loss=0.02110001131795257
Epoch #57: loss=0.020892898449162072
Epoch #58: loss=0.021359496560746306
Epoch #59: loss=0.016385157436132954
Epoch #60: loss=0.020661967777381583
Epoch #61: loss=0.01991949588719935
Epoch #62: loss=0.018274197426037846
Epoch #63: loss=0.014483159221068556
Epoch #64: loss=0.025294916202378483
Epoch #65: loss=0.02027763134354227
Epoch #66: loss=0.017177156834960072
Epoch #67: loss=0.021532710218343097
Epoch #68: loss=0.017015007411011657
Epoch #69: loss=0.017317986123783328
Epoch #70: loss=0.014746222361257482
Epoch #71: loss=0.017212839860736427
Epoch #72: loss=0.01667205202923701
Epoch #73: loss=0.017529531482956766
Epoch #74: loss=0.019134382932764656
Epoch #75: loss=0.018281206969590125
Epoch #76: loss=0.012473969028410256
Epoch #77: loss=0.018416212706193726
Epoch #78: loss=0.01767491696255572
Epoch #79: loss=0.02235707902386377
Epoch #80: loss=0.017363705743727715
Epoch #81: loss=0.014196020837491179
Epoch #82: loss=0.017749774385080724
Epoch #83: loss=0.016534841375364834
Epoch #84: loss=0.016020939880736405
Epoch #85: loss=0.0191926093500026
Epoch #86: loss=0.016191275041310252
Epoch #87: loss=0.021071134026747148
Epoch #88: loss=0.013417930525078729
Epoch #89: loss=0.017149263033034504
Epoch #90: loss=0.010325905566116038
Epoch #91: loss=0.01725544031838391
Epoch #92: loss=0.02241118781940957
Epoch #93: loss=0.013281899324873584
Epoch #94: loss=0.020737934549191213
Epoch #95: loss=0.018112312400411484
Epoch #96: loss=0.012844385443247204
Epoch #97: loss=0.00958621211511456
Epoch #98: loss=0.013092386127344001
Epoch #99: loss=0.02106646603960063
Epoch #100: loss=0.015397992055180068
Epoch #101: loss=0.014945515767578663
Epoch #102: loss=0.015995654138288535
Epoch #103: loss=0.011610812734096237
Epoch #104: loss=0.01227652627107056
Epoch #105: loss=0.014872638396181869
Epoch #106: loss=0.017075203569550026
Epoch #107: loss=0.010933448009980282
Epoch #108: loss=0.02034957166394014
Epoch #109: loss=0.01832713856880253
Epoch #110: loss=0.03742248996479205
Epoch #111: loss=0.01634245313131475
Epoch #112: loss=0.010803130363528621
Epoch #113: loss=0.013346420023506706
Epoch #114: loss=0.011136811133186666
Epoch #115: loss=0.011050924307536845
Epoch #116: loss=0.01187112036362712
Epoch #117: loss=0.021783889848561215
Epoch #118: loss=0.011486452991474999
Epoch #119: loss=0.014249994560951256
Epoch #120: loss=0.011172661409040706
Epoch #121: loss=0.013839172787781948
Epoch #122: loss=0.01308100226440537
Epoch #123: loss=0.016624186415815576
Epoch #124: loss=0.009709630913911733
Epoch #125: loss=0.01448240710047934
Epoch #126: loss=0.01858182641351635
Epoch #127: loss=0.012437598065986098
Epoch #128: loss=0.01549018220041798
Epoch #129: loss=0.015042274094599076
Epoch #130: loss=0.01194236379075094
Epoch #131: loss=0.010068075090508118
Epoch #132: loss=0.013026154932377057
Epoch #133: loss=0.013314730865689043
Epoch #134: loss=0.013183707376743702
Epoch #135: loss=0.011736081559980585
Epoch #136: loss=0.012274499274063344
Epoch #137: loss=0.013074046085961268
Epoch #138: loss=0.013285193969026537
Epoch #139: loss=0.022040287780342362
Epoch #140: loss=0.009922585463831797
Epoch #141: loss=0.015167893367022742
Epoch #142: loss=0.015280579205999081
Epoch #143: loss=0.01189888444949045
Epoch #144: loss=0.009581459243527084
Epoch #145: loss=0.017984597905048753
Epoch #146: loss=0.017642473064542787
Epoch #147: loss=0.014081502482591627
Epoch #148: loss=0.009728035223607589
Epoch #149: loss=0.01222055604945365
Epoch #150: loss=0.019259128948740503
Epoch #151: loss=0.00983936021766853
Epoch #152: loss=0.008737572598265584
Epoch #153: loss=0.010896591982637259
Epoch #154: loss=0.011968181599636118
Epoch #155: loss=0.013025974776694085
Epoch #156: loss=0.015492947973095625
Epoch #157: loss=0.016318376405982774
Epoch #158: loss=0.011033904707970858
Epoch #159: loss=0.012121522898270197
Epoch #160: loss=0.010375129949318728
Epoch #161: loss=0.012131451713049305
Epoch #162: loss=0.012530718515066567
Epoch #163: loss=0.012300945921414548
Epoch #164: loss=0.015166276642005743
Epoch #165: loss=0.009526799130233896
Epoch #166: loss=0.014613641794485079
Epoch #167: loss=0.013027572822033226
Epoch #168: loss=0.010046521678153926
Epoch #169: loss=0.012629507346158846
Epoch #170: loss=0.010257798039458126
Epoch #171: loss=0.015337500504489024
Epoch #172: loss=0.007859391801524515
Epoch #173: loss=0.012779097892652348
Epoch #174: loss=0.011982868853966015
Epoch #175: loss=0.01137451667602014
Epoch #176: loss=0.014109037231900086
Epoch #177: loss=0.010107855590564166
Epoch #178: loss=0.00833233671945412
Epoch #179: loss=0.010942757769381835
Epoch #180: loss=0.012100146645125268
Epoch #181: loss=0.012379781606659533
Epoch #182: loss=0.00859447525706449
Epoch #183: loss=0.011891713461145006
Epoch #184: loss=0.013303414867477105
Epoch #185: loss=0.011507847561655403
Epoch #186: loss=0.009060772719465595
Epoch #187: loss=0.008468585087270978
Epoch #188: loss=0.013492111415198798
Epoch #189: loss=0.01614721264370966
Epoch #190: loss=0.01294340487331383
Epoch #191: loss=0.010397812628315805
Epoch #192: loss=0.015233208045588678
Epoch #193: loss=0.010496056356390088
Epoch #194: loss=0.01159825436624417
Epoch #195: loss=0.007829457658024083
Epoch #196: loss=0.014836084080409775
Epoch #197: loss=0.009023275826625186
Epoch #198: loss=0.013080982757620168
Epoch #199: loss=0.012186058160398019
Epoch #200: loss=0.01190662374260065
Epoch #201: loss=0.009251684900251056
Epoch #202: loss=0.010720954434650895
Epoch #203: loss=0.009467438380490032
Epoch #204: loss=0.014655690699680422
Epoch #205: loss=0.009532743798297143
Epoch #206: loss=0.007842855914104567
Epoch #207: loss=0.008296547844818432
Epoch #208: loss=0.012504441559260636
Epoch #209: loss=0.011903526575286798
Epoch #210: loss=0.008528689511885184
Epoch #211: loss=0.008602084199515839
Epoch #212: loss=0.01489844397390465
Epoch #213: loss=0.012136064219998256
Epoch #214: loss=0.007710124510990084
Epoch #215: loss=0.01227143074773187
Epoch #216: loss=0.00984887745740364
Epoch #217: loss=0.012139935463883283
Epoch #218: loss=0.0088054199730835
Epoch #219: loss=0.010039300380914088
Epoch #220: loss=0.012106929962319718
Epoch #221: loss=0.008818431699607472
Epoch #222: loss=0.01167081644388235
Epoch #223: loss=0.00903050521435425
Epoch #224: loss=0.015778390112494753
Epoch #225: loss=0.01010234348276224
Epoch #226: loss=0.0135314130875057
Epoch #227: loss=0.012864448464122538
Epoch #228: loss=0.012399731377491416
Epoch #229: loss=0.007420943213643924
Epoch #230: loss=0.011185543474194612
Epoch #231: loss=0.008652006183120117
Epoch #232: loss=0.007836236085052321
Epoch #233: loss=0.016243854350913824
Epoch #234: loss=0.010172340533067394
Epoch #235: loss=0.010009883043701697
Epoch #236: loss=0.008343917968253803
Epoch #237: loss=0.010218968085778383
Epoch #238: loss=0.011811687671570275
Epoch #239: loss=0.010424302959181373
Epoch #240: loss=0.010238669179907794
Epoch #241: loss=0.006873248835293787
Epoch #242: loss=0.010572034746981263
Epoch #243: loss=0.010052275093931232
Epoch #244: loss=0.015542935355285269
Epoch #245: loss=0.008410573620911157
Epoch #246: loss=0.007753785516514757
Epoch #247: loss=0.013976314871755663
Epoch #248: loss=0.0062985700355175315
Epoch #249: loss=0.009262732332741542

Training time: 4:45:34.707422

Finished.
n2one setting etth2_ettm1_ettm2_traffic -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_ettm2_traffic_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_ettm1_ettm2_traffic', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.60287e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.04803e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.92967e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.60287e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.41653768317813883, 'MAE': 0.4614859151438678}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm1_ettm2_traffic -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_ettm2_traffic_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_ettm1_ettm2_traffic', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.05343e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.0797e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.43589e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.05343e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.49797243645235584, 'MAE': 0.535722405040142}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm1_ettm2_traffic -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_ettm2_traffic_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_ettm1_ettm2_traffic', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
Evaluation result: {'MSE': 0.2725689138725798, 'MAE': 0.34282910344036555}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm1_ettm2_weather', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm1_ettm2_weather_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=3.9511311227625066
Epoch #1: loss=2.4287903547286986
Epoch #2: loss=2.05042592828924
Epoch #3: loss=2.0681080558083274
Epoch #4: loss=1.6569472139531916
Epoch #5: loss=1.4818492022427645
Epoch #6: loss=1.3513112610036677
Epoch #7: loss=1.2380901087414136
Epoch #8: loss=1.1440384463830429
Epoch #9: loss=1.2036850344051013
Epoch #10: loss=1.0737196727232499
Epoch #11: loss=0.9480891877954657
Epoch #12: loss=0.9421712550249967
Epoch #13: loss=0.8620168241587552
Epoch #14: loss=0.8360880830071189
Epoch #15: loss=0.7905533422123302
Epoch #16: loss=0.787107253074646
Epoch #17: loss=0.7418275605548512
Epoch #18: loss=0.7603674509308554
Epoch #19: loss=0.7501562129367482
Epoch #20: loss=0.7349122697656805
Epoch #21: loss=0.7469285347244956
Epoch #22: loss=0.670295177264647
Epoch #23: loss=0.64598480517214
Epoch #24: loss=0.5901165149428628
Epoch #25: loss=0.6554133171384985
Epoch #26: loss=0.5311690552668138
Epoch #27: loss=0.6082325323061509
Epoch #28: loss=0.5239815804091367
Epoch #29: loss=0.5390419385649942
Epoch #30: loss=0.5421386615796523
Epoch #31: loss=0.4373585083267906
Epoch #32: loss=0.5131246929818933
Epoch #33: loss=0.4643789844079451
Epoch #34: loss=0.5612957168709148
Epoch #35: loss=0.4506995157762007
Epoch #36: loss=0.44024504098025236
Epoch #37: loss=0.4070110394196077
Epoch #38: loss=0.39234071346846494
Epoch #39: loss=0.43827223073352467
Epoch #40: loss=0.46597340892661704
Epoch #41: loss=0.4773768118836663
Epoch #42: loss=0.4766621391881596
Epoch #43: loss=0.45570878901264883
Epoch #44: loss=0.36708740321072664
Epoch #45: loss=0.39195174358107826
Epoch #46: loss=0.37454266358505595
Epoch #47: loss=0.3644544040614908
Epoch #48: loss=0.3452891528606415
Epoch #49: loss=0.2986515760421753
Epoch #50: loss=0.2997338947924701
Epoch #51: loss=0.2896533584052866
Epoch #52: loss=0.3203309931538322
Epoch #53: loss=0.26008152094754305
Epoch #54: loss=0.281883097643202
Epoch #55: loss=0.25899308892813594
Epoch #56: loss=0.2461146358739246
Epoch #57: loss=0.2635957092046738
Epoch #58: loss=0.233829112757336
Epoch #59: loss=0.20958906330845573
Epoch #60: loss=0.2924516140059991
Epoch #61: loss=0.22387106852097946
Epoch #62: loss=0.2350431828336282
Epoch #63: loss=0.2487665512345054
Epoch #64: loss=0.247278672659939
Epoch #65: loss=0.28623401712287555
Epoch #66: loss=0.2219301934946667
Epoch #67: loss=0.22251668030565436
Epoch #68: loss=0.24298992482098666
Epoch #69: loss=0.3063710926608606
Epoch #70: loss=0.20436682172796944
Epoch #71: loss=0.20085165466774593
Epoch #72: loss=0.23774217827753588
Epoch #73: loss=0.20366712469946255
Epoch #74: loss=0.18256766498088836
Epoch #75: loss=0.16667579168623145
Epoch #76: loss=0.2193933457136154
Epoch #77: loss=0.20075775906443596
Epoch #78: loss=0.16514204469594088
Epoch #79: loss=0.12246507263996384
Epoch #80: loss=0.13872340165755964
Epoch #81: loss=0.1817403263666413
Epoch #82: loss=0.1789256124333902
Epoch #83: loss=0.19191454317082057
Epoch #84: loss=0.47630019336938856
Epoch #85: loss=0.28265448998321185
Epoch #86: loss=0.34928468696095727
Epoch #87: loss=0.22997027561068534
Epoch #88: loss=0.17875755320895803
Epoch #89: loss=0.18788396919315511
Epoch #90: loss=0.13748799779198387
Epoch #91: loss=0.17234413583170283
Epoch #92: loss=0.29865998409011146
Epoch #93: loss=0.17814475778828967
Epoch #94: loss=0.15938681187954815
Epoch #95: loss=0.12019917162304575
Epoch #96: loss=0.11815271601080894
Epoch #97: loss=0.11382840079340067
Epoch #98: loss=0.09412258704277603
Epoch #99: loss=0.1088002321395007
Epoch #100: loss=0.1258440866050395
Epoch #101: loss=0.1081833733076399
Epoch #102: loss=0.09883113239299167
Epoch #103: loss=0.09521869620816274
Epoch #104: loss=0.1431976121257652
Epoch #105: loss=0.21512740979140454
Epoch #106: loss=0.13473944867199117
Epoch #107: loss=0.122577499022538
Epoch #108: loss=0.12175938896834851
Epoch #109: loss=0.1155061782083728
Epoch #110: loss=0.09536796750670129
Epoch #111: loss=0.10186148644848303
Epoch #112: loss=0.09209814796393567
Epoch #113: loss=0.1458609210835262
Epoch #114: loss=0.10102367153899236
Epoch #115: loss=0.11022781045599417
Epoch #116: loss=0.09873930127783255
Epoch #117: loss=0.09363449656150558
Epoch #118: loss=0.09889013550498268
Epoch #119: loss=0.10942817845127799
Epoch #120: loss=0.11983752606267278
Epoch #121: loss=0.09938725453208794
Epoch #122: loss=0.1140555834567005
Epoch #123: loss=0.17825796062296087
Epoch #124: loss=0.11075316755609078
Epoch #125: loss=0.0818274929442189
Epoch #126: loss=0.11808502643623135
Epoch #127: loss=0.2005485648797317
Epoch #128: loss=0.10321886105970902
Epoch #129: loss=0.13724052154205063
Epoch #130: loss=0.12950104928829453
Epoch #131: loss=0.10868564491922206
Epoch #132: loss=0.1143152419816364
Epoch #133: loss=0.07912943078712983
Epoch #134: loss=0.07316190629181536
Epoch #135: loss=0.08073405880819667
Epoch #136: loss=0.0874770527197556
Epoch #137: loss=0.07583860216492956
Epoch #138: loss=0.08210667110979557
Epoch #139: loss=0.08928699664432894
Epoch #140: loss=0.06409389241175219
Epoch #141: loss=0.08862295933067799
Epoch #142: loss=0.07418024880303578
Epoch #143: loss=0.11720049581067128
Epoch #144: loss=0.07563032558695837
Epoch #145: loss=0.08133579392663458
Epoch #146: loss=0.06979765467007051
Epoch #147: loss=0.06487824048169634
Epoch #148: loss=0.08696080635894429
Epoch #149: loss=0.11245541071349924
Epoch #150: loss=0.07607790851457552
Epoch #151: loss=0.08964178238741376
Epoch #152: loss=0.08788450062274933
Epoch #153: loss=0.07577534331516786
Epoch #154: loss=0.06820853166282177
Epoch #155: loss=0.08380196307870474
Epoch #156: loss=0.0671007362279025
Epoch #157: loss=0.0752268646928397
Epoch #158: loss=0.08542611090974374
Epoch #159: loss=0.08481467532163317
Epoch #160: loss=0.12360705249011517
Epoch #161: loss=0.09253368309952996
Epoch #162: loss=0.10838318521326239
Epoch #163: loss=0.0948820675638589
Epoch #164: loss=0.1832930068739436
Epoch #165: loss=0.10007310733199119
Epoch #166: loss=0.13809873769906433
Epoch #167: loss=0.11643095582046292
Epoch #168: loss=0.0708094301040877
Epoch #169: loss=0.08979678895663132
Epoch #170: loss=0.09582139089364897
Epoch #171: loss=0.11548059489578008
Epoch #172: loss=0.07788150095465508
Epoch #173: loss=0.0689925144341859
Epoch #174: loss=0.05460234807634896
Epoch #175: loss=0.0723604230210185
Epoch #176: loss=0.07863531405614181
Epoch #177: loss=0.05660193289884112
Epoch #178: loss=0.07591179455207153
Epoch #179: loss=0.06720926871692592
Epoch #180: loss=0.09873034672980958
Epoch #181: loss=0.07016668758270415
Epoch #182: loss=0.07041986833580516
Epoch #183: loss=0.053360739587382834
Epoch #184: loss=0.08488993646407669
Epoch #185: loss=0.06741622224111449
Epoch #186: loss=0.0534459659491073
Epoch #187: loss=0.07040085843340917
Epoch #188: loss=0.1096418547020717
Epoch #189: loss=0.06783178252252665
Epoch #190: loss=0.059596305594525556
Epoch #191: loss=0.052095835613594814
Epoch #192: loss=0.08102299709889021
Epoch #193: loss=0.05941878315061331
Epoch #194: loss=0.09848951897160574
Epoch #195: loss=0.05504010355269367
Epoch #196: loss=0.07429110270670869
Epoch #197: loss=0.05287487136030739
Epoch #198: loss=0.06796917834065178
Epoch #199: loss=0.08196338689462705
Epoch #200: loss=0.06356999383053996
Epoch #201: loss=0.0926804185252298
Epoch #202: loss=0.06883153486996889
Epoch #203: loss=0.09368482003496452
Epoch #204: loss=0.12159156316721981
Epoch #205: loss=0.13965816054154526
Epoch #206: loss=0.058902633224021304
Epoch #207: loss=0.048990445736457
Epoch #208: loss=0.05897736093876037
Epoch #209: loss=0.08380529838190838
Epoch #210: loss=0.08097278325056488
Epoch #211: loss=0.11170684906908057
Epoch #212: loss=0.09107219400731
Epoch #213: loss=0.07087084955789826
Epoch #214: loss=0.06333494297313419
Epoch #215: loss=0.0845705782994628
Epoch #216: loss=0.04300916626710783
Epoch #217: loss=0.04990416207266125
Epoch #218: loss=0.06631703524934975
Epoch #219: loss=0.046467251635410566
Epoch #220: loss=0.04955741202628071
Epoch #221: loss=0.10829477151855826
Epoch #222: loss=0.08376999141817743
Epoch #223: loss=0.0549541454592889
Epoch #224: loss=0.04661836209283634
Epoch #225: loss=0.054582283840599384
Epoch #226: loss=0.04604910480874506
Epoch #227: loss=0.0719710680402138
Epoch #228: loss=0.06350802454081449
Epoch #229: loss=0.06478945143859495
Epoch #230: loss=0.052142337557267056
Epoch #231: loss=0.06982704096219756
Epoch #232: loss=0.06259320202198895
Epoch #233: loss=0.0655395685102452
Epoch #234: loss=0.06276827783069827
Epoch #235: loss=0.0665560126727955
Epoch #236: loss=0.0446022845889357
Epoch #237: loss=0.03852233952757987
Epoch #238: loss=0.04378053142096509
Epoch #239: loss=0.038819047910245985
Epoch #240: loss=0.0442261130718345
Epoch #241: loss=0.03552989122373137
Epoch #242: loss=0.04869002362035892
Epoch #243: loss=0.02867492521605031
Epoch #244: loss=0.047469290608370844
Epoch #245: loss=0.11013893574814905
Epoch #246: loss=0.05323690409687432
Epoch #247: loss=0.05520321057940071
Epoch #248: loss=0.042979954327033325
Epoch #249: loss=0.04149507103826512

Training time: 0:20:28.644274

Finished.
n2one setting etth2_ettm1_ettm2_weather -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_ettm2_weather_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_ettm1_ettm2_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.59519e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.96075e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.59519e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3989406067111912, 'MAE': 0.43912666429670105}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm1_ettm2_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_ettm2_weather_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_ettm1_ettm2_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.03909e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.23370084830632193, 'MAE': 0.33371911042200925}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm1_ettm2_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm1_ettm2_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=3.9756416662319287
Epoch #1: loss=2.2303118544655876
Epoch #2: loss=2.085343151479154
Epoch #3: loss=1.8797025938291807
Epoch #4: loss=1.6776949908282306
Epoch #5: loss=1.5933278992369369
Epoch #6: loss=1.4218962289191581
Epoch #7: loss=1.3463056764087162
Epoch #8: loss=1.2918304559346792
Epoch #9: loss=1.1547325027955544
Epoch #10: loss=1.133061152857703
Epoch #11: loss=1.0414167803687018
Epoch #12: loss=1.0240691626394116
Epoch #13: loss=0.9762259302912532
Epoch #14: loss=0.8985224124547597
Epoch #15: loss=0.9877064356932769
Epoch #16: loss=0.9228918681273589
Epoch #17: loss=0.8959484599732064
Epoch #18: loss=0.8612647733172855
Epoch #19: loss=0.8790920312340195
Epoch #20: loss=0.8176340605761554
Epoch #21: loss=0.7810622840314299
Epoch #22: loss=0.843899797748875
Epoch #23: loss=0.7256221352396784
Epoch #24: loss=0.7749352809545156
Epoch #25: loss=0.6984965446833018
Epoch #26: loss=0.6682860472717801
Epoch #27: loss=0.7987553847802652
Epoch #28: loss=0.7719177209042214
Epoch #29: loss=0.7584945084275426
Epoch #30: loss=0.7395870846671027
Epoch #31: loss=0.6754163447264079
Epoch #32: loss=0.5835912034318254
Epoch #33: loss=0.6233755519261232
Epoch #34: loss=0.5920295248160491
Epoch #35: loss=0.530357282709431
Epoch #36: loss=0.5153298788779491
Epoch #37: loss=0.6089981359404486
Epoch #38: loss=0.5365009420626873
Epoch #39: loss=0.5273710102648348
Epoch #40: loss=0.6277109271771198
Epoch #41: loss=0.6442965695986876
Epoch #42: loss=0.6029754144114416
Epoch #43: loss=0.560872849580404
Epoch #44: loss=0.6173758579267038
Epoch #45: loss=0.4768896280108271
Epoch #46: loss=0.45127648276251714
Epoch #47: loss=0.44533695079184865
Epoch #48: loss=0.5329848044627422
Epoch #49: loss=0.49557980733948787
Epoch #50: loss=0.4872743849818771
Epoch #51: loss=0.5895436655830693
Epoch #52: loss=0.4963361620903015
Epoch #53: loss=0.5093386149084246
Epoch #54: loss=0.49098914539491806
Epoch #55: loss=0.4231174084785822
Epoch #56: loss=0.4434441573716499
Epoch #57: loss=0.4010336628636798
Epoch #58: loss=0.36322193774017125
Epoch #59: loss=0.3220556354200518
Epoch #60: loss=0.3420330612240611
Epoch #61: loss=0.3253078645951039
Epoch #62: loss=0.41220603762446223
Epoch #63: loss=0.3245165911880699
Epoch #64: loss=0.4739677205279067
Epoch #65: loss=0.41273980084303263
Epoch #66: loss=0.3886471644446656
Epoch #67: loss=0.4862259360584053
Epoch #68: loss=0.40941206828967946
Epoch #69: loss=0.41676198268258896
Epoch #70: loss=0.3080367695640873
Epoch #71: loss=0.32026835349765986
Epoch #72: loss=0.3168395016644452
Epoch #73: loss=0.2990987413638347
Epoch #74: loss=0.359138119261007
Epoch #75: loss=0.37544704047409266
Epoch #76: loss=0.31458199668574977
Epoch #77: loss=0.36657557414995656
Epoch #78: loss=0.30413748364190796
Epoch #79: loss=0.3098904450197478
Epoch #80: loss=0.2987283484355823
Epoch #81: loss=0.2768056281917804
Epoch #82: loss=0.25234868498267354
Epoch #83: loss=0.3232144934905542
Epoch #84: loss=0.24396065119150523
Epoch #85: loss=0.21811374780294057
Epoch #86: loss=0.22780088657462919
Epoch #87: loss=0.22295657807105296
Epoch #88: loss=0.23676848331013242
Epoch #89: loss=0.23961970552399353
Epoch #90: loss=0.24774289694992271
Epoch #91: loss=0.2684397578642175
Epoch #92: loss=0.23672399247014844
Epoch #93: loss=0.2572112842588811
Epoch #94: loss=0.22754804145645452
Epoch #95: loss=0.2320869291150892
Epoch #96: loss=0.19677621830959577
Epoch #97: loss=0.18962499519457687
Epoch #98: loss=0.23663431295269244
Epoch #99: loss=0.210345446862079
Epoch #100: loss=0.1858924604146867
Epoch #101: loss=0.17152232696881164
Epoch #102: loss=0.14419328854293437
Epoch #103: loss=0.18025953403195819
Epoch #104: loss=0.2301597110927105
Epoch #105: loss=0.16061888010920705
Epoch #106: loss=0.23933030745467623
Epoch #107: loss=0.21885962321146116
Epoch #108: loss=0.19842418182540583
Epoch #109: loss=0.21478891584116058
Epoch #110: loss=0.23900424387003924
Epoch #111: loss=0.20184236050054832
Epoch #112: loss=0.1980765388422721
Epoch #113: loss=0.20139839902922912
Epoch #114: loss=0.17954679387244019
Epoch #115: loss=0.1638319926286066
Epoch #116: loss=0.19223134259919863
Epoch #117: loss=0.13204909085824684
Epoch #118: loss=0.17908965534455068
Epoch #119: loss=0.15782747911037626
Epoch #120: loss=0.19585074786398862
Epoch #121: loss=0.18768816370819066
Epoch #122: loss=0.16970701717041634
Epoch #123: loss=0.17186738359364304
Epoch #124: loss=0.2521949930972344
Epoch #125: loss=0.20011042561885473
Epoch #126: loss=0.2836694714386721
Epoch #127: loss=0.19749509553248817
Epoch #128: loss=0.2062112056725734
Epoch #129: loss=0.15363286294647166
Epoch #130: loss=0.15094387903809547
Epoch #131: loss=0.14006353461661855
Epoch #132: loss=0.19461500533931964
Epoch #133: loss=0.18788447321669474
Epoch #134: loss=0.2026082586396385
Epoch #135: loss=0.1662541753738313
Epoch #136: loss=0.1526651953825274
Epoch #137: loss=0.15498360528333768
Epoch #138: loss=0.17583950045141014
Epoch #139: loss=0.15770922087737033
Epoch #140: loss=0.12192842157909999
Epoch #141: loss=0.11841006174280837
Epoch #142: loss=0.1304506069502315
Epoch #143: loss=0.12355869082180229
Epoch #144: loss=0.14769159056044914
Epoch #145: loss=0.1835285969884009
Epoch #146: loss=0.11800212815806672
Epoch #147: loss=0.17843115541177826
Epoch #148: loss=0.17659319720759586
Epoch #149: loss=0.1741652446421417
Epoch #150: loss=0.14393382408731692
Epoch #151: loss=0.12055870140525135
Epoch #152: loss=0.12352203960354263
Epoch #153: loss=0.15115320204278906
Epoch #154: loss=0.22818500377439163
Epoch #155: loss=0.1725392572179034
Epoch #156: loss=0.1439349465072155
Epoch #157: loss=0.12227678908085501
Epoch #158: loss=0.1634734762278763
Epoch #159: loss=0.19698127087306333
Epoch #160: loss=0.20494985147505193
Epoch #161: loss=0.14555063541676547
Epoch #162: loss=0.13837433661762122
Epoch #163: loss=0.15013840160257108
Epoch #164: loss=0.14270752361295996
Epoch #165: loss=0.13006940046073617
Epoch #166: loss=0.10560902505106218
Epoch #167: loss=0.18417794997426304
Epoch #168: loss=0.14013019637078852
Epoch #169: loss=0.0910019564970925
Epoch #170: loss=0.10957109746900764
Epoch #171: loss=0.11894755780294135
Epoch #172: loss=0.13720299847222664
Epoch #173: loss=0.09883040582408777
Epoch #174: loss=0.10528132022433989
Epoch #175: loss=0.1454255717831689
Epoch #176: loss=0.16057054718603958
Epoch #177: loss=0.1241693783652138
Epoch #178: loss=0.09915528360854935
Epoch #179: loss=0.11066360031632153
Epoch #180: loss=0.13596729017995499
Epoch #181: loss=0.10348969310320713
Epoch #182: loss=0.11277973178673435
Epoch #183: loss=0.12939936723056678
Epoch #184: loss=0.12565523129258607
Epoch #185: loss=0.11286501377518918
Epoch #186: loss=0.13135908674952146
Epoch #187: loss=0.10430832290266817
Epoch #188: loss=0.1290835330917223
Epoch #189: loss=0.13631354138959903
Epoch #190: loss=0.1251611347134049
Epoch #191: loss=0.13091731519513838
Epoch #192: loss=0.10903902870376368
Epoch #193: loss=0.09480409059874914
Epoch #194: loss=0.11263128213987157
Epoch #195: loss=0.08135428173920593
Epoch #196: loss=0.12343567823739471
Epoch #197: loss=0.10458989944812414
Epoch #198: loss=0.0891725792474038
Epoch #199: loss=0.09541549279379684
Epoch #200: loss=0.09282862581312656
Epoch #201: loss=0.17543889859036818
Epoch #202: loss=0.12083825806306826
Epoch #203: loss=0.11569577782742076
Epoch #204: loss=0.08111644123454352
Epoch #205: loss=0.07898202251542259
Epoch #206: loss=0.08613469388738677
Epoch #207: loss=0.12121817688583522
Epoch #208: loss=0.16969688136029887
Epoch #209: loss=0.09666871161174935
Epoch #210: loss=0.11007082854976526
Epoch #211: loss=0.13153621201982368
Epoch #212: loss=0.11013978976454283
Epoch #213: loss=0.0802053206575078
Epoch #214: loss=0.09140968287514674
Epoch #215: loss=0.10123145550086692
Epoch #216: loss=0.12993393934054956
Epoch #217: loss=0.1296375571825617
Epoch #218: loss=0.09870532927782955
Epoch #219: loss=0.13160711426187205
Epoch #220: loss=0.11765714236409278
Epoch #221: loss=0.1708475958958671
Epoch #222: loss=0.22513817804487976
Epoch #223: loss=0.19432766665075277
Epoch #224: loss=0.10857480140151204
Epoch #225: loss=0.07766278938868561
Epoch #226: loss=0.09133207382684624
Epoch #227: loss=0.06695658537383015
Epoch #228: loss=0.06982612491560143
Epoch #229: loss=0.07523373851703631
Epoch #230: loss=0.1419425026790516
Epoch #231: loss=0.08989395941230091
Epoch #232: loss=0.11797230620239232
Epoch #233: loss=0.08221119964444959
Epoch #234: loss=0.12960187438875437
Epoch #235: loss=0.10643934861228273
Epoch #236: loss=0.0831079458113055
Epoch #237: loss=0.08613949774991016
Epoch #238: loss=0.13311288357284423
Epoch #239: loss=0.10059445205371122
Epoch #240: loss=0.09261194880850412
Epoch #241: loss=0.0664451980610957
Epoch #242: loss=0.06545013481298008
Epoch #243: loss=0.06097292957978474
Epoch #244: loss=0.07136444890921986
Epoch #245: loss=0.05119996446159643
Epoch #246: loss=0.05108523867218881
Epoch #247: loss=0.05865145691141889
Epoch #248: loss=0.08496442921711383
Epoch #249: loss=0.08976457129559808

Training time: 0:12:50.812996

Finished.
n2one setting etth2_ettm1_ettm2_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_ettm2_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_ettm1_ettm2_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.73352e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.32413e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.73352e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3755596994652828, 'MAE': 0.43818932548862705}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm1_ettm2_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_ettm2_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_ettm1_ettm2_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.47548e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.98554e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.47548e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.8396005006858066, 'MAE': 0.7263933333595295}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm1_electricity_traffic', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm1_electricity_traffic_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.8513990280208341
Epoch #1: loss=0.3217139193519863
Epoch #2: loss=0.2070515460577436
Epoch #3: loss=0.15290373482188516
Epoch #4: loss=0.12036283914896223
Epoch #5: loss=0.09656484500132036
Epoch #6: loss=0.07912946247544564
Epoch #7: loss=0.07255543526075936
Epoch #8: loss=0.0653861413467877
Epoch #9: loss=0.05711063756654
Epoch #10: loss=0.05087363796904187
Epoch #11: loss=0.04355112413199561
Epoch #12: loss=0.04361879955984956
Epoch #13: loss=0.046484475462564845
Epoch #14: loss=0.053130776987998105
Epoch #15: loss=0.03707631162292542
Epoch #16: loss=0.03370359228843657
Epoch #17: loss=0.03412035744804749
Epoch #18: loss=0.04627718772441785
Epoch #19: loss=0.0311616945741923
Epoch #20: loss=0.03343943871360359
Epoch #21: loss=0.03210613565778454
Epoch #22: loss=0.026396064512601448
Epoch #23: loss=0.02593482366811909
Epoch #24: loss=0.029062815255203985
Epoch #25: loss=0.02394450827560649
Epoch #26: loss=0.028532290656730644
Epoch #27: loss=0.02691128527170604
Epoch #28: loss=0.026383794198777344
Epoch #29: loss=0.026041075931041952
Epoch #30: loss=0.020900436071165256
Epoch #31: loss=0.027410865660869654
Epoch #32: loss=0.021623396120428864
Epoch #33: loss=0.021892683254147755
Epoch #34: loss=0.019334092497258377
Epoch #35: loss=0.0208335501843343
Epoch #36: loss=0.02704591032348885
Epoch #37: loss=0.018989698285518834
Epoch #38: loss=0.020480334350150065
Epoch #39: loss=0.01777739394604454
Epoch #40: loss=0.020548083752565872
Epoch #41: loss=0.02713381950706662
Epoch #42: loss=0.02391518633891181
Epoch #43: loss=0.01664551000424283
Epoch #44: loss=0.018000572251741828
Epoch #45: loss=0.015069406358141307
Epoch #46: loss=0.01937035572630579
Epoch #47: loss=0.017608990454489905
Epoch #48: loss=0.01910835452336406
Epoch #49: loss=0.020133468238464312
Epoch #50: loss=0.015234048690344072
Epoch #51: loss=0.016243634955263694
Epoch #52: loss=0.014865358210666816
Epoch #53: loss=0.019131865020497057
Epoch #54: loss=0.014915924672065279
Epoch #55: loss=0.01886481333200333
Epoch #56: loss=0.014906035543672026
Epoch #57: loss=0.01493623207068225
Epoch #58: loss=0.01545929569982401
Epoch #59: loss=0.028114335116140116
Epoch #60: loss=0.012852985513297497
Epoch #61: loss=0.018067677279484013
Epoch #62: loss=0.013573877903293364
Epoch #63: loss=0.017748405172020046
Epoch #64: loss=0.02251002334245751
Epoch #65: loss=0.01424228578487405
Epoch #66: loss=0.012996524045643994
Epoch #67: loss=0.01605281984404646
Epoch #68: loss=0.012901904004440643
Epoch #69: loss=0.01471445276399029
Epoch #70: loss=0.013342623340719489
Epoch #71: loss=0.03030891702900083
Epoch #72: loss=0.013686818912079391
Epoch #73: loss=0.013268590966130232
Epoch #74: loss=0.012227527493291878
Epoch #75: loss=0.016629858927509098
Epoch #76: loss=0.01526916532467649
Epoch #77: loss=0.016910023269487613
Epoch #78: loss=0.012940705141906962
Epoch #79: loss=0.014792747610756742
Epoch #80: loss=0.014444675515308416
Epoch #81: loss=0.0119523241458097
Epoch #82: loss=0.015099661890150775
Epoch #83: loss=0.012032152633098373
Epoch #84: loss=0.01312504768695141
Epoch #85: loss=0.012416298210276384
Epoch #86: loss=0.0129558098745892
Epoch #87: loss=0.013878601833435568
Epoch #88: loss=0.012044285584779027
Epoch #89: loss=0.013618656356500456
Epoch #90: loss=0.008706481018200882
Epoch #91: loss=0.014151383820411515
Epoch #92: loss=0.012741198111674458
Epoch #93: loss=0.012407125843410458
Epoch #94: loss=0.017827436579593948
Epoch #95: loss=0.014926364554270061
Epoch #96: loss=0.010664000619684314
Epoch #97: loss=0.014865402471175739
Epoch #98: loss=0.01322902137999381
Epoch #99: loss=0.01793682040333291
Epoch #100: loss=0.011017198455665856
Epoch #101: loss=0.012160322649586056
Epoch #102: loss=0.013296118282342135
Epoch #103: loss=0.014568963224745064
Epoch #104: loss=0.010550427045940664
Epoch #105: loss=0.014296473077979934
Epoch #106: loss=0.01590395339537446
Epoch #107: loss=0.012285816444523732
Epoch #108: loss=0.014403238080507478
Epoch #109: loss=0.008187949829385421
Epoch #110: loss=0.010268448134463553
Epoch #111: loss=0.014293280831209372
Epoch #112: loss=0.01397133700434108
Epoch #113: loss=0.010836469976092448
Epoch #114: loss=0.009943207631179974
Epoch #115: loss=0.009230079313690796
Epoch #116: loss=0.01352163677378232
Epoch #117: loss=0.02590424934375258
Epoch #118: loss=0.013522840303198847
Epoch #119: loss=0.010022124930316517
Epoch #120: loss=0.010192275125938325
Epoch #121: loss=0.021510474598365754
Epoch #122: loss=0.012171606799974075
Epoch #123: loss=0.011238186921343537
Epoch #124: loss=0.009636673456050926
Epoch #125: loss=0.013070904356974672
Epoch #126: loss=0.011625693655263813
Epoch #127: loss=0.012476113513968462
Epoch #128: loss=0.010406319177362504
Epoch #129: loss=0.012593101348306676
Epoch #130: loss=0.020816656713059704
Epoch #131: loss=0.01624061031867347
Epoch #132: loss=0.009891844372623495
Epoch #133: loss=0.011424663208313961
Epoch #134: loss=0.012696330969378533
Epoch #135: loss=0.012254057357707224
Epoch #136: loss=0.013332791747424525
Epoch #137: loss=0.015310005810774583
Epoch #138: loss=0.009474965491043062
Epoch #139: loss=0.013839781745740671
Epoch #140: loss=0.012453390981247502
Epoch #141: loss=0.009262234495727746
Epoch #142: loss=0.010821233248686283
Epoch #143: loss=0.015763371503728422
Epoch #144: loss=0.01101132861425213
Epoch #145: loss=0.010540029593025312
Epoch #146: loss=0.011623961689487854
Epoch #147: loss=0.009648336648898777
Epoch #148: loss=0.01294027021574283
Epoch #149: loss=0.011676042905628379
Epoch #150: loss=0.009376054889000805
Epoch #151: loss=0.009148689423079314
Epoch #152: loss=0.009002999743395527
Epoch #153: loss=0.01732520314565876
Epoch #154: loss=0.01139535836276496
Epoch #155: loss=0.010968641757849836
Epoch #156: loss=0.0101164552048661
Epoch #157: loss=0.010354522508355326
Epoch #158: loss=0.012386156890276109
Epoch #159: loss=0.00975175330135695
Epoch #160: loss=0.013574146551495305
Epoch #161: loss=0.02287567964386221
Epoch #162: loss=0.009814774061326699
Epoch #163: loss=0.012253566743350618
Epoch #164: loss=0.007806083824098103
Epoch #165: loss=0.01093000938897688
Epoch #166: loss=0.01573630388151291
Epoch #167: loss=0.01331762248506443
Epoch #168: loss=0.011885903171878378
Epoch #169: loss=0.012168948647516607
Epoch #170: loss=0.011949158204754999
Epoch #171: loss=0.009682939694926347
Epoch #172: loss=0.012948606293079491
Epoch #173: loss=0.009271261133286773
Epoch #174: loss=0.010609402259060827
Epoch #175: loss=0.006178823140143808
Epoch #176: loss=0.008912030450262473
Epoch #177: loss=0.01176165758092479
Epoch #178: loss=0.0073215898769289425
Epoch #179: loss=0.007937615645136668
Epoch #180: loss=0.011935277016718366
Epoch #181: loss=0.010588588644713582
Epoch #182: loss=0.009133883951220981
Epoch #183: loss=0.011760108575070415
Epoch #184: loss=0.007551582833271447
Epoch #185: loss=0.015287699168907121
Epoch #186: loss=0.009505285585768674
Epoch #187: loss=0.00846348728639674
Epoch #188: loss=0.008034228099889611
Epoch #189: loss=0.011617647164238952
Epoch #190: loss=0.011119704169977679
Epoch #191: loss=0.007719416216482641
Epoch #192: loss=0.009788957021951747
Epoch #193: loss=0.011182100024931389
Epoch #194: loss=0.011873131950183264
Epoch #195: loss=0.008650708637572951
Epoch #196: loss=0.011016763512605266
Epoch #197: loss=0.010369571549056034
Epoch #198: loss=0.015317725372134994
Epoch #199: loss=0.008413107832433302
Epoch #200: loss=0.015323758089028378
Epoch #201: loss=0.00808012620023339
Epoch #202: loss=0.011746983382166351
Epoch #203: loss=0.007899740400769089
Epoch #204: loss=0.012223946840664343
Epoch #205: loss=0.0076877355092849296
Epoch #206: loss=0.011868665456329065
Epoch #207: loss=0.010510788529950502
Epoch #208: loss=0.017715933798165988
Epoch #209: loss=0.008154720031422428
Epoch #210: loss=0.009649901829506527
Epoch #211: loss=0.008837835867854015
Epoch #212: loss=0.013114107735970715
Epoch #213: loss=0.008105479226261824
Epoch #214: loss=0.007863817266602886
Epoch #215: loss=0.010108626762998358
Epoch #216: loss=0.013686242606195208
Epoch #217: loss=0.011552015185991239
Epoch #218: loss=0.01006872480914313
Epoch #219: loss=0.008443592286231167
Epoch #220: loss=0.006366464530453825
Epoch #221: loss=0.01124118728226157
Epoch #222: loss=0.009318185054531246
Epoch #223: loss=0.009920358653656721
Epoch #224: loss=0.010238313298098795
Epoch #225: loss=0.009584960267782815
Epoch #226: loss=0.010825995199208458
Epoch #227: loss=0.013920877499446847
Epoch #228: loss=0.010047558139849177
Epoch #229: loss=0.008736775828294501
Epoch #230: loss=0.01040452665819567
Epoch #231: loss=0.01114635004927668
Epoch #232: loss=0.008725351610149578
Epoch #233: loss=0.009891664282143307
Epoch #234: loss=0.0119365440252714
Epoch #235: loss=0.006942434480572909
Epoch #236: loss=0.010239064827095912
Epoch #237: loss=0.008443728087818018
Epoch #238: loss=0.009884309282511931
Epoch #239: loss=0.0108616905125686
Epoch #240: loss=0.00839424880023648
Epoch #241: loss=0.007856128461423367
Epoch #242: loss=0.010277405078629486
Epoch #243: loss=0.007848963851841997
Epoch #244: loss=0.011188566481529213
Epoch #245: loss=0.007680308556153251
Epoch #246: loss=0.011046399551984248
Epoch #247: loss=0.008270945448986624
Epoch #248: loss=0.010777074469015066
Epoch #249: loss=0.007416598985225992

Training time: 5:21:09.085013

Finished.
n2one setting etth2_ettm1_electricity_traffic -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_electricity_traffic_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_ettm1_electricity_traffic', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.70172e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.4641e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.70172e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4816251810027725, 'MAE': 0.5218314753837257}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm1_electricity_traffic -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_electricity_traffic_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_ettm1_electricity_traffic', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
Evaluation result: {'MSE': 0.35420296891647696, 'MAE': 0.39171016034771916}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm1_electricity_weather', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm1_electricity_weather_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.802453686113227
Epoch #1: loss=0.816384719904155
Epoch #2: loss=0.5595253221792718
Epoch #3: loss=0.4590823981859913
Epoch #4: loss=0.4332518028886351
Epoch #5: loss=0.36533203435270756
Epoch #6: loss=0.32275668762318077
Epoch #7: loss=0.31173345650712103
Epoch #8: loss=0.25869441040574687
Epoch #9: loss=0.26563872468389876
Epoch #10: loss=0.21925011015918155
Epoch #11: loss=0.20053959472538674
Epoch #12: loss=0.1910769863487923
Epoch #13: loss=0.17793951401971791
Epoch #14: loss=0.17110596859495933
Epoch #15: loss=0.17471861873995767
Epoch #16: loss=0.1583138597746418
Epoch #17: loss=0.12244079218131222
Epoch #18: loss=0.13535403304618515
Epoch #19: loss=0.11633349196755723
Epoch #20: loss=0.1108111296155273
Epoch #21: loss=0.10374934215557902
Epoch #22: loss=0.08266999439068445
Epoch #23: loss=0.07633512959853836
Epoch #24: loss=0.11777034753754939
Epoch #25: loss=0.09117582754219232
Epoch #26: loss=0.08167175780599044
Epoch #27: loss=0.07605376427176676
Epoch #28: loss=0.05906181452055908
Epoch #29: loss=0.06999692771685859
Epoch #30: loss=0.0634505005119598
Epoch #31: loss=0.06270684028707751
Epoch #32: loss=0.05824336331363206
Epoch #33: loss=0.06358625989994161
Epoch #34: loss=0.048720019217580554
Epoch #35: loss=0.04008117373267265
Epoch #36: loss=0.05721998894842316
Epoch #37: loss=0.05974876877456291
Epoch #38: loss=0.051807319555967436
Epoch #39: loss=0.0497392202938001
Epoch #40: loss=0.05966676397453228
Epoch #41: loss=0.06019291327373214
Epoch #42: loss=0.05937555158472531
Epoch #43: loss=0.05448670294678017
Epoch #44: loss=0.04261861309689814
Epoch #45: loss=0.029954506228167616
Epoch #46: loss=0.0469160936064763
Epoch #47: loss=0.030053677481331236
Epoch #48: loss=0.03267028517510793
Epoch #49: loss=0.0359952845789288
Epoch #50: loss=0.04039694795971864
Epoch #51: loss=0.036926520841311
Epoch #52: loss=0.035980101826613486
Epoch #53: loss=0.03222729595065474
Epoch #54: loss=0.0374879781632008
Epoch #55: loss=0.03533306694270609
Epoch #56: loss=0.03959794734662067
Epoch #57: loss=0.03275593572698074
Epoch #58: loss=0.034872348991554385
Epoch #59: loss=0.028236170266180822
Epoch #60: loss=0.02744624458352257
Epoch #61: loss=0.03689745541866103
Epoch #62: loss=0.03519716772429441
Epoch #63: loss=0.02663735972114596
Epoch #64: loss=0.026840173438421055
Epoch #65: loss=0.06715987386494518
Epoch #66: loss=0.03577251015167224
Epoch #67: loss=0.04656341030511189
Epoch #68: loss=0.0362786431209988
Epoch #69: loss=0.02095163902746233
Epoch #70: loss=0.020690745255456958
Epoch #71: loss=0.02313204829083526
Epoch #72: loss=0.021461761872641334
Epoch #73: loss=0.023128968079204427
Epoch #74: loss=0.024129957427615173
Epoch #75: loss=0.03496745714011972
Epoch #76: loss=0.027972712133188207
Epoch #77: loss=0.028422009628521254
Epoch #78: loss=0.02134308363279098
Epoch #79: loss=0.02710871433708434
Epoch #80: loss=0.029773109887203532
Epoch #81: loss=0.035626101867640265
Epoch #82: loss=0.03285096908364547
Epoch #83: loss=0.020335917292826185
Epoch #84: loss=0.02579923853858642
Epoch #85: loss=0.02703905477912535
Epoch #86: loss=0.0225168823325139
Epoch #87: loss=0.01861664787866175
Epoch #88: loss=0.017257423106938192
Epoch #89: loss=0.024793940975190432
Epoch #90: loss=0.01706179719823349
Epoch #91: loss=0.021520694035539172
Epoch #92: loss=0.02410767433578021
Epoch #93: loss=0.03741477942157996
Epoch #94: loss=0.04212940974122755
Epoch #95: loss=0.023213671677911732
Epoch #96: loss=0.025709576830618745
Epoch #97: loss=0.02143712353474805
Epoch #98: loss=0.028721279848035273
Epoch #99: loss=0.025826902322994214
Epoch #100: loss=0.025258997289068386
Epoch #101: loss=0.02922565635383027
Epoch #102: loss=0.01899876741577603
Epoch #103: loss=0.024609789326436156
Epoch #104: loss=0.02693571716240824
Epoch #105: loss=0.030277298671059463
Epoch #106: loss=0.022357164722969374
Epoch #107: loss=0.02347587699306593
Epoch #108: loss=0.016437411219302617
Epoch #109: loss=0.018398183875411034
Epoch #110: loss=0.019686182084882452
Epoch #111: loss=0.02614422936952507
Epoch #112: loss=0.017815474625708764
Epoch #113: loss=0.016713200860548356
Epoch #114: loss=0.02535242988306978
Epoch #115: loss=0.019521758231583166
Epoch #116: loss=0.027565927944650032
Epoch #117: loss=0.03431297496179667
Epoch #118: loss=0.017962005631743026
Epoch #119: loss=0.01655379576642028
Epoch #120: loss=0.018855749131722555
Epoch #121: loss=0.02230269354223397
Epoch #122: loss=0.016626381724817705
Epoch #123: loss=0.01765877178021745
Epoch #124: loss=0.019918103972513687
Epoch #125: loss=0.015921889426033585
Epoch #126: loss=0.018805433083516992
Epoch #127: loss=0.023885543079574734
Epoch #128: loss=0.015413335500418986
Epoch #129: loss=0.014878922674967588
Epoch #130: loss=0.019573220618512507
Epoch #131: loss=0.013301069199582818
Epoch #132: loss=0.018648178769237272
Epoch #133: loss=0.01512869128411993
Epoch #134: loss=0.018982052577145983
Epoch #135: loss=0.018443187093043267
Epoch #136: loss=0.052247172210059346
Epoch #137: loss=0.029000846079665504
Epoch #138: loss=0.019489645211134513
Epoch #139: loss=0.027247565335989613
Epoch #140: loss=0.01341262121999011
Epoch #141: loss=0.013637606271906208
Epoch #142: loss=0.017781288416144018
Epoch #143: loss=0.014892586363696378
Epoch #144: loss=0.01921340726772068
Epoch #145: loss=0.017168690532618137
Epoch #146: loss=0.021484705298016334
Epoch #147: loss=0.014404376389535322
Epoch #148: loss=0.015861157286108457
Epoch #149: loss=0.019956257261737723
Epoch #150: loss=0.022749417519263848
Epoch #151: loss=0.01427563774680132
Epoch #152: loss=0.024899417633662792
Epoch #153: loss=0.010878342121188874
Epoch #154: loss=0.05381918047165677
Epoch #155: loss=0.024620099441141963
Epoch #156: loss=0.01674365302562165
Epoch #157: loss=0.013224051153759332
Epoch #158: loss=0.012841904112408958
Epoch #159: loss=0.015205516955298563
Epoch #160: loss=0.014604728732876836
Epoch #161: loss=0.0122544184555172
Epoch #162: loss=0.01461241940468588
Epoch #163: loss=0.04584118984591803
Epoch #164: loss=0.013303264571602571
Epoch #165: loss=0.01105440549603472
Epoch #166: loss=0.021691730276885608
Epoch #167: loss=0.019161972739854954
Epoch #168: loss=0.020960187783770977
Epoch #169: loss=0.019820555627078126
Epoch #170: loss=0.012323764052675807
Epoch #171: loss=0.013882731183747799
Epoch #172: loss=0.011753808359507062
Epoch #173: loss=0.01296246502809992
Epoch #174: loss=0.01770142400342244
Epoch #175: loss=0.012458186910873636
Epoch #176: loss=0.013712058241211184
Epoch #177: loss=0.012953311015934721
Epoch #178: loss=0.0185409331293968
Epoch #179: loss=0.022146491759156884
Epoch #180: loss=0.014165850564413258
Epoch #181: loss=0.01618590084373415
Epoch #182: loss=0.014196732049737738
Epoch #183: loss=0.013461061452406982
Epoch #184: loss=0.020377386685888194
Epoch #185: loss=0.012761372825360462
Epoch #186: loss=0.009895999474476462
Epoch #187: loss=0.011148366570705549
Epoch #188: loss=0.014718485684357328
Epoch #189: loss=0.01752214493183738
Epoch #190: loss=0.025405556497113038
Epoch #191: loss=0.02158792998804392
Epoch #192: loss=0.019990200666895722
Epoch #193: loss=0.010385629784610651
Epoch #194: loss=0.016395811639305154
Epoch #195: loss=0.01261849167249612
Epoch #196: loss=0.012170682649394459
Epoch #197: loss=0.01381553453313544
Epoch #198: loss=0.022015502663928863
Epoch #199: loss=0.015128180984573514
Epoch #200: loss=0.03801735452063739
Epoch #201: loss=0.027380256442518982
Epoch #202: loss=0.013388947048543456
Epoch #203: loss=0.013094509956235552
Epoch #204: loss=0.014510257842421072
Epoch #205: loss=0.014461781908853668
Epoch #206: loss=0.013470239778390562
Epoch #207: loss=0.021995916088312636
Epoch #208: loss=0.010808118625084729
Epoch #209: loss=0.013403978016409282
Epoch #210: loss=0.014159508831783083
Epoch #211: loss=0.03288330023722366
Epoch #212: loss=0.015067536570291251
Epoch #213: loss=0.014751739488007207
Epoch #214: loss=0.018935116988523824
Epoch #215: loss=0.01468118875939718
Epoch #216: loss=0.018098729629745732
Epoch #217: loss=0.015393913656230761
Epoch #218: loss=0.01093138844765123
Epoch #219: loss=0.015031210487877492
Epoch #220: loss=0.02090226833354554
Epoch #221: loss=0.012869732862630259
Epoch #222: loss=0.015573032651166751
Epoch #223: loss=0.010631701957007028
Epoch #224: loss=0.01226086768557713
Epoch #225: loss=0.012374654399631353
Epoch #226: loss=0.015057087516290939
Epoch #227: loss=0.018269984306423123
Epoch #228: loss=0.025615453389026734
Epoch #229: loss=0.0104157627127229
Epoch #230: loss=0.011832170903710916
Epoch #231: loss=0.014609715709628613
Epoch #232: loss=0.015976242346159655
Epoch #233: loss=0.027514330951229043
Epoch #234: loss=0.013288919996527624
Epoch #235: loss=0.012333792210508725
Epoch #236: loss=0.008759467684415054
Epoch #237: loss=0.014206290438496954
Epoch #238: loss=0.017432044522576864
Epoch #239: loss=0.014394591670811864
Epoch #240: loss=0.012505570713714505
Epoch #241: loss=0.02063581283915507
Epoch #242: loss=0.020676470292598163
Epoch #243: loss=0.011856177841968617
Epoch #244: loss=0.013731455513593512
Epoch #245: loss=0.010571896505688815
Epoch #246: loss=0.015970831551933535
Epoch #247: loss=0.01728985908645371
Epoch #248: loss=0.013957629233681636
Epoch #249: loss=0.01596693472453546

Training time: 1:45:46.096530

Finished.
n2one setting etth2_ettm1_electricity_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_electricity_weather_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_ettm1_electricity_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.73768e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.2906583741431614, 'MAE': 0.3629912831323751}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm1_electricity_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm1_electricity_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.714214779629831
Epoch #1: loss=0.7495785055826996
Epoch #2: loss=0.5109326444802436
Epoch #3: loss=0.42012795440917056
Epoch #4: loss=0.34338585306656805
Epoch #5: loss=0.30500024862007724
Epoch #6: loss=0.29455710180984107
Epoch #7: loss=0.25116143775003447
Epoch #8: loss=0.23575197029268363
Epoch #9: loss=0.21498598210964492
Epoch #10: loss=0.19362011033322352
Epoch #11: loss=0.20204262658738953
Epoch #12: loss=0.16156558979098667
Epoch #13: loss=0.15476906282413933
Epoch #14: loss=0.14753332224161894
Epoch #15: loss=0.13953795129438643
Epoch #16: loss=0.13846511598300693
Epoch #17: loss=0.09732695417183448
Epoch #18: loss=0.1081891766875467
Epoch #19: loss=0.09012015576686398
Epoch #20: loss=0.09973051812317255
Epoch #21: loss=0.0940135981812429
Epoch #22: loss=0.10265791810705442
Epoch #23: loss=0.10622268340279287
Epoch #24: loss=0.08725228313335166
Epoch #25: loss=0.07564318340985636
Epoch #26: loss=0.06769901491508361
Epoch #27: loss=0.062267428580725225
Epoch #28: loss=0.07071687695127442
Epoch #29: loss=0.07133319649995662
Epoch #30: loss=0.0696504696954031
Epoch #31: loss=0.07228138254316636
Epoch #32: loss=0.057583451488455194
Epoch #33: loss=0.060620354813247145
Epoch #34: loss=0.046026300553028456
Epoch #35: loss=0.10591188191519432
Epoch #36: loss=0.056385040994443705
Epoch #37: loss=0.05977200209605977
Epoch #38: loss=0.05258520906697153
Epoch #39: loss=0.04653281838665327
Epoch #40: loss=0.047137401209639586
Epoch #41: loss=0.05474608806726826
Epoch #42: loss=0.05582774250757389
Epoch #43: loss=0.04972574336089258
Epoch #44: loss=0.049194151005554694
Epoch #45: loss=0.04437532499284948
Epoch #46: loss=0.05019460936809651
Epoch #47: loss=0.041680667484957475
Epoch #48: loss=0.04284305148523151
Epoch #49: loss=0.030696766213809144
Epoch #50: loss=0.05219400228505756
Epoch #51: loss=0.03761332303752602
Epoch #52: loss=0.04558067694031271
Epoch #53: loss=0.04280961744161189
Epoch #54: loss=0.05003617631717013
Epoch #55: loss=0.05463347533551348
Epoch #56: loss=0.03137091508434457
Epoch #57: loss=0.03511767204775762
Epoch #58: loss=0.04055867573214153
Epoch #59: loss=0.03238928370729293
Epoch #60: loss=0.03186956558595291
Epoch #61: loss=0.027134888481700346
Epoch #62: loss=0.0389742216730077
Epoch #63: loss=0.03271796865327021
Epoch #64: loss=0.043534461509836274
Epoch #65: loss=0.0367670582844916
Epoch #66: loss=0.03233923120823386
Epoch #67: loss=0.043812790107899895
Epoch #68: loss=0.03463496151615084
Epoch #69: loss=0.0328135533695799
Epoch #70: loss=0.03840164749269838
Epoch #71: loss=0.04988686238302814
Epoch #72: loss=0.03567499478793131
Epoch #73: loss=0.03211742084270735
Epoch #74: loss=0.032230485696681056
Epoch #75: loss=0.04247433233064108
Epoch #76: loss=0.032295188348893326
Epoch #77: loss=0.03227789314384559
Epoch #78: loss=0.028338430559407567
Epoch #79: loss=0.02452641250384483
Epoch #80: loss=0.039094910180257895
Epoch #81: loss=0.02692007588696336
Epoch #82: loss=0.033741012502458985
Epoch #83: loss=0.025672565170722108
Epoch #84: loss=0.031112565414413745
Epoch #85: loss=0.03382797805127427
Epoch #86: loss=0.030702744306988414
Epoch #87: loss=0.05116840691194314
Epoch #88: loss=0.02933978102195428
Epoch #89: loss=0.02824046552316782
Epoch #90: loss=0.036886093877014366
Epoch #91: loss=0.03490278118334292
Epoch #92: loss=0.03461289267566978
Epoch #93: loss=0.025005255479591038
Epoch #94: loss=0.02394716909657815
Epoch #95: loss=0.03805793075445202
Epoch #96: loss=0.025076690941488084
Epoch #97: loss=0.02603729006479379
Epoch #98: loss=0.029459145044913294
Epoch #99: loss=0.023607885180026433
Epoch #100: loss=0.018950305895963988
Epoch #101: loss=0.02308212577245233
Epoch #102: loss=0.03753103872040496
Epoch #103: loss=0.023084432509343975
Epoch #104: loss=0.028357180395540686
Epoch #105: loss=0.039147226076495296
Epoch #106: loss=0.02350496280715621
Epoch #107: loss=0.016546727913486842
Epoch #108: loss=0.021537468560316443
Epoch #109: loss=0.02237931768338113
Epoch #110: loss=0.028070064861413297
Epoch #111: loss=0.028640377453343153
Epoch #112: loss=0.023251841303030894
Epoch #113: loss=0.019721658374833733
Epoch #114: loss=0.023103131016049404
Epoch #115: loss=0.022740458939606942
Epoch #116: loss=0.02481637949960022
Epoch #117: loss=0.04184437672854522
Epoch #118: loss=0.04618392168273827
Epoch #119: loss=0.03374320304813669
Epoch #120: loss=0.02394636072586116
Epoch #121: loss=0.023755351894720316
Epoch #122: loss=0.015537197386774823
Epoch #123: loss=0.017993533336329314
Epoch #124: loss=0.02298147383401632
Epoch #125: loss=0.02400675055541377
Epoch #126: loss=0.02585973868868515
Epoch #127: loss=0.022017256990685706
Epoch #128: loss=0.01703597246471293
Epoch #129: loss=0.022300894500154957
Epoch #130: loss=0.03077864018235334
Epoch #131: loss=0.02041393477937357
Epoch #132: loss=0.02640024280968667
Epoch #133: loss=0.03325182411072223
Epoch #134: loss=0.02917647178174783
Epoch #135: loss=0.01731655145077332
Epoch #136: loss=0.021685269244903597
Epoch #137: loss=0.02671452826918948
Epoch #138: loss=0.021792188612375172
Epoch #139: loss=0.017906647016360057
Epoch #140: loss=0.020580042512739823
Epoch #141: loss=0.024386101826234997
Epoch #142: loss=0.02479647642208843
Epoch #143: loss=0.020064537748909133
Epoch #144: loss=0.017796847072526576
Epoch #145: loss=0.016130583382765858
Epoch #146: loss=0.019633720740300176
Epoch #147: loss=0.023373963087542193
Epoch #148: loss=0.02392245217874614
Epoch #149: loss=0.01670413953268911
Epoch #150: loss=0.01848416033292173
Epoch #151: loss=0.01595675358743345
Epoch #152: loss=0.021975647680881106
Epoch #153: loss=0.02129906652745541
Epoch #154: loss=0.01944126751624794
Epoch #155: loss=0.02597213437665329
Epoch #156: loss=0.019135169030847537
Epoch #157: loss=0.01744660396603277
Epoch #158: loss=0.017299042855790665
Epoch #159: loss=0.024666550699238978
Epoch #160: loss=0.01758681896937104
Epoch #161: loss=0.018949617403599645
Epoch #162: loss=0.03327088222511164
Epoch #163: loss=0.021928847218549645
Epoch #164: loss=0.016131765756323954
Epoch #165: loss=0.02281919211687343
Epoch #166: loss=0.019419682451546655
Epoch #167: loss=0.013941687619332385
Epoch #168: loss=0.02038261240015413
Epoch #169: loss=0.023538804438095324
Epoch #170: loss=0.016423956351824406
Epoch #171: loss=0.018004606743289495
Epoch #172: loss=0.021994828544952973
Epoch #173: loss=0.02092967736226123
Epoch #174: loss=0.017070741189867848
Epoch #175: loss=0.015122020276939705
Epoch #176: loss=0.02332136796798117
Epoch #177: loss=0.022054881108750292
Epoch #178: loss=0.015438260890842718
Epoch #179: loss=0.01754356386860959
Epoch #180: loss=0.01873945633519135
Epoch #181: loss=0.03815038548916664
Epoch #182: loss=0.022808860956727437
Epoch #183: loss=0.027883054141219575
Epoch #184: loss=0.020605707013884273
Epoch #185: loss=0.0229456899680938
Epoch #186: loss=0.019502065521235488
Epoch #187: loss=0.016213297639115946
Epoch #188: loss=0.019288051138888315
Epoch #189: loss=0.01684343861130815
Epoch #190: loss=0.015552490731729436
Epoch #191: loss=0.015538140701301804
Epoch #192: loss=0.01411069352043892
Epoch #193: loss=0.02002261183425913
Epoch #194: loss=0.02703188966841622
Epoch #195: loss=0.019139569255748834
Epoch #196: loss=0.014974175310580956
Epoch #197: loss=0.016472374673990497
Epoch #198: loss=0.015825173224427173
Epoch #199: loss=0.017033459993263153
Epoch #200: loss=0.018178535025313185
Epoch #201: loss=0.014205619646001456
Epoch #202: loss=0.016776857497230957
Epoch #203: loss=0.02554858233112042
Epoch #204: loss=0.03156539353861417
Epoch #205: loss=0.019562786572088785
Epoch #206: loss=0.03147586650984705
Epoch #207: loss=0.024940815766983444
Epoch #208: loss=0.024362087074126404
Epoch #209: loss=0.017826154965455095
Epoch #210: loss=0.014161649584650767
Epoch #211: loss=0.028399027294549094
Epoch #212: loss=0.02570866371044669
Epoch #213: loss=0.02606180818534727
Epoch #214: loss=0.014094248819144803
Epoch #215: loss=0.014936625924778657
Epoch #216: loss=0.022327619873662278
Epoch #217: loss=0.020286184639226434
Epoch #218: loss=0.015017553913153396
Epoch #219: loss=0.016465085740932545
Epoch #220: loss=0.011511208549338481
Epoch #221: loss=0.014735802044046597
Epoch #222: loss=0.02347949599717698
Epoch #223: loss=0.014032476627595335
Epoch #224: loss=0.017053652115760678
Epoch #225: loss=0.02743048190393536
Epoch #226: loss=0.0172935582038823
Epoch #227: loss=0.014518534329012628
Epoch #228: loss=0.013229875772002473
Epoch #229: loss=0.033318748583236135
Epoch #230: loss=0.018722239989614226
Epoch #231: loss=0.013331690087903731
Epoch #232: loss=0.011602324035816479
Epoch #233: loss=0.021735035736007772
Epoch #234: loss=0.025713111846878862
Epoch #235: loss=0.017668892142815133
Epoch #236: loss=0.022630495877107148
Epoch #237: loss=0.022700657006232364
Epoch #238: loss=0.01636401474139028
Epoch #239: loss=0.012432021465318906
Epoch #240: loss=0.012266941945120876
Epoch #241: loss=0.011474001822055126
Epoch #242: loss=0.011438484197554262
Epoch #243: loss=0.011550122191284056
Epoch #244: loss=0.01492111780898785
Epoch #245: loss=0.013509470468550727
Epoch #246: loss=0.01787862962283602
Epoch #247: loss=0.01728897637225317
Epoch #248: loss=0.019184032309148193
Epoch #249: loss=0.020061349669526402

Training time: 1:40:14.427153

Finished.
n2one setting etth2_ettm1_electricity_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_electricity_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_ettm1_electricity_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.59598e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.22472e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.604809637331298, 'MAE': 0.5734527837531269}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm1_traffic_weather', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm1_traffic_weather_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.0597545734830776
Epoch #1: loss=0.47037970921061684
Epoch #2: loss=0.31730615467688367
Epoch #3: loss=0.24546971226370098
Epoch #4: loss=0.19826292587037117
Epoch #5: loss=0.1712629667156382
Epoch #6: loss=0.14705831603975617
Epoch #7: loss=0.13908987417076993
Epoch #8: loss=0.11586706689713115
Epoch #9: loss=0.10160087428526504
Epoch #10: loss=0.08199241732413702
Epoch #11: loss=0.08133634382439468
Epoch #12: loss=0.07388211113594012
Epoch #13: loss=0.06569699394140417
Epoch #14: loss=0.07065630285326334
Epoch #15: loss=0.06475947069047353
Epoch #16: loss=0.04663214277991075
Epoch #17: loss=0.051831027577686685
Epoch #18: loss=0.050469827583310485
Epoch #19: loss=0.05152089273784244
Epoch #20: loss=0.04856551825516049
Epoch #21: loss=0.03866718205670614
Epoch #22: loss=0.03900718256904667
Epoch #23: loss=0.04324390227077878
Epoch #24: loss=0.06745888616053992
Epoch #25: loss=0.04025229280526702
Epoch #26: loss=0.02710102966338474
Epoch #27: loss=0.029203218825597822
Epoch #28: loss=0.03432656285172086
Epoch #29: loss=0.04682537394657497
Epoch #30: loss=0.043421450741902595
Epoch #31: loss=0.032676014267977234
Epoch #32: loss=0.0313413904365111
Epoch #33: loss=0.038898405671648054
Epoch #34: loss=0.034559203838368274
Epoch #35: loss=0.0218867445947956
Epoch #36: loss=0.03287504008412464
Epoch #37: loss=0.02927572725052384
Epoch #38: loss=0.03144839978979892
Epoch #39: loss=0.030352849655727616
Epoch #40: loss=0.03062419684394494
Epoch #41: loss=0.02956889401265537
Epoch #42: loss=0.02785074579820888
Epoch #43: loss=0.033008260783615004
Epoch #44: loss=0.024778537806349643
Epoch #45: loss=0.03784671482067528
Epoch #46: loss=0.02490795742955252
Epoch #47: loss=0.01777770962575389
Epoch #48: loss=0.02942802268620087
Epoch #49: loss=0.0256323075057141
Epoch #50: loss=0.025327375933613266
Epoch #51: loss=0.02426216779001752
Epoch #52: loss=0.02472145939513087
Epoch #53: loss=0.029273188826124334
Epoch #54: loss=0.028337761751534397
Epoch #55: loss=0.023734615569333928
Epoch #56: loss=0.028478810241678216
Epoch #57: loss=0.02403223540608989
Epoch #58: loss=0.024822368035730277
Epoch #59: loss=0.017256428048021837
Epoch #60: loss=0.025626224897471392
Epoch #61: loss=0.02070756834468066
Epoch #62: loss=0.01873595017906269
Epoch #63: loss=0.028121643700315946
Epoch #64: loss=0.016373426665378624
Epoch #65: loss=0.024634241048417774
Epoch #66: loss=0.01752128556335271
Epoch #67: loss=0.01788962330897498
Epoch #68: loss=0.017591971467546173
Epoch #69: loss=0.03045947799862827
Epoch #70: loss=0.016199135764555443
Epoch #71: loss=0.0183282631652293
Epoch #72: loss=0.01835039042191586
Epoch #73: loss=0.023068874855979374
Epoch #74: loss=0.01992587031072898
Epoch #75: loss=0.019855947889568525
Epoch #76: loss=0.015743421065499266
Epoch #77: loss=0.023149965863372146
Epoch #78: loss=0.02777052092167783
Epoch #79: loss=0.0151412991965426
Epoch #80: loss=0.013791397113453754
Epoch #81: loss=0.015427702823434093
Epoch #82: loss=0.031423609064844135
Epoch #83: loss=0.02206602958133151
Epoch #84: loss=0.012386503422383021
Epoch #85: loss=0.01609309443441491
Epoch #86: loss=0.016814306121730457
Epoch #87: loss=0.02111731154212811
Epoch #88: loss=0.022307807564410066
Epoch #89: loss=0.01465374544098671
Epoch #90: loss=0.017072186653524644
Epoch #91: loss=0.03249938704537484
Epoch #92: loss=0.01579618232906025
Epoch #93: loss=0.015955641826989424
Epoch #94: loss=0.021169837381865234
Epoch #95: loss=0.019343082800067402
Epoch #96: loss=0.022508448362132026
Epoch #97: loss=0.012990702452503245
Epoch #98: loss=0.023799070441306705
Epoch #99: loss=0.015092610451765461
Epoch #100: loss=0.01686192980646742
Epoch #101: loss=0.015213271661324398
Epoch #102: loss=0.018117615432270584
Epoch #103: loss=0.017029066742156276
Epoch #104: loss=0.017564979625611914
Epoch #105: loss=0.014758682449409434
Epoch #106: loss=0.016996380096536836
Epoch #107: loss=0.026817873175752967
Epoch #108: loss=0.018550985340854188
Epoch #109: loss=0.013139199395002294
Epoch #110: loss=0.01305086876188737
Epoch #111: loss=0.014398772143724141
Epoch #112: loss=0.014619002661994267
Epoch #113: loss=0.018066582260451665
Epoch #114: loss=0.016968911864698934
Epoch #115: loss=0.012685631296857493
Epoch #116: loss=0.013183811155195907
Epoch #117: loss=0.017604183949358972
Epoch #118: loss=0.01486285788672164
Epoch #119: loss=0.01984940474095947
Epoch #120: loss=0.013356947444440236
Epoch #121: loss=0.014191411248067493
Epoch #122: loss=0.023393436023237176
Epoch #123: loss=0.014902690218943932
Epoch #124: loss=0.017539274169096907
Epoch #125: loss=0.01644190586582967
Epoch #126: loss=0.013170057857266748
Epoch #127: loss=0.0171235023876169
Epoch #128: loss=0.01674843282816201
Epoch #129: loss=0.016217100541618762
Epoch #130: loss=0.016781095003756227
Epoch #131: loss=0.011121005125685078
Epoch #132: loss=0.017486512421724894
Epoch #133: loss=0.01461700139389015
Epoch #134: loss=0.016840998596171528
Epoch #135: loss=0.013328458285244453
Epoch #136: loss=0.016114912524274688
Epoch #137: loss=0.010447408358673466
Epoch #138: loss=0.021965401543080874
Epoch #139: loss=0.013761436459129094
Epoch #140: loss=0.022163811746641313
Epoch #141: loss=0.01990276433083652
Epoch #142: loss=0.009707761305782605
Epoch #143: loss=0.011121293001389466
Epoch #144: loss=0.01764911075786778
Epoch #145: loss=0.01067212159428915
Epoch #146: loss=0.013726667266756155
Epoch #147: loss=0.017688732491617263
Epoch #148: loss=0.017573146726565396
Epoch #149: loss=0.01716052038802855
Epoch #150: loss=0.016912252005367237
Epoch #151: loss=0.013980586883287145
Epoch #152: loss=0.021076574765295345
Epoch #153: loss=0.013148625968282406
Epoch #154: loss=0.013027940857636375
Epoch #155: loss=0.012325991124478035
Epoch #156: loss=0.009978090681643334
Epoch #157: loss=0.015081598468056893
Epoch #158: loss=0.011062566664883063
Epoch #159: loss=0.015595620290736542
Epoch #160: loss=0.01255945581599076
Epoch #161: loss=0.016900862879338414
Epoch #162: loss=0.01304405185311239
Epoch #163: loss=0.0254364026132113
Epoch #164: loss=0.017686538869131123
Epoch #165: loss=0.012793447873079376
Epoch #166: loss=0.021245440191898453
Epoch #167: loss=0.011564812666459512
Epoch #168: loss=0.01596602744411417
Epoch #169: loss=0.014859478417677326
Epoch #170: loss=0.016727366167707595
Epoch #171: loss=0.01632428266231133
Epoch #172: loss=0.014505752692957384
Epoch #173: loss=0.010409615463013767
Epoch #174: loss=0.015501685680984211
Epoch #175: loss=0.012812621050089481
Epoch #176: loss=0.011355108146050227
Epoch #177: loss=0.018683945780818372
Epoch #178: loss=0.017103085303456816
Epoch #179: loss=0.010520753807454548
Epoch #180: loss=0.012937819532264706
Epoch #181: loss=0.012875860888441813
Epoch #182: loss=0.023537889604653833
Epoch #183: loss=0.008577202076664674
Epoch #184: loss=0.01606671922696522
Epoch #185: loss=0.01312057796581602
Epoch #186: loss=0.012256390285642486
Epoch #187: loss=0.009951260327556513
Epoch #188: loss=0.020418814021287583
Epoch #189: loss=0.018104658476177246
Epoch #190: loss=0.013722196246142883
Epoch #191: loss=0.014056541996729965
Epoch #192: loss=0.011303964586894179
Epoch #193: loss=0.012748963968687235
Epoch #194: loss=0.01015469058519924
Epoch #195: loss=0.014259926266564138
Epoch #196: loss=0.01131927584630818
Epoch #197: loss=0.009027290917098677
Epoch #198: loss=0.013081706611918032
Epoch #199: loss=0.013913145075830611
Epoch #200: loss=0.010727688885142455
Epoch #201: loss=0.01995432018352313
Epoch #202: loss=0.012897540401585377
Epoch #203: loss=0.012465948607681614
Epoch #204: loss=0.009402310728646966
Epoch #205: loss=0.012653578825791729
Epoch #206: loss=0.01213935529472662
Epoch #207: loss=0.01284175200962074
Epoch #208: loss=0.019365202510855613
Epoch #209: loss=0.011289338640740556
Epoch #210: loss=0.01068839739629252
Epoch #211: loss=0.009633088518971286
Epoch #212: loss=0.01679005016102872
Epoch #213: loss=0.011763698833401698
Epoch #214: loss=0.007012860800019577
Epoch #215: loss=0.012924954225707525
Epoch #216: loss=0.014121280491730366
Epoch #217: loss=0.015506552204045891
Epoch #218: loss=0.012075985198743871
Epoch #219: loss=0.01176066080983777
Epoch #220: loss=0.01111527706193626
Epoch #221: loss=0.010072153202268747
Epoch #222: loss=0.018813593298032064
Epoch #223: loss=0.009265554936068307
Epoch #224: loss=0.010510108094256936
Epoch #225: loss=0.011730323054612008
Epoch #226: loss=0.013481405590700445
Epoch #227: loss=0.00810079824756155
Epoch #228: loss=0.013259099026688731
Epoch #229: loss=0.007779205915421477
Epoch #230: loss=0.012806546038075014
Epoch #231: loss=0.01731708612637111
Epoch #232: loss=0.009520558164564602
Epoch #233: loss=0.011582606564221054
Epoch #234: loss=0.010839601440977606
Epoch #235: loss=0.009750921510860815
Epoch #236: loss=0.010130890461164048
Epoch #237: loss=0.015293318141043899
Epoch #238: loss=0.010744112567693687
Epoch #239: loss=0.011712463060365018
Epoch #240: loss=0.01066848606171362
Epoch #241: loss=0.01171829145994779
Epoch #242: loss=0.011038664105481537
Epoch #243: loss=0.015966060897682342
Epoch #244: loss=0.010503518067370477
Epoch #245: loss=0.008629535623972827
Epoch #246: loss=0.017227430851558517
Epoch #247: loss=0.007994346053779761
Epoch #248: loss=0.014728634710995189
Epoch #249: loss=0.01052577475823537

Training time: 3:44:21.024145

Finished.
n2one setting etth2_ettm1_traffic_weather -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_traffic_weather_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_ettm1_traffic_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.02318e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.15812e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.46537e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.02318e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3978376152085042, 'MAE': 0.44730746876482397}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm1_traffic_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_traffic_weather_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_ettm1_traffic_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.64591e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.42401300772662054, 'MAE': 0.4323839457793218}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm1_traffic_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm1_traffic_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.0242584367861618
Epoch #1: loss=0.3815758173261677
Epoch #2: loss=0.28068611691999545
Epoch #3: loss=0.22329239594238298
Epoch #4: loss=0.16991148008923004
Epoch #5: loss=0.15291491864450477
Epoch #6: loss=0.12302846739882486
Epoch #7: loss=0.10303574192404814
Epoch #8: loss=0.08975343414276066
Epoch #9: loss=0.1018522496750528
Epoch #10: loss=0.0770753646523247
Epoch #11: loss=0.07338446382693276
Epoch #12: loss=0.0758895724587067
Epoch #13: loss=0.06198948591859457
Epoch #14: loss=0.06336576918345616
Epoch #15: loss=0.07320005108333856
Epoch #16: loss=0.054283050119641935
Epoch #17: loss=0.05068034985153055
Epoch #18: loss=0.04973008933577787
Epoch #19: loss=0.04715704596900331
Epoch #20: loss=0.04436817615049648
Epoch #21: loss=0.04775181178843628
Epoch #22: loss=0.04410020074545435
Epoch #23: loss=0.04306042001547023
Epoch #24: loss=0.039738384153073035
Epoch #25: loss=0.03578111947501531
Epoch #26: loss=0.04593221998463074
Epoch #27: loss=0.03342656989693054
Epoch #28: loss=0.04319381248048582
Epoch #29: loss=0.036470192855172626
Epoch #30: loss=0.030048088645950582
Epoch #31: loss=0.03403394860940459
Epoch #32: loss=0.04196372870730786
Epoch #33: loss=0.03393860877914195
Epoch #34: loss=0.03231162583255649
Epoch #35: loss=0.0341588659303762
Epoch #36: loss=0.02706968104512025
Epoch #37: loss=0.035263479279819876
Epoch #38: loss=0.029046471969097085
Epoch #39: loss=0.03457402163647957
Epoch #40: loss=0.03356822251868204
Epoch #41: loss=0.03752203771688761
Epoch #42: loss=0.03306741273027492
Epoch #43: loss=0.026569849530943913
Epoch #44: loss=0.03110342015756655
Epoch #45: loss=0.02862212857793123
Epoch #46: loss=0.026760465501275896
Epoch #47: loss=0.03179579172904817
Epoch #48: loss=0.03138691180159898
Epoch #49: loss=0.025000500529393583
Epoch #50: loss=0.02526104378003757
Epoch #51: loss=0.02841367809732391
Epoch #52: loss=0.02188473136420152
Epoch #53: loss=0.026984268361293536
Epoch #54: loss=0.03240592361727797
Epoch #55: loss=0.028801333720374724
Epoch #56: loss=0.02546277794035714
Epoch #57: loss=0.028126426715168344
Epoch #58: loss=0.026830839021902253
Epoch #59: loss=0.02853175025541589
Epoch #60: loss=0.020524849604158703
Epoch #61: loss=0.022181962663478213
Epoch #62: loss=0.03465563335503412
Epoch #63: loss=0.036725219372234635
Epoch #64: loss=0.02370920672560182
Epoch #65: loss=0.026092821944346086
Epoch #66: loss=0.02680937494746481
Epoch #67: loss=0.02181007468653161
Epoch #68: loss=0.026125923103094677
Epoch #69: loss=0.031471815599771774
Epoch #70: loss=0.018261836273260078
Epoch #71: loss=0.0187073266292295
Epoch #72: loss=0.02247741909810134
Epoch #73: loss=0.025458850785628432
Epoch #74: loss=0.02502212101836932
Epoch #75: loss=0.020561113846286404
Epoch #76: loss=0.02158108018029288
Epoch #77: loss=0.019551664523582125
Epoch #78: loss=0.01941012194046388
Epoch #79: loss=0.020350726335039385
Epoch #80: loss=0.028374146274841593
Epoch #81: loss=0.02047276509813503
Epoch #82: loss=0.019765453840247228
Epoch #83: loss=0.02123097227388473
Epoch #84: loss=0.020938090058956044
Epoch #85: loss=0.01823858647991516
Epoch #86: loss=0.019474654151242436
Epoch #87: loss=0.02228371720385595
Epoch #88: loss=0.018766265428771352
Epoch #89: loss=0.024561474555190903
Epoch #90: loss=0.017886194640989228
Epoch #91: loss=0.01826941395644623
Epoch #92: loss=0.01726212246380332
Epoch #93: loss=0.022126237028026702
Epoch #94: loss=0.021716553347105545
Epoch #95: loss=0.022116453680700122
Epoch #96: loss=0.015406734322479335
Epoch #97: loss=0.016118911138684845
Epoch #98: loss=0.023454974507462017
Epoch #99: loss=0.021917644722503477
Epoch #100: loss=0.02030437530301824
Epoch #101: loss=0.01753696018702383
Epoch #102: loss=0.019683277324958483
Epoch #103: loss=0.018013536693418958
Epoch #104: loss=0.02277680164043632
Epoch #105: loss=0.01679995680712415
Epoch #106: loss=0.018917918511310295
Epoch #107: loss=0.01714597038887593
Epoch #108: loss=0.017735689967676164
Epoch #109: loss=0.020799377590912365
Epoch #110: loss=0.01361168137438719
Epoch #111: loss=0.01886486220138141
Epoch #112: loss=0.014596133133546484
Epoch #113: loss=0.016212814851839154
Epoch #114: loss=0.04548565329893897
Epoch #115: loss=0.018569259154770274
Epoch #116: loss=0.017281571357752993
Epoch #117: loss=0.018618424355195572
Epoch #118: loss=0.02177560899544587
Epoch #119: loss=0.01658181077112425
Epoch #120: loss=0.015622421607429158
Epoch #121: loss=0.016133146340229082
Epoch #122: loss=0.01626132980858496
Epoch #123: loss=0.014960365612251236
Epoch #124: loss=0.016201130488453754
Epoch #125: loss=0.017250279573131633
Epoch #126: loss=0.015068435333051713
Epoch #127: loss=0.019867494884598633
Epoch #128: loss=0.01906010390552068
Epoch #129: loss=0.017088116472141254
Epoch #130: loss=0.01583289449423843
Epoch #131: loss=0.01700016843722813
Epoch #132: loss=0.014105103877817464
Epoch #133: loss=0.014741881624571318
Epoch #134: loss=0.011336470184343509
Epoch #135: loss=0.016513096532435156
Epoch #136: loss=0.0164490334086827
Epoch #137: loss=0.021149387413921382
Epoch #138: loss=0.012835335385038438
Epoch #139: loss=0.011438329859588479
Epoch #140: loss=0.014732747451583785
Epoch #141: loss=0.02179058916075732
Epoch #142: loss=0.01379407765020628
Epoch #143: loss=0.016348549003154616
Epoch #144: loss=0.012981203374242346
Epoch #145: loss=0.020136317480907426
Epoch #146: loss=0.013478615254719337
Epoch #147: loss=0.016770549116126285
Epoch #148: loss=0.01464163126591892
Epoch #149: loss=0.015324346611246379
Epoch #150: loss=0.0145401456195343
Epoch #151: loss=0.013026923363565755
Epoch #152: loss=0.020282561613704595
Epoch #153: loss=0.017486884260842425
Epoch #154: loss=0.018451959326174237
Epoch #155: loss=0.01619214656769858
Epoch #156: loss=0.016306979571684654
Epoch #157: loss=0.01658032486526068
Epoch #158: loss=0.014005141208300457
Epoch #159: loss=0.01476110046351997
Epoch #160: loss=0.015949627034478088
Epoch #161: loss=0.01424630494056236
Epoch #162: loss=0.013676864540061902
Epoch #163: loss=0.023298909100917586
Epoch #164: loss=0.013587789074098272
Epoch #165: loss=0.014357360267813993
Epoch #166: loss=0.021061189881210512
Epoch #167: loss=0.010325587221191486
Epoch #168: loss=0.01603487178058335
Epoch #169: loss=0.013434730256654098
Epoch #170: loss=0.014013921141422298
Epoch #171: loss=0.012770565206976555
Epoch #172: loss=0.014513624010244195
Epoch #173: loss=0.014092657791020879
Epoch #174: loss=0.025385952996051248
Epoch #175: loss=0.012921160206239726
Epoch #176: loss=0.015060757159173247
Epoch #177: loss=0.01667222481570731
Epoch #178: loss=0.010386880605847592
Epoch #179: loss=0.013628104303246768
Epoch #180: loss=0.010645860932879612
Epoch #181: loss=0.01644619271443131
Epoch #182: loss=0.015019570017594143
Epoch #183: loss=0.013645041735684458
Epoch #184: loss=0.01495135402171752
Epoch #185: loss=0.012159361282740705
Epoch #186: loss=0.017074129538561286
Epoch #187: loss=0.015513342875114963
Epoch #188: loss=0.013699292073159758
Epoch #189: loss=0.011585146568527839
Epoch #190: loss=0.016338608007523313
Epoch #191: loss=0.01662488699373359
Epoch #192: loss=0.011319118332557828
Epoch #193: loss=0.014214879749406382
Epoch #194: loss=0.02020444803821266
Epoch #195: loss=0.010750225797187546
Epoch #196: loss=0.011400271919482547
Epoch #197: loss=0.010395479758428977
Epoch #198: loss=0.013307143001470281
Epoch #199: loss=0.011218570842928629
Epoch #200: loss=0.016109817731384292
Epoch #201: loss=0.010185231766520595
Epoch #202: loss=0.017444046035175357
Epoch #203: loss=0.01487845705927251
Epoch #204: loss=0.012377749869014847
Epoch #205: loss=0.01980255443361186
Epoch #206: loss=0.011648410019047374
Epoch #207: loss=0.013345184725334842
Epoch #208: loss=0.018215753126037067
Epoch #209: loss=0.0143644278779886
Epoch #210: loss=0.01218319297839952
Epoch #211: loss=0.01390862446642787
Epoch #212: loss=0.016265049115850364
Epoch #213: loss=0.012531696159770421
Epoch #214: loss=0.009409477248138669
Epoch #215: loss=0.013857658115346174
Epoch #216: loss=0.015872380047496974
Epoch #217: loss=0.01143274615347141
Epoch #218: loss=0.011575690775800042
Epoch #219: loss=0.016532500934461184
Epoch #220: loss=0.012564223704274654
Epoch #221: loss=0.01430195077053721
Epoch #222: loss=0.0098306583742571
Epoch #223: loss=0.012121497523342416
Epoch #224: loss=0.014989699939375184
Epoch #225: loss=0.012415023815756777
Epoch #226: loss=0.016641545272176626
Epoch #227: loss=0.012891753126061778
Epoch #228: loss=0.011994502335911166
Epoch #229: loss=0.011284580440956602
Epoch #230: loss=0.011731575052082818
Epoch #231: loss=0.010605707532778143
Epoch #232: loss=0.015613826488137222
Epoch #233: loss=0.01669011517715098
Epoch #234: loss=0.011984008093276242
Epoch #235: loss=0.016819427012845292
Epoch #236: loss=0.013645061438420508
Epoch #237: loss=0.011065209716098826
Epoch #238: loss=0.016493202631806467
Epoch #239: loss=0.01832782773384974
Epoch #240: loss=0.011603172657258026
Epoch #241: loss=0.01285432887321017
Epoch #242: loss=0.013265973219293644
Epoch #243: loss=0.011657063029872973
Epoch #244: loss=0.010114603166535695
Epoch #245: loss=0.010204648240277992
Epoch #246: loss=0.012218697251752543
Epoch #247: loss=0.016018949456672323
Epoch #248: loss=0.011310528831296603
Epoch #249: loss=0.01058171703074107

Training time: 3:29:09.091210

Finished.
n2one setting etth2_ettm1_traffic_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_traffic_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_ettm1_traffic_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.03448e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.27896e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.30506e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.03448e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.425662350867031, 'MAE': 0.46575591571273517}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm1_traffic_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_traffic_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_ettm1_traffic_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.93858e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.84615e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.41248024557758317, 'MAE': 0.47200753834520437}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm1_weather_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm1_weather_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=5.810524631005067
Epoch #1: loss=2.784141345666005
Epoch #2: loss=2.245073433105762
Epoch #3: loss=2.153070309987435
Epoch #4: loss=1.9809748415763562
Epoch #5: loss=1.9779879978069892
Epoch #6: loss=1.873363957955287
Epoch #7: loss=1.7637138664722443
Epoch #8: loss=1.6327527050788586
Epoch #9: loss=1.5072003373732934
Epoch #10: loss=1.4913550867484167
Epoch #11: loss=1.3247198175925474
Epoch #12: loss=1.2497235066615617
Epoch #13: loss=1.1999503351174867
Epoch #14: loss=1.2433010225112622
Epoch #15: loss=1.076083059494312
Epoch #16: loss=1.0521923097280355
Epoch #17: loss=1.0364635552351291
Epoch #18: loss=1.024935626066648
Epoch #19: loss=0.978367173900971
Epoch #20: loss=0.9121414354214301
Epoch #21: loss=0.9635762274265289
Epoch #22: loss=0.9173216040317829
Epoch #23: loss=0.9732327793653195
Epoch #24: loss=0.9467054525246987
Epoch #25: loss=0.8077691953915817
Epoch #26: loss=0.7859097982828434
Epoch #27: loss=0.8621611033494656
Epoch #28: loss=0.7688410373834463
Epoch #29: loss=0.7536865988603005
Epoch #30: loss=0.7249016463756561
Epoch #31: loss=0.696748035458418
Epoch #32: loss=0.6470187117273991
Epoch #33: loss=0.7216184357037911
Epoch #34: loss=0.7132947616852247
Epoch #35: loss=0.6448036139974227
Epoch #36: loss=0.6908634666066903
Epoch #37: loss=0.6733447158565888
Epoch #38: loss=0.6288557081268384
Epoch #39: loss=0.6478888633159491
Epoch #40: loss=0.6368183333140153
Epoch #41: loss=0.6573102256426444
Epoch #42: loss=0.645045841542574
Epoch #43: loss=0.5560066304527796
Epoch #44: loss=0.5120961746344199
Epoch #45: loss=0.6132028561372024
Epoch #46: loss=0.5263286215754656
Epoch #47: loss=0.5056847219283764
Epoch #48: loss=0.5071275274340923
Epoch #49: loss=0.5286048404299296
Epoch #50: loss=0.49688064478910887
Epoch #51: loss=0.5336792744123019
Epoch #52: loss=0.508184287410516
Epoch #53: loss=0.4851421037545571
Epoch #54: loss=0.5047561775606412
Epoch #55: loss=0.45551431293670946
Epoch #56: loss=0.5131178366450163
Epoch #57: loss=0.514791487214657
Epoch #58: loss=0.44663444791848844
Epoch #59: loss=0.47138409230571526
Epoch #60: loss=0.47630342096090317
Epoch #61: loss=0.4314168445192851
Epoch #62: loss=0.3879532272425982
Epoch #63: loss=0.40928037092089653
Epoch #64: loss=0.3953688233517684
Epoch #65: loss=0.49238148073737437
Epoch #66: loss=0.39244564880545324
Epoch #67: loss=0.41069660880244696
Epoch #68: loss=0.39656331218205965
Epoch #69: loss=0.4249142078826061
Epoch #70: loss=0.3891651424077841
Epoch #71: loss=0.362925310834096
Epoch #72: loss=0.3378062675205561
Epoch #73: loss=0.3158486233307765
Epoch #74: loss=0.33936616205252135
Epoch #75: loss=0.3140854189315668
Epoch #76: loss=0.2980494863138749
Epoch #77: loss=0.2954079915697758
Epoch #78: loss=0.33761242404580116
Epoch #79: loss=0.31552464772875494
Epoch #80: loss=0.2857414885209157
Epoch #81: loss=0.32051632152153897
Epoch #82: loss=0.3355292637760823
Epoch #83: loss=0.32339853134292823
Epoch #84: loss=0.27987003097167384
Epoch #85: loss=0.3129673058596941
Epoch #86: loss=0.32226989475580364
Epoch #87: loss=0.2442831713706255
Epoch #88: loss=0.38003914115520626
Epoch #89: loss=0.424751414415928
Epoch #90: loss=0.3108075838536024
Epoch #91: loss=0.26520094433082986
Epoch #92: loss=0.4240442163382585
Epoch #93: loss=0.37791789409059745
Epoch #94: loss=0.3245406746864319
Epoch #95: loss=0.3550658981100871
Epoch #96: loss=0.31219423404679847
Epoch #97: loss=0.2281266705921063
Epoch #98: loss=0.21151587202285344
Epoch #99: loss=0.2206022537385042
Epoch #100: loss=0.27538885849599654
Epoch #101: loss=0.21593406688995087
Epoch #102: loss=0.23561858758330345
Epoch #103: loss=0.19066429797273415
Epoch #104: loss=0.19771712445295775
Epoch #105: loss=0.21358845920230335
Epoch #106: loss=0.2741803972480389
Epoch #107: loss=0.18536016538452643
Epoch #108: loss=0.253554319533018
Epoch #109: loss=0.2906802331025784
Epoch #110: loss=0.18930812538243258
Epoch #111: loss=0.21835171144742233
Epoch #112: loss=0.2393318213379154
Epoch #113: loss=0.19111722628944194
Epoch #114: loss=0.210729489962642
Epoch #115: loss=0.20551327508516037
Epoch #116: loss=0.21141327580866906
Epoch #117: loss=0.20283152557049805
Epoch #118: loss=0.15336345222133857
Epoch #119: loss=0.2237294721058928
Epoch #120: loss=0.18422517904008812
Epoch #121: loss=0.17720468485584626
Epoch #122: loss=0.17269578558177903
Epoch #123: loss=0.20988816223465478
Epoch #124: loss=0.1910777074069931
Epoch #125: loss=0.1864963203238753
Epoch #126: loss=0.18501427626380554
Epoch #127: loss=0.2308057679866369
Epoch #128: loss=0.2775717659925039
Epoch #129: loss=0.24098751966196758
Epoch #130: loss=0.19767950138506982
Epoch #131: loss=0.15754066737225422
Epoch #132: loss=0.16054195631295443
Epoch #133: loss=0.14751899815522707
Epoch #134: loss=0.12545175255777744
Epoch #135: loss=0.16396522647343004
Epoch #136: loss=0.1381273717404558
Epoch #137: loss=0.17304205471793047
Epoch #138: loss=0.13408527028961822
Epoch #139: loss=0.16249353825472868
Epoch #140: loss=0.20578039007691237
Epoch #141: loss=0.14973308156745938
Epoch #142: loss=0.25988256401167464
Epoch #143: loss=0.15203024869641432
Epoch #144: loss=0.1545720289532955
Epoch #145: loss=0.14990625935248458
Epoch #146: loss=0.12788872757496741
Epoch #147: loss=0.15378690647104612
Epoch #148: loss=0.15241033404778975
Epoch #149: loss=0.1385579533301867
Epoch #150: loss=0.14187996952722853
Epoch #151: loss=0.13319833397578734
Epoch #152: loss=0.3422292727403916
Epoch #153: loss=0.14260093137048757
Epoch #154: loss=0.1359155556330314
Epoch #155: loss=0.1933162035420537
Epoch #156: loss=0.1729909977517449
Epoch #157: loss=0.17318278207228735
Epoch #158: loss=0.138513300066384
Epoch #159: loss=0.15729822752137596
Epoch #160: loss=0.15207158064899537
Epoch #161: loss=0.12371729608052053
Epoch #162: loss=0.18034070153505757
Epoch #163: loss=0.19554121054422396
Epoch #164: loss=0.1895653993750994
Epoch #165: loss=0.15502970604799116
Epoch #166: loss=0.13611842616676137
Epoch #167: loss=0.13321308548060748
Epoch #168: loss=0.15322904027282044
Epoch #169: loss=0.11579033718086205
Epoch #170: loss=0.12697335321886036
Epoch #171: loss=0.10548445209860802
Epoch #172: loss=0.108717250243689
Epoch #173: loss=0.12324892238785441
Epoch #174: loss=0.10643490536424977
Epoch #175: loss=0.09724079552464761
Epoch #176: loss=0.12656209488900808
Epoch #177: loss=0.09511733055114746
Epoch #178: loss=0.11656328942626715
Epoch #179: loss=0.1246694506934056
Epoch #180: loss=0.12985482711631519
Epoch #181: loss=0.10891565712741934
Epoch #182: loss=0.11507303486219965
Epoch #183: loss=0.08925614040344954
Epoch #184: loss=0.11407256574155046
Epoch #185: loss=0.10727712999169643
Epoch #186: loss=0.11626767177278033
Epoch #187: loss=0.08621950974114813
Epoch #188: loss=0.08215225228251746
Epoch #189: loss=0.13765362723587224
Epoch #190: loss=0.11868474295792672
Epoch #191: loss=0.13167923925301203
Epoch #192: loss=0.21125571021380332
Epoch #193: loss=0.12318861380649301
Epoch #194: loss=0.19072651039235866
Epoch #195: loss=0.11725859906381139
Epoch #196: loss=0.14481817798402447
Epoch #197: loss=0.1003868120829933
Epoch #198: loss=0.14468453727805844
Epoch #199: loss=0.117309133701313
Epoch #200: loss=0.09829857952606219
Epoch #201: loss=0.12044801455564223
Epoch #202: loss=0.0718787730169984
Epoch #203: loss=0.07397418589187929
Epoch #204: loss=0.10711588162498978
Epoch #205: loss=0.09960104736427848
Epoch #206: loss=0.08656597794749989
Epoch #207: loss=0.08698304223183256
Epoch #208: loss=0.07127830466757026
Epoch #209: loss=0.10991471217801937
Epoch #210: loss=0.12128362256603745
Epoch #211: loss=0.1630153082526074
Epoch #212: loss=0.18037721163664872
Epoch #213: loss=0.11417783606940737
Epoch #214: loss=0.13867824440463805
Epoch #215: loss=0.15478273276956037
Epoch #216: loss=0.1155071547613121
Epoch #217: loss=0.09686754092287558
Epoch #218: loss=0.1014831282126789
Epoch #219: loss=0.08088966729477622
Epoch #220: loss=0.08994361335554948
Epoch #221: loss=0.08781779899548453
Epoch #222: loss=0.08682595171894018
Epoch #223: loss=0.08562099602288352
Epoch #224: loss=0.0744359906977759
Epoch #225: loss=0.07000443285617691
Epoch #226: loss=0.07909740303428127
Epoch #227: loss=0.08093090409126419
Epoch #228: loss=0.07770357927522407
Epoch #229: loss=0.08356877276673913
Epoch #230: loss=0.10502608267303842
Epoch #231: loss=0.08954125128758068
Epoch #232: loss=0.10583071184989351
Epoch #233: loss=0.09870987055966488
Epoch #234: loss=0.14948627940164164
Epoch #235: loss=0.12139208604080173
Epoch #236: loss=0.10854982753069355
Epoch #237: loss=0.180162162376711
Epoch #238: loss=0.1535248437251609
Epoch #239: loss=0.10048695673378041
Epoch #240: loss=0.10059538458545621
Epoch #241: loss=0.07956202702525143
Epoch #242: loss=0.1146972409556978
Epoch #243: loss=0.08058922633958551
Epoch #244: loss=0.26426363843851364
Epoch #245: loss=0.15677732712804124
Epoch #246: loss=0.14513503718906298
Epoch #247: loss=0.11027836473658681
Epoch #248: loss=0.12358607763711077
Epoch #249: loss=0.1184820520440833

Training time: 0:15:55.262918

Finished.
n2one setting etth2_ettm1_weather_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_weather_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_ettm1_weather_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.59027e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.19169e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.59027e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3735263144835712, 'MAE': 0.4357017805727002}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm2_electricity_traffic', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm2_electricity_traffic_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.8587328384535001
Epoch #1: loss=0.3230605934010656
Epoch #2: loss=0.2121381323465102
Epoch #3: loss=0.15191462780694034
Epoch #4: loss=0.12052850090711688
Epoch #5: loss=0.09180465522768917
Epoch #6: loss=0.07631878222383057
Epoch #7: loss=0.07289961379542513
Epoch #8: loss=0.06407979124502514
Epoch #9: loss=0.05766432804305984
Epoch #10: loss=0.052401554519907696
Epoch #11: loss=0.04402618571886363
Epoch #12: loss=0.0431881097265962
Epoch #13: loss=0.04574661678305015
Epoch #14: loss=0.05577848201073229
Epoch #15: loss=0.03745678205839471
Epoch #16: loss=0.03187438456452515
Epoch #17: loss=0.032128043221906884
Epoch #18: loss=0.04316550284565165
Epoch #19: loss=0.03550938922408999
Epoch #20: loss=0.03380344109822973
Epoch #21: loss=0.03384085909132346
Epoch #22: loss=0.02770700339141839
Epoch #23: loss=0.025970686916415065
Epoch #24: loss=0.026830756527815264
Epoch #25: loss=0.027731063734909845
Epoch #26: loss=0.024275040812955177
Epoch #27: loss=0.025474051051877042
Epoch #28: loss=0.02877035952333305
Epoch #29: loss=0.02838977939075287
Epoch #30: loss=0.02307417834306339
Epoch #31: loss=0.030436188483406804
Epoch #32: loss=0.02210596613550084
Epoch #33: loss=0.018959062536342844
Epoch #34: loss=0.020242845517258277
Epoch #35: loss=0.020988443657483667
Epoch #36: loss=0.02759758299809852
Epoch #37: loss=0.018552352715016877
Epoch #38: loss=0.019667245877310936
Epoch #39: loss=0.01761004717117249
Epoch #40: loss=0.02150086139536794
Epoch #41: loss=0.034116788425011334
Epoch #42: loss=0.023698067206883187
Epoch #43: loss=0.018641515019726624
Epoch #44: loss=0.015735492257201278
Epoch #45: loss=0.018544923028449987
Epoch #46: loss=0.020454369960684286
Epoch #47: loss=0.01774843898107477
Epoch #48: loss=0.020098218397281174
Epoch #49: loss=0.01971265476182077
Epoch #50: loss=0.019059213102453208
Epoch #51: loss=0.014818555499685054
Epoch #52: loss=0.018384907862829116
Epoch #53: loss=0.01629115249615749
Epoch #54: loss=0.01537169663840013
Epoch #55: loss=0.016501481392101485
Epoch #56: loss=0.013948198565475597
Epoch #57: loss=0.018875300287921216
Epoch #58: loss=0.013437122445139924
Epoch #59: loss=0.023938116923805874
Epoch #60: loss=0.013969348019669817
Epoch #61: loss=0.01886830088590581
Epoch #62: loss=0.01556511573216449
Epoch #63: loss=0.016050566683094337
Epoch #64: loss=0.019327618957306805
Epoch #65: loss=0.01721213447843344
Epoch #66: loss=0.013443073336924655
Epoch #67: loss=0.016935968642366538
Epoch #68: loss=0.013204111593532054
Epoch #69: loss=0.014847152527985082
Epoch #70: loss=0.01433464325944345
Epoch #71: loss=0.029351499225544146
Epoch #72: loss=0.012853630722948598
Epoch #73: loss=0.014980497274979744
Epoch #74: loss=0.010881837038720704
Epoch #75: loss=0.01603620021248164
Epoch #76: loss=0.015562051451310583
Epoch #77: loss=0.01657390140060399
Epoch #78: loss=0.012690731381614972
Epoch #79: loss=0.019123760822828514
Epoch #80: loss=0.014973704681459104
Epoch #81: loss=0.01130204070314395
Epoch #82: loss=0.01246390923689318
Epoch #83: loss=0.01445952468086131
Epoch #84: loss=0.01077506182995721
Epoch #85: loss=0.014713692144274815
Epoch #86: loss=0.013084465980303182
Epoch #87: loss=0.014340104879003099
Epoch #88: loss=0.01322946751316824
Epoch #89: loss=0.014070183799506517
Epoch #90: loss=0.011233983732263466
Epoch #91: loss=0.01459220950361353
Epoch #92: loss=0.01042557322092259
Epoch #93: loss=0.010747624946010611
Epoch #94: loss=0.018916647736404595
Epoch #95: loss=0.013095593422821503
Epoch #96: loss=0.012781203229339533
Epoch #97: loss=0.013257293804827553
Epoch #98: loss=0.011841071714501425
Epoch #99: loss=0.020850241459179183
Epoch #100: loss=0.011176405535341135
Epoch #101: loss=0.012605744849098634
Epoch #102: loss=0.014312695174460158
Epoch #103: loss=0.016300875095804288
Epoch #104: loss=0.012167343918101701
Epoch #105: loss=0.01026126415393194
Epoch #106: loss=0.014312466344854086
Epoch #107: loss=0.01229120312191912
Epoch #108: loss=0.012965614631550843
Epoch #109: loss=0.008444248556319277
Epoch #110: loss=0.012439179769658998
Epoch #111: loss=0.01361420861013826
Epoch #112: loss=0.013333314518617943
Epoch #113: loss=0.011163056903767319
Epoch #114: loss=0.01029786233051888
Epoch #115: loss=0.009511686798327503
Epoch #116: loss=0.01348446250794208
Epoch #117: loss=0.024636951407385085
Epoch #118: loss=0.011779981232887513
Epoch #119: loss=0.010473688176728795
Epoch #120: loss=0.011592486870773083
Epoch #121: loss=0.020298413644556607
Epoch #122: loss=0.012647526782645002
Epoch #123: loss=0.010139638561616612
Epoch #124: loss=0.010678899466148261
Epoch #125: loss=0.011019003255352678
Epoch #126: loss=0.010367783716878137
Epoch #127: loss=0.014576416740345759
Epoch #128: loss=0.010146602837392691
Epoch #129: loss=0.01154909259208333
Epoch #130: loss=0.019569555480792332
Epoch #131: loss=0.016364453187856995
Epoch #132: loss=0.00990984295213267
Epoch #133: loss=0.009944065627102065
Epoch #134: loss=0.012737504274353268
Epoch #135: loss=0.013978445203490184
Epoch #136: loss=0.009406158916622541
Epoch #137: loss=0.013649455695290434
Epoch #138: loss=0.012402052640731522
Epoch #139: loss=0.016398465685534474
Epoch #140: loss=0.009621940784710386
Epoch #141: loss=0.009456852212998796
Epoch #142: loss=0.011889312591277323
Epoch #143: loss=0.014817170766766743
Epoch #144: loss=0.0114509413105286
Epoch #145: loss=0.011462601994001054
Epoch #146: loss=0.008947919603164425
Epoch #147: loss=0.009688109871628946
Epoch #148: loss=0.008933726198027445
Epoch #149: loss=0.014027595058950397
Epoch #150: loss=0.010502529008749529
Epoch #151: loss=0.008009040933719342
Epoch #152: loss=0.00957719648801074
Epoch #153: loss=0.016976729938420167
Epoch #154: loss=0.009545576955478904
Epoch #155: loss=0.010898052003441768
Epoch #156: loss=0.01060047071608079
Epoch #157: loss=0.012715638784458473
Epoch #158: loss=0.011858553970648444
Epoch #159: loss=0.009285713903584418
Epoch #160: loss=0.00986752544324628
Epoch #161: loss=0.019870207739144222
Epoch #162: loss=0.008605839193317916
Epoch #163: loss=0.01427625719564296
Epoch #164: loss=0.008819131805055691
Epoch #165: loss=0.010071360474250952
Epoch #166: loss=0.015808157902523556
Epoch #167: loss=0.010123091667200296
Epoch #168: loss=0.011678883279263733
Epoch #169: loss=0.010665068130434795
Epoch #170: loss=0.01176141005258625
Epoch #171: loss=0.008737809256624627
Epoch #172: loss=0.01200307320214445
Epoch #173: loss=0.013290380377558078
Epoch #174: loss=0.011104456960810732
Epoch #175: loss=0.007384719967861101
Epoch #176: loss=0.008848008510285794
Epoch #177: loss=0.012370485567563287
Epoch #178: loss=0.00899562503988934
Epoch #179: loss=0.011074410535806477
Epoch #180: loss=0.011007940570065744
Epoch #181: loss=0.007965263481231347
Epoch #182: loss=0.014058170081602858
Epoch #183: loss=0.012692506602710558
Epoch #184: loss=0.009012102612059099
Epoch #185: loss=0.016278896007728194
Epoch #186: loss=0.010627378577835234
Epoch #187: loss=0.00814649152867886
Epoch #188: loss=0.009668534591874564
Epoch #189: loss=0.010841028945113212
Epoch #190: loss=0.01131133537640984
Epoch #191: loss=0.012656634265707564
Epoch #192: loss=0.010667494933963148
Epoch #193: loss=0.009369222496905295
Epoch #194: loss=0.010748729454502727
Epoch #195: loss=0.007594610041971485
Epoch #196: loss=0.011830962041315764
Epoch #197: loss=0.008543782994114717
Epoch #198: loss=0.014354840846710255
Epoch #199: loss=0.00855140857700744
Epoch #200: loss=0.014170254013139745
Epoch #201: loss=0.008968455796415467
Epoch #202: loss=0.011952169978731967
Epoch #203: loss=0.010316801897109953
Epoch #204: loss=0.010555531777434037
Epoch #205: loss=0.00839282015905253
Epoch #206: loss=0.014412068492753491
Epoch #207: loss=0.007547353362099661
Epoch #208: loss=0.019177180952170546
Epoch #209: loss=0.010058114031027032
Epoch #210: loss=0.009623190713648484
Epoch #211: loss=0.009611317709074094
Epoch #212: loss=0.012594720227090366
Epoch #213: loss=0.008751948136349401
Epoch #214: loss=0.008993718205686724
Epoch #215: loss=0.008456961554126173
Epoch #216: loss=0.015679997640241597
Epoch #217: loss=0.011883507563766878
Epoch #218: loss=0.010258917657686181
Epoch #219: loss=0.008000730572997392
Epoch #220: loss=0.009603271291778888
Epoch #221: loss=0.013441374126904052
Epoch #222: loss=0.014538353787624893
Epoch #223: loss=0.007969698767463116
Epoch #224: loss=0.007693441624981549
Epoch #225: loss=0.010150813909394273
Epoch #226: loss=0.007424723235869913
Epoch #227: loss=0.014880494409500367
Epoch #228: loss=0.00902904195219426
Epoch #229: loss=0.007156448857161472
Epoch #230: loss=0.009211161343826114
Epoch #231: loss=0.009828291718681714
Epoch #232: loss=0.008901316282793956
Epoch #233: loss=0.012299054232105507
Epoch #234: loss=0.011091809159303825
Epoch #235: loss=0.008351111406397205
Epoch #236: loss=0.008651337522613533
Epoch #237: loss=0.00977606953298962
Epoch #238: loss=0.009703222266158464
Epoch #239: loss=0.008667254601557255
Epoch #240: loss=0.00792022430719926
Epoch #241: loss=0.010477161353103944
Epoch #242: loss=0.009806655742660155
Epoch #243: loss=0.008675611689624958
Epoch #244: loss=0.010781068743154605
Epoch #245: loss=0.007795421312348223
Epoch #246: loss=0.006965823490526669
Epoch #247: loss=0.008395115584321891
Epoch #248: loss=0.010735503587989853
Epoch #249: loss=0.009076783290024511

Training time: 4:53:54.939230

Finished.
n2one setting etth2_ettm2_electricity_traffic -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm2_electricity_traffic_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_ettm2_electricity_traffic', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.65575e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.32228e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.65575e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.40129927059075327, 'MAE': 0.47479167841268244}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm2_electricity_traffic -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm2_electricity_traffic_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_ettm2_electricity_traffic', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.6056e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.24804909908015588, 'MAE': 0.34296289691032256}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm2_electricity_weather', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm2_electricity_weather_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.8068837753713947
Epoch #1: loss=0.8178687926841108
Epoch #2: loss=0.5580755449321172
Epoch #3: loss=0.46025359271323846
Epoch #4: loss=0.42686368120859747
Epoch #5: loss=0.3710191109817322
Epoch #6: loss=0.3252237519172773
Epoch #7: loss=0.30334266940616583
Epoch #8: loss=0.25694279115493984
Epoch #9: loss=0.2528570394401681
Epoch #10: loss=0.21861179464892166
Epoch #11: loss=0.21841083858927635
Epoch #12: loss=0.1891808781619758
Epoch #13: loss=0.17653342850812495
Epoch #14: loss=0.16395121408651953
Epoch #15: loss=0.16281251337838498
Epoch #16: loss=0.14729162861835465
Epoch #17: loss=0.12446223591798788
Epoch #18: loss=0.1340004904629433
Epoch #19: loss=0.11998234787726239
Epoch #20: loss=0.10692609612868256
Epoch #21: loss=0.09428568824054036
Epoch #22: loss=0.08426656974607134
Epoch #23: loss=0.08148154282355553
Epoch #24: loss=0.1205874038758139
Epoch #25: loss=0.08303720268025382
Epoch #26: loss=0.07662159656621005
Epoch #27: loss=0.08787380408954946
Epoch #28: loss=0.06869992634460126
Epoch #29: loss=0.06920693546839773
Epoch #30: loss=0.06315981089328862
Epoch #31: loss=0.05594178129446833
Epoch #32: loss=0.05790825122457049
Epoch #33: loss=0.05646202037340566
Epoch #34: loss=0.054464554245749565
Epoch #35: loss=0.04017183054429926
Epoch #36: loss=0.052768181617792745
Epoch #37: loss=0.056354946987575864
Epoch #38: loss=0.04714501360367524
Epoch #39: loss=0.05405359357812327
Epoch #40: loss=0.056483181134146986
Epoch #41: loss=0.07139569968495467
Epoch #42: loss=0.062185260828278244
Epoch #43: loss=0.03757214902593971
Epoch #44: loss=0.03607488428051137
Epoch #45: loss=0.02651480098561167
Epoch #46: loss=0.04944800046361881
Epoch #47: loss=0.031580523796673
Epoch #48: loss=0.034724517824919254
Epoch #49: loss=0.0291098856271487
Epoch #50: loss=0.033066777068777135
Epoch #51: loss=0.036260842114738
Epoch #52: loss=0.033258240949362514
Epoch #53: loss=0.04054641495203625
Epoch #54: loss=0.043297301136174124
Epoch #55: loss=0.025875342725967504
Epoch #56: loss=0.03509718203783188
Epoch #57: loss=0.027832318702393707
Epoch #58: loss=0.029835242206830377
Epoch #59: loss=0.03158421008145972
Epoch #60: loss=0.027139546439587457
Epoch #61: loss=0.030677142084180695
Epoch #62: loss=0.028611834510229528
Epoch #63: loss=0.034235167924684715
Epoch #64: loss=0.031042448777150466
Epoch #65: loss=0.04073766335647247
Epoch #66: loss=0.026253423307645962
Epoch #67: loss=0.03411044969880469
Epoch #68: loss=0.028108941888666316
Epoch #69: loss=0.02021889995260496
Epoch #70: loss=0.02598419584117013
Epoch #71: loss=0.02561424471922729
Epoch #72: loss=0.024031561360318112
Epoch #73: loss=0.0220957386131998
Epoch #74: loss=0.02543903752772316
Epoch #75: loss=0.03131237778723342
Epoch #76: loss=0.03004311335238003
Epoch #77: loss=0.025012701043017106
Epoch #78: loss=0.018410127764975984
Epoch #79: loss=0.022637004939175837
Epoch #80: loss=0.02509462200774977
Epoch #81: loss=0.035559270739529844
Epoch #82: loss=0.035916532384397536
Epoch #83: loss=0.024554661282159593
Epoch #84: loss=0.023363479137841665
Epoch #85: loss=0.02096510487624559
Epoch #86: loss=0.025779900225102646
Epoch #87: loss=0.025908059624904025
Epoch #88: loss=0.020298387396327947
Epoch #89: loss=0.02363571316443945
Epoch #90: loss=0.0164430164974438
Epoch #91: loss=0.027967969464355032
Epoch #92: loss=0.022388758720536653
Epoch #93: loss=0.021584288194003733
Epoch #94: loss=0.03527345612887548
Epoch #95: loss=0.0156990717520797
Epoch #96: loss=0.026133655975668448
Epoch #97: loss=0.02223415392329789
Epoch #98: loss=0.028500527785835814
Epoch #99: loss=0.024101308264693068
Epoch #100: loss=0.029540550023993504
Epoch #101: loss=0.03448119466511967
Epoch #102: loss=0.01757117755908825
Epoch #103: loss=0.020566632406712727
Epoch #104: loss=0.032796374488819696
Epoch #105: loss=0.031795178893124304
Epoch #106: loss=0.01919051083219429
Epoch #107: loss=0.022097399247465784
Epoch #108: loss=0.020986510529374218
Epoch #109: loss=0.020338940199891947
Epoch #110: loss=0.020861069819641184
Epoch #111: loss=0.02156017124110654
Epoch #112: loss=0.01737691533643344
Epoch #113: loss=0.01600594768015196
Epoch #114: loss=0.016555490526243125
Epoch #115: loss=0.016425233939024682
Epoch #116: loss=0.01848285943652465
Epoch #117: loss=0.032682220584693784
Epoch #118: loss=0.019521362219509758
Epoch #119: loss=0.022331018486914978
Epoch #120: loss=0.021418676975865733
Epoch #121: loss=0.022181405637681176
Epoch #122: loss=0.015755243387156205
Epoch #123: loss=0.016420921127627643
Epoch #124: loss=0.022891226009631605
Epoch #125: loss=0.018217769949473696
Epoch #126: loss=0.024034509078634598
Epoch #127: loss=0.028466149716963353
Epoch #128: loss=0.013423669405444207
Epoch #129: loss=0.012133708481847513
Epoch #130: loss=0.01898016116943861
Epoch #131: loss=0.017479836503729505
Epoch #132: loss=0.022172419906574724
Epoch #133: loss=0.01489370924720464
Epoch #134: loss=0.017428422955898186
Epoch #135: loss=0.020173363711474438
Epoch #136: loss=0.04155949061155983
Epoch #137: loss=0.030048196764076
Epoch #138: loss=0.017528574148747967
Epoch #139: loss=0.02480400627262074
Epoch #140: loss=0.014994360727564215
Epoch #141: loss=0.02034515134323618
Epoch #142: loss=0.019877623312003042
Epoch #143: loss=0.01409085254975888
Epoch #144: loss=0.015049609769779985
Epoch #145: loss=0.013309884282332934
Epoch #146: loss=0.024399167221128837
Epoch #147: loss=0.013216577571328755
Epoch #148: loss=0.020490359154223682
Epoch #149: loss=0.024185701821171614
Epoch #150: loss=0.02130001231953055
Epoch #151: loss=0.014378054520236456
Epoch #152: loss=0.027276638777582102
Epoch #153: loss=0.012818986080963267
Epoch #154: loss=0.04266645009932427
Epoch #155: loss=0.01748187045912794
Epoch #156: loss=0.018007962380484868
Epoch #157: loss=0.011379105774111638
Epoch #158: loss=0.0136144062846242
Epoch #159: loss=0.014362075099361141
Epoch #160: loss=0.014442169672828678
Epoch #161: loss=0.01252615584892999
Epoch #162: loss=0.01453314602218747
Epoch #163: loss=0.060732955463256126
Epoch #164: loss=0.01345161859963523
Epoch #165: loss=0.013500313180951682
Epoch #166: loss=0.025214689329572736
Epoch #167: loss=0.016055712818761343
Epoch #168: loss=0.0215923181114629
Epoch #169: loss=0.017363933731533894
Epoch #170: loss=0.012759522438425673
Epoch #171: loss=0.015171939520522544
Epoch #172: loss=0.013100511344366591
Epoch #173: loss=0.012863593857914005
Epoch #174: loss=0.01808689711487865
Epoch #175: loss=0.014630178098761387
Epoch #176: loss=0.011549382444314837
Epoch #177: loss=0.013379951106457753
Epoch #178: loss=0.014070115325340925
Epoch #179: loss=0.021424649695368253
Epoch #180: loss=0.0153759568948809
Epoch #181: loss=0.015763472498726252
Epoch #182: loss=0.011361543291123993
Epoch #183: loss=0.013628999683814608
Epoch #184: loss=0.02507024241431157
Epoch #185: loss=0.013383999956159355
Epoch #186: loss=0.01369721227491351
Epoch #187: loss=0.012485378640161648
Epoch #188: loss=0.01254410247026611
Epoch #189: loss=0.016328746149290915
Epoch #190: loss=0.019211676821339084
Epoch #191: loss=0.01759347590141011
Epoch #192: loss=0.025055798047464595
Epoch #193: loss=0.010864351915290471
Epoch #194: loss=0.016785097866532813
Epoch #195: loss=0.012381598501695856
Epoch #196: loss=0.015599651430647387
Epoch #197: loss=0.01485546769802331
Epoch #198: loss=0.01765337868813706
Epoch #199: loss=0.01718114927691752
Epoch #200: loss=0.05457412064034007
Epoch #201: loss=0.027050145344221836
Epoch #202: loss=0.011438868776018005
Epoch #203: loss=0.01099795910620692
Epoch #204: loss=0.009175353660686772
Epoch #205: loss=0.013545448969721105
Epoch #206: loss=0.01295723592565867
Epoch #207: loss=0.027232556034211222
Epoch #208: loss=0.013246966115109724
Epoch #209: loss=0.013778942536518029
Epoch #210: loss=0.013909098928258435
Epoch #211: loss=0.026790503819540068
Epoch #212: loss=0.01277479189208849
Epoch #213: loss=0.008467243791020424
Epoch #214: loss=0.019014916413468436
Epoch #215: loss=0.012867984667337462
Epoch #216: loss=0.013163913281679103
Epoch #217: loss=0.015480818024163505
Epoch #218: loss=0.009105031191345866
Epoch #219: loss=0.01752717177836505
Epoch #220: loss=0.018237831413248324
Epoch #221: loss=0.012260925340105791
Epoch #222: loss=0.012197579405101475
Epoch #223: loss=0.011432083734320732
Epoch #224: loss=0.015773230534818737
Epoch #225: loss=0.01629111301799764
Epoch #226: loss=0.012219761162581663
Epoch #227: loss=0.020701758427567756
Epoch #228: loss=0.025987006504126914
Epoch #229: loss=0.009784391866709832
Epoch #230: loss=0.012806270913897107
Epoch #231: loss=0.012563750270135343
Epoch #232: loss=0.011607369410004849
Epoch #233: loss=0.020307096143808115
Epoch #234: loss=0.01474286855209606
Epoch #235: loss=0.012433342057382306
Epoch #236: loss=0.01123257877595391
Epoch #237: loss=0.008461235362912005
Epoch #238: loss=0.02154321409865563
Epoch #239: loss=0.016589739720802753
Epoch #240: loss=0.009597368748923954
Epoch #241: loss=0.007370011008516822
Epoch #242: loss=0.012242922977678325
Epoch #243: loss=0.012768004497964483
Epoch #244: loss=0.022644099837714447
Epoch #245: loss=0.010885828417129432
Epoch #246: loss=0.013589830334658722
Epoch #247: loss=0.02328293799404342
Epoch #248: loss=0.019803225651880956
Epoch #249: loss=0.01357667533679202

Training time: 1:44:03.764650

Finished.
n2one setting etth2_ettm2_electricity_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm2_electricity_weather_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_ettm2_electricity_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.33324e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.33324e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.21759102761022509, 'MAE': 0.3229419159680702}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm2_electricity_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm2_electricity_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.7212097117467984
Epoch #1: loss=0.7491428895882983
Epoch #2: loss=0.5080661974224646
Epoch #3: loss=0.4160861264302339
Epoch #4: loss=0.35039920044220146
Epoch #5: loss=0.3015703442117323
Epoch #6: loss=0.2897310437532598
Epoch #7: loss=0.24529026216835384
Epoch #8: loss=0.2268973724857531
Epoch #9: loss=0.21158088711479556
Epoch #10: loss=0.19347981031801584
Epoch #11: loss=0.19680548439967185
Epoch #12: loss=0.16596756398849596
Epoch #13: loss=0.1549490538589463
Epoch #14: loss=0.14375825976732828
Epoch #15: loss=0.1391416091085425
Epoch #16: loss=0.14439602242916907
Epoch #17: loss=0.10188183499773916
Epoch #18: loss=0.1089196002073264
Epoch #19: loss=0.09189148679354177
Epoch #20: loss=0.1048496108561196
Epoch #21: loss=0.10294675075526884
Epoch #22: loss=0.09825621277995687
Epoch #23: loss=0.1035952857139947
Epoch #24: loss=0.08682242097059313
Epoch #25: loss=0.07582102868416124
Epoch #26: loss=0.06485330936517728
Epoch #27: loss=0.06604568190169481
Epoch #28: loss=0.06965770731312397
Epoch #29: loss=0.08073405178279887
Epoch #30: loss=0.0722479252158114
Epoch #31: loss=0.07543681137215465
Epoch #32: loss=0.054459629108007425
Epoch #33: loss=0.060711355047214574
Epoch #34: loss=0.04694196226958303
Epoch #35: loss=0.10628906185591126
Epoch #36: loss=0.05660478177853465
Epoch #37: loss=0.05839228565651677
Epoch #38: loss=0.05260663110392453
Epoch #39: loss=0.04007783385734436
Epoch #40: loss=0.04124422636358148
Epoch #41: loss=0.04877276704391674
Epoch #42: loss=0.05015448748029403
Epoch #43: loss=0.04626597948734694
Epoch #44: loss=0.05057352618582719
Epoch #45: loss=0.06476032744183256
Epoch #46: loss=0.053715827167624616
Epoch #47: loss=0.03856292853510324
Epoch #48: loss=0.047920483437243325
Epoch #49: loss=0.039949508217131176
Epoch #50: loss=0.06056414983001798
Epoch #51: loss=0.038325651451846
Epoch #52: loss=0.05090615021666077
Epoch #53: loss=0.04398331545113508
Epoch #54: loss=0.04865998159241876
Epoch #55: loss=0.04986437727557629
Epoch #56: loss=0.03485943033408256
Epoch #57: loss=0.03158629898677019
Epoch #58: loss=0.03735213402070921
Epoch #59: loss=0.03698697653652762
Epoch #60: loss=0.031167204996372336
Epoch #61: loss=0.028429586620483366
Epoch #62: loss=0.03733316476467557
Epoch #63: loss=0.03048992816423219
Epoch #64: loss=0.0298977317872272
Epoch #65: loss=0.0347584194212854
Epoch #66: loss=0.029356339279768898
Epoch #67: loss=0.04553924285154521
Epoch #68: loss=0.037688827955349204
Epoch #69: loss=0.03424969610492417
Epoch #70: loss=0.03761854624242847
Epoch #71: loss=0.045809042141490994
Epoch #72: loss=0.03506220782427949
Epoch #73: loss=0.038110081865975594
Epoch #74: loss=0.03593665685354375
Epoch #75: loss=0.04060235040085202
Epoch #76: loss=0.038265038026035134
Epoch #77: loss=0.0387303881143872
Epoch #78: loss=0.02741520414219482
Epoch #79: loss=0.026798481218112895
Epoch #80: loss=0.03726713805659392
Epoch #81: loss=0.026115650984107033
Epoch #82: loss=0.028556586383111905
Epoch #83: loss=0.02660661793927198
Epoch #84: loss=0.03670345044323117
Epoch #85: loss=0.036557489852769895
Epoch #86: loss=0.0274686055531006
Epoch #87: loss=0.0459302101523806
Epoch #88: loss=0.028022842947058164
Epoch #89: loss=0.030974394796813385
Epoch #90: loss=0.027903113766474065
Epoch #91: loss=0.02863989256725644
Epoch #92: loss=0.025790473923317937
Epoch #93: loss=0.02325234205162781
Epoch #94: loss=0.023045523223830845
Epoch #95: loss=0.03931669259285527
Epoch #96: loss=0.028067759018772488
Epoch #97: loss=0.027325940931682887
Epoch #98: loss=0.02816846343200192
Epoch #99: loss=0.02408251671358052
Epoch #100: loss=0.02497745958081063
Epoch #101: loss=0.02952249768919443
Epoch #102: loss=0.04463106959082605
Epoch #103: loss=0.02805610111513999
Epoch #104: loss=0.0285144243097491
Epoch #105: loss=0.04103119610620915
Epoch #106: loss=0.023250679064291107
Epoch #107: loss=0.01863349303257617
Epoch #108: loss=0.01857330235961277
Epoch #109: loss=0.014964077306504734
Epoch #110: loss=0.02334086715184375
Epoch #111: loss=0.02787151474939117
Epoch #112: loss=0.019057175148914564
Epoch #113: loss=0.01519657163753279
Epoch #114: loss=0.021298146790386007
Epoch #115: loss=0.02288000752494512
Epoch #116: loss=0.028773014760785535
Epoch #117: loss=0.03675091595832468
Epoch #118: loss=0.04121939300476259
Epoch #119: loss=0.031135497833481355
Epoch #120: loss=0.022408647433873427
Epoch #121: loss=0.02438743596108797
Epoch #122: loss=0.01457439837655219
Epoch #123: loss=0.01617942667302544
Epoch #124: loss=0.017755276254886192
Epoch #125: loss=0.033089190212236747
Epoch #126: loss=0.036938956308632184
Epoch #127: loss=0.02305082060626147
Epoch #128: loss=0.018961543866476145
Epoch #129: loss=0.020789216743394335
Epoch #130: loss=0.02242214680446033
Epoch #131: loss=0.021168135669349455
Epoch #132: loss=0.028558956608458044
Epoch #133: loss=0.038377184082984774
Epoch #134: loss=0.028516346341809554
Epoch #135: loss=0.01699218333558574
Epoch #136: loss=0.021891213680573226
Epoch #137: loss=0.02076008241296201
Epoch #138: loss=0.01803021403066465
Epoch #139: loss=0.01871366072841987
Epoch #140: loss=0.01524449303779437
Epoch #141: loss=0.019655099452972433
Epoch #142: loss=0.024033860741444844
Epoch #143: loss=0.02012928478823712
Epoch #144: loss=0.016751505814959707
Epoch #145: loss=0.015154742641657623
Epoch #146: loss=0.0201465699458374
Epoch #147: loss=0.03379074050706036
Epoch #148: loss=0.026609897511871667
Epoch #149: loss=0.019515619828699222
Epoch #150: loss=0.02303395726364401
Epoch #151: loss=0.0188725581806977
Epoch #152: loss=0.0243239706845636
Epoch #153: loss=0.01966424589330513
Epoch #154: loss=0.018923881428144464
Epoch #155: loss=0.019727939541716
Epoch #156: loss=0.027738612225367783
Epoch #157: loss=0.022173510440148852
Epoch #158: loss=0.021442679565041582
Epoch #159: loss=0.02337048336630687
Epoch #160: loss=0.014540111263261126
Epoch #161: loss=0.015357623963753668
Epoch #162: loss=0.02795094446770938
Epoch #163: loss=0.023419392726287482
Epoch #164: loss=0.014012851703526875
Epoch #165: loss=0.031533830591158066
Epoch #166: loss=0.021633265873313927
Epoch #167: loss=0.01500285001134806
Epoch #168: loss=0.0167629061756932
Epoch #169: loss=0.02706088032305069
Epoch #170: loss=0.01307542291245093
Epoch #171: loss=0.014476881645316585
Epoch #172: loss=0.020379639288876206
Epoch #173: loss=0.017370541607363885
Epoch #174: loss=0.018450791168701634
Epoch #175: loss=0.016201101854592507
Epoch #176: loss=0.01912273541116357
Epoch #177: loss=0.028346497880366042
Epoch #178: loss=0.01909220606754252
Epoch #179: loss=0.020471586956359415
Epoch #180: loss=0.017625113016347366
Epoch #181: loss=0.024159239695316196
Epoch #182: loss=0.016747518775881313
Epoch #183: loss=0.021468329521316113
Epoch #184: loss=0.02477448256313935
Epoch #185: loss=0.02747056899580203
Epoch #186: loss=0.0218425029507967
Epoch #187: loss=0.020567323287689968
Epoch #188: loss=0.022574985315466315
Epoch #189: loss=0.02465826364494766
Epoch #190: loss=0.021025056628341268
Epoch #191: loss=0.023711154843957007
Epoch #192: loss=0.01385796541010596
Epoch #193: loss=0.017111708613056206
Epoch #194: loss=0.018038968712638968
Epoch #195: loss=0.014754902939389324
Epoch #196: loss=0.015282604853946028
Epoch #197: loss=0.020865695383124622
Epoch #198: loss=0.01920254226631058
Epoch #199: loss=0.020063034770070907
Epoch #200: loss=0.015459852553306883
Epoch #201: loss=0.017729741145094444
Epoch #202: loss=0.015120183928988428
Epoch #203: loss=0.01900865972915702
Epoch #204: loss=0.021440155805331474
Epoch #205: loss=0.02437977646531199
Epoch #206: loss=0.025982079491849924
Epoch #207: loss=0.02074656293238312
Epoch #208: loss=0.01944522952854832
Epoch #209: loss=0.017590759740572056
Epoch #210: loss=0.019593814870521094
Epoch #211: loss=0.03543875401776542
Epoch #212: loss=0.03072100714394576
Epoch #213: loss=0.023198771503433902
Epoch #214: loss=0.022287080195760596
Epoch #215: loss=0.019659331965834567
Epoch #216: loss=0.018048064942657545
Epoch #217: loss=0.013547636959393126
Epoch #218: loss=0.01554896297550261
Epoch #219: loss=0.0205364432783062
Epoch #220: loss=0.014219266685398205
Epoch #221: loss=0.015340572679502573
Epoch #222: loss=0.017817026353944415
Epoch #223: loss=0.016249837018250855
Epoch #224: loss=0.021094702406295223
Epoch #225: loss=0.01530606284441013
Epoch #226: loss=0.013778402688624526
Epoch #227: loss=0.015413426879997383
Epoch #228: loss=0.016256786330323934
Epoch #229: loss=0.03296118168836669
Epoch #230: loss=0.01861510797764741
Epoch #231: loss=0.01493095182983127
Epoch #232: loss=0.012281618212042404
Epoch #233: loss=0.0204415329954599
Epoch #234: loss=0.02277304588227267
Epoch #235: loss=0.016777435162219405
Epoch #236: loss=0.01494072801398277
Epoch #237: loss=0.021694761730115916
Epoch #238: loss=0.018997938184487643
Epoch #239: loss=0.016820909249259466
Epoch #240: loss=0.01233269404958778
Epoch #241: loss=0.013333763737333483
Epoch #242: loss=0.009424885285693498
Epoch #243: loss=0.012386488411186386
Epoch #244: loss=0.01713976058981486
Epoch #245: loss=0.01265186133629425
Epoch #246: loss=0.02185915834193255
Epoch #247: loss=0.01749927390759988
Epoch #248: loss=0.01417603158743942
Epoch #249: loss=0.01464239379252852

Training time: 1:40:17.419391

Finished.
n2one setting etth2_ettm2_electricity_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm2_electricity_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_ettm2_electricity_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.67045e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.2126e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.67045e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.581116330247229, 'MAE': 0.565728515063806}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm2_traffic_weather', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm2_traffic_weather_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.061743435086004
Epoch #1: loss=0.4685126586630118
Epoch #2: loss=0.31423411218996344
Epoch #3: loss=0.24614746717296163
Epoch #4: loss=0.19272621105492904
Epoch #5: loss=0.17413753424884204
Epoch #6: loss=0.14961316020620646
Epoch #7: loss=0.13583350723925935
Epoch #8: loss=0.11698191953827082
Epoch #9: loss=0.10110397486295757
Epoch #10: loss=0.07846939950465959
Epoch #11: loss=0.0832635583844299
Epoch #12: loss=0.07645994965881356
Epoch #13: loss=0.06857013942521666
Epoch #14: loss=0.06544454030334851
Epoch #15: loss=0.06545235542323498
Epoch #16: loss=0.04914286540292828
Epoch #17: loss=0.052732062488013084
Epoch #18: loss=0.054110956392286934
Epoch #19: loss=0.04987717534119374
Epoch #20: loss=0.044310642542290786
Epoch #21: loss=0.04193578420024957
Epoch #22: loss=0.03958112457456174
Epoch #23: loss=0.04624481517903786
Epoch #24: loss=0.05994354749972691
Epoch #25: loss=0.04292155047991698
Epoch #26: loss=0.03179280425431659
Epoch #27: loss=0.028872029234323172
Epoch #28: loss=0.03339990950703506
Epoch #29: loss=0.04045722561862184
Epoch #30: loss=0.042838320452550316
Epoch #31: loss=0.03569684687532355
Epoch #32: loss=0.0289950919044348
Epoch #33: loss=0.03568650685860077
Epoch #34: loss=0.03930097944683973
Epoch #35: loss=0.023956548637352273
Epoch #36: loss=0.03202926652995812
Epoch #37: loss=0.030865832784076407
Epoch #38: loss=0.03356529296071024
Epoch #39: loss=0.02650984664970318
Epoch #40: loss=0.029374881893913952
Epoch #41: loss=0.02550794182036372
Epoch #42: loss=0.030537404071783264
Epoch #43: loss=0.03538578553315433
Epoch #44: loss=0.026338763151468943
Epoch #45: loss=0.03286306080918514
Epoch #46: loss=0.022852101077471612
Epoch #47: loss=0.02066457343943598
Epoch #48: loss=0.02703862136612013
Epoch #49: loss=0.025776362070884705
Epoch #50: loss=0.024112525290844778
Epoch #51: loss=0.021267895219232332
Epoch #52: loss=0.02317634159154269
Epoch #53: loss=0.026957383678682383
Epoch #54: loss=0.02614380299048416
Epoch #55: loss=0.026954585390918936
Epoch #56: loss=0.022243347963514567
Epoch #57: loss=0.026694809148169307
Epoch #58: loss=0.021230571926674224
Epoch #59: loss=0.01694909397868088
Epoch #60: loss=0.022284983314993168
Epoch #61: loss=0.020238561113692655
Epoch #62: loss=0.024683639447761918
Epoch #63: loss=0.025344944892591353
Epoch #64: loss=0.020242883954490132
Epoch #65: loss=0.024414246004019816
Epoch #66: loss=0.01874443969698818
Epoch #67: loss=0.019205713225549478
Epoch #68: loss=0.015935520935852737
Epoch #69: loss=0.026605238334792843
Epoch #70: loss=0.015555115447805735
Epoch #71: loss=0.023311900368197275
Epoch #72: loss=0.01859241310293374
Epoch #73: loss=0.020945831563873175
Epoch #74: loss=0.02127300371015912
Epoch #75: loss=0.01745117899284479
Epoch #76: loss=0.019734394863218575
Epoch #77: loss=0.022620877839080584
Epoch #78: loss=0.02284958861844314
Epoch #79: loss=0.017681961369720774
Epoch #80: loss=0.014369636272038097
Epoch #81: loss=0.018063680827707592
Epoch #82: loss=0.029773179770570153
Epoch #83: loss=0.01930524607102395
Epoch #84: loss=0.017814371273597182
Epoch #85: loss=0.016203180122492212
Epoch #86: loss=0.019589370702458628
Epoch #87: loss=0.016801555486899395
Epoch #88: loss=0.02307934082007456
Epoch #89: loss=0.017937465935660767
Epoch #90: loss=0.016191818974909598
Epoch #91: loss=0.0223919378116001
Epoch #92: loss=0.015995473231890014
Epoch #93: loss=0.021218011162052842
Epoch #94: loss=0.021517846070817994
Epoch #95: loss=0.019085779491305147
Epoch #96: loss=0.02041471629380017
Epoch #97: loss=0.013659307041656993
Epoch #98: loss=0.017360373609435896
Epoch #99: loss=0.017333883292931666
Epoch #100: loss=0.016749013388223863
Epoch #101: loss=0.01945650197127424
Epoch #102: loss=0.01336125866407179
Epoch #103: loss=0.017630485505614506
Epoch #104: loss=0.0158389531541166
Epoch #105: loss=0.015204356337783635
Epoch #106: loss=0.017882381453693825
Epoch #107: loss=0.026750059552808347
Epoch #108: loss=0.016051036388925265
Epoch #109: loss=0.012904789079739182
Epoch #110: loss=0.01231102572795015
Epoch #111: loss=0.01813079047264921
Epoch #112: loss=0.017619515068346695
Epoch #113: loss=0.018825296978328725
Epoch #114: loss=0.01844821975319225
Epoch #115: loss=0.01671999926637333
Epoch #116: loss=0.010682053673381776
Epoch #117: loss=0.016647747153453282
Epoch #118: loss=0.017310076863634723
Epoch #119: loss=0.01847078520346393
Epoch #120: loss=0.013987352487662752
Epoch #121: loss=0.014218782388916646
Epoch #122: loss=0.02605701949412443
Epoch #123: loss=0.014272937972728722
Epoch #124: loss=0.0177531992900892
Epoch #125: loss=0.01587286145958554
Epoch #126: loss=0.015556723931869831
Epoch #127: loss=0.017109367658098118
Epoch #128: loss=0.015022373120509917
Epoch #129: loss=0.012467756417311269
Epoch #130: loss=0.016331855972679696
Epoch #131: loss=0.01382345218712795
Epoch #132: loss=0.014949856447249962
Epoch #133: loss=0.020359818797487102
Epoch #134: loss=0.015540961080846771
Epoch #135: loss=0.012686706591551973
Epoch #136: loss=0.012103608596176176
Epoch #137: loss=0.012772202770848642
Epoch #138: loss=0.016391658417034532
Epoch #139: loss=0.011349275233028724
Epoch #140: loss=0.021261788853494272
Epoch #141: loss=0.019905271263317426
Epoch #142: loss=0.011841952487113592
Epoch #143: loss=0.015293297437940946
Epoch #144: loss=0.014337230080533845
Epoch #145: loss=0.013857085608042547
Epoch #146: loss=0.014718348514032961
Epoch #147: loss=0.01598292925495875
Epoch #148: loss=0.016766148599244503
Epoch #149: loss=0.017042360714245867
Epoch #150: loss=0.016259837519337895
Epoch #151: loss=0.015208024148113314
Epoch #152: loss=0.016193228022983838
Epoch #153: loss=0.012409250438553857
Epoch #154: loss=0.012375351892119668
Epoch #155: loss=0.011861268745565161
Epoch #156: loss=0.011742281093183498
Epoch #157: loss=0.017128231280142025
Epoch #158: loss=0.012965209801172762
Epoch #159: loss=0.013585507347457683
Epoch #160: loss=0.01717535450032534
Epoch #161: loss=0.012398308660704864
Epoch #162: loss=0.01221196221912544
Epoch #163: loss=0.017483963109601687
Epoch #164: loss=0.016530863725456663
Epoch #165: loss=0.031064032817454228
Epoch #166: loss=0.022383746054104713
Epoch #167: loss=0.010963751536973385
Epoch #168: loss=0.01421955685175518
Epoch #169: loss=0.015359008057865574
Epoch #170: loss=0.014005975798029395
Epoch #171: loss=0.013901748477967525
Epoch #172: loss=0.012466920831096287
Epoch #173: loss=0.012417042354833274
Epoch #174: loss=0.014554812216005138
Epoch #175: loss=0.01423697872007051
Epoch #176: loss=0.013486947262108175
Epoch #177: loss=0.01412863050770322
Epoch #178: loss=0.013304934426739959
Epoch #179: loss=0.014433999686861959
Epoch #180: loss=0.01196364356208658
Epoch #181: loss=0.013053482009279624
Epoch #182: loss=0.02497630206429953
Epoch #183: loss=0.007431024725720591
Epoch #184: loss=0.01568859442204384
Epoch #185: loss=0.011746303803267145
Epoch #186: loss=0.013536370640248471
Epoch #187: loss=0.014602851136784155
Epoch #188: loss=0.017410659014733577
Epoch #189: loss=0.016019226217013578
Epoch #190: loss=0.01212967676047925
Epoch #191: loss=0.014127820860341379
Epoch #192: loss=0.009510652928920997
Epoch #193: loss=0.012785188717248224
Epoch #194: loss=0.015327564963102065
Epoch #195: loss=0.018224665707375066
Epoch #196: loss=0.00995409717978257
Epoch #197: loss=0.010204489921491668
Epoch #198: loss=0.013661465994156918
Epoch #199: loss=0.01173035397574539
Epoch #200: loss=0.01317223637419029
Epoch #201: loss=0.015893917577105593
Epoch #202: loss=0.015554903712074547
Epoch #203: loss=0.0150250934092945
Epoch #204: loss=0.009065311440871488
Epoch #205: loss=0.01249109805107955
Epoch #206: loss=0.015336401750587769
Epoch #207: loss=0.014221024416164402
Epoch #208: loss=0.01657403645253556
Epoch #209: loss=0.011732585905618332
Epoch #210: loss=0.010380225596015565
Epoch #211: loss=0.013050962819942174
Epoch #212: loss=0.012291058524898585
Epoch #213: loss=0.014425283913875262
Epoch #214: loss=0.007797857331663972
Epoch #215: loss=0.012231012556215422
Epoch #216: loss=0.017864744612103158
Epoch #217: loss=0.01567451983506066
Epoch #218: loss=0.010146860926481817
Epoch #219: loss=0.01004307596292745
Epoch #220: loss=0.010799753132132196
Epoch #221: loss=0.010375984432644758
Epoch #222: loss=0.01338646054828373
Epoch #223: loss=0.010027240401332547
Epoch #224: loss=0.009926945054479035
Epoch #225: loss=0.012674776158814944
Epoch #226: loss=0.014347987528453492
Epoch #227: loss=0.00956172770461097
Epoch #228: loss=0.018968078679266764
Epoch #229: loss=0.006931334219056502
Epoch #230: loss=0.014837137673829768
Epoch #231: loss=0.018661612846141283
Epoch #232: loss=0.008590735631229595
Epoch #233: loss=0.011710309119763137
Epoch #234: loss=0.00997282114240601
Epoch #235: loss=0.007807467412344894
Epoch #236: loss=0.011743583804494421
Epoch #237: loss=0.017487871456004868
Epoch #238: loss=0.009657656758730444
Epoch #239: loss=0.010250091071323068
Epoch #240: loss=0.00861860361709244
Epoch #241: loss=0.012825594972302545
Epoch #242: loss=0.014018621627156181
Epoch #243: loss=0.011486219221334925
Epoch #244: loss=0.009548490649847226
Epoch #245: loss=0.014095406808273182
Epoch #246: loss=0.020024248393588247
Epoch #247: loss=0.01120086001456745
Epoch #248: loss=0.01071747170788404
Epoch #249: loss=0.012165029661942075

Training time: 3:36:06.277179

Finished.
n2one setting etth2_ettm2_traffic_weather -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm2_traffic_weather_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_ettm2_traffic_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.88928e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.04229e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.1601e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.88928e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4130789689971523, 'MAE': 0.45503526911376735}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm2_traffic_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm2_traffic_weather_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_ettm2_traffic_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.79968e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3668681105806435, 'MAE': 0.40486065511828395}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm2_traffic_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm2_traffic_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.0264369013744432
Epoch #1: loss=0.38388274289533364
Epoch #2: loss=0.2793126043670618
Epoch #3: loss=0.2263604048303924
Epoch #4: loss=0.17531826459123073
Epoch #5: loss=0.15094265230377582
Epoch #6: loss=0.13384156907816325
Epoch #7: loss=0.10347205297161431
Epoch #8: loss=0.09621457704384853
Epoch #9: loss=0.09941508861149552
Epoch #10: loss=0.07827537204086495
Epoch #11: loss=0.0728713250236569
Epoch #12: loss=0.0759050554741669
Epoch #13: loss=0.060885789570281165
Epoch #14: loss=0.06475044243239067
Epoch #15: loss=0.06302725067514263
Epoch #16: loss=0.05485154807500474
Epoch #17: loss=0.04932984760002787
Epoch #18: loss=0.04911663969989178
Epoch #19: loss=0.040733502447544305
Epoch #20: loss=0.04393351258660734
Epoch #21: loss=0.043342538115564266
Epoch #22: loss=0.04917663220656503
Epoch #23: loss=0.04279723159731827
Epoch #24: loss=0.041415247576403524
Epoch #25: loss=0.034405506293993096
Epoch #26: loss=0.04043056391182708
Epoch #27: loss=0.03313819878104852
Epoch #28: loss=0.03550330773302719
Epoch #29: loss=0.034579916582663066
Epoch #30: loss=0.02667996008194923
Epoch #31: loss=0.03746495179901201
Epoch #32: loss=0.04453151120171307
Epoch #33: loss=0.03524682865997772
Epoch #34: loss=0.029574372549751052
Epoch #35: loss=0.033747259389660486
Epoch #36: loss=0.028969043352812116
Epoch #37: loss=0.03163417876275416
Epoch #38: loss=0.02869718106297581
Epoch #39: loss=0.03554989724688238
Epoch #40: loss=0.03460478058427274
Epoch #41: loss=0.03390775943858767
Epoch #42: loss=0.03194676163076184
Epoch #43: loss=0.02363826631296212
Epoch #44: loss=0.03050525192756558
Epoch #45: loss=0.027255431089305365
Epoch #46: loss=0.025621037750121055
Epoch #47: loss=0.028671902015966234
Epoch #48: loss=0.025260841759928054
Epoch #49: loss=0.021047506725579722
Epoch #50: loss=0.025624012221964518
Epoch #51: loss=0.026375172899074765
Epoch #52: loss=0.02287243945518328
Epoch #53: loss=0.024467024684699853
Epoch #54: loss=0.029251908408679795
Epoch #55: loss=0.029886631859791034
Epoch #56: loss=0.026944958688578515
Epoch #57: loss=0.031814268309644504
Epoch #58: loss=0.022612546317874262
Epoch #59: loss=0.027229650582248233
Epoch #60: loss=0.02228557786542182
Epoch #61: loss=0.018669575304794545
Epoch #62: loss=0.02388557642146364
Epoch #63: loss=0.03528059653500997
Epoch #64: loss=0.022018265585257223
Epoch #65: loss=0.020074443700240908
Epoch #66: loss=0.022968001495289034
Epoch #67: loss=0.01965625341570656
Epoch #68: loss=0.026393180306488805
Epoch #69: loss=0.03500526426547482
Epoch #70: loss=0.01909799063110227
Epoch #71: loss=0.019760415217116044
Epoch #72: loss=0.019570003963782986
Epoch #73: loss=0.02966955967588604
Epoch #74: loss=0.021425230237041803
Epoch #75: loss=0.020500538370650426
Epoch #76: loss=0.017533377098565374
Epoch #77: loss=0.020322184279565763
Epoch #78: loss=0.016269440346035367
Epoch #79: loss=0.019174796200188523
Epoch #80: loss=0.02626254117641512
Epoch #81: loss=0.018886984105143004
Epoch #82: loss=0.01894954130133359
Epoch #83: loss=0.021467016435053665
Epoch #84: loss=0.024225754328105174
Epoch #85: loss=0.019252879386922443
Epoch #86: loss=0.020375318521227863
Epoch #87: loss=0.01671971173989011
Epoch #88: loss=0.01803830766774817
Epoch #89: loss=0.019205883367019623
Epoch #90: loss=0.018085041774414806
Epoch #91: loss=0.02333104602305186
Epoch #92: loss=0.016900002414823156
Epoch #93: loss=0.019583550901098444
Epoch #94: loss=0.021367216265266383
Epoch #95: loss=0.024441666921562945
Epoch #96: loss=0.01338004326149727
Epoch #97: loss=0.013456795618162482
Epoch #98: loss=0.02124810031084774
Epoch #99: loss=0.019455513139496564
Epoch #100: loss=0.016183687584572483
Epoch #101: loss=0.02321092365322706
Epoch #102: loss=0.01964738680334785
Epoch #103: loss=0.01891431257729539
Epoch #104: loss=0.01621775599608202
Epoch #105: loss=0.015196165360517166
Epoch #106: loss=0.01885721598493448
Epoch #107: loss=0.016114031261151452
Epoch #108: loss=0.016234068872067797
Epoch #109: loss=0.018151468665359768
Epoch #110: loss=0.015091300195398706
Epoch #111: loss=0.014766433674217828
Epoch #112: loss=0.015515319510168492
Epoch #113: loss=0.015163839015774618
Epoch #114: loss=0.04249654033405891
Epoch #115: loss=0.015913517819180024
Epoch #116: loss=0.013961774106212181
Epoch #117: loss=0.016201915110221243
Epoch #118: loss=0.02301677785303705
Epoch #119: loss=0.017193742332843563
Epoch #120: loss=0.014061186222009768
Epoch #121: loss=0.014581872798255456
Epoch #122: loss=0.015767334341463286
Epoch #123: loss=0.016989127456163097
Epoch #124: loss=0.016044627832613786
Epoch #125: loss=0.015160591488286931
Epoch #126: loss=0.013502817703910468
Epoch #127: loss=0.02070204703517988
Epoch #128: loss=0.018639749418988695
Epoch #129: loss=0.02146458849974888
Epoch #130: loss=0.015588223334791994
Epoch #131: loss=0.016043411641091167
Epoch #132: loss=0.012807986858755251
Epoch #133: loss=0.017025628486858745
Epoch #134: loss=0.015512128170509665
Epoch #135: loss=0.01755913591435413
Epoch #136: loss=0.014152512846464503
Epoch #137: loss=0.02096680013271104
Epoch #138: loss=0.016256857808846625
Epoch #139: loss=0.015603000853819115
Epoch #140: loss=0.020839385159585316
Epoch #141: loss=0.02261810262260386
Epoch #142: loss=0.011637707168349382
Epoch #143: loss=0.013546347406395603
Epoch #144: loss=0.01955498305061803
Epoch #145: loss=0.01690479847184998
Epoch #146: loss=0.0170604108990029
Epoch #147: loss=0.013159129093093053
Epoch #148: loss=0.015435129575052997
Epoch #149: loss=0.014173808111524055
Epoch #150: loss=0.014645805210035702
Epoch #151: loss=0.0142146482756305
Epoch #152: loss=0.019384144132509554
Epoch #153: loss=0.01800374007753153
Epoch #154: loss=0.020034344809319666
Epoch #155: loss=0.016894522231489868
Epoch #156: loss=0.013986279171919566
Epoch #157: loss=0.01494275688254437
Epoch #158: loss=0.016194955473520577
Epoch #159: loss=0.013121949046191898
Epoch #160: loss=0.01522214803641488
Epoch #161: loss=0.011646371114218235
Epoch #162: loss=0.013347903336326199
Epoch #163: loss=0.015675225670559297
Epoch #164: loss=0.014240825994502384
Epoch #165: loss=0.015029309430214166
Epoch #166: loss=0.022304279783080954
Epoch #167: loss=0.012418646118742611
Epoch #168: loss=0.016543774243112788
Epoch #169: loss=0.01216759024815097
Epoch #170: loss=0.01871464155067827
Epoch #171: loss=0.015759524418909505
Epoch #172: loss=0.01144434255823128
Epoch #173: loss=0.015193550033186225
Epoch #174: loss=0.023787650630356028
Epoch #175: loss=0.011761457215536278
Epoch #176: loss=0.015437716857828031
Epoch #177: loss=0.022580580987925862
Epoch #178: loss=0.011112955397349963
Epoch #179: loss=0.013360422219799753
Epoch #180: loss=0.012644771059795685
Epoch #181: loss=0.015537096197206396
Epoch #182: loss=0.01220498540879071
Epoch #183: loss=0.013826308379066177
Epoch #184: loss=0.012600511004829723
Epoch #185: loss=0.01419887027883748
Epoch #186: loss=0.017650068107081803
Epoch #187: loss=0.012466283758053701
Epoch #188: loss=0.017374261296116945
Epoch #189: loss=0.012041141950363567
Epoch #190: loss=0.01562157153662033
Epoch #191: loss=0.014806797105323698
Epoch #192: loss=0.011581440461324402
Epoch #193: loss=0.014473997287471296
Epoch #194: loss=0.014036659116181335
Epoch #195: loss=0.01377017232523219
Epoch #196: loss=0.012555184850236139
Epoch #197: loss=0.011421382307326148
Epoch #198: loss=0.01391424679281995
Epoch #199: loss=0.012806805036070564
Epoch #200: loss=0.013186121002322866
Epoch #201: loss=0.010175666803915446
Epoch #202: loss=0.017083053311924577
Epoch #203: loss=0.012657051370452947
Epoch #204: loss=0.009774396559084568
Epoch #205: loss=0.02393346643273961
Epoch #206: loss=0.01371627289842542
Epoch #207: loss=0.012743062585893009
Epoch #208: loss=0.01931958137464716
Epoch #209: loss=0.01274147015147219
Epoch #210: loss=0.013659419342140018
Epoch #211: loss=0.009782768883179326
Epoch #212: loss=0.011682415505912341
Epoch #213: loss=0.011975906923809718
Epoch #214: loss=0.011258978815972156
Epoch #215: loss=0.014241932447967466
Epoch #216: loss=0.012793543417337624
Epoch #217: loss=0.009076857989376541
Epoch #218: loss=0.011634489060442493
Epoch #219: loss=0.01981382357776097
Epoch #220: loss=0.013984541395312827
Epoch #221: loss=0.012927295525907932
Epoch #222: loss=0.012643094255156586
Epoch #223: loss=0.010647915045902246
Epoch #224: loss=0.012910590039593427
Epoch #225: loss=0.015848818747693807
Epoch #226: loss=0.00965666590665015
Epoch #227: loss=0.014934014513290766
Epoch #228: loss=0.013149422893007254
Epoch #229: loss=0.009283910945882084
Epoch #230: loss=0.012710906678614003
Epoch #231: loss=0.009887142424197812
Epoch #232: loss=0.016754287151392468
Epoch #233: loss=0.0129571414685956
Epoch #234: loss=0.015100825351501946
Epoch #235: loss=0.016632648247888265
Epoch #236: loss=0.014463664210419305
Epoch #237: loss=0.010702614820065964
Epoch #238: loss=0.016856715110456257
Epoch #239: loss=0.015025736462121131
Epoch #240: loss=0.008873040128401864
Epoch #241: loss=0.013179637941780006
Epoch #242: loss=0.015349412798215027
Epoch #243: loss=0.011923769370352258
Epoch #244: loss=0.009512523739040993
Epoch #245: loss=0.009991571573066124
Epoch #246: loss=0.010537490027549997
Epoch #247: loss=0.0121207310995479
Epoch #248: loss=0.01598360124963775
Epoch #249: loss=0.009590459022768522

Training time: 3:26:00.790655

Finished.
n2one setting etth2_ettm2_traffic_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm2_traffic_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_ettm2_traffic_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.11717e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.39145e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.84701e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.11717e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4165995591596811, 'MAE': 0.4624532441013787}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm2_traffic_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm2_traffic_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_ettm2_traffic_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.9797e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.90324e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.9797e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.5875123952533982, 'MAE': 0.5793781722188746}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm2_weather_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm2_weather_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=6.034943516437824
Epoch #1: loss=2.7870630209262552
Epoch #2: loss=2.2512833636540632
Epoch #3: loss=2.1684545163924875
Epoch #4: loss=2.001241209415289
Epoch #5: loss=2.011337855687508
Epoch #6: loss=1.895446580189925
Epoch #7: loss=1.7809693584075341
Epoch #8: loss=1.6439888867048116
Epoch #9: loss=1.5437585138357603
Epoch #10: loss=1.5083919442616975
Epoch #11: loss=1.3329437856490796
Epoch #12: loss=1.2633038724844272
Epoch #13: loss=1.2168808052173028
Epoch #14: loss=1.2539565803912969
Epoch #15: loss=1.0906957582785533
Epoch #16: loss=1.0715481581596227
Epoch #17: loss=1.054679980644813
Epoch #18: loss=1.040358834541761
Epoch #19: loss=0.9931619247564902
Epoch #20: loss=0.9402764198871759
Epoch #21: loss=0.9560753405094147
Epoch #22: loss=0.910507572384981
Epoch #23: loss=0.9429410787729117
Epoch #24: loss=0.9086375935719564
Epoch #25: loss=0.8049268218187186
Epoch #26: loss=0.7886246992991521
Epoch #27: loss=0.8688123535651427
Epoch #28: loss=0.7685312984081415
Epoch #29: loss=0.7558703411083955
Epoch #30: loss=0.7169199924056346
Epoch #31: loss=0.6976943004589814
Epoch #32: loss=0.6484050034330442
Epoch #33: loss=0.7183923532183354
Epoch #34: loss=0.7105186822322699
Epoch #35: loss=0.6488955003710893
Epoch #36: loss=0.6907510161399841
Epoch #37: loss=0.6848334383506042
Epoch #38: loss=0.6336698297124642
Epoch #39: loss=0.6537126589279908
Epoch #40: loss=0.6282191276550293
Epoch #41: loss=0.6229173947985356
Epoch #42: loss=0.6251048623369291
Epoch #43: loss=0.540052208189781
Epoch #44: loss=0.5201830606047924
Epoch #45: loss=0.582076718027775
Epoch #46: loss=0.5136930432457191
Epoch #47: loss=0.5392514679294366
Epoch #48: loss=0.546577510352318
Epoch #49: loss=0.5337819755077362
Epoch #50: loss=0.5011424278983703
Epoch #51: loss=0.5287010274254359
Epoch #52: loss=0.4952739213521664
Epoch #53: loss=0.4905366891851792
Epoch #54: loss=0.5180536488500925
Epoch #55: loss=0.46805578326949704
Epoch #56: loss=0.5073443525112592
Epoch #57: loss=0.5254383889528421
Epoch #58: loss=0.46086854487657547
Epoch #59: loss=0.45582314781271493
Epoch #60: loss=0.47303154004307896
Epoch #61: loss=0.43206468854959196
Epoch #62: loss=0.40757306636526036
Epoch #63: loss=0.41350891441106796
Epoch #64: loss=0.3904401373404723
Epoch #65: loss=0.4794957239467364
Epoch #66: loss=0.41822210756632
Epoch #67: loss=0.4036346166752852
Epoch #68: loss=0.38905125627150905
Epoch #69: loss=0.41657790828209657
Epoch #70: loss=0.38694700455436337
Epoch #71: loss=0.35673444202313054
Epoch #72: loss=0.33703492839749044
Epoch #73: loss=0.3259303622807448
Epoch #74: loss=0.35045888217595905
Epoch #75: loss=0.31755548557982993
Epoch #76: loss=0.2986750943729511
Epoch #77: loss=0.2903582972402756
Epoch #78: loss=0.3336431139077132
Epoch #79: loss=0.2977992386485522
Epoch #80: loss=0.29637556637708956
Epoch #81: loss=0.3163697990373923
Epoch #82: loss=0.3208258750920112
Epoch #83: loss=0.32183281160317934
Epoch #84: loss=0.2823864731651086
Epoch #85: loss=0.3222659839173922
Epoch #86: loss=0.3378593104963119
Epoch #87: loss=0.24849881489689535
Epoch #88: loss=0.33339058177975506
Epoch #89: loss=0.30393043919824636
Epoch #90: loss=0.2495003521728974
Epoch #91: loss=0.22965593005602175
Epoch #92: loss=0.22839524073956105
Epoch #93: loss=0.32736373893343484
Epoch #94: loss=0.3142287116497755
Epoch #95: loss=0.3667312224323933
Epoch #96: loss=0.3615718479626454
Epoch #97: loss=0.2730213822080539
Epoch #98: loss=0.2662988078708832
Epoch #99: loss=0.24540844903542444
Epoch #100: loss=0.2648351532048904
Epoch #101: loss=0.2067479296372487
Epoch #102: loss=0.2231808346337997
Epoch #103: loss=0.17537024803459644
Epoch #104: loss=0.19896880601747677
Epoch #105: loss=0.2069774425516908
Epoch #106: loss=0.2687078851919908
Epoch #107: loss=0.19089304741758567
Epoch #108: loss=0.25074024584430915
Epoch #109: loss=0.2774592208174559
Epoch #110: loss=0.18553542976195997
Epoch #111: loss=0.21325046518960825
Epoch #112: loss=0.2298412317266831
Epoch #113: loss=0.19254488182755616
Epoch #114: loss=0.21141449820536834
Epoch #115: loss=0.19782159226731613
Epoch #116: loss=0.19985693105711386
Epoch #117: loss=0.18573186618204302
Epoch #118: loss=0.14917097634707505
Epoch #119: loss=0.2101777153662764
Epoch #120: loss=0.18352693426780975
Epoch #121: loss=0.17376594460354403
Epoch #122: loss=0.16138073347079065
Epoch #123: loss=0.1865508697497157
Epoch #124: loss=0.1680889191249242
Epoch #125: loss=0.16455833749988905
Epoch #126: loss=0.1596369115062631
Epoch #127: loss=0.17973852580269942
Epoch #128: loss=0.25228403243594444
Epoch #129: loss=0.2547687406723316
Epoch #130: loss=0.2346395438966843
Epoch #131: loss=0.17592150868418124
Epoch #132: loss=0.17805944648213112
Epoch #133: loss=0.152865326211143
Epoch #134: loss=0.1356610763244904
Epoch #135: loss=0.19643756926346284
Epoch #136: loss=0.41692687671345013
Epoch #137: loss=0.290314954562256
Epoch #138: loss=0.2010245333927182
Epoch #139: loss=0.16929337590073162
Epoch #140: loss=0.1999045071693567
Epoch #141: loss=0.14142078161239624
Epoch #142: loss=0.23222665839756912
Epoch #143: loss=0.1787051153011047
Epoch #144: loss=0.17071186615010867
Epoch #145: loss=0.15694399969652295
Epoch #146: loss=0.11240310393846951
Epoch #147: loss=0.13876789779617235
Epoch #148: loss=0.1437494597541025
Epoch #149: loss=0.13398883842791504
Epoch #150: loss=0.1395415449873186
Epoch #151: loss=0.1324433793242161
Epoch #152: loss=0.31825526459858966
Epoch #153: loss=0.13892995551801646
Epoch #154: loss=0.13239615525190646
Epoch #155: loss=0.17078192435348263
Epoch #156: loss=0.16612713099815524
Epoch #157: loss=0.1586136368031685
Epoch #158: loss=0.14048764048717344
Epoch #159: loss=0.15701531045711958
Epoch #160: loss=0.15542949890144742
Epoch #161: loss=0.11704906710208608
Epoch #162: loss=0.18039128965196702
Epoch #163: loss=0.18915633183832353
Epoch #164: loss=0.16833582223178103
Epoch #165: loss=0.12651400425686285
Epoch #166: loss=0.11477262204369673
Epoch #167: loss=0.11147269327193499
Epoch #168: loss=0.1357497525616334
Epoch #169: loss=0.11205574905929658
Epoch #170: loss=0.13330912615100926
Epoch #171: loss=0.1155719615232486
Epoch #172: loss=0.12250405431796725
Epoch #173: loss=0.15678774307553583
Epoch #174: loss=0.14169808136872375
Epoch #175: loss=0.1361382122223194
Epoch #176: loss=0.12992911982851532
Epoch #177: loss=0.09227628282342966
Epoch #178: loss=0.10828102852862614
Epoch #179: loss=0.11618486709462908
Epoch #180: loss=0.11976190903582253
Epoch #181: loss=0.10917204346221226
Epoch #182: loss=0.12065016338601708
Epoch #183: loss=0.09370335596255384
Epoch #184: loss=0.10700208724189836
Epoch #185: loss=0.1031426413056369
Epoch #186: loss=0.10307450474311526
Epoch #187: loss=0.07890862113652894
Epoch #188: loss=0.08467077288346794
Epoch #189: loss=0.11632893768210824
Epoch #190: loss=0.10632171764826545
Epoch #191: loss=0.12295050818759662
Epoch #192: loss=0.21874729443628055
Epoch #193: loss=0.12774424645333335
Epoch #194: loss=0.19133051413183028
Epoch #195: loss=0.12876966806988305
Epoch #196: loss=0.1398126082136654
Epoch #197: loss=0.09481789605118908
Epoch #198: loss=0.1332069786193852
Epoch #199: loss=0.10305565341304128
Epoch #200: loss=0.09200275879210004
Epoch #201: loss=0.12404491902830508
Epoch #202: loss=0.07112181158019946
Epoch #203: loss=0.07738180494365784
Epoch #204: loss=0.11092991657698384
Epoch #205: loss=0.08940593498902252
Epoch #206: loss=0.08297598603754662
Epoch #207: loss=0.0958354281118283
Epoch #208: loss=0.09432998652426669
Epoch #209: loss=0.1763154762940338
Epoch #210: loss=0.15326275415002152
Epoch #211: loss=0.14871298177884176
Epoch #212: loss=0.13829537040482348
Epoch #213: loss=0.08787606977141248
Epoch #214: loss=0.09989903303078161
Epoch #215: loss=0.12792485644324467
Epoch #216: loss=0.0980196321526399
Epoch #217: loss=0.08565716807229015
Epoch #218: loss=0.09584001055918634
Epoch #219: loss=0.0958998490196581
Epoch #220: loss=0.11002339775530764
Epoch #221: loss=0.09240869891185027
Epoch #222: loss=0.09306912425045784
Epoch #223: loss=0.08706409487730035
Epoch #224: loss=0.08626092490381919
Epoch #225: loss=0.07930280583409163
Epoch #226: loss=0.08165991179143581
Epoch #227: loss=0.0890533179223824
Epoch #228: loss=0.09269648969459993
Epoch #229: loss=0.09922459015909296
Epoch #230: loss=0.10598231418631397
Epoch #231: loss=0.0889374682894693
Epoch #232: loss=0.1119365085883496
Epoch #233: loss=0.10166343147508226
Epoch #234: loss=0.1536791413807525
Epoch #235: loss=0.12690602952184585
Epoch #236: loss=0.10413156578747126
Epoch #237: loss=0.0991735767501478
Epoch #238: loss=0.07865361099203046
Epoch #239: loss=0.07518454479913299
Epoch #240: loss=0.0930413269939331
Epoch #241: loss=0.07717932810863623
Epoch #242: loss=0.1058133862232073
Epoch #243: loss=0.09263708161261792
Epoch #244: loss=0.13616065673816663
Epoch #245: loss=0.39831829834013033
Epoch #246: loss=0.21216922604407257
Epoch #247: loss=0.12737045204266906
Epoch #248: loss=0.18215686544919243
Epoch #249: loss=0.168725470546633

Training time: 0:16:04.134770

Finished.
n2one setting etth2_ettm2_weather_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm2_weather_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_ettm2_weather_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.78247e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.47665e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.78247e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.38549878662145964, 'MAE': 0.43671816348741854}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_electricity_traffic_weather', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_electricity_traffic_weather_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.862224301690922
Epoch #1: loss=0.3492129690283419
Epoch #2: loss=0.2412103151620709
Epoch #3: loss=0.1853231145252817
Epoch #4: loss=0.14277104529441872
Epoch #5: loss=0.1269242467640556
Epoch #6: loss=0.09714682970202136
Epoch #7: loss=0.08784713747292316
Epoch #8: loss=0.08593073941607911
Epoch #9: loss=0.08271847770696408
Epoch #10: loss=0.06763175796865988
Epoch #11: loss=0.05651667268638879
Epoch #12: loss=0.05430810870836324
Epoch #13: loss=0.04525626162323629
Epoch #14: loss=0.05122310108938683
Epoch #15: loss=0.057464513920039234
Epoch #16: loss=0.046288117334992614
Epoch #17: loss=0.03942743842851901
Epoch #18: loss=0.034490077976538726
Epoch #19: loss=0.04066815151552299
Epoch #20: loss=0.03617961597716969
Epoch #21: loss=0.04616563165243286
Epoch #22: loss=0.02943854111483808
Epoch #23: loss=0.03739009296125579
Epoch #24: loss=0.028340894640438676
Epoch #25: loss=0.02951229712935425
Epoch #26: loss=0.027001792365090774
Epoch #27: loss=0.036360701269825914
Epoch #28: loss=0.028772111118039328
Epoch #29: loss=0.025494212523546212
Epoch #30: loss=0.029850933610807835
Epoch #31: loss=0.03358556394299452
Epoch #32: loss=0.023972572436641235
Epoch #33: loss=0.02316959366558685
Epoch #34: loss=0.02467550827431727
Epoch #35: loss=0.020151043368873377
Epoch #36: loss=0.022477156561044945
Epoch #37: loss=0.022179704414587543
Epoch #38: loss=0.02702794013868314
Epoch #39: loss=0.02370498990311669
Epoch #40: loss=0.023714376526569186
Epoch #41: loss=0.029119755246220416
Epoch #42: loss=0.037331251575348064
Epoch #43: loss=0.02471741822362099
Epoch #44: loss=0.01794476489289752
Epoch #45: loss=0.02380645448642769
Epoch #46: loss=0.019527087664611923
Epoch #47: loss=0.01683541211921118
Epoch #48: loss=0.02760091515876028
Epoch #49: loss=0.018196843594140727
Epoch #50: loss=0.018202819236600925
Epoch #51: loss=0.018230953806730548
Epoch #52: loss=0.017333165895682835
Epoch #53: loss=0.017332427054689584
Epoch #54: loss=0.021192078907401275
Epoch #55: loss=0.028170073279110704
Epoch #56: loss=0.01753854057362428
Epoch #57: loss=0.01970534159657913
Epoch #58: loss=0.018311512012228616
Epoch #59: loss=0.015163915513192862
Epoch #60: loss=0.020394922712248922
Epoch #61: loss=0.013381656930337877
Epoch #62: loss=0.024726906298143916
Epoch #63: loss=0.01852510525297571
Epoch #64: loss=0.016410750904134675
Epoch #65: loss=0.014583181335302996
Epoch #66: loss=0.018032742002596455
Epoch #67: loss=0.017191105175123466
Epoch #68: loss=0.019258710136838136
Epoch #69: loss=0.018527095339705785
Epoch #70: loss=0.01537791640339492
Epoch #71: loss=0.01781149305038286
Epoch #72: loss=0.015437096432833641
Epoch #73: loss=0.018262921396123937
Epoch #74: loss=0.022656203811110526
Epoch #75: loss=0.01922992549129719
Epoch #76: loss=0.012394744617100323
Epoch #77: loss=0.02718232329176604
Epoch #78: loss=0.014250859184812725
Epoch #79: loss=0.012543056951998503
Epoch #80: loss=0.011403718740217826
Epoch #81: loss=0.02204228752242144
Epoch #82: loss=0.017566663228798893
Epoch #83: loss=0.015485500873773025
Epoch #84: loss=0.013904051293282368
Epoch #85: loss=0.014978201446769833
Epoch #86: loss=0.017071113184795792
Epoch #87: loss=0.013162106314020525
Epoch #88: loss=0.012987055763867255
Epoch #89: loss=0.014278533970690134
Epoch #90: loss=0.017249264218830114
Epoch #91: loss=0.018987038867276408
Epoch #92: loss=0.020003998064255842
Epoch #93: loss=0.017229037102448563
Epoch #94: loss=0.018888410527157055
Epoch #95: loss=0.01361324433704986
Epoch #96: loss=0.023322065998914503
Epoch #97: loss=0.016702718615808982
Epoch #98: loss=0.013724871072458643
Epoch #99: loss=0.014293275755562718
Epoch #100: loss=0.014860691134919378
Epoch #101: loss=0.012185372383400088
Epoch #102: loss=0.014437403859287051
Epoch #103: loss=0.014847036311996482
Epoch #104: loss=0.01083828085168199
Epoch #105: loss=0.012326835035477606
Epoch #106: loss=0.014133116346890892
Epoch #107: loss=0.014571764099053709
Epoch #108: loss=0.020027967476045506
Epoch #109: loss=0.011006331262634424
Epoch #110: loss=0.014919745042358332
Epoch #111: loss=0.01149637015946849
Epoch #112: loss=0.013163335373304252
Epoch #113: loss=0.01186669320409955
Epoch #114: loss=0.0147118912282167
Epoch #115: loss=0.016761569560033326
Epoch #116: loss=0.012814635864575203
Epoch #117: loss=0.014343421932177367
Epoch #118: loss=0.01411874124271076
Epoch #119: loss=0.015369802044006065
Epoch #120: loss=0.01183091959411573
Epoch #121: loss=0.017057453290015855
Epoch #122: loss=0.009104809539466211
Epoch #123: loss=0.014804953661265143
Epoch #124: loss=0.02618310491238605
Epoch #125: loss=0.012737173027409497
Epoch #126: loss=0.01371940715568455
Epoch #127: loss=0.012668019007522065
Epoch #128: loss=0.014121618427069686
Epoch #129: loss=0.011093097887815498
Epoch #130: loss=0.012148103287305085
Epoch #131: loss=0.01331003557910854
Epoch #132: loss=0.015703975964625944
Epoch #133: loss=0.013448119656411444
Epoch #134: loss=0.0114648728399396
Epoch #135: loss=0.013092482322630722
Epoch #136: loss=0.010523247472184792
Epoch #137: loss=0.01764893861163249
Epoch #138: loss=0.009745109502797564
Epoch #139: loss=0.015322492468784862
Epoch #140: loss=0.011018233340947566
Epoch #141: loss=0.01871124491330384
Epoch #142: loss=0.01584427573814202
Epoch #143: loss=0.01248607230624992
Epoch #144: loss=0.012253204552076855
Epoch #145: loss=0.010416478414143919
Epoch #146: loss=0.012325327011275908
Epoch #147: loss=0.009136516629867305
Epoch #148: loss=0.013030326600743903
Epoch #149: loss=0.019894399555764004
Epoch #150: loss=0.009071024631363176
Epoch #151: loss=0.01346820940267734
Epoch #152: loss=0.011443497154363956
Epoch #153: loss=0.025639604135257718
Epoch #154: loss=0.01581535898538421
Epoch #155: loss=0.012003689816861209
Epoch #156: loss=0.012927703769073082
Epoch #157: loss=0.010294813799051002
Epoch #158: loss=0.013953480436867949
Epoch #159: loss=0.010911971417325922
Epoch #160: loss=0.012618493073506218
Epoch #161: loss=0.01140203059707059
Epoch #162: loss=0.010609541315596672
Epoch #163: loss=0.010675744853110222
Epoch #164: loss=0.011946295482438904
Epoch #165: loss=0.02231535657048617
Epoch #166: loss=0.016635182359742
Epoch #167: loss=0.007914573173991357
Epoch #168: loss=0.010048476974170148
Epoch #169: loss=0.012158742070560516
Epoch #170: loss=0.012148333755308877
Epoch #171: loss=0.012093285865232343
Epoch #172: loss=0.014032082617225234
Epoch #173: loss=0.009859799558745707
Epoch #174: loss=0.01283939865152206
Epoch #175: loss=0.008308374160211124
Epoch #176: loss=0.016252568677947766
Epoch #177: loss=0.010605062052054325
Epoch #178: loss=0.010550941420385578
Epoch #179: loss=0.01774504537424467
Epoch #180: loss=0.014838171529043776
Epoch #181: loss=0.010665105304245739
Epoch #182: loss=0.010395343023886701
Epoch #183: loss=0.009644488579373214
Epoch #184: loss=0.01166909460649597
Epoch #185: loss=0.012348431950356013
Epoch #186: loss=0.009565995063254425
Epoch #187: loss=0.013353463440065943
Epoch #188: loss=0.01128877772129942
Epoch #189: loss=0.020100356298574918
Epoch #190: loss=0.008779863141099716
Epoch #191: loss=0.013139972470861195
Epoch #192: loss=0.00808743895590537
Epoch #193: loss=0.014384952234877346
Epoch #194: loss=0.008054686006364352
Epoch #195: loss=0.011905383039483672
Epoch #196: loss=0.008517588755233575
Epoch #197: loss=0.010337626132899172
Epoch #198: loss=0.013804840071688468
Epoch #199: loss=0.01035448370211387
Epoch #200: loss=0.011377164404345757
Epoch #201: loss=0.011627447035009123
Epoch #202: loss=0.012944653089909096
Epoch #203: loss=0.013165203788802452
Epoch #204: loss=0.008357333429887004
Epoch #205: loss=0.012406453310811565
Epoch #206: loss=0.014399954841529075
Epoch #207: loss=0.010237216268023985
Epoch #208: loss=0.01471184752019302
Epoch #209: loss=0.010555597959958692
Epoch #210: loss=0.014169421822543882
Epoch #211: loss=0.009139257618051332
Epoch #212: loss=0.009373533046910828
Epoch #213: loss=0.01342316323399772
Epoch #214: loss=0.009158694232897497
Epoch #215: loss=0.01107002280012861
Epoch #216: loss=0.009894325309915075
Epoch #217: loss=0.011134119764045337
Epoch #218: loss=0.012422551973534274
Epoch #219: loss=0.009803789117576775
Epoch #220: loss=0.006172862299892083
Epoch #221: loss=0.012207519159741614
Epoch #222: loss=0.008834158567280707
Epoch #223: loss=0.010536368802339786
Epoch #224: loss=0.01349225279298145
Epoch #225: loss=0.025483671998774514
Epoch #226: loss=0.012116033569590831
Epoch #227: loss=0.009133993225215195
Epoch #228: loss=0.008661093318443435
Epoch #229: loss=0.01241158248363885
Epoch #230: loss=0.010186646866462692
Epoch #231: loss=0.019186121723961197
Epoch #232: loss=0.009075355090532722
Epoch #233: loss=0.010259701500564532
Epoch #234: loss=0.013145286828070743
Epoch #235: loss=0.01086027598571012
Epoch #236: loss=0.010894651756709544
Epoch #237: loss=0.01104550889141664
Epoch #238: loss=0.014468624981262971
Epoch #239: loss=0.008354702688369511
Epoch #240: loss=0.01006502382310708
Epoch #241: loss=0.011736984955590694
Epoch #242: loss=0.008648383991624686
Epoch #243: loss=0.01219011984320679
Epoch #244: loss=0.0111256629140706
Epoch #245: loss=0.006618726165602072
Epoch #246: loss=0.01254484821903421
Epoch #247: loss=0.00868037077325904
Epoch #248: loss=0.0131164195301913
Epoch #249: loss=0.014668791902534539

Training time: 4:56:02.276995

Finished.
n2one setting etth2_electricity_traffic_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_electricity_traffic_weather_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_electricity_traffic_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.95807e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.29051147437116387, 'MAE': 0.3576453809532559}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_electricity_traffic_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_electricity_traffic_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.8368665541029334
Epoch #1: loss=0.301389924205454
Epoch #2: loss=0.2109277318410563
Epoch #3: loss=0.15550318661337106
Epoch #4: loss=0.11550581067931125
Epoch #5: loss=0.09827764546389821
Epoch #6: loss=0.09185595010859715
Epoch #7: loss=0.06649120304871892
Epoch #8: loss=0.06145414312794581
Epoch #9: loss=0.063688389617617
Epoch #10: loss=0.0579131735929557
Epoch #11: loss=0.05564092550790544
Epoch #12: loss=0.0422073212309969
Epoch #13: loss=0.05336878352463463
Epoch #14: loss=0.04841267702248234
Epoch #15: loss=0.04064322514820981
Epoch #16: loss=0.04136614649434526
Epoch #17: loss=0.035963107211315515
Epoch #18: loss=0.03665361861785398
Epoch #19: loss=0.033074265343501684
Epoch #20: loss=0.03752921499605003
Epoch #21: loss=0.03387414632526029
Epoch #22: loss=0.03113131320427789
Epoch #23: loss=0.03445182091298782
Epoch #24: loss=0.03069627729961874
Epoch #25: loss=0.031191202785853973
Epoch #26: loss=0.03579541753207136
Epoch #27: loss=0.024733109207707653
Epoch #28: loss=0.02789015922972735
Epoch #29: loss=0.033369575387855385
Epoch #30: loss=0.024215331101884913
Epoch #31: loss=0.026910488042023846
Epoch #32: loss=0.027383506998646372
Epoch #33: loss=0.025300857695591136
Epoch #34: loss=0.021857432830363174
Epoch #35: loss=0.02524961397056281
Epoch #36: loss=0.018993187950120793
Epoch #37: loss=0.024879384750373216
Epoch #38: loss=0.025874513823673898
Epoch #39: loss=0.022683500229184344
Epoch #40: loss=0.026846080490546178
Epoch #41: loss=0.023801333872429973
Epoch #42: loss=0.025423783240134352
Epoch #43: loss=0.024399519066716186
Epoch #44: loss=0.019027419629967762
Epoch #45: loss=0.02336214923313745
Epoch #46: loss=0.02733025431875155
Epoch #47: loss=0.01689030453457302
Epoch #48: loss=0.02336451787026778
Epoch #49: loss=0.019223888374543214
Epoch #50: loss=0.01993245885456533
Epoch #51: loss=0.01934996788059198
Epoch #52: loss=0.01946130851474618
Epoch #53: loss=0.018588501671187266
Epoch #54: loss=0.018810637046624588
Epoch #55: loss=0.018222834698453864
Epoch #56: loss=0.02303310774256225
Epoch #57: loss=0.019069779353173145
Epoch #58: loss=0.017950581440811693
Epoch #59: loss=0.018316561092600422
Epoch #60: loss=0.016840430895661087
Epoch #61: loss=0.018596540208411706
Epoch #62: loss=0.015909473972728565
Epoch #63: loss=0.017753499850270436
Epoch #64: loss=0.01601051566765709
Epoch #65: loss=0.01780464265774236
Epoch #66: loss=0.022746234068202743
Epoch #67: loss=0.01931931784439957
Epoch #68: loss=0.017502751442020136
Epoch #69: loss=0.014532858985815335
Epoch #70: loss=0.015254556213277983
Epoch #71: loss=0.015695474468231746
Epoch #72: loss=0.020394223299021685
Epoch #73: loss=0.01688499418973537
Epoch #74: loss=0.0190232557281088
Epoch #75: loss=0.013667501666588368
Epoch #76: loss=0.02073881072397437
Epoch #77: loss=0.017433775618289696
Epoch #78: loss=0.016374574502225916
Epoch #79: loss=0.01688406515803063
Epoch #80: loss=0.012897397726435077
Epoch #81: loss=0.015696212307120306
Epoch #82: loss=0.015613085464583142
Epoch #83: loss=0.017189851767631895
Epoch #84: loss=0.01899613133612066
Epoch #85: loss=0.01505106638290337
Epoch #86: loss=0.017682919405335257
Epoch #87: loss=0.014349413942924634
Epoch #88: loss=0.017220180786035676
Epoch #89: loss=0.02150214348485513
Epoch #90: loss=0.027466235616483814
Epoch #91: loss=0.01582991506086444
Epoch #92: loss=0.012235287824697239
Epoch #93: loss=0.01381469723635986
Epoch #94: loss=0.019367159258766458
Epoch #95: loss=0.012602579692708645
Epoch #96: loss=0.023194266177062994
Epoch #97: loss=0.017947441473389853
Epoch #98: loss=0.013316370437909205
Epoch #99: loss=0.01435734534834182
Epoch #100: loss=0.01808626836928413
Epoch #101: loss=0.015223039818256848
Epoch #102: loss=0.01248006379572991
Epoch #103: loss=0.012907042796534055
Epoch #104: loss=0.014916300247832456
Epoch #105: loss=0.014350203137817786
Epoch #106: loss=0.014301185369775716
Epoch #107: loss=0.015574328913509836
Epoch #108: loss=0.014010839046517723
Epoch #109: loss=0.01768756838683416
Epoch #110: loss=0.01276319007455715
Epoch #111: loss=0.011216055101944166
Epoch #112: loss=0.013441031795659355
Epoch #113: loss=0.012208624484209606
Epoch #114: loss=0.016666001907442128
Epoch #115: loss=0.013788978250792292
Epoch #116: loss=0.02075543340567351
Epoch #117: loss=0.017342755229013428
Epoch #118: loss=0.013079569202370456
Epoch #119: loss=0.014342840901558103
Epoch #120: loss=0.015463924928514275
Epoch #121: loss=0.013390905265134676
Epoch #122: loss=0.013509494108587148
Epoch #123: loss=0.014640031390677079
Epoch #124: loss=0.013805140096026446
Epoch #125: loss=0.015230789797488722
Epoch #126: loss=0.01570314171301117
Epoch #127: loss=0.012572412767432664
Epoch #128: loss=0.015174204039126782
Epoch #129: loss=0.011667078740941243
Epoch #130: loss=0.0164168887011371
Epoch #131: loss=0.021723608962631976
Epoch #132: loss=0.012189210055557077
Epoch #133: loss=0.013189708336484028
Epoch #134: loss=0.013417336635108596
Epoch #135: loss=0.013696063124085544
Epoch #136: loss=0.014938568942007001
Epoch #137: loss=0.014643342098356158
Epoch #138: loss=0.013712572414260953
Epoch #139: loss=0.009102321577299026
Epoch #140: loss=0.017080845930092722
Epoch #141: loss=0.012906529131563706
Epoch #142: loss=0.011291742509048089
Epoch #143: loss=0.014166858747901
Epoch #144: loss=0.014194031493656278
Epoch #145: loss=0.012334898801423548
Epoch #146: loss=0.01459583328226006
Epoch #147: loss=0.010889534531947818
Epoch #148: loss=0.016159087539472088
Epoch #149: loss=0.012118794680778568
Epoch #150: loss=0.01253669736346188
Epoch #151: loss=0.010061036746517064
Epoch #152: loss=0.013099266967003682
Epoch #153: loss=0.012752198505648066
Epoch #154: loss=0.010409992348589994
Epoch #155: loss=0.012747425627746022
Epoch #156: loss=0.014548827818721589
Epoch #157: loss=0.01733752542137406
Epoch #158: loss=0.012049617338911025
Epoch #159: loss=0.010905455958078932
Epoch #160: loss=0.011455665621449798
Epoch #161: loss=0.010672539767201578
Epoch #162: loss=0.018080202500292242
Epoch #163: loss=0.008837217735626093
Epoch #164: loss=0.009952023918841512
Epoch #165: loss=0.01401048353558833
Epoch #166: loss=0.017853620238180424
Epoch #167: loss=0.012207544466338932
Epoch #168: loss=0.011665613998655117
Epoch #169: loss=0.013642018454886485
Epoch #170: loss=0.010609642851880978
Epoch #171: loss=0.013398744801505106
Epoch #172: loss=0.019942018712827244
Epoch #173: loss=0.013044988022713326
Epoch #174: loss=0.016791057326720243
Epoch #175: loss=0.008036598527372672
Epoch #176: loss=0.010326513114456438
Epoch #177: loss=0.01044368252184475
Epoch #178: loss=0.014103776851509781
Epoch #179: loss=0.010825811266209266
Epoch #180: loss=0.012454002267054383
Epoch #181: loss=0.011295106335311236
Epoch #182: loss=0.007927685457133625
Epoch #183: loss=0.009479987749366656
Epoch #184: loss=0.012845778075285787
Epoch #185: loss=0.014214192436774707
Epoch #186: loss=0.011723481582469721
Epoch #187: loss=0.010780942399479517
Epoch #188: loss=0.00999116411380198
Epoch #189: loss=0.011095222189934233
Epoch #190: loss=0.013802648990706367
Epoch #191: loss=0.016689867630663314
Epoch #192: loss=0.009063989547183713
Epoch #193: loss=0.011364191185258067
Epoch #194: loss=0.008537004124356679
Epoch #195: loss=0.012089698980995787
Epoch #196: loss=0.010161235754616995
Epoch #197: loss=0.008749123162066
Epoch #198: loss=0.01197231153244089
Epoch #199: loss=0.009782044029236754
Epoch #200: loss=0.0101779188668732
Epoch #201: loss=0.014606926386720363
Epoch #202: loss=0.021315353156663306
Epoch #203: loss=0.010445314262918226
Epoch #204: loss=0.010094996362463287
Epoch #205: loss=0.014984440603492443
Epoch #206: loss=0.012781404319789415
Epoch #207: loss=0.009790047631406215
Epoch #208: loss=0.010249212939553203
Epoch #209: loss=0.013875784418451702
Epoch #210: loss=0.01019986772006327
Epoch #211: loss=0.009106180563570697
Epoch #212: loss=0.014995112356427398
Epoch #213: loss=0.012893291989255427
Epoch #214: loss=0.0102531553472085
Epoch #215: loss=0.01232649724748225
Epoch #216: loss=0.010488271035098716
Epoch #217: loss=0.013289228134687706
Epoch #218: loss=0.012379572808072795
Epoch #219: loss=0.0098188434259375
Epoch #220: loss=0.010369298739776343
Epoch #221: loss=0.010302493935434393
Epoch #222: loss=0.011863788814053701
Epoch #223: loss=0.010681758708434885
Epoch #224: loss=0.010159847136260008
Epoch #225: loss=0.010344824536589055
Epoch #226: loss=0.011647840041630005
Epoch #227: loss=0.013939168105421892
Epoch #228: loss=0.008552846245884106
Epoch #229: loss=0.011755262164171444
Epoch #230: loss=0.010738954780176701
Epoch #231: loss=0.012009265031324481
Epoch #232: loss=0.014201361520563463
Epoch #233: loss=0.010712323398719473
Epoch #234: loss=0.009208207854746542
Epoch #235: loss=0.011745967920244755
Epoch #236: loss=0.008479465077111255
Epoch #237: loss=0.010227660482251308
Epoch #238: loss=0.00934048033963099
Epoch #239: loss=0.011245783168665783
Epoch #240: loss=0.00835271633621108
Epoch #241: loss=0.011111764026136128
Epoch #242: loss=0.012962456748402795
Epoch #243: loss=0.008996911759595225
Epoch #244: loss=0.009611622961055338
Epoch #245: loss=0.010585462186414202
Epoch #246: loss=0.009909944154977299
Epoch #247: loss=0.01158804533058503
Epoch #248: loss=0.012622184921980164
Epoch #249: loss=0.009893692423631702

Training time: 4:59:39.056901

Finished.
n2one setting etth2_electricity_traffic_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_electricity_traffic_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_electricity_traffic_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.54895e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.05539e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.54895e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.5069726247816481, 'MAE': 0.5310553506976575}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_electricity_weather_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_electricity_weather_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.7964557300615047
Epoch #1: loss=0.8439886090834496
Epoch #2: loss=0.5947394123228874
Epoch #3: loss=0.49019087105989456
Epoch #4: loss=0.4300921970556454
Epoch #5: loss=0.3674832940595585
Epoch #6: loss=0.3546387267952466
Epoch #7: loss=0.3126635618137391
Epoch #8: loss=0.27524000620315087
Epoch #9: loss=0.24997247111319837
Epoch #10: loss=0.2258540652898135
Epoch #11: loss=0.24606048610081988
Epoch #12: loss=0.2150592025348824
Epoch #13: loss=0.1874125719749631
Epoch #14: loss=0.16519162040306717
Epoch #15: loss=0.17530219750839043
Epoch #16: loss=0.1622224492200995
Epoch #17: loss=0.15391072242916948
Epoch #18: loss=0.14568423157177082
Epoch #19: loss=0.144380918868627
Epoch #20: loss=0.11226626332252394
Epoch #21: loss=0.12088698846447533
Epoch #22: loss=0.12790705121600826
Epoch #23: loss=0.10557217678847564
Epoch #24: loss=0.10315988542131298
Epoch #25: loss=0.08753915766037959
Epoch #26: loss=0.08542981277636731
Epoch #27: loss=0.08605205659492157
Epoch #28: loss=0.11051388888347133
Epoch #29: loss=0.09730289521169184
Epoch #30: loss=0.07121381737569667
Epoch #31: loss=0.0677555973824237
Epoch #32: loss=0.08133456758249201
Epoch #33: loss=0.06413281383893314
Epoch #34: loss=0.059032913979184067
Epoch #35: loss=0.06627420214061415
Epoch #36: loss=0.07050505732777863
Epoch #37: loss=0.06912849606169151
Epoch #38: loss=0.06437202849880747
Epoch #39: loss=0.07367757907476873
Epoch #40: loss=0.06618431642090707
Epoch #41: loss=0.07338731911275227
Epoch #42: loss=0.05082659439559388
Epoch #43: loss=0.054899435009272225
Epoch #44: loss=0.05742945732196371
Epoch #45: loss=0.05704434124948406
Epoch #46: loss=0.04585740674294799
Epoch #47: loss=0.04671816189274274
Epoch #48: loss=0.037209254138953776
Epoch #49: loss=0.0583338949685268
Epoch #50: loss=0.06594262319200193
Epoch #51: loss=0.0597134489811782
Epoch #52: loss=0.04309247855292582
Epoch #53: loss=0.03363678926436066
Epoch #54: loss=0.04899875883454231
Epoch #55: loss=0.038432604726532586
Epoch #56: loss=0.04455399944335068
Epoch #57: loss=0.04294943698560973
Epoch #58: loss=0.046991000155203085
Epoch #59: loss=0.03811099840706286
Epoch #60: loss=0.03791637855835352
Epoch #61: loss=0.031396316851936897
Epoch #62: loss=0.04131498331820222
Epoch #63: loss=0.054278460888575394
Epoch #64: loss=0.03302991132667411
Epoch #65: loss=0.035509900401220325
Epoch #66: loss=0.030125699194150757
Epoch #67: loss=0.04414252142064294
Epoch #68: loss=0.03696500597771216
Epoch #69: loss=0.03656296796571896
Epoch #70: loss=0.03740085062933623
Epoch #71: loss=0.036823314821697484
Epoch #72: loss=0.04714047385460712
Epoch #73: loss=0.0495675855871928
Epoch #74: loss=0.0375576126312024
Epoch #75: loss=0.03564230470213195
Epoch #76: loss=0.043605244644204906
Epoch #77: loss=0.03933904730864075
Epoch #78: loss=0.035713758636060175
Epoch #79: loss=0.03185500468362833
Epoch #80: loss=0.03577127620591962
Epoch #81: loss=0.04985260271411955
Epoch #82: loss=0.030181689433578546
Epoch #83: loss=0.030923671171118026
Epoch #84: loss=0.023986141121166742
Epoch #85: loss=0.02988512213284006
Epoch #86: loss=0.03072490240817051
Epoch #87: loss=0.030167858174214787
Epoch #88: loss=0.031488240535775563
Epoch #89: loss=0.02903432354397907
Epoch #90: loss=0.02927160098247014
Epoch #91: loss=0.026573498857635953
Epoch #92: loss=0.025207361325078764
Epoch #93: loss=0.05029114704734764
Epoch #94: loss=0.03849361939690184
Epoch #95: loss=0.03572593551825022
Epoch #96: loss=0.03956531965622719
Epoch #97: loss=0.022158260123890397
Epoch #98: loss=0.02163819345074464
Epoch #99: loss=0.02200782947108479
Epoch #100: loss=0.030651212860611447
Epoch #101: loss=0.04128704316999624
Epoch #102: loss=0.02405041534224016
Epoch #103: loss=0.025354921743814006
Epoch #104: loss=0.02425855265940586
Epoch #105: loss=0.02077989588611893
Epoch #106: loss=0.028647446871776318
Epoch #107: loss=0.03384410972045786
Epoch #108: loss=0.03622349210547216
Epoch #109: loss=0.03695659598628913
Epoch #110: loss=0.028385706825724683
Epoch #111: loss=0.029198691041147057
Epoch #112: loss=0.025478619676133494
Epoch #113: loss=0.020514270669886155
Epoch #114: loss=0.02452075015174647
Epoch #115: loss=0.028755113178573405
Epoch #116: loss=0.024766410043969934
Epoch #117: loss=0.026403133259270628
Epoch #118: loss=0.028270522321771203
Epoch #119: loss=0.054132655545141684
Epoch #120: loss=0.03027263641819224
Epoch #121: loss=0.03105280760647369
Epoch #122: loss=0.024767175406051636
Epoch #123: loss=0.022698139565841175
Epoch #124: loss=0.028091017957918286
Epoch #125: loss=0.033342441692671775
Epoch #126: loss=0.0322416115466001
Epoch #127: loss=0.02841006583458286
Epoch #128: loss=0.037633476647013255
Epoch #129: loss=0.03789086316297994
Epoch #130: loss=0.02724591179272335
Epoch #131: loss=0.019646244933018305
Epoch #132: loss=0.022355917565754835
Epoch #133: loss=0.024273288324320925
Epoch #134: loss=0.0246599837436562
Epoch #135: loss=0.02193813199738236
Epoch #136: loss=0.02360482841330704
Epoch #137: loss=0.03799081945297236
Epoch #138: loss=0.020092316201305305
Epoch #139: loss=0.02152247721337693
Epoch #140: loss=0.01891635995659236
Epoch #141: loss=0.038036922299050986
Epoch #142: loss=0.041036816558913836
Epoch #143: loss=0.024050374417269902
Epoch #144: loss=0.015987247826376522
Epoch #145: loss=0.017318106276685504
Epoch #146: loss=0.014632874227788825
Epoch #147: loss=0.01803668004039994
Epoch #148: loss=0.019482683302263486
Epoch #149: loss=0.023708371336196257
Epoch #150: loss=0.03557144418678462
Epoch #151: loss=0.017810967645687643
Epoch #152: loss=0.020106907155382762
Epoch #153: loss=0.01499185974044643
Epoch #154: loss=0.02039072734402822
Epoch #155: loss=0.025034574993747127
Epoch #156: loss=0.0240063524389516
Epoch #157: loss=0.032510522359053384
Epoch #158: loss=0.02486631043820683
Epoch #159: loss=0.0393422456256896
Epoch #160: loss=0.030306562733256326
Epoch #161: loss=0.03203975914341387
Epoch #162: loss=0.023009728536122986
Epoch #163: loss=0.01441536938508867
Epoch #164: loss=0.025024715261418085
Epoch #165: loss=0.01640630185119139
Epoch #166: loss=0.018961318656326224
Epoch #167: loss=0.028166086265035178
Epoch #168: loss=0.034672576983784745
Epoch #169: loss=0.019289965372795023
Epoch #170: loss=0.020008081322965516
Epoch #171: loss=0.01438836114724213
Epoch #172: loss=0.025334418719462043
Epoch #173: loss=0.023885674271118332
Epoch #174: loss=0.02231000798808421
Epoch #175: loss=0.029698937243424376
Epoch #176: loss=0.01862807039271793
Epoch #177: loss=0.01657530911791316
Epoch #178: loss=0.021472768062141656
Epoch #179: loss=0.02360170354194507
Epoch #180: loss=0.01777463522820106
Epoch #181: loss=0.022467035233739052
Epoch #182: loss=0.01846045861623664
Epoch #183: loss=0.021753007551373462
Epoch #184: loss=0.02336885971345203
Epoch #185: loss=0.022153846003328714
Epoch #186: loss=0.020097111750719553
Epoch #187: loss=0.018382855240790717
Epoch #188: loss=0.025731431379803656
Epoch #189: loss=0.02662445921309354
Epoch #190: loss=0.022861555263075917
Epoch #191: loss=0.02475062214646576
Epoch #192: loss=0.027067195755321512
Epoch #193: loss=0.015436146543628166
Epoch #194: loss=0.014990826813625981
Epoch #195: loss=0.017355299234542692
Epoch #196: loss=0.018944497958747978
Epoch #197: loss=0.01568634625859057
Epoch #198: loss=0.016665810694209252
Epoch #199: loss=0.02068504123374156
Epoch #200: loss=0.0244288510407864
Epoch #201: loss=0.028790513537528293
Epoch #202: loss=0.02193155259701799
Epoch #203: loss=0.024764884945850316
Epoch #204: loss=0.02752273674579646
Epoch #205: loss=0.027015365203533794
Epoch #206: loss=0.025009111268606644
Epoch #207: loss=0.023411915511570135
Epoch #208: loss=0.02353021504681619
Epoch #209: loss=0.06613968887243507
Epoch #210: loss=0.026643251208459846
Epoch #211: loss=0.01641358185166529
Epoch #212: loss=0.02885465105710608
Epoch #213: loss=0.03710270267898392
Epoch #214: loss=0.028001783055012778
Epoch #215: loss=0.025229542574058003
Epoch #216: loss=0.016563603303167525
Epoch #217: loss=0.01575874140476795
Epoch #218: loss=0.016732251010153402
Epoch #219: loss=0.016752642487723752
Epoch #220: loss=0.016294592320796834
Epoch #221: loss=0.01611659452058658
Epoch #222: loss=0.020171136949619778
Epoch #223: loss=0.02986713621195519
Epoch #224: loss=0.013096380744866501
Epoch #225: loss=0.017087852217653222
Epoch #226: loss=0.016259361038615448
Epoch #227: loss=0.018865621836054607
Epoch #228: loss=0.018270389869930067
Epoch #229: loss=0.01742147505302651
Epoch #230: loss=0.018790402662237974
Epoch #231: loss=0.02075135307187132
Epoch #232: loss=0.018622157035282305
Epoch #233: loss=0.026119572333013895
Epoch #234: loss=0.016658167307167338
Epoch #235: loss=0.02498052498650189
Epoch #236: loss=0.021374140104094972
Epoch #237: loss=0.021962895433631346
Epoch #238: loss=0.02475294542630095
Epoch #239: loss=0.014025133078369873
Epoch #240: loss=0.012795325574580546
Epoch #241: loss=0.017063627460503883
Epoch #242: loss=0.02411684512050735
Epoch #243: loss=0.02356080947014843
Epoch #244: loss=0.019157512561104244
Epoch #245: loss=0.021696723396703345
Epoch #246: loss=0.01608903447499895
Epoch #247: loss=0.02090409403320824
Epoch #248: loss=0.015351010772215656
Epoch #249: loss=0.01749059775276933

Training time: 1:39:56.091147

Finished.
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_traffic_weather_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_traffic_weather_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.143073435538631
Epoch #1: loss=0.43816911340881953
Epoch #2: loss=0.3126959176868167
Epoch #3: loss=0.25377995441621326
Epoch #4: loss=0.2065165411817077
Epoch #5: loss=0.1686214119410462
Epoch #6: loss=0.15996030671676725
Epoch #7: loss=0.12975500444835206
Epoch #8: loss=0.11759532792524642
Epoch #9: loss=0.09378601515774974
Epoch #10: loss=0.09706064397809513
Epoch #11: loss=0.0813285853231072
Epoch #12: loss=0.07849321234713444
Epoch #13: loss=0.08437020063363139
Epoch #14: loss=0.09331428165602212
Epoch #15: loss=0.06359645030342645
Epoch #16: loss=0.060710262002862767
Epoch #17: loss=0.06293300534768705
Epoch #18: loss=0.052171064539712465
Epoch #19: loss=0.053382318301883384
Epoch #20: loss=0.05024792384696611
Epoch #21: loss=0.050041784457980985
Epoch #22: loss=0.05021053538678352
Epoch #23: loss=0.048190107480658925
Epoch #24: loss=0.0460093162438429
Epoch #25: loss=0.03798292922567688
Epoch #26: loss=0.035574767873044914
Epoch #27: loss=0.062069988931484875
Epoch #28: loss=0.040458513442365035
Epoch #29: loss=0.04616046702986375
Epoch #30: loss=0.035335820726934274
Epoch #31: loss=0.03291736345220943
Epoch #32: loss=0.03238572289234858
Epoch #33: loss=0.04227406079679777
Epoch #34: loss=0.03257924190127824
Epoch #35: loss=0.03254866889875964
Epoch #36: loss=0.036416182355725246
Epoch #37: loss=0.04419627820246297
Epoch #38: loss=0.030635330422780375
Epoch #39: loss=0.036823283333229755
Epoch #40: loss=0.031325168060698336
Epoch #41: loss=0.03712052149001451
Epoch #42: loss=0.029936974518029957
Epoch #43: loss=0.027723457199879245
Epoch #44: loss=0.023883574686589696
Epoch #45: loss=0.033339630705789186
Epoch #46: loss=0.03136086990298231
Epoch #47: loss=0.037303549330243234
Epoch #48: loss=0.028242478264724695
Epoch #49: loss=0.03250780419803896
Epoch #50: loss=0.030796074359153026
Epoch #51: loss=0.03501795361783863
Epoch #52: loss=0.026561046044851714
Epoch #53: loss=0.02196255337255094
Epoch #54: loss=0.028431937678710374
Epoch #55: loss=0.03795605601572946
Epoch #56: loss=0.02453291913879167
Epoch #57: loss=0.025076267025152435
Epoch #58: loss=0.022135949444674483
Epoch #59: loss=0.028202972851347093
Epoch #60: loss=0.023859423755733595
Epoch #61: loss=0.02678399440623069
Epoch #62: loss=0.03239006822702402
Epoch #63: loss=0.029543159586034
Epoch #64: loss=0.026388634157914707
Epoch #65: loss=0.02598641718283207
Epoch #66: loss=0.025216009008367096
Epoch #67: loss=0.04692667330635076
Epoch #68: loss=0.02933894295633718
Epoch #69: loss=0.01914548527011426
Epoch #70: loss=0.020165207061660296
Epoch #71: loss=0.025647321386816618
Epoch #72: loss=0.02212414789943856
Epoch #73: loss=0.021997578032000212
Epoch #74: loss=0.02121360062376327
Epoch #75: loss=0.02038568930645243
Epoch #76: loss=0.02187851864570862
Epoch #77: loss=0.03699476156438673
Epoch #78: loss=0.025071880927863173
Epoch #79: loss=0.018056127929504125
Epoch #80: loss=0.019394084768344526
Epoch #81: loss=0.02413576809888875
Epoch #82: loss=0.025588370501094707
Epoch #83: loss=0.0167637507876372
Epoch #84: loss=0.01985542046526681
Epoch #85: loss=0.023988125088187873
Epoch #86: loss=0.01895367811065387
Epoch #87: loss=0.021644561692357067
Epoch #88: loss=0.017227747116677756
Epoch #89: loss=0.018423909753053587
Epoch #90: loss=0.023968716667179153
Epoch #91: loss=0.02270277858275254
Epoch #92: loss=0.020413881076687013
Epoch #93: loss=0.019004492001679692
Epoch #94: loss=0.029063336004823827
Epoch #95: loss=0.016707111857864998
Epoch #96: loss=0.017194870457571187
Epoch #97: loss=0.0168788147688849
Epoch #98: loss=0.021272084986718044
Epoch #99: loss=0.026386206094505614
Epoch #100: loss=0.035566996888990864
Epoch #101: loss=0.017039296092789886
Epoch #102: loss=0.01805447658528687
Epoch #103: loss=0.01760115084261685
Epoch #104: loss=0.025240312123249346
Epoch #105: loss=0.022329714318928447
Epoch #106: loss=0.017357477560254683
Epoch #107: loss=0.018846721696036437
Epoch #108: loss=0.022230366626130427
Epoch #109: loss=0.02192827117569917
Epoch #110: loss=0.024276506588773665
Epoch #111: loss=0.017459874171975087
Epoch #112: loss=0.023400799023151987
Epoch #113: loss=0.03256054305963183
Epoch #114: loss=0.01804568594389163
Epoch #115: loss=0.019353535599235118
Epoch #116: loss=0.017293117878930737
Epoch #117: loss=0.0233110578114204
Epoch #118: loss=0.01625871054245059
Epoch #119: loss=0.01658757541608813
Epoch #120: loss=0.02123034809679819
Epoch #121: loss=0.01925126287936241
Epoch #122: loss=0.014868449927136202
Epoch #123: loss=0.01822244075546196
Epoch #124: loss=0.01863826654036916
Epoch #125: loss=0.025799078911510405
Epoch #126: loss=0.01741766591329083
Epoch #127: loss=0.017050760822038807
Epoch #128: loss=0.015453260959781487
Epoch #129: loss=0.020016399203737267
Epoch #130: loss=0.01608043102825866
Epoch #131: loss=0.014812939216376098
Epoch #132: loss=0.016826712530248634
Epoch #133: loss=0.026069614899544957
Epoch #134: loss=0.019775220716225422
Epoch #135: loss=0.015160685380414625
Epoch #136: loss=0.011944270757419405
Epoch #137: loss=0.014004405981151734
Epoch #138: loss=0.02022719448695969
Epoch #139: loss=0.02258650283786857
Epoch #140: loss=0.026616224881861324
Epoch #141: loss=0.015081541925054539
Epoch #142: loss=0.016053840038058497
Epoch #143: loss=0.02363992847717142
Epoch #144: loss=0.016173312860989175
Epoch #145: loss=0.018901899528045336
Epoch #146: loss=0.017286359711399597
Epoch #147: loss=0.020818182118506463
Epoch #148: loss=0.024608867379233648
Epoch #149: loss=0.012963537942847094
Epoch #150: loss=0.016071986766117714
Epoch #151: loss=0.019553903866559783
Epoch #152: loss=0.016735835429743176
Epoch #153: loss=0.01570558575562646
Epoch #154: loss=0.02336614484552143
Epoch #155: loss=0.021759307466761663
Epoch #156: loss=0.0156275823570923
Epoch #157: loss=0.010733612487949936
Epoch #158: loss=0.020881744781699844
Epoch #159: loss=0.020354609884424054
Epoch #160: loss=0.02904123987920416
Epoch #161: loss=0.01968371115172651
Epoch #162: loss=0.023971484951981252
Epoch #163: loss=0.01677350077285882
Epoch #164: loss=0.015326939849357006
Epoch #165: loss=0.012627693979078099
Epoch #166: loss=0.017089816452218538
Epoch #167: loss=0.014578636848773335
Epoch #168: loss=0.01765113615364884
Epoch #169: loss=0.021630005997800517
Epoch #170: loss=0.01705871604503718
Epoch #171: loss=0.02003801726367383
Epoch #172: loss=0.014624409467303673
Epoch #173: loss=0.011387561723873008
Epoch #174: loss=0.019722377030015947
Epoch #175: loss=0.011286709755345826
Epoch #176: loss=0.016875923331691557
Epoch #177: loss=0.01726962760602514
Epoch #178: loss=0.016593386151365432
Epoch #179: loss=0.01559286384363963
Epoch #180: loss=0.01842164872945178
Epoch #181: loss=0.01669747960089282
Epoch #182: loss=0.012286214907128922
Epoch #183: loss=0.01757491128097607
Epoch #184: loss=0.012680434109894497
Epoch #185: loss=0.015417193958408416
Epoch #186: loss=0.015591546360395628
Epoch #187: loss=0.01459973027954094
Epoch #188: loss=0.017572763282051495
Epoch #189: loss=0.013398975647934625
Epoch #190: loss=0.019493508050655264
Epoch #191: loss=0.013193655590371282
Epoch #192: loss=0.015217874350408113
Epoch #193: loss=0.015951656633103627
Epoch #194: loss=0.017735456951387465
Epoch #195: loss=0.013273229485614626
Epoch #196: loss=0.0175374829874959
Epoch #197: loss=0.01483409469188521
Epoch #198: loss=0.011582319127920343
Epoch #199: loss=0.014658440732315146
Epoch #200: loss=0.02691458258191268
Epoch #201: loss=0.014618205902736365
Epoch #202: loss=0.015525399251172845
Epoch #203: loss=0.016004551065950844
Epoch #204: loss=0.019699529146976463
Epoch #205: loss=0.013361666372957602
Epoch #206: loss=0.01292042685004832
Epoch #207: loss=0.013181654243906759
Epoch #208: loss=0.0137098891035016
Epoch #209: loss=0.01354897033972645
Epoch #210: loss=0.0163243879405663
Epoch #211: loss=0.01573680205931882
Epoch #212: loss=0.010428588092256212
Epoch #213: loss=0.018205214117252465
Epoch #214: loss=0.0180047864903289
Epoch #215: loss=0.017135270532676466
Epoch #216: loss=0.010587831644513716
Epoch #217: loss=0.028636060041640196
Epoch #218: loss=0.015731113744083047
Epoch #219: loss=0.010321620816028014
Epoch #220: loss=0.013284039990471085
Epoch #221: loss=0.016390860383972528
Epoch #222: loss=0.03141977649219081
Epoch #223: loss=0.021577325217772104
Epoch #224: loss=0.013312996890352563
Epoch #225: loss=0.01075392860465372
Epoch #226: loss=0.012323228286749168
Epoch #227: loss=0.014669685656641087
Epoch #228: loss=0.013797076053683159
Epoch #229: loss=0.014535401685281727
Epoch #230: loss=0.017963253704347294
Epoch #231: loss=0.015210766653124973
Epoch #232: loss=0.012175197516183048
Epoch #233: loss=0.013061426717027091
Epoch #234: loss=0.014637368948496404
Epoch #235: loss=0.017410495276734335
Epoch #236: loss=0.014958832204241702
Epoch #237: loss=0.011773035846600999
Epoch #238: loss=0.01492424255153765
Epoch #239: loss=0.011567330838179532
Epoch #240: loss=0.014639530002632243
Epoch #241: loss=0.015645371325127142
Epoch #242: loss=0.01147815904946578
Epoch #243: loss=0.01117478808229735
Epoch #244: loss=0.011487253109719125
Epoch #245: loss=0.022758957926589524
Epoch #246: loss=0.01629424642650684
Epoch #247: loss=0.016034712407067324
Epoch #248: loss=0.012405338660006308
Epoch #249: loss=0.011270224764472047

Training time: 3:34:32.967126

Finished.
n2one setting etth2_traffic_weather_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_traffic_weather_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='etth2_traffic_weather_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.22075e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.38613e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.87464e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.22075e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4297585081511611, 'MAE': 0.46640021080360966}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='ettm1_ettm2_electricity_traffic', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/ettm1_ettm2_electricity_traffic_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.8802750832806979
Epoch #1: loss=0.31724457440287246
Epoch #2: loss=0.21977260047222075
Epoch #3: loss=0.1554249784325663
Epoch #4: loss=0.11267618981897212
Epoch #5: loss=0.09891011036345078
Epoch #6: loss=0.08401894157141818
Epoch #7: loss=0.06924664591327001
Epoch #8: loss=0.06498923945468676
Epoch #9: loss=0.05382114016872162
Epoch #10: loss=0.05573484054959816
Epoch #11: loss=0.04699758152067816
Epoch #12: loss=0.036413443868948896
Epoch #13: loss=0.05158744025125296
Epoch #14: loss=0.048623535033562745
Epoch #15: loss=0.0339492047391059
Epoch #16: loss=0.03692384941128558
Epoch #17: loss=0.03319497688893708
Epoch #18: loss=0.03403599482846999
Epoch #19: loss=0.03600695184084173
Epoch #20: loss=0.026677423183462307
Epoch #21: loss=0.027727460232080267
Epoch #22: loss=0.03801974970422283
Epoch #23: loss=0.029931442556068055
Epoch #24: loss=0.024819650091482057
Epoch #25: loss=0.026312600418295386
Epoch #26: loss=0.022155009026840113
Epoch #27: loss=0.0229676465395668
Epoch #28: loss=0.025282055473233346
Epoch #29: loss=0.025920150121741568
Epoch #30: loss=0.02355750389469602
Epoch #31: loss=0.026160031652147593
Epoch #32: loss=0.01961793766851649
Epoch #33: loss=0.01747376824399704
Epoch #34: loss=0.02405499732865724
Epoch #35: loss=0.02202727951919003
Epoch #36: loss=0.02052629363814396
Epoch #37: loss=0.018962551023872933
Epoch #38: loss=0.02443837258985065
Epoch #39: loss=0.019373178274585203
Epoch #40: loss=0.02115721563176789
Epoch #41: loss=0.018391111700967556
Epoch #42: loss=0.017541844318731962
Epoch #43: loss=0.02035534351385929
Epoch #44: loss=0.016608917109520442
Epoch #45: loss=0.02118020122986735
Epoch #46: loss=0.01717657024520005
Epoch #47: loss=0.01324846770769445
Epoch #48: loss=0.023460194984493445
Epoch #49: loss=0.01936700581092314
Epoch #50: loss=0.01637815338855559
Epoch #51: loss=0.01556481681322134
Epoch #52: loss=0.01799727369283898
Epoch #53: loss=0.019252061213248822
Epoch #54: loss=0.018990079098848697
Epoch #55: loss=0.01592370337957354
Epoch #56: loss=0.01604727266358281
Epoch #57: loss=0.016870643054033702
Epoch #58: loss=0.016529482420383185
Epoch #59: loss=0.013345702863694459
Epoch #60: loss=0.015093724634034628
Epoch #61: loss=0.01902665985570409
Epoch #62: loss=0.01598650497457793
Epoch #63: loss=0.012763868577013187
Epoch #64: loss=0.013506698386557207
Epoch #65: loss=0.015796331944005926
Epoch #66: loss=0.017931537356138755
Epoch #67: loss=0.020553548842996042
Epoch #68: loss=0.016765970007117444
Epoch #69: loss=0.015199751377297002
Epoch #70: loss=0.015193576011053167
Epoch #71: loss=0.012574142166287773
Epoch #72: loss=0.01558007756924388
Epoch #73: loss=0.014836768899620144
Epoch #74: loss=0.013556448014692647
Epoch #75: loss=0.015312110273799322
Epoch #76: loss=0.016507417562681433
Epoch #77: loss=0.010983563722975946
Epoch #78: loss=0.015382668001821682
Epoch #79: loss=0.012214023211856925
Epoch #80: loss=0.013908642532796158
Epoch #81: loss=0.014361817244062571
Epoch #82: loss=0.013683687771223215
Epoch #83: loss=0.016987179063817998
Epoch #84: loss=0.012237137824700782
Epoch #85: loss=0.01298398514513962
Epoch #86: loss=0.016394972667584478
Epoch #87: loss=0.011224843859112207
Epoch #88: loss=0.011943666822509795
Epoch #89: loss=0.014680828007070455
Epoch #90: loss=0.010825383778128563
Epoch #91: loss=0.01522174044925221
Epoch #92: loss=0.010777753297359338
Epoch #93: loss=0.012456483282878246
Epoch #94: loss=0.012613256970993861
Epoch #95: loss=0.01249116230760875
Epoch #96: loss=0.01491034827762693
Epoch #97: loss=0.014989474866803952
Epoch #98: loss=0.013526669951205054
Epoch #99: loss=0.015276266099823275
Epoch #100: loss=0.011853568905907011
Epoch #101: loss=0.012939512840396322
Epoch #102: loss=0.01057332654968962
Epoch #103: loss=0.017681013284015848
Epoch #104: loss=0.013846727644707534
Epoch #105: loss=0.010925520600685709
Epoch #106: loss=0.014431502338181466
Epoch #107: loss=0.012299358999454203
Epoch #108: loss=0.011094717088245295
Epoch #109: loss=0.012518256703460264
Epoch #110: loss=0.00844616320775677
Epoch #111: loss=0.017269665281929816
Epoch #112: loss=0.011000110569767001
Epoch #113: loss=0.012409293211424623
Epoch #114: loss=0.011610495667765496
Epoch #115: loss=0.009433285743314522
Epoch #116: loss=0.009264389138619987
Epoch #117: loss=0.013593544226856632
Epoch #118: loss=0.012097123253045225
Epoch #119: loss=0.012610103523298805
Epoch #120: loss=0.015917946947632256
Epoch #121: loss=0.015272139376683907
Epoch #122: loss=0.010869073715153695
Epoch #123: loss=0.013670827566981276
Epoch #124: loss=0.010202276536818551
Epoch #125: loss=0.011563729791041208
Epoch #126: loss=0.008546989043332594
Epoch #127: loss=0.012302986227330477
Epoch #128: loss=0.01400801032185999
Epoch #129: loss=0.013583057341880757
Epoch #130: loss=0.009611784903866973
Epoch #131: loss=0.013037863438533566
Epoch #132: loss=0.010761417613506774
Epoch #133: loss=0.010725243085984689
Epoch #134: loss=0.009826050587981472
Epoch #135: loss=0.01124733592150733
Epoch #136: loss=0.010407672931934819
Epoch #137: loss=0.011831670480971591
Epoch #138: loss=0.012406106291142442
Epoch #139: loss=0.010522258071767706
Epoch #140: loss=0.018510676719029957
Epoch #141: loss=0.011752026737812536
Epoch #142: loss=0.00938640813114623
Epoch #143: loss=0.013647880046787823
Epoch #144: loss=0.01098147549882509
Epoch #145: loss=0.013527721440645622
Epoch #146: loss=0.012594651245401933
Epoch #147: loss=0.009843787132459016
Epoch #148: loss=0.009383734817523895
Epoch #149: loss=0.015226398425440485
Epoch #150: loss=0.009333967698469402
Epoch #151: loss=0.014492551052263701
Epoch #152: loss=0.008261917134217003
Epoch #153: loss=0.01249087319444407
Epoch #154: loss=0.009456236809139484
Epoch #155: loss=0.010821107376201674
Epoch #156: loss=0.009057594231249914
Epoch #157: loss=0.011635836599712526
Epoch #158: loss=0.010327709266066713
Epoch #159: loss=0.01008282397029798
Epoch #160: loss=0.010489100587039344
Epoch #161: loss=0.017965727506704915
Epoch #162: loss=0.007875236878084614
Epoch #163: loss=0.009629920683112827
Epoch #164: loss=0.00954931975636753
Epoch #165: loss=0.008838836310121726
Epoch #166: loss=0.010837179269145665
Epoch #167: loss=0.009953927969917727
Epoch #168: loss=0.012995520379470132
Epoch #169: loss=0.008032909217140834
Epoch #170: loss=0.021229900958670323
Epoch #171: loss=0.008301251943979637
Epoch #172: loss=0.009721477942807403
Epoch #173: loss=0.009956406972528517
Epoch #174: loss=0.009422985452608421
Epoch #175: loss=0.008946500459785369
Epoch #176: loss=0.009447231969026982
Epoch #177: loss=0.011425821847862977
Epoch #178: loss=0.01035713554544498
Epoch #179: loss=0.009953343481838866
Epoch #180: loss=0.010702996442605996
Epoch #181: loss=0.02649906639827761
Epoch #182: loss=0.008585079940358618
Epoch #183: loss=0.009404135804371695
Epoch #184: loss=0.01372016699836373
Epoch #185: loss=0.010047239501558678
Epoch #186: loss=0.007738606824771738
Epoch #187: loss=0.009714126441171877
Epoch #188: loss=0.01049361130400441
Epoch #189: loss=0.009093856455031706
Epoch #190: loss=0.010648763968607583
Epoch #191: loss=0.009592348685936376
Epoch #192: loss=0.008555500644385473
Epoch #193: loss=0.012701031580942691
Epoch #194: loss=0.008036216223082038
Epoch #195: loss=0.008115700409852482
Epoch #196: loss=0.009785892593579038
Epoch #197: loss=0.008690715952729517
Epoch #198: loss=0.010364293718806669
Epoch #199: loss=0.011131621428366658
Epoch #200: loss=0.007552967650046706
Epoch #201: loss=0.011660953618332944
Epoch #202: loss=0.00701557565104823
Epoch #203: loss=0.005487504695112
Epoch #204: loss=0.009715892771572993
Epoch #205: loss=0.011310001440779538
Epoch #206: loss=0.00834942159781047
Epoch #207: loss=0.007278936340276326
Epoch #208: loss=0.01276586010985833
Epoch #209: loss=0.0109040997768931
Epoch #210: loss=0.011183830991712702
Epoch #211: loss=0.011278135883158142
Epoch #212: loss=0.010423450222245178
Epoch #213: loss=0.008980934019985839
Epoch #214: loss=0.008367445179982764
Epoch #215: loss=0.008299350108345946
Epoch #216: loss=0.012615267425537384
Epoch #217: loss=0.00765644786526491
Epoch #218: loss=0.012306718134209688
Epoch #219: loss=0.008457619325775668
Epoch #220: loss=0.0096340537729355
Epoch #221: loss=0.009055506122644887
Epoch #222: loss=0.010540057534820022
Epoch #223: loss=0.009530194861138954
Epoch #224: loss=0.00823210135336267
Epoch #225: loss=0.009576003881353939
Epoch #226: loss=0.009242612012829159
Epoch #227: loss=0.008221227716228487
Epoch #228: loss=0.00950871026869216
Epoch #229: loss=0.007960777039034871
Epoch #230: loss=0.00820488823782213
Epoch #231: loss=0.010364312802761923
Epoch #232: loss=0.009803555269121324
Epoch #233: loss=0.0068242457436873
Epoch #234: loss=0.009678750054696832
Epoch #235: loss=0.009195316328591748
Epoch #236: loss=0.007295934919616173
Epoch #237: loss=0.007271618635848472
Epoch #238: loss=0.007572432079135548
Epoch #239: loss=0.008245071895416687
Epoch #240: loss=0.010067424364339684
Epoch #241: loss=0.01123575233309585
Epoch #242: loss=0.008499106578462461
Epoch #243: loss=0.007523601752177244
Epoch #244: loss=0.013158410155154501
Epoch #245: loss=0.007310663413396371
Epoch #246: loss=0.00882012890590233
Epoch #247: loss=0.011332061758513187
Epoch #248: loss=0.010896087615105614
Epoch #249: loss=0.011130716709758945

Training time: 5:00:26.370273

Finished.
n2one setting ettm1_ettm2_electricity_traffic -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm1_ettm2_electricity_traffic_epochs_250_seed_2021/model.pkl', muti_dataset='ettm1_ettm2_electricity_traffic', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.20812e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.60871e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.20812e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.5671031631258345, 'MAE': 0.5758978599575189}
Finished.
------------------------- record done -------------------------
n2one setting ettm1_ettm2_electricity_traffic -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm1_ettm2_electricity_traffic_epochs_250_seed_2021/model.pkl', muti_dataset='ettm1_ettm2_electricity_traffic', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.10653e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.2815300116180662, 'MAE': 0.3535654716555167}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='ettm1_ettm2_electricity_weather', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/ettm1_ettm2_electricity_weather_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.8266267765182143
Epoch #1: loss=0.8229962210991195
Epoch #2: loss=0.6180934154486591
Epoch #3: loss=0.4668747676904932
Epoch #4: loss=0.4233779178321523
Epoch #5: loss=0.3838293102537067
Epoch #6: loss=0.32570759725926046
Epoch #7: loss=0.3034028714386428
Epoch #8: loss=0.2608268552921652
Epoch #9: loss=0.25970719572974416
Epoch #10: loss=0.22248940747281723
Epoch #11: loss=0.23046927475105455
Epoch #12: loss=0.20181697807943594
Epoch #13: loss=0.17417621723600843
Epoch #14: loss=0.17631932074421144
Epoch #15: loss=0.16520898262175118
Epoch #16: loss=0.15865504924399743
Epoch #17: loss=0.16005497096676813
Epoch #18: loss=0.14793631957899425
Epoch #19: loss=0.11888581861648456
Epoch #20: loss=0.1094464259247389
Epoch #21: loss=0.1072394333497134
Epoch #22: loss=0.10623342361866539
Epoch #23: loss=0.10215389248498571
Epoch #24: loss=0.09297154136860193
Epoch #25: loss=0.0925576272786552
Epoch #26: loss=0.07518919909418356
Epoch #27: loss=0.0691488235923878
Epoch #28: loss=0.06662275993232401
Epoch #29: loss=0.06819746677125212
Epoch #30: loss=0.0830748704953629
Epoch #31: loss=0.09613242417922228
Epoch #32: loss=0.059376485753037174
Epoch #33: loss=0.05417878805788431
Epoch #34: loss=0.06367986290627298
Epoch #35: loss=0.05468130309821225
Epoch #36: loss=0.08863507473316336
Epoch #37: loss=0.05177847045059833
Epoch #38: loss=0.05752971352691331
Epoch #39: loss=0.04210661836208266
Epoch #40: loss=0.047012261320082196
Epoch #41: loss=0.04334054012823254
Epoch #42: loss=0.04216363779042007
Epoch #43: loss=0.06017652004679569
Epoch #44: loss=0.04292160146118856
Epoch #45: loss=0.03404294129910306
Epoch #46: loss=0.04414303659721401
Epoch #47: loss=0.03412590735480896
Epoch #48: loss=0.039032494478296174
Epoch #49: loss=0.040208726650644046
Epoch #50: loss=0.041639613114463965
Epoch #51: loss=0.04811791912904943
Epoch #52: loss=0.0695736195852975
Epoch #53: loss=0.033899711433300866
Epoch #54: loss=0.03066018410027027
Epoch #55: loss=0.03511969575047655
Epoch #56: loss=0.03254509979018533
Epoch #57: loss=0.03339339717421277
Epoch #58: loss=0.031717387928758674
Epoch #59: loss=0.054360529521434775
Epoch #60: loss=0.03524474489255266
Epoch #61: loss=0.03697110177995763
Epoch #62: loss=0.04870778805485404
Epoch #63: loss=0.048961523552753315
Epoch #64: loss=0.042552452325899166
Epoch #65: loss=0.028452942961496287
Epoch #66: loss=0.026858031813769542
Epoch #67: loss=0.03545774150132466
Epoch #68: loss=0.027450167362611026
Epoch #69: loss=0.026141528272370335
Epoch #70: loss=0.024421067751923875
Epoch #71: loss=0.027780603249885426
Epoch #72: loss=0.030317402456452956
Epoch #73: loss=0.023002928973751037
Epoch #74: loss=0.0291005421736212
Epoch #75: loss=0.04875799135063954
Epoch #76: loss=0.04019073444149813
Epoch #77: loss=0.030382475689517935
Epoch #78: loss=0.019693719968641415
Epoch #79: loss=0.0211033538216725
Epoch #80: loss=0.02718551034283847
Epoch #81: loss=0.02102935682685016
Epoch #82: loss=0.023875464085675018
Epoch #83: loss=0.020862619110526955
Epoch #84: loss=0.025246753883901428
Epoch #85: loss=0.024153699009959412
Epoch #86: loss=0.03722434380434978
Epoch #87: loss=0.036025090502741615
Epoch #88: loss=0.03027127078875677
Epoch #89: loss=0.029860084594686725
Epoch #90: loss=0.020716759195137355
Epoch #91: loss=0.017497991951848795
Epoch #92: loss=0.021931026994091708
Epoch #93: loss=0.03430212784459471
Epoch #94: loss=0.031099407901157068
Epoch #95: loss=0.052817674653433004
Epoch #96: loss=0.04332612284369575
Epoch #97: loss=0.02538396419766725
Epoch #98: loss=0.01779450477258022
Epoch #99: loss=0.018573875626237423
Epoch #100: loss=0.02521682524868113
Epoch #101: loss=0.01356213230864955
Epoch #102: loss=0.023005489444519144
Epoch #103: loss=0.018081731210604086
Epoch #104: loss=0.018732555461246116
Epoch #105: loss=0.01877905067395883
Epoch #106: loss=0.02304998288646613
Epoch #107: loss=0.02583609915639433
Epoch #108: loss=0.03407482994464163
Epoch #109: loss=0.018869051072484027
Epoch #110: loss=0.02662921734113211
Epoch #111: loss=0.02953027146218501
Epoch #112: loss=0.020195995835741342
Epoch #113: loss=0.02531225978255494
Epoch #114: loss=0.02157049793320983
Epoch #115: loss=0.02085721900126314
Epoch #116: loss=0.02050879791042664
Epoch #117: loss=0.018073051486910147
Epoch #118: loss=0.020214639079433973
Epoch #119: loss=0.01682675972048996
Epoch #120: loss=0.015767438517981854
Epoch #121: loss=0.028640130869659334
Epoch #122: loss=0.021309584497977655
Epoch #123: loss=0.022905405517888375
Epoch #124: loss=0.023213518194117277
Epoch #125: loss=0.02704696156567866
Epoch #126: loss=0.016266705680778627
Epoch #127: loss=0.019378190536618607
Epoch #128: loss=0.016180781772338754
Epoch #129: loss=0.015197392368687918
Epoch #130: loss=0.025781232150660218
Epoch #131: loss=0.021351502225374637
Epoch #132: loss=0.019906392094942927
Epoch #133: loss=0.011555083922134475
Epoch #134: loss=0.014453225036222376
Epoch #135: loss=0.01573950030973754
Epoch #136: loss=0.02108244443219849
Epoch #137: loss=0.016583005147468712
Epoch #138: loss=0.03523087071972271
Epoch #139: loss=0.027292499882812665
Epoch #140: loss=0.020537566328465404
Epoch #141: loss=0.015533113525454762
Epoch #142: loss=0.0167930584094395
Epoch #143: loss=0.018951725985221993
Epoch #144: loss=0.027019404806669922
Epoch #145: loss=0.02227689619371693
Epoch #146: loss=0.023505159158090528
Epoch #147: loss=0.012400411721271636
Epoch #148: loss=0.013656430894939285
Epoch #149: loss=0.014224083164894857
Epoch #150: loss=0.025091336141554968
Epoch #151: loss=0.016040513095721038
Epoch #152: loss=0.02740436649804324
Epoch #153: loss=0.02166001569889208
Epoch #154: loss=0.018321122304532617
Epoch #155: loss=0.023639724096775477
Epoch #156: loss=0.022374842082923858
Epoch #157: loss=0.019786213420212855
Epoch #158: loss=0.016466759455700714
Epoch #159: loss=0.027777013566873735
Epoch #160: loss=0.01636686065782563
Epoch #161: loss=0.016884530839563264
Epoch #162: loss=0.016875822979800382
Epoch #163: loss=0.011245303176899332
Epoch #164: loss=0.029817331361938974
Epoch #165: loss=0.013554231395255925
Epoch #166: loss=0.011392052089533615
Epoch #167: loss=0.020957821643492334
Epoch #168: loss=0.014426046720867457
Epoch #169: loss=0.020113268239943558
Epoch #170: loss=0.013083478575635469
Epoch #171: loss=0.013746304473957062
Epoch #172: loss=0.01043826672552989
Epoch #173: loss=0.012514532273108402
Epoch #174: loss=0.010005164292841635
Epoch #175: loss=0.015704579011860197
Epoch #176: loss=0.016209179288165034
Epoch #177: loss=0.013718407876618575
Epoch #178: loss=0.018143048990444662
Epoch #179: loss=0.018005492631661475
Epoch #180: loss=0.03293940872297847
Epoch #181: loss=0.015295126839152217
Epoch #182: loss=0.014356640871547335
Epoch #183: loss=0.021320655939123797
Epoch #184: loss=0.021913273587159127
Epoch #185: loss=0.015227888486642128
Epoch #186: loss=0.014657270744348925
Epoch #187: loss=0.015300062701148977
Epoch #188: loss=0.008938472037491336
Epoch #189: loss=0.012195143643432224
Epoch #190: loss=0.021005918132551368
Epoch #191: loss=0.0163047328417197
Epoch #192: loss=0.01417248849526709
Epoch #193: loss=0.015603306917644038
Epoch #194: loss=0.013310149461008875
Epoch #195: loss=0.01708639283263223
Epoch #196: loss=0.016589053065723017
Epoch #197: loss=0.011186422676754721
Epoch #198: loss=0.01557442899111931
Epoch #199: loss=0.020337855854045808
Epoch #200: loss=0.01789089658585955
Epoch #201: loss=0.01574915563523628
Epoch #202: loss=0.01450894678833069
Epoch #203: loss=0.012078133159314552
Epoch #204: loss=0.015218719033187451
Epoch #205: loss=0.024914337598168492
Epoch #206: loss=0.014145133567457831
Epoch #207: loss=0.018338487518422538
Epoch #208: loss=0.011641968728161763
Epoch #209: loss=0.025508633431906593
Epoch #210: loss=0.015195267028894609
Epoch #211: loss=0.011647785384855346
Epoch #212: loss=0.015522933183654355
Epoch #213: loss=0.01551448716151056
Epoch #214: loss=0.012860523628371926
Epoch #215: loss=0.018936554408745164
Epoch #216: loss=0.016770613151678163
Epoch #217: loss=0.023445076225461124
Epoch #218: loss=0.03074154553403018
Epoch #219: loss=0.016096879666618154
Epoch #220: loss=0.012867344647370214
Epoch #221: loss=0.010525826044771239
Epoch #222: loss=0.016448644730391808
Epoch #223: loss=0.009638436939419048
Epoch #224: loss=0.011513904107215266
Epoch #225: loss=0.01218127527117709
Epoch #226: loss=0.014530096769390936
Epoch #227: loss=0.014397557872488873
Epoch #228: loss=0.01910949434993882
Epoch #229: loss=0.01620377266319244
Epoch #230: loss=0.010711954937500722
Epoch #231: loss=0.009653830537029862
Epoch #232: loss=0.011991892176078314
Epoch #233: loss=0.02830035942997834
Epoch #234: loss=0.01663718945589699
Epoch #235: loss=0.01861552617163713
Epoch #236: loss=0.012152689448756552
Epoch #237: loss=0.012887946299723977
Epoch #238: loss=0.012426490334905609
Epoch #239: loss=0.014108452304874656
Epoch #240: loss=0.01577618321767304
Epoch #241: loss=0.015877771626515592
Epoch #242: loss=0.014075375454680777
Epoch #243: loss=0.016473044390660184
Epoch #244: loss=0.014913451320508768
Epoch #245: loss=0.012730441652228905
Epoch #246: loss=0.010655185356161993
Epoch #247: loss=0.018303550875333686
Epoch #248: loss=0.016306391354337296
Epoch #249: loss=0.013003231736081765

Training time: 1:44:46.014676

Finished.
n2one setting ettm1_ettm2_electricity_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm1_ettm2_electricity_weather_epochs_250_seed_2021/model.pkl', muti_dataset='ettm1_ettm2_electricity_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.54595e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.2698001393681557, 'MAE': 0.3471629322155517}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='ettm1_ettm2_electricity_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/ettm1_ettm2_electricity_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.7473172149766885
Epoch #1: loss=0.7490654692181156
Epoch #2: loss=0.5370780190511307
Epoch #3: loss=0.42886390556127596
Epoch #4: loss=0.3793444829618829
Epoch #5: loss=0.3455835056101155
Epoch #6: loss=0.2855339790681149
Epoch #7: loss=0.2578395933889256
Epoch #8: loss=0.23039641842628136
Epoch #9: loss=0.22515097901522263
Epoch #10: loss=0.1935442055328789
Epoch #11: loss=0.1831728972579509
Epoch #12: loss=0.1666844053422114
Epoch #13: loss=0.15829458968591825
Epoch #14: loss=0.15290453820423014
Epoch #15: loss=0.13853968988753793
Epoch #16: loss=0.12864241833424467
Epoch #17: loss=0.11943117540297854
Epoch #18: loss=0.10391453442368073
Epoch #19: loss=0.11135929770650942
Epoch #20: loss=0.09735781034757184
Epoch #21: loss=0.0909591443953436
Epoch #22: loss=0.09521358761872746
Epoch #23: loss=0.08864595947861459
Epoch #24: loss=0.09228089456035202
Epoch #25: loss=0.08174359854682219
Epoch #26: loss=0.07307936071001651
Epoch #27: loss=0.06853373488543975
Epoch #28: loss=0.05966805265765329
Epoch #29: loss=0.07194333564506
Epoch #30: loss=0.058870023158259496
Epoch #31: loss=0.06658665558583292
Epoch #32: loss=0.07467623815694001
Epoch #33: loss=0.0882577740539534
Epoch #34: loss=0.05769613102487052
Epoch #35: loss=0.049609709870033075
Epoch #36: loss=0.05184011390708663
Epoch #37: loss=0.05043911486346689
Epoch #38: loss=0.05335404237989665
Epoch #39: loss=0.052251031634230644
Epoch #40: loss=0.0595487361466061
Epoch #41: loss=0.0666567197008499
Epoch #42: loss=0.06921663518432539
Epoch #43: loss=0.045677528750453875
Epoch #44: loss=0.049621393391000176
Epoch #45: loss=0.03514247043907345
Epoch #46: loss=0.06772173959178122
Epoch #47: loss=0.04322522323236315
Epoch #48: loss=0.039422181173575314
Epoch #49: loss=0.04639161623280729
Epoch #50: loss=0.05116870258457194
Epoch #51: loss=0.052025584910301084
Epoch #52: loss=0.05027961452886929
Epoch #53: loss=0.03252255656170072
Epoch #54: loss=0.03271266718811629
Epoch #55: loss=0.0340943600063045
Epoch #56: loss=0.040990886896347195
Epoch #57: loss=0.05112536482418757
Epoch #58: loss=0.0512865433572895
Epoch #59: loss=0.04533647206025543
Epoch #60: loss=0.04016191425416194
Epoch #61: loss=0.03836845047805097
Epoch #62: loss=0.04246029661679136
Epoch #63: loss=0.03205219755928295
Epoch #64: loss=0.03229991172339523
Epoch #65: loss=0.08469982889674582
Epoch #66: loss=0.03935700286102834
Epoch #67: loss=0.043546023801834116
Epoch #68: loss=0.03755506587531842
Epoch #69: loss=0.05008594479353467
Epoch #70: loss=0.037660388098207126
Epoch #71: loss=0.03299832447833963
Epoch #72: loss=0.03472796130787443
Epoch #73: loss=0.025713232351517425
Epoch #74: loss=0.03705070869356362
Epoch #75: loss=0.03270194497744837
Epoch #76: loss=0.03312924371613057
Epoch #77: loss=0.032340027874486886
Epoch #78: loss=0.03568685860399613
Epoch #79: loss=0.044813260932564415
Epoch #80: loss=0.03236143610641185
Epoch #81: loss=0.026091013675684272
Epoch #82: loss=0.035549561347828336
Epoch #83: loss=0.031020222821450682
Epoch #84: loss=0.025713381897114175
Epoch #85: loss=0.02262219382573365
Epoch #86: loss=0.02498365565006783
Epoch #87: loss=0.02382701699571562
Epoch #88: loss=0.02784626380135133
Epoch #89: loss=0.04365646165723984
Epoch #90: loss=0.044627609311807315
Epoch #91: loss=0.03318217420483544
Epoch #92: loss=0.030122478825552256
Epoch #93: loss=0.026064889842811495
Epoch #94: loss=0.0246570061874361
Epoch #95: loss=0.025805112255068544
Epoch #96: loss=0.02776686162913372
Epoch #97: loss=0.02240520713176244
Epoch #98: loss=0.02993517120248052
Epoch #99: loss=0.03192383827402143
Epoch #100: loss=0.03446604098800962
Epoch #101: loss=0.04336412388140182
Epoch #102: loss=0.03797058069427097
Epoch #103: loss=0.02866692106608312
Epoch #104: loss=0.026301934333396094
Epoch #105: loss=0.021259198263267644
Epoch #106: loss=0.024005698950721105
Epoch #107: loss=0.02033984973068824
Epoch #108: loss=0.01927801468237131
Epoch #109: loss=0.02652978980608624
Epoch #110: loss=0.022607424352988018
Epoch #111: loss=0.020117192148387517
Epoch #112: loss=0.02199751641213273
Epoch #113: loss=0.020654651064570314
Epoch #114: loss=0.01984170560563843
Epoch #115: loss=0.022732606900761704
Epoch #116: loss=0.03460312196689703
Epoch #117: loss=0.026146444361365036
Epoch #118: loss=0.02150553359087567
Epoch #119: loss=0.020837348808887338
Epoch #120: loss=0.020264269776796216
Epoch #121: loss=0.024934136680694843
Epoch #122: loss=0.029460646166662524
Epoch #123: loss=0.02856265283700482
Epoch #124: loss=0.01798188204341767
Epoch #125: loss=0.019654398558839114
Epoch #126: loss=0.01739365219299753
Epoch #127: loss=0.021658689779643383
Epoch #128: loss=0.02928555655681881
Epoch #129: loss=0.023548534052098898
Epoch #130: loss=0.015475788056861046
Epoch #131: loss=0.012618910551450594
Epoch #132: loss=0.019941176400596856
Epoch #133: loss=0.020404876054077543
Epoch #134: loss=0.020400545795639165
Epoch #135: loss=0.02120333642531664
Epoch #136: loss=0.02293291476543892
Epoch #137: loss=0.04045368792844719
Epoch #138: loss=0.02311239353357217
Epoch #139: loss=0.020927753457016817
Epoch #140: loss=0.016404184167196394
Epoch #141: loss=0.03990356644988325
Epoch #142: loss=0.021628441219748742
Epoch #143: loss=0.01827390560443497
Epoch #144: loss=0.020463359426273208
Epoch #145: loss=0.02336842209555771
Epoch #146: loss=0.032602634736133784
Epoch #147: loss=0.021885333197527005
Epoch #148: loss=0.01933289734856292
Epoch #149: loss=0.020965030752659704
Epoch #150: loss=0.024446913128071318
Epoch #151: loss=0.017471386958593557
Epoch #152: loss=0.013088921127038904
Epoch #153: loss=0.01609671024451075
Epoch #154: loss=0.02007610220734051
Epoch #155: loss=0.031120878580441578
Epoch #156: loss=0.03594889786615808
Epoch #157: loss=0.01885133437471374
Epoch #158: loss=0.01717191679035698
Epoch #159: loss=0.023219564992621372
Epoch #160: loss=0.014889485667230152
Epoch #161: loss=0.020501124148556905
Epoch #162: loss=0.022617672086478427
Epoch #163: loss=0.03392811605540645
Epoch #164: loss=0.019728745184434137
Epoch #165: loss=0.03395482091988673
Epoch #166: loss=0.023055424202005365
Epoch #167: loss=0.018710099447729528
Epoch #168: loss=0.017521366987449046
Epoch #169: loss=0.01799879602270673
Epoch #170: loss=0.02162263112522773
Epoch #171: loss=0.017961418638244655
Epoch #172: loss=0.024513199183979786
Epoch #173: loss=0.03088592775673486
Epoch #174: loss=0.022718725349897377
Epoch #175: loss=0.01641399786921027
Epoch #176: loss=0.013122700874665832
Epoch #177: loss=0.01712456679099672
Epoch #178: loss=0.018288875734161564
Epoch #179: loss=0.022683690408705083
Epoch #180: loss=0.0133624989540214
Epoch #181: loss=0.01893862072883195
Epoch #182: loss=0.024057653285841592
Epoch #183: loss=0.03055624146726874
Epoch #184: loss=0.027941332590544696
Epoch #185: loss=0.01758856129389126
Epoch #186: loss=0.019640284590257275
Epoch #187: loss=0.015599232319572628
Epoch #188: loss=0.018172424493149916
Epoch #189: loss=0.01001252501239825
Epoch #190: loss=0.018389711656310512
Epoch #191: loss=0.023561411024140264
Epoch #192: loss=0.012542084179005382
Epoch #193: loss=0.01661568636139669
Epoch #194: loss=0.012814539042235142
Epoch #195: loss=0.013000979193053779
Epoch #196: loss=0.015809447139579845
Epoch #197: loss=0.017530316084807745
Epoch #198: loss=0.014776698380484487
Epoch #199: loss=0.017372431895202104
Epoch #200: loss=0.019897830926287823
Epoch #201: loss=0.0192889286851261
Epoch #202: loss=0.011906724716364234
Epoch #203: loss=0.011464242681302396
Epoch #204: loss=0.01823515785915082
Epoch #205: loss=0.012288312577530396
Epoch #206: loss=0.016548268264325393
Epoch #207: loss=0.019472475272923062
Epoch #208: loss=0.015135680920921367
Epoch #209: loss=0.017267223393250698
Epoch #210: loss=0.01363899707634989
Epoch #211: loss=0.015239307001011547
Epoch #212: loss=0.015291046548267115
Epoch #213: loss=0.01157357167496354
Epoch #214: loss=0.011645165633408889
Epoch #215: loss=0.0509595631726585
Epoch #216: loss=0.02173175752538381
Epoch #217: loss=0.013436256025810368
Epoch #218: loss=0.059987712764423974
Epoch #219: loss=0.029091784033388367
Epoch #220: loss=0.02055352035826311
Epoch #221: loss=0.013716417635831467
Epoch #222: loss=0.020611614138126757
Epoch #223: loss=0.011554538666673981
Epoch #224: loss=0.01304954850957981
Epoch #225: loss=0.02204544103320985
Epoch #226: loss=0.020021480630036507
Epoch #227: loss=0.013698265786638266
Epoch #228: loss=0.01112709667707264
Epoch #229: loss=0.018387881604715137
Epoch #230: loss=0.01584295615384042
Epoch #231: loss=0.012088220611700862
Epoch #232: loss=0.012045917111403173
Epoch #233: loss=0.010623339223317228
Epoch #234: loss=0.015431421776395025
Epoch #235: loss=0.020244074054559868
Epoch #236: loss=0.01543083646420278
Epoch #237: loss=0.01737884310935823
Epoch #238: loss=0.025833093909980554
Epoch #239: loss=0.033542469902888755
Epoch #240: loss=0.024807879073492932
Epoch #241: loss=0.01934578006326266
Epoch #242: loss=0.023623029785986956
Epoch #243: loss=0.022889746689341135
Epoch #244: loss=0.020541888236484764
Epoch #245: loss=0.015909639776862116
Epoch #246: loss=0.01164617643083321
Epoch #247: loss=0.01278948491020327
Epoch #248: loss=0.017354798238217683
Epoch #249: loss=0.014711220610624463

Training time: 1:37:00.805504

Finished.
n2one setting ettm1_ettm2_electricity_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm1_ettm2_electricity_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='ettm1_ettm2_electricity_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.52482e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.92173e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.6365269587819888, 'MAE': 0.6089039393466127}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='ettm1_ettm2_traffic_weather', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/ettm1_ettm2_traffic_weather_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.0686708931903264
Epoch #1: loss=0.4305633410647675
Epoch #2: loss=0.3153198416170838
Epoch #3: loss=0.2494534937808147
Epoch #4: loss=0.20456921739892645
Epoch #5: loss=0.1800209552049637
Epoch #6: loss=0.15305135418753046
Epoch #7: loss=0.1326244872309022
Epoch #8: loss=0.1258529142732476
Epoch #9: loss=0.10936116147888722
Epoch #10: loss=0.09299964307510591
Epoch #11: loss=0.08808541321860892
Epoch #12: loss=0.07568716553889297
Epoch #13: loss=0.07571104298663009
Epoch #14: loss=0.07225808366304161
Epoch #15: loss=0.06031752056646887
Epoch #16: loss=0.06098383481276559
Epoch #17: loss=0.05835387578878838
Epoch #18: loss=0.049123411516116544
Epoch #19: loss=0.0514894545646282
Epoch #20: loss=0.04081098334863782
Epoch #21: loss=0.05755826956080785
Epoch #22: loss=0.04336227015924773
Epoch #23: loss=0.03961504302473718
Epoch #24: loss=0.03419535505012251
Epoch #25: loss=0.035423927633142976
Epoch #26: loss=0.033602175539088244
Epoch #27: loss=0.03580918108844863
Epoch #28: loss=0.027780391238207653
Epoch #29: loss=0.03650298620239002
Epoch #30: loss=0.039830850815057633
Epoch #31: loss=0.040758158175331016
Epoch #32: loss=0.029389983580376092
Epoch #33: loss=0.029708029802474143
Epoch #34: loss=0.03625909734951015
Epoch #35: loss=0.031063039275270037
Epoch #36: loss=0.02477410835544016
Epoch #37: loss=0.03017500416864385
Epoch #38: loss=0.029160229187167076
Epoch #39: loss=0.03282164106501143
Epoch #40: loss=0.027416678609462085
Epoch #41: loss=0.03853222094885596
Epoch #42: loss=0.022968889258425825
Epoch #43: loss=0.029572576750581572
Epoch #44: loss=0.02410532919808987
Epoch #45: loss=0.02831307469910666
Epoch #46: loss=0.02174960432918282
Epoch #47: loss=0.03756900184453915
Epoch #48: loss=0.02785093247184305
Epoch #49: loss=0.023932840354781555
Epoch #50: loss=0.024556503433780234
Epoch #51: loss=0.023482126917927986
Epoch #52: loss=0.02615871464508678
Epoch #53: loss=0.030014513555855316
Epoch #54: loss=0.020056650513120427
Epoch #55: loss=0.02441211768328775
Epoch #56: loss=0.022123424341719197
Epoch #57: loss=0.030222026359642967
Epoch #58: loss=0.02452201525518251
Epoch #59: loss=0.03269428235023272
Epoch #60: loss=0.0225875005893573
Epoch #61: loss=0.01913954902959701
Epoch #62: loss=0.017978863312752794
Epoch #63: loss=0.019498734055505937
Epoch #64: loss=0.022057832927176994
Epoch #65: loss=0.01906843528463019
Epoch #66: loss=0.020889709036730764
Epoch #67: loss=0.021474748757839904
Epoch #68: loss=0.019808474625396838
Epoch #69: loss=0.02587039325566026
Epoch #70: loss=0.017529871201163137
Epoch #71: loss=0.031601428567268115
Epoch #72: loss=0.017899031838872932
Epoch #73: loss=0.01661911576143261
Epoch #74: loss=0.019481446330850062
Epoch #75: loss=0.035960993823687455
Epoch #76: loss=0.01854368279234552
Epoch #77: loss=0.034920333466456774
Epoch #78: loss=0.013363339808023698
Epoch #79: loss=0.015574986269028479
Epoch #80: loss=0.020332306015318734
Epoch #81: loss=0.01898664870823268
Epoch #82: loss=0.017942181193131627
Epoch #83: loss=0.022729846677527976
Epoch #84: loss=0.01400658675005076
Epoch #85: loss=0.01901856120483909
Epoch #86: loss=0.021954516441481966
Epoch #87: loss=0.020465614197962497
Epoch #88: loss=0.014937096050809966
Epoch #89: loss=0.0182929266616866
Epoch #90: loss=0.017853507044428323
Epoch #91: loss=0.017586178187847617
Epoch #92: loss=0.01591511050777786
Epoch #93: loss=0.02604100524919916
Epoch #94: loss=0.013428681450070824
Epoch #95: loss=0.016564744615391317
Epoch #96: loss=0.02814207098465656
Epoch #97: loss=0.021465807540532827
Epoch #98: loss=0.018639938369812956
Epoch #99: loss=0.016078847721647624
Epoch #100: loss=0.012173581677508172
Epoch #101: loss=0.01911378553094647
Epoch #102: loss=0.01650245075125585
Epoch #103: loss=0.015077984244959266
Epoch #104: loss=0.03581596230205333
Epoch #105: loss=0.016599170940257812
Epoch #106: loss=0.013575313280523336
Epoch #107: loss=0.03165794369648851
Epoch #108: loss=0.020614350913987996
Epoch #109: loss=0.018082202083858467
Epoch #110: loss=0.016717222311014596
Epoch #111: loss=0.017322644729270847
Epoch #112: loss=0.018678408858473772
Epoch #113: loss=0.018549176499312793
Epoch #114: loss=0.01148134086519009
Epoch #115: loss=0.01299631587996603
Epoch #116: loss=0.017366709170420398
Epoch #117: loss=0.015428785269550344
Epoch #118: loss=0.015537706426067206
Epoch #119: loss=0.015051633218951923
Epoch #120: loss=0.020267221770760385
Epoch #121: loss=0.01459950657572935
Epoch #122: loss=0.026660327233596716
Epoch #123: loss=0.014290887917461357
Epoch #124: loss=0.013317134226995372
Epoch #125: loss=0.013616807048738638
Epoch #126: loss=0.014081712975102774
Epoch #127: loss=0.02361286060314032
Epoch #128: loss=0.01769110109416543
Epoch #129: loss=0.010540181159164634
Epoch #130: loss=0.022301454399200667
Epoch #131: loss=0.01781134756888355
Epoch #132: loss=0.015671821112698457
Epoch #133: loss=0.015483922046797279
Epoch #134: loss=0.013422302692932854
Epoch #135: loss=0.016161695785902357
Epoch #136: loss=0.02149704366296806
Epoch #137: loss=0.012675122941452703
Epoch #138: loss=0.017533082157471933
Epoch #139: loss=0.01784570066979191
Epoch #140: loss=0.018262698472356603
Epoch #141: loss=0.021855628876153707
Epoch #142: loss=0.009941076507387622
Epoch #143: loss=0.01912961204833374
Epoch #144: loss=0.021158121021625658
Epoch #145: loss=0.012104124291819151
Epoch #146: loss=0.014444921471422876
Epoch #147: loss=0.01623679762982807
Epoch #148: loss=0.0130440034366162
Epoch #149: loss=0.01827651584401962
Epoch #150: loss=0.015233916613263088
Epoch #151: loss=0.016115500090565726
Epoch #152: loss=0.011692860592502057
Epoch #153: loss=0.01337811148835469
Epoch #154: loss=0.015130180445951307
Epoch #155: loss=0.013446612132807227
Epoch #156: loss=0.014297625909023406
Epoch #157: loss=0.013008549878985242
Epoch #158: loss=0.01280524346211178
Epoch #159: loss=0.016734760084316125
Epoch #160: loss=0.013642554068400595
Epoch #161: loss=0.016820491802274854
Epoch #162: loss=0.013153530327330732
Epoch #163: loss=0.01901673961342517
Epoch #164: loss=0.01243620151776218
Epoch #165: loss=0.008878208637423207
Epoch #166: loss=0.018967313921318268
Epoch #167: loss=0.014772914054740864
Epoch #168: loss=0.012124222644366795
Epoch #169: loss=0.013047134012571066
Epoch #170: loss=0.012310487784046788
Epoch #171: loss=0.015845596708559142
Epoch #172: loss=0.011270722025553799
Epoch #173: loss=0.01262272126130903
Epoch #174: loss=0.01934495718435226
Epoch #175: loss=0.008411790230401004
Epoch #176: loss=0.01267534946105865
Epoch #177: loss=0.01198078037628515
Epoch #178: loss=0.013002902429338523
Epoch #179: loss=0.017501256049125825
Epoch #180: loss=0.016808621041031535
Epoch #181: loss=0.028482011471271187
Epoch #182: loss=0.013873417177084055
Epoch #183: loss=0.010341134210114603
Epoch #184: loss=0.0163042338546922
Epoch #185: loss=0.011732659670639436
Epoch #186: loss=0.010008144707719291
Epoch #187: loss=0.014445608248326487
Epoch #188: loss=0.019120335124610862
Epoch #189: loss=0.008396410176838788
Epoch #190: loss=0.017022097672100413
Epoch #191: loss=0.012524327184963532
Epoch #192: loss=0.01121759443733506
Epoch #193: loss=0.01444866861525992
Epoch #194: loss=0.0167849739153478
Epoch #195: loss=0.015414534374600747
Epoch #196: loss=0.010732130319069416
Epoch #197: loss=0.008932539290821455
Epoch #198: loss=0.03763509515527723
Epoch #199: loss=0.016299298369059606
Epoch #200: loss=0.009801845702423925
Epoch #201: loss=0.022996310474463627
Epoch #202: loss=0.014331235676385964
Epoch #203: loss=0.011971649869815587
Epoch #204: loss=0.014394810857869504
Epoch #205: loss=0.01139085315419604
Epoch #206: loss=0.00841024661514074
Epoch #207: loss=0.016067135086648324
Epoch #208: loss=0.01797734618850262
Epoch #209: loss=0.012082910802260753
Epoch #210: loss=0.01033607417951686
Epoch #211: loss=0.024964688101317734
Epoch #212: loss=0.00931133152766711
Epoch #213: loss=0.013231676526509665
Epoch #214: loss=0.028133303363062953
Epoch #215: loss=0.00918285693854329
Epoch #216: loss=0.014966199296663495
Epoch #217: loss=0.012889131997244375
Epoch #218: loss=0.011344626892657418
Epoch #219: loss=0.007785399168906324
Epoch #220: loss=0.013903705889274684
Epoch #221: loss=0.01586717256545703
Epoch #222: loss=0.012468976624278674
Epoch #223: loss=0.009963841123089378
Epoch #224: loss=0.030682392608327023
Epoch #225: loss=0.011554186163970031
Epoch #226: loss=0.01358525904297194
Epoch #227: loss=0.012138735036561418
Epoch #228: loss=0.010682325902478744
Epoch #229: loss=0.0062539191250555
Epoch #230: loss=0.011367250461170353
Epoch #231: loss=0.00879788174424103
Epoch #232: loss=0.01700065329652996
Epoch #233: loss=0.009592698615515373
Epoch #234: loss=0.009163370077638339
Epoch #235: loss=0.011213919836794317
Epoch #236: loss=0.01189440369192168
Epoch #237: loss=0.01586409602733201
Epoch #238: loss=0.009472829791892373
Epoch #239: loss=0.008707184598245146
Epoch #240: loss=0.010647475062496897
Epoch #241: loss=0.010915819991582743
Epoch #242: loss=0.015208067702114131
Epoch #243: loss=0.00904838346678234
Epoch #244: loss=0.01345544062174089
Epoch #245: loss=0.010737769730334109
Epoch #246: loss=0.009911444003168506
Epoch #247: loss=0.009323464484855272
Epoch #248: loss=0.010897539134330746
Epoch #249: loss=0.012287286397934492

Training time: 3:40:10.123747

Finished.
n2one setting ettm1_ettm2_traffic_weather -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm1_ettm2_traffic_weather_epochs_250_seed_2021/model.pkl', muti_dataset='ettm1_ettm2_traffic_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.04123e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.23438e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.54729e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.04123e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4136927921270399, 'MAE': 0.45695048215441764}
Finished.
------------------------- record done -------------------------
n2one setting ettm1_ettm2_traffic_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm1_ettm2_traffic_weather_epochs_250_seed_2021/model.pkl', muti_dataset='ettm1_ettm2_traffic_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.34525e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.5141317496493621, 'MAE': 0.4480799218916434}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='ettm1_ettm2_traffic_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/ettm1_ettm2_traffic_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.0510707109531747
Epoch #1: loss=0.40314954429063027
Epoch #2: loss=0.298819603557143
Epoch #3: loss=0.23484635546870294
Epoch #4: loss=0.19024799251302477
Epoch #5: loss=0.14300040556159654
Epoch #6: loss=0.13890797426431303
Epoch #7: loss=0.11384112966109083
Epoch #8: loss=0.09372191401950246
Epoch #9: loss=0.09351290176902384
Epoch #10: loss=0.08240874842510897
Epoch #11: loss=0.07361902564350566
Epoch #12: loss=0.0713767137387851
Epoch #13: loss=0.06891117650063316
Epoch #14: loss=0.06144064569463661
Epoch #15: loss=0.0583343876229762
Epoch #16: loss=0.05514766355520198
Epoch #17: loss=0.05074413214061585
Epoch #18: loss=0.05139308174285879
Epoch #19: loss=0.04721374374828949
Epoch #20: loss=0.041590252339645736
Epoch #21: loss=0.046443261906730156
Epoch #22: loss=0.04146380765225755
Epoch #23: loss=0.0446076612606866
Epoch #24: loss=0.032451755485331406
Epoch #25: loss=0.04617634754014022
Epoch #26: loss=0.03984494389174715
Epoch #27: loss=0.03525485909830271
Epoch #28: loss=0.02837756358613281
Epoch #29: loss=0.033166875390230464
Epoch #30: loss=0.03141588737980375
Epoch #31: loss=0.03721890249668053
Epoch #32: loss=0.029677702059302136
Epoch #33: loss=0.04313401108325225
Epoch #34: loss=0.03430126150820724
Epoch #35: loss=0.027847719916015666
Epoch #36: loss=0.0262568016888129
Epoch #37: loss=0.039838912486487105
Epoch #38: loss=0.03645326698672929
Epoch #39: loss=0.02863753188017499
Epoch #40: loss=0.032130584533816
Epoch #41: loss=0.030304541822048864
Epoch #42: loss=0.028282875272538303
Epoch #43: loss=0.03136065885242682
Epoch #44: loss=0.032968603483505124
Epoch #45: loss=0.0235846764814592
Epoch #46: loss=0.021035840549579854
Epoch #47: loss=0.033580979998909966
Epoch #48: loss=0.03294212575516384
Epoch #49: loss=0.032434463815898276
Epoch #50: loss=0.02381587583851487
Epoch #51: loss=0.023835072563707958
Epoch #52: loss=0.026877754409390296
Epoch #53: loss=0.023023931410530635
Epoch #54: loss=0.028931528706371893
Epoch #55: loss=0.023390952985585096
Epoch #56: loss=0.02199710385608064
Epoch #57: loss=0.020201721304897648
Epoch #58: loss=0.02789466338347792
Epoch #59: loss=0.025055000287262177
Epoch #60: loss=0.027416861040458696
Epoch #61: loss=0.022355986889642288
Epoch #62: loss=0.022842872586403294
Epoch #63: loss=0.025336627022054196
Epoch #64: loss=0.018299834749563763
Epoch #65: loss=0.030266860072752106
Epoch #66: loss=0.023481547576101235
Epoch #67: loss=0.024459052094072523
Epoch #68: loss=0.019919828234439833
Epoch #69: loss=0.024568790555838965
Epoch #70: loss=0.022935124243883158
Epoch #71: loss=0.0196716280991377
Epoch #72: loss=0.03373150531764533
Epoch #73: loss=0.02095557435224096
Epoch #74: loss=0.017694492457706518
Epoch #75: loss=0.023703478571748458
Epoch #76: loss=0.019164408013704098
Epoch #77: loss=0.0197197459843999
Epoch #78: loss=0.021428326526622816
Epoch #79: loss=0.016001824833821524
Epoch #80: loss=0.015997814884928217
Epoch #81: loss=0.02041588940841956
Epoch #82: loss=0.019907492982603938
Epoch #83: loss=0.021653348577131554
Epoch #84: loss=0.019636006889911264
Epoch #85: loss=0.017413713175134165
Epoch #86: loss=0.016436538512179275
Epoch #87: loss=0.019690297202750333
Epoch #88: loss=0.02093242056010815
Epoch #89: loss=0.018862654078826063
Epoch #90: loss=0.021409881532423496
Epoch #91: loss=0.01933586791850994
Epoch #92: loss=0.017499806282213353
Epoch #93: loss=0.020634319715467052
Epoch #94: loss=0.01878851488700623
Epoch #95: loss=0.01712092382356607
Epoch #96: loss=0.01671227939192502
Epoch #97: loss=0.019521322113948858
Epoch #98: loss=0.01740659707872669
Epoch #99: loss=0.02006076137073789
Epoch #100: loss=0.01770354240243699
Epoch #101: loss=0.01674128198346766
Epoch #102: loss=0.02312262536857783
Epoch #103: loss=0.02010591442268937
Epoch #104: loss=0.01854557961225118
Epoch #105: loss=0.013800154132361318
Epoch #106: loss=0.020533397068164358
Epoch #107: loss=0.01978562258314075
Epoch #108: loss=0.02318688252283703
Epoch #109: loss=0.026756232894770176
Epoch #110: loss=0.016455154217016932
Epoch #111: loss=0.01643258138781496
Epoch #112: loss=0.015981144992371805
Epoch #113: loss=0.019510933233174703
Epoch #114: loss=0.014316947817110202
Epoch #115: loss=0.013890179508725769
Epoch #116: loss=0.01809584301135974
Epoch #117: loss=0.01456361800698316
Epoch #118: loss=0.015451078717659474
Epoch #119: loss=0.020535998827405325
Epoch #120: loss=0.013799800850392785
Epoch #121: loss=0.014988555115341045
Epoch #122: loss=0.012632540276979754
Epoch #123: loss=0.0211448135801485
Epoch #124: loss=0.017876454648254294
Epoch #125: loss=0.022748293945699723
Epoch #126: loss=0.017860148743210274
Epoch #127: loss=0.01529814753707654
Epoch #128: loss=0.017222033050762187
Epoch #129: loss=0.013070249933482674
Epoch #130: loss=0.02076491727364498
Epoch #131: loss=0.018011840954643515
Epoch #132: loss=0.015609503051486898
Epoch #133: loss=0.019460871503989875
Epoch #134: loss=0.01754160110025044
Epoch #135: loss=0.01739558699235269
Epoch #136: loss=0.016028313647361573
Epoch #137: loss=0.015295998641170223
Epoch #138: loss=0.01484235628805791
Epoch #139: loss=0.015318004363866402
Epoch #140: loss=0.012386974082984847
Epoch #141: loss=0.01497549978767432
Epoch #142: loss=0.012569365994623683
Epoch #143: loss=0.01869014823715168
Epoch #144: loss=0.021666866811417825
Epoch #145: loss=0.014316692331663177
Epoch #146: loss=0.011000849871326594
Epoch #147: loss=0.014478955279595652
Epoch #148: loss=0.015252709325272203
Epoch #149: loss=0.021123349435950865
Epoch #150: loss=0.016549214749405686
Epoch #151: loss=0.01217345292623846
Epoch #152: loss=0.01939824215054769
Epoch #153: loss=0.013862503233730884
Epoch #154: loss=0.01785349147100651
Epoch #155: loss=0.015744325581018192
Epoch #156: loss=0.017388547617867574
Epoch #157: loss=0.019459835652397964
Epoch #158: loss=0.017163719009834336
Epoch #159: loss=0.013260866633238298
Epoch #160: loss=0.012449027863838825
Epoch #161: loss=0.01684339388237179
Epoch #162: loss=0.013612230776364377
Epoch #163: loss=0.014546500686526083
Epoch #164: loss=0.013661054625900748
Epoch #165: loss=0.016731450622162632
Epoch #166: loss=0.01722488298025786
Epoch #167: loss=0.011802685693636716
Epoch #168: loss=0.011475377108793676
Epoch #169: loss=0.014202329499721191
Epoch #170: loss=0.015323551559596032
Epoch #171: loss=0.013132594343001543
Epoch #172: loss=0.014105662577865163
Epoch #173: loss=0.017593214908767973
Epoch #174: loss=0.011771135089748395
Epoch #175: loss=0.014412275141289623
Epoch #176: loss=0.017776683691669855
Epoch #177: loss=0.012568783627139382
Epoch #178: loss=0.020241945391974252
Epoch #179: loss=0.015030931240497647
Epoch #180: loss=0.012706950153607871
Epoch #181: loss=0.013818248670518575
Epoch #182: loss=0.014237301101507551
Epoch #183: loss=0.014649808664082246
Epoch #184: loss=0.012176295776782043
Epoch #185: loss=0.012555066925415304
Epoch #186: loss=0.013014237737149208
Epoch #187: loss=0.012997556749051082
Epoch #188: loss=0.023208941539332915
Epoch #189: loss=0.014526119181329558
Epoch #190: loss=0.013521335477551294
Epoch #191: loss=0.012690857831237719
Epoch #192: loss=0.011398694324690845
Epoch #193: loss=0.014770261515983258
Epoch #194: loss=0.0113167133192206
Epoch #195: loss=0.013804175032190759
Epoch #196: loss=0.01169011156465451
Epoch #197: loss=0.010100149412556826
Epoch #198: loss=0.01831104319839623
Epoch #199: loss=0.014738173671160728
Epoch #200: loss=0.014982989088079064
Epoch #201: loss=0.010057425965207725
Epoch #202: loss=0.01510161871386529
Epoch #203: loss=0.014379334336054312
Epoch #204: loss=0.014880342571728607
Epoch #205: loss=0.01470071691838944
Epoch #206: loss=0.012203630511132131
Epoch #207: loss=0.012960916670317806
Epoch #208: loss=0.016623933441444163
Epoch #209: loss=0.014322717035505236
Epoch #210: loss=0.016056432073050745
Epoch #211: loss=0.014140234241821184
Epoch #212: loss=0.013200251316888447
Epoch #213: loss=0.01397090891887804
Epoch #214: loss=0.018363909218632596
Epoch #215: loss=0.01279118312473175
Epoch #216: loss=0.023311578249062867
Epoch #217: loss=0.011260330352942395
Epoch #218: loss=0.014656403378042917
Epoch #219: loss=0.011486392584613044
Epoch #220: loss=0.013334884382865283
Epoch #221: loss=0.01894152464248259
Epoch #222: loss=0.014145973025309679
Epoch #223: loss=0.009236011143043328
Epoch #224: loss=0.009026752490025106
Epoch #225: loss=0.015984005987848576
Epoch #226: loss=0.017664554747888576
Epoch #227: loss=0.009798867861200499
Epoch #228: loss=0.012917439094171682
Epoch #229: loss=0.011243355191336091
Epoch #230: loss=0.014649862594797423
Epoch #231: loss=0.011935705717711282
Epoch #232: loss=0.012252808330427111
Epoch #233: loss=0.011853138207131162
Epoch #234: loss=0.013645572116727414
Epoch #235: loss=0.011159712300800411
Epoch #236: loss=0.016229501196736367
Epoch #237: loss=0.014205967342984004
Epoch #238: loss=0.01390318586082877
Epoch #239: loss=0.010536323666385027
Epoch #240: loss=0.016934960298924058
Epoch #241: loss=0.013097858649204515
Epoch #242: loss=0.011814364413108265
Epoch #243: loss=0.01738292181029375
Epoch #244: loss=0.011485043194241804
Epoch #245: loss=0.011892435477918375
Epoch #246: loss=0.010619215900796224
Epoch #247: loss=0.015301834529784801
Epoch #248: loss=0.011781017634266677
Epoch #249: loss=0.01917690350406057

Training time: 3:25:34.756847

Finished.
n2one setting ettm1_ettm2_traffic_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm1_ettm2_traffic_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='ettm1_ettm2_traffic_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.77118e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.18447e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.11141e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.77118e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.40829115166825547, 'MAE': 0.4552579713680987}
Finished.
------------------------- record done -------------------------
n2one setting ettm1_ettm2_traffic_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm1_ettm2_traffic_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='ettm1_ettm2_traffic_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.56928e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.00735e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.56928e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 1.0766214386041908, 'MAE': 0.8516684557917711}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='ettm1_ettm2_weather_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/ettm1_ettm2_weather_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=5.696544172508376
Epoch #1: loss=2.5861494732754573
Epoch #2: loss=2.2824718643512045
Epoch #3: loss=2.1281310447624753
Epoch #4: loss=1.991897048694747
Epoch #5: loss=1.7669272380215781
Epoch #6: loss=1.693471712725503
Epoch #7: loss=1.5840308261769158
Epoch #8: loss=1.4383815356663294
Epoch #9: loss=1.3043268557105745
Epoch #10: loss=1.2501277785216058
Epoch #11: loss=1.20083157398871
Epoch #12: loss=1.1408126088125365
Epoch #13: loss=1.0628976396151952
Epoch #14: loss=1.1326250401990754
Epoch #15: loss=1.0705297738313675
Epoch #16: loss=1.0315236992069654
Epoch #17: loss=0.9018050549285752
Epoch #18: loss=0.9422222407800811
Epoch #19: loss=0.8897431301219123
Epoch #20: loss=0.8171618325369698
Epoch #21: loss=0.7789048978260585
Epoch #22: loss=0.8415962819542203
Epoch #23: loss=0.8137230170624596
Epoch #24: loss=0.7749004725899015
Epoch #25: loss=0.7668730989098549
Epoch #26: loss=0.7797825639801366
Epoch #27: loss=0.747026583978108
Epoch #28: loss=0.7676056650068078
Epoch #29: loss=0.7334428424281734
Epoch #30: loss=0.6797796211072377
Epoch #31: loss=0.6931166867060321
Epoch #32: loss=0.6693203071398395
Epoch #33: loss=0.652217619653259
Epoch #34: loss=0.6176554416971547
Epoch #35: loss=0.6478235588542053
Epoch #36: loss=0.6497009561530181
Epoch #37: loss=0.6398214075182166
Epoch #38: loss=0.5951063191252095
Epoch #39: loss=0.5789087132683822
Epoch #40: loss=0.5580072849988937
Epoch #41: loss=0.5330431477299759
Epoch #42: loss=0.5445192365774086
Epoch #43: loss=0.4944537287311895
Epoch #44: loss=0.48637741271938595
Epoch #45: loss=0.5013912506401539
Epoch #46: loss=0.41671329497226645
Epoch #47: loss=0.4421293873872076
Epoch #48: loss=0.47460896654852797
Epoch #49: loss=0.46780693770519327
Epoch #50: loss=0.4940037823149136
Epoch #51: loss=0.43786256946623325
Epoch #52: loss=0.4622960476470845
Epoch #53: loss=0.39613636902400423
Epoch #54: loss=0.5295722644243922
Epoch #55: loss=0.3900598260973181
Epoch #56: loss=0.35593230170863016
Epoch #57: loss=0.40755115422819344
Epoch #58: loss=0.3495493390198265
Epoch #59: loss=0.3718631091926779
Epoch #60: loss=0.3261140427951302
Epoch #61: loss=0.36073070152529646
Epoch #62: loss=0.3743927896554981
Epoch #63: loss=0.31313057988882065
Epoch #64: loss=0.3651812752442701
Epoch #65: loss=0.3603147619536945
Epoch #66: loss=0.32683656870254446
Epoch #67: loss=0.3452649539602654
Epoch #68: loss=0.38469506720347063
Epoch #69: loss=0.4078343138098717
Epoch #70: loss=0.4184432867914438
Epoch #71: loss=0.3607650811650923
Epoch #72: loss=0.2851130971685052
Epoch #73: loss=0.31443085481545757
Epoch #74: loss=0.2694507383608392
Epoch #75: loss=0.31443104786532267
Epoch #76: loss=0.2620708243921399
Epoch #77: loss=0.2649374710662024
Epoch #78: loss=0.27576484850474764
Epoch #79: loss=0.3128700620893921
Epoch #80: loss=0.27323909463094814
Epoch #81: loss=0.22537010642034666
Epoch #82: loss=0.21493484066533192
Epoch #83: loss=0.21861744565623148
Epoch #84: loss=0.21959244632827385
Epoch #85: loss=0.2312984903609114
Epoch #86: loss=0.24419416700090682
Epoch #87: loss=0.20461280031927995
Epoch #88: loss=0.2086515669444842
Epoch #89: loss=0.17495902009042247
Epoch #90: loss=0.16578753957790987
Epoch #91: loss=0.16897009945075428
Epoch #92: loss=0.17320768175912754
Epoch #93: loss=0.17815013023625528
Epoch #94: loss=0.25323674608288066
Epoch #95: loss=0.20416601401354587
Epoch #96: loss=0.19043162518313952
Epoch #97: loss=0.2088508971833757
Epoch #98: loss=0.25275424282465664
Epoch #99: loss=0.18113024120352098
Epoch #100: loss=0.1999429422430694
Epoch #101: loss=0.20787195515419757
Epoch #102: loss=0.2336227847263217
Epoch #103: loss=0.26109513766797526
Epoch #104: loss=0.2138351118857307
Epoch #105: loss=0.23359401264627064
Epoch #106: loss=0.21552296614806568
Epoch #107: loss=0.21500223974830338
Epoch #108: loss=0.15503809787333012
Epoch #109: loss=0.13840291303183352
Epoch #110: loss=0.143278465273657
Epoch #111: loss=0.15045529677133476
Epoch #112: loss=0.1466527250928006
Epoch #113: loss=0.12754958232731692
Epoch #114: loss=0.16212028517786944
Epoch #115: loss=0.15489876489820226
Epoch #116: loss=0.17594747594557703
Epoch #117: loss=0.1669455991525735
Epoch #118: loss=0.18275886235226477
Epoch #119: loss=0.19189995437461352
Epoch #120: loss=0.14696112451409654
Epoch #121: loss=0.12380623544699379
Epoch #122: loss=0.15337736578658223
Epoch #123: loss=0.131867136639942
Epoch #124: loss=0.10382407115373228
Epoch #125: loss=0.10603163840382226
Epoch #126: loss=0.10653896939142474
Epoch #127: loss=0.09810120406161461
Epoch #128: loss=0.10966056453928884
Epoch #129: loss=0.09103500247666878
Epoch #130: loss=0.10738508709307228
Epoch #131: loss=0.10221868726824011
Epoch #132: loss=0.14185838930175773
Epoch #133: loss=0.13023067921000933
Epoch #134: loss=0.17065289629889385
Epoch #135: loss=0.13403573904984764
Epoch #136: loss=0.1332712495766048
Epoch #137: loss=0.14190480325903213
Epoch #138: loss=0.17379979682820185
Epoch #139: loss=0.1500724228764219
Epoch #140: loss=0.10629294905811548
Epoch #141: loss=0.11285670420953206
Epoch #142: loss=0.10682174769629325
Epoch #143: loss=0.09545504295134119
Epoch #144: loss=0.11283408740668424
Epoch #145: loss=0.12511624365911952
Epoch #146: loss=0.09565823724759477
Epoch #147: loss=0.1278928111174277
Epoch #148: loss=0.115555795009381
Epoch #149: loss=0.12814104829781822
Epoch #150: loss=0.10904747400698918
Epoch #151: loss=0.17272752476856112
Epoch #152: loss=0.1728456452422376
Epoch #153: loss=0.16670682005185103
Epoch #154: loss=0.18227720613192236
Epoch #155: loss=0.1451075995074851
Epoch #156: loss=0.13803775079681405
Epoch #157: loss=0.15733427201796854
Epoch #158: loss=0.4980936331807503
Epoch #159: loss=0.1651559516654483
Epoch #160: loss=0.11093756852538458
Epoch #161: loss=0.10369292766387973
Epoch #162: loss=0.1182454560351159
Epoch #163: loss=0.11727307946421206
Epoch #164: loss=0.10980252863373607
Epoch #165: loss=0.09787291105437491
Epoch #166: loss=0.0958091135835275
Epoch #167: loss=0.1572360826124038
Epoch #168: loss=0.18328927690163255
Epoch #169: loss=0.21073125725212907
Epoch #170: loss=0.10948760847428016
Epoch #171: loss=0.0758699004072696
Epoch #172: loss=0.0684635843749025
Epoch #173: loss=0.062106322563652484
Epoch #174: loss=0.07706860118612115
Epoch #175: loss=0.07434576688267823
Epoch #176: loss=0.08784359257801302
Epoch #177: loss=0.07511266896368138
Epoch #178: loss=0.06883681823299932
Epoch #179: loss=0.08341845083383045
Epoch #180: loss=0.11931394516224307
Epoch #181: loss=0.08554170337239546
Epoch #182: loss=0.08216476172674447
Epoch #183: loss=0.09175888705067337
Epoch #184: loss=0.09105872921645641
Epoch #185: loss=0.06966817806408342
Epoch #186: loss=0.06009096640627831
Epoch #187: loss=0.07068958374605115
Epoch #188: loss=0.06165140384941229
Epoch #189: loss=0.09259436307807586
Epoch #190: loss=0.10018621004253093
Epoch #191: loss=0.08526292662801487
Epoch #192: loss=0.08218994039842593
Epoch #193: loss=0.06856109002338988
Epoch #194: loss=0.05818421850978796
Epoch #195: loss=0.05848673732751714
Epoch #196: loss=0.08334410253779165
Epoch #197: loss=0.08097531927549946
Epoch #198: loss=0.10287654759096247
Epoch #199: loss=0.12069926118212086
Epoch #200: loss=0.14790464001375117
Epoch #201: loss=0.0726041225550164
Epoch #202: loss=0.06457651677607958
Epoch #203: loss=0.05993219558149576
Epoch #204: loss=0.07602935370856098
Epoch #205: loss=0.07034854279897575
Epoch #206: loss=0.1458064113477511
Epoch #207: loss=0.11746882865138884
Epoch #208: loss=0.10284362537121135
Epoch #209: loss=0.12409894996588784
Epoch #210: loss=0.11604889518847424
Epoch #211: loss=0.10475098270191145
Epoch #212: loss=0.08583047813070672
Epoch #213: loss=0.09287284454330802
Epoch #214: loss=0.1844127830117941
Epoch #215: loss=0.11781083120565329
Epoch #216: loss=0.08890605959043439
Epoch #217: loss=0.06842149840667844
Epoch #218: loss=0.08432535694113799
Epoch #219: loss=0.1353545554447919
Epoch #220: loss=0.08154553994869015
Epoch #221: loss=0.05962548662708806
Epoch #222: loss=0.06470804829483054
Epoch #223: loss=0.09146239209387984
Epoch #224: loss=0.08172943823904331
Epoch #225: loss=0.09255085015735988
Epoch #226: loss=0.0699870043899864
Epoch #227: loss=0.07155923157863851
Epoch #228: loss=0.04556297557428479
Epoch #229: loss=0.061653197410383394
Epoch #230: loss=0.04514667431690863
Epoch #231: loss=0.055304751897762926
Epoch #232: loss=0.062000019933163585
Epoch #233: loss=0.08599785124949579
Epoch #234: loss=0.09022425565802093
Epoch #235: loss=0.08223327706634466
Epoch #236: loss=0.07035182461342109
Epoch #237: loss=0.07612425511303757
Epoch #238: loss=0.0551190856411787
Epoch #239: loss=0.06276022901459198
Epoch #240: loss=0.05473918942568291
Epoch #241: loss=0.06294203119718336
Epoch #242: loss=0.08549285029792893
Epoch #243: loss=0.08255638749272164
Epoch #244: loss=0.12298749327393514
Epoch #245: loss=0.15264348163535552
Epoch #246: loss=0.12172534862267119
Epoch #247: loss=0.07326337482248034
Epoch #248: loss=0.0646461624253009
Epoch #249: loss=0.0523402094175773

Training time: 0:18:09.879850

Finished.
n2one setting ettm1_ettm2_weather_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm1_ettm2_weather_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='ettm1_ettm2_weather_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.38148e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.91361e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.38148e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3793324072285608, 'MAE': 0.43972897791476395}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='ettm1_electricity_traffic_weather', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/ettm1_electricity_traffic_weather_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.931107928872597
Epoch #1: loss=0.35393813514440764
Epoch #2: loss=0.25251237781199276
Epoch #3: loss=0.18579420381393588
Epoch #4: loss=0.13916605069592106
Epoch #5: loss=0.1272655142257448
Epoch #6: loss=0.09350656411747953
Epoch #7: loss=0.08110282916926825
Epoch #8: loss=0.08312545979288635
Epoch #9: loss=0.07784335613517915
Epoch #10: loss=0.06270035346607357
Epoch #11: loss=0.0576717455239707
Epoch #12: loss=0.05436528000873742
Epoch #13: loss=0.04547518053603526
Epoch #14: loss=0.05073653927347699
Epoch #15: loss=0.043366755866903625
Epoch #16: loss=0.04283093189606901
Epoch #17: loss=0.03976294198779572
Epoch #18: loss=0.03311902214124127
Epoch #19: loss=0.05067749130873574
Epoch #20: loss=0.037116603543562054
Epoch #21: loss=0.0375048727146827
Epoch #22: loss=0.02882703979677422
Epoch #23: loss=0.03252424256829354
Epoch #24: loss=0.0370780233669736
Epoch #25: loss=0.02652189678390373
Epoch #26: loss=0.029214174614658153
Epoch #27: loss=0.030898699325034164
Epoch #28: loss=0.027212989814339738
Epoch #29: loss=0.03657593476895212
Epoch #30: loss=0.03386238837723437
Epoch #31: loss=0.021480590935517865
Epoch #32: loss=0.025960164000690518
Epoch #33: loss=0.022708269159050016
Epoch #34: loss=0.023504617459810584
Epoch #35: loss=0.023014103420237155
Epoch #36: loss=0.028963044231574312
Epoch #37: loss=0.02752855193842256
Epoch #38: loss=0.02322770660276979
Epoch #39: loss=0.02369884909693625
Epoch #40: loss=0.02092800883010419
Epoch #41: loss=0.020970598330695495
Epoch #42: loss=0.023291009611003558
Epoch #43: loss=0.019593341414268953
Epoch #44: loss=0.02039827549734418
Epoch #45: loss=0.023999226404798644
Epoch #46: loss=0.020094303449508008
Epoch #47: loss=0.02396165588460328
Epoch #48: loss=0.023497115355652954
Epoch #49: loss=0.01884235375948235
Epoch #50: loss=0.01643909107343595
Epoch #51: loss=0.017667123464832644
Epoch #52: loss=0.021620114358785164
Epoch #53: loss=0.02683422106301954
Epoch #54: loss=0.01912776711039039
Epoch #55: loss=0.0165003121334088
Epoch #56: loss=0.018967060244462805
Epoch #57: loss=0.01775883334883504
Epoch #58: loss=0.01920575489744269
Epoch #59: loss=0.01735670901014332
Epoch #60: loss=0.02070343517290417
Epoch #61: loss=0.015688691355768003
Epoch #62: loss=0.026182906512604246
Epoch #63: loss=0.015605118787264428
Epoch #64: loss=0.015908060901699068
Epoch #65: loss=0.014892495084877439
Epoch #66: loss=0.01956477714220604
Epoch #67: loss=0.019767889136507663
Epoch #68: loss=0.027568297760134572
Epoch #69: loss=0.018518273696493257
Epoch #70: loss=0.013541037880349905
Epoch #71: loss=0.01716555874020846
Epoch #72: loss=0.01903288270209412
Epoch #73: loss=0.023197110095724546
Epoch #74: loss=0.018368427227151037
Epoch #75: loss=0.014660782985137318
Epoch #76: loss=0.01787337412665022
Epoch #77: loss=0.01607952802291724
Epoch #78: loss=0.015715808898151364
Epoch #79: loss=0.014763739335968076
Epoch #80: loss=0.02493613469982176
Epoch #81: loss=0.01617207258788737
Epoch #82: loss=0.01756568131643943
Epoch #83: loss=0.01808779589785549
Epoch #84: loss=0.015812714318849803
Epoch #85: loss=0.012637057244483302
Epoch #86: loss=0.013005803776074765
Epoch #87: loss=0.015679688541315014
Epoch #88: loss=0.020667627099825697
Epoch #89: loss=0.023041278828072866
Epoch #90: loss=0.019152182952374922
Epoch #91: loss=0.01579935837152498
Epoch #92: loss=0.011267814036092786
Epoch #93: loss=0.017372540670583504
Epoch #94: loss=0.014829278378399112
Epoch #95: loss=0.01822281623443829
Epoch #96: loss=0.019991952713772645
Epoch #97: loss=0.013535972014846803
Epoch #98: loss=0.01597784083636218
Epoch #99: loss=0.015297175050177038
Epoch #100: loss=0.01161420921321298
Epoch #101: loss=0.012382037954220784
Epoch #102: loss=0.01613250761562443
Epoch #103: loss=0.015269363255165593
Epoch #104: loss=0.012850368245777705
Epoch #105: loss=0.013714629583517338
Epoch #106: loss=0.021181714258535544
Epoch #107: loss=0.014505381433180625
Epoch #108: loss=0.012177138840593588
Epoch #109: loss=0.011220072052519306
Epoch #110: loss=0.01353800558107218
Epoch #111: loss=0.013665922339833875
Epoch #112: loss=0.01465541554987526
Epoch #113: loss=0.014490905546353744
Epoch #114: loss=0.014330348385246012
Epoch #115: loss=0.01886936128370895
Epoch #116: loss=0.01294586244426891
Epoch #117: loss=0.019663767401187693
Epoch #118: loss=0.018789288571383993
Epoch #119: loss=0.02476894260876999
Epoch #120: loss=0.0103093251344661
Epoch #121: loss=0.015093540291619304
Epoch #122: loss=0.011791315432778678
Epoch #123: loss=0.012381769015575897
Epoch #124: loss=0.01340144696028339
Epoch #125: loss=0.014068482504426655
Epoch #126: loss=0.011955286087406243
Epoch #127: loss=0.014276652520242888
Epoch #128: loss=0.011054816465867425
Epoch #129: loss=0.01198607401282538
Epoch #130: loss=0.010904887152981723
Epoch #131: loss=0.011308574850098936
Epoch #132: loss=0.011768315337752432
Epoch #133: loss=0.013549747562835559
Epoch #134: loss=0.012515454014414229
Epoch #135: loss=0.01073511563112423
Epoch #136: loss=0.011956196295360598
Epoch #137: loss=0.01350287310807125
Epoch #138: loss=0.011250075317783754
Epoch #139: loss=0.01774428671428201
Epoch #140: loss=0.012153290508810687
Epoch #141: loss=0.01444849509093505
Epoch #142: loss=0.008438566705122778
Epoch #143: loss=0.015993041745313064
Epoch #144: loss=0.013263346190439331
Epoch #145: loss=0.01555648888270447
Epoch #146: loss=0.013466611902030771
Epoch #147: loss=0.011982201459327595
Epoch #148: loss=0.01831893989324644
Epoch #149: loss=0.010242390257989144
Epoch #150: loss=0.016245891173433637
Epoch #151: loss=0.009930697559571317
Epoch #152: loss=0.012712460155880316
Epoch #153: loss=0.010376877006972075
Epoch #154: loss=0.01330456971596415
Epoch #155: loss=0.01910266490413647
Epoch #156: loss=0.01163721092711361
Epoch #157: loss=0.012105162519786019
Epoch #158: loss=0.008548153878846129
Epoch #159: loss=0.024435725117261622
Epoch #160: loss=0.012547378491712391
Epoch #161: loss=0.010685308623429651
Epoch #162: loss=0.013753873393675274
Epoch #163: loss=0.008384362130223574
Epoch #164: loss=0.011640692256809953
Epoch #165: loss=0.012907421603437693
Epoch #166: loss=0.014272595641738068
Epoch #167: loss=0.019954978897169254
Epoch #168: loss=0.008774997273850785
Epoch #169: loss=0.014926215349617853
Epoch #170: loss=0.011825141745653947
Epoch #171: loss=0.008199627692112223
Epoch #172: loss=0.011104757832233235
Epoch #173: loss=0.011997042664328637
Epoch #174: loss=0.012335418620980325
Epoch #175: loss=0.01290624764363604
Epoch #176: loss=0.011330165416701243
Epoch #177: loss=0.009259215993644501
Epoch #178: loss=0.011387130195195272
Epoch #179: loss=0.009898910135723513
Epoch #180: loss=0.012527487522203926
Epoch #181: loss=0.01394092259118925
Epoch #182: loss=0.008825676378266329
Epoch #183: loss=0.009636188697317504
Epoch #184: loss=0.01207988364047077
Epoch #185: loss=0.010690923261481881
Epoch #186: loss=0.013135220454056313
Epoch #187: loss=0.010117386944438906
Epoch #188: loss=0.00987002028922629
Epoch #189: loss=0.012014336883449224
Epoch #190: loss=0.012150822355638934
Epoch #191: loss=0.012803631505239985
Epoch #192: loss=0.012350436487568154
Epoch #193: loss=0.013844683247147944
Epoch #194: loss=0.015818594329915062
Epoch #195: loss=0.008852353840574116
Epoch #196: loss=0.013662225483989697
Epoch #197: loss=0.009214511467388413
Epoch #198: loss=0.013880286402485073
Epoch #199: loss=0.013567644745572564
Epoch #200: loss=0.00917290108228953
Epoch #201: loss=0.010693477036788789
Epoch #202: loss=0.014425762259977135
Epoch #203: loss=0.010232462238169229
Epoch #204: loss=0.012729352992314265
Epoch #205: loss=0.013391581292528484
Epoch #206: loss=0.016718443215221833
Epoch #207: loss=0.00970142004501168
Epoch #208: loss=0.01245512445809746
Epoch #209: loss=0.012185194929400898
Epoch #210: loss=0.011211359650411902
Epoch #211: loss=0.010735050284365272
Epoch #212: loss=0.013046982437022127
Epoch #213: loss=0.00808764911522959
Epoch #214: loss=0.009768622467735903
Epoch #215: loss=0.010027488272227528
Epoch #216: loss=0.011186664568028436
Epoch #217: loss=0.014478721036494625
Epoch #218: loss=0.007922041643058812
Epoch #219: loss=0.01091659562829233
Epoch #220: loss=0.009305646021353734
Epoch #221: loss=0.011414259527042364
Epoch #222: loss=0.00955008357123006
Epoch #223: loss=0.00942698456117975
Epoch #224: loss=0.025287870650745538
Epoch #225: loss=0.010123677365207515
Epoch #226: loss=0.012455002188140557
Epoch #227: loss=0.009189597851865692
Epoch #228: loss=0.010449895480299154
Epoch #229: loss=0.011563009691348807
Epoch #230: loss=0.01275759318632332
Epoch #231: loss=0.011369956134172961
Epoch #232: loss=0.008869770411414436
Epoch #233: loss=0.008902246812031677
Epoch #234: loss=0.010680689441716233
Epoch #235: loss=0.012118815454238353
Epoch #236: loss=0.012305232807414197
Epoch #237: loss=0.01356218996787917
Epoch #238: loss=0.007595263714235209
Epoch #239: loss=0.009717725938747611
Epoch #240: loss=0.012002597253120287
Epoch #241: loss=0.008243714691738593
Epoch #242: loss=0.00921426942438943
Epoch #243: loss=0.011331205143923414
Epoch #244: loss=0.00761689164442703
Epoch #245: loss=0.01145002420867133
Epoch #246: loss=0.010871314375979964
Epoch #247: loss=0.01139899138927786
Epoch #248: loss=0.008405338446766377
Epoch #249: loss=0.015771360742166774

Training time: 5:01:32.613486

Finished.
n2one setting ettm1_electricity_traffic_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm1_electricity_traffic_weather_epochs_250_seed_2021/model.pkl', muti_dataset='ettm1_electricity_traffic_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.62497e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.26778615025621544, 'MAE': 0.3463617877816431}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='ettm1_electricity_traffic_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/ettm1_electricity_traffic_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.9065636930097756
Epoch #1: loss=0.3402826504691964
Epoch #2: loss=0.22977941966121287
Epoch #3: loss=0.16714538044347343
Epoch #4: loss=0.12816185101451424
Epoch #5: loss=0.09917045618405879
Epoch #6: loss=0.0914892463049171
Epoch #7: loss=0.08073429012912854
Epoch #8: loss=0.06797809263973337
Epoch #9: loss=0.06255405558352227
Epoch #10: loss=0.06282386696121087
Epoch #11: loss=0.054498475522830304
Epoch #12: loss=0.05257547831708277
Epoch #13: loss=0.05084622301337171
Epoch #14: loss=0.04667140097557234
Epoch #15: loss=0.04613543245104605
Epoch #16: loss=0.03510243889107485
Epoch #17: loss=0.03915271639931225
Epoch #18: loss=0.040203298990438056
Epoch #19: loss=0.03687111307795589
Epoch #20: loss=0.03189085654200778
Epoch #21: loss=0.03812254848551027
Epoch #22: loss=0.029693999938415393
Epoch #23: loss=0.03932360659061719
Epoch #24: loss=0.03181788955385891
Epoch #25: loss=0.03009207092487825
Epoch #26: loss=0.034800892840531936
Epoch #27: loss=0.028321604216808356
Epoch #28: loss=0.029034567832551237
Epoch #29: loss=0.024298722969643933
Epoch #30: loss=0.04144385186547589
Epoch #31: loss=0.026000284551038096
Epoch #32: loss=0.03192424890265634
Epoch #33: loss=0.023207618783076235
Epoch #34: loss=0.023910909630356282
Epoch #35: loss=0.027807387801849156
Epoch #36: loss=0.03014281295367188
Epoch #37: loss=0.030126941693431858
Epoch #38: loss=0.02102990516609808
Epoch #39: loss=0.024574172912501014
Epoch #40: loss=0.0273509935358502
Epoch #41: loss=0.02243778401547609
Epoch #42: loss=0.027975563690459167
Epoch #43: loss=0.018993338164264226
Epoch #44: loss=0.027955399218862628
Epoch #45: loss=0.02004312650292233
Epoch #46: loss=0.0277720615134583
Epoch #47: loss=0.01823891085581645
Epoch #48: loss=0.02421453722588758
Epoch #49: loss=0.025841918283784467
Epoch #50: loss=0.02217559693033494
Epoch #51: loss=0.01959923064776273
Epoch #52: loss=0.025752792399575758
Epoch #53: loss=0.02162453852094727
Epoch #54: loss=0.02145165113104428
Epoch #55: loss=0.01860340671558026
Epoch #56: loss=0.018037228847820136
Epoch #57: loss=0.024134538656030123
Epoch #58: loss=0.019784725064290888
Epoch #59: loss=0.02394618188017362
Epoch #60: loss=0.02377130459264206
Epoch #61: loss=0.016005848279444054
Epoch #62: loss=0.017732103236489147
Epoch #63: loss=0.017865310049229945
Epoch #64: loss=0.0184956319112863
Epoch #65: loss=0.018348776733864196
Epoch #66: loss=0.022255121016037726
Epoch #67: loss=0.015945317943273623
Epoch #68: loss=0.017373262413354365
Epoch #69: loss=0.015634954136571795
Epoch #70: loss=0.015568567172846154
Epoch #71: loss=0.019764861029260148
Epoch #72: loss=0.016405318295196692
Epoch #73: loss=0.014718663775689044
Epoch #74: loss=0.021542056742735974
Epoch #75: loss=0.020536980678105787
Epoch #76: loss=0.015285388333069203
Epoch #77: loss=0.016924948152038464
Epoch #78: loss=0.01576084261889412
Epoch #79: loss=0.017556911594901324
Epoch #80: loss=0.018467127928934905
Epoch #81: loss=0.016789758318502296
Epoch #82: loss=0.01714531469647734
Epoch #83: loss=0.016379862787561705
Epoch #84: loss=0.012358889437547711
Epoch #85: loss=0.022575460206221375
Epoch #86: loss=0.014886120371954898
Epoch #87: loss=0.014553277144558572
Epoch #88: loss=0.017787581427023687
Epoch #89: loss=0.015064857358114093
Epoch #90: loss=0.018020701272692646
Epoch #91: loss=0.013763831269771102
Epoch #92: loss=0.016889727353289787
Epoch #93: loss=0.013909953367212026
Epoch #94: loss=0.0189202973433052
Epoch #95: loss=0.018185329641498407
Epoch #96: loss=0.02037606399663278
Epoch #97: loss=0.013671236030014867
Epoch #98: loss=0.01747820470674361
Epoch #99: loss=0.013294595102673515
Epoch #100: loss=0.016648965180662077
Epoch #101: loss=0.011924837583794333
Epoch #102: loss=0.0140980297407128
Epoch #103: loss=0.015144796978356665
Epoch #104: loss=0.015536584825580494
Epoch #105: loss=0.015122494503975608
Epoch #106: loss=0.018572165800005543
Epoch #107: loss=0.01705452055573131
Epoch #108: loss=0.01468314781463271
Epoch #109: loss=0.015618917932285472
Epoch #110: loss=0.012800001126291585
Epoch #111: loss=0.015783902314726338
Epoch #112: loss=0.022619173487225322
Epoch #113: loss=0.012221142746259794
Epoch #114: loss=0.014923033458433507
Epoch #115: loss=0.015731551327626703
Epoch #116: loss=0.013668695896711493
Epoch #117: loss=0.013101121691215061
Epoch #118: loss=0.014254856100786297
Epoch #119: loss=0.016889714903496774
Epoch #120: loss=0.012591912580558433
Epoch #121: loss=0.015688272638299878
Epoch #122: loss=0.014274189312917726
Epoch #123: loss=0.026272667357521814
Epoch #124: loss=0.015454477581427782
Epoch #125: loss=0.013251005261873993
Epoch #126: loss=0.016420806357988618
Epoch #127: loss=0.014291307488444746
Epoch #128: loss=0.01372584152689065
Epoch #129: loss=0.013107491037856156
Epoch #130: loss=0.013359979638299954
Epoch #131: loss=0.01597023408262105
Epoch #132: loss=0.014271315718251753
Epoch #133: loss=0.012861277167742956
Epoch #134: loss=0.017769716393733096
Epoch #135: loss=0.013762855126922284
Epoch #136: loss=0.012648734782931133
Epoch #137: loss=0.014112414200492375
Epoch #138: loss=0.012075083340539871
Epoch #139: loss=0.01254425770183996
Epoch #140: loss=0.03052666470933955
Epoch #141: loss=0.014853203049559687
Epoch #142: loss=0.009609884816688861
Epoch #143: loss=0.019136702428868634
Epoch #144: loss=0.017922319515867136
Epoch #145: loss=0.016212173377274312
Epoch #146: loss=0.013944390858385534
Epoch #147: loss=0.011719814642500435
Epoch #148: loss=0.012169235575026374
Epoch #149: loss=0.013794618794119633
Epoch #150: loss=0.015928491558392453
Epoch #151: loss=0.01280470938768901
Epoch #152: loss=0.012905778484193324
Epoch #153: loss=0.017183262302374432
Epoch #154: loss=0.014552960493599922
Epoch #155: loss=0.010520032111248996
Epoch #156: loss=0.013513031303487445
Epoch #157: loss=0.014098722895892288
Epoch #158: loss=0.015604036521042981
Epoch #159: loss=0.009794193683193102
Epoch #160: loss=0.011791522283498904
Epoch #161: loss=0.011974421906207119
Epoch #162: loss=0.016252395438780768
Epoch #163: loss=0.012526766594211992
Epoch #164: loss=0.012984980885960245
Epoch #165: loss=0.011412571261975602
Epoch #166: loss=0.013218151892398054
Epoch #167: loss=0.012063322713061665
Epoch #168: loss=0.013682435020707456
Epoch #169: loss=0.013177067111033215
Epoch #170: loss=0.01616654525475713
Epoch #171: loss=0.015232002421731361
Epoch #172: loss=0.012253506505821589
Epoch #173: loss=0.010068329234960831
Epoch #174: loss=0.013744434209767797
Epoch #175: loss=0.010211364921023945
Epoch #176: loss=0.014012500059317015
Epoch #177: loss=0.013317679036778635
Epoch #178: loss=0.010500985580309954
Epoch #179: loss=0.013878188008045817
Epoch #180: loss=0.0113638644655349
Epoch #181: loss=0.013190463969055695
Epoch #182: loss=0.012304222382850206
Epoch #183: loss=0.010101863382776527
Epoch #184: loss=0.013896662952430111
Epoch #185: loss=0.012991386031616323
Epoch #186: loss=0.01446458087873441
Epoch #187: loss=0.011712637949420063
Epoch #188: loss=0.015016431163361307
Epoch #189: loss=0.012245754557454329
Epoch #190: loss=0.011928884447775507
Epoch #191: loss=0.01365386853101582
Epoch #192: loss=0.012880778708318446
Epoch #193: loss=0.012278721367066417
Epoch #194: loss=0.010907050873411117
Epoch #195: loss=0.014297252270364406
Epoch #196: loss=0.014735285784586638
Epoch #197: loss=0.018386676264809602
Epoch #198: loss=0.011913803234826556
Epoch #199: loss=0.011629255464326275
Epoch #200: loss=0.011548063714041615
Epoch #201: loss=0.01226827903169253
Epoch #202: loss=0.014431408909953335
Epoch #203: loss=0.015354389701971859
Epoch #204: loss=0.01165164219996231
Epoch #205: loss=0.013471161270147644
Epoch #206: loss=0.01065383593804306
Epoch #207: loss=0.015772272080931498
Epoch #208: loss=0.012541527714323254
Epoch #209: loss=0.013323845366026587
Epoch #210: loss=0.012248335106356633
Epoch #211: loss=0.015690796923477992
Epoch #212: loss=0.013800833830746479
Epoch #213: loss=0.0177127956149418
Epoch #214: loss=0.01611058821793157
Epoch #215: loss=0.01758118748173384
Epoch #216: loss=0.009644776521725759
Epoch #217: loss=0.012031706171084365
Epoch #218: loss=0.013895555579065952
Epoch #219: loss=0.01044681753553115
Epoch #220: loss=0.011747844938945975
Epoch #221: loss=0.011323695832415766
Epoch #222: loss=0.014302635991182868
Epoch #223: loss=0.009533822029112713
Epoch #224: loss=0.014283204565875344
Epoch #225: loss=0.009838948664029292
Epoch #226: loss=0.013474453985214078
Epoch #227: loss=0.011867944294454673
Epoch #228: loss=0.01068758042028413
Epoch #229: loss=0.01056490743167841
Epoch #230: loss=0.011506963907999846
Epoch #231: loss=0.013937268879150502
Epoch #232: loss=0.015506673435050647
Epoch #233: loss=0.009802517942790199
Epoch #234: loss=0.010386627593342898
Epoch #235: loss=0.011093541580277918
Epoch #236: loss=0.012979175483265264
Epoch #237: loss=0.011347553497251528
Epoch #238: loss=0.010932844341190195
Epoch #239: loss=0.011852784494626024
Epoch #240: loss=0.01267752841342066
Epoch #241: loss=0.011316723641841641
Epoch #242: loss=0.010829593661227578
Epoch #243: loss=0.019091319372271456
Epoch #244: loss=0.011686414706587274
Epoch #245: loss=0.008973720904434167
Epoch #246: loss=0.008874062850733637
Epoch #247: loss=0.009123246509425099
Epoch #248: loss=0.01179101558145234
Epoch #249: loss=0.008598696611691483

Training time: 4:54:36.949275

Finished.
n2one setting ettm1_electricity_traffic_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm1_electricity_traffic_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='ettm1_electricity_traffic_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.74835e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.52397e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.8417324995635109, 'MAE': 0.7465147269343873}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='ettm1_electricity_weather_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/ettm1_electricity_weather_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.9302246974465624
Epoch #1: loss=0.9001666353048523
Epoch #2: loss=0.642458838110413
Epoch #3: loss=0.525182331479638
Epoch #4: loss=0.4517778770926872
Epoch #5: loss=0.4074010581510966
Epoch #6: loss=0.37755372839384393
Epoch #7: loss=0.328895081302833
Epoch #8: loss=0.304872417425523
Epoch #9: loss=0.29103278737169147
Epoch #10: loss=0.2513036337665847
Epoch #11: loss=0.257174062456101
Epoch #12: loss=0.2156220336185127
Epoch #13: loss=0.20937555464483348
Epoch #14: loss=0.19475557866806542
Epoch #15: loss=0.18215215972578916
Epoch #16: loss=0.17616281026333083
Epoch #17: loss=0.16310971478621164
Epoch #18: loss=0.1503144867382333
Epoch #19: loss=0.15283112324611411
Epoch #20: loss=0.14342877732925727
Epoch #21: loss=0.14386630205875212
Epoch #22: loss=0.12432566700411625
Epoch #23: loss=0.11552043883587981
Epoch #24: loss=0.1031660274297121
Epoch #25: loss=0.10688528370193608
Epoch #26: loss=0.10863204449008071
Epoch #27: loss=0.08917477631768406
Epoch #28: loss=0.09864543334840507
Epoch #29: loss=0.08184726926360707
Epoch #30: loss=0.08885013129144825
Epoch #31: loss=0.07519920525405699
Epoch #32: loss=0.08842286718831159
Epoch #33: loss=0.07087536067371078
Epoch #34: loss=0.0655054827106231
Epoch #35: loss=0.06595421244283436
Epoch #36: loss=0.058690924828495486
Epoch #37: loss=0.06707405699976807
Epoch #38: loss=0.05816062104498937
Epoch #39: loss=0.06615778018308223
Epoch #40: loss=0.07285327139651515
Epoch #41: loss=0.05189544626045972
Epoch #42: loss=0.05723316951647218
Epoch #43: loss=0.056313947574082826
Epoch #44: loss=0.06657382355598336
Epoch #45: loss=0.06116637167815994
Epoch #46: loss=0.043281336198560894
Epoch #47: loss=0.042593641330671235
Epoch #48: loss=0.04385001517010374
Epoch #49: loss=0.05273814056872751
Epoch #50: loss=0.049402793680439844
Epoch #51: loss=0.04077998936733567
Epoch #52: loss=0.04730564256833581
Epoch #53: loss=0.054685717369709674
Epoch #54: loss=0.11355690479334546
Epoch #55: loss=0.05621442207086913
Epoch #56: loss=0.0428448915786919
Epoch #57: loss=0.046914359601723445
Epoch #58: loss=0.039135375616771724
Epoch #59: loss=0.033992719277039764
Epoch #60: loss=0.04889429882620436
Epoch #61: loss=0.03692842350415173
Epoch #62: loss=0.0373466264181694
Epoch #63: loss=0.03748744951123423
Epoch #64: loss=0.04260876103745814
Epoch #65: loss=0.043000710231463214
Epoch #66: loss=0.04851978896007634
Epoch #67: loss=0.03964813423560566
Epoch #68: loss=0.038668164873337935
Epoch #69: loss=0.03612950405607234
Epoch #70: loss=0.05888688201504592
Epoch #71: loss=0.037143378154644385
Epoch #72: loss=0.029350586989360144
Epoch #73: loss=0.04307062148951157
Epoch #74: loss=0.050078644929167464
Epoch #75: loss=0.06424194109299133
Epoch #76: loss=0.0351586518624716
Epoch #77: loss=0.026845190595502104
Epoch #78: loss=0.05774263746348143
Epoch #79: loss=0.04092998657683471
Epoch #80: loss=0.028022607531439248
Epoch #81: loss=0.02447736152489746
Epoch #82: loss=0.039452051013883695
Epoch #83: loss=0.0534757168726904
Epoch #84: loss=0.02631168986850067
Epoch #85: loss=0.026880764528724767
Epoch #86: loss=0.04228008629167656
Epoch #87: loss=0.028570967109662688
Epoch #88: loss=0.02930579622514047
Epoch #89: loss=0.030916726729251148
Epoch #90: loss=0.02710819249951072
Epoch #91: loss=0.02839492441471819
Epoch #92: loss=0.030631385599530193
Epoch #93: loss=0.05502758466888631
Epoch #94: loss=0.0370063971662245
Epoch #95: loss=0.03097087371988792
Epoch #96: loss=0.03914150868827487
Epoch #97: loss=0.030607732429227645
Epoch #98: loss=0.026194910978760998
Epoch #99: loss=0.036836621258821325
Epoch #100: loss=0.03298219083363058
Epoch #101: loss=0.03566199976615633
Epoch #102: loss=0.023967905188567142
Epoch #103: loss=0.03863781734539547
Epoch #104: loss=0.02530080578200865
Epoch #105: loss=0.027541038737526734
Epoch #106: loss=0.03350759980706447
Epoch #107: loss=0.02694412188660455
Epoch #108: loss=0.028502592989663424
Epoch #109: loss=0.021383329072128726
Epoch #110: loss=0.03207638281218764
Epoch #111: loss=0.03135560099747989
Epoch #112: loss=0.025637616989612477
Epoch #113: loss=0.05740731376951021
Epoch #114: loss=0.03847952816117545
Epoch #115: loss=0.027027272982866366
Epoch #116: loss=0.033041661370499825
Epoch #117: loss=0.023209606598848936
Epoch #118: loss=0.031716235680982745
Epoch #119: loss=0.029212290140268358
Epoch #120: loss=0.032215294237006864
Epoch #121: loss=0.025474696739480062
Epoch #122: loss=0.0181918031899602
Epoch #123: loss=0.04816393065679808
Epoch #124: loss=0.027125211441641307
Epoch #125: loss=0.02570321225933985
Epoch #126: loss=0.04865982835855376
Epoch #127: loss=0.022307815769104584
Epoch #128: loss=0.020104262432976642
Epoch #129: loss=0.04809707037428944
Epoch #130: loss=0.025993435404262164
Epoch #131: loss=0.02648797586081229
Epoch #132: loss=0.025327767949370677
Epoch #133: loss=0.030250449292107278
Epoch #134: loss=0.04864867267283469
Epoch #135: loss=0.026635559055638688
Epoch #136: loss=0.020141238463429297
Epoch #137: loss=0.023728163684355704
Epoch #138: loss=0.02205268815229774
Epoch #139: loss=0.03118903538427835
Epoch #140: loss=0.028244682159872796
Epoch #141: loss=0.017960579968038487
Epoch #142: loss=0.021317826700555872
Epoch #143: loss=0.028283744283472797
Epoch #144: loss=0.02585652363333912
Epoch #145: loss=0.019298369128223955
Epoch #146: loss=0.018557964159841164
Epoch #147: loss=0.023522015523433918
Epoch #148: loss=0.024798137000940048
Epoch #149: loss=0.027309394157822423
Epoch #150: loss=0.03139531592945975
Epoch #151: loss=0.03328761836062847
Epoch #152: loss=0.02183916014724136
Epoch #153: loss=0.023218853449731392
Epoch #154: loss=0.02150156557282606
Epoch #155: loss=0.021637128281252475
Epoch #156: loss=0.022177247509622407
Epoch #157: loss=0.022600113629405463
Epoch #158: loss=0.019942497542729764
Epoch #159: loss=0.020681221325642585
Epoch #160: loss=0.02251050044919868
Epoch #161: loss=0.02634621644901529
Epoch #162: loss=0.02516183441602167
Epoch #163: loss=0.026027207584626073
Epoch #164: loss=0.02837907327237269
Epoch #165: loss=0.022548315719614832
Epoch #166: loss=0.02018330165721308
Epoch #167: loss=0.016601018092096936
Epoch #168: loss=0.025325416726609845
Epoch #169: loss=0.024213376659212908
Epoch #170: loss=0.02211955538282904
Epoch #171: loss=0.03124670276454589
Epoch #172: loss=0.018668127295025497
Epoch #173: loss=0.02431313561299775
Epoch #174: loss=0.023055162625908954
Epoch #175: loss=0.022589168310148865
Epoch #176: loss=0.019409797377178264
Epoch #177: loss=0.022059026150391667
Epoch #178: loss=0.01908152063025411
Epoch #179: loss=0.031191112034186935
Epoch #180: loss=0.02805990774945936
Epoch #181: loss=0.0195043082215411
Epoch #182: loss=0.020710208822840755
Epoch #183: loss=0.018379112029997785
Epoch #184: loss=0.020609041728725647
Epoch #185: loss=0.021562237149871672
Epoch #186: loss=0.02060489491683614
Epoch #187: loss=0.017335230227759554
Epoch #188: loss=0.019176233385701007
Epoch #189: loss=0.015968660505926185
Epoch #190: loss=0.01839164540819223
Epoch #191: loss=0.017401103576555558
Epoch #192: loss=0.02225028524029608
Epoch #193: loss=0.025891222050343513
Epoch #194: loss=0.026880948043484343
Epoch #195: loss=0.03514184054818076
Epoch #196: loss=0.019255357770926112
Epoch #197: loss=0.020466930346017643
Epoch #198: loss=0.014343043445905956
Epoch #199: loss=0.017086861031212656
Epoch #200: loss=0.013971770090964506
Epoch #201: loss=0.018688007673125236
Epoch #202: loss=0.017490421313044357
Epoch #203: loss=0.022734810337532423
Epoch #204: loss=0.015333695754331226
Epoch #205: loss=0.012741956886863387
Epoch #206: loss=0.017007323787636707
Epoch #207: loss=0.015059862626351344
Epoch #208: loss=0.020997728408225863
Epoch #209: loss=0.021981767840432816
Epoch #210: loss=0.02140088610432513
Epoch #211: loss=0.018487580101160955
Epoch #212: loss=0.01739754299254696
Epoch #213: loss=0.016403440671210825
Epoch #214: loss=0.027727225944565233
Epoch #215: loss=0.02208171516534099
Epoch #216: loss=0.03071134008627507
Epoch #217: loss=0.018979008788722593
Epoch #218: loss=0.01935936726344739
Epoch #219: loss=0.03054213503603391
Epoch #220: loss=0.019185921748689137
Epoch #221: loss=0.01316305932613049
Epoch #222: loss=0.014606868102558115
Epoch #223: loss=0.017908954302827407
Epoch #224: loss=0.024934715689815163
Epoch #225: loss=0.0203445124119594
Epoch #226: loss=0.018264680528390486
Epoch #227: loss=0.023653819347392066
Epoch #228: loss=0.04182912172880685
Epoch #229: loss=0.023516800704738508
Epoch #230: loss=0.019592949136286272
Epoch #231: loss=0.015084204236789774
Epoch #232: loss=0.013113850794234466
Epoch #233: loss=0.025780667456711738
Epoch #234: loss=0.017294615718009346
Epoch #235: loss=0.018060116935934862
Epoch #236: loss=0.030530610075983844
Epoch #237: loss=0.020938344658581447
Epoch #238: loss=0.01710535052532707
Epoch #239: loss=0.024186751068584988
Epoch #240: loss=0.021188018653641044
Epoch #241: loss=0.022109176841427068
Epoch #242: loss=0.02413681553628377
Epoch #243: loss=0.0220091580277305
Epoch #244: loss=0.014039681617188384
Epoch #245: loss=0.012979569240003097
Epoch #246: loss=0.017163883104743538
Epoch #247: loss=0.023490347140888514
Epoch #248: loss=0.016751841839486886
Epoch #249: loss=0.01618403254582259

Training time: 1:42:48.949983

Finished.
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='ettm1_traffic_weather_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/ettm1_traffic_weather_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.1839715928135002
Epoch #1: loss=0.4610579213109011
Epoch #2: loss=0.3331794625244698
Epoch #3: loss=0.2770426623613595
Epoch #4: loss=0.22203473807564117
Epoch #5: loss=0.1861453128582259
Epoch #6: loss=0.15690054879816456
Epoch #7: loss=0.13567923279242977
Epoch #8: loss=0.12119373854130605
Epoch #9: loss=0.10670717420054408
Epoch #10: loss=0.09916217610252305
Epoch #11: loss=0.1109318785141443
Epoch #12: loss=0.08520691012224345
Epoch #13: loss=0.07440775829699002
Epoch #14: loss=0.08494252110025388
Epoch #15: loss=0.0759820573190032
Epoch #16: loss=0.06083685672116007
Epoch #17: loss=0.061449150762252734
Epoch #18: loss=0.06053161905444912
Epoch #19: loss=0.053783208126399376
Epoch #20: loss=0.05770580903403646
Epoch #21: loss=0.05629026976156294
Epoch #22: loss=0.046648811531492404
Epoch #23: loss=0.04768906481055257
Epoch #24: loss=0.05499360099054417
Epoch #25: loss=0.049893267676562825
Epoch #26: loss=0.04515385748256335
Epoch #27: loss=0.05215320204753766
Epoch #28: loss=0.03733536668656786
Epoch #29: loss=0.043716960447858874
Epoch #30: loss=0.04030214107090704
Epoch #31: loss=0.0372248266932304
Epoch #32: loss=0.035827395665103026
Epoch #33: loss=0.03728839418686035
Epoch #34: loss=0.038306734379629434
Epoch #35: loss=0.05028014099831224
Epoch #36: loss=0.03975748078555665
Epoch #37: loss=0.03759289829996378
Epoch #38: loss=0.0371092522797681
Epoch #39: loss=0.03023597334305958
Epoch #40: loss=0.03821367661841162
Epoch #41: loss=0.02907947366728623
Epoch #42: loss=0.029768541046339185
Epoch #43: loss=0.028007431332833906
Epoch #44: loss=0.026331904643898587
Epoch #45: loss=0.029269446329806152
Epoch #46: loss=0.0356320171236921
Epoch #47: loss=0.03472838327069146
Epoch #48: loss=0.028321179771557646
Epoch #49: loss=0.034433588860292075
Epoch #50: loss=0.03319218835026917
Epoch #51: loss=0.025202667520585847
Epoch #52: loss=0.0391882133885526
Epoch #53: loss=0.029285400017326886
Epoch #54: loss=0.02809206421620263
Epoch #55: loss=0.02250109653552335
Epoch #56: loss=0.030691884023464944
Epoch #57: loss=0.02710777579841657
Epoch #58: loss=0.03274810927752672
Epoch #59: loss=0.032752057706604505
Epoch #60: loss=0.021617277537109566
Epoch #61: loss=0.027739274857438434
Epoch #62: loss=0.03571752416185086
Epoch #63: loss=0.028019774619945814
Epoch #64: loss=0.024618864950019036
Epoch #65: loss=0.02029955088844535
Epoch #66: loss=0.02290544476889663
Epoch #67: loss=0.02998712395779663
Epoch #68: loss=0.02770046915362518
Epoch #69: loss=0.02137734761123793
Epoch #70: loss=0.020008907695907983
Epoch #71: loss=0.023815191966838838
Epoch #72: loss=0.025322892336093215
Epoch #73: loss=0.02550917377513438
Epoch #74: loss=0.026715260443006577
Epoch #75: loss=0.02295249350491681
Epoch #76: loss=0.022014802000718963
Epoch #77: loss=0.023930927233289427
Epoch #78: loss=0.029037399372343148
Epoch #79: loss=0.028554090779005677
Epoch #80: loss=0.025923600762863278
Epoch #81: loss=0.02609823697504342
Epoch #82: loss=0.02452022916097769
Epoch #83: loss=0.019837150224331763
Epoch #84: loss=0.02049349371101009
Epoch #85: loss=0.01842561920490239
Epoch #86: loss=0.02335485001036881
Epoch #87: loss=0.027213680840602047
Epoch #88: loss=0.02543234851605286
Epoch #89: loss=0.021563076951160828
Epoch #90: loss=0.022599381353290773
Epoch #91: loss=0.01781762145316411
Epoch #92: loss=0.02403864065581027
Epoch #93: loss=0.021230571771599146
Epoch #94: loss=0.02510536840591629
Epoch #95: loss=0.02724368273177366
Epoch #96: loss=0.01766755089569116
Epoch #97: loss=0.018037610049181092
Epoch #98: loss=0.02245487395370181
Epoch #99: loss=0.034343897665249104
Epoch #100: loss=0.021400619628726244
Epoch #101: loss=0.01807248502116329
Epoch #102: loss=0.017471577760777842
Epoch #103: loss=0.020629652837689763
Epoch #104: loss=0.027383220022841527
Epoch #105: loss=0.01869852909738842
Epoch #106: loss=0.025524083423608443
Epoch #107: loss=0.02032076733505411
Epoch #108: loss=0.018560856660665502
Epoch #109: loss=0.016985643857252323
Epoch #110: loss=0.02136701580607168
Epoch #111: loss=0.016704970540513737
Epoch #112: loss=0.022123214387442185
Epoch #113: loss=0.021533645400342347
Epoch #114: loss=0.017436907497405865
Epoch #115: loss=0.016839104854859115
Epoch #116: loss=0.01975352427509666
Epoch #117: loss=0.02440257521195783
Epoch #118: loss=0.013408850794085615
Epoch #119: loss=0.01831131230769838
Epoch #120: loss=0.01824454864372947
Epoch #121: loss=0.018993773380680267
Epoch #122: loss=0.0141557665776524
Epoch #123: loss=0.015027876798055301
Epoch #124: loss=0.022467287058432206
Epoch #125: loss=0.01429674199912124
Epoch #126: loss=0.01597159066027782
Epoch #127: loss=0.021064598657799957
Epoch #128: loss=0.017101022735486564
Epoch #129: loss=0.017086213967178115
Epoch #130: loss=0.016591433659508437
Epoch #131: loss=0.017670511978187073
Epoch #132: loss=0.0163729658721671
Epoch #133: loss=0.016151160073375213
Epoch #134: loss=0.01926150138518396
Epoch #135: loss=0.018282894759650455
Epoch #136: loss=0.02321155123660842
Epoch #137: loss=0.01652259791670742
Epoch #138: loss=0.021048199256025708
Epoch #139: loss=0.016202463668725138
Epoch #140: loss=0.017028022142791508
Epoch #141: loss=0.017694018321460146
Epoch #142: loss=0.021524557116433213
Epoch #143: loss=0.02048826880615447
Epoch #144: loss=0.025254474526174703
Epoch #145: loss=0.014631693098499505
Epoch #146: loss=0.02423082648539277
Epoch #147: loss=0.017581097944280238
Epoch #148: loss=0.017031654899883675
Epoch #149: loss=0.014801064735923328
Epoch #150: loss=0.014670037442937395
Epoch #151: loss=0.011705436840348712
Epoch #152: loss=0.015116083331315885
Epoch #153: loss=0.026860761608096206
Epoch #154: loss=0.01907373659773894
Epoch #155: loss=0.01530050429456627
Epoch #156: loss=0.019959657900339576
Epoch #157: loss=0.01835322213995996
Epoch #158: loss=0.016240062479165863
Epoch #159: loss=0.017262825487520908
Epoch #160: loss=0.02825235459927106
Epoch #161: loss=0.02096796677193205
Epoch #162: loss=0.013334616041547363
Epoch #163: loss=0.014388431863353075
Epoch #164: loss=0.01567504909835487
Epoch #165: loss=0.01393664656995689
Epoch #166: loss=0.019770902052413632
Epoch #167: loss=0.015677301287910332
Epoch #168: loss=0.011587293069754997
Epoch #169: loss=0.015008430865259796
Epoch #170: loss=0.0235955768487906
Epoch #171: loss=0.01455166288914006
Epoch #172: loss=0.01955806849000189
Epoch #173: loss=0.01955001049938747
Epoch #174: loss=0.019179560472501946
Epoch #175: loss=0.016364895355241587
Epoch #176: loss=0.013547831956293822
Epoch #177: loss=0.01692820386027341
Epoch #178: loss=0.014272860217963467
Epoch #179: loss=0.015824973028066673
Epoch #180: loss=0.012764823689327505
Epoch #181: loss=0.013732862732569044
Epoch #182: loss=0.017214464280974964
Epoch #183: loss=0.0139346651123506
Epoch #184: loss=0.013075433282343087
Epoch #185: loss=0.01623701628957714
Epoch #186: loss=0.011760721850101635
Epoch #187: loss=0.01656733626212135
Epoch #188: loss=0.013151280583051159
Epoch #189: loss=0.020695103525425782
Epoch #190: loss=0.01711129080213301
Epoch #191: loss=0.015777628046787492
Epoch #192: loss=0.016690973926611147
Epoch #193: loss=0.010942490660259962
Epoch #194: loss=0.013020427148413609
Epoch #195: loss=0.012035751825974035
Epoch #196: loss=0.013536419101089471
Epoch #197: loss=0.016625605073904818
Epoch #198: loss=0.012935276545219426
Epoch #199: loss=0.013480230151728138
Epoch #200: loss=0.015128103367236773
Epoch #201: loss=0.014135673709254549
Epoch #202: loss=0.015267425220440575
Epoch #203: loss=0.01542891375784677
Epoch #204: loss=0.017976353792109795
Epoch #205: loss=0.01325707893915266
Epoch #206: loss=0.0123447347450986
Epoch #207: loss=0.015622678577421565
Epoch #208: loss=0.018641236328541443
Epoch #209: loss=0.011970443655700805
Epoch #210: loss=0.010491870996479736
Epoch #211: loss=0.018643611691251158
Epoch #212: loss=0.014346630537311025
Epoch #213: loss=0.016373145079725118
Epoch #214: loss=0.014024811632601495
Epoch #215: loss=0.01583246287428738
Epoch #216: loss=0.013928959119669394
Epoch #217: loss=0.014071368940801965
Epoch #218: loss=0.015995838205866458
Epoch #219: loss=0.01748356985724611
Epoch #220: loss=0.014054277472978646
Epoch #221: loss=0.011613825519802562
Epoch #222: loss=0.014272698058672054
Epoch #223: loss=0.016361406103008586
Epoch #224: loss=0.012989171473001994
Epoch #225: loss=0.01297970466326207
Epoch #226: loss=0.015180644453727486
Epoch #227: loss=0.019269921896319354
Epoch #228: loss=0.011142181037484487
Epoch #229: loss=0.016248889724089166
Epoch #230: loss=0.0192242082091001
Epoch #231: loss=0.016498533072267556
Epoch #232: loss=0.012878098067981032
Epoch #233: loss=0.014461865682808538
Epoch #234: loss=0.018105946361331005
Epoch #235: loss=0.029527823557595125
Epoch #236: loss=0.02290042530138612
Epoch #237: loss=0.011458735526377661
Epoch #238: loss=0.013723186169116415
Epoch #239: loss=0.017457881972522044
Epoch #240: loss=0.011644123503783011
Epoch #241: loss=0.02278913048867012
Epoch #242: loss=0.014164546658617154
Epoch #243: loss=0.011815597932233066
Epoch #244: loss=0.013161474302886752
Epoch #245: loss=0.009580808478214905
Epoch #246: loss=0.016985153016398632
Epoch #247: loss=0.011531157797716069
Epoch #248: loss=0.014056948187616998
Epoch #249: loss=0.012842927319930801

Training time: 3:31:56.577144

Finished.
n2one setting ettm1_traffic_weather_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm1_traffic_weather_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='ettm1_traffic_weather_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.04306e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.06557e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.92052e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.04306e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4151336603779474, 'MAE': 0.4585759340242468}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='ettm2_electricity_traffic_weather', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/ettm2_electricity_traffic_weather_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.9393995348058763
Epoch #1: loss=0.35627115854352226
Epoch #2: loss=0.2540376650200027
Epoch #3: loss=0.1855812229246634
Epoch #4: loss=0.14418184518294988
Epoch #5: loss=0.12720412368748765
Epoch #6: loss=0.09451655605884238
Epoch #7: loss=0.08161023152976862
Epoch #8: loss=0.08335138744308201
Epoch #9: loss=0.07547532700796107
Epoch #10: loss=0.06533783624028848
Epoch #11: loss=0.05592276259634613
Epoch #12: loss=0.057908774216155534
Epoch #13: loss=0.04624921140665585
Epoch #14: loss=0.04843242413919709
Epoch #15: loss=0.04448263816340811
Epoch #16: loss=0.04085137236741234
Epoch #17: loss=0.03658215729367049
Epoch #18: loss=0.03360293671578459
Epoch #19: loss=0.05131089267250318
Epoch #20: loss=0.03353453026158872
Epoch #21: loss=0.034687979919664165
Epoch #22: loss=0.029433761241074774
Epoch #23: loss=0.03380655036460547
Epoch #24: loss=0.029738343259144085
Epoch #25: loss=0.026535759644762263
Epoch #26: loss=0.02732367248381259
Epoch #27: loss=0.037883263227785555
Epoch #28: loss=0.02712173331098905
Epoch #29: loss=0.035483754444752866
Epoch #30: loss=0.033440988923692086
Epoch #31: loss=0.0223150765921703
Epoch #32: loss=0.021843470434551357
Epoch #33: loss=0.02733827439622503
Epoch #34: loss=0.02140529024450263
Epoch #35: loss=0.021375424104654917
Epoch #36: loss=0.028605632056419156
Epoch #37: loss=0.02458529976792023
Epoch #38: loss=0.028432193976926205
Epoch #39: loss=0.02076857613762707
Epoch #40: loss=0.020310669321353073
Epoch #41: loss=0.023000880639063057
Epoch #42: loss=0.028770184479405738
Epoch #43: loss=0.022531263735364803
Epoch #44: loss=0.021065965958357576
Epoch #45: loss=0.02071908744215225
Epoch #46: loss=0.02353127001330054
Epoch #47: loss=0.02155506570089215
Epoch #48: loss=0.0209076276846272
Epoch #49: loss=0.01762593588474508
Epoch #50: loss=0.018596156877687404
Epoch #51: loss=0.0211398089339157
Epoch #52: loss=0.016413684056205368
Epoch #53: loss=0.025327080183712092
Epoch #54: loss=0.01945679200642368
Epoch #55: loss=0.016735789603525085
Epoch #56: loss=0.01687822583557076
Epoch #57: loss=0.018049072689776593
Epoch #58: loss=0.01775020286302487
Epoch #59: loss=0.01630637368531306
Epoch #60: loss=0.024162327589904442
Epoch #61: loss=0.01423218925959444
Epoch #62: loss=0.014287939310368708
Epoch #63: loss=0.022855201795874698
Epoch #64: loss=0.018881590716964488
Epoch #65: loss=0.012195675917031561
Epoch #66: loss=0.01756476515724675
Epoch #67: loss=0.015529516478427915
Epoch #68: loss=0.02516402639326979
Epoch #69: loss=0.02130047446214613
Epoch #70: loss=0.015168882863926243
Epoch #71: loss=0.02268771004737126
Epoch #72: loss=0.019974058787252554
Epoch #73: loss=0.018633744640077356
Epoch #74: loss=0.014752674276714374
Epoch #75: loss=0.01274988984175744
Epoch #76: loss=0.022639195688477276
Epoch #77: loss=0.01336860330489113
Epoch #78: loss=0.018000156738505257
Epoch #79: loss=0.015145306378726077
Epoch #80: loss=0.018322165366801334
Epoch #81: loss=0.01709570899034648
Epoch #82: loss=0.019896014974587102
Epoch #83: loss=0.016365689554415856
Epoch #84: loss=0.017821526643331066
Epoch #85: loss=0.013690233452361412
Epoch #86: loss=0.013128539074685131
Epoch #87: loss=0.015279657725954703
Epoch #88: loss=0.02240071075416903
Epoch #89: loss=0.016897748005967664
Epoch #90: loss=0.013981689136383719
Epoch #91: loss=0.01600255106550023
Epoch #92: loss=0.010350323106748143
Epoch #93: loss=0.014331906387481273
Epoch #94: loss=0.014826734651122948
Epoch #95: loss=0.021079175408760687
Epoch #96: loss=0.023450779680570123
Epoch #97: loss=0.014063915593134402
Epoch #98: loss=0.018029248774038307
Epoch #99: loss=0.014138867386848643
Epoch #100: loss=0.015962699195346222
Epoch #101: loss=0.014159992246790293
Epoch #102: loss=0.012042467239538024
Epoch #103: loss=0.013681426042090666
Epoch #104: loss=0.011502227588920744
Epoch #105: loss=0.013982290336762014
Epoch #106: loss=0.02254500441106712
Epoch #107: loss=0.010885747404783435
Epoch #108: loss=0.013883339557353002
Epoch #109: loss=0.010668659795526048
Epoch #110: loss=0.01325602564010311
Epoch #111: loss=0.012000593460595796
Epoch #112: loss=0.019773257425824014
Epoch #113: loss=0.01112947113514729
Epoch #114: loss=0.018151199300611223
Epoch #115: loss=0.019629310568380475
Epoch #116: loss=0.01061915570989797
Epoch #117: loss=0.017500832305932953
Epoch #118: loss=0.014425347250200175
Epoch #119: loss=0.025101739837555214
Epoch #120: loss=0.011617458967700006
Epoch #121: loss=0.010741273771740542
Epoch #122: loss=0.014323196949539362
Epoch #123: loss=0.013810778611514252
Epoch #124: loss=0.012234801975760316
Epoch #125: loss=0.0133996335639271
Epoch #126: loss=0.013044203041976826
Epoch #127: loss=0.015575188394234187
Epoch #128: loss=0.011971812504300749
Epoch #129: loss=0.011184330098557602
Epoch #130: loss=0.011879156977362876
Epoch #131: loss=0.010583352109856456
Epoch #132: loss=0.017566532853105273
Epoch #133: loss=0.015702858774721926
Epoch #134: loss=0.010710547236844012
Epoch #135: loss=0.012016083845893994
Epoch #136: loss=0.012303749957388137
Epoch #137: loss=0.01018031830565439
Epoch #138: loss=0.011220299155338282
Epoch #139: loss=0.016936836308145086
Epoch #140: loss=0.015863298177044002
Epoch #141: loss=0.014283537916493455
Epoch #142: loss=0.010875846517807135
Epoch #143: loss=0.013019217807428861
Epoch #144: loss=0.011809974801573963
Epoch #145: loss=0.014473096953027932
Epoch #146: loss=0.014313678546070567
Epoch #147: loss=0.010542881143588662
Epoch #148: loss=0.020685757600084963
Epoch #149: loss=0.011614264941346816
Epoch #150: loss=0.017346731995897497
Epoch #151: loss=0.008513078047749853
Epoch #152: loss=0.01517007827012586
Epoch #153: loss=0.010993350769076343
Epoch #154: loss=0.011690452254971787
Epoch #155: loss=0.01877651731740086
Epoch #156: loss=0.013087579504978943
Epoch #157: loss=0.011727522018536845
Epoch #158: loss=0.01031878465699742
Epoch #159: loss=0.01692565608167063
Epoch #160: loss=0.01565358169409294
Epoch #161: loss=0.012222326199438702
Epoch #162: loss=0.011689172281402252
Epoch #163: loss=0.012417816884933063
Epoch #164: loss=0.011792512629591462
Epoch #165: loss=0.009942806860659612
Epoch #166: loss=0.012478522877021727
Epoch #167: loss=0.011411895386833643
Epoch #168: loss=0.009018706567785856
Epoch #169: loss=0.013938502182182845
Epoch #170: loss=0.012701459868832421
Epoch #171: loss=0.009339323016934404
Epoch #172: loss=0.013537825473690273
Epoch #173: loss=0.010779065050209298
Epoch #174: loss=0.012571015875997904
Epoch #175: loss=0.010869596771190714
Epoch #176: loss=0.014947987441641476
Epoch #177: loss=0.009693202525832915
Epoch #178: loss=0.012652814536108292
Epoch #179: loss=0.012189356635024554
Epoch #180: loss=0.013551784723736613
Epoch #181: loss=0.012288693682016035
Epoch #182: loss=0.009218047122964786
Epoch #183: loss=0.009353035495086424
Epoch #184: loss=0.01625969612702692
Epoch #185: loss=0.011977425432686702
Epoch #186: loss=0.011693502522480305
Epoch #187: loss=0.009119445508352489
Epoch #188: loss=0.012760277518529739
Epoch #189: loss=0.008130536342984863
Epoch #190: loss=0.0142593023167141
Epoch #191: loss=0.012206692649112378
Epoch #192: loss=0.016970002000982545
Epoch #193: loss=0.01386703715199742
Epoch #194: loss=0.012498390378656398
Epoch #195: loss=0.009679260428191677
Epoch #196: loss=0.013125766278697812
Epoch #197: loss=0.00710340445872194
Epoch #198: loss=0.014700237560512013
Epoch #199: loss=0.013936279644568443
Epoch #200: loss=0.009900182768281217
Epoch #201: loss=0.012435965604395948
Epoch #202: loss=0.01567623409764397
Epoch #203: loss=0.009935409138117511
Epoch #204: loss=0.011473447501410819
Epoch #205: loss=0.012354147837549298
Epoch #206: loss=0.014945918137769307
Epoch #207: loss=0.010496616868918177
Epoch #208: loss=0.010163292430124635
Epoch #209: loss=0.015590155273129626
Epoch #210: loss=0.01077712557895718
Epoch #211: loss=0.00959222647287505
Epoch #212: loss=0.011591722677353498
Epoch #213: loss=0.008838109126414476
Epoch #214: loss=0.011314703591635973
Epoch #215: loss=0.010218291202456056
Epoch #216: loss=0.013849584556606476
Epoch #217: loss=0.01093604660489917
Epoch #218: loss=0.012141054068110191
Epoch #219: loss=0.009173297642104682
Epoch #220: loss=0.010632059953894015
Epoch #221: loss=0.010431252622859152
Epoch #222: loss=0.011313025312608901
Epoch #223: loss=0.0066684294101788345
Epoch #224: loss=0.025410625351209776
Epoch #225: loss=0.008725622431248652
Epoch #226: loss=0.010819151704315312
Epoch #227: loss=0.009108270799441046
Epoch #228: loss=0.010057266329676209
Epoch #229: loss=0.011377549592761483
Epoch #230: loss=0.011810052553268119
Epoch #231: loss=0.010734821385385956
Epoch #232: loss=0.009560523615004595
Epoch #233: loss=0.009540424778886697
Epoch #234: loss=0.009089224204503584
Epoch #235: loss=0.01169714798222126
Epoch #236: loss=0.012879482025015081
Epoch #237: loss=0.0125742036567091
Epoch #238: loss=0.00984800155906147
Epoch #239: loss=0.009917227647395626
Epoch #240: loss=0.01131162941152875
Epoch #241: loss=0.007344127137160986
Epoch #242: loss=0.012567494724832807
Epoch #243: loss=0.012031613450213984
Epoch #244: loss=0.009666268151552491
Epoch #245: loss=0.009350835959000998
Epoch #246: loss=0.011639532098742479
Epoch #247: loss=0.010267666587063358
Epoch #248: loss=0.010245890582385023
Epoch #249: loss=0.014684229876401646

Training time: 4:58:03.019165

Finished.
n2one setting ettm2_electricity_traffic_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm2_electricity_traffic_weather_epochs_250_seed_2021/model.pkl', muti_dataset='ettm2_electricity_traffic_weather', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.30797e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.35806568286730633, 'MAE': 0.3926679087532747}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='ettm2_electricity_traffic_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/ettm2_electricity_traffic_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.9174168364279679
Epoch #1: loss=0.34176698584921544
Epoch #2: loss=0.23113558643471183
Epoch #3: loss=0.1699747349911938
Epoch #4: loss=0.13272831501274954
Epoch #5: loss=0.1041918087707284
Epoch #6: loss=0.09095235410752317
Epoch #7: loss=0.08270464592710906
Epoch #8: loss=0.07097878849781591
Epoch #9: loss=0.06104197745217621
Epoch #10: loss=0.06462934048545738
Epoch #11: loss=0.055578361702742
Epoch #12: loss=0.049910206044752915
Epoch #13: loss=0.04858974470100683
Epoch #14: loss=0.04445355040450873
Epoch #15: loss=0.04491567408500205
Epoch #16: loss=0.03941292771968848
Epoch #17: loss=0.04051755134377725
Epoch #18: loss=0.041665527340065
Epoch #19: loss=0.03619828488812945
Epoch #20: loss=0.032462597102315756
Epoch #21: loss=0.03564174247622031
Epoch #22: loss=0.029841956531560396
Epoch #23: loss=0.03771383558925297
Epoch #24: loss=0.033016109027080055
Epoch #25: loss=0.027513033500688535
Epoch #26: loss=0.0320388215814621
Epoch #27: loss=0.031442455059369115
Epoch #28: loss=0.026881866078121052
Epoch #29: loss=0.025125332112376036
Epoch #30: loss=0.039139985464363765
Epoch #31: loss=0.025238633460904505
Epoch #32: loss=0.029458472479449372
Epoch #33: loss=0.026401331987307125
Epoch #34: loss=0.02213696876521216
Epoch #35: loss=0.02919825796244593
Epoch #36: loss=0.036444148780809434
Epoch #37: loss=0.03247367320082518
Epoch #38: loss=0.022205100664806965
Epoch #39: loss=0.023652103083402293
Epoch #40: loss=0.027714438440364177
Epoch #41: loss=0.023056181774613372
Epoch #42: loss=0.02464092315060161
Epoch #43: loss=0.02066488089849599
Epoch #44: loss=0.030631095845253826
Epoch #45: loss=0.021951663202326048
Epoch #46: loss=0.025936250006853637
Epoch #47: loss=0.020020296207162128
Epoch #48: loss=0.023366748825203357
Epoch #49: loss=0.023826721191275307
Epoch #50: loss=0.022482691130326974
Epoch #51: loss=0.018212177923775143
Epoch #52: loss=0.021710346261900965
Epoch #53: loss=0.021764977957442026
Epoch #54: loss=0.023890802405655272
Epoch #55: loss=0.017614527527072828
Epoch #56: loss=0.018075662367541757
Epoch #57: loss=0.027592814001549164
Epoch #58: loss=0.020744095836725773
Epoch #59: loss=0.02296383419816387
Epoch #60: loss=0.022554787543973033
Epoch #61: loss=0.021330206070710112
Epoch #62: loss=0.01695173136594229
Epoch #63: loss=0.019699222475595187
Epoch #64: loss=0.01858309245935274
Epoch #65: loss=0.01844350143426122
Epoch #66: loss=0.024762940738340854
Epoch #67: loss=0.01807479963862777
Epoch #68: loss=0.022307708377656627
Epoch #69: loss=0.014863933615820186
Epoch #70: loss=0.014159167931616978
Epoch #71: loss=0.01833230579534767
Epoch #72: loss=0.018967121853276207
Epoch #73: loss=0.017611473342000868
Epoch #74: loss=0.01781743380917409
Epoch #75: loss=0.017361663441108656
Epoch #76: loss=0.015154495834166257
Epoch #77: loss=0.016086325351043856
Epoch #78: loss=0.01789696180982633
Epoch #79: loss=0.01664231434477917
Epoch #80: loss=0.018188448885459407
Epoch #81: loss=0.01683189736530239
Epoch #82: loss=0.01764004261758525
Epoch #83: loss=0.01478461367741073
Epoch #84: loss=0.014804350042290686
Epoch #85: loss=0.019444721314745
Epoch #86: loss=0.014721039667977958
Epoch #87: loss=0.01423735982685161
Epoch #88: loss=0.017310466353885928
Epoch #89: loss=0.017038470061452125
Epoch #90: loss=0.01832240245842236
Epoch #91: loss=0.015487718316761254
Epoch #92: loss=0.013375941993229673
Epoch #93: loss=0.014249272772327268
Epoch #94: loss=0.016926584851754883
Epoch #95: loss=0.01643157347829698
Epoch #96: loss=0.02320123168554803
Epoch #97: loss=0.011165630404204312
Epoch #98: loss=0.016026083898296004
Epoch #99: loss=0.014277720135888345
Epoch #100: loss=0.015965713573157354
Epoch #101: loss=0.014893533649849083
Epoch #102: loss=0.013322222753738427
Epoch #103: loss=0.015079895619608263
Epoch #104: loss=0.012833875613755851
Epoch #105: loss=0.015622054099167478
Epoch #106: loss=0.02044371332417412
Epoch #107: loss=0.014950319141899732
Epoch #108: loss=0.01210611437749739
Epoch #109: loss=0.01899407400136119
Epoch #110: loss=0.013975256195650421
Epoch #111: loss=0.013311290374350542
Epoch #112: loss=0.02260863046832429
Epoch #113: loss=0.01260717973412718
Epoch #114: loss=0.015190039080656859
Epoch #115: loss=0.016505332270850423
Epoch #116: loss=0.015042967042107423
Epoch #117: loss=0.012985492044512686
Epoch #118: loss=0.013100823981396097
Epoch #119: loss=0.014974287028620857
Epoch #120: loss=0.01277766648417553
Epoch #121: loss=0.016468670174026027
Epoch #122: loss=0.01278560869099852
Epoch #123: loss=0.02475727342858778
Epoch #124: loss=0.014195209104901322
Epoch #125: loss=0.011972712368731304
Epoch #126: loss=0.01879312065091974
Epoch #127: loss=0.014139643682910947
Epoch #128: loss=0.016103452133895566
Epoch #129: loss=0.010938016195541725
Epoch #130: loss=0.010660249413502337
Epoch #131: loss=0.013349820395013257
Epoch #132: loss=0.013082254905902166
Epoch #133: loss=0.01273334416612499
Epoch #134: loss=0.01495030362171314
Epoch #135: loss=0.012200431560394555
Epoch #136: loss=0.016182721929177513
Epoch #137: loss=0.01564566809766846
Epoch #138: loss=0.009701102716125162
Epoch #139: loss=0.014101465645523396
Epoch #140: loss=0.024701911961204977
Epoch #141: loss=0.0144399350899649
Epoch #142: loss=0.013789459470492522
Epoch #143: loss=0.016962339300227416
Epoch #144: loss=0.0223478348522566
Epoch #145: loss=0.015934979168069335
Epoch #146: loss=0.014533221372451631
Epoch #147: loss=0.009665250210455632
Epoch #148: loss=0.014311050746356293
Epoch #149: loss=0.015919862570722056
Epoch #150: loss=0.015214333480818487
Epoch #151: loss=0.010746234287916545
Epoch #152: loss=0.012883778575025444
Epoch #153: loss=0.018871111219646
Epoch #154: loss=0.013886694140699747
Epoch #155: loss=0.011215122190213351
Epoch #156: loss=0.010711980674265658
Epoch #157: loss=0.013927344216865575
Epoch #158: loss=0.013951623916517794
Epoch #159: loss=0.011478353775074506
Epoch #160: loss=0.01244442500514478
Epoch #161: loss=0.01138830564236068
Epoch #162: loss=0.014828619218305313
Epoch #163: loss=0.012121935026079398
Epoch #164: loss=0.012353412705741784
Epoch #165: loss=0.013434994534412577
Epoch #166: loss=0.013885986969326162
Epoch #167: loss=0.010983811688358625
Epoch #168: loss=0.012554814342786415
Epoch #169: loss=0.01471942415969995
Epoch #170: loss=0.020134998896991572
Epoch #171: loss=0.016304311458783236
Epoch #172: loss=0.009985635983103354
Epoch #173: loss=0.010721617430072864
Epoch #174: loss=0.01137586454349491
Epoch #175: loss=0.009783489055225135
Epoch #176: loss=0.011907655595261921
Epoch #177: loss=0.011880073172808606
Epoch #178: loss=0.012248363937005752
Epoch #179: loss=0.013940169011255665
Epoch #180: loss=0.010688093657361866
Epoch #181: loss=0.012484531078667826
Epoch #182: loss=0.012646221491363296
Epoch #183: loss=0.009950477355193233
Epoch #184: loss=0.0133467815375753
Epoch #185: loss=0.014859660761019241
Epoch #186: loss=0.012014840021519483
Epoch #187: loss=0.008907094961039292
Epoch #188: loss=0.015453076540571797
Epoch #189: loss=0.011476780288633437
Epoch #190: loss=0.00836323765868114
Epoch #191: loss=0.012367307171118043
Epoch #192: loss=0.012051936517112784
Epoch #193: loss=0.009628771887081031
Epoch #194: loss=0.010496658084919609
Epoch #195: loss=0.011438903880096437
Epoch #196: loss=0.013573219563292249
Epoch #197: loss=0.01580956030964674
Epoch #198: loss=0.011680269147111172
Epoch #199: loss=0.011056032369725197
Epoch #200: loss=0.011256547602265066
Epoch #201: loss=0.008874031109895174
Epoch #202: loss=0.01109611528526437
Epoch #203: loss=0.015116094310098997
Epoch #204: loss=0.009947024701055572
Epoch #205: loss=0.010494136512838342
Epoch #206: loss=0.00952995328015021
Epoch #207: loss=0.015376537517290376
Epoch #208: loss=0.012032518585558967
Epoch #209: loss=0.013884891235708487
Epoch #210: loss=0.01383024592508925
Epoch #211: loss=0.01221336658369022
Epoch #212: loss=0.012289122486840151
Epoch #213: loss=0.013652302510163522
Epoch #214: loss=0.0133762247879923
Epoch #215: loss=0.015320399066664601
Epoch #216: loss=0.01098144643965921
Epoch #217: loss=0.015429464083205802
Epoch #218: loss=0.011207290376110911
Epoch #219: loss=0.007790721788994283
Epoch #220: loss=0.01359547035018127
Epoch #221: loss=0.01031870810014919
Epoch #222: loss=0.012623024126664911
Epoch #223: loss=0.008015078457850384
Epoch #224: loss=0.012196427181483517
Epoch #225: loss=0.012382282492891226
Epoch #226: loss=0.012806521226854047
Epoch #227: loss=0.012728097078541218
Epoch #228: loss=0.011273210491699517
Epoch #229: loss=0.010784492584879235
Epoch #230: loss=0.012113577580415898
Epoch #231: loss=0.01093685515890605
Epoch #232: loss=0.012970430632228882
Epoch #233: loss=0.010066247607760783
Epoch #234: loss=0.012249807955623766
Epoch #235: loss=0.011505904388687605
Epoch #236: loss=0.011077181001561565
Epoch #237: loss=0.011993016949869198
Epoch #238: loss=0.010408392997803658
Epoch #239: loss=0.009759607553811979
Epoch #240: loss=0.013151915426177753
Epoch #241: loss=0.011162541079973746
Epoch #242: loss=0.012284975998183425
Epoch #243: loss=0.0171484486180303
Epoch #244: loss=0.010916820977298375
Epoch #245: loss=0.01129834966024325
Epoch #246: loss=0.009839591968299954
Epoch #247: loss=0.009039377612018942
Epoch #248: loss=0.009308619910705347
Epoch #249: loss=0.01087795863931752

Training time: 4:59:11.939295

Finished.
n2one setting ettm2_electricity_traffic_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm2_electricity_traffic_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='ettm2_electricity_traffic_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.75968e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.39052e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.75968e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.5057545965509114, 'MAE': 0.5198180208991322}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='ettm2_electricity_weather_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/ettm2_electricity_weather_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.955092050827266
Epoch #1: loss=0.907132469891199
Epoch #2: loss=0.6464211693226966
Epoch #3: loss=0.5359473311917378
Epoch #4: loss=0.4553357076938035
Epoch #5: loss=0.399302069769531
Epoch #6: loss=0.3704956905519376
Epoch #7: loss=0.32968428409327577
Epoch #8: loss=0.30383029708363973
Epoch #9: loss=0.2780189186008902
Epoch #10: loss=0.24352810710994272
Epoch #11: loss=0.25390208838253076
Epoch #12: loss=0.2124146327905642
Epoch #13: loss=0.2068480473581722
Epoch #14: loss=0.19583991980129253
Epoch #15: loss=0.17619474407265096
Epoch #16: loss=0.16897064065713374
Epoch #17: loss=0.15710811110345718
Epoch #18: loss=0.14331842886151674
Epoch #19: loss=0.1493112192097339
Epoch #20: loss=0.13673412652757486
Epoch #21: loss=0.15197202015179592
Epoch #22: loss=0.12365546226603248
Epoch #23: loss=0.1151123696307097
Epoch #24: loss=0.09871318455164631
Epoch #25: loss=0.09589105520061537
Epoch #26: loss=0.11260184132661975
Epoch #27: loss=0.0928342762896842
Epoch #28: loss=0.1008588273938277
Epoch #29: loss=0.0810853276920856
Epoch #30: loss=0.07775253378989715
Epoch #31: loss=0.0808987169490893
Epoch #32: loss=0.09353783205049775
Epoch #33: loss=0.08565193892690694
Epoch #34: loss=0.07974413444690122
Epoch #35: loss=0.07364586856574981
Epoch #36: loss=0.0538125974227944
Epoch #37: loss=0.06592837169567947
Epoch #38: loss=0.05996289719570469
Epoch #39: loss=0.063054448840987
Epoch #40: loss=0.06083274559026248
Epoch #41: loss=0.0507676157314086
Epoch #42: loss=0.07241230119844197
Epoch #43: loss=0.05433915968497075
Epoch #44: loss=0.059375410067436636
Epoch #45: loss=0.05401474831096543
Epoch #46: loss=0.03568806390270408
Epoch #47: loss=0.03886292784543494
Epoch #48: loss=0.049958095401703616
Epoch #49: loss=0.05166727232192058
Epoch #50: loss=0.04834143162699915
Epoch #51: loss=0.04537519548772809
Epoch #52: loss=0.06782861240080919
Epoch #53: loss=0.06277344197408892
Epoch #54: loss=0.08618423076667135
Epoch #55: loss=0.05571439858688846
Epoch #56: loss=0.042647478114711784
Epoch #57: loss=0.04743049009270518
Epoch #58: loss=0.04237733930451134
Epoch #59: loss=0.040101016586318185
Epoch #60: loss=0.047887554687709936
Epoch #61: loss=0.040269457341344836
Epoch #62: loss=0.03734953406004775
Epoch #63: loss=0.04001097294884922
Epoch #64: loss=0.042879516090892376
Epoch #65: loss=0.04331397324325924
Epoch #66: loss=0.051780140615523856
Epoch #67: loss=0.03974195656015492
Epoch #68: loss=0.0428196194255979
Epoch #69: loss=0.03606666053347595
Epoch #70: loss=0.06833306228636403
Epoch #71: loss=0.03452853063665982
Epoch #72: loss=0.025581041121946983
Epoch #73: loss=0.03687421390958527
Epoch #74: loss=0.04884584652656903
Epoch #75: loss=0.06205479594970458
Epoch #76: loss=0.036861893593058845
Epoch #77: loss=0.03474826436703567
Epoch #78: loss=0.05136294217107187
Epoch #79: loss=0.03535441783272096
Epoch #80: loss=0.02811864354899611
Epoch #81: loss=0.030185348301161527
Epoch #82: loss=0.03912865374869631
Epoch #83: loss=0.04348504474727549
Epoch #84: loss=0.024785381391303502
Epoch #85: loss=0.024577139989699393
Epoch #86: loss=0.03770478225416183
Epoch #87: loss=0.026762366890932733
Epoch #88: loss=0.029282617508662772
Epoch #89: loss=0.03572549841518112
Epoch #90: loss=0.034102969664553576
Epoch #91: loss=0.02734834530525663
Epoch #92: loss=0.030173690453339674
Epoch #93: loss=0.04952976983988434
Epoch #94: loss=0.03926676473611472
Epoch #95: loss=0.03221831974844433
Epoch #96: loss=0.04029775562548572
Epoch #97: loss=0.02788804468661903
Epoch #98: loss=0.024423625298567075
Epoch #99: loss=0.04403574772632701
Epoch #100: loss=0.037252792390063405
Epoch #101: loss=0.03358562120562165
Epoch #102: loss=0.02176228194094207
Epoch #103: loss=0.030107412866254395
Epoch #104: loss=0.025347198261383187
Epoch #105: loss=0.028720294229229504
Epoch #106: loss=0.034073003113862695
Epoch #107: loss=0.026190054544077197
Epoch #108: loss=0.02769121825644146
Epoch #109: loss=0.029672287636731694
Epoch #110: loss=0.029555133419223334
Epoch #111: loss=0.027377922309923898
Epoch #112: loss=0.02596381009105323
Epoch #113: loss=0.055252365517471994
Epoch #114: loss=0.03526482188563967
Epoch #115: loss=0.03223413928514321
Epoch #116: loss=0.03160980287392222
Epoch #117: loss=0.021470074762610588
Epoch #118: loss=0.025278296153050914
Epoch #119: loss=0.020877406350177933
Epoch #120: loss=0.023864938186187692
Epoch #121: loss=0.029966571541627757
Epoch #122: loss=0.019058202219843265
Epoch #123: loss=0.04481740410139408
Epoch #124: loss=0.03283813130587614
Epoch #125: loss=0.04439354510841092
Epoch #126: loss=0.04952506790105559
Epoch #127: loss=0.025522549236524097
Epoch #128: loss=0.024595273434867716
Epoch #129: loss=0.03703329616586953
Epoch #130: loss=0.03768503437769126
Epoch #131: loss=0.030088324966532548
Epoch #132: loss=0.02828598700771032
Epoch #133: loss=0.026337527723243725
Epoch #134: loss=0.04723617432990793
Epoch #135: loss=0.027748487043051974
Epoch #136: loss=0.020762226750432957
Epoch #137: loss=0.025464786470122125
Epoch #138: loss=0.019454002386891624
Epoch #139: loss=0.023413000241414354
Epoch #140: loss=0.03050274528258307
Epoch #141: loss=0.020220958680560803
Epoch #142: loss=0.02297735584456387
Epoch #143: loss=0.025404432302314147
Epoch #144: loss=0.02481216870364733
Epoch #145: loss=0.017397198762777746
Epoch #146: loss=0.022326129022349546
Epoch #147: loss=0.02514755364559601
Epoch #148: loss=0.02664974944674298
Epoch #149: loss=0.02412126870422568
Epoch #150: loss=0.027433673612317935
Epoch #151: loss=0.03154494104107913
Epoch #152: loss=0.015006217779369028
Epoch #153: loss=0.01898229355231065
Epoch #154: loss=0.021177675329305264
Epoch #155: loss=0.03426912034698889
Epoch #156: loss=0.03553283746676173
Epoch #157: loss=0.032386861493762666
Epoch #158: loss=0.023270037915981298
Epoch #159: loss=0.01998296137892799
Epoch #160: loss=0.020665505133305874
Epoch #161: loss=0.025029635624218952
Epoch #162: loss=0.032424519011239356
Epoch #163: loss=0.028269771336389533
Epoch #164: loss=0.023987409418106558
Epoch #165: loss=0.032017196184456795
Epoch #166: loss=0.027991918972922396
Epoch #167: loss=0.024015428307542545
Epoch #168: loss=0.022185496433973287
Epoch #169: loss=0.01915941230906301
Epoch #170: loss=0.020653676561937447
Epoch #171: loss=0.021903282190454218
Epoch #172: loss=0.020424594282353287
Epoch #173: loss=0.023868082378910794
Epoch #174: loss=0.023831750433561213
Epoch #175: loss=0.01947980058472349
Epoch #176: loss=0.01791753998927039
Epoch #177: loss=0.01858165571674427
Epoch #178: loss=0.01929186649437322
Epoch #179: loss=0.020360769147194587
Epoch #180: loss=0.03688694151036334
Epoch #181: loss=0.019610078464951775
Epoch #182: loss=0.01703884843463343
Epoch #183: loss=0.0214310775170945
Epoch #184: loss=0.02397477538566629
Epoch #185: loss=0.02020647152215039
Epoch #186: loss=0.0184239612819431
Epoch #187: loss=0.01557039231759473
Epoch #188: loss=0.01917465252431537
Epoch #189: loss=0.020186918127017166
Epoch #190: loss=0.019276641863347363
Epoch #191: loss=0.02559535240097979
Epoch #192: loss=0.0189393178015614
Epoch #193: loss=0.026279375289472665
Epoch #194: loss=0.024193748571881973
Epoch #195: loss=0.03348596257608018
Epoch #196: loss=0.022339281977279635
Epoch #197: loss=0.030109493434206516
Epoch #198: loss=0.01986452291776551
Epoch #199: loss=0.020822698397840542
Epoch #200: loss=0.014389517719767061
Epoch #201: loss=0.01928167083730687
Epoch #202: loss=0.018939304401871592
Epoch #203: loss=0.02197181216719092
Epoch #204: loss=0.01763225164006164
Epoch #205: loss=0.014988209284022018
Epoch #206: loss=0.019168199178676217
Epoch #207: loss=0.016617435228958716
Epoch #208: loss=0.03304158083383946
Epoch #209: loss=0.027385976750472347
Epoch #210: loss=0.025946333186632236
Epoch #211: loss=0.030030631505256988
Epoch #212: loss=0.018894159719169832
Epoch #213: loss=0.01739955301329117
Epoch #214: loss=0.017385855936725203
Epoch #215: loss=0.013603836660514474
Epoch #216: loss=0.02021968487484439
Epoch #217: loss=0.017180331411410142
Epoch #218: loss=0.022203138473289738
Epoch #219: loss=0.03540059140819135
Epoch #220: loss=0.022282167167028747
Epoch #221: loss=0.016268311302518584
Epoch #222: loss=0.014227466900210161
Epoch #223: loss=0.01459528178137554
Epoch #224: loss=0.018953209659727188
Epoch #225: loss=0.016018127385448014
Epoch #226: loss=0.02252251784924082
Epoch #227: loss=0.02131327540005234
Epoch #228: loss=0.04512315081932475
Epoch #229: loss=0.028809930664589603
Epoch #230: loss=0.021747553987616845
Epoch #231: loss=0.020091185413279998
Epoch #232: loss=0.014486405650812807
Epoch #233: loss=0.03271513958224617
Epoch #234: loss=0.01905461554266029
Epoch #235: loss=0.015743543701488116
Epoch #236: loss=0.03268117542999486
Epoch #237: loss=0.0210101945098945
Epoch #238: loss=0.015551255947749304
Epoch #239: loss=0.01845922139500296
Epoch #240: loss=0.025839025644862852
Epoch #241: loss=0.0199190347208616
Epoch #242: loss=0.02331771700174797
Epoch #243: loss=0.022741610007462363
Epoch #244: loss=0.014375304901696324
Epoch #245: loss=0.020022842442251672
Epoch #246: loss=0.02050572698328344
Epoch #247: loss=0.023246484904364262
Epoch #248: loss=0.01455708874260391
Epoch #249: loss=0.014482663682906231

Training time: 1:47:23.977581

Finished.
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='ettm2_traffic_weather_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/ettm2_traffic_weather_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.1801016644185538
Epoch #1: loss=0.45696879522474493
Epoch #2: loss=0.3362486756261943
Epoch #3: loss=0.27508476085739075
Epoch #4: loss=0.22289967599356714
Epoch #5: loss=0.18425816169795153
Epoch #6: loss=0.17122061197803065
Epoch #7: loss=0.13853786489592562
Epoch #8: loss=0.12685854227180451
Epoch #9: loss=0.10619230778906351
Epoch #10: loss=0.10349093401617686
Epoch #11: loss=0.11165019357012217
Epoch #12: loss=0.08750123888523191
Epoch #13: loss=0.07490777758965649
Epoch #14: loss=0.08339471004640452
Epoch #15: loss=0.07708846299437747
Epoch #16: loss=0.06136433608355586
Epoch #17: loss=0.06621432474782524
Epoch #18: loss=0.05934356843032017
Epoch #19: loss=0.058966636707515445
Epoch #20: loss=0.05293337833942371
Epoch #21: loss=0.05730232121725798
Epoch #22: loss=0.04145296360237694
Epoch #23: loss=0.04785026753215528
Epoch #24: loss=0.05949578131472049
Epoch #25: loss=0.05049847574766454
Epoch #26: loss=0.043330713290112274
Epoch #27: loss=0.04955007093807101
Epoch #28: loss=0.03433454260956537
Epoch #29: loss=0.03989982382315309
Epoch #30: loss=0.03914001878081947
Epoch #31: loss=0.042069723912670824
Epoch #32: loss=0.0388042713614805
Epoch #33: loss=0.02870988233650027
Epoch #34: loss=0.03886008833313223
Epoch #35: loss=0.045552977715165054
Epoch #36: loss=0.037236867784553276
Epoch #37: loss=0.036553888229366754
Epoch #38: loss=0.0391195782270568
Epoch #39: loss=0.029269232548148984
Epoch #40: loss=0.03612069351379908
Epoch #41: loss=0.03286947179841116
Epoch #42: loss=0.028617994058769414
Epoch #43: loss=0.028638565556633685
Epoch #44: loss=0.027155032754534816
Epoch #45: loss=0.03796916343107442
Epoch #46: loss=0.03473696884875778
Epoch #47: loss=0.03529581779688792
Epoch #48: loss=0.03180454349745467
Epoch #49: loss=0.032903255105928376
Epoch #50: loss=0.034790718690014745
Epoch #51: loss=0.025424286863810763
Epoch #52: loss=0.040737601085781616
Epoch #53: loss=0.026982947554253966
Epoch #54: loss=0.025380891164733445
Epoch #55: loss=0.02317307373665914
Epoch #56: loss=0.02765067776272591
Epoch #57: loss=0.023850199869267084
Epoch #58: loss=0.03299669212150329
Epoch #59: loss=0.0325469188109146
Epoch #60: loss=0.023468828618771868
Epoch #61: loss=0.03180236323010649
Epoch #62: loss=0.03375122956869982
Epoch #63: loss=0.027906458811909413
Epoch #64: loss=0.02767553518349387
Epoch #65: loss=0.018313386257598742
Epoch #66: loss=0.02233808101692659
Epoch #67: loss=0.02921789558777635
Epoch #68: loss=0.030862764855002205
Epoch #69: loss=0.024543673016529842
Epoch #70: loss=0.02329066480497615
Epoch #71: loss=0.021149871259534478
Epoch #72: loss=0.025416362587857455
Epoch #73: loss=0.02100669114911814
Epoch #74: loss=0.023723218660550594
Epoch #75: loss=0.023249100269944856
Epoch #76: loss=0.03188239812499011
Epoch #77: loss=0.025725468965334553
Epoch #78: loss=0.022529992243237054
Epoch #79: loss=0.026383755500424527
Epoch #80: loss=0.02454788836225962
Epoch #81: loss=0.024461467042316342
Epoch #82: loss=0.022307766990863453
Epoch #83: loss=0.018361040999994294
Epoch #84: loss=0.02214938230036533
Epoch #85: loss=0.020792004688901678
Epoch #86: loss=0.02361147944615741
Epoch #87: loss=0.02864740577929031
Epoch #88: loss=0.022997439087669148
Epoch #89: loss=0.021656773980645836
Epoch #90: loss=0.02406798248362672
Epoch #91: loss=0.019877643640373362
Epoch #92: loss=0.02646880584012059
Epoch #93: loss=0.03460318230728125
Epoch #94: loss=0.02432925572881707
Epoch #95: loss=0.02288371618555257
Epoch #96: loss=0.020663682066220913
Epoch #97: loss=0.018442195648742818
Epoch #98: loss=0.022588604500082394
Epoch #99: loss=0.03145354272283782
Epoch #100: loss=0.02117970277001576
Epoch #101: loss=0.02005713325955976
Epoch #102: loss=0.02026770028073003
Epoch #103: loss=0.020553741408802072
Epoch #104: loss=0.03438568830116864
Epoch #105: loss=0.01880284930819896
Epoch #106: loss=0.0247550894543947
Epoch #107: loss=0.02039333572868719
Epoch #108: loss=0.020609340783659894
Epoch #109: loss=0.017799021693638627
Epoch #110: loss=0.021845461555028617
Epoch #111: loss=0.015199432047641985
Epoch #112: loss=0.020992965166777365
Epoch #113: loss=0.028458834120009276
Epoch #114: loss=0.017162703027810887
Epoch #115: loss=0.019601532313509362
Epoch #116: loss=0.022641140074886806
Epoch #117: loss=0.02408664473010301
Epoch #118: loss=0.014871744024075718
Epoch #119: loss=0.016906496660447346
Epoch #120: loss=0.01687453853538493
Epoch #121: loss=0.018792296627260716
Epoch #122: loss=0.01839232667534234
Epoch #123: loss=0.016486202640665717
Epoch #124: loss=0.019057141004187747
Epoch #125: loss=0.018073392948333395
Epoch #126: loss=0.015491893571497802
Epoch #127: loss=0.0179095246670321
Epoch #128: loss=0.018501445159337625
Epoch #129: loss=0.018705174403587026
Epoch #130: loss=0.01825315992760163
Epoch #131: loss=0.01813874766718321
Epoch #132: loss=0.018741461390998037
Epoch #133: loss=0.01962409834102794
Epoch #134: loss=0.023483051840376874
Epoch #135: loss=0.019267853231652143
Epoch #136: loss=0.025231238380980427
Epoch #137: loss=0.016444292213107267
Epoch #138: loss=0.02030485683248369
Epoch #139: loss=0.015973758743280914
Epoch #140: loss=0.016971286714832733
Epoch #141: loss=0.018245172824083222
Epoch #142: loss=0.01597460292625565
Epoch #143: loss=0.017799978586736
Epoch #144: loss=0.02432683879069192
Epoch #145: loss=0.017977639786653166
Epoch #146: loss=0.02130745008505435
Epoch #147: loss=0.01571526388051666
Epoch #148: loss=0.019333552340780515
Epoch #149: loss=0.01749332303187965
Epoch #150: loss=0.01637978278728902
Epoch #151: loss=0.017098678528507577
Epoch #152: loss=0.016653674504939927
Epoch #153: loss=0.0232799925818031
Epoch #154: loss=0.013887470909609956
Epoch #155: loss=0.017182756573750558
Epoch #156: loss=0.01685829880065798
Epoch #157: loss=0.017105476011127045
Epoch #158: loss=0.016426090523212315
Epoch #159: loss=0.02105963784585093
Epoch #160: loss=0.03266385424671805
Epoch #161: loss=0.02335777812589385
Epoch #162: loss=0.01588016702134964
Epoch #163: loss=0.011710492530688767
Epoch #164: loss=0.014357427043418396
Epoch #165: loss=0.016536163456882778
Epoch #166: loss=0.019938559798858013
Epoch #167: loss=0.013680492961324101
Epoch #168: loss=0.01547474771785671
Epoch #169: loss=0.021625113262460683
Epoch #170: loss=0.015023465150101634
Epoch #171: loss=0.014777172666461214
Epoch #172: loss=0.020789922867361775
Epoch #173: loss=0.017682763881100363
Epoch #174: loss=0.021062323200774904
Epoch #175: loss=0.017633229458477152
Epoch #176: loss=0.016836755677125576
Epoch #177: loss=0.01731966934977392
Epoch #178: loss=0.014894560685094363
Epoch #179: loss=0.017262482870201493
Epoch #180: loss=0.012832462328111742
Epoch #181: loss=0.013787839188533239
Epoch #182: loss=0.015850766481833724
Epoch #183: loss=0.016163519043440735
Epoch #184: loss=0.013356264428829347
Epoch #185: loss=0.014707865928061118
Epoch #186: loss=0.016605405647655724
Epoch #187: loss=0.018325464204831672
Epoch #188: loss=0.01516435450652605
Epoch #189: loss=0.024750970772240626
Epoch #190: loss=0.018832574930152925
Epoch #191: loss=0.01976317195850065
Epoch #192: loss=0.015058381262417861
Epoch #193: loss=0.010822726728310814
Epoch #194: loss=0.012405776695839574
Epoch #195: loss=0.015219484415725352
Epoch #196: loss=0.016309087375550382
Epoch #197: loss=0.013553191931513185
Epoch #198: loss=0.013742866908439334
Epoch #199: loss=0.015080534985083358
Epoch #200: loss=0.01387480687141621
Epoch #201: loss=0.01599408587017094
Epoch #202: loss=0.016040481286228772
Epoch #203: loss=0.014206176726399745
Epoch #204: loss=0.017082632643822298
Epoch #205: loss=0.01405659932951541
Epoch #206: loss=0.012662340349095741
Epoch #207: loss=0.017196430679771495
Epoch #208: loss=0.013193030360707379
Epoch #209: loss=0.014175125591649676
Epoch #210: loss=0.013543485566091137
Epoch #211: loss=0.027808562774500473
Epoch #212: loss=0.01570895213829256
Epoch #213: loss=0.017107152479217243
Epoch #214: loss=0.01366300305914182
Epoch #215: loss=0.014264757299217263
Epoch #216: loss=0.012235751291982755
Epoch #217: loss=0.01819879074446262
Epoch #218: loss=0.012929357758502048
Epoch #219: loss=0.018737528699423498
Epoch #220: loss=0.014612785237096866
Epoch #221: loss=0.01172591882312525
Epoch #222: loss=0.014076278663912681
Epoch #223: loss=0.015137507050864701
Epoch #224: loss=0.013789600893592487
Epoch #225: loss=0.014022067321322976
Epoch #226: loss=0.01632371076973822
Epoch #227: loss=0.02114939050702866
Epoch #228: loss=0.016359483288978908
Epoch #229: loss=0.013374195381641042
Epoch #230: loss=0.016549564768915958
Epoch #231: loss=0.01782291192782667
Epoch #232: loss=0.0126106138550824
Epoch #233: loss=0.015562466801313094
Epoch #234: loss=0.015416399508978697
Epoch #235: loss=0.01969196148318251
Epoch #236: loss=0.015493712240438334
Epoch #237: loss=0.012013615194161956
Epoch #238: loss=0.013036809503060381
Epoch #239: loss=0.015597190914504629
Epoch #240: loss=0.01197264517978724
Epoch #241: loss=0.020782421484296036
Epoch #242: loss=0.012666308935207331
Epoch #243: loss=0.013102587004671696
Epoch #244: loss=0.013552656934794004
Epoch #245: loss=0.012902057921980988
Epoch #246: loss=0.015183893293472183
Epoch #247: loss=0.013732296070994634
Epoch #248: loss=0.010439529533952292
Epoch #249: loss=0.0125381222090765

Training time: 3:41:26.043773

Finished.
n2one setting ettm2_traffic_weather_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm2_traffic_weather_exchange_epochs_250_seed_2021/model.pkl', muti_dataset='ettm2_traffic_weather_exchange', random_seed=2021, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.97562e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.08336e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.26103e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.97562e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4284405931320972, 'MAE': 0.4658429232490283}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='electricity_traffic_weather_exchange', random_seed=2021, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/electricity_traffic_weather_exchange_epochs_250_seed_2021
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.8620018130359633
Epoch #1: loss=0.34849202719837696
Epoch #2: loss=0.23084653629297688
Epoch #3: loss=0.18213420704729555
Epoch #4: loss=0.14772415480705783
Epoch #5: loss=0.12315949405204496
Epoch #6: loss=0.11110336892230278
Epoch #7: loss=0.09177743532100269
Epoch #8: loss=0.07975450919706897
Epoch #9: loss=0.06796258387072418
Epoch #10: loss=0.06810133310758808
Epoch #11: loss=0.07062438716166848
Epoch #12: loss=0.06280232556742037
Epoch #13: loss=0.05171917662125512
Epoch #14: loss=0.06609951897701072
Epoch #15: loss=0.04818014170595306
Epoch #16: loss=0.04630832623016172
Epoch #17: loss=0.04344018854544442
Epoch #18: loss=0.04382136191762586
Epoch #19: loss=0.04059170659288271
Epoch #20: loss=0.03930992273556033
Epoch #21: loss=0.03202325344734635
Epoch #22: loss=0.038762153535092214
Epoch #23: loss=0.03459744106678961
Epoch #24: loss=0.042345075300150845
Epoch #25: loss=0.036097984389656806
Epoch #26: loss=0.030011909813451792
Epoch #27: loss=0.03097309032732494
Epoch #28: loss=0.031206278114150308
Epoch #29: loss=0.0295077409712336
Epoch #30: loss=0.02696089370841208
Epoch #31: loss=0.027886090196566557
Epoch #32: loss=0.030263187744963307
Epoch #33: loss=0.024223106250361268
Epoch #34: loss=0.02601925451219527
Epoch #35: loss=0.02950353992838636
Epoch #36: loss=0.029880580899771303
Epoch #37: loss=0.03360031178827002
Epoch #38: loss=0.026893722861437028
Epoch #39: loss=0.025162962239963404
Epoch #40: loss=0.02439554836403964
Epoch #41: loss=0.0250081520043765
Epoch #42: loss=0.03323099179024638
Epoch #43: loss=0.020501460094692073
Epoch #44: loss=0.02347818221115364
Epoch #45: loss=0.027113016494716254
Epoch #46: loss=0.023319144792462207
Epoch #47: loss=0.02601605417502848
Epoch #48: loss=0.02143000165969952
Epoch #49: loss=0.021996837429541196
Epoch #50: loss=0.028757116647374847
Epoch #51: loss=0.018753285253228773
Epoch #52: loss=0.033200880748008574
Epoch #53: loss=0.022238226561024043
Epoch #54: loss=0.02602692923337166
Epoch #55: loss=0.0198522530678683
Epoch #56: loss=0.023420291659072112
Epoch #57: loss=0.022877065424486726
Epoch #58: loss=0.01885047154350898
Epoch #59: loss=0.02376044464013059
Epoch #60: loss=0.02013638237162762
Epoch #61: loss=0.022734261474248035
Epoch #62: loss=0.018744912389558707
Epoch #63: loss=0.02548041206811522
Epoch #64: loss=0.01885085163353223
Epoch #65: loss=0.021285858811128957
Epoch #66: loss=0.01965233322433173
Epoch #67: loss=0.017492050370630015
Epoch #68: loss=0.024271831444960895
Epoch #69: loss=0.018646442316618505
Epoch #70: loss=0.02049758779917631
Epoch #71: loss=0.017326804113697917
Epoch #72: loss=0.021398307587232077
Epoch #73: loss=0.017231909510168827
Epoch #74: loss=0.022351347789858624
Epoch #75: loss=0.02185971601164537
Epoch #76: loss=0.021478723534644983
Epoch #77: loss=0.01857412719038057
Epoch #78: loss=0.01712114572339544
Epoch #79: loss=0.017001113075217355
Epoch #80: loss=0.01636329168295882
Epoch #81: loss=0.018685048274174443
Epoch #82: loss=0.018655109890434743
Epoch #83: loss=0.01844236648344701
Epoch #84: loss=0.0143781775465555
Epoch #85: loss=0.02614222578171544
Epoch #86: loss=0.01893436260243383
Epoch #87: loss=0.018975086053129326
Epoch #88: loss=0.015014350026049677
Epoch #89: loss=0.01787630491335199
Epoch #90: loss=0.018004215621843248
Epoch #91: loss=0.015484568291837725
Epoch #92: loss=0.019003508912065373
Epoch #93: loss=0.01602464256271618
Epoch #94: loss=0.020031232020171815
Epoch #95: loss=0.016306408391969857
Epoch #96: loss=0.017245515509906103
Epoch #97: loss=0.01744991544732727
Epoch #98: loss=0.01684495728513059
Epoch #99: loss=0.017601531865184757
Epoch #100: loss=0.022499029819154154
Epoch #101: loss=0.018028781504424607
Epoch #102: loss=0.01618913154193763
Epoch #103: loss=0.016989689366217593
Epoch #104: loss=0.016754579128741134
Epoch #105: loss=0.016322135758203023
Epoch #106: loss=0.014688917398207876
Epoch #107: loss=0.018268454308890767
Epoch #108: loss=0.01781355940904518
Epoch #109: loss=0.01788667675460503
Epoch #110: loss=0.014323050866995715
Epoch #111: loss=0.01212778532373066
Epoch #112: loss=0.015304869900091384
Epoch #113: loss=0.02713468828002129
Epoch #114: loss=0.02035142416157913
Epoch #115: loss=0.012581262820304258
Epoch #116: loss=0.018191051618505046
Epoch #117: loss=0.01350516392960827
Epoch #118: loss=0.021182205837497168
Epoch #119: loss=0.013666653163596604
Epoch #120: loss=0.01414136118234511
Epoch #121: loss=0.014749021738372415
Epoch #122: loss=0.01586766455232777
Epoch #123: loss=0.013799939622843121
Epoch #124: loss=0.01588862386320055
Epoch #125: loss=0.015945474012100943
Epoch #126: loss=0.01711082774443642
Epoch #127: loss=0.017093477238949363
Epoch #128: loss=0.016721626208661217
Epoch #129: loss=0.010402853347501267
Epoch #130: loss=0.01600828070334911
Epoch #131: loss=0.013987333511691862
Epoch #132: loss=0.015600124925904736
Epoch #133: loss=0.016666025382983358
Epoch #134: loss=0.01282308960849348
Epoch #135: loss=0.013359950007465204
Epoch #136: loss=0.03212600509968479
Epoch #137: loss=0.014830160028311319
Epoch #138: loss=0.013403907798047655
Epoch #139: loss=0.017272437828553353
Epoch #140: loss=0.014302120397624333
Epoch #141: loss=0.014657865755347804
Epoch #142: loss=0.015579702270366657
Epoch #143: loss=0.015547159717859426
Epoch #144: loss=0.015746033938967792
Epoch #145: loss=0.012205502122874301
Epoch #146: loss=0.01763124503657312
Epoch #147: loss=0.012623580472281543
Epoch #148: loss=0.017262706969727492
Epoch #149: loss=0.014409332589633554
Epoch #150: loss=0.01232599000403309
Epoch #151: loss=0.013212814371952146
Epoch #152: loss=0.012163041002034258
Epoch #153: loss=0.012988084958792199
Epoch #154: loss=0.013520078982034087
Epoch #155: loss=0.016465662360306516
Epoch #156: loss=0.015177206950272807
Epoch #157: loss=0.013875015467173254
Epoch #158: loss=0.012537368591232018
Epoch #159: loss=0.01399118344429781
Epoch #160: loss=0.015092277847573941
Epoch #161: loss=0.015982435670268153
Epoch #162: loss=0.013149449220286864
Epoch #163: loss=0.01269701223654195
Epoch #164: loss=0.020613026875195582
Epoch #165: loss=0.008896378990535945
Epoch #166: loss=0.01695418291099235
Epoch #167: loss=0.011612638573951147
Epoch #168: loss=0.015990379748650925
Epoch #169: loss=0.015894624567370643
Epoch #170: loss=0.013130432112406842
Epoch #171: loss=0.01841613918725281
Epoch #172: loss=0.01860201750902919
Epoch #173: loss=0.014844308787511164
Epoch #174: loss=0.010787890071735006
Epoch #175: loss=0.011764146075254932
Epoch #176: loss=0.011150935810662814
Epoch #177: loss=0.012711037211279877
Epoch #178: loss=0.009355972996341725
Epoch #179: loss=0.014838721038583871
Epoch #180: loss=0.012341843818410223
Epoch #181: loss=0.011099591806459197
Epoch #182: loss=0.014052036052522683
Epoch #183: loss=0.010791947863061072
Epoch #184: loss=0.009739751565873152
Epoch #185: loss=0.011736037902418358
Epoch #186: loss=0.016621731238128983
Epoch #187: loss=0.015245932865009838
Epoch #188: loss=0.010635967581053077
Epoch #189: loss=0.014316096132961805
Epoch #190: loss=0.01427133913368967
Epoch #191: loss=0.013803151639852972
Epoch #192: loss=0.013408570385707547
Epoch #193: loss=0.012949202683227497
Epoch #194: loss=0.010654651117580445
Epoch #195: loss=0.013927699799830497
Epoch #196: loss=0.01519752958798651
Epoch #197: loss=0.022690849316527574
Epoch #198: loss=0.010991128351507663
Epoch #199: loss=0.010500709422631668
Epoch #200: loss=0.011824517775073571
Epoch #201: loss=0.014564408759187429
Epoch #202: loss=0.014007429004590973
Epoch #203: loss=0.014520743692994647
Epoch #204: loss=0.015327112368549448
Epoch #205: loss=0.015727642983068644
Epoch #206: loss=0.01522585338968003
Epoch #207: loss=0.010629217188456478
Epoch #208: loss=0.015752678146095482
Epoch #209: loss=0.009948323416419273
Epoch #210: loss=0.010890918591655405
Epoch #211: loss=0.010388921537996525
Epoch #212: loss=0.014680585236770818
Epoch #213: loss=0.01211777738411023
Epoch #214: loss=0.015760979604498015
Epoch #215: loss=0.012632667419165656
Epoch #216: loss=0.012069694307812963
Epoch #217: loss=0.0153104627292274
Epoch #218: loss=0.011554249683820227
Epoch #219: loss=0.011981362493571414
Epoch #220: loss=0.018774808035291912
Epoch #221: loss=0.009501589928097368
Epoch #222: loss=0.012988556487478688
Epoch #223: loss=0.012218084410835925
Epoch #224: loss=0.012768531162677744
Epoch #225: loss=0.011687143002199576
Epoch #226: loss=0.0162715366245896
Epoch #227: loss=0.013011328614155793
Epoch #228: loss=0.013067171783723134
Epoch #229: loss=0.00853833109308873
Epoch #230: loss=0.013273673173945049
Epoch #231: loss=0.013264381419283766
Epoch #232: loss=0.014012950952755874
Epoch #233: loss=0.01090238573873194
Epoch #234: loss=0.011597590454005683
Epoch #235: loss=0.011018139689212498
Epoch #236: loss=0.015842472533238155
Epoch #237: loss=0.00939096806750437
Epoch #238: loss=0.013115569859829784
Epoch #239: loss=0.010036897455307104
Epoch #240: loss=0.01311755221439051
Epoch #241: loss=0.009835125243926377
Epoch #242: loss=0.019594028368438255
Epoch #243: loss=0.011104964912245432
Epoch #244: loss=0.015357302213246469
Epoch #245: loss=0.011956085751108935
Epoch #246: loss=0.012546216306590759
Epoch #247: loss=0.016885813887859237
Epoch #248: loss=0.014022766531415265
Epoch #249: loss=0.014495078887882847

Training time: 5:04:01.797769

Finished.
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_ettm1_ettm2', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_ettm1_ettm2_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=3.8830887609057956
Epoch #1: loss=2.259984638955858
Epoch #2: loss=1.955963436100218
Epoch #3: loss=1.7290679944886103
Epoch #4: loss=1.5268038743072085
Epoch #5: loss=1.3838418391015794
Epoch #6: loss=1.262644648551941
Epoch #7: loss=1.2071974111927881
Epoch #8: loss=1.0875997874471877
Epoch #9: loss=1.0290860997305975
Epoch #10: loss=0.9861493971612718
Epoch #11: loss=0.8999026682641771
Epoch #12: loss=0.8843293935060501
Epoch #13: loss=0.815842393371794
Epoch #14: loss=0.7973187665144602
Epoch #15: loss=0.7828379306528304
Epoch #16: loss=0.7218535467982292
Epoch #17: loss=0.6634560972452164
Epoch #18: loss=0.6644441874490844
Epoch #19: loss=0.6655731110109223
Epoch #20: loss=0.672732831703292
Epoch #21: loss=0.5545545261767175
Epoch #22: loss=0.5364308431744576
Epoch #23: loss=0.619141419728597
Epoch #24: loss=0.5337230430708991
Epoch #25: loss=0.548041556444433
Epoch #26: loss=0.5733720825778114
Epoch #27: loss=0.5094761633210712
Epoch #28: loss=0.6555767920282152
Epoch #29: loss=0.5615900216831101
Epoch #30: loss=0.5884074974391196
Epoch #31: loss=0.5014026032553779
Epoch #32: loss=0.49137350420157117
Epoch #33: loss=0.5205686315894127
Epoch #34: loss=0.42789828694529003
Epoch #35: loss=0.4343275585108333
Epoch #36: loss=0.40034425755341846
Epoch #37: loss=0.40249523727430236
Epoch #38: loss=0.450709988673528
Epoch #39: loss=0.40345852159791523
Epoch #40: loss=0.3988248300221231
Epoch #41: loss=0.33420737087726593
Epoch #42: loss=0.4167197806139787
Epoch #43: loss=0.39794380714495975
Epoch #44: loss=0.3365197769469685
Epoch #45: loss=0.3962131225400501
Epoch #46: loss=0.35798098519444466
Epoch #47: loss=0.3119034411178695
Epoch #48: loss=0.3601694078081184
Epoch #49: loss=0.35339923327167827
Epoch #50: loss=0.33228876234756577
Epoch #51: loss=0.30186207633879447
Epoch #52: loss=0.35035425424575806
Epoch #53: loss=0.3679128897686799
Epoch #54: loss=0.2957923420601421
Epoch #55: loss=0.2745313843091329
Epoch #56: loss=0.32339635408586925
Epoch #57: loss=0.2743472100959884
Epoch #58: loss=0.2528352952665753
Epoch #59: loss=0.2512127574947145
Epoch #60: loss=0.279770154092047
Epoch #61: loss=0.23767399560246202
Epoch #62: loss=0.3245712353123559
Epoch #63: loss=0.3096504132780764
Epoch #64: loss=0.23819523346092966
Epoch #65: loss=0.2890247710876995
Epoch #66: loss=0.3032924164500501
Epoch #67: loss=0.24507123687201077
Epoch #68: loss=0.21610009297728539
Epoch #69: loss=0.22455715553628075
Epoch #70: loss=0.26210596391724217
Epoch #71: loss=0.2640876592033439
Epoch #72: loss=0.2734127009494437
Epoch #73: loss=0.23338699961702028
Epoch #74: loss=0.18270665365788671
Epoch #75: loss=0.18863994400534365
Epoch #76: loss=0.17384099960327148
Epoch #77: loss=0.19483215113480887
Epoch #78: loss=0.1959194572021564
Epoch #79: loss=0.20552120130095217
Epoch #80: loss=0.194293186482456
Epoch #81: loss=0.22638222388923168
Epoch #82: loss=0.19080083589586946
Epoch #83: loss=0.15980824703971544
Epoch #84: loss=0.1331360401171777
Epoch #85: loss=0.1623272888569368
Epoch #86: loss=0.17153950977242655
Epoch #87: loss=0.22645790968090296
Epoch #88: loss=0.19657329583747518
Epoch #89: loss=0.18295974532763162
Epoch #90: loss=0.17491030951754916
Epoch #91: loss=0.16913016181853083
Epoch #92: loss=0.201935103473564
Epoch #93: loss=0.17172063649114636
Epoch #94: loss=0.17090267253418764
Epoch #95: loss=0.13639580996500122
Epoch #96: loss=0.23383569034437338
Epoch #97: loss=0.1551880252858003
Epoch #98: loss=0.11772534623742104
Epoch #99: loss=0.170411866158247
Epoch #100: loss=0.17755089555349615
Epoch #101: loss=0.18508236224038732
Epoch #102: loss=0.1384073318913579
Epoch #103: loss=0.1285509945721262
Epoch #104: loss=0.11423673827408089
Epoch #105: loss=0.1315464237704873
Epoch #106: loss=0.10674720992230707
Epoch #107: loss=0.10194990095785922
Epoch #108: loss=0.12743928055796358
Epoch #109: loss=0.12812246992770168
Epoch #110: loss=0.15756844367004103
Epoch #111: loss=0.09297208839820491
Epoch #112: loss=0.2169661314951049
Epoch #113: loss=0.1367563197078804
Epoch #114: loss=0.18488759050766626
Epoch #115: loss=0.31313894378642243
Epoch #116: loss=0.21416032717873654
Epoch #117: loss=0.13160736175874868
Epoch #118: loss=0.11379911295241779
Epoch #119: loss=0.10755763735829128
Epoch #120: loss=0.13952780013076133
Epoch #121: loss=0.09031390735051698
Epoch #122: loss=0.10255432615263595
Epoch #123: loss=0.11781596061256197
Epoch #124: loss=0.09809773591243559
Epoch #125: loss=0.10061814108242591
Epoch #126: loss=0.10408019036468533
Epoch #127: loss=0.10607810830697417
Epoch #128: loss=0.08303027853576674
Epoch #129: loss=0.12483247498878175
Epoch #130: loss=0.07432501426794463
Epoch #131: loss=0.10180344065237376
Epoch #132: loss=0.08572794440098935
Epoch #133: loss=0.07314540942509969
Epoch #134: loss=0.07465843382912378
Epoch #135: loss=0.10260635446239677
Epoch #136: loss=0.10130476421262655
Epoch #137: loss=0.11504143140175277
Epoch #138: loss=0.13551394123997954
Epoch #139: loss=0.18142498325970438
Epoch #140: loss=0.09552826018383105
Epoch #141: loss=0.19245399312219685
Epoch #142: loss=0.12439225293282005
Epoch #143: loss=0.10901376853386562
Epoch #144: loss=0.07887123726929228
Epoch #145: loss=0.12811143225472835
Epoch #146: loss=0.09381121014141375
Epoch #147: loss=0.10768368602212933
Epoch #148: loss=0.12747887392631835
Epoch #149: loss=0.09519249335345295
Epoch #150: loss=0.06784693234496647
Epoch #151: loss=0.12508445631505716
Epoch #152: loss=0.11049840904565321
Epoch #153: loss=0.07338162335670656
Epoch #154: loss=0.08571713368615343
Epoch #155: loss=0.0919866672096153
Epoch #156: loss=0.1028673583900349
Epoch #157: loss=0.07145199849684206
Epoch #158: loss=0.09286963955188791
Epoch #159: loss=0.07054618508037594
Epoch #160: loss=0.08008963614702225
Epoch #161: loss=0.07661387650296092
Epoch #162: loss=0.13751151350637278
Epoch #163: loss=0.11419788758373922
Epoch #164: loss=0.1260267753774921
Epoch #165: loss=0.09246818121108744
Epoch #166: loss=0.12069295010425979
Epoch #167: loss=0.07350384260320829
Epoch #168: loss=0.07816203732767867
Epoch #169: loss=0.05534382881079283
Epoch #170: loss=0.05480852058260805
Epoch #171: loss=0.06755528661111991
Epoch #172: loss=0.05445638718083501
Epoch #173: loss=0.07238024082552227
Epoch #174: loss=0.06477317995288306
Epoch #175: loss=0.0633898275749137
Epoch #176: loss=0.058503499461544886
Epoch #177: loss=0.07511295326468018
Epoch #178: loss=0.07554747089226213
Epoch #179: loss=0.07105908250539666
Epoch #180: loss=0.07388283097599116
Epoch #181: loss=0.12729327660053968
Epoch #182: loss=0.0949009051029053
Epoch #183: loss=0.130516776168305
Epoch #184: loss=0.11613838162480129
Epoch #185: loss=0.0691953264694247
Epoch #186: loss=0.07134851694314016
Epoch #187: loss=0.09036438891457187
Epoch #188: loss=0.07165976313667165
Epoch #189: loss=0.07106693624518812
Epoch #190: loss=0.07030704066467781
Epoch #191: loss=0.07383147536569999
Epoch #192: loss=0.05888724306391345
Epoch #193: loss=0.04715458925865176
Epoch #194: loss=0.044698167644027204
Epoch #195: loss=0.05044073060465356
Epoch #196: loss=0.08582241082977918
Epoch #197: loss=0.08011544485472971
Epoch #198: loss=0.04855273224206434
Epoch #199: loss=0.040349355070955224
Epoch #200: loss=0.049512615026388734
Epoch #201: loss=0.05696632213787072
Epoch #202: loss=0.05277642532665697
Epoch #203: loss=0.05367950255620397
Epoch #204: loss=0.12424740940332413
Epoch #205: loss=0.07584983620068265
Epoch #206: loss=0.0746548034561177
Epoch #207: loss=0.05411119918183734
Epoch #208: loss=0.0714944660042723
Epoch #209: loss=0.05872376299359732
Epoch #210: loss=0.12882878160518077
Epoch #211: loss=0.08934200130816963
Epoch #212: loss=0.1327746207308438
Epoch #213: loss=0.12542724860314694
Epoch #214: loss=0.06670327727786368
Epoch #215: loss=0.06346118170768023
Epoch #216: loss=0.08496671415761942
Epoch #217: loss=0.07051154859881434
Epoch #218: loss=0.047309626592323184
Epoch #219: loss=0.039643535196470715
Epoch #220: loss=0.07949772430583835
Epoch #221: loss=0.07389025972224772
Epoch #222: loss=0.04627085399503509
Epoch #223: loss=0.046838160319667727
Epoch #224: loss=0.027761034499336448
Epoch #225: loss=0.04413931497320947
Epoch #226: loss=0.05693036729159454
Epoch #227: loss=0.04554677975829691
Epoch #228: loss=0.03929556280167566
Epoch #229: loss=0.05021619585911847
Epoch #230: loss=0.04907809148749544
Epoch #231: loss=0.04194023637359755
Epoch #232: loss=0.052486423881620996
Epoch #233: loss=0.049137810077000826
Epoch #234: loss=0.03629855937065764
Epoch #235: loss=0.05018400315505763
Epoch #236: loss=0.0562222427300488
Epoch #237: loss=0.08517614027692212
Epoch #238: loss=0.09793859011390144
Epoch #239: loss=0.08056591003615823
Epoch #240: loss=0.06373505972118841
Epoch #241: loss=0.05727591932130357
Epoch #242: loss=0.05713406945061353
Epoch #243: loss=0.05102614789373345
Epoch #244: loss=0.04140563081536028
Epoch #245: loss=0.04287216908091472
Epoch #246: loss=0.0503105083739178
Epoch #247: loss=0.044906908969601825
Epoch #248: loss=0.05236440599482092
Epoch #249: loss=0.057384691304630704

Training time: 0:11:15.094276

Finished.
n2one setting etth1_etth2_ettm1_ettm2 -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm1_ettm2_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_etth2_ettm1_ettm2', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.6565e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.01066e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.6565e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3789306044333755, 'MAE': 0.434574904888852}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_ettm1_ettm2 -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm1_ettm2_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_etth2_ettm1_ettm2', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.8193e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.27837e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.8193e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.6381841855930016, 'MAE': 0.6290648078498153}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_ettm1_ettm2 -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm1_ettm2_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_etth2_ettm1_ettm2', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.55224e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.2422772108822774, 'MAE': 0.32965882975113847}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_ettm1_electricity', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_ettm1_electricity_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.5895530481559004
Epoch #1: loss=0.6422822863897147
Epoch #2: loss=0.4665880366901442
Epoch #3: loss=0.3571195819474369
Epoch #4: loss=0.3303337457207586
Epoch #5: loss=0.25781477964079447
Epoch #6: loss=0.23025649546973967
Epoch #7: loss=0.19339609165498287
Epoch #8: loss=0.1895864634758475
Epoch #9: loss=0.15665834219426433
Epoch #10: loss=0.14602056808898903
Epoch #11: loss=0.12880408467800286
Epoch #12: loss=0.1375660805806862
Epoch #13: loss=0.1159137087104293
Epoch #14: loss=0.10829916015547307
Epoch #15: loss=0.1003110795524079
Epoch #16: loss=0.09429044485350564
Epoch #17: loss=0.08349362515839022
Epoch #18: loss=0.07872840133630213
Epoch #19: loss=0.08876594343637197
Epoch #20: loss=0.06402978922558054
Epoch #21: loss=0.06994291840960955
Epoch #22: loss=0.06038208998405951
Epoch #23: loss=0.06226928404268588
Epoch #24: loss=0.04940306483848677
Epoch #25: loss=0.04903234841538905
Epoch #26: loss=0.05535977995130799
Epoch #27: loss=0.0676503653619223
Epoch #28: loss=0.04857717671450443
Epoch #29: loss=0.04640877951808661
Epoch #30: loss=0.04561761542724047
Epoch #31: loss=0.05356214177926647
Epoch #32: loss=0.056465584522307
Epoch #33: loss=0.039562218121355235
Epoch #34: loss=0.037135783004213795
Epoch #35: loss=0.044796447181465866
Epoch #36: loss=0.035734265875152035
Epoch #37: loss=0.030373506405460785
Epoch #38: loss=0.04733357172610098
Epoch #39: loss=0.04416730109672197
Epoch #40: loss=0.04012998291277838
Epoch #41: loss=0.03392197877758134
Epoch #42: loss=0.03104167580308468
Epoch #43: loss=0.02520768506744489
Epoch #44: loss=0.04368244874091937
Epoch #45: loss=0.03314323882394702
Epoch #46: loss=0.037810323615908366
Epoch #47: loss=0.037275296080766
Epoch #48: loss=0.03980525611964394
Epoch #49: loss=0.024304015527282858
Epoch #50: loss=0.025694331263576908
Epoch #51: loss=0.022857299980955103
Epoch #52: loss=0.03014335523438882
Epoch #53: loss=0.02121487274971882
Epoch #54: loss=0.03293803069912801
Epoch #55: loss=0.027841259784272446
Epoch #56: loss=0.019443411769000867
Epoch #57: loss=0.021895746254487328
Epoch #58: loss=0.03004753032956283
Epoch #59: loss=0.025783632388688367
Epoch #60: loss=0.025320810732509767
Epoch #61: loss=0.01486388397671557
Epoch #62: loss=0.023644917801687374
Epoch #63: loss=0.02176184815723406
Epoch #64: loss=0.026581057967117454
Epoch #65: loss=0.02325850456543913
Epoch #66: loss=0.022090263082982294
Epoch #67: loss=0.0338128364003651
Epoch #68: loss=0.033308922729018885
Epoch #69: loss=0.024747901837034635
Epoch #70: loss=0.023258248350288276
Epoch #71: loss=0.02292753552698
Epoch #72: loss=0.03462307815604192
Epoch #73: loss=0.014992028795454564
Epoch #74: loss=0.018165356473697113
Epoch #75: loss=0.019855473448611216
Epoch #76: loss=0.013548634342567974
Epoch #77: loss=0.02093710858530279
Epoch #78: loss=0.036323339451909215
Epoch #79: loss=0.021119840896683017
Epoch #80: loss=0.015090994554709082
Epoch #81: loss=0.01702366064647832
Epoch #82: loss=0.01782641524897829
Epoch #83: loss=0.021245507725125522
Epoch #84: loss=0.020436094572829525
Epoch #85: loss=0.01989432776463218
Epoch #86: loss=0.02379909539265515
Epoch #87: loss=0.021611841201359634
Epoch #88: loss=0.016617109096168967
Epoch #89: loss=0.023478137663662475
Epoch #90: loss=0.02565368587276333
Epoch #91: loss=0.0170969511661544
Epoch #92: loss=0.015805073315950616
Epoch #93: loss=0.023672022100745274
Epoch #94: loss=0.014311386993514223
Epoch #95: loss=0.017704403146830888
Epoch #96: loss=0.015434973336543586
Epoch #97: loss=0.016889600309501592
Epoch #98: loss=0.01568426425428119
Epoch #99: loss=0.01611153341929369
Epoch #100: loss=0.02179349976434639
Epoch #101: loss=0.02001112220304846
Epoch #102: loss=0.017337499779744633
Epoch #103: loss=0.011856829047551637
Epoch #104: loss=0.015588383668275937
Epoch #105: loss=0.016585147537720373
Epoch #106: loss=0.019565346907330354
Epoch #107: loss=0.016373321731107827
Epoch #108: loss=0.021027753361254512
Epoch #109: loss=0.02184723931730784
Epoch #110: loss=0.015320292815991348
Epoch #111: loss=0.011756996214362884
Epoch #112: loss=0.015937721251942098
Epoch #113: loss=0.016188866904475106
Epoch #114: loss=0.013761524938052315
Epoch #115: loss=0.01619098843442077
Epoch #116: loss=0.017095015782457805
Epoch #117: loss=0.019105133562176517
Epoch #118: loss=0.011419421090136115
Epoch #119: loss=0.02242026249107614
Epoch #120: loss=0.013421654549321009
Epoch #121: loss=0.015338242172419681
Epoch #122: loss=0.012708262844644406
Epoch #123: loss=0.014341451936587153
Epoch #124: loss=0.020657127401441593
Epoch #125: loss=0.021853937497604746
Epoch #126: loss=0.014743042225724711
Epoch #127: loss=0.011515850610395565
Epoch #128: loss=0.012315304918084132
Epoch #129: loss=0.013575389981101606
Epoch #130: loss=0.025093296047493902
Epoch #131: loss=0.014589471828812905
Epoch #132: loss=0.022312603730993006
Epoch #133: loss=0.01231051328127014
Epoch #134: loss=0.0126723497027647
Epoch #135: loss=0.013772362952000822
Epoch #136: loss=0.013017332696455471
Epoch #137: loss=0.014386167805614972
Epoch #138: loss=0.013935413251959348
Epoch #139: loss=0.008123846764331737
Epoch #140: loss=0.017680092375070084
Epoch #141: loss=0.01297067558258971
Epoch #142: loss=0.015439112651877838
Epoch #143: loss=0.013430191373527911
Epoch #144: loss=0.012020749014124645
Epoch #145: loss=0.015749905448180834
Epoch #146: loss=0.013879123294501932
Epoch #147: loss=0.009465577494566035
Epoch #148: loss=0.011344674484625276
Epoch #149: loss=0.010510591343428799
Epoch #150: loss=0.05164008311415226
Epoch #151: loss=0.015527309724863221
Epoch #152: loss=0.013559325196446495
Epoch #153: loss=0.011112853061798772
Epoch #154: loss=0.012418659756194283
Epoch #155: loss=0.01478314037031677
Epoch #156: loss=0.015874674416640422
Epoch #157: loss=0.009579310952207999
Epoch #158: loss=0.009043879501068712
Epoch #159: loss=0.014254040163174551
Epoch #160: loss=0.01154481933850558
Epoch #161: loss=0.010605913415403815
Epoch #162: loss=0.010046457765725538
Epoch #163: loss=0.017255224548350896
Epoch #164: loss=0.015212959831484964
Epoch #165: loss=0.010710700748927724
Epoch #166: loss=0.01763205719752388
Epoch #167: loss=0.020194549329267314
Epoch #168: loss=0.01366220287103179
Epoch #169: loss=0.011778397009017571
Epoch #170: loss=0.018177640651008842
Epoch #171: loss=0.01231085558386918
Epoch #172: loss=0.010600587718926958
Epoch #173: loss=0.012765794547477931
Epoch #174: loss=0.010466269628586237
Epoch #175: loss=0.012013715284242634
Epoch #176: loss=0.011288454223607903
Epoch #177: loss=0.011697243137444595
Epoch #178: loss=0.010225550264336783
Epoch #179: loss=0.023279713613628492
Epoch #180: loss=0.01321352642053749
Epoch #181: loss=0.013915060426517675
Epoch #182: loss=0.012339879236889955
Epoch #183: loss=0.011565407764249363
Epoch #184: loss=0.008759330992867518
Epoch #185: loss=0.010687956570077694
Epoch #186: loss=0.029656297617256803
Epoch #187: loss=0.011872703305242389
Epoch #188: loss=0.008676783968035045
Epoch #189: loss=0.012047536862355313
Epoch #190: loss=0.015224646308225166
Epoch #191: loss=0.016189513886158996
Epoch #192: loss=0.01784232465383419
Epoch #193: loss=0.012650683233541345
Epoch #194: loss=0.010077607329743726
Epoch #195: loss=0.008740969944083821
Epoch #196: loss=0.012618267715227591
Epoch #197: loss=0.0074684700628842166
Epoch #198: loss=0.015503247612781117
Epoch #199: loss=0.009822817620413506
Epoch #200: loss=0.013072940781362613
Epoch #201: loss=0.012717903882562522
Epoch #202: loss=0.010339256605914676
Epoch #203: loss=0.012652836782663301
Epoch #204: loss=0.01300817861777227
Epoch #205: loss=0.014213999833762269
Epoch #206: loss=0.015997313239579387
Epoch #207: loss=0.016813198462158247
Epoch #208: loss=0.011156757538996885
Epoch #209: loss=0.010047719910279229
Epoch #210: loss=0.011440401780082592
Epoch #211: loss=0.03958938808958961
Epoch #212: loss=0.011568103338062838
Epoch #213: loss=0.0075494141722581825
Epoch #214: loss=0.011525095448017691
Epoch #215: loss=0.00852149174511002
Epoch #216: loss=0.007507119721358217
Epoch #217: loss=0.009208830574675761
Epoch #218: loss=0.008175665259578621
Epoch #219: loss=0.00859245830979279
Epoch #220: loss=0.014347831070011972
Epoch #221: loss=0.011112996975614048
Epoch #222: loss=0.013260700281997443
Epoch #223: loss=0.00863761666386975
Epoch #224: loss=0.009218474820197688
Epoch #225: loss=0.008660846273330676
Epoch #226: loss=0.01755007400574106
Epoch #227: loss=0.015003206402822425
Epoch #228: loss=0.00976529235493091
Epoch #229: loss=0.021349393825566214
Epoch #230: loss=0.009406212929601247
Epoch #231: loss=0.007651452366831292
Epoch #232: loss=0.007972815248788883
Epoch #233: loss=0.009719992410781864
Epoch #234: loss=0.010201201905063058
Epoch #235: loss=0.014021850354576516
Epoch #236: loss=0.012145201335179975
Epoch #237: loss=0.006258996240300062
Epoch #238: loss=0.005875972941931003
Epoch #239: loss=0.010918695206089063
Epoch #240: loss=0.017641908885181662
Epoch #241: loss=0.020283555198121667
Epoch #242: loss=0.010494642255836533
Epoch #243: loss=0.015398772142277735
Epoch #244: loss=0.008575951702158623
Epoch #245: loss=0.007178856861904449
Epoch #246: loss=0.008528433966576902
Epoch #247: loss=0.007219663305535126
Epoch #248: loss=0.020341818855730196
Epoch #249: loss=0.011405656672744995

Training time: 1:38:18.542257

Finished.
n2one setting etth1_etth2_ettm1_electricity -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm1_electricity_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_etth2_ettm1_electricity', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.01667e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.2145e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.23026e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.01667e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.40166300292015455, 'MAE': 0.4618490998023755}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_ettm1_electricity -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm1_electricity_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_etth2_ettm1_electricity', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.00059e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.00059e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.27423392999838914, 'MAE': 0.35364755158716815}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_ettm1_traffic', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_ettm1_traffic_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.9604264517916364
Epoch #1: loss=0.3524611583389048
Epoch #2: loss=0.2555132683748726
Epoch #3: loss=0.19109273059325127
Epoch #4: loss=0.14587901507870724
Epoch #5: loss=0.129939765344965
Epoch #6: loss=0.10883038769252472
Epoch #7: loss=0.09341421127403333
Epoch #8: loss=0.08217259012939662
Epoch #9: loss=0.07744978176190474
Epoch #10: loss=0.06801600697667684
Epoch #11: loss=0.06581561027615507
Epoch #12: loss=0.059645608963661126
Epoch #13: loss=0.05197232907476258
Epoch #14: loss=0.053855169956386506
Epoch #15: loss=0.057861838794261926
Epoch #16: loss=0.05252913719624819
Epoch #17: loss=0.043906477626713396
Epoch #18: loss=0.044941858549653775
Epoch #19: loss=0.03969489892114168
Epoch #20: loss=0.03860705699236158
Epoch #21: loss=0.03413448909616776
Epoch #22: loss=0.03812949119354656
Epoch #23: loss=0.033248257068229425
Epoch #24: loss=0.03234755914942325
Epoch #25: loss=0.033731025511678725
Epoch #26: loss=0.034107015068798194
Epoch #27: loss=0.029553839028760447
Epoch #28: loss=0.03614057879343738
Epoch #29: loss=0.03050251101809601
Epoch #30: loss=0.02788483700321267
Epoch #31: loss=0.029089364708399162
Epoch #32: loss=0.0345696408570384
Epoch #33: loss=0.023425748149600308
Epoch #34: loss=0.02317104084451873
Epoch #35: loss=0.0329006818320556
Epoch #36: loss=0.021116415163323077
Epoch #37: loss=0.02253083273981831
Epoch #38: loss=0.024130752762890364
Epoch #39: loss=0.025869691903188954
Epoch #40: loss=0.02852342982051722
Epoch #41: loss=0.022392290010625704
Epoch #42: loss=0.019836998270525836
Epoch #43: loss=0.023287790755530256
Epoch #44: loss=0.025544791112931103
Epoch #45: loss=0.01964175454989231
Epoch #46: loss=0.029428251382247507
Epoch #47: loss=0.020943432053004567
Epoch #48: loss=0.01606739329387042
Epoch #49: loss=0.020934955151255527
Epoch #50: loss=0.024025786461546416
Epoch #51: loss=0.021308583709313676
Epoch #52: loss=0.02014798765018763
Epoch #53: loss=0.017528720765896698
Epoch #54: loss=0.03163566425611478
Epoch #55: loss=0.024883388137138262
Epoch #56: loss=0.014618721894755552
Epoch #57: loss=0.02177456799920033
Epoch #58: loss=0.025582505702676322
Epoch #59: loss=0.028092792956289764
Epoch #60: loss=0.014793123806702875
Epoch #61: loss=0.02066172266472446
Epoch #62: loss=0.016593133813684244
Epoch #63: loss=0.01923778769533909
Epoch #64: loss=0.021351626830392337
Epoch #65: loss=0.016729811884543155
Epoch #66: loss=0.020939837137859036
Epoch #67: loss=0.016739717966241956
Epoch #68: loss=0.023452124538242906
Epoch #69: loss=0.013591053205297623
Epoch #70: loss=0.019036555352846263
Epoch #71: loss=0.013983582982175544
Epoch #72: loss=0.018222070409302897
Epoch #73: loss=0.015875397265822207
Epoch #74: loss=0.013799188093875777
Epoch #75: loss=0.017846870426471286
Epoch #76: loss=0.019280385965517625
Epoch #77: loss=0.01612548525606596
Epoch #78: loss=0.037493168436562516
Epoch #79: loss=0.013742653696796213
Epoch #80: loss=0.01552723385522897
Epoch #81: loss=0.014868548963663327
Epoch #82: loss=0.014497873435999668
Epoch #83: loss=0.01267648037209878
Epoch #84: loss=0.015362129119692607
Epoch #85: loss=0.01791074184247785
Epoch #86: loss=0.01817193180169089
Epoch #87: loss=0.01397884557326298
Epoch #88: loss=0.013783018642250584
Epoch #89: loss=0.011341871167384136
Epoch #90: loss=0.014412128427559394
Epoch #91: loss=0.013013379339155681
Epoch #92: loss=0.018702626334379396
Epoch #93: loss=0.014346550795768194
Epoch #94: loss=0.014266186060809547
Epoch #95: loss=0.02054145886103928
Epoch #96: loss=0.016510751240074596
Epoch #97: loss=0.013734407703623988
Epoch #98: loss=0.014439302782498966
Epoch #99: loss=0.011179035695356589
Epoch #100: loss=0.01615643595719895
Epoch #101: loss=0.017934164419401308
Epoch #102: loss=0.017077834195057887
Epoch #103: loss=0.014819788603149375
Epoch #104: loss=0.012243897569363962
Epoch #105: loss=0.015149025393857566
Epoch #106: loss=0.011426767637979937
Epoch #107: loss=0.013668790154223117
Epoch #108: loss=0.014694051608837523
Epoch #109: loss=0.019480293750195433
Epoch #110: loss=0.013118672581403196
Epoch #111: loss=0.011712622292663701
Epoch #112: loss=0.013719435260226119
Epoch #113: loss=0.017105671984773273
Epoch #114: loss=0.014426214161732946
Epoch #115: loss=0.010975108841065844
Epoch #116: loss=0.010418383958175927
Epoch #117: loss=0.009664720223063321
Epoch #118: loss=0.01926182715867708
Epoch #119: loss=0.011584512116849965
Epoch #120: loss=0.013965876444802397
Epoch #121: loss=0.012709226048766321
Epoch #122: loss=0.013980053305513569
Epoch #123: loss=0.014467897923837028
Epoch #124: loss=0.014505192039978325
Epoch #125: loss=0.012650033028383151
Epoch #126: loss=0.012992446878753033
Epoch #127: loss=0.01600550739902435
Epoch #128: loss=0.011403693193283663
Epoch #129: loss=0.014856597916640471
Epoch #130: loss=0.013042229154273072
Epoch #131: loss=0.020565414124698953
Epoch #132: loss=0.010877870290763014
Epoch #133: loss=0.013822470855817257
Epoch #134: loss=0.012613427700384209
Epoch #135: loss=0.012539897368951274
Epoch #136: loss=0.01251710694430374
Epoch #137: loss=0.01104447832412434
Epoch #138: loss=0.012578964198060415
Epoch #139: loss=0.013808840749328043
Epoch #140: loss=0.006827174151313529
Epoch #141: loss=0.01317703633035928
Epoch #142: loss=0.013201014983655177
Epoch #143: loss=0.01389812440566142
Epoch #144: loss=0.009570425010316196
Epoch #145: loss=0.013110079669981319
Epoch #146: loss=0.008887105464386104
Epoch #147: loss=0.009324467412788414
Epoch #148: loss=0.01703684376933971
Epoch #149: loss=0.01583030675246518
Epoch #150: loss=0.012292813323316765
Epoch #151: loss=0.011276131870721576
Epoch #152: loss=0.009203285406745382
Epoch #153: loss=0.009964259505334779
Epoch #154: loss=0.009866664612686378
Epoch #155: loss=0.013918217445024564
Epoch #156: loss=0.01647019815089033
Epoch #157: loss=0.015557213372564292
Epoch #158: loss=0.01174505155956099
Epoch #159: loss=0.010596816724096975
Epoch #160: loss=0.01107466927873721
Epoch #161: loss=0.01560523832758118
Epoch #162: loss=0.013123504095090676
Epoch #163: loss=0.009781138830620841
Epoch #164: loss=0.026200358261285493
Epoch #165: loss=0.019199644768377766
Epoch #166: loss=0.01069436703431995
Epoch #167: loss=0.011347621117539761
Epoch #168: loss=0.008706710083963214
Epoch #169: loss=0.009300591722971407
Epoch #170: loss=0.012293952966335711
Epoch #171: loss=0.010358985608799033
Epoch #172: loss=0.011280900603443753
Epoch #173: loss=0.015252901956474716
Epoch #174: loss=0.015203535538123451
Epoch #175: loss=0.009545874159225722
Epoch #176: loss=0.009455824964972456
Epoch #177: loss=0.018510012155655443
Epoch #178: loss=0.00926812843784082
Epoch #179: loss=0.012455358265290402
Epoch #180: loss=0.01023573111865286
Epoch #181: loss=0.010953384912045191
Epoch #182: loss=0.01163304202518323
Epoch #183: loss=0.009882160753723451
Epoch #184: loss=0.013500791312048496
Epoch #185: loss=0.011335906347930153
Epoch #186: loss=0.012937113916685278
Epoch #187: loss=0.010860960921021299
Epoch #188: loss=0.011181748877187916
Epoch #189: loss=0.012898452731006618
Epoch #190: loss=0.011765258606962162
Epoch #191: loss=0.014722503670035855
Epoch #192: loss=0.013191862585380822
Epoch #193: loss=0.00940681237499626
Epoch #194: loss=0.010867020007076683
Epoch #195: loss=0.011715036043674808
Epoch #196: loss=0.012167647104599963
Epoch #197: loss=0.008945311177594622
Epoch #198: loss=0.011087067168435133
Epoch #199: loss=0.012637596576536424
Epoch #200: loss=0.010819059467908985
Epoch #201: loss=0.015141337754112603
Epoch #202: loss=0.011921074573819565
Epoch #203: loss=0.007815917186780803
Epoch #204: loss=0.012648988769395202
Epoch #205: loss=0.00990434199623583
Epoch #206: loss=0.017774148427246332
Epoch #207: loss=0.009694783438913595
Epoch #208: loss=0.009020696342537047
Epoch #209: loss=0.01039517500085794
Epoch #210: loss=0.0081093643344818
Epoch #211: loss=0.013701515252802473
Epoch #212: loss=0.010495465505114055
Epoch #213: loss=0.007836608710833179
Epoch #214: loss=0.009349469487656581
Epoch #215: loss=0.009500678963172068
Epoch #216: loss=0.00934614130881983
Epoch #217: loss=0.013614673562993751
Epoch #218: loss=0.01116700909613514
Epoch #219: loss=0.011489258822971868
Epoch #220: loss=0.010459451280774973
Epoch #221: loss=0.013519752287766763
Epoch #222: loss=0.013059673473241603
Epoch #223: loss=0.007032746830005582
Epoch #224: loss=0.01221429619931179
Epoch #225: loss=0.01004966061177486
Epoch #226: loss=0.013162722357142992
Epoch #227: loss=0.010289950001585977
Epoch #228: loss=0.008974040756678478
Epoch #229: loss=0.011417991681786652
Epoch #230: loss=0.009768641587717595
Epoch #231: loss=0.009951306196020075
Epoch #232: loss=0.012522066557729904
Epoch #233: loss=0.010771942125163367
Epoch #234: loss=0.012430856102152114
Epoch #235: loss=0.008629624290006792
Epoch #236: loss=0.012487602799862708
Epoch #237: loss=0.013108531687670653
Epoch #238: loss=0.00969426109927815
Epoch #239: loss=0.011365358131199451
Epoch #240: loss=0.006428589608478008
Epoch #241: loss=0.00984821303073908
Epoch #242: loss=0.01144218308324957
Epoch #243: loss=0.012557822035973642
Epoch #244: loss=0.00911186641476595
Epoch #245: loss=0.009289205021639588
Epoch #246: loss=0.00474493238095554
Epoch #247: loss=0.007793803147276944
Epoch #248: loss=0.014502309328137716
Epoch #249: loss=0.007569997975827308

Training time: 3:35:26.909206

Finished.
n2one setting etth1_etth2_ettm1_traffic -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm1_traffic_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_etth2_ettm1_traffic', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.33935e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.92094e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.93367e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.33935e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.41269593092473367, 'MAE': 0.45632326564784087}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_ettm1_traffic -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm1_traffic_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_etth2_ettm1_traffic', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.63927e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.05663e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.25663e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.63927e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.6691717291254247, 'MAE': 0.6543004073143573}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_ettm1_traffic -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm1_traffic_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_etth2_ettm1_traffic', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.62811e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.30158234982761206, 'MAE': 0.3651262396604404}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_ettm1_weather', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_ettm1_weather_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=4.2856175478766945
Epoch #1: loss=2.8139316381192674
Epoch #2: loss=2.1851606298895443
Epoch #3: loss=2.007861997566971
Epoch #4: loss=1.8393373232261807
Epoch #5: loss=1.7280112855574663
Epoch #6: loss=1.6049040298835904
Epoch #7: loss=1.3940560326856726
Epoch #8: loss=1.2416133974112717
Epoch #9: loss=1.177800387728448
Epoch #10: loss=1.1012135451915217
Epoch #11: loss=1.0282613401319467
Epoch #12: loss=0.9659808254709431
Epoch #13: loss=1.0029159620696424
Epoch #14: loss=1.080900694809708
Epoch #15: loss=1.0575106739997864
Epoch #16: loss=0.9174876178012175
Epoch #17: loss=0.8716247806362077
Epoch #18: loss=0.818255556564705
Epoch #19: loss=0.7973555595267052
Epoch #20: loss=0.760303163060955
Epoch #21: loss=0.7165933835740183
Epoch #22: loss=0.7089621307803136
Epoch #23: loss=0.7057586271388858
Epoch #24: loss=0.7324206373270821
Epoch #25: loss=0.7424047478273803
Epoch #26: loss=0.6398440920839122
Epoch #27: loss=0.6100049807744867
Epoch #28: loss=0.6132717646804511
Epoch #29: loss=0.6222075995276956
Epoch #30: loss=0.5619615333921769
Epoch #31: loss=0.5134353012430901
Epoch #32: loss=0.6321568039118075
Epoch #33: loss=0.5290883125043383
Epoch #34: loss=0.5649432125044804
Epoch #35: loss=0.5350636641184489
Epoch #36: loss=0.48256876421909706
Epoch #37: loss=0.5957103681330588
Epoch #38: loss=0.6356189397035861
Epoch #39: loss=0.5647093548494226
Epoch #40: loss=0.5248907564901838
Epoch #41: loss=0.4976762784462349
Epoch #42: loss=0.4476669372296801
Epoch #43: loss=0.4746640698582518
Epoch #44: loss=0.42346847291086237
Epoch #45: loss=0.4205730797029009
Epoch #46: loss=0.4189833329588759
Epoch #47: loss=0.4277781654222339
Epoch #48: loss=0.4199351890414369
Epoch #49: loss=0.3770885768474317
Epoch #50: loss=0.45333874167180527
Epoch #51: loss=0.460523075040649
Epoch #52: loss=0.3970283632184945
Epoch #53: loss=0.36254409715241076
Epoch #54: loss=0.4017772078514099
Epoch #55: loss=0.3993012393806495
Epoch #56: loss=0.35562988619009656
Epoch #57: loss=0.314068565473837
Epoch #58: loss=0.3530014545894137
Epoch #59: loss=0.3235212920927534
Epoch #60: loss=0.38125985451773103
Epoch #61: loss=0.32123298417119417
Epoch #62: loss=0.31581313031561237
Epoch #63: loss=0.3270611546787561
Epoch #64: loss=0.31185908936986734
Epoch #65: loss=0.32040514168786066
Epoch #66: loss=0.32272105678623797
Epoch #67: loss=0.3085005553621872
Epoch #68: loss=0.2676866129040718
Epoch #69: loss=0.25253944215821283
Epoch #70: loss=0.2961245791292658
Epoch #71: loss=0.3185773563443446
Epoch #72: loss=0.2488870376757547
Epoch #73: loss=0.26921269312208773
Epoch #74: loss=0.2586006006481601
Epoch #75: loss=0.23510398686516518
Epoch #76: loss=0.33367088626997143
Epoch #77: loss=0.2696963434710222
Epoch #78: loss=0.23418818837871738
Epoch #79: loss=0.2331485922137896
Epoch #80: loss=0.19818773763436898
Epoch #81: loss=0.2216827446485267
Epoch #82: loss=0.28425734329457375
Epoch #83: loss=0.2857544955377485
Epoch #84: loss=0.25213270532149895
Epoch #85: loss=0.25724991659323376
Epoch #86: loss=0.24145485153969595
Epoch #87: loss=0.2887192424021515
Epoch #88: loss=0.20596255274379954
Epoch #89: loss=0.22146470932399526
Epoch #90: loss=0.2080553006015572
Epoch #91: loss=0.2555376588567799
Epoch #92: loss=0.16799909679913053
Epoch #93: loss=0.17566106183563962
Epoch #94: loss=0.16309865943941415
Epoch #95: loss=0.15940682831055977
Epoch #96: loss=0.17333984988577225
Epoch #97: loss=0.155168463859488
Epoch #98: loss=0.1476563771857935
Epoch #99: loss=0.15046404185248355
Epoch #100: loss=0.1317788804424744
Epoch #101: loss=0.17543722426190095
Epoch #102: loss=0.16146557135324852
Epoch #103: loss=0.14745852855198524
Epoch #104: loss=0.14642699588747585
Epoch #105: loss=0.17622531307678596
Epoch #106: loss=0.14949424601360864
Epoch #107: loss=0.26157434511126254
Epoch #108: loss=0.15274751602726824
Epoch #109: loss=0.15620963005166427
Epoch #110: loss=0.2505889885565814
Epoch #111: loss=0.3038491793707305
Epoch #112: loss=0.3683564192524143
Epoch #113: loss=0.24345801288590713
Epoch #114: loss=0.20497002627919703
Epoch #115: loss=0.14071783649862982
Epoch #116: loss=0.1170702005426089
Epoch #117: loss=0.1373155396796909
Epoch #118: loss=0.10786573340495427
Epoch #119: loss=0.10493359360478673
Epoch #120: loss=0.10399020956281353
Epoch #121: loss=0.10716869148845766
Epoch #122: loss=0.10661619299036615
Epoch #123: loss=0.12159095700903266
Epoch #124: loss=0.1344616764097237
Epoch #125: loss=0.12734857365927277
Epoch #126: loss=0.1464894917957923
Epoch #127: loss=0.1194634301332282
Epoch #128: loss=0.1254054868922514
Epoch #129: loss=0.11742341182395524
Epoch #130: loss=0.14554849697970876
Epoch #131: loss=0.12132785900258551
Epoch #132: loss=0.12719739221182524
Epoch #133: loss=0.08316722336937399
Epoch #134: loss=0.08483915852711481
Epoch #135: loss=0.13309400126922363
Epoch #136: loss=0.09167264007470187
Epoch #137: loss=0.1168117248544506
Epoch #138: loss=0.09716867140549071
Epoch #139: loss=0.08587278217515525
Epoch #140: loss=0.1266183932403139
Epoch #141: loss=0.14856830980701774
Epoch #142: loss=0.11470624771626557
Epoch #143: loss=0.13073344159798295
Epoch #144: loss=0.11130995927926372
Epoch #145: loss=0.14216259695297362
Epoch #146: loss=0.16356062154997797
Epoch #147: loss=0.13713882176899442
Epoch #148: loss=0.11690713943657922
Epoch #149: loss=0.1457220881300814
Epoch #150: loss=0.09700362271099698
Epoch #151: loss=0.11622100732490129
Epoch #152: loss=0.12329502655741047
Epoch #153: loss=0.09260414347198664
Epoch #154: loss=0.08294516257649544
Epoch #155: loss=0.11923809959461876
Epoch #156: loss=0.14523297990215758
Epoch #157: loss=0.10950811638259421
Epoch #158: loss=0.11114091539353717
Epoch #159: loss=0.08283500804328452
Epoch #160: loss=0.07224599547757238
Epoch #161: loss=0.0891862292317491
Epoch #162: loss=0.09490228951999954
Epoch #163: loss=0.10465445628791463
Epoch #164: loss=0.10451406419423281
Epoch #165: loss=0.15941165712680302
Epoch #166: loss=0.10441530572579187
Epoch #167: loss=0.08942131281775587
Epoch #168: loss=0.16835812705696798
Epoch #169: loss=0.12921066406895132
Epoch #170: loss=0.12061266882308558
Epoch #171: loss=0.12499164004682325
Epoch #172: loss=0.11989853731995705
Epoch #173: loss=0.1363431240486748
Epoch #174: loss=0.07530433626151552
Epoch #175: loss=0.08379770850068798
Epoch #176: loss=0.10809372794613534
Epoch #177: loss=0.08118953278251723
Epoch #178: loss=0.08970141556917452
Epoch #179: loss=0.06682964967673316
Epoch #180: loss=0.08371484429374629
Epoch #181: loss=0.06219933541747285
Epoch #182: loss=0.09572196426783122
Epoch #183: loss=0.08186059923586893
Epoch #184: loss=0.10625807369383526
Epoch #185: loss=0.2670706580666935
Epoch #186: loss=0.1501939374515239
Epoch #187: loss=0.10087811022850812
Epoch #188: loss=0.09777555161831426
Epoch #189: loss=0.1026940323302851
Epoch #190: loss=0.10607520837848093
Epoch #191: loss=0.06853596451600977
Epoch #192: loss=0.08738498860860572
Epoch #193: loss=0.09332891108066428
Epoch #194: loss=0.10859564859785285
Epoch #195: loss=0.08956196612002802
Epoch #196: loss=0.08490582526314493
Epoch #197: loss=0.0683780911506391
Epoch #198: loss=0.0987396228729802
Epoch #199: loss=0.07747415909726246
Epoch #200: loss=0.06075561283996292
Epoch #201: loss=0.06450067915241509
Epoch #202: loss=0.05709523742324581
Epoch #203: loss=0.07156366350896218
Epoch #204: loss=0.07534416973152581
Epoch #205: loss=0.06109513879260596
Epoch #206: loss=0.16273588104648332
Epoch #207: loss=0.1047435278693835
Epoch #208: loss=0.0761886441751438
Epoch #209: loss=0.07086914920193307
Epoch #210: loss=0.05681571799019972
Epoch #211: loss=0.04709131781961404
Epoch #212: loss=0.0773571571700421
Epoch #213: loss=0.09148281872929896
Epoch #214: loss=0.08418139230971243
Epoch #215: loss=0.051246405889590584
Epoch #216: loss=0.05610512520241387
Epoch #217: loss=0.07629179134599719
Epoch #218: loss=0.06874722565579064
Epoch #219: loss=0.08398184932622255
Epoch #220: loss=0.0623011011812909
Epoch #221: loss=0.058738786142830755
Epoch #222: loss=0.04820276510116516
Epoch #223: loss=0.050234488741147755
Epoch #224: loss=0.05825731616613327
Epoch #225: loss=0.066928156450683
Epoch #226: loss=0.053366454646867865
Epoch #227: loss=0.054465522797887814
Epoch #228: loss=0.05978446822686523
Epoch #229: loss=0.05976568723060921
Epoch #230: loss=0.04630024327586094
Epoch #231: loss=0.04993256325742193
Epoch #232: loss=0.061453274560763556
Epoch #233: loss=0.06475629042103595
Epoch #234: loss=0.11241470750275195
Epoch #235: loss=0.19810119837376416
Epoch #236: loss=0.1615604947083721
Epoch #237: loss=0.09118876646400667
Epoch #238: loss=0.0807920294430326
Epoch #239: loss=0.06971260362907368
Epoch #240: loss=0.06933123574537389
Epoch #241: loss=0.07287884288120504
Epoch #242: loss=0.07568095628099114
Epoch #243: loss=0.038754127152702385
Epoch #244: loss=0.05009602037641932
Epoch #245: loss=0.043483295012265444
Epoch #246: loss=0.07397994125152335
Epoch #247: loss=0.056505896753686315
Epoch #248: loss=0.08053772971399274
Epoch #249: loss=0.047512133286206744

Training time: 0:17:23.588935

Finished.
n2one setting etth1_etth2_ettm1_weather -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm1_weather_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_etth2_ettm1_weather', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.48919e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.92292e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.48919e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.370306986581982, 'MAE': 0.430121751619881}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_ettm1_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm1_weather_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_etth2_ettm1_weather', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.71099e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.27027529728121263, 'MAE': 0.3538452918960792}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_ettm1_exchange', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_ettm1_exchange_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=3.6997361110918447
Epoch #1: loss=2.2353686636144463
Epoch #2: loss=1.9723288471048528
Epoch #3: loss=1.8334664612105398
Epoch #4: loss=1.6959295417323257
Epoch #5: loss=1.5508756565325188
Epoch #6: loss=1.4441006328120376
Epoch #7: loss=1.3178990862586282
Epoch #8: loss=1.2755684527483853
Epoch #9: loss=1.2068737456292817
Epoch #10: loss=1.0932239348238164
Epoch #11: loss=1.1208372098026853
Epoch #12: loss=1.01767307881153
Epoch #13: loss=1.0584377483888106
Epoch #14: loss=0.9469972668272076
Epoch #15: loss=0.9534903728600704
Epoch #16: loss=0.8729202331918658
Epoch #17: loss=0.8617551073883519
Epoch #18: loss=0.8540042855522849
Epoch #19: loss=0.8598849068988453
Epoch #20: loss=0.9396639610781814
Epoch #21: loss=0.8257293719233889
Epoch #22: loss=0.825952843283162
Epoch #23: loss=0.7036903283812783
Epoch #24: loss=0.7273739160913409
Epoch #25: loss=0.6732819423531041
Epoch #26: loss=0.6670779630993352
Epoch #27: loss=0.70401029604854
Epoch #28: loss=0.6459955582112977
Epoch #29: loss=0.6832805185606985
Epoch #30: loss=0.6829062907984762
Epoch #31: loss=0.5787051256858942
Epoch #32: loss=0.6569199309204564
Epoch #33: loss=0.6366191452199762
Epoch #34: loss=0.6268998790871013
Epoch #35: loss=0.5771407385667165
Epoch #36: loss=0.5782354293447552
Epoch #37: loss=0.5651035877791318
Epoch #38: loss=0.5283649473479299
Epoch #39: loss=0.5280311414689729
Epoch #40: loss=0.5386335903948004
Epoch #41: loss=0.5987552910140066
Epoch #42: loss=0.4794811610922669
Epoch #43: loss=0.5376286326032697
Epoch #44: loss=0.513587191249385
Epoch #45: loss=0.7345773875713348
Epoch #46: loss=0.6233631842064135
Epoch #47: loss=0.5438200036684672
Epoch #48: loss=0.543782909711202
Epoch #49: loss=0.46645335446704517
Epoch #50: loss=0.5359143858606165
Epoch #51: loss=0.5235657931277247
Epoch #52: loss=0.48946022806745587
Epoch #53: loss=0.49188167895331525
Epoch #54: loss=0.4864768223329024
Epoch #55: loss=0.5100756684939066
Epoch #56: loss=0.5208246920144919
Epoch #57: loss=0.4518035045175841
Epoch #58: loss=0.4312761371785944
Epoch #59: loss=0.437931217027433
Epoch #60: loss=0.3774811833193808
Epoch #61: loss=0.4095562890623555
Epoch #62: loss=0.4229149922276988
Epoch #63: loss=0.3610551704963048
Epoch #64: loss=0.39818569566264295
Epoch #65: loss=0.4220606865304889
Epoch #66: loss=0.40392393280159344
Epoch #67: loss=0.40311233473546576
Epoch #68: loss=0.38488210692550195
Epoch #69: loss=0.415315744100195
Epoch #70: loss=0.4021404552640337
Epoch #71: loss=0.44060495586106274
Epoch #72: loss=0.44801377843726764
Epoch #73: loss=0.38882475639834546
Epoch #74: loss=0.36868570970766473
Epoch #75: loss=0.3532092864766265
Epoch #76: loss=0.3456347489898855
Epoch #77: loss=0.34944586275201855
Epoch #78: loss=0.37189431262738776
Epoch #79: loss=0.39981230009685864
Epoch #80: loss=0.3461400153058948
Epoch #81: loss=0.34575652985861804
Epoch #82: loss=0.3557199178771539
Epoch #83: loss=0.2868821474187302
Epoch #84: loss=0.29700778063499567
Epoch #85: loss=0.39873961743080255
Epoch #86: loss=0.39547717435793445
Epoch #87: loss=0.3833420086990703
Epoch #88: loss=0.3253734278859514
Epoch #89: loss=0.30872250416062097
Epoch #90: loss=0.44442167245980463
Epoch #91: loss=0.4170907934506734
Epoch #92: loss=0.32954039898785675
Epoch #93: loss=0.31038619939124945
Epoch #94: loss=0.2911987390482064
Epoch #95: loss=0.3061369630423459
Epoch #96: loss=0.3107833397207838
Epoch #97: loss=0.36205078751751874
Epoch #98: loss=0.2863879533428134
Epoch #99: loss=0.3156851633931651
Epoch #100: loss=0.2652362226085229
Epoch #101: loss=0.30998753146691754
Epoch #102: loss=0.21742175677509018
Epoch #103: loss=0.26301651831829187
Epoch #104: loss=0.28118882215384283
Epoch #105: loss=0.2312906930843989
Epoch #106: loss=0.2816841584263426
Epoch #107: loss=0.2535955345991886
Epoch #108: loss=0.326593795057499
Epoch #109: loss=0.30908609384840185
Epoch #110: loss=0.3324239434617938
Epoch #111: loss=0.31788104185552307
Epoch #112: loss=0.2578905369296218
Epoch #113: loss=0.2633843376781001
Epoch #114: loss=0.3505423935976895
Epoch #115: loss=0.26462120675679407
Epoch #116: loss=0.2279996887752504
Epoch #117: loss=0.21748719364404678
Epoch #118: loss=0.20801879510735022
Epoch #119: loss=0.1758279807188294
Epoch #120: loss=0.2449114252672051
Epoch #121: loss=0.24775299046075705
Epoch #122: loss=0.2599173824895512
Epoch #123: loss=0.2574099823832512
Epoch #124: loss=0.25826431697968283
Epoch #125: loss=0.20488301077575394
Epoch #126: loss=0.2200296555053104
Epoch #127: loss=0.20219042942379462
Epoch #128: loss=0.23625903034752066
Epoch #129: loss=0.21345212107354944
Epoch #130: loss=0.2243130188999754
Epoch #131: loss=0.22114160002181024
Epoch #132: loss=0.20778280157934537
Epoch #133: loss=0.19070468459165457
Epoch #134: loss=0.16793068927345853
Epoch #135: loss=0.20354120128534056
Epoch #136: loss=0.16826502843336624
Epoch #137: loss=0.15044167141119638
Epoch #138: loss=0.17017208965438785
Epoch #139: loss=0.1749749711968682
Epoch #140: loss=0.15679424120621246
Epoch #141: loss=0.1322043745806723
Epoch #142: loss=0.18485973301258954
Epoch #143: loss=0.1713750311596827
Epoch #144: loss=0.1994184853904175
Epoch #145: loss=0.2629300933895689
Epoch #146: loss=0.19530617344108495
Epoch #147: loss=0.1798155124891888
Epoch #148: loss=0.1694763953035528
Epoch #149: loss=0.12426536417368686
Epoch #150: loss=0.16147519986737857
Epoch #151: loss=0.1879888145309506
Epoch #152: loss=0.1532265484107263
Epoch #153: loss=0.1877238591286269
Epoch #154: loss=0.159980952626828
Epoch #155: loss=0.16346710288163388
Epoch #156: loss=0.1528908976099708
Epoch #157: loss=0.1812659688293934
Epoch #158: loss=0.18368265281120935
Epoch #159: loss=0.20535695575403445
Epoch #160: loss=0.23416879479632233
Epoch #161: loss=0.2088058100956859
Epoch #162: loss=0.17161863150470186
Epoch #163: loss=0.18189302041675104
Epoch #164: loss=0.16333587230606514
Epoch #165: loss=0.16427483341910623
Epoch #166: loss=0.18018173189325767
Epoch #167: loss=0.19100713154131715
Epoch #168: loss=0.15878634256395427
Epoch #169: loss=0.1627990912758943
Epoch #170: loss=0.12543788665171826
Epoch #171: loss=0.13987043590256662
Epoch #172: loss=0.13625919356039076
Epoch #173: loss=0.1714115637269887
Epoch #174: loss=0.16275180447282214
Epoch #175: loss=0.14727356352589346
Epoch #176: loss=0.19793645800514656
Epoch #177: loss=0.21474298812223203
Epoch #178: loss=0.17228661127614253
Epoch #179: loss=0.13997016260118195
Epoch #180: loss=0.13386267976778926
Epoch #181: loss=0.20030313481887183
Epoch #182: loss=0.22005917131900787
Epoch #183: loss=0.1483065320009535
Epoch #184: loss=0.21295111378033957
Epoch #185: loss=0.17546110261570325
Epoch #186: loss=0.15983759837620187
Epoch #187: loss=0.12562760106767668
Epoch #188: loss=0.12401196642807036
Epoch #189: loss=0.19815830073573373
Epoch #190: loss=0.12008463963866234
Epoch #191: loss=0.11234013950734427
Epoch #192: loss=0.14502024266755942
Epoch #193: loss=0.1256492038567861
Epoch #194: loss=0.15668153469309662
Epoch #195: loss=0.1516975426312649
Epoch #196: loss=0.19440622932531618
Epoch #197: loss=0.15435252982107076
Epoch #198: loss=0.23292331702329896
Epoch #199: loss=0.15730281716043298
Epoch #200: loss=0.15543332255699419
Epoch #201: loss=0.10364774829058936
Epoch #202: loss=0.12632834030823273
Epoch #203: loss=0.12028693848035553
Epoch #204: loss=0.135763820034988
Epoch #205: loss=0.1678034309862238
Epoch #206: loss=0.1340805200690573
Epoch #207: loss=0.11794021635344534
Epoch #208: loss=0.12813401820533205
Epoch #209: loss=0.11691027078213113
Epoch #210: loss=0.10744839551096613
Epoch #211: loss=0.13099530536794302
Epoch #212: loss=0.11579246830308076
Epoch #213: loss=0.1267741842929161
Epoch #214: loss=0.12719352486910243
Epoch #215: loss=0.13007686004945726
Epoch #216: loss=0.10230065103281628
Epoch #217: loss=0.09276107630946419
Epoch #218: loss=0.1405626264485446
Epoch #219: loss=0.12215786653034615
Epoch #220: loss=0.12628067183223637
Epoch #221: loss=0.1043911398473111
Epoch #222: loss=0.11922408290433162
Epoch #223: loss=0.13318405210068732
Epoch #224: loss=0.1037599506477515
Epoch #225: loss=0.12316856296225027
Epoch #226: loss=0.11558464271101085
Epoch #227: loss=0.09078785720648187
Epoch #228: loss=0.19992707026275722
Epoch #229: loss=0.16017924802321376
Epoch #230: loss=0.11375640281899409
Epoch #231: loss=0.10186740925366228
Epoch #232: loss=0.11331814154982567
Epoch #233: loss=0.11299620348621499
Epoch #234: loss=0.0989433295573249
Epoch #235: loss=0.18376722875418086
Epoch #236: loss=0.182777589469245
Epoch #237: loss=0.14643825060038856
Epoch #238: loss=0.20069243533141684
Epoch #239: loss=0.19267761142867984
Epoch #240: loss=0.143135464834896
Epoch #241: loss=0.1334235235822923
Epoch #242: loss=0.11898249263564746
Epoch #243: loss=0.11340366089434335
Epoch #244: loss=0.09810664860362356
Epoch #245: loss=0.11226108015486688
Epoch #246: loss=0.08979955304301146
Epoch #247: loss=0.09551285173405301
Epoch #248: loss=0.0896161992215749
Epoch #249: loss=0.10094451576922879

Training time: 0:08:44.985862

Finished.
n2one setting etth1_etth2_ettm1_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm1_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_etth2_ettm1_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.41423e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.74531e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.41423e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.37294789635337156, 'MAE': 0.4339004348479094}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_ettm1_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm1_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_etth2_ettm1_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.50026e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.87535e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.5259062046487616, 'MAE': 0.5280984207498122}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_ettm2_electricity', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_ettm2_electricity_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.610514808769171
Epoch #1: loss=0.649854654780013
Epoch #2: loss=0.47147939991572
Epoch #3: loss=0.35796856195423643
Epoch #4: loss=0.3324175727677483
Epoch #5: loss=0.2608944888447406
Epoch #6: loss=0.23556065753188438
Epoch #7: loss=0.19410257648698168
Epoch #8: loss=0.18756823073749598
Epoch #9: loss=0.1605419926560683
Epoch #10: loss=0.14338507627088554
Epoch #11: loss=0.1326616051784485
Epoch #12: loss=0.13759000091194418
Epoch #13: loss=0.1148551122656878
Epoch #14: loss=0.10472664673613503
Epoch #15: loss=0.10740598874177375
Epoch #16: loss=0.10068698968156914
Epoch #17: loss=0.0807698379308416
Epoch #18: loss=0.07800108277524224
Epoch #19: loss=0.09248247804023282
Epoch #20: loss=0.062157031466290785
Epoch #21: loss=0.06883106155945473
Epoch #22: loss=0.055473999487709875
Epoch #23: loss=0.06833072678412101
Epoch #24: loss=0.048076635160661074
Epoch #25: loss=0.050209592785578586
Epoch #26: loss=0.05469666474843344
Epoch #27: loss=0.06679089506145976
Epoch #28: loss=0.05296710043381146
Epoch #29: loss=0.050124776288544
Epoch #30: loss=0.05006709700043857
Epoch #31: loss=0.054493866688598784
Epoch #32: loss=0.05570772811474354
Epoch #33: loss=0.03732796610034249
Epoch #34: loss=0.037089634459261174
Epoch #35: loss=0.045096348169006706
Epoch #36: loss=0.03699303583128948
Epoch #37: loss=0.04140014442173775
Epoch #38: loss=0.0468168782105271
Epoch #39: loss=0.04631837709427332
Epoch #40: loss=0.031311582035056684
Epoch #41: loss=0.0309638970967576
Epoch #42: loss=0.03410645275823557
Epoch #43: loss=0.02512086349818048
Epoch #44: loss=0.04499836921936838
Epoch #45: loss=0.030487782037897693
Epoch #46: loss=0.03907156077945723
Epoch #47: loss=0.03442607642652069
Epoch #48: loss=0.03398883912908828
Epoch #49: loss=0.027906458923792347
Epoch #50: loss=0.02781886731461498
Epoch #51: loss=0.021526004849580477
Epoch #52: loss=0.030121658754405818
Epoch #53: loss=0.021777517465077813
Epoch #54: loss=0.03506521574985989
Epoch #55: loss=0.026461761603279933
Epoch #56: loss=0.02419412307941888
Epoch #57: loss=0.025416941170189045
Epoch #58: loss=0.028916564410703116
Epoch #59: loss=0.023764464744121763
Epoch #60: loss=0.025302915730933535
Epoch #61: loss=0.015782420612290245
Epoch #62: loss=0.025305410138313857
Epoch #63: loss=0.02157334375835826
Epoch #64: loss=0.024174567527673343
Epoch #65: loss=0.024490549961223424
Epoch #66: loss=0.018046888123425208
Epoch #67: loss=0.043219152396892044
Epoch #68: loss=0.05195386076044571
Epoch #69: loss=0.026204547710579448
Epoch #70: loss=0.02216693652945845
Epoch #71: loss=0.017034266516498985
Epoch #72: loss=0.031048348342738723
Epoch #73: loss=0.014841447258637303
Epoch #74: loss=0.021677985360086867
Epoch #75: loss=0.024797990961562884
Epoch #76: loss=0.017148161829163917
Epoch #77: loss=0.025074854645725998
Epoch #78: loss=0.03196106498355767
Epoch #79: loss=0.01837967553363058
Epoch #80: loss=0.01813886289782903
Epoch #81: loss=0.021881294572682824
Epoch #82: loss=0.020779397549925943
Epoch #83: loss=0.014220923640915983
Epoch #84: loss=0.02090054324752721
Epoch #85: loss=0.017353888495416095
Epoch #86: loss=0.026635224625099492
Epoch #87: loss=0.020998095962652303
Epoch #88: loss=0.014131402052942976
Epoch #89: loss=0.01894519959271595
Epoch #90: loss=0.02950242691036755
Epoch #91: loss=0.014569153379032529
Epoch #92: loss=0.01787301055354206
Epoch #93: loss=0.025859289128344096
Epoch #94: loss=0.017834312441143762
Epoch #95: loss=0.014729745639622685
Epoch #96: loss=0.01920888822584957
Epoch #97: loss=0.020619756128299832
Epoch #98: loss=0.016226526812920777
Epoch #99: loss=0.015699593490595267
Epoch #100: loss=0.020640195829432453
Epoch #101: loss=0.023194101616212656
Epoch #102: loss=0.015993635486939255
Epoch #103: loss=0.013569529832817204
Epoch #104: loss=0.018467369487689473
Epoch #105: loss=0.01639967881808612
Epoch #106: loss=0.021527915734917497
Epoch #107: loss=0.01671751498411587
Epoch #108: loss=0.0125437767261362
Epoch #109: loss=0.018732429987574642
Epoch #110: loss=0.017725440095322786
Epoch #111: loss=0.01768795686092287
Epoch #112: loss=0.01544565902760446
Epoch #113: loss=0.014347188115591651
Epoch #114: loss=0.010293792769201154
Epoch #115: loss=0.01320749110386793
Epoch #116: loss=0.017189857588658337
Epoch #117: loss=0.02281477762069257
Epoch #118: loss=0.014289813180120306
Epoch #119: loss=0.022068270340725386
Epoch #120: loss=0.023057634618726824
Epoch #121: loss=0.016329029402217823
Epoch #122: loss=0.009877984164631926
Epoch #123: loss=0.013650726447402731
Epoch #124: loss=0.018772784101196722
Epoch #125: loss=0.021400405178479097
Epoch #126: loss=0.014683204491231106
Epoch #127: loss=0.011623476977904888
Epoch #128: loss=0.01040034460723454
Epoch #129: loss=0.019067415852009485
Epoch #130: loss=0.02263982587435412
Epoch #131: loss=0.012236823833539457
Epoch #132: loss=0.020904934963644106
Epoch #133: loss=0.014564916731236567
Epoch #134: loss=0.010419119540497667
Epoch #135: loss=0.016538844474643804
Epoch #136: loss=0.012682561465199886
Epoch #137: loss=0.014206449761132122
Epoch #138: loss=0.011072220870497572
Epoch #139: loss=0.013041021253723877
Epoch #140: loss=0.01305501054547797
Epoch #141: loss=0.012428407628722408
Epoch #142: loss=0.014380175129758097
Epoch #143: loss=0.013523973820992137
Epoch #144: loss=0.011529727162143236
Epoch #145: loss=0.016217665525753523
Epoch #146: loss=0.0199910928655047
Epoch #147: loss=0.01398358802199081
Epoch #148: loss=0.012941031543991522
Epoch #149: loss=0.01197831453270995
Epoch #150: loss=0.041758825504012415
Epoch #151: loss=0.015614311181959653
Epoch #152: loss=0.012358797580707613
Epoch #153: loss=0.006831875788473532
Epoch #154: loss=0.010989239606336755
Epoch #155: loss=0.013916002678169432
Epoch #156: loss=0.014059664762304353
Epoch #157: loss=0.012536364781715359
Epoch #158: loss=0.01052629220979241
Epoch #159: loss=0.016829979070832394
Epoch #160: loss=0.011056606273565205
Epoch #161: loss=0.012010348325940468
Epoch #162: loss=0.015341687292927833
Epoch #163: loss=0.015150225412260708
Epoch #164: loss=0.015251412441297246
Epoch #165: loss=0.012878682269802925
Epoch #166: loss=0.013694441194038414
Epoch #167: loss=0.011285576299828817
Epoch #168: loss=0.02027670634998617
Epoch #169: loss=0.01461212464131824
Epoch #170: loss=0.011051645924033049
Epoch #171: loss=0.01117877342578056
Epoch #172: loss=0.016802237877007197
Epoch #173: loss=0.01400319839652084
Epoch #174: loss=0.010000574438260044
Epoch #175: loss=0.012210568753468152
Epoch #176: loss=0.008831074311279536
Epoch #177: loss=0.013300545502694949
Epoch #178: loss=0.014122063830034602
Epoch #179: loss=0.012574013705147333
Epoch #180: loss=0.010501954497095208
Epoch #181: loss=0.010785365882807417
Epoch #182: loss=0.01412118569361665
Epoch #183: loss=0.021368748184718796
Epoch #184: loss=0.009751554437902234
Epoch #185: loss=0.010837528423770906
Epoch #186: loss=0.037706143153606604
Epoch #187: loss=0.01331646565628518
Epoch #188: loss=0.010767116545291746
Epoch #189: loss=0.009944302429706854
Epoch #190: loss=0.014935895482719489
Epoch #191: loss=0.01017476486313329
Epoch #192: loss=0.015817092333730538
Epoch #193: loss=0.014985123605415564
Epoch #194: loss=0.009555182414880693
Epoch #195: loss=0.01323318646891336
Epoch #196: loss=0.013005470278900994
Epoch #197: loss=0.007226946069996917
Epoch #198: loss=0.01527643594029494
Epoch #199: loss=0.014809963004438159
Epoch #200: loss=0.011418147559760198
Epoch #201: loss=0.011849490696540092
Epoch #202: loss=0.008554639359680408
Epoch #203: loss=0.009380395838037278
Epoch #204: loss=0.018561980148072144
Epoch #205: loss=0.011388402089686537
Epoch #206: loss=0.017888505908127638
Epoch #207: loss=0.015736146830695255
Epoch #208: loss=0.013972944446948405
Epoch #209: loss=0.011189530841885753
Epoch #210: loss=0.010639907433796066
Epoch #211: loss=0.02796236573605101
Epoch #212: loss=0.014197204925013555
Epoch #213: loss=0.009411554210926971
Epoch #214: loss=0.01292724290901709
Epoch #215: loss=0.009076980956879881
Epoch #216: loss=0.008085318879228398
Epoch #217: loss=0.006061743892731974
Epoch #218: loss=0.007603373018839003
Epoch #219: loss=0.012269179474759572
Epoch #220: loss=0.010909584364005919
Epoch #221: loss=0.013860860435397101
Epoch #222: loss=0.013341059309707665
Epoch #223: loss=0.006809015607685416
Epoch #224: loss=0.009545551175742835
Epoch #225: loss=0.012201871299669362
Epoch #226: loss=0.01732354920516948
Epoch #227: loss=0.00954257127710462
Epoch #228: loss=0.008315462850130465
Epoch #229: loss=0.019129196895652175
Epoch #230: loss=0.011164995710294145
Epoch #231: loss=0.009359530578004035
Epoch #232: loss=0.008813419099190579
Epoch #233: loss=0.010573187321367286
Epoch #234: loss=0.01305544421004772
Epoch #235: loss=0.01589893021858351
Epoch #236: loss=0.009734787224644574
Epoch #237: loss=0.00883375353244136
Epoch #238: loss=0.00854635713199716
Epoch #239: loss=0.012182713594089796
Epoch #240: loss=0.01141282608325464
Epoch #241: loss=0.016231283477697294
Epoch #242: loss=0.013136462837466405
Epoch #243: loss=0.02070714981839225
Epoch #244: loss=0.011372636672414872
Epoch #245: loss=0.00982875109916335
Epoch #246: loss=0.009841631789004693
Epoch #247: loss=0.009400550898577012
Epoch #248: loss=0.02317613974959533
Epoch #249: loss=0.008658765003319312

Training time: 1:35:50.983732

Finished.
n2one setting etth1_etth2_ettm2_electricity -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm2_electricity_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_etth2_ettm2_electricity', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.07567e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.36573e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.75459e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.07567e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.42980766066809184, 'MAE': 0.48186658363613954}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_ettm2_electricity -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm2_electricity_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_etth2_ettm2_electricity', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.44703e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3125883215237648, 'MAE': 0.3772828754058891}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_ettm2_traffic', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_ettm2_traffic_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.9691829258048951
Epoch #1: loss=0.35588897126301566
Epoch #2: loss=0.25164212157956106
Epoch #3: loss=0.19383988739857544
Epoch #4: loss=0.13753899501000344
Epoch #5: loss=0.12953416488879899
Epoch #6: loss=0.10186492866734641
Epoch #7: loss=0.08481290821918405
Epoch #8: loss=0.07881634964228618
Epoch #9: loss=0.07240483133760706
Epoch #10: loss=0.06455380475755441
Epoch #11: loss=0.06291284240160679
Epoch #12: loss=0.057651302791405325
Epoch #13: loss=0.047209978552236985
Epoch #14: loss=0.05228424581001894
Epoch #15: loss=0.04949634180093455
Epoch #16: loss=0.04949781342972335
Epoch #17: loss=0.0383793584062175
Epoch #18: loss=0.04169851688357341
Epoch #19: loss=0.03779516199298136
Epoch #20: loss=0.03254961299871671
Epoch #21: loss=0.031388613695946546
Epoch #22: loss=0.035560717400013264
Epoch #23: loss=0.03379134162659352
Epoch #24: loss=0.03133685432866388
Epoch #25: loss=0.03087891499328678
Epoch #26: loss=0.03367623448303114
Epoch #27: loss=0.026402879847983254
Epoch #28: loss=0.0360830890595138
Epoch #29: loss=0.030970390145249535
Epoch #30: loss=0.028406315927421034
Epoch #31: loss=0.026426851130725886
Epoch #32: loss=0.028386690348910174
Epoch #33: loss=0.022810420971964892
Epoch #34: loss=0.02856486761223802
Epoch #35: loss=0.026048533351823642
Epoch #36: loss=0.020137985654174233
Epoch #37: loss=0.02195388031368781
Epoch #38: loss=0.025558197438394548
Epoch #39: loss=0.022085070448679262
Epoch #40: loss=0.022612387005222924
Epoch #41: loss=0.025053352639963694
Epoch #42: loss=0.021240785125059756
Epoch #43: loss=0.02086375504687508
Epoch #44: loss=0.022426595666347096
Epoch #45: loss=0.01886216210987022
Epoch #46: loss=0.021877329743397973
Epoch #47: loss=0.023377758573390032
Epoch #48: loss=0.013837442154355091
Epoch #49: loss=0.019089993770211186
Epoch #50: loss=0.022154898871106606
Epoch #51: loss=0.016645314808618097
Epoch #52: loss=0.021337836587442222
Epoch #53: loss=0.01645059825025925
Epoch #54: loss=0.033091623108824054
Epoch #55: loss=0.022820742899200774
Epoch #56: loss=0.02075554535914792
Epoch #57: loss=0.02145007059505428
Epoch #58: loss=0.02167376250259866
Epoch #59: loss=0.027389398077765338
Epoch #60: loss=0.011527923985621698
Epoch #61: loss=0.020100110598080954
Epoch #62: loss=0.014775797047559382
Epoch #63: loss=0.016656001347165425
Epoch #64: loss=0.01930209445037901
Epoch #65: loss=0.017140450727524237
Epoch #66: loss=0.019705885413521217
Epoch #67: loss=0.014516011918003785
Epoch #68: loss=0.021234100368843815
Epoch #69: loss=0.015728893383089013
Epoch #70: loss=0.014504750920865178
Epoch #71: loss=0.01676559262604373
Epoch #72: loss=0.015811877200034002
Epoch #73: loss=0.01573630294616803
Epoch #74: loss=0.01260209583463814
Epoch #75: loss=0.014066365274354993
Epoch #76: loss=0.022287116988284856
Epoch #77: loss=0.015406251601275558
Epoch #78: loss=0.030826532771614543
Epoch #79: loss=0.015287696857659227
Epoch #80: loss=0.015441414651576705
Epoch #81: loss=0.014482672844426506
Epoch #82: loss=0.014242226238003664
Epoch #83: loss=0.015072693821951524
Epoch #84: loss=0.014732580457840549
Epoch #85: loss=0.015122395295640842
Epoch #86: loss=0.015105806846412946
Epoch #87: loss=0.012004928647164096
Epoch #88: loss=0.017025307292108695
Epoch #89: loss=0.011665139142636487
Epoch #90: loss=0.01390809168520183
Epoch #91: loss=0.013784316203752775
Epoch #92: loss=0.015700552517356848
Epoch #93: loss=0.016826670774885505
Epoch #94: loss=0.01043219427791295
Epoch #95: loss=0.0168278133831976
Epoch #96: loss=0.013716948478207506
Epoch #97: loss=0.014877819145008294
Epoch #98: loss=0.01671235874490332
Epoch #99: loss=0.011550419817064662
Epoch #100: loss=0.014998843280025861
Epoch #101: loss=0.020025576855420328
Epoch #102: loss=0.015630970515372187
Epoch #103: loss=0.012996616976410717
Epoch #104: loss=0.01114511285032321
Epoch #105: loss=0.01621501769578103
Epoch #106: loss=0.010569139913442674
Epoch #107: loss=0.015296153457698296
Epoch #108: loss=0.01608458676206404
Epoch #109: loss=0.01636537315123536
Epoch #110: loss=0.011459690734888837
Epoch #111: loss=0.01129563116024746
Epoch #112: loss=0.013655078800929565
Epoch #113: loss=0.020019172457387522
Epoch #114: loss=0.016022585255811527
Epoch #115: loss=0.010228226141790989
Epoch #116: loss=0.008335576793929643
Epoch #117: loss=0.014279148452537263
Epoch #118: loss=0.014329136863975337
Epoch #119: loss=0.012075442928376449
Epoch #120: loss=0.015826496087540186
Epoch #121: loss=0.009147000588448308
Epoch #122: loss=0.017297744936722655
Epoch #123: loss=0.017280764264909532
Epoch #124: loss=0.012192741066109538
Epoch #125: loss=0.013474497118644025
Epoch #126: loss=0.01212095476254761
Epoch #127: loss=0.013099134798419452
Epoch #128: loss=0.01249108198963094
Epoch #129: loss=0.009430778439244909
Epoch #130: loss=0.011899262232129912
Epoch #131: loss=0.022052889859832493
Epoch #132: loss=0.010376060231747064
Epoch #133: loss=0.01248880052136356
Epoch #134: loss=0.010769474857140032
Epoch #135: loss=0.012870773172484798
Epoch #136: loss=0.01382448036568696
Epoch #137: loss=0.009346286269825366
Epoch #138: loss=0.013761560608613964
Epoch #139: loss=0.014762396092064365
Epoch #140: loss=0.011742438552482474
Epoch #141: loss=0.010072599450765983
Epoch #142: loss=0.010374462651538352
Epoch #143: loss=0.012903923881937106
Epoch #144: loss=0.010970650926671224
Epoch #145: loss=0.013896200052631695
Epoch #146: loss=0.010270306766023985
Epoch #147: loss=0.01049000612190891
Epoch #148: loss=0.012755162886593526
Epoch #149: loss=0.01234033978935289
Epoch #150: loss=0.010546297487115927
Epoch #151: loss=0.009588731403490544
Epoch #152: loss=0.01046439051763165
Epoch #153: loss=0.012738425295681586
Epoch #154: loss=0.008859884820156915
Epoch #155: loss=0.011431424148005262
Epoch #156: loss=0.010919631946988912
Epoch #157: loss=0.013397921464871747
Epoch #158: loss=0.008746148007778816
Epoch #159: loss=0.011983307439243534
Epoch #160: loss=0.009708559652603402
Epoch #161: loss=0.01492734677226544
Epoch #162: loss=0.011864653422313862
Epoch #163: loss=0.008375586300011853
Epoch #164: loss=0.025834311513127046
Epoch #165: loss=0.014252510706772303
Epoch #166: loss=0.01009352563537766
Epoch #167: loss=0.012784279193734411
Epoch #168: loss=0.007351860564643451
Epoch #169: loss=0.01201594287257974
Epoch #170: loss=0.011275828821262898
Epoch #171: loss=0.008638127466403588
Epoch #172: loss=0.014040132751630942
Epoch #173: loss=0.012669725624287686
Epoch #174: loss=0.012314210114701364
Epoch #175: loss=0.011793929674501085
Epoch #176: loss=0.009160603764264166
Epoch #177: loss=0.01962497639050471
Epoch #178: loss=0.01258832059617274
Epoch #179: loss=0.009825016149804532
Epoch #180: loss=0.009589110503046434
Epoch #181: loss=0.010878816297680208
Epoch #182: loss=0.014073784075472126
Epoch #183: loss=0.007835605125490058
Epoch #184: loss=0.010791164344943652
Epoch #185: loss=0.012784962326258299
Epoch #186: loss=0.011138862053741694
Epoch #187: loss=0.010590918728157416
Epoch #188: loss=0.014736012639689156
Epoch #189: loss=0.010176711095915163
Epoch #190: loss=0.013997740349603717
Epoch #191: loss=0.02185837870374219
Epoch #192: loss=0.008164481194177354
Epoch #193: loss=0.013377385197598183
Epoch #194: loss=0.012677259259232252
Epoch #195: loss=0.006622240680902897
Epoch #196: loss=0.01027170549703446
Epoch #197: loss=0.005475342850998283
Epoch #198: loss=0.014953059322517543
Epoch #199: loss=0.006953575581907644
Epoch #200: loss=0.009711576145409535
Epoch #201: loss=0.012450743505743432
Epoch #202: loss=0.012914840533102656
Epoch #203: loss=0.009974438885142586
Epoch #204: loss=0.012991998686670827
Epoch #205: loss=0.007278620252299638
Epoch #206: loss=0.013102153235062875
Epoch #207: loss=0.011331754830607351
Epoch #208: loss=0.008763651020211727
Epoch #209: loss=0.008501259303958078
Epoch #210: loss=0.013304453417815646
Epoch #211: loss=0.010659510562751676
Epoch #212: loss=0.009362816925202192
Epoch #213: loss=0.007888599034646717
Epoch #214: loss=0.01139947096497283
Epoch #215: loss=0.012467973618087644
Epoch #216: loss=0.009708099269445039
Epoch #217: loss=0.01042509647291663
Epoch #218: loss=0.010036952814613963
Epoch #219: loss=0.011026022982910399
Epoch #220: loss=0.010449327877673463
Epoch #221: loss=0.011593981049372815
Epoch #222: loss=0.01205932046870807
Epoch #223: loss=0.008521563494791853
Epoch #224: loss=0.009298408377037978
Epoch #225: loss=0.007591764460947903
Epoch #226: loss=0.01002057892511067
Epoch #227: loss=0.010593926207926424
Epoch #228: loss=0.009732379793756974
Epoch #229: loss=0.009774902804432203
Epoch #230: loss=0.008355727132309199
Epoch #231: loss=0.012595762060322889
Epoch #232: loss=0.01201418104542883
Epoch #233: loss=0.008744753462470082
Epoch #234: loss=0.008191276458719554
Epoch #235: loss=0.010305535963622553
Epoch #236: loss=0.011707487038598923
Epoch #237: loss=0.011311903419997136
Epoch #238: loss=0.007601050213022628
Epoch #239: loss=0.007601799180687308
Epoch #240: loss=0.0050151076057755595
Epoch #241: loss=0.01556448550523955
Epoch #242: loss=0.012750751713344359
Epoch #243: loss=0.010193638455056036
Epoch #244: loss=0.009341564474281147
Epoch #245: loss=0.009517790085793312
Epoch #246: loss=0.010203480827075475
Epoch #247: loss=0.009080759523587492
Epoch #248: loss=0.010660799306843207
Epoch #249: loss=0.007075453465343784

Training time: 3:30:18.629304

Finished.
n2one setting etth1_etth2_ettm2_traffic -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm2_traffic_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_etth2_ettm2_traffic', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.06113e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.18805e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.4489e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.06113e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.43569665099620714, 'MAE': 0.469305344671147}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_ettm2_traffic -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm2_traffic_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_etth2_ettm2_traffic', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.18876e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.55508e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.5316758447323442, 'MAE': 0.5510933847374755}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_ettm2_traffic -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm2_traffic_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_etth2_ettm2_traffic', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.66824e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.24391252013832543, 'MAE': 0.3332875337836124}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_ettm2_weather', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_ettm2_weather_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=4.258699010400211
Epoch #1: loss=2.7675002813339233
Epoch #2: loss=2.1670420707440843
Epoch #3: loss=1.996655080832687
Epoch #4: loss=1.8231307875876333
Epoch #5: loss=1.7210061737135345
Epoch #6: loss=1.5864526687883864
Epoch #7: loss=1.4000132925370161
Epoch #8: loss=1.2353322202084112
Epoch #9: loss=1.1654988538985158
Epoch #10: loss=1.0930250590922785
Epoch #11: loss=1.0218571190740549
Epoch #12: loss=0.9613548821093989
Epoch #13: loss=1.012386327865077
Epoch #14: loss=1.0428720233487148
Epoch #15: loss=0.9930938143356174
Epoch #16: loss=0.8621756890240837
Epoch #17: loss=0.8738133498266631
Epoch #18: loss=0.8140658070059383
Epoch #19: loss=0.7875802248131996
Epoch #20: loss=0.7566635959288653
Epoch #21: loss=0.7117530726918987
Epoch #22: loss=0.6962536620158776
Epoch #23: loss=0.6780349816761765
Epoch #24: loss=0.6479310796541327
Epoch #25: loss=0.6902445069715089
Epoch #26: loss=0.620348091803345
Epoch #27: loss=0.5882656048325932
Epoch #28: loss=0.6148851823573019
Epoch #29: loss=0.6371168850683698
Epoch #30: loss=0.5743682366960189
Epoch #31: loss=0.5138519984834334
Epoch #32: loss=0.5987835094040516
Epoch #33: loss=0.5125881597107532
Epoch #34: loss=0.5524106499026803
Epoch #35: loss=0.5072127440396477
Epoch #36: loss=0.45999836804820043
Epoch #37: loss=0.5639188114334556
Epoch #38: loss=0.6434762770054387
Epoch #39: loss=0.7240706635456459
Epoch #40: loss=0.5940971929653018
Epoch #41: loss=0.5256100711869258
Epoch #42: loss=0.4649263123671214
Epoch #43: loss=0.4825589767858094
Epoch #44: loss=0.4318811180544834
Epoch #45: loss=0.43361786066317093
Epoch #46: loss=0.44091464842067046
Epoch #47: loss=0.4445855868797676
Epoch #48: loss=0.41408610256279216
Epoch #49: loss=0.4071666910952213
Epoch #50: loss=0.4643005816375508
Epoch #51: loss=0.45594649542780485
Epoch #52: loss=0.3868527015050252
Epoch #53: loss=0.35130663479075713
Epoch #54: loss=0.37239346989229616
Epoch #55: loss=0.3734586303140603
Epoch #56: loss=0.3292860806572671
Epoch #57: loss=0.3029347494536755
Epoch #58: loss=0.362123562132611
Epoch #59: loss=0.33016447167770535
Epoch #60: loss=0.4042893510823156
Epoch #61: loss=0.3261304304880254
Epoch #62: loss=0.3097303518477608
Epoch #63: loss=0.3101482128395754
Epoch #64: loss=0.2979451981829662
Epoch #65: loss=0.25281326370496376
Epoch #66: loss=0.27610813972412374
Epoch #67: loss=0.28760894767793954
Epoch #68: loss=0.27186202608487187
Epoch #69: loss=0.2579879122329693
Epoch #70: loss=0.2867232908805211
Epoch #71: loss=0.2517729633871247
Epoch #72: loss=0.22957813432987997
Epoch #73: loss=0.2693950598146401
Epoch #74: loss=0.259493558576294
Epoch #75: loss=0.306894279432063
Epoch #76: loss=0.36490267339874716
Epoch #77: loss=0.31595389618008746
Epoch #78: loss=0.2688515509168307
Epoch #79: loss=0.2438230926499647
Epoch #80: loss=0.24086599081170326
Epoch #81: loss=0.23145784992797702
Epoch #82: loss=0.29930874953667325
Epoch #83: loss=0.30606970775361153
Epoch #84: loss=0.24106381380674885
Epoch #85: loss=0.23246677117604836
Epoch #86: loss=0.24458890452104456
Epoch #87: loss=0.2778470000507785
Epoch #88: loss=0.1965834418056058
Epoch #89: loss=0.21790351777100095
Epoch #90: loss=0.21745016440456988
Epoch #91: loss=0.2621039426794239
Epoch #92: loss=0.16907620313120822
Epoch #93: loss=0.17510550973169944
Epoch #94: loss=0.1673249844826904
Epoch #95: loss=0.16151470406090512
Epoch #96: loss=0.1630102579354071
Epoch #97: loss=0.16044390983149118
Epoch #98: loss=0.15646674330620206
Epoch #99: loss=0.16087668761610985
Epoch #100: loss=0.13706937899776533
Epoch #101: loss=0.18506182467236237
Epoch #102: loss=0.15764843855126232
Epoch #103: loss=0.14343705298561676
Epoch #104: loss=0.1625564982201539
Epoch #105: loss=0.20129595280570142
Epoch #106: loss=0.16991439593188903
Epoch #107: loss=0.2517480219111723
Epoch #108: loss=0.1459233178665825
Epoch #109: loss=0.14557709603333005
Epoch #110: loss=0.234544778060095
Epoch #111: loss=0.21504784448474062
Epoch #112: loss=0.26615161711678786
Epoch #113: loss=0.23761195521436485
Epoch #114: loss=0.24712716116040362
Epoch #115: loss=0.17716133105112056
Epoch #116: loss=0.14324262237870225
Epoch #117: loss=0.14483508095145226
Epoch #118: loss=0.10911796899402842
Epoch #119: loss=0.10556340633946307
Epoch #120: loss=0.10879205203816003
Epoch #121: loss=0.10838271330530737
Epoch #122: loss=0.1105862515887209
Epoch #123: loss=0.1217539144278157
Epoch #124: loss=0.13781905053731272
Epoch #125: loss=0.12437165893760382
Epoch #126: loss=0.1481179965331274
Epoch #127: loss=0.1077068449162385
Epoch #128: loss=0.1236103011989126
Epoch #129: loss=0.1107540931187424
Epoch #130: loss=0.16031825199138885
Epoch #131: loss=0.12759917119846625
Epoch #132: loss=0.13608903799425154
Epoch #133: loss=0.0834641168076618
Epoch #134: loss=0.08429843147157454
Epoch #135: loss=0.12963589448847024
Epoch #136: loss=0.09384878531244456
Epoch #137: loss=0.11192610516559844
Epoch #138: loss=0.09378526754239026
Epoch #139: loss=0.081699360344632
Epoch #140: loss=0.1294539181479052
Epoch #141: loss=0.15822630850415603
Epoch #142: loss=0.10513036720016423
Epoch #143: loss=0.119954804506372
Epoch #144: loss=0.11051143585320782
Epoch #145: loss=0.14672241049508253
Epoch #146: loss=0.1752334859076084
Epoch #147: loss=0.1361193168616178
Epoch #148: loss=0.09188402721694872
Epoch #149: loss=0.12833610648179755
Epoch #150: loss=0.08520787001094397
Epoch #151: loss=0.10085591896637983
Epoch #152: loss=0.1158594328398798
Epoch #153: loss=0.0870528576128623
Epoch #154: loss=0.07908610256352261
Epoch #155: loss=0.11240640487156663
Epoch #156: loss=0.1574687625044117
Epoch #157: loss=0.1145172493130553
Epoch #158: loss=0.11612057565327953
Epoch #159: loss=0.09238373174094687
Epoch #160: loss=0.0733796970224848
Epoch #161: loss=0.08841042138416977
Epoch #162: loss=0.08538575631146338
Epoch #163: loss=0.10483505125796679
Epoch #164: loss=0.10426625277043558
Epoch #165: loss=0.15660745139215507
Epoch #166: loss=0.09808401496825266
Epoch #167: loss=0.08609086001182303
Epoch #168: loss=0.16276108499105071
Epoch #169: loss=0.12124913967415399
Epoch #170: loss=0.12402596032502604
Epoch #171: loss=0.11701777142783006
Epoch #172: loss=0.1367578575862389
Epoch #173: loss=0.14798196642568298
Epoch #174: loss=0.0807785118619601
Epoch #175: loss=0.09381214832412262
Epoch #176: loss=0.107078745778577
Epoch #177: loss=0.0806578950883419
Epoch #178: loss=0.09408719172956896
Epoch #179: loss=0.06659388483739366
Epoch #180: loss=0.09809504500498958
Epoch #181: loss=0.06951901177857436
Epoch #182: loss=0.09997124876827002
Epoch #183: loss=0.07429422929371689
Epoch #184: loss=0.06379151844656934
Epoch #185: loss=0.06031653891299285
Epoch #186: loss=0.06758301752601184
Epoch #187: loss=0.06537264337142308
Epoch #188: loss=0.08754285788346156
Epoch #189: loss=0.09267136805197772
Epoch #190: loss=0.1079926772371811
Epoch #191: loss=0.0639452466960339
Epoch #192: loss=0.08544421153983064
Epoch #193: loss=0.10127245097914163
Epoch #194: loss=0.10986830611877582
Epoch #195: loss=0.09397547151528153
Epoch #196: loss=0.08741473523425121
Epoch #197: loss=0.06812969292057496
Epoch #198: loss=0.09611407813488268
Epoch #199: loss=0.07595923605064551
Epoch #200: loss=0.0588291615211204
Epoch #201: loss=0.06367315644142675
Epoch #202: loss=0.056126333864442275
Epoch #203: loss=0.06288509379487996
Epoch #204: loss=0.06928098159750887
Epoch #205: loss=0.05792444168279568
Epoch #206: loss=0.16351858807691172
Epoch #207: loss=0.09611477428937659
Epoch #208: loss=0.07718855653907739
Epoch #209: loss=0.06712029649711707
Epoch #210: loss=0.05688421470204405
Epoch #211: loss=0.04635458714420013
Epoch #212: loss=0.08619524005289171
Epoch #213: loss=0.09779890540841163
Epoch #214: loss=0.09238659038993657
Epoch #215: loss=0.051371781703303844
Epoch #216: loss=0.053202254295933483
Epoch #217: loss=0.07491190908659323
Epoch #218: loss=0.06113822776459012
Epoch #219: loss=0.09119859398068751
Epoch #220: loss=0.0709045757996101
Epoch #221: loss=0.07841390981247612
Epoch #222: loss=0.04864010442157879
Epoch #223: loss=0.056276003948832844
Epoch #224: loss=0.06163175336505268
Epoch #225: loss=0.06307394090382491
Epoch #226: loss=0.039625561540471574
Epoch #227: loss=0.054796588132340535
Epoch #228: loss=0.07151266401085783
Epoch #229: loss=0.06707148509574871
Epoch #230: loss=0.05826750083589086
Epoch #231: loss=0.056187309297349525
Epoch #232: loss=0.049295360952907916
Epoch #233: loss=0.050502924723368064
Epoch #234: loss=0.06236553693409352
Epoch #235: loss=0.32700008745579157
Epoch #236: loss=0.18101495836733603
Epoch #237: loss=0.11076422247524355
Epoch #238: loss=0.1160023290773525
Epoch #239: loss=0.12359325868972376
Epoch #240: loss=0.08449488870945632
Epoch #241: loss=0.13847634943165615
Epoch #242: loss=0.1230898742363149
Epoch #243: loss=0.04981076757551408
Epoch #244: loss=0.05903299030500884
Epoch #245: loss=0.046757952456234715
Epoch #246: loss=0.0770063209438733
Epoch #247: loss=0.05668305134510293
Epoch #248: loss=0.074555708150215
Epoch #249: loss=0.05023705232523236

Training time: 0:16:46.228820

Finished.
n2one setting etth1_etth2_ettm2_weather -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm2_weather_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_etth2_ettm2_weather', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.56108e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.02427e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.56108e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.38403067383980044, 'MAE': 0.4404040075603899}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_ettm2_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm2_weather_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_etth2_ettm2_weather', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.24899e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.23559401141134975, 'MAE': 0.32939980245168604}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_ettm2_exchange', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_ettm2_exchange_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=3.787403699123498
Epoch #1: loss=2.258609262379733
Epoch #2: loss=1.9880521369702888
Epoch #3: loss=1.847560698335821
Epoch #4: loss=1.715661605199178
Epoch #5: loss=1.5640431642532349
Epoch #6: loss=1.4712968269983928
Epoch #7: loss=1.3489860115629253
Epoch #8: loss=1.2907364242004626
Epoch #9: loss=1.2050253351529439
Epoch #10: loss=1.1222541603175076
Epoch #11: loss=1.1339126301534248
Epoch #12: loss=1.023889351974834
Epoch #13: loss=1.0652842359109358
Epoch #14: loss=0.9513891050309846
Epoch #15: loss=0.912422360795917
Epoch #16: loss=0.8904143084179271
Epoch #17: loss=0.8711749423633922
Epoch #18: loss=0.8666862032630227
Epoch #19: loss=0.8638281876390631
Epoch #20: loss=0.9057364644426288
Epoch #21: loss=0.8251109339974143
Epoch #22: loss=0.8441079123453661
Epoch #23: loss=0.7138910709005414
Epoch #24: loss=0.756443137472326
Epoch #25: loss=0.6550019455678535
Epoch #26: loss=0.6451650993390516
Epoch #27: loss=0.6825495226816698
Epoch #28: loss=0.6604363511909138
Epoch #29: loss=0.6812749360546921
Epoch #30: loss=0.6794371252710169
Epoch #31: loss=0.5957020539225955
Epoch #32: loss=0.6430251679637216
Epoch #33: loss=0.6100583311283228
Epoch #34: loss=0.6335655523068977
Epoch #35: loss=0.5577643631082593
Epoch #36: loss=0.5743261015776432
Epoch #37: loss=0.5727500265294855
Epoch #38: loss=0.543484114336245
Epoch #39: loss=0.5548112202774395
Epoch #40: loss=0.5856953850298217
Epoch #41: loss=0.6371779089624231
Epoch #42: loss=0.5482086692795609
Epoch #43: loss=0.6247511740886804
Epoch #44: loss=0.5333732655554106
Epoch #45: loss=0.7213330792658257
Epoch #46: loss=0.5870149451674838
Epoch #47: loss=0.499149453459364
Epoch #48: loss=0.5271055752580817
Epoch #49: loss=0.4337255656719208
Epoch #50: loss=0.5289985329815836
Epoch #51: loss=0.5054940396186077
Epoch #52: loss=0.43988902957150433
Epoch #53: loss=0.4576502072088646
Epoch #54: loss=0.47836078161543066
Epoch #55: loss=0.5493681313413562
Epoch #56: loss=0.60306588176525
Epoch #57: loss=0.4919320995157415
Epoch #58: loss=0.4468563320961865
Epoch #59: loss=0.44861415751052625
Epoch #60: loss=0.4026946985360348
Epoch #61: loss=0.42805504527958954
Epoch #62: loss=0.41013763664346753
Epoch #63: loss=0.3714237642107588
Epoch #64: loss=0.44064688276160846
Epoch #65: loss=0.48175018754872406
Epoch #66: loss=0.44464680552482605
Epoch #67: loss=0.4141095601248019
Epoch #68: loss=0.3834020910841046
Epoch #69: loss=0.3878616053949703
Epoch #70: loss=0.36767101062066626
Epoch #71: loss=0.37324368727929663
Epoch #72: loss=0.4092388780731143
Epoch #73: loss=0.3725756433877078
Epoch #74: loss=0.3631989165689006
Epoch #75: loss=0.3456179851835424
Epoch #76: loss=0.3420455866690838
Epoch #77: loss=0.37808537167130096
Epoch #78: loss=0.455273220484907
Epoch #79: loss=0.4582038580468207
Epoch #80: loss=0.4083278675874074
Epoch #81: loss=0.367419135389906
Epoch #82: loss=0.37909947787270404
Epoch #83: loss=0.28297192242109415
Epoch #84: loss=0.2917331529386116
Epoch #85: loss=0.38992010643987945
Epoch #86: loss=0.3736255132790768
Epoch #87: loss=0.35019856917135644
Epoch #88: loss=0.2855711543198788
Epoch #89: loss=0.27172367681156506
Epoch #90: loss=0.4356449797297969
Epoch #91: loss=0.40174770310069574
Epoch #92: loss=0.3237811227639516
Epoch #93: loss=0.31279467497811175
Epoch #94: loss=0.28970996222712775
Epoch #95: loss=0.2968803752552379
Epoch #96: loss=0.30486273178548523
Epoch #97: loss=0.36451797458258545
Epoch #98: loss=0.3068093844886982
Epoch #99: loss=0.3228808912363919
Epoch #100: loss=0.2643208515011903
Epoch #101: loss=0.30465484455679404
Epoch #102: loss=0.22249837738998007
Epoch #103: loss=0.27601966532793915
Epoch #104: loss=0.29096417986985407
Epoch #105: loss=0.23870776006669708
Epoch #106: loss=0.2616140043193644
Epoch #107: loss=0.21045965046593637
Epoch #108: loss=0.24437051289009326
Epoch #109: loss=0.2586707764051177
Epoch #110: loss=0.3344833498651331
Epoch #111: loss=0.27825659107078204
Epoch #112: loss=0.2630707264849634
Epoch #113: loss=0.282879039645195
Epoch #114: loss=0.3458820495641593
Epoch #115: loss=0.26337518114032166
Epoch #116: loss=0.23553915773377274
Epoch #117: loss=0.2221415282198877
Epoch #118: loss=0.2139767205173319
Epoch #119: loss=0.18164769424633545
Epoch #120: loss=0.26322916082360526
Epoch #121: loss=0.2586135778463248
Epoch #122: loss=0.25819189733628073
Epoch #123: loss=0.24507432092319836
Epoch #124: loss=0.27588985634572577
Epoch #125: loss=0.221094202588905
Epoch #126: loss=0.2439872667644963
Epoch #127: loss=0.2275614980043787
Epoch #128: loss=0.2739455598321828
Epoch #129: loss=0.2507221940340418
Epoch #130: loss=0.24340117068001718
Epoch #131: loss=0.23138043690811505
Epoch #132: loss=0.20783087972438696
Epoch #133: loss=0.1822356732957291
Epoch #134: loss=0.16243906093366217
Epoch #135: loss=0.19531192156401547
Epoch #136: loss=0.1746039932424372
Epoch #137: loss=0.1537989511182814
Epoch #138: loss=0.17935470762577924
Epoch #139: loss=0.18656879618312372
Epoch #140: loss=0.17329024975046967
Epoch #141: loss=0.1574561440131881
Epoch #142: loss=0.22535247897559946
Epoch #143: loss=0.21076237997322372
Epoch #144: loss=0.22748283229090951
Epoch #145: loss=0.25406988484389853
Epoch #146: loss=0.17525743275429262
Epoch #147: loss=0.16619109159166162
Epoch #148: loss=0.16098532791842113
Epoch #149: loss=0.11601269911184456
Epoch #150: loss=0.16411693157120186
Epoch #151: loss=0.20056976039301266
Epoch #152: loss=0.16676710997567032
Epoch #153: loss=0.18502211965846294
Epoch #154: loss=0.16054442807128935
Epoch #155: loss=0.1795651228590445
Epoch #156: loss=0.16393091439297705
Epoch #157: loss=0.20996840557817256
Epoch #158: loss=0.1963671360051993
Epoch #159: loss=0.2084074801567829
Epoch #160: loss=0.21850823046583118
Epoch #161: loss=0.21681420403448018
Epoch #162: loss=0.17164564245578015
Epoch #163: loss=0.19471686920433334
Epoch #164: loss=0.15062078607804846
Epoch #165: loss=0.1531051304755789
Epoch #166: loss=0.16491797893787874
Epoch #167: loss=0.19008052890950983
Epoch #168: loss=0.16562894505984854
Epoch #169: loss=0.18807047537781976
Epoch #170: loss=0.1575877760170084
Epoch #171: loss=0.16068064297238985
Epoch #172: loss=0.1473517661744898
Epoch #173: loss=0.1543900179817821
Epoch #174: loss=0.1430645464270404
Epoch #175: loss=0.12531045000209953
Epoch #176: loss=0.12180571393533186
Epoch #177: loss=0.12304252916664789
Epoch #178: loss=0.10806120401530554
Epoch #179: loss=0.10488342403462439
Epoch #180: loss=0.1144414319459236
Epoch #181: loss=0.18361774628812616
Epoch #182: loss=0.16887927743973155
Epoch #183: loss=0.12698969640063518
Epoch #184: loss=0.20278542398503333
Epoch #185: loss=0.1728450461770549
Epoch #186: loss=0.1573712123614369
Epoch #187: loss=0.12495163241119096
Epoch #188: loss=0.1425384215333245
Epoch #189: loss=0.20194666742375403
Epoch #190: loss=0.12627483588276486
Epoch #191: loss=0.12526983801614155
Epoch #192: loss=0.14395275779745795
Epoch #193: loss=0.14526726418372357
Epoch #194: loss=0.16202793529990947
Epoch #195: loss=0.13375144147060133
Epoch #196: loss=0.1674538426326983
Epoch #197: loss=0.13153653625737538
Epoch #198: loss=0.25355505841699516
Epoch #199: loss=0.15626763394384674
Epoch #200: loss=0.14830687653386232
Epoch #201: loss=0.11093369769779118
Epoch #202: loss=0.1402935324180307
Epoch #203: loss=0.13133484164647985
Epoch #204: loss=0.12724943148593107
Epoch #205: loss=0.18222236238194234
Epoch #206: loss=0.16662211512977426
Epoch #207: loss=0.17763320683981432
Epoch #208: loss=0.14892186709877217
Epoch #209: loss=0.1786910125026197
Epoch #210: loss=0.20791443663113046
Epoch #211: loss=0.22326154826265393
Epoch #212: loss=0.15499778893409352
Epoch #213: loss=0.14184610602079015
Epoch #214: loss=0.14814348462404628
Epoch #215: loss=0.1313273651581822
Epoch #216: loss=0.1072154093646642
Epoch #217: loss=0.10187866933869594
Epoch #218: loss=0.16104751622134988
Epoch #219: loss=0.13238852979107338
Epoch #220: loss=0.14245886671723743
Epoch #221: loss=0.12793733032815385
Epoch #222: loss=0.12198909033428539
Epoch #223: loss=0.12270264818587086
Epoch #224: loss=0.10033803907307712
Epoch #225: loss=0.1104490938173099
Epoch #226: loss=0.10026151765928124
Epoch #227: loss=0.08403893142487064
Epoch #228: loss=0.18098510113177876
Epoch #229: loss=0.1463098909818765
Epoch #230: loss=0.09467099257039302
Epoch #231: loss=0.10224806968912933
Epoch #232: loss=0.10357149374304396
Epoch #233: loss=0.10733653390497873
Epoch #234: loss=0.09675623730502346
Epoch #235: loss=0.1667023805732077
Epoch #236: loss=0.132102875434088
Epoch #237: loss=0.09887066342388139
Epoch #238: loss=0.1568135443058881
Epoch #239: loss=0.15696039084683766
Epoch #240: loss=0.13033789757526282
Epoch #241: loss=0.13083896932728362
Epoch #242: loss=0.14007046762289424
Epoch #243: loss=0.1381855235632622
Epoch #244: loss=0.10059078444134105
Epoch #245: loss=0.11289591223678806
Epoch #246: loss=0.0876725942573764
Epoch #247: loss=0.09627595442262563
Epoch #248: loss=0.10034180686555126
Epoch #249: loss=0.10127881598291975

Training time: 0:08:50.808656

Finished.
n2one setting etth1_etth2_ettm2_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm2_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_etth2_ettm2_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.50453e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.01758e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.50453e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.38975329315419316, 'MAE': 0.4411400937784456}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_ettm2_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm2_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_etth2_ettm2_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.49743e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.89235e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.89235e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.46832238206811144, 'MAE': 0.5005372587174862}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_electricity_traffic', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_electricity_traffic_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.7884842076944927
Epoch #1: loss=0.28520160943344425
Epoch #2: loss=0.19004767486450566
Epoch #3: loss=0.14103043841551322
Epoch #4: loss=0.11026691235508536
Epoch #5: loss=0.09469891087064145
Epoch #6: loss=0.06899476875516034
Epoch #7: loss=0.05859015002899625
Epoch #8: loss=0.0535271672163168
Epoch #9: loss=0.050098784507929955
Epoch #10: loss=0.036976109573550665
Epoch #11: loss=0.04208041797625484
Epoch #12: loss=0.043551873058682106
Epoch #13: loss=0.03615999525444428
Epoch #14: loss=0.0382886255323753
Epoch #15: loss=0.03277276552007234
Epoch #16: loss=0.028577623190844562
Epoch #17: loss=0.029482364265031105
Epoch #18: loss=0.027453563548780126
Epoch #19: loss=0.0215071062017629
Epoch #20: loss=0.030567529800160476
Epoch #21: loss=0.024722715698382153
Epoch #22: loss=0.02291744782910515
Epoch #23: loss=0.02469051558050345
Epoch #24: loss=0.02460254017206659
Epoch #25: loss=0.023974011207055636
Epoch #26: loss=0.0282193276586821
Epoch #27: loss=0.023486595087672632
Epoch #28: loss=0.034202563764250064
Epoch #29: loss=0.023068055224053658
Epoch #30: loss=0.02557320620883303
Epoch #31: loss=0.020830872381363164
Epoch #32: loss=0.021732149016489052
Epoch #33: loss=0.015209876464111085
Epoch #34: loss=0.020545140245150147
Epoch #35: loss=0.024303930445172362
Epoch #36: loss=0.01695049353981229
Epoch #37: loss=0.01953042411921723
Epoch #38: loss=0.02374186545849483
Epoch #39: loss=0.017765319197665847
Epoch #40: loss=0.014410529613470365
Epoch #41: loss=0.015569654399342952
Epoch #42: loss=0.020249605154616285
Epoch #43: loss=0.016743061756747273
Epoch #44: loss=0.01694976924659405
Epoch #45: loss=0.01703046188558862
Epoch #46: loss=0.02757621415061744
Epoch #47: loss=0.01345591697625221
Epoch #48: loss=0.013579545516897896
Epoch #49: loss=0.016059302114762922
Epoch #50: loss=0.020775629019058554
Epoch #51: loss=0.017238024911392362
Epoch #52: loss=0.014693239821672926
Epoch #53: loss=0.01925256233604986
Epoch #54: loss=0.0163308036611466
Epoch #55: loss=0.016636304807733104
Epoch #56: loss=0.012755256084337793
Epoch #57: loss=0.01702063437441847
Epoch #58: loss=0.020162404403223717
Epoch #59: loss=0.0196153287318809
Epoch #60: loss=0.014852243579460973
Epoch #61: loss=0.013059815940761872
Epoch #62: loss=0.016446714553827967
Epoch #63: loss=0.013241897219848028
Epoch #64: loss=0.01887468480055338
Epoch #65: loss=0.011965678241876585
Epoch #66: loss=0.013656499674872462
Epoch #67: loss=0.014173681770943287
Epoch #68: loss=0.01490851872546249
Epoch #69: loss=0.01190375891150045
Epoch #70: loss=0.014346992141639536
Epoch #71: loss=0.015426595113872345
Epoch #72: loss=0.015570899425565601
Epoch #73: loss=0.013741886198924079
Epoch #74: loss=0.012274542030555086
Epoch #75: loss=0.017564443890890864
Epoch #76: loss=0.015295897601124672
Epoch #77: loss=0.01132164192078886
Epoch #78: loss=0.017455557453516696
Epoch #79: loss=0.010361290130801786
Epoch #80: loss=0.016007600449278108
Epoch #81: loss=0.013237177521456131
Epoch #82: loss=0.013421399554260773
Epoch #83: loss=0.010538502982169379
Epoch #84: loss=0.010612924399807289
Epoch #85: loss=0.013518573224702858
Epoch #86: loss=0.012959062367063614
Epoch #87: loss=0.013218159077680492
Epoch #88: loss=0.017380363172610307
Epoch #89: loss=0.012840235258389184
Epoch #90: loss=0.009443934463135607
Epoch #91: loss=0.013233250385464064
Epoch #92: loss=0.010269768391422688
Epoch #93: loss=0.012240771673103902
Epoch #94: loss=0.010484083019977563
Epoch #95: loss=0.01329283746258074
Epoch #96: loss=0.011782481258174089
Epoch #97: loss=0.013300989642544298
Epoch #98: loss=0.009548775891893221
Epoch #99: loss=0.013494619517173788
Epoch #100: loss=0.010361516199193533
Epoch #101: loss=0.010945783451032932
Epoch #102: loss=0.013775995947278019
Epoch #103: loss=0.013442971129423597
Epoch #104: loss=0.010387204295789097
Epoch #105: loss=0.008819065536346591
Epoch #106: loss=0.014277107599417001
Epoch #107: loss=0.012063724018980374
Epoch #108: loss=0.010175064946374539
Epoch #109: loss=0.011975645944228612
Epoch #110: loss=0.012376454349167827
Epoch #111: loss=0.010167807929421372
Epoch #112: loss=0.010543355154936667
Epoch #113: loss=0.015873623149408808
Epoch #114: loss=0.008059862616606937
Epoch #115: loss=0.010833792402055006
Epoch #116: loss=0.010607179654817585
Epoch #117: loss=0.010551175759032423
Epoch #118: loss=0.011401471061278609
Epoch #119: loss=0.008659600770458402
Epoch #120: loss=0.013722747795225636
Epoch #121: loss=0.011294059027444436
Epoch #122: loss=0.010149038624330232
Epoch #123: loss=0.010869784391724015
Epoch #124: loss=0.008591975876557124
Epoch #125: loss=0.016417831550326015
Epoch #126: loss=0.010342214049159488
Epoch #127: loss=0.009959615884730382
Epoch #128: loss=0.019072768352735643
Epoch #129: loss=0.007506225421915216
Epoch #130: loss=0.013725265668878318
Epoch #131: loss=0.012491524288418751
Epoch #132: loss=0.009535423277116682
Epoch #133: loss=0.009960407617298358
Epoch #134: loss=0.00944846014764968
Epoch #135: loss=0.010359313769255116
Epoch #136: loss=0.009462801603634033
Epoch #137: loss=0.010005620452268544
Epoch #138: loss=0.009394676009061378
Epoch #139: loss=0.011620835542467107
Epoch #140: loss=0.009031720676876794
Epoch #141: loss=0.01056424230965173
Epoch #142: loss=0.011900378951109706
Epoch #143: loss=0.014835702418405606
Epoch #144: loss=0.009685333251778842
Epoch #145: loss=0.01144255338162386
Epoch #146: loss=0.009314419850351098
Epoch #147: loss=0.009342120380922341
Epoch #148: loss=0.017220090554276604
Epoch #149: loss=0.0079290647042331
Epoch #150: loss=0.010346654817465275
Epoch #151: loss=0.016301379045887805
Epoch #152: loss=0.009296790194545254
Epoch #153: loss=0.011135819987304927
Epoch #154: loss=0.007667239382415668
Epoch #155: loss=0.008093579357086532
Epoch #156: loss=0.011412076330035707
Epoch #157: loss=0.0141782896680403
Epoch #158: loss=0.010791406608649601
Epoch #159: loss=0.01148786532111799
Epoch #160: loss=0.007771846543245349
Epoch #161: loss=0.012288109362955962
Epoch #162: loss=0.00776119723421702
Epoch #163: loss=0.010974317982136815
Epoch #164: loss=0.011626552145923416
Epoch #165: loss=0.01058708731216941
Epoch #166: loss=0.008528912833184467
Epoch #167: loss=0.011969872416030787
Epoch #168: loss=0.00766235406265056
Epoch #169: loss=0.013621250037457903
Epoch #170: loss=0.0138761234466864
Epoch #171: loss=0.009479923413417688
Epoch #172: loss=0.011815534138854798
Epoch #173: loss=0.01002481485494623
Epoch #174: loss=0.008232563697303134
Epoch #175: loss=0.00781818538044849
Epoch #176: loss=0.011183157501585758
Epoch #177: loss=0.01321844781058239
Epoch #178: loss=0.00692956646713673
Epoch #179: loss=0.0075290001808883695
Epoch #180: loss=0.007589799212221326
Epoch #181: loss=0.012191776353799727
Epoch #182: loss=0.01127613301165182
Epoch #183: loss=0.008596556966293243
Epoch #184: loss=0.008824300632709283
Epoch #185: loss=0.011105867966459756
Epoch #186: loss=0.008202687402875062
Epoch #187: loss=0.008707226841106938
Epoch #188: loss=0.009013667341551523
Epoch #189: loss=0.011294658224904587
Epoch #190: loss=0.010766828627832273
Epoch #191: loss=0.008534813371130568
Epoch #192: loss=0.011559866327667822
Epoch #193: loss=0.008284379987398383
Epoch #194: loss=0.009592247213655772
Epoch #195: loss=0.00951537471903572
Epoch #196: loss=0.00908401731421972
Epoch #197: loss=0.02775134229125409
Epoch #198: loss=0.009160848342139179
Epoch #199: loss=0.007412279949088969
Epoch #200: loss=0.014959150925959454
Epoch #201: loss=0.007505270466398107
Epoch #202: loss=0.010243097068525038
Epoch #203: loss=0.010404494224986063
Epoch #204: loss=0.009272627480450237
Epoch #205: loss=0.010372533443028499
Epoch #206: loss=0.0083748967593685
Epoch #207: loss=0.00873635967511113
Epoch #208: loss=0.010935152573555255
Epoch #209: loss=0.010216456793044221
Epoch #210: loss=0.008685103848117206
Epoch #211: loss=0.010602173292831665
Epoch #212: loss=0.008934148276225608
Epoch #213: loss=0.007410387718011746
Epoch #214: loss=0.008310232260853341
Epoch #215: loss=0.008229104423747746
Epoch #216: loss=0.009506549863563928
Epoch #217: loss=0.009569847080692686
Epoch #218: loss=0.008587603181654888
Epoch #219: loss=0.01010437210010903
Epoch #220: loss=0.010649017098127031
Epoch #221: loss=0.0072853017392621395
Epoch #222: loss=0.007934010127508877
Epoch #223: loss=0.007931249526986253
Epoch #224: loss=0.009949997303649606
Epoch #225: loss=0.010521051159456833
Epoch #226: loss=0.009849715882948943
Epoch #227: loss=0.007331974951063307
Epoch #228: loss=0.012839036788277906
Epoch #229: loss=0.00997797708395142
Epoch #230: loss=0.008946663384862072
Epoch #231: loss=0.009150379507571273
Epoch #232: loss=0.007506778609975925
Epoch #233: loss=0.008873916171186151
Epoch #234: loss=0.008253655920015533
Epoch #235: loss=0.009707812909414713
Epoch #236: loss=0.00860395627022624
Epoch #237: loss=0.011121087581219397
Epoch #238: loss=0.007397405382851391
Epoch #239: loss=0.008899991274214139
Epoch #240: loss=0.009105658003208523
Epoch #241: loss=0.006214054665768606
Epoch #242: loss=0.007347845350983576
Epoch #243: loss=0.010374416839420834
Epoch #244: loss=0.007064627258637548
Epoch #245: loss=0.011089068846127502
Epoch #246: loss=0.01287839649243295
Epoch #247: loss=0.008420901005425738
Epoch #248: loss=0.006227320860464958
Epoch #249: loss=0.026219222923150303

Training time: 5:00:59.291686

Finished.
n2one setting etth1_etth2_electricity_traffic -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_electricity_traffic_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_etth2_electricity_traffic', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.05876e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.99898e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.47948e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.05876e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.6462555511973508, 'MAE': 0.6145148644681575}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_electricity_traffic -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_electricity_traffic_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_etth2_electricity_traffic', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.61509e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3533616517691122, 'MAE': 0.39317679869716565}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_electricity_weather', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_electricity_weather_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.61468718784998
Epoch #1: loss=0.7668675945406145
Epoch #2: loss=0.5339299506015064
Epoch #3: loss=0.4464220674579494
Epoch #4: loss=0.35585808159571936
Epoch #5: loss=0.30945467610438443
Epoch #6: loss=0.3059616775930423
Epoch #7: loss=0.2580715908444489
Epoch #8: loss=0.24538951845958293
Epoch #9: loss=0.21549222343846372
Epoch #10: loss=0.18550482605921925
Epoch #11: loss=0.18023206704293593
Epoch #12: loss=0.15634889912035657
Epoch #13: loss=0.14091527561071507
Epoch #14: loss=0.15013892083864794
Epoch #15: loss=0.14029198738429025
Epoch #16: loss=0.1259729789048846
Epoch #17: loss=0.11373088514520026
Epoch #18: loss=0.10797292731929353
Epoch #19: loss=0.08432952284689095
Epoch #20: loss=0.10712079666916105
Epoch #21: loss=0.08907475852126312
Epoch #22: loss=0.07610286758319988
Epoch #23: loss=0.07061862517174054
Epoch #24: loss=0.06327947367168447
Epoch #25: loss=0.08509959343696978
Epoch #26: loss=0.06952745972041278
Epoch #27: loss=0.07007869493236915
Epoch #28: loss=0.06740402005912112
Epoch #29: loss=0.07085391814198727
Epoch #30: loss=0.0658246341839928
Epoch #31: loss=0.050980562164894515
Epoch #32: loss=0.049023536400265806
Epoch #33: loss=0.04801810726554358
Epoch #34: loss=0.057039568280682504
Epoch #35: loss=0.05038528567324509
Epoch #36: loss=0.05672631887822229
Epoch #37: loss=0.08575273067767827
Epoch #38: loss=0.06137040762973748
Epoch #39: loss=0.04859319670058766
Epoch #40: loss=0.0438648622955126
Epoch #41: loss=0.05083611084230843
Epoch #42: loss=0.05647165254287298
Epoch #43: loss=0.03928344021099839
Epoch #44: loss=0.03499539439931481
Epoch #45: loss=0.03982876171422426
Epoch #46: loss=0.04225113651672652
Epoch #47: loss=0.03578726629148704
Epoch #48: loss=0.04827632996578729
Epoch #49: loss=0.04697260797833843
Epoch #50: loss=0.03132633218435968
Epoch #51: loss=0.02961932234091999
Epoch #52: loss=0.031226840543552944
Epoch #53: loss=0.03476702201456203
Epoch #54: loss=0.035690491993903825
Epoch #55: loss=0.03974131078148452
Epoch #56: loss=0.03606446717035056
Epoch #57: loss=0.03244373525062014
Epoch #58: loss=0.02632463292039446
Epoch #59: loss=0.026181677206409088
Epoch #60: loss=0.030306028736525645
Epoch #61: loss=0.03170600657446769
Epoch #62: loss=0.022623585285863987
Epoch #63: loss=0.025321085094358164
Epoch #64: loss=0.028398323392171743
Epoch #65: loss=0.039765165755950904
Epoch #66: loss=0.03577311351554149
Epoch #67: loss=0.04286873567890675
Epoch #68: loss=0.03304458530445601
Epoch #69: loss=0.03881214796552574
Epoch #70: loss=0.03175227482057592
Epoch #71: loss=0.025889338817772483
Epoch #72: loss=0.02840908186689504
Epoch #73: loss=0.027038148746224653
Epoch #74: loss=0.022373640549419465
Epoch #75: loss=0.020808027484170433
Epoch #76: loss=0.024921916960867593
Epoch #77: loss=0.03228038975887047
Epoch #78: loss=0.024924737703792978
Epoch #79: loss=0.021560542027780738
Epoch #80: loss=0.014438063084596763
Epoch #81: loss=0.023434896774911205
Epoch #82: loss=0.0388208415994222
Epoch #83: loss=0.020841853657977298
Epoch #84: loss=0.020438994891610038
Epoch #85: loss=0.02566268923144189
Epoch #86: loss=0.02906322922722702
Epoch #87: loss=0.019755219777857682
Epoch #88: loss=0.016356905096905808
Epoch #89: loss=0.018713127015967314
Epoch #90: loss=0.02695784021112191
Epoch #91: loss=0.014592677995580613
Epoch #92: loss=0.030863941474746748
Epoch #93: loss=0.019698829300620353
Epoch #94: loss=0.016383272855300095
Epoch #95: loss=0.02483863905578506
Epoch #96: loss=0.020327618651006917
Epoch #97: loss=0.027579365811217834
Epoch #98: loss=0.02501323122684031
Epoch #99: loss=0.014749987754865015
Epoch #100: loss=0.017707393064493846
Epoch #101: loss=0.022181009596737408
Epoch #102: loss=0.02419596833952153
Epoch #103: loss=0.023411279231428564
Epoch #104: loss=0.031638752118783676
Epoch #105: loss=0.02077792043419725
Epoch #106: loss=0.020696970192364668
Epoch #107: loss=0.019027906750719685
Epoch #108: loss=0.016318623545396444
Epoch #109: loss=0.022381472940265826
Epoch #110: loss=0.019516176473990423
Epoch #111: loss=0.017977562140437345
Epoch #112: loss=0.021669356600340157
Epoch #113: loss=0.014811405766522512
Epoch #114: loss=0.019374879412617473
Epoch #115: loss=0.01835019614159225
Epoch #116: loss=0.015057354786567431
Epoch #117: loss=0.03840396260143544
Epoch #118: loss=0.02311721057637525
Epoch #119: loss=0.025556373291415448
Epoch #120: loss=0.014845597964209709
Epoch #121: loss=0.016200976796806828
Epoch #122: loss=0.027789139696732267
Epoch #123: loss=0.015846788197616504
Epoch #124: loss=0.014152136814317451
Epoch #125: loss=0.010879891805564907
Epoch #126: loss=0.017462583923540814
Epoch #127: loss=0.017309855925624833
Epoch #128: loss=0.021214476112812276
Epoch #129: loss=0.020359342264938955
Epoch #130: loss=0.016657173633252958
Epoch #131: loss=0.026758898317251468
Epoch #132: loss=0.013366039332203629
Epoch #133: loss=0.02983553229861472
Epoch #134: loss=0.030250309519063413
Epoch #135: loss=0.017839117425524853
Epoch #136: loss=0.016246503773674245
Epoch #137: loss=0.019985550952303918
Epoch #138: loss=0.019910089974904333
Epoch #139: loss=0.014636530831357505
Epoch #140: loss=0.034471872861502266
Epoch #141: loss=0.017334894411790848
Epoch #142: loss=0.011941830777210683
Epoch #143: loss=0.012907889451853508
Epoch #144: loss=0.019634869247784584
Epoch #145: loss=0.012944204188429252
Epoch #146: loss=0.021449312840690293
Epoch #147: loss=0.01440841418212419
Epoch #148: loss=0.015751330573930872
Epoch #149: loss=0.015663945496145512
Epoch #150: loss=0.022087681612226896
Epoch #151: loss=0.014161595255762102
Epoch #152: loss=0.013676784369804951
Epoch #153: loss=0.015670898221942682
Epoch #154: loss=0.014126539336603877
Epoch #155: loss=0.014674836982859407
Epoch #156: loss=0.012713315983759523
Epoch #157: loss=0.013008795796804532
Epoch #158: loss=0.014562673525242367
Epoch #159: loss=0.0226386490586237
Epoch #160: loss=0.012910695813133167
Epoch #161: loss=0.01591201380125461
Epoch #162: loss=0.010325541813716607
Epoch #163: loss=0.017372359485730498
Epoch #164: loss=0.016119937721860447
Epoch #165: loss=0.009257024581353194
Epoch #166: loss=0.01244701913851726
Epoch #167: loss=0.018008848519704287
Epoch #168: loss=0.03989352595950786
Epoch #169: loss=0.02371824475216816
Epoch #170: loss=0.014123852804098072
Epoch #171: loss=0.011930661724310837
Epoch #172: loss=0.01381829565633127
Epoch #173: loss=0.015389532678863137
Epoch #174: loss=0.012514749896606827
Epoch #175: loss=0.014782704593364789
Epoch #176: loss=0.015689303356943875
Epoch #177: loss=0.014987441204753356
Epoch #178: loss=0.014777261777516516
Epoch #179: loss=0.012531443607059522
Epoch #180: loss=0.017250544785159458
Epoch #181: loss=0.013098960113115067
Epoch #182: loss=0.01731429229933224
Epoch #183: loss=0.022352813523929628
Epoch #184: loss=0.010218962941704436
Epoch #185: loss=0.012462125157502382
Epoch #186: loss=0.0184121160726695
Epoch #187: loss=0.027078546672898867
Epoch #188: loss=0.015905582835708185
Epoch #189: loss=0.019575564278218084
Epoch #190: loss=0.012886963968185857
Epoch #191: loss=0.017733361032840452
Epoch #192: loss=0.013740697980424972
Epoch #193: loss=0.012704479913217586
Epoch #194: loss=0.012470479761482503
Epoch #195: loss=0.021253292360942852
Epoch #196: loss=0.010788139912509102
Epoch #197: loss=0.017960051745705183
Epoch #198: loss=0.012884324142974453
Epoch #199: loss=0.016808053514152026
Epoch #200: loss=0.013288261890966043
Epoch #201: loss=0.011023210362647983
Epoch #202: loss=0.007342112950891658
Epoch #203: loss=0.012580799632283299
Epoch #204: loss=0.018166814884944843
Epoch #205: loss=0.013003569421789886
Epoch #206: loss=0.01964842449774362
Epoch #207: loss=0.012344505287509494
Epoch #208: loss=0.016014715206375284
Epoch #209: loss=0.009631364680168805
Epoch #210: loss=0.011561007023588405
Epoch #211: loss=0.01533449585069038
Epoch #212: loss=0.01400597394238306
Epoch #213: loss=0.010011833321831674
Epoch #214: loss=0.012802106748338933
Epoch #215: loss=0.01956875537121617
Epoch #216: loss=0.024613087575681446
Epoch #217: loss=0.01123940385587854
Epoch #218: loss=0.010256936673930822
Epoch #219: loss=0.011497623289559923
Epoch #220: loss=0.010194506987489482
Epoch #221: loss=0.014759005418353987
Epoch #222: loss=0.013695524416127374
Epoch #223: loss=0.0192222461801595
Epoch #224: loss=0.012378941129001729
Epoch #225: loss=0.012844885357380187
Epoch #226: loss=0.012027407711203445
Epoch #227: loss=0.016286348059310365
Epoch #228: loss=0.010005534241502264
Epoch #229: loss=0.013004144941733305
Epoch #230: loss=0.011565541635784049
Epoch #231: loss=0.020211091359327173
Epoch #232: loss=0.012840545355081764
Epoch #233: loss=0.012248052647314744
Epoch #234: loss=0.01252747517005912
Epoch #235: loss=0.014795459013053673
Epoch #236: loss=0.016234152521367295
Epoch #237: loss=0.010315312802649058
Epoch #238: loss=0.008705095554717462
Epoch #239: loss=0.011175949366044427
Epoch #240: loss=0.012086090686282148
Epoch #241: loss=0.010938853753918983
Epoch #242: loss=0.007915885249279192
Epoch #243: loss=0.009138319688836896
Epoch #244: loss=0.009852529163107951
Epoch #245: loss=0.011323993307505437
Epoch #246: loss=0.01259012999389723
Epoch #247: loss=0.019356300897794387
Epoch #248: loss=0.012367536899294457
Epoch #249: loss=0.018211934215987716

Training time: 1:41:20.758206

Finished.
n2one setting etth1_etth2_electricity_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_electricity_weather_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_etth2_electricity_weather', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
Evaluation result: {'MSE': 0.3597332185140312, 'MAE': 0.40663091759654413}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_electricity_exchange', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_electricity_exchange_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.5724827379596478
Epoch #1: loss=0.6425242715083476
Epoch #2: loss=0.4667225796349195
Epoch #3: loss=0.3575317644603746
Epoch #4: loss=0.3197058048262193
Epoch #5: loss=0.2789263985290819
Epoch #6: loss=0.24046442714185826
Epoch #7: loss=0.2030901091482827
Epoch #8: loss=0.19914109064347543
Epoch #9: loss=0.173735896391528
Epoch #10: loss=0.1657706595761783
Epoch #11: loss=0.16261040976504543
Epoch #12: loss=0.15682482958361288
Epoch #13: loss=0.12627179532939073
Epoch #14: loss=0.11456837835816705
Epoch #15: loss=0.12797643107962156
Epoch #16: loss=0.09869051525374717
Epoch #17: loss=0.10628896583219224
Epoch #18: loss=0.08571318826982996
Epoch #19: loss=0.07867441701624033
Epoch #20: loss=0.07848199272837826
Epoch #21: loss=0.07382130022255742
Epoch #22: loss=0.07300270859928633
Epoch #23: loss=0.06802430248659093
Epoch #24: loss=0.06592752105140999
Epoch #25: loss=0.07078955584523368
Epoch #26: loss=0.07018061724434398
Epoch #27: loss=0.062238804587372104
Epoch #28: loss=0.05114906777711938
Epoch #29: loss=0.059388380158290746
Epoch #30: loss=0.07475951584408999
Epoch #31: loss=0.058064822673678136
Epoch #32: loss=0.08508152863738445
Epoch #33: loss=0.04885729046744829
Epoch #34: loss=0.04427284810015981
Epoch #35: loss=0.05176377734617376
Epoch #36: loss=0.05217066897912923
Epoch #37: loss=0.05658134269533521
Epoch #38: loss=0.055848594349008
Epoch #39: loss=0.048974729940001974
Epoch #40: loss=0.0445754547316972
Epoch #41: loss=0.03790421347655139
Epoch #42: loss=0.03805236140084141
Epoch #43: loss=0.044995186354899804
Epoch #44: loss=0.044865765885460804
Epoch #45: loss=0.0448970408599726
Epoch #46: loss=0.03635025493333621
Epoch #47: loss=0.038882964743103064
Epoch #48: loss=0.03450348176015948
Epoch #49: loss=0.04213304707913527
Epoch #50: loss=0.038761803894249436
Epoch #51: loss=0.039034026359620645
Epoch #52: loss=0.0632221800419054
Epoch #53: loss=0.039331452813102664
Epoch #54: loss=0.034288362289694715
Epoch #55: loss=0.037994688463671565
Epoch #56: loss=0.03108917402087252
Epoch #57: loss=0.03569238353656393
Epoch #58: loss=0.028436120250941128
Epoch #59: loss=0.02865012468357432
Epoch #60: loss=0.04993733253639528
Epoch #61: loss=0.047672646859410944
Epoch #62: loss=0.03639493479377131
Epoch #63: loss=0.0401377922354019
Epoch #64: loss=0.041530979046484034
Epoch #65: loss=0.03310711095591535
Epoch #66: loss=0.036786020605461045
Epoch #67: loss=0.02514203929148191
Epoch #68: loss=0.03032991983391529
Epoch #69: loss=0.024796214905016278
Epoch #70: loss=0.03701924541544267
Epoch #71: loss=0.0322394279831662
Epoch #72: loss=0.03143840744540247
Epoch #73: loss=0.02947462022283492
Epoch #74: loss=0.028201055924785553
Epoch #75: loss=0.035335707226048604
Epoch #76: loss=0.030924266936670195
Epoch #77: loss=0.03055565867881201
Epoch #78: loss=0.037772762101434126
Epoch #79: loss=0.030669112210216287
Epoch #80: loss=0.044599462224512686
Epoch #81: loss=0.03357331864515444
Epoch #82: loss=0.023218770668252696
Epoch #83: loss=0.024575617040491205
Epoch #84: loss=0.03152331670830379
Epoch #85: loss=0.029314175814610117
Epoch #86: loss=0.024330381610337102
Epoch #87: loss=0.0277509695589651
Epoch #88: loss=0.033256320025209805
Epoch #89: loss=0.029693653794146704
Epoch #90: loss=0.026172790786491724
Epoch #91: loss=0.022372501152879816
Epoch #92: loss=0.03909413275036027
Epoch #93: loss=0.029855034585957993
Epoch #94: loss=0.017657555173573414
Epoch #95: loss=0.01826096718021704
Epoch #96: loss=0.021805133236471683
Epoch #97: loss=0.023736668672241574
Epoch #98: loss=0.016649786581803907
Epoch #99: loss=0.027106126429276872
Epoch #100: loss=0.02675174207663511
Epoch #101: loss=0.02210048564221661
Epoch #102: loss=0.027548266089393734
Epoch #103: loss=0.03330890907201395
Epoch #104: loss=0.02322874508381335
Epoch #105: loss=0.02810051485318446
Epoch #106: loss=0.0243237415819399
Epoch #107: loss=0.02779018263496817
Epoch #108: loss=0.039732246441120396
Epoch #109: loss=0.03239129098290414
Epoch #110: loss=0.03795490237719952
Epoch #111: loss=0.01794924164640937
Epoch #112: loss=0.02219599656965692
Epoch #113: loss=0.02081989879793224
Epoch #114: loss=0.017396101545652444
Epoch #115: loss=0.018858856113923513
Epoch #116: loss=0.0228478684247561
Epoch #117: loss=0.028049606881470967
Epoch #118: loss=0.030857210006475254
Epoch #119: loss=0.028395079492059137
Epoch #120: loss=0.03167176563238437
Epoch #121: loss=0.03333692371613772
Epoch #122: loss=0.024093370410086284
Epoch #123: loss=0.01999631722730248
Epoch #124: loss=0.02408205126086386
Epoch #125: loss=0.01915038494412236
Epoch #126: loss=0.022337402469775863
Epoch #127: loss=0.03294226161676728
Epoch #128: loss=0.02363667609346569
Epoch #129: loss=0.017231564956096766
Epoch #130: loss=0.017956829145849403
Epoch #131: loss=0.0187566833762023
Epoch #132: loss=0.021330040558811506
Epoch #133: loss=0.02377001391319862
Epoch #134: loss=0.015443574187295571
Epoch #135: loss=0.017871907633884045
Epoch #136: loss=0.01643523804432069
Epoch #137: loss=0.019885603349510603
Epoch #138: loss=0.018534648121516534
Epoch #139: loss=0.018972536220854017
Epoch #140: loss=0.01955342007686897
Epoch #141: loss=0.01973822823866154
Epoch #142: loss=0.035827701870432126
Epoch #143: loss=0.03227849996447802
Epoch #144: loss=0.022500507151721583
Epoch #145: loss=0.017895760099504023
Epoch #146: loss=0.015313966081134226
Epoch #147: loss=0.015136695688735671
Epoch #148: loss=0.022801792162365983
Epoch #149: loss=0.015511627757376054
Epoch #150: loss=0.01272718673451456
Epoch #151: loss=0.013926004823100408
Epoch #152: loss=0.02947600621597043
Epoch #153: loss=0.020131426551800124
Epoch #154: loss=0.020249409779279054
Epoch #155: loss=0.023124888477373172
Epoch #156: loss=0.020742611837900535
Epoch #157: loss=0.017668502741464774
Epoch #158: loss=0.017350711240521403
Epoch #159: loss=0.01267280510829357
Epoch #160: loss=0.02726977890487706
Epoch #161: loss=0.010267311022223216
Epoch #162: loss=0.014665589222559602
Epoch #163: loss=0.034905454915854534
Epoch #164: loss=0.0240020738672275
Epoch #165: loss=0.01483939071090854
Epoch #166: loss=0.01481120763867537
Epoch #167: loss=0.013200495794446699
Epoch #168: loss=0.01527443717969663
Epoch #169: loss=0.01574540090931813
Epoch #170: loss=0.014026730011981632
Epoch #171: loss=0.01532333284129766
Epoch #172: loss=0.021513897872159297
Epoch #173: loss=0.030734869056352775
Epoch #174: loss=0.017338650241703252
Epoch #175: loss=0.02649359469391601
Epoch #176: loss=0.020971169643838546
Epoch #177: loss=0.012648573855386841
Epoch #178: loss=0.015068618179863704
Epoch #179: loss=0.011203521062313164
Epoch #180: loss=0.019482905752128722
Epoch #181: loss=0.014266703735172217
Epoch #182: loss=0.016316321019338494
Epoch #183: loss=0.015982875692944584
Epoch #184: loss=0.012158091264028842
Epoch #185: loss=0.00906624483447264
Epoch #186: loss=0.014226613354916024
Epoch #187: loss=0.009865730835271473
Epoch #188: loss=0.015494640970211639
Epoch #189: loss=0.016744174648336958
Epoch #190: loss=0.026838150169325684
Epoch #191: loss=0.024480264970582012
Epoch #192: loss=0.01328383584321156
Epoch #193: loss=0.02292158365732944
Epoch #194: loss=0.021395458339723016
Epoch #195: loss=0.022863565329984972
Epoch #196: loss=0.018959565177246243
Epoch #197: loss=0.017935934568023577
Epoch #198: loss=0.016109068831496764
Epoch #199: loss=0.013695853475193458
Epoch #200: loss=0.014973564637446798
Epoch #201: loss=0.016147007263243827
Epoch #202: loss=0.014836611875224961
Epoch #203: loss=0.019803344588570634
Epoch #204: loss=0.01977169638484005
Epoch #205: loss=0.024929517513866
Epoch #206: loss=0.017391735234239435
Epoch #207: loss=0.014870904044688708
Epoch #208: loss=0.013899441631887591
Epoch #209: loss=0.021810533239916184
Epoch #210: loss=0.014660645684440492
Epoch #211: loss=0.017556203215460378
Epoch #212: loss=0.020159705092742872
Epoch #213: loss=0.014137946023590831
Epoch #214: loss=0.009996362083113641
Epoch #215: loss=0.010551354223940353
Epoch #216: loss=0.008677641173849105
Epoch #217: loss=0.011460351882181362
Epoch #218: loss=0.012751555087675446
Epoch #219: loss=0.02910944807350652
Epoch #220: loss=0.015380727147558601
Epoch #221: loss=0.026599536146717444
Epoch #222: loss=0.013585259642047433
Epoch #223: loss=0.012088121828499573
Epoch #224: loss=0.010817808568061521
Epoch #225: loss=0.012038002095129898
Epoch #226: loss=0.013493077877845138
Epoch #227: loss=0.013847145041075478
Epoch #228: loss=0.017528661876324965
Epoch #229: loss=0.023076807913430166
Epoch #230: loss=0.015043500353770233
Epoch #231: loss=0.013694823055179198
Epoch #232: loss=0.014222734021012734
Epoch #233: loss=0.018766568232912832
Epoch #234: loss=0.013585287356785153
Epoch #235: loss=0.012989855804918442
Epoch #236: loss=0.02521298822075259
Epoch #237: loss=0.03369673134171222
Epoch #238: loss=0.01991601619542286
Epoch #239: loss=0.012934763735443973
Epoch #240: loss=0.014437198823721097
Epoch #241: loss=0.013393905054103806
Epoch #242: loss=0.010188550946697099
Epoch #243: loss=0.008910643028804038
Epoch #244: loss=0.054451402727481925
Epoch #245: loss=0.016852776704589584
Epoch #246: loss=0.01385996560116418
Epoch #247: loss=0.011729577756161007
Epoch #248: loss=0.035860143204453146
Epoch #249: loss=0.018402321091561195

Training time: 1:33:18.952539

Finished.
n2one setting etth1_etth2_electricity_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_electricity_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_etth2_electricity_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.04884e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.08838e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.15676e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.04884e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3518038542545366, 'MAE': 0.4297042592914494}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_traffic_weather', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_traffic_weather_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.0011381218478315
Epoch #1: loss=0.3958340858309602
Epoch #2: loss=0.2778659169531186
Epoch #3: loss=0.21572078948638126
Epoch #4: loss=0.18608156994745104
Epoch #5: loss=0.16466719721198214
Epoch #6: loss=0.129525279838947
Epoch #7: loss=0.11496572222296322
Epoch #8: loss=0.10442155163152816
Epoch #9: loss=0.10202397249572953
Epoch #10: loss=0.07873601547262721
Epoch #11: loss=0.07631955455478587
Epoch #12: loss=0.06962533038318108
Epoch #13: loss=0.06384263789779951
Epoch #14: loss=0.06233885729098961
Epoch #15: loss=0.059997543915352496
Epoch #16: loss=0.04920635159961681
Epoch #17: loss=0.05107561686487162
Epoch #18: loss=0.05022329033998785
Epoch #19: loss=0.04153703803458807
Epoch #20: loss=0.041310470901788965
Epoch #21: loss=0.03639232153393031
Epoch #22: loss=0.041892081014337036
Epoch #23: loss=0.04229547056119617
Epoch #24: loss=0.03776504718822462
Epoch #25: loss=0.039300454566988295
Epoch #26: loss=0.03626516941462968
Epoch #27: loss=0.028509493632964324
Epoch #28: loss=0.03633142269976404
Epoch #29: loss=0.03372298695904383
Epoch #30: loss=0.027192865849933082
Epoch #31: loss=0.024111509997541695
Epoch #32: loss=0.028997894868506593
Epoch #33: loss=0.032098173245722054
Epoch #34: loss=0.03319064606607844
Epoch #35: loss=0.025963397646021354
Epoch #36: loss=0.02268343623228084
Epoch #37: loss=0.024977854852027213
Epoch #38: loss=0.028051681133960796
Epoch #39: loss=0.023203231200566537
Epoch #40: loss=0.024001244462609907
Epoch #41: loss=0.0239944148762513
Epoch #42: loss=0.02868501041853747
Epoch #43: loss=0.024126646173586182
Epoch #44: loss=0.03218726029060987
Epoch #45: loss=0.02525336107527197
Epoch #46: loss=0.027091679272142254
Epoch #47: loss=0.02473903548588332
Epoch #48: loss=0.016846894363268947
Epoch #49: loss=0.03186574631962748
Epoch #50: loss=0.029514246484043518
Epoch #51: loss=0.018429626021190894
Epoch #52: loss=0.023142601034119765
Epoch #53: loss=0.018130127152267604
Epoch #54: loss=0.022739191591340073
Epoch #55: loss=0.025822963368895148
Epoch #56: loss=0.017300974018320037
Epoch #57: loss=0.022059181038020004
Epoch #58: loss=0.03097652077939833
Epoch #59: loss=0.01838864389240526
Epoch #60: loss=0.02446785066862737
Epoch #61: loss=0.01841064042985045
Epoch #62: loss=0.016672979143158812
Epoch #63: loss=0.013701491378982885
Epoch #64: loss=0.0271721610147919
Epoch #65: loss=0.02886838897749856
Epoch #66: loss=0.016489124933585262
Epoch #67: loss=0.01844994410683833
Epoch #68: loss=0.018268041336087316
Epoch #69: loss=0.01818619795672636
Epoch #70: loss=0.0227680646788206
Epoch #71: loss=0.01972099879307816
Epoch #72: loss=0.016089114236981353
Epoch #73: loss=0.015309679509538583
Epoch #74: loss=0.023401497499820383
Epoch #75: loss=0.021867889964239603
Epoch #76: loss=0.019750471058281753
Epoch #77: loss=0.020946507654364475
Epoch #78: loss=0.02288816461942397
Epoch #79: loss=0.022663448728061548
Epoch #80: loss=0.013606034241431648
Epoch #81: loss=0.020337930709897218
Epoch #82: loss=0.020344082188492842
Epoch #83: loss=0.017367925800886697
Epoch #84: loss=0.01728258009328473
Epoch #85: loss=0.02070527969980344
Epoch #86: loss=0.015362287740475558
Epoch #87: loss=0.018078919647696704
Epoch #88: loss=0.01708344950852401
Epoch #89: loss=0.021230016624305383
Epoch #90: loss=0.024873037177000967
Epoch #91: loss=0.017140453876945565
Epoch #92: loss=0.016636351818975655
Epoch #93: loss=0.017013153661174226
Epoch #94: loss=0.015063403181407848
Epoch #95: loss=0.020375244545558273
Epoch #96: loss=0.014948725481777031
Epoch #97: loss=0.0209768006219033
Epoch #98: loss=0.013173220120899548
Epoch #99: loss=0.015382487884608559
Epoch #100: loss=0.018620989524273816
Epoch #101: loss=0.015275002626565124
Epoch #102: loss=0.03066780188692266
Epoch #103: loss=0.014634566614275257
Epoch #104: loss=0.018759347610347265
Epoch #105: loss=0.013388506899148478
Epoch #106: loss=0.01743960660631782
Epoch #107: loss=0.024523525770550735
Epoch #108: loss=0.015136258342115419
Epoch #109: loss=0.014889940026679805
Epoch #110: loss=0.013673808545097085
Epoch #111: loss=0.015054696113468219
Epoch #112: loss=0.013358294040725764
Epoch #113: loss=0.016526265278731692
Epoch #114: loss=0.015515034263190156
Epoch #115: loss=0.020968138441068384
Epoch #116: loss=0.019373229943677767
Epoch #117: loss=0.01688695551805351
Epoch #118: loss=0.013654831618196053
Epoch #119: loss=0.013838473552238597
Epoch #120: loss=0.01914149605027119
Epoch #121: loss=0.010903764678832058
Epoch #122: loss=0.017256650004725378
Epoch #123: loss=0.016924626367627912
Epoch #124: loss=0.01651857162778268
Epoch #125: loss=0.016007155835652515
Epoch #126: loss=0.012874620112406188
Epoch #127: loss=0.015057104625834664
Epoch #128: loss=0.017216288780301427
Epoch #129: loss=0.016044322601636168
Epoch #130: loss=0.01346756521896152
Epoch #131: loss=0.024647399331831493
Epoch #132: loss=0.01221837495649058
Epoch #133: loss=0.01567694887352649
Epoch #134: loss=0.014656057399229101
Epoch #135: loss=0.01620591792688801
Epoch #136: loss=0.009908805662523331
Epoch #137: loss=0.012748851278985096
Epoch #138: loss=0.015075971811209359
Epoch #139: loss=0.010763178996658783
Epoch #140: loss=0.012766792443957791
Epoch #141: loss=0.013466774248205715
Epoch #142: loss=0.02527262761413175
Epoch #143: loss=0.017857521121420365
Epoch #144: loss=0.012393581144984846
Epoch #145: loss=0.012974232265120681
Epoch #146: loss=0.013744125372975159
Epoch #147: loss=0.014144078689909224
Epoch #148: loss=0.013495377363602113
Epoch #149: loss=0.011006497004601259
Epoch #150: loss=0.009696206832067766
Epoch #151: loss=0.019931515482264135
Epoch #152: loss=0.029635417189819744
Epoch #153: loss=0.015204340461556368
Epoch #154: loss=0.00999605977324607
Epoch #155: loss=0.012217875753780786
Epoch #156: loss=0.015184363467702867
Epoch #157: loss=0.012939990846952062
Epoch #158: loss=0.012353913456080492
Epoch #159: loss=0.010327069496947852
Epoch #160: loss=0.011129663744221825
Epoch #161: loss=0.028732507924952994
Epoch #162: loss=0.01872279922536754
Epoch #163: loss=0.01354579177859705
Epoch #164: loss=0.013431177150318451
Epoch #165: loss=0.015307777319833979
Epoch #166: loss=0.009882737333108588
Epoch #167: loss=0.015166252662633967
Epoch #168: loss=0.012632171065725195
Epoch #169: loss=0.013804316905235764
Epoch #170: loss=0.015395103019471574
Epoch #171: loss=0.007045520953220037
Epoch #172: loss=0.014647294886439535
Epoch #173: loss=0.012334968379482255
Epoch #174: loss=0.011433377380465475
Epoch #175: loss=0.0161220680230102
Epoch #176: loss=0.014233559769073123
Epoch #177: loss=0.01200581928098186
Epoch #178: loss=0.01487810191775617
Epoch #179: loss=0.01279909743678262
Epoch #180: loss=0.010106073906396087
Epoch #181: loss=0.010889528348230516
Epoch #182: loss=0.010466728036063874
Epoch #183: loss=0.014935774572730914
Epoch #184: loss=0.012134094307242486
Epoch #185: loss=0.008365901141172105
Epoch #186: loss=0.01993649567902605
Epoch #187: loss=0.011049189497631543
Epoch #188: loss=0.012345406311802141
Epoch #189: loss=0.011593632483717437
Epoch #190: loss=0.016433292736864377
Epoch #191: loss=0.012333752119469332
Epoch #192: loss=0.009639464394222199
Epoch #193: loss=0.010807877444842068
Epoch #194: loss=0.010804857491728968
Epoch #195: loss=0.014902086922969357
Epoch #196: loss=0.010822220830612992
Epoch #197: loss=0.029474988056098404
Epoch #198: loss=0.019620580016958017
Epoch #199: loss=0.007071406128511071
Epoch #200: loss=0.010449709546258734
Epoch #201: loss=0.011822943957264707
Epoch #202: loss=0.014198320905007876
Epoch #203: loss=0.00890963781456798
Epoch #204: loss=0.011862656538045094
Epoch #205: loss=0.010884943138265945
Epoch #206: loss=0.014185277433890928
Epoch #207: loss=0.011291222785446718
Epoch #208: loss=0.010848127693940546
Epoch #209: loss=0.014600070324635284
Epoch #210: loss=0.009294167993367086
Epoch #211: loss=0.01220603547415344
Epoch #212: loss=0.01055149157757937
Epoch #213: loss=0.02156299532126486
Epoch #214: loss=0.020528695816994992
Epoch #215: loss=0.009879939165285777
Epoch #216: loss=0.016226506379376577
Epoch #217: loss=0.005864059754268578
Epoch #218: loss=0.019720716666385838
Epoch #219: loss=0.015655551059549067
Epoch #220: loss=0.014055512585195025
Epoch #221: loss=0.009910465456845942
Epoch #222: loss=0.012465147314057711
Epoch #223: loss=0.009732939713633777
Epoch #224: loss=0.014844496442659907
Epoch #225: loss=0.02099670794410574
Epoch #226: loss=0.013202736504557786
Epoch #227: loss=0.011636555067469013
Epoch #228: loss=0.010505909945815415
Epoch #229: loss=0.011776563161508487
Epoch #230: loss=0.011605660451817849
Epoch #231: loss=0.013410679605265678
Epoch #232: loss=0.00853490738180318
Epoch #233: loss=0.01160615202475844
Epoch #234: loss=0.012731542261470958
Epoch #235: loss=0.008255128033831922
Epoch #236: loss=0.011981243751111297
Epoch #237: loss=0.010085154974524281
Epoch #238: loss=0.011424244453811357
Epoch #239: loss=0.016246219594614295
Epoch #240: loss=0.01139111889739461
Epoch #241: loss=0.009550205565604538
Epoch #242: loss=0.01164648578502367
Epoch #243: loss=0.007686558381753523
Epoch #244: loss=0.011540643221753811
Epoch #245: loss=0.015739616920205247
Epoch #246: loss=0.016316501923668403
Epoch #247: loss=0.009889732217640737
Epoch #248: loss=0.013103206073842386
Epoch #249: loss=0.010430701954068023

Training time: 3:35:49.060920

Finished.
n2one setting etth1_etth2_traffic_weather -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_traffic_weather_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_etth2_traffic_weather', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.15501e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.7268e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.3854e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.15501e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.42076409930819014, 'MAE': 0.46250032614927744}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_traffic_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_traffic_weather_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_etth2_traffic_weather', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.39482e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.5313036526885541, 'MAE': 0.4618753720278815}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_traffic_exchange', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_traffic_exchange_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.9599037430337651
Epoch #1: loss=0.35634118246074714
Epoch #2: loss=0.2671101210866444
Epoch #3: loss=0.18201621086652733
Epoch #4: loss=0.16393612634087176
Epoch #5: loss=0.12688657307862494
Epoch #6: loss=0.12261726719230347
Epoch #7: loss=0.08864534911236038
Epoch #8: loss=0.08659560158027008
Epoch #9: loss=0.07565656538138259
Epoch #10: loss=0.07101345369307856
Epoch #11: loss=0.06507327064779077
Epoch #12: loss=0.054066094406300995
Epoch #13: loss=0.062235049779602744
Epoch #14: loss=0.056491476728062553
Epoch #15: loss=0.049540184806174774
Epoch #16: loss=0.04725006861850299
Epoch #17: loss=0.051100031009188335
Epoch #18: loss=0.04648982507136663
Epoch #19: loss=0.048939351813669624
Epoch #20: loss=0.04089425859774771
Epoch #21: loss=0.038205218155830424
Epoch #22: loss=0.03911076290166844
Epoch #23: loss=0.03311011029462166
Epoch #24: loss=0.028716140854692852
Epoch #25: loss=0.04276108645243524
Epoch #26: loss=0.02936548206571182
Epoch #27: loss=0.03257624270049149
Epoch #28: loss=0.03223146790090992
Epoch #29: loss=0.02983925444886775
Epoch #30: loss=0.03281768528893127
Epoch #31: loss=0.03998928936073247
Epoch #32: loss=0.02864913198573049
Epoch #33: loss=0.030023895020818453
Epoch #34: loss=0.03533474967320612
Epoch #35: loss=0.02873621583161391
Epoch #36: loss=0.022919769601804748
Epoch #37: loss=0.033523868761571624
Epoch #38: loss=0.028261894005012583
Epoch #39: loss=0.022065702929623465
Epoch #40: loss=0.022281660221696715
Epoch #41: loss=0.025826036299347595
Epoch #42: loss=0.033296624094256246
Epoch #43: loss=0.027077052498086698
Epoch #44: loss=0.02917476886970558
Epoch #45: loss=0.025125794514572003
Epoch #46: loss=0.0248627883324329
Epoch #47: loss=0.02389337644867264
Epoch #48: loss=0.019490302538254817
Epoch #49: loss=0.0222951106642709
Epoch #50: loss=0.025179055416287552
Epoch #51: loss=0.02822833642045118
Epoch #52: loss=0.020204396501678143
Epoch #53: loss=0.02526350635833716
Epoch #54: loss=0.02364091655154917
Epoch #55: loss=0.0178701239953761
Epoch #56: loss=0.021055355465789728
Epoch #57: loss=0.021791436710138515
Epoch #58: loss=0.023064271107116372
Epoch #59: loss=0.024499632699152493
Epoch #60: loss=0.0254923244975128
Epoch #61: loss=0.02535602188074163
Epoch #62: loss=0.023602246466907673
Epoch #63: loss=0.018889477792800702
Epoch #64: loss=0.02141924115486245
Epoch #65: loss=0.01964518114633656
Epoch #66: loss=0.018536288105860055
Epoch #67: loss=0.03775181383754725
Epoch #68: loss=0.021572868467721565
Epoch #69: loss=0.017839022498211468
Epoch #70: loss=0.01696437070416434
Epoch #71: loss=0.019634682082187077
Epoch #72: loss=0.018694883045593986
Epoch #73: loss=0.023749929435519034
Epoch #74: loss=0.02174148367895909
Epoch #75: loss=0.019142390583980012
Epoch #76: loss=0.01752547050276571
Epoch #77: loss=0.017644429578323642
Epoch #78: loss=0.020769622494130526
Epoch #79: loss=0.019416003372016884
Epoch #80: loss=0.019149400228508053
Epoch #81: loss=0.018654447689713548
Epoch #82: loss=0.01760742156267244
Epoch #83: loss=0.01948217918146328
Epoch #84: loss=0.019881349151250297
Epoch #85: loss=0.01235578345577733
Epoch #86: loss=0.01918848449845242
Epoch #87: loss=0.016998575212422345
Epoch #88: loss=0.019412332658660023
Epoch #89: loss=0.019944502386565813
Epoch #90: loss=0.01667281395759132
Epoch #91: loss=0.016748364744165373
Epoch #92: loss=0.018593488636918364
Epoch #93: loss=0.01588820848670835
Epoch #94: loss=0.014787129512937989
Epoch #95: loss=0.01846323232884188
Epoch #96: loss=0.015464325568846683
Epoch #97: loss=0.017957486847397754
Epoch #98: loss=0.016764140397371362
Epoch #99: loss=0.01813844633912241
Epoch #100: loss=0.023028424069172403
Epoch #101: loss=0.021426371053981645
Epoch #102: loss=0.012134571785281878
Epoch #103: loss=0.016663284858627343
Epoch #104: loss=0.019265943355065544
Epoch #105: loss=0.02012293829189664
Epoch #106: loss=0.017252429919740096
Epoch #107: loss=0.024370011971126693
Epoch #108: loss=0.016235261242054468
Epoch #109: loss=0.015975838197031474
Epoch #110: loss=0.02863606427834639
Epoch #111: loss=0.016422226106714007
Epoch #112: loss=0.017275316874092082
Epoch #113: loss=0.013774761363834447
Epoch #114: loss=0.018711916593645385
Epoch #115: loss=0.013266270265450155
Epoch #116: loss=0.014857435409745177
Epoch #117: loss=0.015846930820682895
Epoch #118: loss=0.01650354222873093
Epoch #119: loss=0.01680762434192713
Epoch #120: loss=0.016897376440649817
Epoch #121: loss=0.021316326213272327
Epoch #122: loss=0.016848780185452238
Epoch #123: loss=0.01864837012090404
Epoch #124: loss=0.019219731346994316
Epoch #125: loss=0.017988708961869083
Epoch #126: loss=0.012725413229426568
Epoch #127: loss=0.014169162377394837
Epoch #128: loss=0.014736648029302735
Epoch #129: loss=0.01348874676461401
Epoch #130: loss=0.011360559345738451
Epoch #131: loss=0.01050823341767468
Epoch #132: loss=0.01714093455880442
Epoch #133: loss=0.015133091676783379
Epoch #134: loss=0.018642040181125943
Epoch #135: loss=0.02195652382561175
Epoch #136: loss=0.013050441201824992
Epoch #137: loss=0.013082807392377892
Epoch #138: loss=0.013280884261651025
Epoch #139: loss=0.016292230370762648
Epoch #140: loss=0.01373377433411484
Epoch #141: loss=0.019872364387779003
Epoch #142: loss=0.015418781995741973
Epoch #143: loss=0.014981445607561218
Epoch #144: loss=0.013272931016616816
Epoch #145: loss=0.013727855609863684
Epoch #146: loss=0.012610383122023965
Epoch #147: loss=0.014859109013926735
Epoch #148: loss=0.01567072921029052
Epoch #149: loss=0.01096241093175886
Epoch #150: loss=0.010835451904078655
Epoch #151: loss=0.018893119651075964
Epoch #152: loss=0.016474540592144257
Epoch #153: loss=0.016621697182375706
Epoch #154: loss=0.01680080485106151
Epoch #155: loss=0.0117220181486966
Epoch #156: loss=0.012717378020170145
Epoch #157: loss=0.016654097101765967
Epoch #158: loss=0.017470944804284034
Epoch #159: loss=0.012348865930403729
Epoch #160: loss=0.011912335637731402
Epoch #161: loss=0.014675632981988823
Epoch #162: loss=0.015528890192691748
Epoch #163: loss=0.010641145933061529
Epoch #164: loss=0.012443153240325638
Epoch #165: loss=0.008447946113793639
Epoch #166: loss=0.013274741089597688
Epoch #167: loss=0.015015119151890487
Epoch #168: loss=0.011305218670191006
Epoch #169: loss=0.015508093708438421
Epoch #170: loss=0.011418270420404763
Epoch #171: loss=0.012358103860458054
Epoch #172: loss=0.015348302081584976
Epoch #173: loss=0.013907317887521265
Epoch #174: loss=0.013337254574570048
Epoch #175: loss=0.009596891262688636
Epoch #176: loss=0.015340469850796342
Epoch #177: loss=0.016756190011442806
Epoch #178: loss=0.021372554068735693
Epoch #179: loss=0.012026168646972271
Epoch #180: loss=0.010163329381414591
Epoch #181: loss=0.01491407145685079
Epoch #182: loss=0.013843252412986423
Epoch #183: loss=0.013437706312909775
Epoch #184: loss=0.014591899945112778
Epoch #185: loss=0.009525035420253982
Epoch #186: loss=0.014610272429452717
Epoch #187: loss=0.011917550503440245
Epoch #188: loss=0.011598239631741834
Epoch #189: loss=0.01051101859034607
Epoch #190: loss=0.014119202428541096
Epoch #191: loss=0.020979806400934414
Epoch #192: loss=0.010921157607011317
Epoch #193: loss=0.012133387516888635
Epoch #194: loss=0.009954164017200453
Epoch #195: loss=0.015738266453961314
Epoch #196: loss=0.015611801534093472
Epoch #197: loss=0.014569304498866698
Epoch #198: loss=0.017440645961322106
Epoch #199: loss=0.008449523547552741
Epoch #200: loss=0.009654174924937284
Epoch #201: loss=0.012157452563075299
Epoch #202: loss=0.01166381123621908
Epoch #203: loss=0.01435782631587372
Epoch #204: loss=0.013370364612805693
Epoch #205: loss=0.01503524663650043
Epoch #206: loss=0.013718931156541674
Epoch #207: loss=0.013431237551040287
Epoch #208: loss=0.01485971054985405
Epoch #209: loss=0.009081322028078641
Epoch #210: loss=0.010365174745992882
Epoch #211: loss=0.012246981201611372
Epoch #212: loss=0.014307825825548766
Epoch #213: loss=0.011944151872064976
Epoch #214: loss=0.009685074092075044
Epoch #215: loss=0.01659052820811185
Epoch #216: loss=0.013367946683131559
Epoch #217: loss=0.010382084271667617
Epoch #218: loss=0.012812478992201328
Epoch #219: loss=0.0120367248858683
Epoch #220: loss=0.010502436479735446
Epoch #221: loss=0.009486373777604038
Epoch #222: loss=0.011661760845617708
Epoch #223: loss=0.009918502780019645
Epoch #224: loss=0.01546408571859946
Epoch #225: loss=0.017299121062493067
Epoch #226: loss=0.012807415393922899
Epoch #227: loss=0.012063139027205946
Epoch #228: loss=0.01285913653405527
Epoch #229: loss=0.011594871122453112
Epoch #230: loss=0.011891193879280072
Epoch #231: loss=0.010336853860511286
Epoch #232: loss=0.01631704556575436
Epoch #233: loss=0.010661181949995083
Epoch #234: loss=0.011145510111398266
Epoch #235: loss=0.009182208074959747
Epoch #236: loss=0.014572592027002326
Epoch #237: loss=0.008960191250122384
Epoch #238: loss=0.009713165910887675
Epoch #239: loss=0.014737451873132744
Epoch #240: loss=0.010172194341930868
Epoch #241: loss=0.008194100003966344
Epoch #242: loss=0.0116210529241014
Epoch #243: loss=0.009988016326211413
Epoch #244: loss=0.012248301480270446
Epoch #245: loss=0.010291913259191448
Epoch #246: loss=0.009109930566270262
Epoch #247: loss=0.011011074060924868
Epoch #248: loss=0.01111720053830231
Epoch #249: loss=0.015803823250844208

Training time: 3:27:40.218487

Finished.
n2one setting etth1_etth2_traffic_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_traffic_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_etth2_traffic_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.83003e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.69268e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.35091e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.83003e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.39215021149293516, 'MAE': 0.4451286996999877}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_traffic_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_traffic_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_etth2_traffic_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.13804e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.52295e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.13804e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3935510875850802, 'MAE': 0.4652613117322611}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_weather_exchange', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_weather_exchange_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=4.497979822258155
Epoch #1: loss=2.7585212339957557
Epoch #2: loss=2.2327015697956085
Epoch #3: loss=2.025281128784021
Epoch #4: loss=1.961090050637722
Epoch #5: loss=1.828012965619564
Epoch #6: loss=1.665504736204942
Epoch #7: loss=1.5955925757686298
Epoch #8: loss=1.5177644193172455
Epoch #9: loss=1.3721998209754627
Epoch #10: loss=1.2799533233046532
Epoch #11: loss=1.194572813808918
Epoch #12: loss=1.1901598361631234
Epoch #13: loss=1.1527411018808682
Epoch #14: loss=1.1372691616415977
Epoch #15: loss=1.0528465000291665
Epoch #16: loss=0.9970599686106046
Epoch #17: loss=0.9830417024592558
Epoch #18: loss=0.9490491102139155
Epoch #19: loss=0.9186194874346256
Epoch #20: loss=0.8955958411097527
Epoch #21: loss=0.8213950010637442
Epoch #22: loss=0.9061309086779753
Epoch #23: loss=0.9761019696791967
Epoch #24: loss=0.8699899862209955
Epoch #25: loss=0.7619544876118501
Epoch #26: loss=0.757879838347435
Epoch #27: loss=0.7884820885956287
Epoch #28: loss=0.7559366188943386
Epoch #29: loss=0.6574855335056782
Epoch #30: loss=0.7352441307157278
Epoch #31: loss=0.6338773841659228
Epoch #32: loss=0.6713360504557689
Epoch #33: loss=0.6744558562835058
Epoch #34: loss=0.6533930183698734
Epoch #35: loss=0.5555312000215054
Epoch #36: loss=0.5889962861935297
Epoch #37: loss=0.5473648210366567
Epoch #38: loss=0.5380698076138893
Epoch #39: loss=0.5460925530642271
Epoch #40: loss=0.51515517073373
Epoch #41: loss=0.5488301844646534
Epoch #42: loss=0.5351504534482956
Epoch #43: loss=0.5178707620749871
Epoch #44: loss=0.582011059547464
Epoch #45: loss=0.5207657509793838
Epoch #46: loss=0.5524651184678078
Epoch #47: loss=0.523981391141812
Epoch #48: loss=0.5276128457238277
Epoch #49: loss=0.5702568131188551
Epoch #50: loss=0.6056049317121506
Epoch #51: loss=0.5035793899248043
Epoch #52: loss=0.48985313810408115
Epoch #53: loss=0.5707310090462366
Epoch #54: loss=0.6082686974356571
Epoch #55: loss=0.4756939969956875
Epoch #56: loss=0.4048064698775609
Epoch #57: loss=0.43651977305610973
Epoch #58: loss=0.40932194019357365
Epoch #59: loss=0.48227240331470966
Epoch #60: loss=0.4671214396754901
Epoch #61: loss=0.3722913696741064
Epoch #62: loss=0.33341211918741465
Epoch #63: loss=0.4383938815444708
Epoch #64: loss=0.5560446974510947
Epoch #65: loss=0.418187874990205
Epoch #66: loss=0.37352344145377475
Epoch #67: loss=0.4330080235376954
Epoch #68: loss=0.4132302673533559
Epoch #69: loss=0.5904398951679468
Epoch #70: loss=0.4324704119935632
Epoch #71: loss=0.34593831406285364
Epoch #72: loss=0.38514476797233027
Epoch #73: loss=0.3300574151799083
Epoch #74: loss=0.37424911744892597
Epoch #75: loss=0.31049993354827166
Epoch #76: loss=0.361536364381512
Epoch #77: loss=0.3191869193688035
Epoch #78: loss=0.34331204323098063
Epoch #79: loss=0.3062422030294935
Epoch #80: loss=0.2566847437992692
Epoch #81: loss=0.29449790017679334
Epoch #82: loss=0.2830871989329656
Epoch #83: loss=0.26086288628478843
Epoch #84: loss=0.3369108766006927
Epoch #85: loss=0.2390385918940107
Epoch #86: loss=0.3443165513065954
Epoch #87: loss=0.3454523083443443
Epoch #88: loss=0.336891694770505
Epoch #89: loss=0.30065413067738217
Epoch #90: loss=0.2796183604126175
Epoch #91: loss=0.3155667847022414
Epoch #92: loss=0.24687123096858463
Epoch #93: loss=0.26713232742622495
Epoch #94: loss=0.29295072037105757
Epoch #95: loss=0.22610193397849798
Epoch #96: loss=0.21028509379054108
Epoch #97: loss=0.22406382098173103
Epoch #98: loss=0.20962577918544412
Epoch #99: loss=0.22200098121538758
Epoch #100: loss=0.23926078140114745
Epoch #101: loss=0.30114101416741806
Epoch #102: loss=0.2598465763342877
Epoch #103: loss=0.27243131725117564
Epoch #104: loss=0.24886520920942226
Epoch #105: loss=0.23001531534828246
Epoch #106: loss=0.25878355861641467
Epoch #107: loss=0.21574535702044764
Epoch #108: loss=0.22379652907450995
Epoch #109: loss=0.23926091256241003
Epoch #110: loss=0.2070983100372056
Epoch #111: loss=0.22096590379563472
Epoch #112: loss=0.2848609268354873
Epoch #113: loss=0.20472836727276444
Epoch #114: loss=0.19924895240304372
Epoch #115: loss=0.2555499974017342
Epoch #116: loss=0.18292755912989378
Epoch #117: loss=0.22111226548440754
Epoch #118: loss=0.1978544023198386
Epoch #119: loss=0.21791966895883283
Epoch #120: loss=0.24276883845838407
Epoch #121: loss=0.18809817894361913
Epoch #122: loss=0.23585400823503733
Epoch #123: loss=0.16810730642949542
Epoch #124: loss=0.2255376644898206
Epoch #125: loss=0.1730315591363857
Epoch #126: loss=0.20186524946863452
Epoch #127: loss=0.17585248197428882
Epoch #128: loss=0.20474532580313584
Epoch #129: loss=0.21813481332113346
Epoch #130: loss=0.24588741781190038
Epoch #131: loss=0.2118198269357284
Epoch #132: loss=0.1758469712610046
Epoch #133: loss=0.18468042936486503
Epoch #134: loss=0.14167637300367156
Epoch #135: loss=0.17479783296585083
Epoch #136: loss=0.14203897258266807
Epoch #137: loss=0.1675210865214467
Epoch #138: loss=0.15541173424571753
Epoch #139: loss=0.14252496999688447
Epoch #140: loss=0.12301555671729147
Epoch #141: loss=0.13301318623901656
Epoch #142: loss=0.1518124332263445
Epoch #143: loss=0.18858794076368213
Epoch #144: loss=0.20727467630058527
Epoch #145: loss=0.1662099523236975
Epoch #146: loss=0.17812634950193265
Epoch #147: loss=0.1454277445251743
Epoch #148: loss=0.16935587542441985
Epoch #149: loss=0.13724857584262887
Epoch #150: loss=0.1271456889420127
Epoch #151: loss=0.15017309982795268
Epoch #152: loss=0.13112705697615942
Epoch #153: loss=0.11516444229831298
Epoch #154: loss=0.09585157801241924
Epoch #155: loss=0.17753870672701547
Epoch #156: loss=0.21704418406200907
Epoch #157: loss=0.18613870915335914
Epoch #158: loss=0.27704691716159385
Epoch #159: loss=0.2573927422054112
Epoch #160: loss=0.19156288378871977
Epoch #161: loss=0.22080686052019396
Epoch #162: loss=0.12135608835766713
Epoch #163: loss=0.19462403856838742
Epoch #164: loss=0.15998124874507388
Epoch #165: loss=0.13638251375717422
Epoch #166: loss=0.12789017470398298
Epoch #167: loss=0.1662594146716098
Epoch #168: loss=0.13577553179735938
Epoch #169: loss=0.13835100717066476
Epoch #170: loss=0.13581968234696737
Epoch #171: loss=0.10122837622960408
Epoch #172: loss=0.11148240137845278
Epoch #173: loss=0.1254115860986834
Epoch #174: loss=0.14745552407111973
Epoch #175: loss=0.14061776315793395
Epoch #176: loss=0.15209339027448246
Epoch #177: loss=0.1326175891639044
Epoch #178: loss=0.10009214254872252
Epoch #179: loss=0.13486812678941837
Epoch #180: loss=0.11059156979899853
Epoch #181: loss=0.1290068643478056
Epoch #182: loss=0.11855192575603724
Epoch #183: loss=0.112381775630638
Epoch #184: loss=0.0980296516402935
Epoch #185: loss=0.12191456001407157
Epoch #186: loss=0.1094528022998323
Epoch #187: loss=0.10996309275894116
Epoch #188: loss=0.11679949425160885
Epoch #189: loss=0.10559872390391926
Epoch #190: loss=0.10113807771510135
Epoch #191: loss=0.11640457246297349
Epoch #192: loss=0.10806435548389952
Epoch #193: loss=0.1538439649545277
Epoch #194: loss=0.12483479827642441
Epoch #195: loss=0.11450732379065205
Epoch #196: loss=0.1498419656030213
Epoch #197: loss=0.16565413656644523
Epoch #198: loss=0.12285359591866533
Epoch #199: loss=0.12936701350069293
Epoch #200: loss=0.1305545896369343
Epoch #201: loss=0.13100244663655758
Epoch #202: loss=0.10214411257766187
Epoch #203: loss=0.16058132296893746
Epoch #204: loss=0.1394632535520941
Epoch #205: loss=0.12484887568280101
Epoch #206: loss=0.1411521213982875
Epoch #207: loss=0.1356802717394506
Epoch #208: loss=0.11962780022683243
Epoch #209: loss=0.11805823759641498
Epoch #210: loss=0.11691911863939215
Epoch #211: loss=0.08254203402126829
Epoch #212: loss=0.09757756647498657
Epoch #213: loss=0.07113870858059575
Epoch #214: loss=0.12177206114089738
Epoch #215: loss=0.11781538871582597
Epoch #216: loss=0.12848632171517238
Epoch #217: loss=0.11186476047926892
Epoch #218: loss=0.09200802014674991
Epoch #219: loss=0.09076267180110638
Epoch #220: loss=0.10569933105337743
Epoch #221: loss=0.1081909912172705
Epoch #222: loss=0.11720181178922455
Epoch #223: loss=0.1407874218033006
Epoch #224: loss=0.14388078334741294
Epoch #225: loss=0.12977346874928722
Epoch #226: loss=0.16674294501232603
Epoch #227: loss=0.12379139366870125
Epoch #228: loss=0.11561291125447799
Epoch #229: loss=0.09673316528399785
Epoch #230: loss=0.08942531379094969
Epoch #231: loss=0.0986198326960827
Epoch #232: loss=0.08980187523411587
Epoch #233: loss=0.10855278473657866
Epoch #234: loss=0.11658625547230865
Epoch #235: loss=0.12280400687207778
Epoch #236: loss=0.0932845618808642
Epoch #237: loss=0.0801981963062038
Epoch #238: loss=0.10153966984944418
Epoch #239: loss=0.07622893641625221
Epoch #240: loss=0.08118516587031384
Epoch #241: loss=0.12060816388111562
Epoch #242: loss=0.16168452040680373
Epoch #243: loss=0.14897716736110547
Epoch #244: loss=0.17382886912673712
Epoch #245: loss=0.1618985307480519
Epoch #246: loss=0.17723367215755084
Epoch #247: loss=0.16523887232566872
Epoch #248: loss=0.08366778985752414
Epoch #249: loss=0.10014536136683698

Training time: 0:14:08.407666

Finished.
n2one setting etth1_etth2_weather_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_weather_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_etth2_weather_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.48689e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.1903e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.48689e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.37863926866201947, 'MAE': 0.435934271451869}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm1_ettm2_electricity', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm1_ettm2_electricity_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.6348879633631026
Epoch #1: loss=0.6743490240403585
Epoch #2: loss=0.4777665162086487
Epoch #3: loss=0.3488682708569935
Epoch #4: loss=0.3077809388296945
Epoch #5: loss=0.2598654472615038
Epoch #6: loss=0.2448906249659402
Epoch #7: loss=0.22087912008166313
Epoch #8: loss=0.1836117066762277
Epoch #9: loss=0.16629750472094332
Epoch #10: loss=0.14098976777068206
Epoch #11: loss=0.13882543783102716
Epoch #12: loss=0.13748652213386128
Epoch #13: loss=0.12634552580969674
Epoch #14: loss=0.10668083367070981
Epoch #15: loss=0.09836257613663163
Epoch #16: loss=0.12023798398673534
Epoch #17: loss=0.07950383559401546
Epoch #18: loss=0.08310979303770831
Epoch #19: loss=0.0802912449224719
Epoch #20: loss=0.0784185737903629
Epoch #21: loss=0.06765478229150176
Epoch #22: loss=0.06615448539943568
Epoch #23: loss=0.05972551031703396
Epoch #24: loss=0.06286609120400889
Epoch #25: loss=0.058627660321071744
Epoch #26: loss=0.0596757651333298
Epoch #27: loss=0.05192094163436975
Epoch #28: loss=0.05427251310886017
Epoch #29: loss=0.04970123610924929
Epoch #30: loss=0.05837501859292388
Epoch #31: loss=0.0533404327011002
Epoch #32: loss=0.03956551099794784
Epoch #33: loss=0.05176360386556813
Epoch #34: loss=0.04077870277155723
Epoch #35: loss=0.03242579976495887
Epoch #36: loss=0.04023623370898089
Epoch #37: loss=0.04535122070394989
Epoch #38: loss=0.03737166246665376
Epoch #39: loss=0.036663950148171615
Epoch #40: loss=0.03786684087510886
Epoch #41: loss=0.02854070812363976
Epoch #42: loss=0.028736223670587476
Epoch #43: loss=0.025736625325599952
Epoch #44: loss=0.027906822085413816
Epoch #45: loss=0.030671354243531825
Epoch #46: loss=0.03706542106544865
Epoch #47: loss=0.03686495346915243
Epoch #48: loss=0.024204694101520416
Epoch #49: loss=0.020217989544450705
Epoch #50: loss=0.02631545637900542
Epoch #51: loss=0.02683006866968104
Epoch #52: loss=0.04270561922341585
Epoch #53: loss=0.02097363652495135
Epoch #54: loss=0.02412098901845249
Epoch #55: loss=0.04277802430525688
Epoch #56: loss=0.027319640148697154
Epoch #57: loss=0.02347018994973041
Epoch #58: loss=0.023037536575492207
Epoch #59: loss=0.02120939899768148
Epoch #60: loss=0.029314273187025848
Epoch #61: loss=0.021644301635678858
Epoch #62: loss=0.04675610771153255
Epoch #63: loss=0.021473824978207372
Epoch #64: loss=0.023605663135448204
Epoch #65: loss=0.01593713232665323
Epoch #66: loss=0.02157709406589025
Epoch #67: loss=0.01889799031063116
Epoch #68: loss=0.0291645410853172
Epoch #69: loss=0.02536131280740457
Epoch #70: loss=0.02369275903828176
Epoch #71: loss=0.029634122946299614
Epoch #72: loss=0.020185558109743786
Epoch #73: loss=0.016838647338362146
Epoch #74: loss=0.019390540503331326
Epoch #75: loss=0.036768462989878445
Epoch #76: loss=0.022662122296502014
Epoch #77: loss=0.015951274624925904
Epoch #78: loss=0.03307296960448314
Epoch #79: loss=0.024264021082781254
Epoch #80: loss=0.01815780839400499
Epoch #81: loss=0.016244823976220298
Epoch #82: loss=0.012129549905158845
Epoch #83: loss=0.017959270882752856
Epoch #84: loss=0.0201593205988008
Epoch #85: loss=0.017631640335811036
Epoch #86: loss=0.01576527320214414
Epoch #87: loss=0.01882786117028445
Epoch #88: loss=0.018721410338600565
Epoch #89: loss=0.024171277701389045
Epoch #90: loss=0.01987302585920718
Epoch #91: loss=0.01915952430289638
Epoch #92: loss=0.02057055201797214
Epoch #93: loss=0.014573264376293601
Epoch #94: loss=0.011712386822660587
Epoch #95: loss=0.018444363533053548
Epoch #96: loss=0.018612262733180875
Epoch #97: loss=0.014499705890526196
Epoch #98: loss=0.017515585190849378
Epoch #99: loss=0.018218607197050006
Epoch #100: loss=0.023382194701449147
Epoch #101: loss=0.01783262391508158
Epoch #102: loss=0.012944929701292754
Epoch #103: loss=0.01661359452442931
Epoch #104: loss=0.026140200223973287
Epoch #105: loss=0.03720250274886244
Epoch #106: loss=0.021721709929739257
Epoch #107: loss=0.01518840167255673
Epoch #108: loss=0.011624701707124976
Epoch #109: loss=0.012857561458866778
Epoch #110: loss=0.013672735897375138
Epoch #111: loss=0.024274553997841265
Epoch #112: loss=0.027570266549342446
Epoch #113: loss=0.01733837332443467
Epoch #114: loss=0.02171029197185167
Epoch #115: loss=0.016499871428823098
Epoch #116: loss=0.015351201327617412
Epoch #117: loss=0.01591234989372814
Epoch #118: loss=0.018069149062669435
Epoch #119: loss=0.01683824801152306
Epoch #120: loss=0.016650841264220485
Epoch #121: loss=0.015917575475260883
Epoch #122: loss=0.019164007948212592
Epoch #123: loss=0.013849518624733069
Epoch #124: loss=0.014200937910604158
Epoch #125: loss=0.019378240915747094
Epoch #126: loss=0.020339669094786846
Epoch #127: loss=0.0176450271039669
Epoch #128: loss=0.012008170628188444
Epoch #129: loss=0.011497554254352248
Epoch #130: loss=0.011098769046449368
Epoch #131: loss=0.014193927115827266
Epoch #132: loss=0.014467305916789753
Epoch #133: loss=0.01911839380294883
Epoch #134: loss=0.011268674329372256
Epoch #135: loss=0.010346939158293286
Epoch #136: loss=0.015440432801260612
Epoch #137: loss=0.012142901784640604
Epoch #138: loss=0.03136035872773001
Epoch #139: loss=0.016310387288685887
Epoch #140: loss=0.012173061624136089
Epoch #141: loss=0.014528613268131657
Epoch #142: loss=0.013692952568443226
Epoch #143: loss=0.01789676509315281
Epoch #144: loss=0.012681204529113269
Epoch #145: loss=0.012682182921063422
Epoch #146: loss=0.01828771210458529
Epoch #147: loss=0.013171161261769676
Epoch #148: loss=0.0077663198251476774
Epoch #149: loss=0.012495713801888218
Epoch #150: loss=0.011781110856099985
Epoch #151: loss=0.017450849604626586
Epoch #152: loss=0.013081179571038644
Epoch #153: loss=0.011559909904026427
Epoch #154: loss=0.008373610553514611
Epoch #155: loss=0.019139970266925436
Epoch #156: loss=0.014587322574641024
Epoch #157: loss=0.014066371486197958
Epoch #158: loss=0.00910468631582002
Epoch #159: loss=0.03650806211766654
Epoch #160: loss=0.011408173558551685
Epoch #161: loss=0.0094702952685267
Epoch #162: loss=0.009284507244343071
Epoch #163: loss=0.013319105374227678
Epoch #164: loss=0.01437816355360805
Epoch #165: loss=0.013225958588882349
Epoch #166: loss=0.012456597209010007
Epoch #167: loss=0.016964981498562598
Epoch #168: loss=0.01550070753329367
Epoch #169: loss=0.008783294029833216
Epoch #170: loss=0.014958179445446668
Epoch #171: loss=0.0158884332136118
Epoch #172: loss=0.014860236075473949
Epoch #173: loss=0.013707496084555584
Epoch #174: loss=0.016346071598569063
Epoch #175: loss=0.009032922852950704
Epoch #176: loss=0.010662550040287898
Epoch #177: loss=0.010503583086704436
Epoch #178: loss=0.0323128071618599
Epoch #179: loss=0.014379838312576923
Epoch #180: loss=0.011038704237268706
Epoch #181: loss=0.008243250198595758
Epoch #182: loss=0.010546041624620557
Epoch #183: loss=0.019285091801346944
Epoch #184: loss=0.010555472604797354
Epoch #185: loss=0.012804746539082512
Epoch #186: loss=0.017900258839196926
Epoch #187: loss=0.01213275059708394
Epoch #188: loss=0.008576151789883234
Epoch #189: loss=0.008808020117576233
Epoch #190: loss=0.010690417830399902
Epoch #191: loss=0.017973571072631915
Epoch #192: loss=0.012827789331287412
Epoch #193: loss=0.015261860182093058
Epoch #194: loss=0.010987940054785992
Epoch #195: loss=0.018807443004334345
Epoch #196: loss=0.0188327525348203
Epoch #197: loss=0.010457177795303453
Epoch #198: loss=0.01299867921666841
Epoch #199: loss=0.008019610253728129
Epoch #200: loss=0.010298269999787278
Epoch #201: loss=0.011188126038011562
Epoch #202: loss=0.011092254041328228
Epoch #203: loss=0.012221202302607708
Epoch #204: loss=0.010402635591038104
Epoch #205: loss=0.016487490779088277
Epoch #206: loss=0.011713895563069465
Epoch #207: loss=0.019434264010716497
Epoch #208: loss=0.01491008511927378
Epoch #209: loss=0.012002821789355949
Epoch #210: loss=0.010231932887025843
Epoch #211: loss=0.009608365245928455
Epoch #212: loss=0.008619376840651966
Epoch #213: loss=0.005939950103347655
Epoch #214: loss=0.013225485951573189
Epoch #215: loss=0.012544657056818584
Epoch #216: loss=0.02957216509218727
Epoch #217: loss=0.011404876533696161
Epoch #218: loss=0.009277144896872674
Epoch #219: loss=0.014907530157111718
Epoch #220: loss=0.012921093267754518
Epoch #221: loss=0.014180916459964854
Epoch #222: loss=0.024438825199779655
Epoch #223: loss=0.015535883743598659
Epoch #224: loss=0.012065519298360285
Epoch #225: loss=0.008992645376794306
Epoch #226: loss=0.009211797569545785
Epoch #227: loss=0.008467441389387074
Epoch #228: loss=0.008524763468553178
Epoch #229: loss=0.008155355549533852
Epoch #230: loss=0.01517053363861383
Epoch #231: loss=0.007197315943527169
Epoch #232: loss=0.01241190454082763
Epoch #233: loss=0.011509388977512053
Epoch #234: loss=0.01971355343711496
Epoch #235: loss=0.00798797871543294
Epoch #236: loss=0.00838836275797803
Epoch #237: loss=0.010743620652106723
Epoch #238: loss=0.012846432059138482
Epoch #239: loss=0.013317063308703447
Epoch #240: loss=0.008030495855491608
Epoch #241: loss=0.007793092165707743
Epoch #242: loss=0.012123460943028996
Epoch #243: loss=0.009644982428539412
Epoch #244: loss=0.00727418720688937
Epoch #245: loss=0.009114764956674272
Epoch #246: loss=0.014622928978808757
Epoch #247: loss=0.013822715786684836
Epoch #248: loss=0.008779241829761303
Epoch #249: loss=0.013585624451931965

Training time: 1:37:47.651302

Finished.
n2one setting etth1_ettm1_ettm2_electricity -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_ettm2_electricity_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_ettm1_ettm2_electricity', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.15021e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.30982e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.8493e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.30982e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.8590985843832512, 'MAE': 0.7126212880773237}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm1_ettm2_electricity -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_ettm2_electricity_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_ettm1_ettm2_electricity', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.03329e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.03329e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.24852912131880905, 'MAE': 0.33808322231673293}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm1_ettm2_traffic', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm1_ettm2_traffic_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.9963193376089721
Epoch #1: loss=0.39119026059855516
Epoch #2: loss=0.26491583035014965
Epoch #3: loss=0.1896323216734109
Epoch #4: loss=0.16289068283941743
Epoch #5: loss=0.13333392847333558
Epoch #6: loss=0.10843679764413607
Epoch #7: loss=0.10245915577359138
Epoch #8: loss=0.08432421402945095
Epoch #9: loss=0.07780215602920011
Epoch #10: loss=0.06820140272069526
Epoch #11: loss=0.07355928003284182
Epoch #12: loss=0.05902673975291728
Epoch #13: loss=0.049803274653603215
Epoch #14: loss=0.05375370403096356
Epoch #15: loss=0.04447018260875242
Epoch #16: loss=0.05630590854809483
Epoch #17: loss=0.03713151898617124
Epoch #18: loss=0.03968342404820936
Epoch #19: loss=0.038045975994125354
Epoch #20: loss=0.03565286752881794
Epoch #21: loss=0.03460273656740107
Epoch #22: loss=0.031257489058147285
Epoch #23: loss=0.03134010555774003
Epoch #24: loss=0.030456011668689064
Epoch #25: loss=0.03681640467759615
Epoch #26: loss=0.02668476837630228
Epoch #27: loss=0.027350960918425194
Epoch #28: loss=0.03556207937343144
Epoch #29: loss=0.024809112350160346
Epoch #30: loss=0.029157129377278254
Epoch #31: loss=0.029494554872713945
Epoch #32: loss=0.029824420448806028
Epoch #33: loss=0.02099657726568702
Epoch #34: loss=0.025011410622613965
Epoch #35: loss=0.02843732456521507
Epoch #36: loss=0.024392433054852336
Epoch #37: loss=0.023855634703688684
Epoch #38: loss=0.025074984872552716
Epoch #39: loss=0.022858458553236
Epoch #40: loss=0.02250393633839155
Epoch #41: loss=0.02332948316615096
Epoch #42: loss=0.02092845772009439
Epoch #43: loss=0.026812139673220717
Epoch #44: loss=0.019747502105925952
Epoch #45: loss=0.016578648511989837
Epoch #46: loss=0.015130293808182895
Epoch #47: loss=0.02534573140823806
Epoch #48: loss=0.01600304702232178
Epoch #49: loss=0.01938507658263248
Epoch #50: loss=0.0177617604094726
Epoch #51: loss=0.016039593644230077
Epoch #52: loss=0.01902303704848214
Epoch #53: loss=0.019777854260393784
Epoch #54: loss=0.021631881965200942
Epoch #55: loss=0.017084947676362844
Epoch #56: loss=0.014796578082635969
Epoch #57: loss=0.02148682933869614
Epoch #58: loss=0.016893469742444416
Epoch #59: loss=0.01591454685920971
Epoch #60: loss=0.016314676636542527
Epoch #61: loss=0.015166908780355362
Epoch #62: loss=0.015375261349309817
Epoch #63: loss=0.020557451817624094
Epoch #64: loss=0.01343843239993505
Epoch #65: loss=0.01783224839445906
Epoch #66: loss=0.019722533536630428
Epoch #67: loss=0.012006250897165822
Epoch #68: loss=0.01637009976636336
Epoch #69: loss=0.0176301830956531
Epoch #70: loss=0.021079022218679695
Epoch #71: loss=0.015150904508859472
Epoch #72: loss=0.01456420977759843
Epoch #73: loss=0.01726107852878786
Epoch #74: loss=0.013810169721433426
Epoch #75: loss=0.015877338512196998
Epoch #76: loss=0.01668573278744572
Epoch #77: loss=0.015575996043394956
Epoch #78: loss=0.016558172185886986
Epoch #79: loss=0.014981647419494207
Epoch #80: loss=0.015239815095266564
Epoch #81: loss=0.015795016933248748
Epoch #82: loss=0.016364827892602202
Epoch #83: loss=0.017908335278234284
Epoch #84: loss=0.01851052480053907
Epoch #85: loss=0.015846908988478656
Epoch #86: loss=0.016781922421176678
Epoch #87: loss=0.019078853074722537
Epoch #88: loss=0.015935433690006846
Epoch #89: loss=0.013074337927642614
Epoch #90: loss=0.015263741569052369
Epoch #91: loss=0.014116876213762996
Epoch #92: loss=0.017269464407915013
Epoch #93: loss=0.011905609451015622
Epoch #94: loss=0.01690717618956882
Epoch #95: loss=0.017364355893428676
Epoch #96: loss=0.01544035629862679
Epoch #97: loss=0.015182906444334477
Epoch #98: loss=0.011378798840643774
Epoch #99: loss=0.015622439226603363
Epoch #100: loss=0.01596886395374454
Epoch #101: loss=0.013351993733583496
Epoch #102: loss=0.017634796201133267
Epoch #103: loss=0.017566545179435684
Epoch #104: loss=0.01256261162424769
Epoch #105: loss=0.016411096742330954
Epoch #106: loss=0.012230619732150703
Epoch #107: loss=0.014753981915451655
Epoch #108: loss=0.01808608804473248
Epoch #109: loss=0.018032734119679567
Epoch #110: loss=0.013489777069227476
Epoch #111: loss=0.010972699988754251
Epoch #112: loss=0.01570683285752996
Epoch #113: loss=0.014861631552559689
Epoch #114: loss=0.01594291300457713
Epoch #115: loss=0.014795755001877808
Epoch #116: loss=0.010601020670961327
Epoch #117: loss=0.015252068993339146
Epoch #118: loss=0.015412147307084345
Epoch #119: loss=0.009938116111905251
Epoch #120: loss=0.02304425978208406
Epoch #121: loss=0.015778058921030066
Epoch #122: loss=0.009623269336110615
Epoch #123: loss=0.012390555731251739
Epoch #124: loss=0.010095907006518969
Epoch #125: loss=0.0169662042193906
Epoch #126: loss=0.012664981760333139
Epoch #127: loss=0.016421067487367706
Epoch #128: loss=0.017982507107753776
Epoch #129: loss=0.010965589222832197
Epoch #130: loss=0.011101163391280746
Epoch #131: loss=0.01534045391331801
Epoch #132: loss=0.012533601650426753
Epoch #133: loss=0.015184646716336672
Epoch #134: loss=0.010155823546723466
Epoch #135: loss=0.014753136292862205
Epoch #136: loss=0.011594904938874861
Epoch #137: loss=0.016806610088499353
Epoch #138: loss=0.01028497877967017
Epoch #139: loss=0.008849529640335045
Epoch #140: loss=0.01399693879796734
Epoch #141: loss=0.015510909209310367
Epoch #142: loss=0.009667102602112142
Epoch #143: loss=0.012886426375001512
Epoch #144: loss=0.011414385486423434
Epoch #145: loss=0.012520805534306447
Epoch #146: loss=0.009138973474655237
Epoch #147: loss=0.012860785258722657
Epoch #148: loss=0.014959848676221528
Epoch #149: loss=0.01230743148146387
Epoch #150: loss=0.011861625982235618
Epoch #151: loss=0.014591154175010635
Epoch #152: loss=0.015281129352439783
Epoch #153: loss=0.016722890218891263
Epoch #154: loss=0.008447245094083343
Epoch #155: loss=0.01234881108867524
Epoch #156: loss=0.011807085227442192
Epoch #157: loss=0.011269708006039386
Epoch #158: loss=0.015545674418322648
Epoch #159: loss=0.012662760642781544
Epoch #160: loss=0.012891995553193796
Epoch #161: loss=0.00945073556790351
Epoch #162: loss=0.015107344663104849
Epoch #163: loss=0.01356362422511941
Epoch #164: loss=0.011122439493796647
Epoch #165: loss=0.01614028920057464
Epoch #166: loss=0.008912080856793096
Epoch #167: loss=0.014721506795381832
Epoch #168: loss=0.00802430154052908
Epoch #169: loss=0.012436273163819516
Epoch #170: loss=0.011360895769381462
Epoch #171: loss=0.01017056170410809
Epoch #172: loss=0.012953567643039447
Epoch #173: loss=0.014061640210506989
Epoch #174: loss=0.010127815215002514
Epoch #175: loss=0.011524937248569402
Epoch #176: loss=0.012661426616645774
Epoch #177: loss=0.012600920690659087
Epoch #178: loss=0.012837075832687677
Epoch #179: loss=0.011947054914724057
Epoch #180: loss=0.012595606629911672
Epoch #181: loss=0.009155189273958633
Epoch #182: loss=0.01298175725499121
Epoch #183: loss=0.012679004304486773
Epoch #184: loss=0.01061818753354127
Epoch #185: loss=0.009555642824986763
Epoch #186: loss=0.010765099178175348
Epoch #187: loss=0.012909426273452485
Epoch #188: loss=0.01215896941122255
Epoch #189: loss=0.013776629368373998
Epoch #190: loss=0.013343975976852681
Epoch #191: loss=0.011717299399206281
Epoch #192: loss=0.007617788318827564
Epoch #193: loss=0.009176817092247904
Epoch #194: loss=0.019776235142199183
Epoch #195: loss=0.011639606333497126
Epoch #196: loss=0.009457702456157083
Epoch #197: loss=0.007850366259482664
Epoch #198: loss=0.014834086847781359
Epoch #199: loss=0.012623931120266598
Epoch #200: loss=0.008044786220215216
Epoch #201: loss=0.011301775453028172
Epoch #202: loss=0.012715649893072273
Epoch #203: loss=0.011198935351277285
Epoch #204: loss=0.012888225299012497
Epoch #205: loss=0.007663789702500723
Epoch #206: loss=0.012411555663772217
Epoch #207: loss=0.012459445720370057
Epoch #208: loss=0.01036723506756983
Epoch #209: loss=0.00982360772514929
Epoch #210: loss=0.01857278229272911
Epoch #211: loss=0.009360867242067378
Epoch #212: loss=0.009711921825795824
Epoch #213: loss=0.011914111354147104
Epoch #214: loss=0.00870820350772398
Epoch #215: loss=0.01077293391976368
Epoch #216: loss=0.010224992318821612
Epoch #217: loss=0.006995165815841746
Epoch #218: loss=0.010854994424842335
Epoch #219: loss=0.011051038447239642
Epoch #220: loss=0.01388476262628255
Epoch #221: loss=0.009424326992678306
Epoch #222: loss=0.011363889418992367
Epoch #223: loss=0.012405963603542505
Epoch #224: loss=0.014980143478712382
Epoch #225: loss=0.009285774360358998
Epoch #226: loss=0.011457593001173882
Epoch #227: loss=0.009744812328278011
Epoch #228: loss=0.010648139943321044
Epoch #229: loss=0.011162549222654358
Epoch #230: loss=0.011185231119522738
Epoch #231: loss=0.009232417478311182
Epoch #232: loss=0.01587617565053062
Epoch #233: loss=0.00932377108236734
Epoch #234: loss=0.01008141488622086
Epoch #235: loss=0.016344901270633688
Epoch #236: loss=0.011629820568405388
Epoch #237: loss=0.015230282471584748
Epoch #238: loss=0.007912343951154085
Epoch #239: loss=0.006250059805952802
Epoch #240: loss=0.012925017706443729
Epoch #241: loss=0.011002088576314451
Epoch #242: loss=0.009304773990764625
Epoch #243: loss=0.00970354055591943
Epoch #244: loss=0.009601865612710205
Epoch #245: loss=0.011441889815679887
Epoch #246: loss=0.008123175774402846
Epoch #247: loss=0.009437521561273329
Epoch #248: loss=0.00643512526501961
Epoch #249: loss=0.010740534134714014

Training time: 3:31:08.414739

Finished.
n2one setting etth1_ettm1_ettm2_traffic -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_ettm2_traffic_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_ettm1_ettm2_traffic', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.0278e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.15976e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.0278e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.39302687116820506, 'MAE': 0.44352182273935326}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm1_ettm2_traffic -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_ettm2_traffic_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_ettm1_ettm2_traffic', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.07289e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.34959e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.07289e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.7637938632626838, 'MAE': 0.6916363119234605}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm1_ettm2_traffic -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_ettm2_traffic_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_ettm1_ettm2_traffic', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
Evaluation result: {'MSE': 0.2919272944060919, 'MAE': 0.3566547198605235}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm1_ettm2_weather', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm1_ettm2_weather_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=4.357806977358732
Epoch #1: loss=2.3420886061408304
Epoch #2: loss=2.261609859900041
Epoch #3: loss=1.9388246081092142
Epoch #4: loss=1.6249957193027844
Epoch #5: loss=1.5443920547311956
Epoch #6: loss=1.39687932621349
Epoch #7: loss=1.3015692309899765
Epoch #8: loss=1.2479257561943748
Epoch #9: loss=1.1696358106353066
Epoch #10: loss=1.0300943732261658
Epoch #11: loss=1.0714618780396201
Epoch #12: loss=0.9963615449992094
Epoch #13: loss=0.8903288787061517
Epoch #14: loss=0.8150440161878413
Epoch #15: loss=0.8335877342657609
Epoch #16: loss=0.8657835451039401
Epoch #17: loss=0.732301909273321
Epoch #18: loss=0.7644284974444996
Epoch #19: loss=0.6805024363777854
Epoch #20: loss=0.7502982963215221
Epoch #21: loss=0.7172466180541298
Epoch #22: loss=0.6949434432116421
Epoch #23: loss=0.8308025479316712
Epoch #24: loss=0.7239919852126728
Epoch #25: loss=0.8928604516116055
Epoch #26: loss=0.602377470514991
Epoch #27: loss=0.7128073963251981
Epoch #28: loss=0.5486232475800947
Epoch #29: loss=0.6182154173200781
Epoch #30: loss=0.6057142360643907
Epoch #31: loss=0.5379612971435893
Epoch #32: loss=0.5047137878157876
Epoch #33: loss=0.47920268015428025
Epoch #34: loss=0.50472129908475
Epoch #35: loss=0.5168936312198639
Epoch #36: loss=0.518646945736625
Epoch #37: loss=0.4545590010556308
Epoch #38: loss=0.45390030633319506
Epoch #39: loss=0.44268225756558505
Epoch #40: loss=0.41208536245606164
Epoch #41: loss=0.42400849759578707
Epoch #42: loss=0.39895150336352264
Epoch #43: loss=0.3677349239587784
Epoch #44: loss=0.4369576876813715
Epoch #45: loss=0.37902009730989283
Epoch #46: loss=0.3654498268257488
Epoch #47: loss=0.4460825191302733
Epoch #48: loss=0.3578470224683935
Epoch #49: loss=0.35988327291878786
Epoch #50: loss=0.33471664136106316
Epoch #51: loss=0.3247132163156163
Epoch #52: loss=0.3356261483647607
Epoch #53: loss=0.3000850298187949
Epoch #54: loss=0.39243876012888823
Epoch #55: loss=0.3469474665143273
Epoch #56: loss=0.3246225427497517
Epoch #57: loss=0.3031169371171431
Epoch #58: loss=0.25179082453250884
Epoch #59: loss=0.2804091282866218
Epoch #60: loss=0.2611497858708555
Epoch #61: loss=0.23484200523658233
Epoch #62: loss=0.2800927048379725
Epoch #63: loss=0.28828257701613685
Epoch #64: loss=0.21634223393418572
Epoch #65: loss=0.25433152900500733
Epoch #66: loss=0.2493284285068512
Epoch #67: loss=0.22518018037080764
Epoch #68: loss=0.19356264038519425
Epoch #69: loss=0.21169968396425248
Epoch #70: loss=0.23867414173754778
Epoch #71: loss=0.22391508465463464
Epoch #72: loss=0.22543116225437684
Epoch #73: loss=0.2386754940856587
Epoch #74: loss=0.22371966608545996
Epoch #75: loss=0.21357683607123115
Epoch #76: loss=0.17052774930542167
Epoch #77: loss=0.20855390063740992
Epoch #78: loss=0.18891887813806535
Epoch #79: loss=0.15671518228270792
Epoch #80: loss=0.19064232415773652
Epoch #81: loss=0.16128264116969976
Epoch #82: loss=0.16741952706467023
Epoch #83: loss=0.14991316483779388
Epoch #84: loss=0.15508376190608197
Epoch #85: loss=0.15260053690184247
Epoch #86: loss=0.2658652912486683
Epoch #87: loss=0.18557534658096053
Epoch #88: loss=0.13963113129138946
Epoch #89: loss=0.14897041801701894
Epoch #90: loss=0.1643965757028623
Epoch #91: loss=0.19768912853165108
Epoch #92: loss=0.1209756248715249
Epoch #93: loss=0.11642329814759168
Epoch #94: loss=0.12900326956402172
Epoch #95: loss=0.16723351634361527
Epoch #96: loss=0.20174752568656748
Epoch #97: loss=0.17710102037949996
Epoch #98: loss=0.1506094861436974
Epoch #99: loss=0.1729427074844187
Epoch #100: loss=0.15228772447867828
Epoch #101: loss=0.10625680979679931
Epoch #102: loss=0.12218287113037976
Epoch #103: loss=0.16206086989153515
Epoch #104: loss=0.15439742312512614
Epoch #105: loss=0.12922406020489605
Epoch #106: loss=0.0992825648324056
Epoch #107: loss=0.11960147998549721
Epoch #108: loss=0.1291848939589479
Epoch #109: loss=0.1634568650275469
Epoch #110: loss=0.10229349674826319
Epoch #111: loss=0.10320484868504784
Epoch #112: loss=0.10125142718580636
Epoch #113: loss=0.12921310737729072
Epoch #114: loss=0.11318382935767823
Epoch #115: loss=0.16071102974767035
Epoch #116: loss=0.22104736603796482
Epoch #117: loss=0.396643282066692
Epoch #118: loss=0.20961067906834863
Epoch #119: loss=0.3247683428905227
Epoch #120: loss=0.1596389391882853
Epoch #121: loss=0.13136491281065074
Epoch #122: loss=0.14291616007685662
Epoch #123: loss=0.09990976158190858
Epoch #124: loss=0.12980388423258607
Epoch #125: loss=0.09087606661699035
Epoch #126: loss=0.14022466997531327
Epoch #127: loss=0.10187916579571638
Epoch #128: loss=0.07959784421731125
Epoch #129: loss=0.07919045232913711
Epoch #130: loss=0.07500440908426588
Epoch #131: loss=0.07144634471359577
Epoch #132: loss=0.11777345165610313
Epoch #133: loss=0.10301428105343471
Epoch #134: loss=0.11793877011673017
Epoch #135: loss=0.12571375019509684
Epoch #136: loss=0.15531932105394927
Epoch #137: loss=0.13926562504334883
Epoch #138: loss=0.14232682575556366
Epoch #139: loss=0.10129135400056839
Epoch #140: loss=0.07267173386432908
Epoch #141: loss=0.08984014324166557
Epoch #142: loss=0.07379088767550208
Epoch #143: loss=0.07874598652124405
Epoch #144: loss=0.08918429724872112
Epoch #145: loss=0.07182258706201207
Epoch #146: loss=0.06595910606397824
Epoch #147: loss=0.07641914754428647
Epoch #148: loss=0.09948930821635506
Epoch #149: loss=0.07127525262873281
Epoch #150: loss=0.05711212965913794
Epoch #151: loss=0.06595795985988595
Epoch #152: loss=0.07026120105927641
Epoch #153: loss=0.07305413596332073
Epoch #154: loss=0.08992750465192578
Epoch #155: loss=0.06945469467477365
Epoch #156: loss=0.08092422351579774
Epoch #157: loss=0.07401523483409123
Epoch #158: loss=0.06325911413878202
Epoch #159: loss=0.08496843198822303
Epoch #160: loss=0.12702580646357753
Epoch #161: loss=0.09482780759307471
Epoch #162: loss=0.11262722858651118
Epoch #163: loss=0.10770956501364708
Epoch #164: loss=0.08678790805014697
Epoch #165: loss=0.07882036378776486
Epoch #166: loss=0.0629623639989983
Epoch #167: loss=0.05657555479556322
Epoch #168: loss=0.05915506951172243
Epoch #169: loss=0.06816869278184393
Epoch #170: loss=0.06453991120850498
Epoch #171: loss=0.05397773024372079
Epoch #172: loss=0.055132951435040344
Epoch #173: loss=0.12780369740318168
Epoch #174: loss=0.06124272778291594
Epoch #175: loss=0.08266225348819387
Epoch #176: loss=0.0788719120350751
Epoch #177: loss=0.07805557543919846
Epoch #178: loss=0.08787000143731183
Epoch #179: loss=0.06228751392865723
Epoch #180: loss=0.07795781207016923
Epoch #181: loss=0.08425903344018892
Epoch #182: loss=0.06519085597246885
Epoch #183: loss=0.07358014075593515
Epoch #184: loss=0.10362078704955903
Epoch #185: loss=0.0874436472796581
Epoch #186: loss=0.08699932652102275
Epoch #187: loss=0.08370651352134618
Epoch #188: loss=0.054324388063766736
Epoch #189: loss=0.05931383240121332
Epoch #190: loss=0.06322674044323238
Epoch #191: loss=0.13218051086772573
Epoch #192: loss=0.10784337571398779
Epoch #193: loss=0.11617155925116755
Epoch #194: loss=0.1299642027779059
Epoch #195: loss=0.1428714677014134
Epoch #196: loss=0.12306668236851692
Epoch #197: loss=0.1380979545922442
Epoch #198: loss=0.1007830530574376
Epoch #199: loss=0.07213496062904597
Epoch #200: loss=0.05643713484433564
Epoch #201: loss=0.056704931706190106
Epoch #202: loss=0.1292472575029189
Epoch #203: loss=0.06674696215513078
Epoch #204: loss=0.05154188314283436
Epoch #205: loss=0.0534578266214918
Epoch #206: loss=0.04358642817559567
Epoch #207: loss=0.04625483825802803
Epoch #208: loss=0.044878201482986865
Epoch #209: loss=0.08937902555546977
Epoch #210: loss=0.08587430635975166
Epoch #211: loss=0.05872742879119786
Epoch #212: loss=0.05422634682194753
Epoch #213: loss=0.054243513450703836
Epoch #214: loss=0.051445808879692446
Epoch #215: loss=0.04679056807336482
Epoch #216: loss=0.03964293150400573
Epoch #217: loss=0.0640809811313044
Epoch #218: loss=0.042783008558167655
Epoch #219: loss=0.0772225922820243
Epoch #220: loss=0.04723154225979339
Epoch #221: loss=0.04029543741860173
Epoch #222: loss=0.04303021772171963
Epoch #223: loss=0.040786627476865595
Epoch #224: loss=0.03852799682115966
Epoch #225: loss=0.0622490155341273
Epoch #226: loss=0.0540432811122049
Epoch #227: loss=0.0623288806527853
Epoch #228: loss=0.04230270914056084
Epoch #229: loss=0.09770848860286853
Epoch #230: loss=0.07015221115540374
Epoch #231: loss=0.11440974792296237
Epoch #232: loss=0.058302303395149385
Epoch #233: loss=0.05282083984295076
Epoch #234: loss=0.058990171153775674
Epoch #235: loss=0.05793136109343984
Epoch #236: loss=0.07108957323838364
Epoch #237: loss=0.06832427704198794
Epoch #238: loss=0.05225780653682622
Epoch #239: loss=0.05968110784888268
Epoch #240: loss=0.06691070243885572
Epoch #241: loss=0.08163959680294448
Epoch #242: loss=0.06284522781656547
Epoch #243: loss=0.04051801853559234
Epoch #244: loss=0.04453261869705536
Epoch #245: loss=0.06318414471196858
Epoch #246: loss=0.03150926542214372
Epoch #247: loss=0.04307659174400297
Epoch #248: loss=0.036729705418375405
Epoch #249: loss=0.05826888586479154

Training time: 0:19:06.002522

Finished.
n2one setting etth1_ettm1_ettm2_weather -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_ettm2_weather_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_ettm1_ettm2_weather', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.32685e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.59233e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.32685e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3659031022244622, 'MAE': 0.42705542825615506}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm1_ettm2_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_ettm2_weather_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_ettm1_ettm2_weather', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.15685e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.22505764301505748, 'MAE': 0.3240067707260325}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm1_ettm2_exchange', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm1_ettm2_exchange_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=3.8082760153590023
Epoch #1: loss=2.2833130810711837
Epoch #2: loss=1.9763065447678436
Epoch #3: loss=1.7984648588541392
Epoch #4: loss=1.6094521412978302
Epoch #5: loss=1.5366112605945483
Epoch #6: loss=1.487502027202297
Epoch #7: loss=1.3634930559106775
Epoch #8: loss=1.2086217451739956
Epoch #9: loss=1.2061222614468754
Epoch #10: loss=1.1028583468617619
Epoch #11: loss=1.0621768461691368
Epoch #12: loss=1.0336525295231793
Epoch #13: loss=0.9656164307852049
Epoch #14: loss=0.929251851262273
Epoch #15: loss=0.9008754701227755
Epoch #16: loss=0.8894133664466239
Epoch #17: loss=0.8552618203936396
Epoch #18: loss=0.8204832544197908
Epoch #19: loss=0.79387582314981
Epoch #20: loss=0.7377485987302419
Epoch #21: loss=0.6649417724158313
Epoch #22: loss=0.7563068753964192
Epoch #23: loss=0.6843682189245481
Epoch #24: loss=0.6504202195115991
Epoch #25: loss=0.7164923492315654
Epoch #26: loss=0.765385156547701
Epoch #27: loss=0.8190880836667241
Epoch #28: loss=0.7287415459349349
Epoch #29: loss=0.618338480994508
Epoch #30: loss=0.5985966993344797
Epoch #31: loss=0.5860330438291704
Epoch #32: loss=0.5565175083843438
Epoch #33: loss=0.5646110088438601
Epoch #34: loss=0.585564864648355
Epoch #35: loss=0.6500289697904844
Epoch #36: loss=0.6155386792646872
Epoch #37: loss=0.5907188694219332
Epoch #38: loss=0.5436759784414962
Epoch #39: loss=0.5145393682492746
Epoch #40: loss=0.6189190769517744
Epoch #41: loss=0.5992442031164427
Epoch #42: loss=0.5208626163972391
Epoch #43: loss=0.47206919096611644
Epoch #44: loss=0.48498492949717753
Epoch #45: loss=0.46768488352363174
Epoch #46: loss=0.45887616397561254
Epoch #47: loss=0.4799446487748945
Epoch #48: loss=0.6086386329418904
Epoch #49: loss=0.5559466916161615
Epoch #50: loss=0.5245150287409086
Epoch #51: loss=0.5265251277266322
Epoch #52: loss=0.5054888395038811
Epoch #53: loss=0.4387541211940147
Epoch #54: loss=0.4382592834330894
Epoch #55: loss=0.3841911336860141
Epoch #56: loss=0.37434462115571304
Epoch #57: loss=0.34349030054904317
Epoch #58: loss=0.3268727305773142
Epoch #59: loss=0.37041201140429525
Epoch #60: loss=0.3889750077112301
Epoch #61: loss=0.3258113051588471
Epoch #62: loss=0.45158097872862946
Epoch #63: loss=0.30624196940177195
Epoch #64: loss=0.32114927712324504
Epoch #65: loss=0.3360678311940786
Epoch #66: loss=0.2818482308774381
Epoch #67: loss=0.36018751440821467
Epoch #68: loss=0.3346084263679144
Epoch #69: loss=0.3614217264426721
Epoch #70: loss=0.3014052266607413
Epoch #71: loss=0.42841311524043213
Epoch #72: loss=0.3345821336717219
Epoch #73: loss=0.3090123469765122
Epoch #74: loss=0.2736562625379176
Epoch #75: loss=0.3245069491299423
Epoch #76: loss=0.31269800381080526
Epoch #77: loss=0.2968398286281405
Epoch #78: loss=0.39405027575589513
Epoch #79: loss=0.36398078541497925
Epoch #80: loss=0.3736348826740239
Epoch #81: loss=0.260665802335417
Epoch #82: loss=0.32003392299284805
Epoch #83: loss=0.21024493671752312
Epoch #84: loss=0.22360695012517878
Epoch #85: loss=0.21898293555588336
Epoch #86: loss=0.28373103145812006
Epoch #87: loss=0.2808477139553508
Epoch #88: loss=0.22336411677502296
Epoch #89: loss=0.26647709138892794
Epoch #90: loss=0.21853700692991954
Epoch #91: loss=0.21590799415433728
Epoch #92: loss=0.18685320200952324
Epoch #93: loss=0.1800752224753032
Epoch #94: loss=0.17503752116415952
Epoch #95: loss=0.2865486575945004
Epoch #96: loss=0.18154596094344114
Epoch #97: loss=0.20599334797746427
Epoch #98: loss=0.2781533274698902
Epoch #99: loss=0.34033151232712977
Epoch #100: loss=0.2103958473213621
Epoch #101: loss=0.28462813734202774
Epoch #102: loss=0.21213689506859393
Epoch #103: loss=0.21056703206252408
Epoch #104: loss=0.20523324065111778
Epoch #105: loss=0.20468787516693812
Epoch #106: loss=0.1604392871864744
Epoch #107: loss=0.14725565477400213
Epoch #108: loss=0.15204105657097455
Epoch #109: loss=0.1272658008477978
Epoch #110: loss=0.14037791579156308
Epoch #111: loss=0.19623602272288218
Epoch #112: loss=0.23432839349717707
Epoch #113: loss=0.18413063712619446
Epoch #114: loss=0.186858197724497
Epoch #115: loss=0.17743470504678585
Epoch #116: loss=0.1882210662840186
Epoch #117: loss=0.17368023258608742
Epoch #118: loss=0.1743691572667779
Epoch #119: loss=0.16088239496221413
Epoch #120: loss=0.22646860526622953
Epoch #121: loss=0.27402114515771736
Epoch #122: loss=0.190738826688077
Epoch #123: loss=0.19749848766101374
Epoch #124: loss=0.18287188388608597
Epoch #125: loss=0.15941835517013395
Epoch #126: loss=0.16580905976730423
Epoch #127: loss=0.11589072639676365
Epoch #128: loss=0.11665734245970442
Epoch #129: loss=0.21457318568954598
Epoch #130: loss=0.22734675999428774
Epoch #131: loss=0.173916631051012
Epoch #132: loss=0.12390816513751005
Epoch #133: loss=0.18303109302714066
Epoch #134: loss=0.14658795845871037
Epoch #135: loss=0.15019944753195788
Epoch #136: loss=0.19310464594211127
Epoch #137: loss=0.13499676365707372
Epoch #138: loss=0.12607546085240068
Epoch #139: loss=0.1879768766261436
Epoch #140: loss=0.20028740097139333
Epoch #141: loss=0.14193764177931323
Epoch #142: loss=0.20443327800446265
Epoch #143: loss=0.12234407149859376
Epoch #144: loss=0.12352125135225218
Epoch #145: loss=0.15005859128526738
Epoch #146: loss=0.1606506028187436
Epoch #147: loss=0.16122769337852258
Epoch #148: loss=0.13323791722792225
Epoch #149: loss=0.18894261509381435
Epoch #150: loss=0.14272263283665115
Epoch #151: loss=0.14476834881950068
Epoch #152: loss=0.12437248270253877
Epoch #153: loss=0.14755571155330618
Epoch #154: loss=0.12451027665992041
Epoch #155: loss=0.17273609999667955
Epoch #156: loss=0.12902079044362982
Epoch #157: loss=0.12767110276665236
Epoch #158: loss=0.2683275752776378
Epoch #159: loss=0.15799092813520818
Epoch #160: loss=0.15759081388446125
Epoch #161: loss=0.12119387724512332
Epoch #162: loss=0.1483031083401796
Epoch #163: loss=0.1221856085734593
Epoch #164: loss=0.1515417027513723
Epoch #165: loss=0.13389980475846175
Epoch #166: loss=0.12208594316364946
Epoch #167: loss=0.10456664779701748
Epoch #168: loss=0.12488764031110583
Epoch #169: loss=0.11097035748330322
Epoch #170: loss=0.09717303801428627
Epoch #171: loss=0.11559933831764234
Epoch #172: loss=0.14420206160158724
Epoch #173: loss=0.12129675116188623
Epoch #174: loss=0.133453573276465
Epoch #175: loss=0.11088237045584498
Epoch #176: loss=0.09603040839067183
Epoch #177: loss=0.10484065870578224
Epoch #178: loss=0.1048366320697037
Epoch #179: loss=0.14350015911701564
Epoch #180: loss=0.14484296386709083
Epoch #181: loss=0.15601916772288246
Epoch #182: loss=0.1757152595028684
Epoch #183: loss=0.1610883270969262
Epoch #184: loss=0.12079952896346112
Epoch #185: loss=0.13298246289628582
Epoch #186: loss=0.0913573549305265
Epoch #187: loss=0.10747009062686481
Epoch #188: loss=0.0882650314754731
Epoch #189: loss=0.0959218913638914
Epoch #190: loss=0.11282705933459707
Epoch #191: loss=0.11351618442583729
Epoch #192: loss=0.07107653033391044
Epoch #193: loss=0.07461903453175281
Epoch #194: loss=0.08071523313284726
Epoch #195: loss=0.09256628042439351
Epoch #196: loss=0.09869758429861553
Epoch #197: loss=0.08486850096567257
Epoch #198: loss=0.09829356239454166
Epoch #199: loss=0.09929084219038486
Epoch #200: loss=0.11978621282488913
Epoch #201: loss=0.11465734104953103
Epoch #202: loss=0.10210321818453234
Epoch #203: loss=0.11548814086897953
Epoch #204: loss=0.14743007075142217
Epoch #205: loss=0.10987032013567719
Epoch #206: loss=0.12621761795536085
Epoch #207: loss=0.11675989882064026
Epoch #208: loss=0.10156553042297428
Epoch #209: loss=0.10604528732899879
Epoch #210: loss=0.08818346717571085
Epoch #211: loss=0.08544909120914904
Epoch #212: loss=0.10939962812070106
Epoch #213: loss=0.07339870582359868
Epoch #214: loss=0.13731160274127852
Epoch #215: loss=0.12828039420718276
Epoch #216: loss=0.08994537028106483
Epoch #217: loss=0.12615165919870944
Epoch #218: loss=0.1080169965437538
Epoch #219: loss=0.1616483708793247
Epoch #220: loss=0.13572117175302795
Epoch #221: loss=0.1041202887489989
Epoch #222: loss=0.11925653959750324
Epoch #223: loss=0.08666895604314837
Epoch #224: loss=0.07502078813676899
Epoch #225: loss=0.10097471405626149
Epoch #226: loss=0.08492113138876252
Epoch #227: loss=0.09905549669889985
Epoch #228: loss=0.11791103305546818
Epoch #229: loss=0.17068008489504055
Epoch #230: loss=0.14035996719187982
Epoch #231: loss=0.09748658097374278
Epoch #232: loss=0.10129446397862725
Epoch #233: loss=0.09230873200136262
Epoch #234: loss=0.0678337086998933
Epoch #235: loss=0.08419588253506131
Epoch #236: loss=0.11867808011939397
Epoch #237: loss=0.274655733710608
Epoch #238: loss=0.14855694066028338
Epoch #239: loss=0.13045270564789707
Epoch #240: loss=0.11097763639849585
Epoch #241: loss=0.10289521840073772
Epoch #242: loss=0.11085603076561883
Epoch #243: loss=0.10406623277309779
Epoch #244: loss=0.08616137021296733
Epoch #245: loss=0.16303615893765883
Epoch #246: loss=0.09452276344637613
Epoch #247: loss=0.10055878944694996
Epoch #248: loss=0.08056098449270467
Epoch #249: loss=0.11770814813270762

Training time: 0:11:19.706637

Finished.
n2one setting etth1_ettm1_ettm2_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_ettm2_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_ettm1_ettm2_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.36612e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.68106e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.36612e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3704962098064226, 'MAE': 0.4328365479205019}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm1_ettm2_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_ettm2_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_ettm1_ettm2_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.33455e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.79588e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.79588e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.6714443849071399, 'MAE': 0.5869681182513824}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm1_electricity_traffic', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm1_electricity_traffic_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.8288596355101151
Epoch #1: loss=0.2896942900591448
Epoch #2: loss=0.18755345965900785
Epoch #3: loss=0.13715777699707649
Epoch #4: loss=0.12388953814852198
Epoch #5: loss=0.10202008342179629
Epoch #6: loss=0.07688230624209956
Epoch #7: loss=0.07218569590803933
Epoch #8: loss=0.06069252537416107
Epoch #9: loss=0.05063806230560578
Epoch #10: loss=0.05084242469624932
Epoch #11: loss=0.04654065533975398
Epoch #12: loss=0.041710131219297425
Epoch #13: loss=0.04768603570432829
Epoch #14: loss=0.03729685772129712
Epoch #15: loss=0.03738717569011519
Epoch #16: loss=0.04051966272212323
Epoch #17: loss=0.03201522254117522
Epoch #18: loss=0.028342411301054565
Epoch #19: loss=0.028769853136651095
Epoch #20: loss=0.03296977005915237
Epoch #21: loss=0.03024030939338932
Epoch #22: loss=0.02507708142655006
Epoch #23: loss=0.027335283036679526
Epoch #24: loss=0.025536729544645437
Epoch #25: loss=0.024485599042942358
Epoch #26: loss=0.02281178033222087
Epoch #27: loss=0.022672014488147683
Epoch #28: loss=0.026615095653219907
Epoch #29: loss=0.02416919363488317
Epoch #30: loss=0.027275134968526002
Epoch #31: loss=0.019511389459196796
Epoch #32: loss=0.021145739132814888
Epoch #33: loss=0.017239000109027448
Epoch #34: loss=0.02374862076617315
Epoch #35: loss=0.0203619998026293
Epoch #36: loss=0.017004059083306336
Epoch #37: loss=0.02455420126710886
Epoch #38: loss=0.022815045504821083
Epoch #39: loss=0.014878924969013014
Epoch #40: loss=0.017481818462993994
Epoch #41: loss=0.01920963247208998
Epoch #42: loss=0.01822110226119618
Epoch #43: loss=0.017794093311733088
Epoch #44: loss=0.018731659165396278
Epoch #45: loss=0.016974758033056765
Epoch #46: loss=0.021212097963549507
Epoch #47: loss=0.01747524496015715
Epoch #48: loss=0.021736830933421592
Epoch #49: loss=0.017754882387729667
Epoch #50: loss=0.018530014786349927
Epoch #51: loss=0.018235714967129172
Epoch #52: loss=0.014800032633959667
Epoch #53: loss=0.01570310715185945
Epoch #54: loss=0.014894951446895736
Epoch #55: loss=0.014749060103229667
Epoch #56: loss=0.024279233351026854
Epoch #57: loss=0.020997199565813886
Epoch #58: loss=0.027393545593233155
Epoch #59: loss=0.015084986297140746
Epoch #60: loss=0.014940383087377995
Epoch #61: loss=0.01942252325271427
Epoch #62: loss=0.013596460515496357
Epoch #63: loss=0.012979212927108214
Epoch #64: loss=0.021322707850145808
Epoch #65: loss=0.01317998869688216
Epoch #66: loss=0.01925287209131323
Epoch #67: loss=0.014109257852799569
Epoch #68: loss=0.010976776218449474
Epoch #69: loss=0.01169354707928534
Epoch #70: loss=0.01569720827568234
Epoch #71: loss=0.017777386822754815
Epoch #72: loss=0.01291810401540279
Epoch #73: loss=0.011262305920370167
Epoch #74: loss=0.014397834092875877
Epoch #75: loss=0.014686331859913668
Epoch #76: loss=0.01454074814874267
Epoch #77: loss=0.012487246378962352
Epoch #78: loss=0.01585121963448535
Epoch #79: loss=0.013150288645693951
Epoch #80: loss=0.014343977918677602
Epoch #81: loss=0.012664649410113782
Epoch #82: loss=0.013932341616435967
Epoch #83: loss=0.017541372776899034
Epoch #84: loss=0.010459012182177992
Epoch #85: loss=0.016739218245265457
Epoch #86: loss=0.009850880299811349
Epoch #87: loss=0.014246457438511955
Epoch #88: loss=0.016652189201577842
Epoch #89: loss=0.010446465552431573
Epoch #90: loss=0.011551124302934597
Epoch #91: loss=0.016380448831037092
Epoch #92: loss=0.011097662441546759
Epoch #93: loss=0.018934860052190975
Epoch #94: loss=0.0106863686373379
Epoch #95: loss=0.014833257171750627
Epoch #96: loss=0.015905411795116002
Epoch #97: loss=0.013371319265095525
Epoch #98: loss=0.0102409163755798
Epoch #99: loss=0.01292962975398545
Epoch #100: loss=0.01013809690513372
Epoch #101: loss=0.012280873445572788
Epoch #102: loss=0.013969363660422106
Epoch #103: loss=0.014369326835789203
Epoch #104: loss=0.010028319542767708
Epoch #105: loss=0.010091344591978081
Epoch #106: loss=0.01589079843170543
Epoch #107: loss=0.010717306529795715
Epoch #108: loss=0.013037111128712977
Epoch #109: loss=0.010974997818614624
Epoch #110: loss=0.012731597818418535
Epoch #111: loss=0.014492366148474324
Epoch #112: loss=0.011473238316059639
Epoch #113: loss=0.013171900458654061
Epoch #114: loss=0.011082673637911489
Epoch #115: loss=0.013952520940218045
Epoch #116: loss=0.0109563228143603
Epoch #117: loss=0.014464554733537227
Epoch #118: loss=0.015014265875694002
Epoch #119: loss=0.008062253094007448
Epoch #120: loss=0.010679379763069747
Epoch #121: loss=0.011903576095482172
Epoch #122: loss=0.008587032079107406
Epoch #123: loss=0.012683781677600947
Epoch #124: loss=0.010471781231169494
Epoch #125: loss=0.008762114132553322
Epoch #126: loss=0.013482169169866883
Epoch #127: loss=0.01176985692570946
Epoch #128: loss=0.008978580446605546
Epoch #129: loss=0.015631200345607422
Epoch #130: loss=0.008718645231757386
Epoch #131: loss=0.01325650749637743
Epoch #132: loss=0.010168478313427234
Epoch #133: loss=0.010467059243405291
Epoch #134: loss=0.008505285856607998
Epoch #135: loss=0.007893239452533573
Epoch #136: loss=0.01118982944174299
Epoch #137: loss=0.011122619870663942
Epoch #138: loss=0.009673034659475303
Epoch #139: loss=0.011307917384660592
Epoch #140: loss=0.00979810282364819
Epoch #141: loss=0.011752066993402538
Epoch #142: loss=0.011695276675316436
Epoch #143: loss=0.01036716275596425
Epoch #144: loss=0.012169552850973197
Epoch #145: loss=0.007646861414419356
Epoch #146: loss=0.010258309521432132
Epoch #147: loss=0.010708687980797918
Epoch #148: loss=0.01874102839304318
Epoch #149: loss=0.00889992225191063
Epoch #150: loss=0.009553272175229137
Epoch #151: loss=0.008031251587458424
Epoch #152: loss=0.014913779246296305
Epoch #153: loss=0.012691081023305309
Epoch #154: loss=0.007711730374211948
Epoch #155: loss=0.012899581216027352
Epoch #156: loss=0.00927247592159039
Epoch #157: loss=0.01555992081185051
Epoch #158: loss=0.010618709523077542
Epoch #159: loss=0.00843280426477586
Epoch #160: loss=0.00974430171126786
Epoch #161: loss=0.013874865833115304
Epoch #162: loss=0.022055803460246288
Epoch #163: loss=0.009713394354156383
Epoch #164: loss=0.01087700651972543
Epoch #165: loss=0.007941534694162164
Epoch #166: loss=0.01333801512855848
Epoch #167: loss=0.009026854763652347
Epoch #168: loss=0.009289455139268186
Epoch #169: loss=0.013181296377324521
Epoch #170: loss=0.016249530488053464
Epoch #171: loss=0.009023605256098001
Epoch #172: loss=0.010529667965556088
Epoch #173: loss=0.008925248527114526
Epoch #174: loss=0.013130006213995437
Epoch #175: loss=0.009183901739053271
Epoch #176: loss=0.008736409390841313
Epoch #177: loss=0.01124800581291266
Epoch #178: loss=0.012241589944952358
Epoch #179: loss=0.00971205052155256
Epoch #180: loss=0.011494264747514362
Epoch #181: loss=0.00718207973585081
Epoch #182: loss=0.009177451089477907
Epoch #183: loss=0.009204219662347475
Epoch #184: loss=0.009179275935008032
Epoch #185: loss=0.02312948398153535
Epoch #186: loss=0.009574081954564937
Epoch #187: loss=0.008580562911358128
Epoch #188: loss=0.009614897327213882
Epoch #189: loss=0.010941646259748567
Epoch #190: loss=0.011081380300665546
Epoch #191: loss=0.010976152785987901
Epoch #192: loss=0.009559598987056276
Epoch #193: loss=0.010239564197319312
Epoch #194: loss=0.013503833119467647
Epoch #195: loss=0.009052206728899472
Epoch #196: loss=0.008579979452553317
Epoch #197: loss=0.008883054317193516
Epoch #198: loss=0.011338813613797693
Epoch #199: loss=0.010216191296656796
Epoch #200: loss=0.009105864887287278
Epoch #201: loss=0.009603443686888851
Epoch #202: loss=0.009469819807968023
Epoch #203: loss=0.009040098959374762
Epoch #204: loss=0.010032779684586999
Epoch #205: loss=0.008693413678817458
Epoch #206: loss=0.010546732608174252
Epoch #207: loss=0.008693912268501297
Epoch #208: loss=0.010656041938238891
Epoch #209: loss=0.01172643255168948
Epoch #210: loss=0.007706194764482874
Epoch #211: loss=0.010787769614579853
Epoch #212: loss=0.010426785707145553
Epoch #213: loss=0.008524167707807277
Epoch #214: loss=0.008830941566199237
Epoch #215: loss=0.009938374329109708
Epoch #216: loss=0.012110370990769727
Epoch #217: loss=0.00814117883077094
Epoch #218: loss=0.02083921838601389
Epoch #219: loss=0.007815676638517753
Epoch #220: loss=0.01626503244890067
Epoch #221: loss=0.008299077538736389
Epoch #222: loss=0.011730058889794974
Epoch #223: loss=0.00914481769315026
Epoch #224: loss=0.01535869926111664
Epoch #225: loss=0.0075541278397656475
Epoch #226: loss=0.007874342315443967
Epoch #227: loss=0.009524370259405668
Epoch #228: loss=0.009976826814282646
Epoch #229: loss=0.01213342300448997
Epoch #230: loss=0.008518086741197634
Epoch #231: loss=0.010348115642783333
Epoch #232: loss=0.008306064743871997
Epoch #233: loss=0.007811788953001301
Epoch #234: loss=0.006456456416581008
Epoch #235: loss=0.009648026686210126
Epoch #236: loss=0.009750762940468779
Epoch #237: loss=0.011819360721539388
Epoch #238: loss=0.008269848398523722
Epoch #239: loss=0.018696960429039643
Epoch #240: loss=0.0070065790831685595
Epoch #241: loss=0.00815884327758726
Epoch #242: loss=0.006812977584618189
Epoch #243: loss=0.007181862706975599
Epoch #244: loss=0.009268704543062148
Epoch #245: loss=0.010863366985882009
Epoch #246: loss=0.010311971857976502
Epoch #247: loss=0.008222878987383393
Epoch #248: loss=0.007365239542130797
Epoch #249: loss=0.008055629983116055

Training time: 5:02:19.617041

Finished.
n2one setting etth1_ettm1_electricity_traffic -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_electricity_traffic_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_ettm1_electricity_traffic', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.48572e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.98455e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.95497e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.48572e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3372438204001436, 'MAE': 0.4234785151281599}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm1_electricity_traffic -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_electricity_traffic_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_ettm1_electricity_traffic', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.13127e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.23267588874336184, 'MAE': 0.3275277568590463}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm1_electricity_weather', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm1_electricity_weather_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.7011674596838755
Epoch #1: loss=0.73864729624905
Epoch #2: loss=0.5265786682906216
Epoch #3: loss=0.45500231903709776
Epoch #4: loss=0.38927489821225
Epoch #5: loss=0.3444477097220617
Epoch #6: loss=0.2997527543200205
Epoch #7: loss=0.2554388937680689
Epoch #8: loss=0.24337508886644285
Epoch #9: loss=0.21195745941710797
Epoch #10: loss=0.18959298171613315
Epoch #11: loss=0.1737159358312006
Epoch #12: loss=0.17481852170743353
Epoch #13: loss=0.21317192215013178
Epoch #14: loss=0.17967661052738151
Epoch #15: loss=0.12709373246929417
Epoch #16: loss=0.1103044146033999
Epoch #17: loss=0.11354948575672222
Epoch #18: loss=0.12364098753218782
Epoch #19: loss=0.09681275046545348
Epoch #20: loss=0.13239929972037878
Epoch #21: loss=0.09392108835075816
Epoch #22: loss=0.09061133346890342
Epoch #23: loss=0.11514659159855076
Epoch #24: loss=0.08193499959546001
Epoch #25: loss=0.08746928320814894
Epoch #26: loss=0.08804886894275064
Epoch #27: loss=0.10448816733256186
Epoch #28: loss=0.06319109534666147
Epoch #29: loss=0.061162868589928296
Epoch #30: loss=0.056680317909444035
Epoch #31: loss=0.05601054973109332
Epoch #32: loss=0.06186814415587546
Epoch #33: loss=0.05211354110466495
Epoch #34: loss=0.06044347253564286
Epoch #35: loss=0.054325873624176194
Epoch #36: loss=0.05273889598806631
Epoch #37: loss=0.047788157199879416
Epoch #38: loss=0.0592337589940592
Epoch #39: loss=0.06669567150688947
Epoch #40: loss=0.07349339822013799
Epoch #41: loss=0.04543507569405722
Epoch #42: loss=0.04061370392406538
Epoch #43: loss=0.07839341118089753
Epoch #44: loss=0.03974723774391188
Epoch #45: loss=0.03868873773704041
Epoch #46: loss=0.03897835134388241
Epoch #47: loss=0.04821927983390346
Epoch #48: loss=0.06291292565236863
Epoch #49: loss=0.0367075428615439
Epoch #50: loss=0.05064581231156696
Epoch #51: loss=0.04540640509126019
Epoch #52: loss=0.03483016046453012
Epoch #53: loss=0.03326803408850189
Epoch #54: loss=0.027391935568558026
Epoch #55: loss=0.03779120820874272
Epoch #56: loss=0.04420076350502874
Epoch #57: loss=0.02916641848206469
Epoch #58: loss=0.029445861126232434
Epoch #59: loss=0.031153914886399185
Epoch #60: loss=0.04591470359512031
Epoch #61: loss=0.031226179890385636
Epoch #62: loss=0.026615948217589256
Epoch #63: loss=0.030139257619157433
Epoch #64: loss=0.03346133802169041
Epoch #65: loss=0.03556802325167578
Epoch #66: loss=0.02793382491010611
Epoch #67: loss=0.03603023650628604
Epoch #68: loss=0.029885401371675096
Epoch #69: loss=0.029101714681298154
Epoch #70: loss=0.033385070712841435
Epoch #71: loss=0.027801499184067935
Epoch #72: loss=0.03266289754458129
Epoch #73: loss=0.026388220297019573
Epoch #74: loss=0.02282676177501219
Epoch #75: loss=0.01966180338760302
Epoch #76: loss=0.029666348476814465
Epoch #77: loss=0.022499074670486154
Epoch #78: loss=0.01950224738086459
Epoch #79: loss=0.024532617750252304
Epoch #80: loss=0.026392347311715865
Epoch #81: loss=0.023113939166387976
Epoch #82: loss=0.023253306225803363
Epoch #83: loss=0.03597330472030205
Epoch #84: loss=0.03622921551928587
Epoch #85: loss=0.02477434324961768
Epoch #86: loss=0.02865803329790751
Epoch #87: loss=0.019438081793646544
Epoch #88: loss=0.029075876970724394
Epoch #89: loss=0.016717903585849354
Epoch #90: loss=0.05688977746535348
Epoch #91: loss=0.026317467062721308
Epoch #92: loss=0.023361621986538784
Epoch #93: loss=0.017828625763370975
Epoch #94: loss=0.01679385729175546
Epoch #95: loss=0.0260569132232962
Epoch #96: loss=0.014865844146259232
Epoch #97: loss=0.02111096346451046
Epoch #98: loss=0.01857829712704462
Epoch #99: loss=0.017827260368886367
Epoch #100: loss=0.022006933315025567
Epoch #101: loss=0.034173872602516656
Epoch #102: loss=0.01941460555719135
Epoch #103: loss=0.01909800101652078
Epoch #104: loss=0.02479517360581468
Epoch #105: loss=0.0237025071117287
Epoch #106: loss=0.01993017376349499
Epoch #107: loss=0.017544434662614884
Epoch #108: loss=0.018222973460478274
Epoch #109: loss=0.04164542861901581
Epoch #110: loss=0.03873087751060367
Epoch #111: loss=0.019676849293867
Epoch #112: loss=0.03857270819956297
Epoch #113: loss=0.01955593442321079
Epoch #114: loss=0.014544400687597386
Epoch #115: loss=0.06798239816681878
Epoch #116: loss=0.02702491573689582
Epoch #117: loss=0.017487779865041374
Epoch #118: loss=0.023199253224397767
Epoch #119: loss=0.039109403592987264
Epoch #120: loss=0.031185936563558978
Epoch #121: loss=0.018034963370045672
Epoch #122: loss=0.03244457689117104
Epoch #123: loss=0.02093351273653927
Epoch #124: loss=0.021516120437475254
Epoch #125: loss=0.019435924570608807
Epoch #126: loss=0.013040729405753926
Epoch #127: loss=0.01654319298200067
Epoch #128: loss=0.016711023415531327
Epoch #129: loss=0.014531435251350783
Epoch #130: loss=0.018754886431868303
Epoch #131: loss=0.025871918940827354
Epoch #132: loss=0.02011721330736317
Epoch #133: loss=0.017584359315255888
Epoch #134: loss=0.019749381273589415
Epoch #135: loss=0.0235194387378439
Epoch #136: loss=0.013361620893367017
Epoch #137: loss=0.014047711525169801
Epoch #138: loss=0.035864959325807244
Epoch #139: loss=0.024027589462340286
Epoch #140: loss=0.014981880712431332
Epoch #141: loss=0.016016947576690033
Epoch #142: loss=0.020651438004538187
Epoch #143: loss=0.029766073370310925
Epoch #144: loss=0.015854801073166454
Epoch #145: loss=0.016285488020536195
Epoch #146: loss=0.025646958395692022
Epoch #147: loss=0.02068969442872713
Epoch #148: loss=0.015703900222353996
Epoch #149: loss=0.01619818040818831
Epoch #150: loss=0.016885062352409715
Epoch #151: loss=0.023414856500362288
Epoch #152: loss=0.01780738464304667
Epoch #153: loss=0.013824692763920798
Epoch #154: loss=0.015358060759441187
Epoch #155: loss=0.025500103819649667
Epoch #156: loss=0.023703339775188584
Epoch #157: loss=0.016506798990861805
Epoch #158: loss=0.01496092059963689
Epoch #159: loss=0.01137896031763226
Epoch #160: loss=0.02099008193663768
Epoch #161: loss=0.013669809460566597
Epoch #162: loss=0.013964138116706673
Epoch #163: loss=0.013083208320113792
Epoch #164: loss=0.02129758913101858
Epoch #165: loss=0.021286593181438336
Epoch #166: loss=0.012835621844690288
Epoch #167: loss=0.01658028841324865
Epoch #168: loss=0.015191559844063467
Epoch #169: loss=0.011077184561593777
Epoch #170: loss=0.013616007724489813
Epoch #171: loss=0.018642085282632774
Epoch #172: loss=0.012233165591358756
Epoch #173: loss=0.01963887564297319
Epoch #174: loss=0.01814647192942387
Epoch #175: loss=0.01657222366480361
Epoch #176: loss=0.016489355342481797
Epoch #177: loss=0.015985988820615953
Epoch #178: loss=0.026805563434186608
Epoch #179: loss=0.01674503076818376
Epoch #180: loss=0.019869961723691643
Epoch #181: loss=0.01680572561039398
Epoch #182: loss=0.02615223247860877
Epoch #183: loss=0.014479866160689024
Epoch #184: loss=0.02889111765073485
Epoch #185: loss=0.012624670695896222
Epoch #186: loss=0.02793210248131152
Epoch #187: loss=0.021743630342447032
Epoch #188: loss=0.016111316062567424
Epoch #189: loss=0.014485940201668872
Epoch #190: loss=0.015588375376952072
Epoch #191: loss=0.0195002673775889
Epoch #192: loss=0.01023118108357877
Epoch #193: loss=0.014050623235509615
Epoch #194: loss=0.013403228382031396
Epoch #195: loss=0.032792759416720586
Epoch #196: loss=0.01336323714620523
Epoch #197: loss=0.014158072407606173
Epoch #198: loss=0.023780074639864625
Epoch #199: loss=0.017259151893125668
Epoch #200: loss=0.011379683578118988
Epoch #201: loss=0.010292044922722223
Epoch #202: loss=0.011677421766814891
Epoch #203: loss=0.015988796352638467
Epoch #204: loss=0.020836377462646476
Epoch #205: loss=0.01607139927338273
Epoch #206: loss=0.017935241505340992
Epoch #207: loss=0.01902317297102705
Epoch #208: loss=0.022162341445920452
Epoch #209: loss=0.01452151193053857
Epoch #210: loss=0.013697872645291818
Epoch #211: loss=0.019569068728812193
Epoch #212: loss=0.022820665610297136
Epoch #213: loss=0.019602815322865005
Epoch #214: loss=0.013660328280920647
Epoch #215: loss=0.00840032852361655
Epoch #216: loss=0.027541138534513877
Epoch #217: loss=0.01271758939949668
Epoch #218: loss=0.014134833893391036
Epoch #219: loss=0.012198929203760313
Epoch #220: loss=0.011796518236802164
Epoch #221: loss=0.013089526986483203
Epoch #222: loss=0.011597847111829339
Epoch #223: loss=0.011416955667225746
Epoch #224: loss=0.013871125760009793
Epoch #225: loss=0.018934007657034808
Epoch #226: loss=0.02525604763498836
Epoch #227: loss=0.013227502913102636
Epoch #228: loss=0.01981574164237827
Epoch #229: loss=0.02264231507034896
Epoch #230: loss=0.014104385546062538
Epoch #231: loss=0.010694326323453874
Epoch #232: loss=0.014552735582421445
Epoch #233: loss=0.012061019581965846
Epoch #234: loss=0.017802986464692815
Epoch #235: loss=0.022436413790692562
Epoch #236: loss=0.013151862865077867
Epoch #237: loss=0.010255280354304227
Epoch #238: loss=0.014987666090896148
Epoch #239: loss=0.02108893528921938
Epoch #240: loss=0.011296770864561812
Epoch #241: loss=0.010192719431775814
Epoch #242: loss=0.011728630628203974
Epoch #243: loss=0.01556270838904909
Epoch #244: loss=0.017605838566788868
Epoch #245: loss=0.010843424286975602
Epoch #246: loss=0.01197846002744396
Epoch #247: loss=0.016788676307434598
Epoch #248: loss=0.010504048530328125
Epoch #249: loss=0.014834209145142455

Training time: 1:49:07.495399

Finished.
n2one setting etth1_ettm1_electricity_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_electricity_weather_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_ettm1_electricity_weather', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.4322e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.328564388824557, 'MAE': 0.3834672887481911}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm1_electricity_exchange', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm1_electricity_exchange_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.6707633824788184
Epoch #1: loss=0.7140308115255593
Epoch #2: loss=0.5008802041196686
Epoch #3: loss=0.40453413317801284
Epoch #4: loss=0.3496370419902829
Epoch #5: loss=0.30203364682128864
Epoch #6: loss=0.2737898055560651
Epoch #7: loss=0.23331261797665862
Epoch #8: loss=0.2142949283165959
Epoch #9: loss=0.19153248001244294
Epoch #10: loss=0.18411025004488246
Epoch #11: loss=0.1573856054598557
Epoch #12: loss=0.15010176429401556
Epoch #13: loss=0.1467439534158717
Epoch #14: loss=0.1188677290524289
Epoch #15: loss=0.13994602671145362
Epoch #16: loss=0.11974625915331868
Epoch #17: loss=0.1260631243437958
Epoch #18: loss=0.12362259935040124
Epoch #19: loss=0.08953054688377064
Epoch #20: loss=0.09549430938120877
Epoch #21: loss=0.09921817964624603
Epoch #22: loss=0.08201954188764697
Epoch #23: loss=0.0723878238202537
Epoch #24: loss=0.07660051986108124
Epoch #25: loss=0.08553485684392045
Epoch #26: loss=0.08120591728209976
Epoch #27: loss=0.07559609390601989
Epoch #28: loss=0.06849619327649818
Epoch #29: loss=0.07934575667470607
Epoch #30: loss=0.05499632507750512
Epoch #31: loss=0.06530944529856403
Epoch #32: loss=0.05608971453854218
Epoch #33: loss=0.05989092602381101
Epoch #34: loss=0.0681232790159389
Epoch #35: loss=0.05105839868717604
Epoch #36: loss=0.05483609395871954
Epoch #37: loss=0.05086888188579434
Epoch #38: loss=0.04592009124336684
Epoch #39: loss=0.05478098816426218
Epoch #40: loss=0.044553134594413235
Epoch #41: loss=0.05534319352608185
Epoch #42: loss=0.046403908943730574
Epoch #43: loss=0.04298902202299622
Epoch #44: loss=0.03524058829101946
Epoch #45: loss=0.04621761113872231
Epoch #46: loss=0.04241317608299791
Epoch #47: loss=0.05350828557261816
Epoch #48: loss=0.05410149626323808
Epoch #49: loss=0.05421910512057114
Epoch #50: loss=0.044397361873131064
Epoch #51: loss=0.03874841837886109
Epoch #52: loss=0.029509068322461904
Epoch #53: loss=0.05167635819426488
Epoch #54: loss=0.036979945526815286
Epoch #55: loss=0.033720095501004875
Epoch #56: loss=0.03462748286939664
Epoch #57: loss=0.04369596933633336
Epoch #58: loss=0.038858651025529406
Epoch #59: loss=0.03896979660316443
Epoch #60: loss=0.03604305201070517
Epoch #61: loss=0.03474531358950678
Epoch #62: loss=0.030870121802063794
Epoch #63: loss=0.03137425740312527
Epoch #64: loss=0.04210885603353918
Epoch #65: loss=0.03026665627563195
Epoch #66: loss=0.020797564114661354
Epoch #67: loss=0.05505827928575223
Epoch #68: loss=0.03718517397017747
Epoch #69: loss=0.0461139147282613
Epoch #70: loss=0.026452452248305898
Epoch #71: loss=0.022950252532651674
Epoch #72: loss=0.025525680148668094
Epoch #73: loss=0.03089624744442745
Epoch #74: loss=0.027144235379991232
Epoch #75: loss=0.031446885270930786
Epoch #76: loss=0.025909929638272232
Epoch #77: loss=0.036766971214553634
Epoch #78: loss=0.033913576728879055
Epoch #79: loss=0.034360337281138006
Epoch #80: loss=0.039311318706602975
Epoch #81: loss=0.02701222340902448
Epoch #82: loss=0.028795658142415952
Epoch #83: loss=0.028445167158682016
Epoch #84: loss=0.036214267887022096
Epoch #85: loss=0.029719676622471394
Epoch #86: loss=0.015840947223083796
Epoch #87: loss=0.020579637309082754
Epoch #88: loss=0.029244102156514393
Epoch #89: loss=0.027950067778979494
Epoch #90: loss=0.028681264245501513
Epoch #91: loss=0.022760328446563217
Epoch #92: loss=0.035235498792972275
Epoch #93: loss=0.02996026279011564
Epoch #94: loss=0.01950025438349184
Epoch #95: loss=0.022362130529533064
Epoch #96: loss=0.02015665332419041
Epoch #97: loss=0.041752789602333126
Epoch #98: loss=0.026381167193998176
Epoch #99: loss=0.025807800251347757
Epoch #100: loss=0.024350251621863286
Epoch #101: loss=0.02116382899975957
Epoch #102: loss=0.02200999376411021
Epoch #103: loss=0.021651011718382056
Epoch #104: loss=0.03416743261691972
Epoch #105: loss=0.028632345039703445
Epoch #106: loss=0.029601091988349832
Epoch #107: loss=0.03560961119398496
Epoch #108: loss=0.02450586742686607
Epoch #109: loss=0.018648643732025297
Epoch #110: loss=0.01752576718535623
Epoch #111: loss=0.02600498508272145
Epoch #112: loss=0.02188009040256404
Epoch #113: loss=0.017692901871283875
Epoch #114: loss=0.023084004452889544
Epoch #115: loss=0.025379491256857265
Epoch #116: loss=0.024682034850080286
Epoch #117: loss=0.024170537392161948
Epoch #118: loss=0.0202278124890827
Epoch #119: loss=0.028343171441205576
Epoch #120: loss=0.02377420984193822
Epoch #121: loss=0.028228399005613854
Epoch #122: loss=0.03152237747096717
Epoch #123: loss=0.021481741538139795
Epoch #124: loss=0.023526088708021305
Epoch #125: loss=0.01853766337893259
Epoch #126: loss=0.022712448557254374
Epoch #127: loss=0.022876028678217575
Epoch #128: loss=0.017430830456018554
Epoch #129: loss=0.028538003915810812
Epoch #130: loss=0.015206923693893558
Epoch #131: loss=0.023644009881326793
Epoch #132: loss=0.020580218844377416
Epoch #133: loss=0.027881798189152193
Epoch #134: loss=0.025474575571467567
Epoch #135: loss=0.025678937044263057
Epoch #136: loss=0.029099715979949647
Epoch #137: loss=0.022796801910051265
Epoch #138: loss=0.030230259761329665
Epoch #139: loss=0.022143909573469105
Epoch #140: loss=0.01940927058748528
Epoch #141: loss=0.02170757721604307
Epoch #142: loss=0.032222338467675346
Epoch #143: loss=0.044009412879893225
Epoch #144: loss=0.021476888850496367
Epoch #145: loss=0.02233593433864565
Epoch #146: loss=0.016387982358377674
Epoch #147: loss=0.012656697143883759
Epoch #148: loss=0.017765103127594006
Epoch #149: loss=0.009987196132291768
Epoch #150: loss=0.01323757226621163
Epoch #151: loss=0.016933021785809473
Epoch #152: loss=0.032760597042295204
Epoch #153: loss=0.038726318350648214
Epoch #154: loss=0.033886626971716474
Epoch #155: loss=0.019654397568390342
Epoch #156: loss=0.022528765271874064
Epoch #157: loss=0.018362427680211017
Epoch #158: loss=0.018821072910633205
Epoch #159: loss=0.020202984248847575
Epoch #160: loss=0.01962881753192973
Epoch #161: loss=0.016356169224497983
Epoch #162: loss=0.023436249570950588
Epoch #163: loss=0.0335570832255487
Epoch #164: loss=0.023193640717451516
Epoch #165: loss=0.018573882043501227
Epoch #166: loss=0.01887312901417003
Epoch #167: loss=0.02576210385712497
Epoch #168: loss=0.015960289089724432
Epoch #169: loss=0.013812908064204963
Epoch #170: loss=0.02169804933973419
Epoch #171: loss=0.014808150816266626
Epoch #172: loss=0.019446549432550794
Epoch #173: loss=0.020037360177529703
Epoch #174: loss=0.021870737158967132
Epoch #175: loss=0.02294175442560141
Epoch #176: loss=0.024158869128404533
Epoch #177: loss=0.028368504103997813
Epoch #178: loss=0.019404261892323277
Epoch #179: loss=0.021896252418017438
Epoch #180: loss=0.015845878308394692
Epoch #181: loss=0.02007874563329327
Epoch #182: loss=0.020100058322122874
Epoch #183: loss=0.016426128595805747
Epoch #184: loss=0.009975865542749748
Epoch #185: loss=0.015521337241451027
Epoch #186: loss=0.018051642152079533
Epoch #187: loss=0.02015206700310672
Epoch #188: loss=0.020518189447097244
Epoch #189: loss=0.02076395091205508
Epoch #190: loss=0.017751124635324023
Epoch #191: loss=0.013032018858872311
Epoch #192: loss=0.009435267718820846
Epoch #193: loss=0.02276788887977788
Epoch #194: loss=0.02640606786318322
Epoch #195: loss=0.017469155029306505
Epoch #196: loss=0.013562112487047395
Epoch #197: loss=0.015981123188707806
Epoch #198: loss=0.024993401611229184
Epoch #199: loss=0.0181315376197514
Epoch #200: loss=0.01776338149482278
Epoch #201: loss=0.024110302296856293
Epoch #202: loss=0.022820158280004138
Epoch #203: loss=0.016365369720876308
Epoch #204: loss=0.01823404359816431
Epoch #205: loss=0.014500114171006193
Epoch #206: loss=0.016699226233928388
Epoch #207: loss=0.022279932588471035
Epoch #208: loss=0.017306880957832137
Epoch #209: loss=0.01552143396446696
Epoch #210: loss=0.022478986465739842
Epoch #211: loss=0.020469145099021847
Epoch #212: loss=0.024448776393202844
Epoch #213: loss=0.019950090488989273
Epoch #214: loss=0.023263577904930655
Epoch #215: loss=0.018223561323046554
Epoch #216: loss=0.014643110899001048
Epoch #217: loss=0.011612834852565918
Epoch #218: loss=0.01215129847348445
Epoch #219: loss=0.011702279206325088
Epoch #220: loss=0.015518196649287132
Epoch #221: loss=0.01959993853116333
Epoch #222: loss=0.023768083001513795
Epoch #223: loss=0.028952302216446183
Epoch #224: loss=0.01863830831198435
Epoch #225: loss=0.012341535910031348
Epoch #226: loss=0.017989644194400925
Epoch #227: loss=0.009802425014169119
Epoch #228: loss=0.01831564836818671
Epoch #229: loss=0.013873239772317808
Epoch #230: loss=0.01515339697170694
Epoch #231: loss=0.01712147892477603
Epoch #232: loss=0.012692085242500093
Epoch #233: loss=0.01797450610445893
Epoch #234: loss=0.014205678839502207
Epoch #235: loss=0.015194229717548904
Epoch #236: loss=0.016712899269671677
Epoch #237: loss=0.011754211986112685
Epoch #238: loss=0.012930577538333168
Epoch #239: loss=0.011488245395535565
Epoch #240: loss=0.013571459976095714
Epoch #241: loss=0.016432299117389287
Epoch #242: loss=0.02115139351986276
Epoch #243: loss=0.014979119936302196
Epoch #244: loss=0.017508376170330887
Epoch #245: loss=0.02439021766645383
Epoch #246: loss=0.014165928503444756
Epoch #247: loss=0.014754580295750715
Epoch #248: loss=0.013655445280888115
Epoch #249: loss=0.015485714963685603

Training time: 1:37:46.623473

Finished.
n2one setting etth1_ettm1_electricity_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_electricity_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_ettm1_electricity_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.52751e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.06241e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.06241e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.6554744391491537, 'MAE': 0.6253603131160617}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm1_traffic_weather', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm1_traffic_weather_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.0465186476773247
Epoch #1: loss=0.4034784540830069
Epoch #2: loss=0.29996429038363576
Epoch #3: loss=0.22863784021231248
Epoch #4: loss=0.18601265774163978
Epoch #5: loss=0.16265069235272492
Epoch #6: loss=0.1386113696059348
Epoch #7: loss=0.11814754595466073
Epoch #8: loss=0.10448679993665114
Epoch #9: loss=0.10426367693282582
Epoch #10: loss=0.07958951091525406
Epoch #11: loss=0.06543029686662206
Epoch #12: loss=0.07103320915574747
Epoch #13: loss=0.06458174267826935
Epoch #14: loss=0.051938578242304474
Epoch #15: loss=0.059039174341884486
Epoch #16: loss=0.05469838550641195
Epoch #17: loss=0.04291798452069062
Epoch #18: loss=0.05026972878860026
Epoch #19: loss=0.047979493651674775
Epoch #20: loss=0.051037387759219156
Epoch #21: loss=0.03544266753938978
Epoch #22: loss=0.03804211107570427
Epoch #23: loss=0.03847667323111888
Epoch #24: loss=0.03645030526836479
Epoch #25: loss=0.04039032830497986
Epoch #26: loss=0.03457177064415462
Epoch #27: loss=0.03429469791992421
Epoch #28: loss=0.030985766735234222
Epoch #29: loss=0.05114072637203834
Epoch #30: loss=0.029250216056391283
Epoch #31: loss=0.03348676708645638
Epoch #32: loss=0.037183931019906545
Epoch #33: loss=0.03297373922147262
Epoch #34: loss=0.025211098622214604
Epoch #35: loss=0.03217317070901932
Epoch #36: loss=0.029017988653356523
Epoch #37: loss=0.035133037881007745
Epoch #38: loss=0.03162744538239193
Epoch #39: loss=0.018949647177518066
Epoch #40: loss=0.02756838331357
Epoch #41: loss=0.028182588391677758
Epoch #42: loss=0.0263597009774574
Epoch #43: loss=0.02794605939026879
Epoch #44: loss=0.026868545620845605
Epoch #45: loss=0.021949121173253802
Epoch #46: loss=0.0283311463007909
Epoch #47: loss=0.031039981969756075
Epoch #48: loss=0.027153540364873677
Epoch #49: loss=0.024298009789414154
Epoch #50: loss=0.021556027006487944
Epoch #51: loss=0.023854653252775432
Epoch #52: loss=0.0289946342910312
Epoch #53: loss=0.028409765829950483
Epoch #54: loss=0.020683580454060897
Epoch #55: loss=0.0237129728692593
Epoch #56: loss=0.01842021469069721
Epoch #57: loss=0.019010330949377763
Epoch #58: loss=0.02272491511196478
Epoch #59: loss=0.01955058298395072
Epoch #60: loss=0.02426665520099419
Epoch #61: loss=0.022306882566778825
Epoch #62: loss=0.022092615431223463
Epoch #63: loss=0.013575041516995979
Epoch #64: loss=0.018522706147870275
Epoch #65: loss=0.018531673360103536
Epoch #66: loss=0.016592697510056334
Epoch #67: loss=0.024363083490255344
Epoch #68: loss=0.022623054711926816
Epoch #69: loss=0.01609819770370976
Epoch #70: loss=0.04426536518460997
Epoch #71: loss=0.018075222780459786
Epoch #72: loss=0.01613636330326723
Epoch #73: loss=0.02424759404688419
Epoch #74: loss=0.02370487784858378
Epoch #75: loss=0.023230221479394624
Epoch #76: loss=0.01975845975406102
Epoch #77: loss=0.018286902178226656
Epoch #78: loss=0.015332447694994615
Epoch #79: loss=0.020692145305484733
Epoch #80: loss=0.019824068971678807
Epoch #81: loss=0.015455048010540894
Epoch #82: loss=0.019145432128626225
Epoch #83: loss=0.020361062198444052
Epoch #84: loss=0.01746169860908046
Epoch #85: loss=0.03756398645957683
Epoch #86: loss=0.022202391770414425
Epoch #87: loss=0.017168210950266584
Epoch #88: loss=0.015720576972602485
Epoch #89: loss=0.024648953090961784
Epoch #90: loss=0.015265960898462357
Epoch #91: loss=0.017958852143292098
Epoch #92: loss=0.015572857206006829
Epoch #93: loss=0.012649893137944308
Epoch #94: loss=0.015300120534171005
Epoch #95: loss=0.01476598063631088
Epoch #96: loss=0.02232479559029293
Epoch #97: loss=0.024105518765378257
Epoch #98: loss=0.017148771105241906
Epoch #99: loss=0.016392271778719485
Epoch #100: loss=0.012126956089419286
Epoch #101: loss=0.016378940375184867
Epoch #102: loss=0.020292932879376054
Epoch #103: loss=0.016134548554702963
Epoch #104: loss=0.017809229042721815
Epoch #105: loss=0.016618677480774623
Epoch #106: loss=0.03262119885985318
Epoch #107: loss=0.01758590065290798
Epoch #108: loss=0.012437406936373867
Epoch #109: loss=0.011339553344963817
Epoch #110: loss=0.01583547139532348
Epoch #111: loss=0.01894972963567266
Epoch #112: loss=0.015494881520361565
Epoch #113: loss=0.020646996630502713
Epoch #114: loss=0.016289521917180624
Epoch #115: loss=0.019729798976419324
Epoch #116: loss=0.018851085838712197
Epoch #117: loss=0.01279454111026124
Epoch #118: loss=0.015987711932727806
Epoch #119: loss=0.014873716501162128
Epoch #120: loss=0.012763051521025338
Epoch #121: loss=0.013428210998858606
Epoch #122: loss=0.013071618245199638
Epoch #123: loss=0.013195297031901842
Epoch #124: loss=0.016153904766562113
Epoch #125: loss=0.014532085539444548
Epoch #126: loss=0.01537956900213111
Epoch #127: loss=0.01343631797890359
Epoch #128: loss=0.014900294780612923
Epoch #129: loss=0.011668803873015441
Epoch #130: loss=0.012505005010359106
Epoch #131: loss=0.014277071633898058
Epoch #132: loss=0.017491878521907294
Epoch #133: loss=0.016961272528157857
Epoch #134: loss=0.015095626571854046
Epoch #135: loss=0.008102074299868176
Epoch #136: loss=0.02133991946027461
Epoch #137: loss=0.01434482033481404
Epoch #138: loss=0.01620610811521847
Epoch #139: loss=0.021919787704395493
Epoch #140: loss=0.011322876740346337
Epoch #141: loss=0.01163813844965627
Epoch #142: loss=0.025699646221123026
Epoch #143: loss=0.01320816735915889
Epoch #144: loss=0.012845374441192119
Epoch #145: loss=0.012570358223633102
Epoch #146: loss=0.017392032637976437
Epoch #147: loss=0.01134395007778483
Epoch #148: loss=0.014088029288883407
Epoch #149: loss=0.016940191429183935
Epoch #150: loss=0.01009774476508317
Epoch #151: loss=0.016319779259647154
Epoch #152: loss=0.021972580512951024
Epoch #153: loss=0.012985708056317533
Epoch #154: loss=0.011626691834547656
Epoch #155: loss=0.011817848156228154
Epoch #156: loss=0.013045542388951193
Epoch #157: loss=0.014291462265816915
Epoch #158: loss=0.01271523492524239
Epoch #159: loss=0.013212130842353275
Epoch #160: loss=0.017803589714302414
Epoch #161: loss=0.011095707043932935
Epoch #162: loss=0.015313619566967229
Epoch #163: loss=0.010725734058607455
Epoch #164: loss=0.017002684120280914
Epoch #165: loss=0.013874134153445563
Epoch #166: loss=0.009047122832030345
Epoch #167: loss=0.013717236114393074
Epoch #168: loss=0.010928198308288171
Epoch #169: loss=0.008429299093011842
Epoch #170: loss=0.01656606208715381
Epoch #171: loss=0.012778468950763119
Epoch #172: loss=0.013178185509809084
Epoch #173: loss=0.007052040742588806
Epoch #174: loss=0.012338617250134925
Epoch #175: loss=0.012027885251938469
Epoch #176: loss=0.013913171081982345
Epoch #177: loss=0.01837462229765597
Epoch #178: loss=0.01424319453309195
Epoch #179: loss=0.01442160730614588
Epoch #180: loss=0.012195699893528695
Epoch #181: loss=0.012586723042336045
Epoch #182: loss=0.010896060180585507
Epoch #183: loss=0.012310516814323231
Epoch #184: loss=0.012179045604963872
Epoch #185: loss=0.008995867507419422
Epoch #186: loss=0.013845998936227526
Epoch #187: loss=0.016757324145186568
Epoch #188: loss=0.015587180214597398
Epoch #189: loss=0.010723420065762393
Epoch #190: loss=0.009966760004855689
Epoch #191: loss=0.011871440767525915
Epoch #192: loss=0.011917405698334575
Epoch #193: loss=0.009412779495848993
Epoch #194: loss=0.012743001205794113
Epoch #195: loss=0.009939270883550734
Epoch #196: loss=0.010956065653481267
Epoch #197: loss=0.014336492695140104
Epoch #198: loss=0.012783304089334988
Epoch #199: loss=0.011706256612400483
Epoch #200: loss=0.00894767707298244
Epoch #201: loss=0.012871510161629289
Epoch #202: loss=0.01221426401288795
Epoch #203: loss=0.01069810056701268
Epoch #204: loss=0.008785114980352992
Epoch #205: loss=0.015024195220072138
Epoch #206: loss=0.01538987468205193
Epoch #207: loss=0.014520481197889549
Epoch #208: loss=0.012455266476524007
Epoch #209: loss=0.010414637373787327
Epoch #210: loss=0.01131706967893073
Epoch #211: loss=0.008344985668918926
Epoch #212: loss=0.015104104864422492
Epoch #213: loss=0.011631112532638384
Epoch #214: loss=0.013642292052143314
Epoch #215: loss=0.010269430422485076
Epoch #216: loss=0.015607082011022273
Epoch #217: loss=0.012581160310564601
Epoch #218: loss=0.013235551507637408
Epoch #219: loss=0.015506454492336043
Epoch #220: loss=0.01179014764254333
Epoch #221: loss=0.009980160538749304
Epoch #222: loss=0.011016015617935518
Epoch #223: loss=0.009201710659968944
Epoch #224: loss=0.014482974535141862
Epoch #225: loss=0.010980930941357487
Epoch #226: loss=0.009857662467902728
Epoch #227: loss=0.01006306482571279
Epoch #228: loss=0.010843442147607308
Epoch #229: loss=0.0108829576646799
Epoch #230: loss=0.010851664357669124
Epoch #231: loss=0.011863393452493669
Epoch #232: loss=0.008518717341920645
Epoch #233: loss=0.01255294609120759
Epoch #234: loss=0.011045364935985794
Epoch #235: loss=0.010720571070838443
Epoch #236: loss=0.013297399431510743
Epoch #237: loss=0.010911504289445135
Epoch #238: loss=0.009981234498883785
Epoch #239: loss=0.00895519991390917
Epoch #240: loss=0.009616238192963403
Epoch #241: loss=0.01155998852375488
Epoch #242: loss=0.01684467646129641
Epoch #243: loss=0.008610853969846314
Epoch #244: loss=0.009809986656049133
Epoch #245: loss=0.008605485169031831
Epoch #246: loss=0.014527532784375472
Epoch #247: loss=0.012859903862492349
Epoch #248: loss=0.015190327365127923
Epoch #249: loss=0.01040900650757165

Training time: 3:37:21.900404

Finished.
n2one setting etth1_ettm1_traffic_weather -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_traffic_weather_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_ettm1_traffic_weather', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.51965e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.8234e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.7533e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.51965e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.41902655364347513, 'MAE': 0.4613694129170132}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm1_traffic_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_traffic_weather_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_ettm1_traffic_weather', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
Evaluation result: {'MSE': 0.3430071284936337, 'MAE': 0.381342882589945}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm1_traffic_exchange', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm1_traffic_exchange_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.0108309731155902
Epoch #1: loss=0.39759607671818753
Epoch #2: loss=0.27859665367853
Epoch #3: loss=0.20158548302411497
Epoch #4: loss=0.1762495790314567
Epoch #5: loss=0.14274714205850353
Epoch #6: loss=0.11529824466587187
Epoch #7: loss=0.09899240593333636
Epoch #8: loss=0.09376941078241814
Epoch #9: loss=0.08620243322267826
Epoch #10: loss=0.07363419177488902
Epoch #11: loss=0.0643850063751997
Epoch #12: loss=0.0641516787356588
Epoch #13: loss=0.06334701340319379
Epoch #14: loss=0.06097369482226855
Epoch #15: loss=0.05247123756887483
Epoch #16: loss=0.04764910608630728
Epoch #17: loss=0.04655724541999416
Epoch #18: loss=0.04738102028689658
Epoch #19: loss=0.04262817119272334
Epoch #20: loss=0.04755460243747645
Epoch #21: loss=0.04828083485171937
Epoch #22: loss=0.037416869988937666
Epoch #23: loss=0.036866172684984794
Epoch #24: loss=0.032874000175234126
Epoch #25: loss=0.04089643322007399
Epoch #26: loss=0.02988723734662992
Epoch #27: loss=0.03315802067224574
Epoch #28: loss=0.031373973678365384
Epoch #29: loss=0.03638082559022272
Epoch #30: loss=0.033484439655555295
Epoch #31: loss=0.03159696000721515
Epoch #32: loss=0.03691357705620986
Epoch #33: loss=0.033370450526703496
Epoch #34: loss=0.027274353869182272
Epoch #35: loss=0.035243937487557726
Epoch #36: loss=0.029395724305629242
Epoch #37: loss=0.02744025153266308
Epoch #38: loss=0.02988865404486287
Epoch #39: loss=0.029557249127433065
Epoch #40: loss=0.02410179841732512
Epoch #41: loss=0.025934624163235165
Epoch #42: loss=0.021490631977186394
Epoch #43: loss=0.03170145426944752
Epoch #44: loss=0.030466194961116196
Epoch #45: loss=0.024480629631127796
Epoch #46: loss=0.026865229907294584
Epoch #47: loss=0.0250716115305303
Epoch #48: loss=0.02616843097823696
Epoch #49: loss=0.022574842959075542
Epoch #50: loss=0.024820446955362074
Epoch #51: loss=0.0294761539090515
Epoch #52: loss=0.020665002131208237
Epoch #53: loss=0.019827867548195394
Epoch #54: loss=0.022162833734680816
Epoch #55: loss=0.021977386084964145
Epoch #56: loss=0.029576329156485816
Epoch #57: loss=0.022027213792072772
Epoch #58: loss=0.02141578159621982
Epoch #59: loss=0.017189336515690917
Epoch #60: loss=0.021031329896236007
Epoch #61: loss=0.021558726969217516
Epoch #62: loss=0.02426865308213589
Epoch #63: loss=0.02350719089087294
Epoch #64: loss=0.02427630940806708
Epoch #65: loss=0.024898620130353176
Epoch #66: loss=0.025621123853279068
Epoch #67: loss=0.016126300623917823
Epoch #68: loss=0.02348042336175363
Epoch #69: loss=0.027640396717050625
Epoch #70: loss=0.018375552594145184
Epoch #71: loss=0.020327611668255634
Epoch #72: loss=0.017768042861896427
Epoch #73: loss=0.029251944764149124
Epoch #74: loss=0.018710700878432976
Epoch #75: loss=0.027721887992352544
Epoch #76: loss=0.020460382312431885
Epoch #77: loss=0.01806377867942829
Epoch #78: loss=0.017377620340093027
Epoch #79: loss=0.022958171875297348
Epoch #80: loss=0.021320953471765713
Epoch #81: loss=0.020948054705808614
Epoch #82: loss=0.021232226713002567
Epoch #83: loss=0.023477789984541676
Epoch #84: loss=0.01666106753488363
Epoch #85: loss=0.018487105056838034
Epoch #86: loss=0.01567421161293955
Epoch #87: loss=0.01929972799251544
Epoch #88: loss=0.01933186310298543
Epoch #89: loss=0.02306242866767649
Epoch #90: loss=0.01918094592349974
Epoch #91: loss=0.015984973817417945
Epoch #92: loss=0.013793937386950134
Epoch #93: loss=0.01694606784073036
Epoch #94: loss=0.015344975166265835
Epoch #95: loss=0.01589226380567017
Epoch #96: loss=0.01782388479651664
Epoch #97: loss=0.023531372624658927
Epoch #98: loss=0.018974932708826255
Epoch #99: loss=0.01777871872423225
Epoch #100: loss=0.013603969908233938
Epoch #101: loss=0.01772323424023574
Epoch #102: loss=0.025155114485732245
Epoch #103: loss=0.020729097790961958
Epoch #104: loss=0.012842037492707794
Epoch #105: loss=0.01739322292551274
Epoch #106: loss=0.023673176402168407
Epoch #107: loss=0.017742105010092764
Epoch #108: loss=0.015669232684419374
Epoch #109: loss=0.012952172356800712
Epoch #110: loss=0.019284849141439662
Epoch #111: loss=0.014578156143306022
Epoch #112: loss=0.01632433932533237
Epoch #113: loss=0.01803605010834806
Epoch #114: loss=0.01705528902800267
Epoch #115: loss=0.016981833744294645
Epoch #116: loss=0.019708082820527436
Epoch #117: loss=0.016037521528077223
Epoch #118: loss=0.027288934794341912
Epoch #119: loss=0.01264916754935093
Epoch #120: loss=0.014397036877428266
Epoch #121: loss=0.017891566393020412
Epoch #122: loss=0.013329541457039283
Epoch #123: loss=0.018884114088045002
Epoch #124: loss=0.015018913327498143
Epoch #125: loss=0.01847323213394145
Epoch #126: loss=0.01489160992797052
Epoch #127: loss=0.014044080246880971
Epoch #128: loss=0.013897976345909122
Epoch #129: loss=0.012518941305913628
Epoch #130: loss=0.014136791976246363
Epoch #131: loss=0.01576036515541853
Epoch #132: loss=0.022473535568539635
Epoch #133: loss=0.014396279815251168
Epoch #134: loss=0.01508096332179679
Epoch #135: loss=0.01125203377130281
Epoch #136: loss=0.01608380888878323
Epoch #137: loss=0.017451456051980837
Epoch #138: loss=0.01631621722278011
Epoch #139: loss=0.013072006589510722
Epoch #140: loss=0.01329633173408765
Epoch #141: loss=0.015875088575158187
Epoch #142: loss=0.013209256037412529
Epoch #143: loss=0.018912102458794048
Epoch #144: loss=0.016149349735648792
Epoch #145: loss=0.015619732955036573
Epoch #146: loss=0.016892099938886858
Epoch #147: loss=0.012511448713970216
Epoch #148: loss=0.01595131932345294
Epoch #149: loss=0.016090719142838526
Epoch #150: loss=0.014759902137410717
Epoch #151: loss=0.015258055506483861
Epoch #152: loss=0.01606077058733701
Epoch #153: loss=0.016270942652988958
Epoch #154: loss=0.01286651565234999
Epoch #155: loss=0.01173736877788067
Epoch #156: loss=0.01246707544580843
Epoch #157: loss=0.014805805588776321
Epoch #158: loss=0.013846593197691569
Epoch #159: loss=0.016786170085971528
Epoch #160: loss=0.012271840170594028
Epoch #161: loss=0.01638955141692071
Epoch #162: loss=0.012667806565946809
Epoch #163: loss=0.012416084553691902
Epoch #164: loss=0.015570866804352533
Epoch #165: loss=0.011495937572977415
Epoch #166: loss=0.01649204520676371
Epoch #167: loss=0.013130121954901854
Epoch #168: loss=0.014927241802332254
Epoch #169: loss=0.016769140605115477
Epoch #170: loss=0.010571277032327417
Epoch #171: loss=0.01394749092759338
Epoch #172: loss=0.009541726887045451
Epoch #173: loss=0.011183454692490248
Epoch #174: loss=0.016812796008125915
Epoch #175: loss=0.015617204029727905
Epoch #176: loss=0.015392453041959589
Epoch #177: loss=0.013778711891243982
Epoch #178: loss=0.011625915688275019
Epoch #179: loss=0.011481597876899376
Epoch #180: loss=0.01787997623290033
Epoch #181: loss=0.01218566394320963
Epoch #182: loss=0.0130178084908219
Epoch #183: loss=0.019511908278546215
Epoch #184: loss=0.01607766783693863
Epoch #185: loss=0.011166585350168191
Epoch #186: loss=0.011599114999347597
Epoch #187: loss=0.013702661468512914
Epoch #188: loss=0.011294701758284186
Epoch #189: loss=0.015394407830860251
Epoch #190: loss=0.014214799836678992
Epoch #191: loss=0.01320569292843871
Epoch #192: loss=0.011243913702479026
Epoch #193: loss=0.018723272504503913
Epoch #194: loss=0.01170133082498298
Epoch #195: loss=0.010770259178644739
Epoch #196: loss=0.013036130020040431
Epoch #197: loss=0.008794004624440539
Epoch #198: loss=0.021259573698370258
Epoch #199: loss=0.01141355990423747
Epoch #200: loss=0.013051058804325425
Epoch #201: loss=0.014502621332212584
Epoch #202: loss=0.012708017636304338
Epoch #203: loss=0.01750281947153764
Epoch #204: loss=0.011126871654768538
Epoch #205: loss=0.01410330865287137
Epoch #206: loss=0.011512786042396066
Epoch #207: loss=0.01180372195295268
Epoch #208: loss=0.013043685186366437
Epoch #209: loss=0.010831601432647067
Epoch #210: loss=0.01424486776798133
Epoch #211: loss=0.014192714400705226
Epoch #212: loss=0.01645924773596939
Epoch #213: loss=0.012775593235018859
Epoch #214: loss=0.011973128188532559
Epoch #215: loss=0.010737189044366378
Epoch #216: loss=0.015076594081144756
Epoch #217: loss=0.0209032962991694
Epoch #218: loss=0.010786218132256312
Epoch #219: loss=0.014307928944683293
Epoch #220: loss=0.01165947771677328
Epoch #221: loss=0.016823229219717014
Epoch #222: loss=0.011926112383121476
Epoch #223: loss=0.012047697173329652
Epoch #224: loss=0.016758670544109296
Epoch #225: loss=0.011661324904347205
Epoch #226: loss=0.008094889202774546
Epoch #227: loss=0.010094778564126574
Epoch #228: loss=0.013630375448334595
Epoch #229: loss=0.009889347262500663
Epoch #230: loss=0.01066714719168017
Epoch #231: loss=0.01171091003405243
Epoch #232: loss=0.02229242962546466
Epoch #233: loss=0.01381093986423661
Epoch #234: loss=0.010768470437379857
Epoch #235: loss=0.01187918397364548
Epoch #236: loss=0.012917901803342142
Epoch #237: loss=0.010629436200483847
Epoch #238: loss=0.0140045295221982
Epoch #239: loss=0.013401431183304233
Epoch #240: loss=0.013428599088476878
Epoch #241: loss=0.012542471578722921
Epoch #242: loss=0.01358464007759582
Epoch #243: loss=0.01667021648314108
Epoch #244: loss=0.009942091802627515
Epoch #245: loss=0.009988182886306138
Epoch #246: loss=0.012466704051877133
Epoch #247: loss=0.010615214648865518
Epoch #248: loss=0.01010376087964818
Epoch #249: loss=0.013174294175589059

Training time: 3:27:45.976293

Finished.
n2one setting etth1_ettm1_traffic_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_traffic_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_ettm1_traffic_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.3135e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.89121e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.8444e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.3135e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4103991964200202, 'MAE': 0.4561080231907028}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm1_traffic_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_traffic_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_ettm1_traffic_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.94043e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.13496e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.61469e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.94043e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.5637022286520519, 'MAE': 0.5887113546656405}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm1_weather_exchange', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm1_weather_exchange_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=4.215180486440659
Epoch #1: loss=2.3559572123564205
Epoch #2: loss=2.2879245304144344
Epoch #3: loss=1.9771609122936542
Epoch #4: loss=1.8818819385308485
Epoch #5: loss=1.762323184655263
Epoch #6: loss=1.5122335323920617
Epoch #7: loss=1.4363371821550222
Epoch #8: loss=1.3232463621176207
Epoch #9: loss=1.2759647151598563
Epoch #10: loss=1.2066067720835025
Epoch #11: loss=1.115249597109281
Epoch #12: loss=1.0956401217442293
Epoch #13: loss=1.0811848101707606
Epoch #14: loss=1.0379622349372277
Epoch #15: loss=0.9953142358706548
Epoch #16: loss=1.1051256840045636
Epoch #17: loss=1.0309071632531972
Epoch #18: loss=0.9373029642380201
Epoch #19: loss=0.9194489499697318
Epoch #20: loss=0.8618571964594034
Epoch #21: loss=0.8232174756435248
Epoch #22: loss=0.819554498562446
Epoch #23: loss=0.8022033004806592
Epoch #24: loss=0.7798459913868171
Epoch #25: loss=0.8118536105522742
Epoch #26: loss=0.7656953071172421
Epoch #27: loss=0.6850968289833802
Epoch #28: loss=0.7246032597926947
Epoch #29: loss=0.6590868836412063
Epoch #30: loss=0.7024478872235005
Epoch #31: loss=0.694473938873181
Epoch #32: loss=0.6600439428136899
Epoch #33: loss=0.588281668149508
Epoch #34: loss=0.5606809143836682
Epoch #35: loss=0.6115789132622572
Epoch #36: loss=0.5917137872714263
Epoch #37: loss=0.6352548037584012
Epoch #38: loss=0.5501465522325956
Epoch #39: loss=0.5161635531828954
Epoch #40: loss=0.5440549649871312
Epoch #41: loss=0.5173460972996858
Epoch #42: loss=0.4976660368534235
Epoch #43: loss=0.4844564680869763
Epoch #44: loss=0.48803472633545214
Epoch #45: loss=0.5036814688489988
Epoch #46: loss=0.4679654630330893
Epoch #47: loss=0.4677254377076259
Epoch #48: loss=0.5057196124241903
Epoch #49: loss=0.4690576450755963
Epoch #50: loss=0.4441448166393317
Epoch #51: loss=0.44482495836340463
Epoch #52: loss=0.3882303068844172
Epoch #53: loss=0.4054261795603312
Epoch #54: loss=0.43428444547148853
Epoch #55: loss=0.4609807967566527
Epoch #56: loss=0.3911738361303623
Epoch #57: loss=0.4188721420673224
Epoch #58: loss=0.3877144441581689
Epoch #59: loss=0.38566909014032436
Epoch #60: loss=0.3747499897502936
Epoch #61: loss=0.40326925080556136
Epoch #62: loss=0.5574565036938741
Epoch #63: loss=0.5922957045527605
Epoch #64: loss=0.459564033895731
Epoch #65: loss=0.3370617183928306
Epoch #66: loss=0.30639076677079385
Epoch #67: loss=0.30252284527971196
Epoch #68: loss=0.34639371931552887
Epoch #69: loss=0.29905469744251323
Epoch #70: loss=0.3477278115371099
Epoch #71: loss=0.3735924125290834
Epoch #72: loss=0.36021781913363016
Epoch #73: loss=0.28598707197950435
Epoch #74: loss=0.32451752573251724
Epoch #75: loss=0.32570897673185056
Epoch #76: loss=0.3651251754222008
Epoch #77: loss=0.2619620780818738
Epoch #78: loss=0.33212180278049064
Epoch #79: loss=0.2763497902510258
Epoch #80: loss=0.3128508561505721
Epoch #81: loss=0.31737103614096457
Epoch #82: loss=0.2857952408779126
Epoch #83: loss=0.22659362795261237
Epoch #84: loss=0.29154784318346244
Epoch #85: loss=0.2304439556140166
Epoch #86: loss=0.20968729228927538
Epoch #87: loss=0.29336181182700855
Epoch #88: loss=0.2385007105767727
Epoch #89: loss=0.25763403194455
Epoch #90: loss=0.29868823605088085
Epoch #91: loss=0.30769442637952477
Epoch #92: loss=0.23644822305784777
Epoch #93: loss=0.2720906793211515
Epoch #94: loss=0.23141698066431743
Epoch #95: loss=0.1936536541638466
Epoch #96: loss=0.2081094399954264
Epoch #97: loss=0.2137664584442973
Epoch #98: loss=0.1862217875627371
Epoch #99: loss=0.19736387788389737
Epoch #100: loss=0.22938533528493002
Epoch #101: loss=0.17832968692080334
Epoch #102: loss=0.1672771835986238
Epoch #103: loss=0.1743213443372112
Epoch #104: loss=0.19573449787612146
Epoch #105: loss=0.16082138059517512
Epoch #106: loss=0.22015801989115202
Epoch #107: loss=0.219754306671138
Epoch #108: loss=0.22171161581690496
Epoch #109: loss=0.19505020059072053
Epoch #110: loss=0.1655785684258892
Epoch #111: loss=0.17854066630108997
Epoch #112: loss=0.1918791920089951
Epoch #113: loss=0.17759200687018725
Epoch #114: loss=0.15023168914306623
Epoch #115: loss=0.19974069204181433
Epoch #116: loss=0.18318286194251135
Epoch #117: loss=0.17187341410093582
Epoch #118: loss=0.18232066707255748
Epoch #119: loss=0.22807365390830314
Epoch #120: loss=0.2249000629123587
Epoch #121: loss=0.20913538293769726
Epoch #122: loss=0.18339967978401825
Epoch #123: loss=0.16632340289652348
Epoch #124: loss=0.1935063493796266
Epoch #125: loss=0.17710226369448578
Epoch #126: loss=0.17711723108704275
Epoch #127: loss=0.2035172373916094
Epoch #128: loss=0.19039403059734747
Epoch #129: loss=0.26162963926505584
Epoch #130: loss=0.32481673854188275
Epoch #131: loss=0.28317237143906265
Epoch #132: loss=0.17578111968647975
Epoch #133: loss=0.1746786588516373
Epoch #134: loss=0.17801371023345453
Epoch #135: loss=0.25053418499345964
Epoch #136: loss=0.26374899381055283
Epoch #137: loss=0.22678830209546363
Epoch #138: loss=0.19602973501269633
Epoch #139: loss=0.1714493716852023
Epoch #140: loss=0.13851461860422903
Epoch #141: loss=0.17796398641971442
Epoch #142: loss=0.1514242046799224
Epoch #143: loss=0.12442277024428432
Epoch #144: loss=0.15009939201319447
Epoch #145: loss=0.17370945487457973
Epoch #146: loss=0.13873673964721653
Epoch #147: loss=0.1667578720416014
Epoch #148: loss=0.1517499199566933
Epoch #149: loss=0.13078232507149762
Epoch #150: loss=0.10959238781092259
Epoch #151: loss=0.13171597516450745
Epoch #152: loss=0.1492027026028014
Epoch #153: loss=0.13059510319278791
Epoch #154: loss=0.1246163695334242
Epoch #155: loss=0.1231013282846946
Epoch #156: loss=0.14613561052829027
Epoch #157: loss=0.14790968740215668
Epoch #158: loss=0.1558949571604339
Epoch #159: loss=0.1361171051931496
Epoch #160: loss=0.14089371962472796
Epoch #161: loss=0.12407523232440536
Epoch #162: loss=0.1676737039278333
Epoch #163: loss=0.1778261554427445
Epoch #164: loss=0.19945243169338658
Epoch #165: loss=0.16955516773920792
Epoch #166: loss=0.1429213983221696
Epoch #167: loss=0.13015733662849435
Epoch #168: loss=0.11103403070368446
Epoch #169: loss=0.09779871158445111
Epoch #170: loss=0.11109057321356466
Epoch #171: loss=0.18919322367470998
Epoch #172: loss=0.12824843698539412
Epoch #173: loss=0.10799814463378145
Epoch #174: loss=0.12084034081691733
Epoch #175: loss=0.11442429196232787
Epoch #176: loss=0.10748818717323817
Epoch #177: loss=0.1614957462924604
Epoch #178: loss=0.1302438762683708
Epoch #179: loss=0.11877083950317822
Epoch #180: loss=0.12908088437353188
Epoch #181: loss=0.10594526997122627
Epoch #182: loss=0.14701288057347903
Epoch #183: loss=0.10413389688787553
Epoch #184: loss=0.11213524406775832
Epoch #185: loss=0.08782945913620867
Epoch #186: loss=0.11094692764947048
Epoch #187: loss=0.12728578310746413
Epoch #188: loss=0.11876791006383988
Epoch #189: loss=0.13335209930888736
Epoch #190: loss=0.12689435163226265
Epoch #191: loss=0.15870715351775289
Epoch #192: loss=0.13692874962893817
Epoch #193: loss=0.1234942192498308
Epoch #194: loss=0.1127005208713504
Epoch #195: loss=0.10163100816022891
Epoch #196: loss=0.1770504034983997
Epoch #197: loss=0.19018746787109053
Epoch #198: loss=0.13330069889959234
Epoch #199: loss=0.10924926597195175
Epoch #200: loss=0.10627828219618934
Epoch #201: loss=0.11954695500361805
Epoch #202: loss=0.11546902548378477
Epoch #203: loss=0.16610011999280408
Epoch #204: loss=0.12280486878724052
Epoch #205: loss=0.09826442696010837
Epoch #206: loss=0.09324115991162565
Epoch #207: loss=0.1697354674196014
Epoch #208: loss=0.14767677601999962
Epoch #209: loss=0.11155681770581466
Epoch #210: loss=0.09548196443714775
Epoch #211: loss=0.09316658669223006
Epoch #212: loss=0.14364952088978428
Epoch #213: loss=0.09858206351502584
Epoch #214: loss=0.08777604895070769
Epoch #215: loss=0.09011114540939721
Epoch #216: loss=0.08068264707421455
Epoch #217: loss=0.1309379915205332
Epoch #218: loss=0.07115376296524818
Epoch #219: loss=0.07813524771839954
Epoch #220: loss=0.08260640457200889
Epoch #221: loss=0.09780494951141569
Epoch #222: loss=0.10237057055704869
Epoch #223: loss=0.08517796329509181
Epoch #224: loss=0.07542740292130755
Epoch #225: loss=0.07215985852795151
Epoch #226: loss=0.1117815961344884
Epoch #227: loss=0.06512346722257252
Epoch #228: loss=0.09868232454531468
Epoch #229: loss=0.11354249966545747
Epoch #230: loss=0.12398028289541028
Epoch #231: loss=0.11819600972991723
Epoch #232: loss=0.10304193958066978
Epoch #233: loss=0.09860939485952258
Epoch #234: loss=0.09647395468961734
Epoch #235: loss=0.11239298366798231
Epoch #236: loss=0.10744720100998305
Epoch #237: loss=0.10514784799530529
Epoch #238: loss=0.06493609088759583
Epoch #239: loss=0.08681890252046287
Epoch #240: loss=0.09424937781519614
Epoch #241: loss=0.11101645421093473
Epoch #242: loss=0.13256235435031927
Epoch #243: loss=0.11465408076317264
Epoch #244: loss=0.08911440251036905
Epoch #245: loss=0.07090532948048069
Epoch #246: loss=0.06254281974039398
Epoch #247: loss=0.061148332252811924
Epoch #248: loss=0.05980419851123141
Epoch #249: loss=0.07338052327171542

Training time: 0:16:00.137384

Finished.
n2one setting etth1_ettm1_weather_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_weather_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_ettm1_weather_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.4923e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.83548e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.4923e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3640598121849082, 'MAE': 0.42976938946842497}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm2_electricity_traffic', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm2_electricity_traffic_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.8423382980341121
Epoch #1: loss=0.2881611810561322
Epoch #2: loss=0.18864122974212522
Epoch #3: loss=0.1423078863156477
Epoch #4: loss=0.12031522726517584
Epoch #5: loss=0.10020050744787416
Epoch #6: loss=0.07596284960265536
Epoch #7: loss=0.06804471628447308
Epoch #8: loss=0.05971799821916232
Epoch #9: loss=0.053118199090257
Epoch #10: loss=0.04584951479461736
Epoch #11: loss=0.051604022912651634
Epoch #12: loss=0.03683304755431255
Epoch #13: loss=0.04443069104997784
Epoch #14: loss=0.03831565354196208
Epoch #15: loss=0.036699851885085906
Epoch #16: loss=0.04271073502931995
Epoch #17: loss=0.032786975413011066
Epoch #18: loss=0.030231541719793233
Epoch #19: loss=0.028369964043327534
Epoch #20: loss=0.035798768728966056
Epoch #21: loss=0.027263589523160568
Epoch #22: loss=0.028921642812196908
Epoch #23: loss=0.029118341463269026
Epoch #24: loss=0.02749181162525429
Epoch #25: loss=0.022719997629749324
Epoch #26: loss=0.02356173433234518
Epoch #27: loss=0.020760566095040674
Epoch #28: loss=0.026878199763070685
Epoch #29: loss=0.02238133906031634
Epoch #30: loss=0.021569091824157092
Epoch #31: loss=0.020220122526424605
Epoch #32: loss=0.023186494672975715
Epoch #33: loss=0.01811173815550833
Epoch #34: loss=0.024068449865485758
Epoch #35: loss=0.021197122438288495
Epoch #36: loss=0.01589036247437877
Epoch #37: loss=0.025803970823414953
Epoch #38: loss=0.023792218076310226
Epoch #39: loss=0.016427548596649806
Epoch #40: loss=0.01783199733310068
Epoch #41: loss=0.017457871485319684
Epoch #42: loss=0.019452114597169976
Epoch #43: loss=0.015715546749109986
Epoch #44: loss=0.021389447937375995
Epoch #45: loss=0.01940615881366429
Epoch #46: loss=0.019963823194562424
Epoch #47: loss=0.017433381917494637
Epoch #48: loss=0.018771341868089226
Epoch #49: loss=0.0177067944155847
Epoch #50: loss=0.016640527401903214
Epoch #51: loss=0.019751460696911777
Epoch #52: loss=0.015382562060262714
Epoch #53: loss=0.018656890386459922
Epoch #54: loss=0.013796518920050533
Epoch #55: loss=0.018706655296319468
Epoch #56: loss=0.015509256203720916
Epoch #57: loss=0.018863583822365537
Epoch #58: loss=0.02632333138086395
Epoch #59: loss=0.013725939368946226
Epoch #60: loss=0.016732565837000713
Epoch #61: loss=0.019621922361436103
Epoch #62: loss=0.01336214344689334
Epoch #63: loss=0.014908015924332574
Epoch #64: loss=0.017816172932200197
Epoch #65: loss=0.01438757114342203
Epoch #66: loss=0.018074698022558594
Epoch #67: loss=0.016072373460191375
Epoch #68: loss=0.01320444362053491
Epoch #69: loss=0.013522915822501487
Epoch #70: loss=0.013931865244430158
Epoch #71: loss=0.01751716601392673
Epoch #72: loss=0.013175687611579575
Epoch #73: loss=0.010551624747248503
Epoch #74: loss=0.01632628488783018
Epoch #75: loss=0.014227453983148643
Epoch #76: loss=0.013478755525323592
Epoch #77: loss=0.014170668328291024
Epoch #78: loss=0.014494747570758495
Epoch #79: loss=0.0137900147307606
Epoch #80: loss=0.014299153600281243
Epoch #81: loss=0.013074839372516646
Epoch #82: loss=0.009400513732322787
Epoch #83: loss=0.019361487627676924
Epoch #84: loss=0.010039777797806758
Epoch #85: loss=0.01835258810039994
Epoch #86: loss=0.012108224803175882
Epoch #87: loss=0.015036753710558239
Epoch #88: loss=0.013259908208993518
Epoch #89: loss=0.010273872586995147
Epoch #90: loss=0.015021655407056564
Epoch #91: loss=0.018290986743837837
Epoch #92: loss=0.011579081350385942
Epoch #93: loss=0.014049289042141163
Epoch #94: loss=0.010566869641473513
Epoch #95: loss=0.012055314757344452
Epoch #96: loss=0.014478375860234004
Epoch #97: loss=0.012076373051544326
Epoch #98: loss=0.011214539747679185
Epoch #99: loss=0.012790617079071377
Epoch #100: loss=0.00927206048891018
Epoch #101: loss=0.014310728989332255
Epoch #102: loss=0.013874364919328697
Epoch #103: loss=0.013708990870991533
Epoch #104: loss=0.010353290472100362
Epoch #105: loss=0.010070396489969246
Epoch #106: loss=0.015662005271674013
Epoch #107: loss=0.011885069372120013
Epoch #108: loss=0.01217132381814775
Epoch #109: loss=0.011409792571707003
Epoch #110: loss=0.012749382985506347
Epoch #111: loss=0.012871696459292105
Epoch #112: loss=0.011918843683521968
Epoch #113: loss=0.013204651588025805
Epoch #114: loss=0.008963860625545701
Epoch #115: loss=0.015703423296146563
Epoch #116: loss=0.010471467766688454
Epoch #117: loss=0.014277843696839347
Epoch #118: loss=0.014654949997815588
Epoch #119: loss=0.009730183777989095
Epoch #120: loss=0.012309163748785379
Epoch #121: loss=0.010695074700075666
Epoch #122: loss=0.009062437604962838
Epoch #123: loss=0.010287133648544826
Epoch #124: loss=0.012651590979973096
Epoch #125: loss=0.009009704360642483
Epoch #126: loss=0.013877118352856247
Epoch #127: loss=0.01210709237728877
Epoch #128: loss=0.009831239386109037
Epoch #129: loss=0.01585056534597794
Epoch #130: loss=0.009869051711024293
Epoch #131: loss=0.010644138704421817
Epoch #132: loss=0.009939129159574107
Epoch #133: loss=0.010450846029312344
Epoch #134: loss=0.005925598014650378
Epoch #135: loss=0.011204265139584656
Epoch #136: loss=0.012241446030606127
Epoch #137: loss=0.012472489930107356
Epoch #138: loss=0.008040515539280665
Epoch #139: loss=0.009675419164545153
Epoch #140: loss=0.010958945234559633
Epoch #141: loss=0.013907381419050154
Epoch #142: loss=0.009530084343541198
Epoch #143: loss=0.011283828779114272
Epoch #144: loss=0.020422389225577348
Epoch #145: loss=0.010439681788074973
Epoch #146: loss=0.010130002579855234
Epoch #147: loss=0.00999024339942027
Epoch #148: loss=0.013453598612360928
Epoch #149: loss=0.009962069422230907
Epoch #150: loss=0.00920818151672672
Epoch #151: loss=0.008045043377288121
Epoch #152: loss=0.016653193582866783
Epoch #153: loss=0.01161734873251943
Epoch #154: loss=0.008032784037995051
Epoch #155: loss=0.014788659463702393
Epoch #156: loss=0.00843754194724712
Epoch #157: loss=0.01493124225958918
Epoch #158: loss=0.011730477099116314
Epoch #159: loss=0.01031201437891513
Epoch #160: loss=0.00836092076747964
Epoch #161: loss=0.01167766956096208
Epoch #162: loss=0.019856482383193718
Epoch #163: loss=0.009525534317885033
Epoch #164: loss=0.009284439262844536
Epoch #165: loss=0.00974182988131488
Epoch #166: loss=0.0088713490931014
Epoch #167: loss=0.009128616223216241
Epoch #168: loss=0.01023297993339568
Epoch #169: loss=0.007216981708266087
Epoch #170: loss=0.01299740049215871
Epoch #171: loss=0.008591634625884305
Epoch #172: loss=0.010507300275835544
Epoch #173: loss=0.011832664253375995
Epoch #174: loss=0.010013934947484092
Epoch #175: loss=0.011071581428175138
Epoch #176: loss=0.007025113591540847
Epoch #177: loss=0.009772797386895953
Epoch #178: loss=0.012254523479421492
Epoch #179: loss=0.010993319177766196
Epoch #180: loss=0.007889754760102858
Epoch #181: loss=0.00800509433881494
Epoch #182: loss=0.009813505519205432
Epoch #183: loss=0.008566694399836688
Epoch #184: loss=0.010796042479572063
Epoch #185: loss=0.018188926079642953
Epoch #186: loss=0.008956816728813473
Epoch #187: loss=0.01012916110792974
Epoch #188: loss=0.012608589978387881
Epoch #189: loss=0.007055905152229145
Epoch #190: loss=0.014369288719852233
Epoch #191: loss=0.007444445695875885
Epoch #192: loss=0.008313065559967641
Epoch #193: loss=0.010037146216395275
Epoch #194: loss=0.012170402947192424
Epoch #195: loss=0.010853012472772653
Epoch #196: loss=0.008386028645564798
Epoch #197: loss=0.00886487464745365
Epoch #198: loss=0.01111710121602438
Epoch #199: loss=0.010997414901924463
Epoch #200: loss=0.010581613932136694
Epoch #201: loss=0.007821854492784656
Epoch #202: loss=0.009329604354890813
Epoch #203: loss=0.010733234681380792
Epoch #204: loss=0.010687046815607008
Epoch #205: loss=0.008857802330686103
Epoch #206: loss=0.00821730153772503
Epoch #207: loss=0.008188363754240037
Epoch #208: loss=0.009730027398558307
Epoch #209: loss=0.015091527033490966
Epoch #210: loss=0.008207989443085857
Epoch #211: loss=0.007738166079229984
Epoch #212: loss=0.00933922442308086
Epoch #213: loss=0.009917057231181537
Epoch #214: loss=0.008272309175479223
Epoch #215: loss=0.008548998316825731
Epoch #216: loss=0.010984116130240756
Epoch #217: loss=0.008385111282778166
Epoch #218: loss=0.019745812952220106
Epoch #219: loss=0.0075559218129608195
Epoch #220: loss=0.018689593583894822
Epoch #221: loss=0.00905475328300985
Epoch #222: loss=0.010402639997957732
Epoch #223: loss=0.008888506475778074
Epoch #224: loss=0.009809132763812
Epoch #225: loss=0.007976788491076265
Epoch #226: loss=0.011580496144144262
Epoch #227: loss=0.009065893929231475
Epoch #228: loss=0.0070536130952949935
Epoch #229: loss=0.012525701372650414
Epoch #230: loss=0.007576707572694707
Epoch #231: loss=0.009699810937799052
Epoch #232: loss=0.01045115412578148
Epoch #233: loss=0.008116877868618316
Epoch #234: loss=0.006618415361183207
Epoch #235: loss=0.010693940688853716
Epoch #236: loss=0.008341464390455269
Epoch #237: loss=0.017291199739796183
Epoch #238: loss=0.009025512530523316
Epoch #239: loss=0.016909099347828065
Epoch #240: loss=0.005865280869717309
Epoch #241: loss=0.008951926162860628
Epoch #242: loss=0.008036401022726175
Epoch #243: loss=0.004664282571255226
Epoch #244: loss=0.009360795837531287
Epoch #245: loss=0.008412463556188814
Epoch #246: loss=0.011458505239664537
Epoch #247: loss=0.009240214077455901
Epoch #248: loss=0.006422374256589251
Epoch #249: loss=0.007284442439925319

Training time: 5:00:22.957610

Finished.
n2one setting etth1_ettm2_electricity_traffic -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm2_electricity_traffic_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_ettm2_electricity_traffic', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.3158e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.85172e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.94485e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.5504829491246405, 'MAE': 0.552111370752233}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm2_electricity_traffic -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm2_electricity_traffic_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_ettm2_electricity_traffic', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.38525e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.23235594995911674, 'MAE': 0.3267967839732605}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm2_electricity_weather', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm2_electricity_weather_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.7322629450118705
Epoch #1: loss=0.7477076444723835
Epoch #2: loss=0.5309613293164397
Epoch #3: loss=0.4585416670123192
Epoch #4: loss=0.3973425501421706
Epoch #5: loss=0.3470128915897787
Epoch #6: loss=0.2981681284022658
Epoch #7: loss=0.26852253606058146
Epoch #8: loss=0.24333556098480746
Epoch #9: loss=0.20701856319218465
Epoch #10: loss=0.1880010708247962
Epoch #11: loss=0.17291507148375249
Epoch #12: loss=0.17650730291458025
Epoch #13: loss=0.21082241524980494
Epoch #14: loss=0.1792640580808463
Epoch #15: loss=0.12792910187415882
Epoch #16: loss=0.11330790673318791
Epoch #17: loss=0.12116258722053816
Epoch #18: loss=0.12302267648892043
Epoch #19: loss=0.09525188507690821
Epoch #20: loss=0.13215823697104845
Epoch #21: loss=0.09556975618310987
Epoch #22: loss=0.08890488522050724
Epoch #23: loss=0.11584930650328529
Epoch #24: loss=0.08130677644775747
Epoch #25: loss=0.0809038823011191
Epoch #26: loss=0.08677370466087779
Epoch #27: loss=0.09594418288859194
Epoch #28: loss=0.05886070228449694
Epoch #29: loss=0.0643003004513783
Epoch #30: loss=0.053120488045762665
Epoch #31: loss=0.06135526558078111
Epoch #32: loss=0.06391281012496719
Epoch #33: loss=0.059915662716359716
Epoch #34: loss=0.05565539979924486
Epoch #35: loss=0.0477214479015196
Epoch #36: loss=0.042155471775833876
Epoch #37: loss=0.05049402408161494
Epoch #38: loss=0.06247334557789544
Epoch #39: loss=0.07258168908333636
Epoch #40: loss=0.07007571432535371
Epoch #41: loss=0.041972159628105694
Epoch #42: loss=0.037707754812037496
Epoch #43: loss=0.06173656379089576
Epoch #44: loss=0.03966779628679258
Epoch #45: loss=0.03623442428428935
Epoch #46: loss=0.03820600167478192
Epoch #47: loss=0.041475776045213214
Epoch #48: loss=0.05562809374923371
Epoch #49: loss=0.03584129344353019
Epoch #50: loss=0.047493473873537494
Epoch #51: loss=0.041331186465765925
Epoch #52: loss=0.03228979502830093
Epoch #53: loss=0.03948501181590996
Epoch #54: loss=0.04175578051546512
Epoch #55: loss=0.050300323100097175
Epoch #56: loss=0.03990264651748313
Epoch #57: loss=0.026328454820171304
Epoch #58: loss=0.03126920899822798
Epoch #59: loss=0.03150738504849221
Epoch #60: loss=0.043250619858656435
Epoch #61: loss=0.02718611571982452
Epoch #62: loss=0.02716997415688501
Epoch #63: loss=0.030869324116214906
Epoch #64: loss=0.030839043561598823
Epoch #65: loss=0.032427180187189826
Epoch #66: loss=0.029707978625960443
Epoch #67: loss=0.037034156580442845
Epoch #68: loss=0.025588411881192905
Epoch #69: loss=0.02914207170921544
Epoch #70: loss=0.0330052685056341
Epoch #71: loss=0.03683453525786531
Epoch #72: loss=0.025835636242496948
Epoch #73: loss=0.022126631207974652
Epoch #74: loss=0.024558864307130546
Epoch #75: loss=0.01447808229434623
Epoch #76: loss=0.026202239944401823
Epoch #77: loss=0.027805488480395345
Epoch #78: loss=0.018716881715226917
Epoch #79: loss=0.02187683523300882
Epoch #80: loss=0.030702062788712854
Epoch #81: loss=0.020678537487600967
Epoch #82: loss=0.03218980879309166
Epoch #83: loss=0.03588056279257042
Epoch #84: loss=0.042199648526969225
Epoch #85: loss=0.024791466686491893
Epoch #86: loss=0.02803759597949939
Epoch #87: loss=0.01946196880012955
Epoch #88: loss=0.026320832282661983
Epoch #89: loss=0.01534756028032798
Epoch #90: loss=0.055300520551518524
Epoch #91: loss=0.025428081774918287
Epoch #92: loss=0.021997222487738177
Epoch #93: loss=0.019039669388280032
Epoch #94: loss=0.017748814813748053
Epoch #95: loss=0.023288855043699173
Epoch #96: loss=0.016030248388813884
Epoch #97: loss=0.019553004599763207
Epoch #98: loss=0.019772563377165632
Epoch #99: loss=0.02340717985077876
Epoch #100: loss=0.02113974825574774
Epoch #101: loss=0.034355697360476604
Epoch #102: loss=0.019585760243951457
Epoch #103: loss=0.01946601567021252
Epoch #104: loss=0.03321788593431399
Epoch #105: loss=0.025221112663283536
Epoch #106: loss=0.018310361809243947
Epoch #107: loss=0.013999073757400915
Epoch #108: loss=0.026354025373688247
Epoch #109: loss=0.041060528000306386
Epoch #110: loss=0.03473999335475215
Epoch #111: loss=0.03830657273607507
Epoch #112: loss=0.038713303742107415
Epoch #113: loss=0.01866446841294456
Epoch #114: loss=0.015122559208308078
Epoch #115: loss=0.062456847878160235
Epoch #116: loss=0.0238258796386829
Epoch #117: loss=0.019257799251489852
Epoch #118: loss=0.020495249558406026
Epoch #119: loss=0.018286064075312438
Epoch #120: loss=0.029060192406336994
Epoch #121: loss=0.01680360090781692
Epoch #122: loss=0.027102347293530577
Epoch #123: loss=0.018355001686204683
Epoch #124: loss=0.022664451770076196
Epoch #125: loss=0.020525741572204773
Epoch #126: loss=0.019431868618456263
Epoch #127: loss=0.025014476970393107
Epoch #128: loss=0.01921306724137027
Epoch #129: loss=0.011608256430967953
Epoch #130: loss=0.01641247177557152
Epoch #131: loss=0.03144725217238349
Epoch #132: loss=0.023008661183579634
Epoch #133: loss=0.017088469556909156
Epoch #134: loss=0.014996943625379098
Epoch #135: loss=0.02357053418694804
Epoch #136: loss=0.014186175896830806
Epoch #137: loss=0.018030204878616056
Epoch #138: loss=0.024934034461908245
Epoch #139: loss=0.02810515928551019
Epoch #140: loss=0.017774874535357348
Epoch #141: loss=0.012907233171098011
Epoch #142: loss=0.018645769954907822
Epoch #143: loss=0.02493933145792466
Epoch #144: loss=0.020773023357040774
Epoch #145: loss=0.016537743600161924
Epoch #146: loss=0.019029147751718656
Epoch #147: loss=0.01811192941450042
Epoch #148: loss=0.016286089413397473
Epoch #149: loss=0.016034319003476214
Epoch #150: loss=0.016557690054848025
Epoch #151: loss=0.02276812340364128
Epoch #152: loss=0.01941539782756455
Epoch #153: loss=0.013227027884607955
Epoch #154: loss=0.014789034936047631
Epoch #155: loss=0.013543498438997482
Epoch #156: loss=0.01690837499503786
Epoch #157: loss=0.02461654679747681
Epoch #158: loss=0.013812139228445618
Epoch #159: loss=0.01411193300944383
Epoch #160: loss=0.022893412194967475
Epoch #161: loss=0.019107751256135636
Epoch #162: loss=0.02202247083378471
Epoch #163: loss=0.01291312914443751
Epoch #164: loss=0.018698120354323916
Epoch #165: loss=0.01583748906109265
Epoch #166: loss=0.01308701520527343
Epoch #167: loss=0.018179145807157945
Epoch #168: loss=0.013657172181649925
Epoch #169: loss=0.011224896617932245
Epoch #170: loss=0.012278823289870323
Epoch #171: loss=0.013704601051094495
Epoch #172: loss=0.015200193048365515
Epoch #173: loss=0.016626520329537764
Epoch #174: loss=0.020916097971916913
Epoch #175: loss=0.017756920052239392
Epoch #176: loss=0.01249732636290041
Epoch #177: loss=0.015010192921889104
Epoch #178: loss=0.03446551050021224
Epoch #179: loss=0.020229084371774113
Epoch #180: loss=0.02390674447277178
Epoch #181: loss=0.014292549516141338
Epoch #182: loss=0.02704854393680899
Epoch #183: loss=0.016682617641404933
Epoch #184: loss=0.028564586755835567
Epoch #185: loss=0.015270869470877598
Epoch #186: loss=0.02999296566640499
Epoch #187: loss=0.01860829933342358
Epoch #188: loss=0.01723577078760359
Epoch #189: loss=0.01569772138402236
Epoch #190: loss=0.020393163444193667
Epoch #191: loss=0.018031063922824442
Epoch #192: loss=0.007344206252050816
Epoch #193: loss=0.015390161404303236
Epoch #194: loss=0.013563105023038664
Epoch #195: loss=0.026329887229773814
Epoch #196: loss=0.011680910633143344
Epoch #197: loss=0.015304610496610149
Epoch #198: loss=0.031567932975044705
Epoch #199: loss=0.021304762359447012
Epoch #200: loss=0.013870794744922919
Epoch #201: loss=0.010746656851811105
Epoch #202: loss=0.01235315122766012
Epoch #203: loss=0.0153310511934201
Epoch #204: loss=0.01984334364358004
Epoch #205: loss=0.013537240811114914
Epoch #206: loss=0.018065648848009104
Epoch #207: loss=0.010780003833367604
Epoch #208: loss=0.014924403469712945
Epoch #209: loss=0.012913279927635489
Epoch #210: loss=0.014843443326320345
Epoch #211: loss=0.022702876484174638
Epoch #212: loss=0.01846844319673574
Epoch #213: loss=0.012451028183408796
Epoch #214: loss=0.01712091743207715
Epoch #215: loss=0.010652395260475627
Epoch #216: loss=0.027523745190390476
Epoch #217: loss=0.012890623316124132
Epoch #218: loss=0.010370182574085559
Epoch #219: loss=0.010512727479831546
Epoch #220: loss=0.01262222538879205
Epoch #221: loss=0.0122971264422195
Epoch #222: loss=0.01293002052203918
Epoch #223: loss=0.01326785401428399
Epoch #224: loss=0.012166026084323427
Epoch #225: loss=0.02215194927994162
Epoch #226: loss=0.02731981350026055
Epoch #227: loss=0.017698922431676915
Epoch #228: loss=0.02318823571637439
Epoch #229: loss=0.022346784855631397
Epoch #230: loss=0.013488766667672293
Epoch #231: loss=0.013929005852925962
Epoch #232: loss=0.014263765961338434
Epoch #233: loss=0.009982472074486009
Epoch #234: loss=0.010886206866436548
Epoch #235: loss=0.014495322232976659
Epoch #236: loss=0.011748429409894862
Epoch #237: loss=0.01016640660204695
Epoch #238: loss=0.00974194367865917
Epoch #239: loss=0.030688662923017695
Epoch #240: loss=0.014756565600671895
Epoch #241: loss=0.013598828233797614
Epoch #242: loss=0.01165093865711242
Epoch #243: loss=0.015417446626178053
Epoch #244: loss=0.01964099859541333
Epoch #245: loss=0.009040788828183209
Epoch #246: loss=0.010408092566450089
Epoch #247: loss=0.013198095666203164
Epoch #248: loss=0.010109313175700962
Epoch #249: loss=0.01690692604528995

Training time: 1:43:16.279572

Finished.
n2one setting etth1_ettm2_electricity_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm2_electricity_weather_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_ettm2_electricity_weather', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.40595e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.35264488857542065, 'MAE': 0.3872030976885358}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm2_electricity_exchange', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm2_electricity_exchange_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.7031149137604134
Epoch #1: loss=0.7227260344138406
Epoch #2: loss=0.5030625760984696
Epoch #3: loss=0.4059833449228353
Epoch #4: loss=0.3455162096865239
Epoch #5: loss=0.3042034558758612
Epoch #6: loss=0.2689233549175414
Epoch #7: loss=0.23071016963861174
Epoch #8: loss=0.21439119318892014
Epoch #9: loss=0.18841578925205582
Epoch #10: loss=0.18410815635658478
Epoch #11: loss=0.16607011397307475
Epoch #12: loss=0.15307260722308405
Epoch #13: loss=0.14008334877576023
Epoch #14: loss=0.1132765717654132
Epoch #15: loss=0.14345717907316918
Epoch #16: loss=0.12605472182806698
Epoch #17: loss=0.12845115669565516
Epoch #18: loss=0.12392377972023116
Epoch #19: loss=0.09799018265244683
Epoch #20: loss=0.10008343258706225
Epoch #21: loss=0.09590480894236812
Epoch #22: loss=0.09219518813012055
Epoch #23: loss=0.08365442272898357
Epoch #24: loss=0.08513019216496508
Epoch #25: loss=0.08618510007772391
Epoch #26: loss=0.07637348235115109
Epoch #27: loss=0.06608292668714304
Epoch #28: loss=0.06480590150468803
Epoch #29: loss=0.0843863214368822
Epoch #30: loss=0.062202984213517706
Epoch #31: loss=0.07016075094920242
Epoch #32: loss=0.05774499673761363
Epoch #33: loss=0.06362664280325088
Epoch #34: loss=0.06921667482177875
Epoch #35: loss=0.051197793747376256
Epoch #36: loss=0.05835762111032623
Epoch #37: loss=0.04966451209951031
Epoch #38: loss=0.05286537344508431
Epoch #39: loss=0.0553629820695367
Epoch #40: loss=0.042370912069401113
Epoch #41: loss=0.06682508973463812
Epoch #42: loss=0.043429616282449804
Epoch #43: loss=0.04487383569475339
Epoch #44: loss=0.03353399767806104
Epoch #45: loss=0.04106969225974565
Epoch #46: loss=0.04097137523087692
Epoch #47: loss=0.04937232379071543
Epoch #48: loss=0.056327223626800114
Epoch #49: loss=0.062384153399562804
Epoch #50: loss=0.042294007104684624
Epoch #51: loss=0.035886811426309305
Epoch #52: loss=0.033930791266496035
Epoch #53: loss=0.04692334549700149
Epoch #54: loss=0.03903448693145614
Epoch #55: loss=0.04140996513015964
Epoch #56: loss=0.03394760882014929
Epoch #57: loss=0.04114860457352092
Epoch #58: loss=0.040447089993207036
Epoch #59: loss=0.042538617662776806
Epoch #60: loss=0.03650697717652455
Epoch #61: loss=0.03227932400993402
Epoch #62: loss=0.02605283073611257
Epoch #63: loss=0.03399800485495199
Epoch #64: loss=0.04319675911623201
Epoch #65: loss=0.03456824700722487
Epoch #66: loss=0.02255128397101735
Epoch #67: loss=0.05711992934610566
Epoch #68: loss=0.05399648873947335
Epoch #69: loss=0.04911829239181552
Epoch #70: loss=0.02631333400361154
Epoch #71: loss=0.023738060658193737
Epoch #72: loss=0.02895010602848352
Epoch #73: loss=0.030746126655148347
Epoch #74: loss=0.03266290799709257
Epoch #75: loss=0.027950792650890774
Epoch #76: loss=0.027389144692006345
Epoch #77: loss=0.027477527299952245
Epoch #78: loss=0.024866515638874386
Epoch #79: loss=0.031918094183455196
Epoch #80: loss=0.033311857796953157
Epoch #81: loss=0.027538167032270938
Epoch #82: loss=0.02630026923993774
Epoch #83: loss=0.033627421886697734
Epoch #84: loss=0.04920552272426088
Epoch #85: loss=0.03213188109848305
Epoch #86: loss=0.01872414867970717
Epoch #87: loss=0.026272958096905857
Epoch #88: loss=0.027769089179577825
Epoch #89: loss=0.027542269538406293
Epoch #90: loss=0.03342397101203339
Epoch #91: loss=0.02192319610145383
Epoch #92: loss=0.028314202694123027
Epoch #93: loss=0.02833961469311836
Epoch #94: loss=0.01621833224079682
Epoch #95: loss=0.020158334594268235
Epoch #96: loss=0.026747164715709492
Epoch #97: loss=0.055723088758900995
Epoch #98: loss=0.027431427875214312
Epoch #99: loss=0.021601041705952822
Epoch #100: loss=0.021545450921406598
Epoch #101: loss=0.022876096749309214
Epoch #102: loss=0.02363814986532323
Epoch #103: loss=0.02270412012889058
Epoch #104: loss=0.029575005150534298
Epoch #105: loss=0.02740377521206778
Epoch #106: loss=0.034743812940987925
Epoch #107: loss=0.030560496375427692
Epoch #108: loss=0.02087666509456272
Epoch #109: loss=0.01843777803622954
Epoch #110: loss=0.017588957397553062
Epoch #111: loss=0.028567701631818793
Epoch #112: loss=0.02100402712909188
Epoch #113: loss=0.019246963542377475
Epoch #114: loss=0.025156162010729902
Epoch #115: loss=0.02544965543928462
Epoch #116: loss=0.028920448567853807
Epoch #117: loss=0.021644492157747008
Epoch #118: loss=0.01782696501496825
Epoch #119: loss=0.016502648505774094
Epoch #120: loss=0.020405637434152323
Epoch #121: loss=0.020715732640225807
Epoch #122: loss=0.02948347335464592
Epoch #123: loss=0.02237006991089158
Epoch #124: loss=0.03473121047278958
Epoch #125: loss=0.018927000135653693
Epoch #126: loss=0.02410967729469729
Epoch #127: loss=0.026785875419329218
Epoch #128: loss=0.020749925392524203
Epoch #129: loss=0.021916060098540843
Epoch #130: loss=0.014825587271429566
Epoch #131: loss=0.018200312807192483
Epoch #132: loss=0.014292749225850396
Epoch #133: loss=0.024200331595671292
Epoch #134: loss=0.020348719487427024
Epoch #135: loss=0.02631872552259146
Epoch #136: loss=0.02573416458331424
Epoch #137: loss=0.0190633424034883
Epoch #138: loss=0.033718735943494706
Epoch #139: loss=0.02308938947324413
Epoch #140: loss=0.017792875774762316
Epoch #141: loss=0.02503324918259708
Epoch #142: loss=0.032635351839731645
Epoch #143: loss=0.03615238439135377
Epoch #144: loss=0.018337040960282807
Epoch #145: loss=0.024612084016343443
Epoch #146: loss=0.015917904482099635
Epoch #147: loss=0.015428674560203285
Epoch #148: loss=0.028716899554066692
Epoch #149: loss=0.013789100441289932
Epoch #150: loss=0.016410818230729787
Epoch #151: loss=0.017838854308562857
Epoch #152: loss=0.03248409168094917
Epoch #153: loss=0.03096654426601047
Epoch #154: loss=0.03472437021075627
Epoch #155: loss=0.02064587265841518
Epoch #156: loss=0.020028861152157133
Epoch #157: loss=0.01988618978133468
Epoch #158: loss=0.018812907069266617
Epoch #159: loss=0.019068096031338213
Epoch #160: loss=0.024360894442768097
Epoch #161: loss=0.020128584464190673
Epoch #162: loss=0.022231806620823955
Epoch #163: loss=0.025851628763912518
Epoch #164: loss=0.02031144592223249
Epoch #165: loss=0.016208627546388625
Epoch #166: loss=0.02247519002194377
Epoch #167: loss=0.021209362055569544
Epoch #168: loss=0.022626662575280808
Epoch #169: loss=0.018391067700954396
Epoch #170: loss=0.017475101826893654
Epoch #171: loss=0.016987055211974796
Epoch #172: loss=0.018593425361938795
Epoch #173: loss=0.013850570631281256
Epoch #174: loss=0.01788863482444228
Epoch #175: loss=0.020302054571489044
Epoch #176: loss=0.025891748189547713
Epoch #177: loss=0.04877634671374469
Epoch #178: loss=0.02257351303185935
Epoch #179: loss=0.025708130790962052
Epoch #180: loss=0.016892228970339023
Epoch #181: loss=0.012932218203535142
Epoch #182: loss=0.016564106148827328
Epoch #183: loss=0.019480828903192755
Epoch #184: loss=0.01486623614002556
Epoch #185: loss=0.01555985155728745
Epoch #186: loss=0.015766648681175437
Epoch #187: loss=0.02024714958079707
Epoch #188: loss=0.01590370668231856
Epoch #189: loss=0.014333417056556469
Epoch #190: loss=0.01712822579488196
Epoch #191: loss=0.012489063090994358
Epoch #192: loss=0.013257530735190341
Epoch #193: loss=0.03188792406581342
Epoch #194: loss=0.025364697663420786
Epoch #195: loss=0.013371001695207607
Epoch #196: loss=0.010980480025882727
Epoch #197: loss=0.01787879958652196
Epoch #198: loss=0.027998380639851335
Epoch #199: loss=0.02711594173408272
Epoch #200: loss=0.01835292703812601
Epoch #201: loss=0.019170502033648257
Epoch #202: loss=0.02046450552371564
Epoch #203: loss=0.015061127088503693
Epoch #204: loss=0.01829414502796395
Epoch #205: loss=0.014846659026924596
Epoch #206: loss=0.014681935243601093
Epoch #207: loss=0.016738869802038633
Epoch #208: loss=0.01646896154290637
Epoch #209: loss=0.01423939680046555
Epoch #210: loss=0.019817757082738047
Epoch #211: loss=0.01722951906985504
Epoch #212: loss=0.024423476143690465
Epoch #213: loss=0.022638896779795997
Epoch #214: loss=0.026859713896189116
Epoch #215: loss=0.02160959765053373
Epoch #216: loss=0.01921405509774847
Epoch #217: loss=0.0151270049954939
Epoch #218: loss=0.01769324850763385
Epoch #219: loss=0.030816899083812403
Epoch #220: loss=0.02196131880151548
Epoch #221: loss=0.020826240467553103
Epoch #222: loss=0.016087336422438044
Epoch #223: loss=0.020246194806070702
Epoch #224: loss=0.016435843458438095
Epoch #225: loss=0.015158553932265376
Epoch #226: loss=0.021277627761083887
Epoch #227: loss=0.012992147630451634
Epoch #228: loss=0.017718935715637145
Epoch #229: loss=0.020122799255850962
Epoch #230: loss=0.017293414031809614
Epoch #231: loss=0.017904642619201324
Epoch #232: loss=0.014135660988618204
Epoch #233: loss=0.01959076048876763
Epoch #234: loss=0.016174118968548108
Epoch #235: loss=0.012763630822388138
Epoch #236: loss=0.01821411481878307
Epoch #237: loss=0.011430623697641008
Epoch #238: loss=0.00975590291005621
Epoch #239: loss=0.010935404116518645
Epoch #240: loss=0.018488161663238967
Epoch #241: loss=0.021956294659935798
Epoch #242: loss=0.019993197419465942
Epoch #243: loss=0.017317719662948497
Epoch #244: loss=0.012925911490115677
Epoch #245: loss=0.030532792725389613
Epoch #246: loss=0.016994512640275277
Epoch #247: loss=0.02387375342146351
Epoch #248: loss=0.017599087610930708
Epoch #249: loss=0.01376670598405043

Training time: 1:36:04.546030

Finished.
n2one setting etth1_ettm2_electricity_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm2_electricity_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_ettm2_electricity_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.73202e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.34777e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.73202e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.7006708895468954, 'MAE': 0.6370612266983796}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm2_traffic_weather', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm2_traffic_weather_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.0493611927261415
Epoch #1: loss=0.40254383213472683
Epoch #2: loss=0.300109089300793
Epoch #3: loss=0.22632485554938023
Epoch #4: loss=0.18500668764788716
Epoch #5: loss=0.15353258413614224
Epoch #6: loss=0.130680257567589
Epoch #7: loss=0.11985727481720825
Epoch #8: loss=0.09945000985546848
Epoch #9: loss=0.09996043463498683
Epoch #10: loss=0.08322346624435145
Epoch #11: loss=0.07176959305841303
Epoch #12: loss=0.07066811647273345
Epoch #13: loss=0.06536699603178084
Epoch #14: loss=0.05308281794544022
Epoch #15: loss=0.057140259561745683
Epoch #16: loss=0.056687864525064774
Epoch #17: loss=0.044957411836546994
Epoch #18: loss=0.047724816848207306
Epoch #19: loss=0.05124962553906174
Epoch #20: loss=0.0489022086060166
Epoch #21: loss=0.04160901116902136
Epoch #22: loss=0.040737161266609256
Epoch #23: loss=0.03359460373353583
Epoch #24: loss=0.040513952211816084
Epoch #25: loss=0.04157707495089347
Epoch #26: loss=0.03631994955996709
Epoch #27: loss=0.035553396846952585
Epoch #28: loss=0.0275819703615214
Epoch #29: loss=0.04058338471624854
Epoch #30: loss=0.035394505267807595
Epoch #31: loss=0.033282399052398375
Epoch #32: loss=0.037364553019356095
Epoch #33: loss=0.03633246117294098
Epoch #34: loss=0.029918874906970674
Epoch #35: loss=0.030296018692471033
Epoch #36: loss=0.027563740928229725
Epoch #37: loss=0.025607998242503326
Epoch #38: loss=0.029824712964275413
Epoch #39: loss=0.018897487407511154
Epoch #40: loss=0.026105310043312863
Epoch #41: loss=0.027626209338331827
Epoch #42: loss=0.02424757337902064
Epoch #43: loss=0.02893335837093449
Epoch #44: loss=0.022727473599247216
Epoch #45: loss=0.02483949968969104
Epoch #46: loss=0.024515271793447525
Epoch #47: loss=0.03523800990140275
Epoch #48: loss=0.0240470060743813
Epoch #49: loss=0.030603428036685074
Epoch #50: loss=0.02082345345401653
Epoch #51: loss=0.024688408284619753
Epoch #52: loss=0.027843446211946437
Epoch #53: loss=0.02775211136600015
Epoch #54: loss=0.022751418482307932
Epoch #55: loss=0.022228298228840287
Epoch #56: loss=0.02191333882366749
Epoch #57: loss=0.022130749410914696
Epoch #58: loss=0.018379590736485443
Epoch #59: loss=0.019197341004629654
Epoch #60: loss=0.029944059723167358
Epoch #61: loss=0.023299222262938575
Epoch #62: loss=0.016768209509773563
Epoch #63: loss=0.01779998583783638
Epoch #64: loss=0.02003737506338459
Epoch #65: loss=0.02206778974241729
Epoch #66: loss=0.014993072637269698
Epoch #67: loss=0.018546422200939706
Epoch #68: loss=0.018978527903252163
Epoch #69: loss=0.019593952810103957
Epoch #70: loss=0.031444086666693336
Epoch #71: loss=0.01523156720316387
Epoch #72: loss=0.014131063721466514
Epoch #73: loss=0.023567999819322914
Epoch #74: loss=0.021317912282073453
Epoch #75: loss=0.01917893383938513
Epoch #76: loss=0.023867501712936928
Epoch #77: loss=0.016786976012752843
Epoch #78: loss=0.017135873247752897
Epoch #79: loss=0.016597892690468456
Epoch #80: loss=0.01932280373490502
Epoch #81: loss=0.015565830036383852
Epoch #82: loss=0.02229343941944053
Epoch #83: loss=0.019869122165345195
Epoch #84: loss=0.018535943928461987
Epoch #85: loss=0.023566996748449958
Epoch #86: loss=0.021016815181749113
Epoch #87: loss=0.0176413389836144
Epoch #88: loss=0.017032415334734846
Epoch #89: loss=0.021131304777287734
Epoch #90: loss=0.012974542262109468
Epoch #91: loss=0.018615205090015737
Epoch #92: loss=0.01348299064136251
Epoch #93: loss=0.014374459124962793
Epoch #94: loss=0.0152586899810506
Epoch #95: loss=0.01583760580253298
Epoch #96: loss=0.02779683338027323
Epoch #97: loss=0.027910792056284023
Epoch #98: loss=0.017606084409378525
Epoch #99: loss=0.016811042357148514
Epoch #100: loss=0.011814886402801577
Epoch #101: loss=0.013151590693512034
Epoch #102: loss=0.01686310063355379
Epoch #103: loss=0.018097097692352248
Epoch #104: loss=0.014487858398207905
Epoch #105: loss=0.016845615395422148
Epoch #106: loss=0.02994684248845423
Epoch #107: loss=0.017094305634636597
Epoch #108: loss=0.013854924110949109
Epoch #109: loss=0.010207397883249628
Epoch #110: loss=0.013895633689577719
Epoch #111: loss=0.01654307942578048
Epoch #112: loss=0.01888319619703975
Epoch #113: loss=0.020193157443604802
Epoch #114: loss=0.01540216823610198
Epoch #115: loss=0.016351823266911054
Epoch #116: loss=0.017635075151509298
Epoch #117: loss=0.01332655134380828
Epoch #118: loss=0.01885518742195923
Epoch #119: loss=0.010615321640473267
Epoch #120: loss=0.013545750023337917
Epoch #121: loss=0.01658167031516332
Epoch #122: loss=0.014179176661574228
Epoch #123: loss=0.013318844251943728
Epoch #124: loss=0.014361228676078914
Epoch #125: loss=0.01586282572472724
Epoch #126: loss=0.011460909616939926
Epoch #127: loss=0.015469205845931183
Epoch #128: loss=0.013609594892355548
Epoch #129: loss=0.012053924199537373
Epoch #130: loss=0.016652832296458496
Epoch #131: loss=0.012610398763780608
Epoch #132: loss=0.017717628355842986
Epoch #133: loss=0.01976295470283341
Epoch #134: loss=0.012098343506427859
Epoch #135: loss=0.010458685623447305
Epoch #136: loss=0.01880053982000053
Epoch #137: loss=0.014788223260998979
Epoch #138: loss=0.012458739142136898
Epoch #139: loss=0.021177349383068703
Epoch #140: loss=0.011201697333568602
Epoch #141: loss=0.013982353880721356
Epoch #142: loss=0.018984282748276977
Epoch #143: loss=0.013953068040498423
Epoch #144: loss=0.010069983733114947
Epoch #145: loss=0.010914201953573765
Epoch #146: loss=0.01686131758288358
Epoch #147: loss=0.011272614894406669
Epoch #148: loss=0.014101273222429633
Epoch #149: loss=0.016788152714669047
Epoch #150: loss=0.010454044667808606
Epoch #151: loss=0.013291990542860144
Epoch #152: loss=0.01732692397523285
Epoch #153: loss=0.012325478545671792
Epoch #154: loss=0.01445581645411567
Epoch #155: loss=0.012134371509312429
Epoch #156: loss=0.011108751612241667
Epoch #157: loss=0.015276935781757877
Epoch #158: loss=0.01585502730594217
Epoch #159: loss=0.009918856434640506
Epoch #160: loss=0.01282811425890975
Epoch #161: loss=0.012474235002345032
Epoch #162: loss=0.014711106737903946
Epoch #163: loss=0.013167439565467535
Epoch #164: loss=0.0182378584188864
Epoch #165: loss=0.013413666102086413
Epoch #166: loss=0.009337642358796014
Epoch #167: loss=0.013573457336927138
Epoch #168: loss=0.011816550784723249
Epoch #169: loss=0.012537835425383486
Epoch #170: loss=0.01617603175506619
Epoch #171: loss=0.010218896016185702
Epoch #172: loss=0.009853084870214752
Epoch #173: loss=0.009767139893839915
Epoch #174: loss=0.012437871926217176
Epoch #175: loss=0.011637276050083894
Epoch #176: loss=0.015327573323696358
Epoch #177: loss=0.015329365038891707
Epoch #178: loss=0.014467905862129676
Epoch #179: loss=0.013870299952341117
Epoch #180: loss=0.01224738826990196
Epoch #181: loss=0.014331000580183316
Epoch #182: loss=0.011663141828189038
Epoch #183: loss=0.011810954416183694
Epoch #184: loss=0.011419869418636711
Epoch #185: loss=0.011172175307891273
Epoch #186: loss=0.011434026983236497
Epoch #187: loss=0.013322058638536461
Epoch #188: loss=0.012028289096962935
Epoch #189: loss=0.013153774260833554
Epoch #190: loss=0.013719365638840731
Epoch #191: loss=0.011952232719617088
Epoch #192: loss=0.010344285077952382
Epoch #193: loss=0.011009769202300597
Epoch #194: loss=0.009969674328233953
Epoch #195: loss=0.012568935627100885
Epoch #196: loss=0.00831661640642204
Epoch #197: loss=0.012430633326388985
Epoch #198: loss=0.012165140632743522
Epoch #199: loss=0.011743634218793613
Epoch #200: loss=0.008747390503915776
Epoch #201: loss=0.013077615847963754
Epoch #202: loss=0.009313690880425048
Epoch #203: loss=0.011219885534233342
Epoch #204: loss=0.010383326773526338
Epoch #205: loss=0.013627539330692016
Epoch #206: loss=0.015923946764678374
Epoch #207: loss=0.010645583533432909
Epoch #208: loss=0.010095369284646175
Epoch #209: loss=0.010773163756886193
Epoch #210: loss=0.011575649228717252
Epoch #211: loss=0.012729727171964597
Epoch #212: loss=0.01672375790577456
Epoch #213: loss=0.012713007230811986
Epoch #214: loss=0.014239090107788411
Epoch #215: loss=0.00828586885205332
Epoch #216: loss=0.017269192900796853
Epoch #217: loss=0.014244399982910973
Epoch #218: loss=0.014316702706781839
Epoch #219: loss=0.012162568301385707
Epoch #220: loss=0.007621936568639948
Epoch #221: loss=0.00919797803178692
Epoch #222: loss=0.012254766176543736
Epoch #223: loss=0.01096053471415554
Epoch #224: loss=0.011969718325537951
Epoch #225: loss=0.014360945158528583
Epoch #226: loss=0.007578136484346763
Epoch #227: loss=0.01312902158822099
Epoch #228: loss=0.01090510590147781
Epoch #229: loss=0.009732607027074907
Epoch #230: loss=0.012175938391451974
Epoch #231: loss=0.008003836798548589
Epoch #232: loss=0.01220334244448505
Epoch #233: loss=0.010759505015832543
Epoch #234: loss=0.013136254956266816
Epoch #235: loss=0.01021411661895801
Epoch #236: loss=0.014704068900522478
Epoch #237: loss=0.0082610485995359
Epoch #238: loss=0.01045261762136024
Epoch #239: loss=0.012496772659292329
Epoch #240: loss=0.00895248546298988
Epoch #241: loss=0.008074616188903377
Epoch #242: loss=0.017299525967085536
Epoch #243: loss=0.00996793856667049
Epoch #244: loss=0.0115572279237413
Epoch #245: loss=0.00906207351530306
Epoch #246: loss=0.01714213935367406
Epoch #247: loss=0.009127711222611494
Epoch #248: loss=0.01783620116786298
Epoch #249: loss=0.012949798527842765

Training time: 3:40:40.565171

Finished.
n2one setting etth1_ettm2_traffic_weather -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm2_traffic_weather_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_ettm2_traffic_weather', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.90752e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.02694e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.00505e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.90752e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.423517214911132, 'MAE': 0.46218968000459265}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm2_traffic_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm2_traffic_weather_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_ettm2_traffic_weather', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.29432e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.387082541648448, 'MAE': 0.40929267599574604}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm2_traffic_exchange', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm2_traffic_exchange_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.0163121965990678
Epoch #1: loss=0.39450580072966784
Epoch #2: loss=0.27286827714425754
Epoch #3: loss=0.20468603962663193
Epoch #4: loss=0.178533237511376
Epoch #5: loss=0.1413058456796985
Epoch #6: loss=0.11323248667155837
Epoch #7: loss=0.0984748935532496
Epoch #8: loss=0.09476424319573117
Epoch #9: loss=0.08107346033379603
Epoch #10: loss=0.07370129359837806
Epoch #11: loss=0.06479875996041842
Epoch #12: loss=0.06252956011270693
Epoch #13: loss=0.0611162286108624
Epoch #14: loss=0.06002795321343525
Epoch #15: loss=0.05620555742434016
Epoch #16: loss=0.04836303397839016
Epoch #17: loss=0.043913102142281016
Epoch #18: loss=0.047415998308638296
Epoch #19: loss=0.04017554607131175
Epoch #20: loss=0.046713718969578356
Epoch #21: loss=0.04436896396221421
Epoch #22: loss=0.034276923081608957
Epoch #23: loss=0.03887422641357491
Epoch #24: loss=0.034496405312811396
Epoch #25: loss=0.0408252651306595
Epoch #26: loss=0.03167004510917625
Epoch #27: loss=0.03333736634024037
Epoch #28: loss=0.034260810523158616
Epoch #29: loss=0.03436843383829697
Epoch #30: loss=0.030239974376682594
Epoch #31: loss=0.031941678659358014
Epoch #32: loss=0.03290644607208837
Epoch #33: loss=0.034841884231600735
Epoch #34: loss=0.027901019055452954
Epoch #35: loss=0.0305138899831847
Epoch #36: loss=0.031691696815090965
Epoch #37: loss=0.02939827024146415
Epoch #38: loss=0.026764275439082004
Epoch #39: loss=0.03148880569282122
Epoch #40: loss=0.022902869377880428
Epoch #41: loss=0.03133367297289681
Epoch #42: loss=0.026139540042922734
Epoch #43: loss=0.03224152560541951
Epoch #44: loss=0.02759390192731443
Epoch #45: loss=0.026750108574347693
Epoch #46: loss=0.022579465492674138
Epoch #47: loss=0.022194973195534356
Epoch #48: loss=0.021516331079780956
Epoch #49: loss=0.02701000960839772
Epoch #50: loss=0.027702558745691965
Epoch #51: loss=0.03146737366320874
Epoch #52: loss=0.024186558383024036
Epoch #53: loss=0.022939828980786447
Epoch #54: loss=0.019272972281911067
Epoch #55: loss=0.02182746428913995
Epoch #56: loss=0.03506888108847658
Epoch #57: loss=0.020858800812568808
Epoch #58: loss=0.020229811030468874
Epoch #59: loss=0.018431919941724266
Epoch #60: loss=0.02439527955747352
Epoch #61: loss=0.020711383247642615
Epoch #62: loss=0.022443352173279703
Epoch #63: loss=0.022214645020597404
Epoch #64: loss=0.025103538462628406
Epoch #65: loss=0.02870345081812031
Epoch #66: loss=0.030237131731720747
Epoch #67: loss=0.017416714699278156
Epoch #68: loss=0.018175077038806095
Epoch #69: loss=0.026143303931127553
Epoch #70: loss=0.0218287086175117
Epoch #71: loss=0.020572887435526616
Epoch #72: loss=0.018471085654373956
Epoch #73: loss=0.03244878449658171
Epoch #74: loss=0.02683039976322975
Epoch #75: loss=0.02645601445246857
Epoch #76: loss=0.01857365034516693
Epoch #77: loss=0.01895452152150012
Epoch #78: loss=0.0157630326604769
Epoch #79: loss=0.01991171639049237
Epoch #80: loss=0.02240794226780234
Epoch #81: loss=0.025245706114580022
Epoch #82: loss=0.023623103966127854
Epoch #83: loss=0.0262218908954654
Epoch #84: loss=0.017707823602200027
Epoch #85: loss=0.017720797541597177
Epoch #86: loss=0.02198717818087594
Epoch #87: loss=0.016329849879659852
Epoch #88: loss=0.017756333817028912
Epoch #89: loss=0.02712689313383643
Epoch #90: loss=0.020365452524627244
Epoch #91: loss=0.013886818988879411
Epoch #92: loss=0.018166566527643143
Epoch #93: loss=0.016556452242012538
Epoch #94: loss=0.01599226711803092
Epoch #95: loss=0.01785234436790012
Epoch #96: loss=0.0213084456521723
Epoch #97: loss=0.02120032783732477
Epoch #98: loss=0.01872921058719356
Epoch #99: loss=0.018507342569022398
Epoch #100: loss=0.015399380086540708
Epoch #101: loss=0.019685086258988606
Epoch #102: loss=0.01994797703944412
Epoch #103: loss=0.023637117587985902
Epoch #104: loss=0.017182373763864382
Epoch #105: loss=0.01551573254933779
Epoch #106: loss=0.022593892661281464
Epoch #107: loss=0.01804627026734755
Epoch #108: loss=0.01643875933668086
Epoch #109: loss=0.014893997536247454
Epoch #110: loss=0.018183657813203462
Epoch #111: loss=0.014150749130151182
Epoch #112: loss=0.018175300092807774
Epoch #113: loss=0.017145670881455025
Epoch #114: loss=0.014347094405689728
Epoch #115: loss=0.01623359455163711
Epoch #116: loss=0.021234554275095532
Epoch #117: loss=0.014967648846970143
Epoch #118: loss=0.01998150105783999
Epoch #119: loss=0.013409305383984329
Epoch #120: loss=0.01814513778001194
Epoch #121: loss=0.019495610029922762
Epoch #122: loss=0.01482177584644838
Epoch #123: loss=0.019399544772461814
Epoch #124: loss=0.01455601281599524
Epoch #125: loss=0.01611778791053226
Epoch #126: loss=0.016162592192117003
Epoch #127: loss=0.015549056903199033
Epoch #128: loss=0.014197653133672796
Epoch #129: loss=0.014403247850373396
Epoch #130: loss=0.016622719965419714
Epoch #131: loss=0.013865911151770962
Epoch #132: loss=0.02573922405373106
Epoch #133: loss=0.01399414933762232
Epoch #134: loss=0.0145530717951211
Epoch #135: loss=0.015227255578924218
Epoch #136: loss=0.02191769663909941
Epoch #137: loss=0.01912924494801602
Epoch #138: loss=0.015485478791602005
Epoch #139: loss=0.015771873029636382
Epoch #140: loss=0.012821974491810391
Epoch #141: loss=0.016111347490788158
Epoch #142: loss=0.014303905221839176
Epoch #143: loss=0.016175994518463896
Epoch #144: loss=0.012821403324680333
Epoch #145: loss=0.015652701978749746
Epoch #146: loss=0.01886810545394903
Epoch #147: loss=0.014938659340751238
Epoch #148: loss=0.015402743780197835
Epoch #149: loss=0.016848383856110583
Epoch #150: loss=0.012757937184564857
Epoch #151: loss=0.014253795025413981
Epoch #152: loss=0.014637771624637043
Epoch #153: loss=0.024535876914383192
Epoch #154: loss=0.010210838316935051
Epoch #155: loss=0.012687439447921582
Epoch #156: loss=0.012214979239525657
Epoch #157: loss=0.011146756288908035
Epoch #158: loss=0.01708626353439769
Epoch #159: loss=0.013160523181549916
Epoch #160: loss=0.013022230632683401
Epoch #161: loss=0.016151811533409846
Epoch #162: loss=0.0151527765130169
Epoch #163: loss=0.014780095888954337
Epoch #164: loss=0.014058785739040547
Epoch #165: loss=0.018100522415520286
Epoch #166: loss=0.016983242669674516
Epoch #167: loss=0.016738902349741465
Epoch #168: loss=0.01345904308094235
Epoch #169: loss=0.017091206919930473
Epoch #170: loss=0.013439770296270024
Epoch #171: loss=0.014732351628055342
Epoch #172: loss=0.012145994511229219
Epoch #173: loss=0.01565500546666544
Epoch #174: loss=0.013361036127002785
Epoch #175: loss=0.015884737794843753
Epoch #176: loss=0.015245431455581524
Epoch #177: loss=0.012508060006603209
Epoch #178: loss=0.012775938113754656
Epoch #179: loss=0.014280372477121607
Epoch #180: loss=0.014581038025016414
Epoch #181: loss=0.01042060423043933
Epoch #182: loss=0.01876649144377642
Epoch #183: loss=0.025125801254624682
Epoch #184: loss=0.01754098111465479
Epoch #185: loss=0.012232042306742835
Epoch #186: loss=0.01235728778684043
Epoch #187: loss=0.010801978980289114
Epoch #188: loss=0.013955019970314612
Epoch #189: loss=0.015511551581732157
Epoch #190: loss=0.015568394051615132
Epoch #191: loss=0.010160397158812827
Epoch #192: loss=0.010235677652515832
Epoch #193: loss=0.01615467179199022
Epoch #194: loss=0.013331291860251096
Epoch #195: loss=0.012109921052698966
Epoch #196: loss=0.011457786549775896
Epoch #197: loss=0.01645307658791271
Epoch #198: loss=0.023582222471157217
Epoch #199: loss=0.014970676591081035
Epoch #200: loss=0.010383169160860718
Epoch #201: loss=0.012665369993850912
Epoch #202: loss=0.014688790276416406
Epoch #203: loss=0.012765099138247221
Epoch #204: loss=0.0123339758143744
Epoch #205: loss=0.010084410782551172
Epoch #206: loss=0.01299885423348085
Epoch #207: loss=0.01216666540879872
Epoch #208: loss=0.01166771646111974
Epoch #209: loss=0.01242386082689795
Epoch #210: loss=0.015357429475394334
Epoch #211: loss=0.014794433644645914
Epoch #212: loss=0.018760723892367562
Epoch #213: loss=0.015330056813590098
Epoch #214: loss=0.012787424170685856
Epoch #215: loss=0.013015326110738946
Epoch #216: loss=0.014157372561516371
Epoch #217: loss=0.020016253206523362
Epoch #218: loss=0.012013078100255927
Epoch #219: loss=0.011687571443536063
Epoch #220: loss=0.009851661682504372
Epoch #221: loss=0.012966852981670862
Epoch #222: loss=0.011041907606897996
Epoch #223: loss=0.011378524206438588
Epoch #224: loss=0.01611443264315509
Epoch #225: loss=0.014009163276650806
Epoch #226: loss=0.007150161434273704
Epoch #227: loss=0.010717300449930524
Epoch #228: loss=0.013922998578850597
Epoch #229: loss=0.01502155907373972
Epoch #230: loss=0.009163450762407429
Epoch #231: loss=0.010349470173743021
Epoch #232: loss=0.019775264913462435
Epoch #233: loss=0.017190181262301374
Epoch #234: loss=0.014958711483084879
Epoch #235: loss=0.013365573658554675
Epoch #236: loss=0.012939896604760318
Epoch #237: loss=0.011589640816748568
Epoch #238: loss=0.012370152966566919
Epoch #239: loss=0.016106427674294373
Epoch #240: loss=0.012724445771701532
Epoch #241: loss=0.01230908293498057
Epoch #242: loss=0.015027122639186747
Epoch #243: loss=0.019158806097940205
Epoch #244: loss=0.010522998299469085
Epoch #245: loss=0.011212071821097885
Epoch #246: loss=0.0102364683187933
Epoch #247: loss=0.011872605395625657
Epoch #248: loss=0.011705844755638978
Epoch #249: loss=0.010834575214126695

Training time: 3:29:22.225718

Finished.
n2one setting etth1_ettm2_traffic_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm2_traffic_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_ettm2_traffic_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.41026e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.83783e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.94886e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.41026e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.41846099834968986, 'MAE': 0.4602693378325621}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm2_traffic_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm2_traffic_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_ettm2_traffic_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.25762e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.69202e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.25762e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.6089804287716422, 'MAE': 0.6196919314924829}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm2_weather_exchange', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm2_weather_exchange_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=4.20965241927367
Epoch #1: loss=2.3507059858395505
Epoch #2: loss=2.284033248057732
Epoch #3: loss=1.9688319563865662
Epoch #4: loss=1.8924864713962262
Epoch #5: loss=1.7567805418601403
Epoch #6: loss=1.5102808681818156
Epoch #7: loss=1.4220591256251702
Epoch #8: loss=1.3161867960141256
Epoch #9: loss=1.28247581078456
Epoch #10: loss=1.2161610367206426
Epoch #11: loss=1.116481445156611
Epoch #12: loss=1.106219049829703
Epoch #13: loss=1.061553146976691
Epoch #14: loss=1.016199698814979
Epoch #15: loss=0.975467270383468
Epoch #16: loss=1.0332565078368554
Epoch #17: loss=0.9963082269980357
Epoch #18: loss=0.9189866437361791
Epoch #19: loss=0.9022816018416331
Epoch #20: loss=0.857987853196951
Epoch #21: loss=0.8234528990892264
Epoch #22: loss=0.8153371031467731
Epoch #23: loss=0.7799549991121659
Epoch #24: loss=0.7502095189232093
Epoch #25: loss=0.7969036755653528
Epoch #26: loss=0.7690726862503932
Epoch #27: loss=0.6717957584903791
Epoch #28: loss=0.7156233902160938
Epoch #29: loss=0.6568087368057325
Epoch #30: loss=0.7054588657159072
Epoch #31: loss=0.6869969516992569
Epoch #32: loss=0.6507146026079471
Epoch #33: loss=0.5825219612855178
Epoch #34: loss=0.5590583756566048
Epoch #35: loss=0.63730083577908
Epoch #36: loss=0.5905126396280068
Epoch #37: loss=0.6512185140297964
Epoch #38: loss=0.5640773515288646
Epoch #39: loss=0.523354648397519
Epoch #40: loss=0.5625368671921583
Epoch #41: loss=0.5194728729816583
Epoch #42: loss=0.5522589391240706
Epoch #43: loss=0.5155008716078905
Epoch #44: loss=0.49421035613004977
Epoch #45: loss=0.505068522806351
Epoch #46: loss=0.47280854330613065
Epoch #47: loss=0.47809147318968404
Epoch #48: loss=0.528439019448482
Epoch #49: loss=0.4809083812511884
Epoch #50: loss=0.44471528925574744
Epoch #51: loss=0.45551886266240704
Epoch #52: loss=0.38377675184836757
Epoch #53: loss=0.3726829353433389
Epoch #54: loss=0.43310530254474056
Epoch #55: loss=0.4845456268924933
Epoch #56: loss=0.4136466627510694
Epoch #57: loss=0.44100808524168456
Epoch #58: loss=0.4190689167724206
Epoch #59: loss=0.4288090759745011
Epoch #60: loss=0.37226505319659525
Epoch #61: loss=0.35154216765211177
Epoch #62: loss=0.4047395119873377
Epoch #63: loss=0.4545946533863361
Epoch #64: loss=0.41547001898288727
Epoch #65: loss=0.333950481735743
Epoch #66: loss=0.3374990183286942
Epoch #67: loss=0.32672155734438163
Epoch #68: loss=0.3506214724710354
Epoch #69: loss=0.29919348958020026
Epoch #70: loss=0.29359026869329125
Epoch #71: loss=0.28355725238529533
Epoch #72: loss=0.33715807359952193
Epoch #73: loss=0.2799502161259835
Epoch #74: loss=0.23629261954472616
Epoch #75: loss=0.2856772398719421
Epoch #76: loss=0.34223573611905944
Epoch #77: loss=0.2693578449006264
Epoch #78: loss=0.32362172652322513
Epoch #79: loss=0.2672883997169825
Epoch #80: loss=0.3211754927268395
Epoch #81: loss=0.30735816419697726
Epoch #82: loss=0.2768312095879362
Epoch #83: loss=0.22955928886165985
Epoch #84: loss=0.32616987036397826
Epoch #85: loss=0.27721659939449567
Epoch #86: loss=0.24479064789529031
Epoch #87: loss=0.33352698528995883
Epoch #88: loss=0.2603839198127389
Epoch #89: loss=0.2451817195575971
Epoch #90: loss=0.270815929541221
Epoch #91: loss=0.2462375841748256
Epoch #92: loss=0.1908333027162231
Epoch #93: loss=0.24631042706851775
Epoch #94: loss=0.21999292519803232
Epoch #95: loss=0.1803073175251484
Epoch #96: loss=0.19360818455998713
Epoch #97: loss=0.20945100694035107
Epoch #98: loss=0.19728476819224083
Epoch #99: loss=0.22004003672359082
Epoch #100: loss=0.24751808315228957
Epoch #101: loss=0.1895679123699665
Epoch #102: loss=0.17716265433969405
Epoch #103: loss=0.17828777203193077
Epoch #104: loss=0.20036500040441751
Epoch #105: loss=0.1537334555043624
Epoch #106: loss=0.2029569921298669
Epoch #107: loss=0.19565452907520992
Epoch #108: loss=0.18835733651828307
Epoch #109: loss=0.2344848129611749
Epoch #110: loss=0.1676639150828123
Epoch #111: loss=0.17872675848551667
Epoch #112: loss=0.18499157319848353
Epoch #113: loss=0.17178055092405814
Epoch #114: loss=0.14712411989099705
Epoch #115: loss=0.2591937893571762
Epoch #116: loss=0.21968604982472384
Epoch #117: loss=0.31139746422951037
Epoch #118: loss=0.23724125920293423
Epoch #119: loss=0.3252855473412917
Epoch #120: loss=0.24061016373049754
Epoch #121: loss=0.2472551162712849
Epoch #122: loss=0.1916407343143454
Epoch #123: loss=0.1854089731350541
Epoch #124: loss=0.2014258407916014
Epoch #125: loss=0.2613014016801921
Epoch #126: loss=0.15682927841463914
Epoch #127: loss=0.16168131944365227
Epoch #128: loss=0.14689250716653007
Epoch #129: loss=0.23834219503288084
Epoch #130: loss=0.17288575586504662
Epoch #131: loss=0.17829189349252444
Epoch #132: loss=0.15456768057237452
Epoch #133: loss=0.1484257560581542
Epoch #134: loss=0.14850344630674675
Epoch #135: loss=0.21593540666911465
Epoch #136: loss=0.2277747251523229
Epoch #137: loss=0.1996945690077085
Epoch #138: loss=0.16685371398209378
Epoch #139: loss=0.16543651798453468
Epoch #140: loss=0.15293588313775566
Epoch #141: loss=0.2521148989550196
Epoch #142: loss=0.1821319582298971
Epoch #143: loss=0.1422592640782778
Epoch #144: loss=0.15251864349612823
Epoch #145: loss=0.18125391593919352
Epoch #146: loss=0.1336525001992973
Epoch #147: loss=0.15924123144493654
Epoch #148: loss=0.15048223959568602
Epoch #149: loss=0.13507280584711295
Epoch #150: loss=0.11089544524796881
Epoch #151: loss=0.1385764261850944
Epoch #152: loss=0.14519709936128214
Epoch #153: loss=0.1256317337258504
Epoch #154: loss=0.1284090500110044
Epoch #155: loss=0.11744766574926101
Epoch #156: loss=0.14719134504691914
Epoch #157: loss=0.1260163659014954
Epoch #158: loss=0.13094097196769255
Epoch #159: loss=0.12101378875712936
Epoch #160: loss=0.12263028925428024
Epoch #161: loss=0.1373044761757438
Epoch #162: loss=0.16982770904612082
Epoch #163: loss=0.16139961109281734
Epoch #164: loss=0.18314204450983268
Epoch #165: loss=0.14838792562771302
Epoch #166: loss=0.13520554560594833
Epoch #167: loss=0.13209827050853234
Epoch #168: loss=0.11798753782820243
Epoch #169: loss=0.10260889815309873
Epoch #170: loss=0.12520075385243848
Epoch #171: loss=0.18939272063569382
Epoch #172: loss=0.14564571740965432
Epoch #173: loss=0.12579541040871006
Epoch #174: loss=0.1459837662987411
Epoch #175: loss=0.13299430197534653
Epoch #176: loss=0.11096533667296171
Epoch #177: loss=0.1609370353846596
Epoch #178: loss=0.13349569832476285
Epoch #179: loss=0.12674955558031797
Epoch #180: loss=0.10507754275861841
Epoch #181: loss=0.08963270510475223
Epoch #182: loss=0.11773370929922049
Epoch #183: loss=0.09526906454434189
Epoch #184: loss=0.10744005910908946
Epoch #185: loss=0.08631740259723021
Epoch #186: loss=0.10709821339696646
Epoch #187: loss=0.1087239825238402
Epoch #188: loss=0.09341632026749161
Epoch #189: loss=0.13981116108166483
Epoch #190: loss=0.14068561559543014
Epoch #191: loss=0.1629712415429262
Epoch #192: loss=0.1282201620320288
Epoch #193: loss=0.09944607150884202
Epoch #194: loss=0.10975078711859308
Epoch #195: loss=0.1310107571681818
Epoch #196: loss=0.18980899814946148
Epoch #197: loss=0.14600617828993842
Epoch #198: loss=0.12783113512425467
Epoch #199: loss=0.0943397876734917
Epoch #200: loss=0.10738886505938493
Epoch #201: loss=0.1020881486340211
Epoch #202: loss=0.09629784472501622
Epoch #203: loss=0.1283196392827309
Epoch #204: loss=0.10188060321916755
Epoch #205: loss=0.09333835884283942
Epoch #206: loss=0.08879791606719104
Epoch #207: loss=0.193160922660564
Epoch #208: loss=0.16208236331406695
Epoch #209: loss=0.11303449244811557
Epoch #210: loss=0.08896557512119986
Epoch #211: loss=0.09354592390501729
Epoch #212: loss=0.1350038454402238
Epoch #213: loss=0.1034653763859891
Epoch #214: loss=0.0843067521121926
Epoch #215: loss=0.09029156845421173
Epoch #216: loss=0.08084628920858869
Epoch #217: loss=0.1215729053454617
Epoch #218: loss=0.07369573063288744
Epoch #219: loss=0.08062455348240641
Epoch #220: loss=0.09520646523182782
Epoch #221: loss=0.11671625491446601
Epoch #222: loss=0.09721971700827663
Epoch #223: loss=0.08674530351821047
Epoch #224: loss=0.06646164644581194
Epoch #225: loss=0.06473869054864806
Epoch #226: loss=0.10944484279920849
Epoch #227: loss=0.06130279892554077
Epoch #228: loss=0.09104554013062555
Epoch #229: loss=0.08539777148801547
Epoch #230: loss=0.08631651608559948
Epoch #231: loss=0.1052071111312566
Epoch #232: loss=0.09223926683457997
Epoch #233: loss=0.08351635042792903
Epoch #234: loss=0.09092925868641871
Epoch #235: loss=0.12398308280927058
Epoch #236: loss=0.11957985850480887
Epoch #237: loss=0.13369602251511353
Epoch #238: loss=0.11235215830115172
Epoch #239: loss=0.1255089809688238
Epoch #240: loss=0.09784110821783543
Epoch #241: loss=0.10373855455635259
Epoch #242: loss=0.129882611746255
Epoch #243: loss=0.09649584309842724
Epoch #244: loss=0.08088052793979071
Epoch #245: loss=0.06382768993409207
Epoch #246: loss=0.05864636288382686
Epoch #247: loss=0.06175433516574021
Epoch #248: loss=0.06235416799497146
Epoch #249: loss=0.16904126070081615

Training time: 0:16:21.217263

Finished.
n2one setting etth1_ettm2_weather_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm2_weather_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_ettm2_weather_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.37138e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.717e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.37138e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3878790653752843, 'MAE': 0.4415823333155816}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_electricity_traffic_weather', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_electricity_traffic_weather_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.83896942251656
Epoch #1: loss=0.308544888773835
Epoch #2: loss=0.21330222478258962
Epoch #3: loss=0.16264008915382683
Epoch #4: loss=0.1377629363697978
Epoch #5: loss=0.11216585627469038
Epoch #6: loss=0.0941144822856203
Epoch #7: loss=0.07554279858059569
Epoch #8: loss=0.06554370054072933
Epoch #9: loss=0.05955941513514661
Epoch #10: loss=0.054004506079333
Epoch #11: loss=0.051575922753392275
Epoch #12: loss=0.05166946047469728
Epoch #13: loss=0.04745947438315948
Epoch #14: loss=0.04344949001221578
Epoch #15: loss=0.04792661696525389
Epoch #16: loss=0.046528822982509155
Epoch #17: loss=0.03405759766715882
Epoch #18: loss=0.03081460138061007
Epoch #19: loss=0.03297020229432459
Epoch #20: loss=0.02673404294814406
Epoch #21: loss=0.03336701785740029
Epoch #22: loss=0.03627227247326166
Epoch #23: loss=0.025991072258444835
Epoch #24: loss=0.02518743605325749
Epoch #25: loss=0.02549728419798588
Epoch #26: loss=0.027725608745353576
Epoch #27: loss=0.026830253468018015
Epoch #28: loss=0.024888360905941608
Epoch #29: loss=0.0363799155003634
Epoch #30: loss=0.039914839905529666
Epoch #31: loss=0.02095081876144066
Epoch #32: loss=0.025155748733883036
Epoch #33: loss=0.022212586834221407
Epoch #34: loss=0.022210091656808418
Epoch #35: loss=0.03137690468735711
Epoch #36: loss=0.02312359691308972
Epoch #37: loss=0.022420407509679007
Epoch #38: loss=0.031811499153598946
Epoch #39: loss=0.017208688038121374
Epoch #40: loss=0.027013462502341816
Epoch #41: loss=0.021220480772459076
Epoch #42: loss=0.015894438853377466
Epoch #43: loss=0.017341466546991126
Epoch #44: loss=0.02856057163358185
Epoch #45: loss=0.021700373711921298
Epoch #46: loss=0.03672173485124643
Epoch #47: loss=0.018018710666231192
Epoch #48: loss=0.022477138982833964
Epoch #49: loss=0.01710376852509542
Epoch #50: loss=0.022405517838993354
Epoch #51: loss=0.017674141002987056
Epoch #52: loss=0.019059188891237443
Epoch #53: loss=0.017885981384001513
Epoch #54: loss=0.014622589614741867
Epoch #55: loss=0.01987544447506719
Epoch #56: loss=0.022075502509826612
Epoch #57: loss=0.016540580361786277
Epoch #58: loss=0.015022081245708824
Epoch #59: loss=0.02255131222758983
Epoch #60: loss=0.010758432396199313
Epoch #61: loss=0.017561437397058687
Epoch #62: loss=0.01655961197737174
Epoch #63: loss=0.018193795689081815
Epoch #64: loss=0.021545829416433997
Epoch #65: loss=0.024849648598295682
Epoch #66: loss=0.01848953346459319
Epoch #67: loss=0.02329137085496912
Epoch #68: loss=0.016743138469313346
Epoch #69: loss=0.01747269109251934
Epoch #70: loss=0.014449388830742368
Epoch #71: loss=0.021986310305405106
Epoch #72: loss=0.015171722162808453
Epoch #73: loss=0.022496708699260414
Epoch #74: loss=0.015465915981645881
Epoch #75: loss=0.01989765794738368
Epoch #76: loss=0.013437741278865264
Epoch #77: loss=0.0136919888903106
Epoch #78: loss=0.016499362119319766
Epoch #79: loss=0.014106138706402385
Epoch #80: loss=0.01919996221479443
Epoch #81: loss=0.015104997858495488
Epoch #82: loss=0.014154429882721257
Epoch #83: loss=0.01710992742525712
Epoch #84: loss=0.0113417279002964
Epoch #85: loss=0.01686214314237364
Epoch #86: loss=0.013805534353985805
Epoch #87: loss=0.015655806285418582
Epoch #88: loss=0.012720084792219592
Epoch #89: loss=0.0127947535757142
Epoch #90: loss=0.014306498844450144
Epoch #91: loss=0.013679766325798195
Epoch #92: loss=0.011206311765590726
Epoch #93: loss=0.012793764137457305
Epoch #94: loss=0.015198459149647342
Epoch #95: loss=0.013016770511620436
Epoch #96: loss=0.012696353302777578
Epoch #97: loss=0.017433776315077632
Epoch #98: loss=0.01311961478546963
Epoch #99: loss=0.013043642183255974
Epoch #100: loss=0.011359267380564569
Epoch #101: loss=0.014056639641316636
Epoch #102: loss=0.016107259669847974
Epoch #103: loss=0.012071514444414788
Epoch #104: loss=0.013501414730949603
Epoch #105: loss=0.014399714864686374
Epoch #106: loss=0.012772629086109526
Epoch #107: loss=0.02215292556294164
Epoch #108: loss=0.01322533207612172
Epoch #109: loss=0.01370561699296128
Epoch #110: loss=0.017434917836393844
Epoch #111: loss=0.016969647688854724
Epoch #112: loss=0.014344013176672601
Epoch #113: loss=0.010125936116262318
Epoch #114: loss=0.014131589120636005
Epoch #115: loss=0.017875095368732507
Epoch #116: loss=0.013490186874701306
Epoch #117: loss=0.011198513220901268
Epoch #118: loss=0.012270128994570865
Epoch #119: loss=0.016763469228192805
Epoch #120: loss=0.009292996514025282
Epoch #121: loss=0.011174593465762042
Epoch #122: loss=0.018640059530705338
Epoch #123: loss=0.01283355658343728
Epoch #124: loss=0.01254720714749917
Epoch #125: loss=0.009707177179555066
Epoch #126: loss=0.013861082137976299
Epoch #127: loss=0.015602783225260378
Epoch #128: loss=0.013262540154396686
Epoch #129: loss=0.009586717980757959
Epoch #130: loss=0.014800518770148062
Epoch #131: loss=0.015254620281379366
Epoch #132: loss=0.01200994347844866
Epoch #133: loss=0.014252343743943416
Epoch #134: loss=0.010301779270680288
Epoch #135: loss=0.01214018600321771
Epoch #136: loss=0.013715500395882804
Epoch #137: loss=0.011930278802370404
Epoch #138: loss=0.009308748531177451
Epoch #139: loss=0.01147878997440509
Epoch #140: loss=0.012980343907411464
Epoch #141: loss=0.01113254947887598
Epoch #142: loss=0.011099989529480138
Epoch #143: loss=0.015952099618217336
Epoch #144: loss=0.009513535256904728
Epoch #145: loss=0.012192388010730252
Epoch #146: loss=0.013415940228565217
Epoch #147: loss=0.007931563610961683
Epoch #148: loss=0.013516119259831708
Epoch #149: loss=0.011849711173023312
Epoch #150: loss=0.019502623934996383
Epoch #151: loss=0.01176799357332177
Epoch #152: loss=0.011585670448635267
Epoch #153: loss=0.015718060536983103
Epoch #154: loss=0.01031849466332795
Epoch #155: loss=0.020288759630714543
Epoch #156: loss=0.012904296542226228
Epoch #157: loss=0.009718470981756343
Epoch #158: loss=0.015123972767760938
Epoch #159: loss=0.01184740267763118
Epoch #160: loss=0.008668665680835673
Epoch #161: loss=0.01051367811468732
Epoch #162: loss=0.018249416773271247
Epoch #163: loss=0.007286991617356283
Epoch #164: loss=0.015107412880177818
Epoch #165: loss=0.00851373265231814
Epoch #166: loss=0.01349286124084421
Epoch #167: loss=0.01144113250864776
Epoch #168: loss=0.010720719318765316
Epoch #169: loss=0.011402772042354053
Epoch #170: loss=0.011654034059239692
Epoch #171: loss=0.012725321360831961
Epoch #172: loss=0.010714623982613901
Epoch #173: loss=0.011343553189362865
Epoch #174: loss=0.01834731449741268
Epoch #175: loss=0.009942021371841
Epoch #176: loss=0.011562989912123922
Epoch #177: loss=0.007440862181684301
Epoch #178: loss=0.007775129266483897
Epoch #179: loss=0.014599648748667517
Epoch #180: loss=0.008462555309321081
Epoch #181: loss=0.012993829980491443
Epoch #182: loss=0.00998924756986765
Epoch #183: loss=0.010602456109447638
Epoch #184: loss=0.008010472636157348
Epoch #185: loss=0.011329813541231871
Epoch #186: loss=0.007283018008257913
Epoch #187: loss=0.009328636647380432
Epoch #188: loss=0.010756332590475674
Epoch #189: loss=0.009337203410466014
Epoch #190: loss=0.010919908746461116
Epoch #191: loss=0.018319596307456346
Epoch #192: loss=0.012329340827818669
Epoch #193: loss=0.010274019578410412
Epoch #194: loss=0.010072491486485697
Epoch #195: loss=0.016823246717631503
Epoch #196: loss=0.009255017395186147
Epoch #197: loss=0.009671741308047307
Epoch #198: loss=0.009244527817348793
Epoch #199: loss=0.012589933443821696
Epoch #200: loss=0.014690625194661104
Epoch #201: loss=0.010305545294170914
Epoch #202: loss=0.011215698989357597
Epoch #203: loss=0.010400243387817011
Epoch #204: loss=0.009884899623796772
Epoch #205: loss=0.009078106492983065
Epoch #206: loss=0.010228807327122691
Epoch #207: loss=0.00962179029047667
Epoch #208: loss=0.011741205503579079
Epoch #209: loss=0.01019921327013818
Epoch #210: loss=0.009557048837139422
Epoch #211: loss=0.009199857030628329
Epoch #212: loss=0.01439633404965877
Epoch #213: loss=0.009833900432939021
Epoch #214: loss=0.008626114356241762
Epoch #215: loss=0.009504010929766254
Epoch #216: loss=0.014991256000652547
Epoch #217: loss=0.005426190971120018
Epoch #218: loss=0.01271798430846354
Epoch #219: loss=0.017432923883210317
Epoch #220: loss=0.008015556840393257
Epoch #221: loss=0.008607444824472048
Epoch #222: loss=0.009928975073241992
Epoch #223: loss=0.008371932234330129
Epoch #224: loss=0.011063281582341676
Epoch #225: loss=0.008361057403243123
Epoch #226: loss=0.009253236879909596
Epoch #227: loss=0.010088368524891752
Epoch #228: loss=0.012330272837169488
Epoch #229: loss=0.012469231777604646
Epoch #230: loss=0.008483054757131245
Epoch #231: loss=0.012697280216571016
Epoch #232: loss=0.007704828218005619
Epoch #233: loss=0.01106531005247665
Epoch #234: loss=0.009109875868472872
Epoch #235: loss=0.006969891066874149
Epoch #236: loss=0.01260966378079406
Epoch #237: loss=0.009034843524728475
Epoch #238: loss=0.013177015436380507
Epoch #239: loss=0.015329467854844313
Epoch #240: loss=0.009784149782083324
Epoch #241: loss=0.007177131754360744
Epoch #242: loss=0.010257406210808097
Epoch #243: loss=0.013829993351691508
Epoch #244: loss=0.01212460263052076
Epoch #245: loss=0.010142036828830513
Epoch #246: loss=0.010397336821334216
Epoch #247: loss=0.008266448707158097
Epoch #248: loss=0.010476212324015091
Epoch #249: loss=0.009201524744897046

Training time: 5:08:44.355198

Finished.
n2one setting etth1_electricity_traffic_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_electricity_traffic_weather_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_electricity_traffic_weather', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.67984e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.27281121213100545, 'MAE': 0.3469530350275557}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_electricity_traffic_exchange', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_electricity_traffic_exchange_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.8139941503164764
Epoch #1: loss=0.29431481354050526
Epoch #2: loss=0.18649194466388583
Epoch #3: loss=0.1518279066642059
Epoch #4: loss=0.11996485607757643
Epoch #5: loss=0.09011306272483803
Epoch #6: loss=0.08529543638064561
Epoch #7: loss=0.06524613318255075
Epoch #8: loss=0.06565724525294377
Epoch #9: loss=0.05733859459659666
Epoch #10: loss=0.04516965913790774
Epoch #11: loss=0.04541454426182406
Epoch #12: loss=0.0447455889186612
Epoch #13: loss=0.048818452170045615
Epoch #14: loss=0.03389816059056943
Epoch #15: loss=0.04108601654079029
Epoch #16: loss=0.03165536709174511
Epoch #17: loss=0.037247450287917934
Epoch #18: loss=0.03237742629807477
Epoch #19: loss=0.03503350870340179
Epoch #20: loss=0.031458556788113705
Epoch #21: loss=0.03240433899656199
Epoch #22: loss=0.025858922423404224
Epoch #23: loss=0.026627555974927858
Epoch #24: loss=0.026956923905404537
Epoch #25: loss=0.02918985784663088
Epoch #26: loss=0.027220820863830323
Epoch #27: loss=0.02406452157968447
Epoch #28: loss=0.023708915876170997
Epoch #29: loss=0.02716762595241524
Epoch #30: loss=0.021010469703712363
Epoch #31: loss=0.025608165241563723
Epoch #32: loss=0.024904192279305584
Epoch #33: loss=0.019364627334085185
Epoch #34: loss=0.026519116584852162
Epoch #35: loss=0.021386200378434958
Epoch #36: loss=0.01926499220065676
Epoch #37: loss=0.019488216898529805
Epoch #38: loss=0.018962496858554074
Epoch #39: loss=0.029761911798352126
Epoch #40: loss=0.017574342883840934
Epoch #41: loss=0.019701788898622338
Epoch #42: loss=0.019958871674212005
Epoch #43: loss=0.023536717458357
Epoch #44: loss=0.02169493964587755
Epoch #45: loss=0.014805759239500857
Epoch #46: loss=0.0216918686668022
Epoch #47: loss=0.01897002220779031
Epoch #48: loss=0.0208801245474772
Epoch #49: loss=0.01905189965135816
Epoch #50: loss=0.01933791619842718
Epoch #51: loss=0.021227391712818035
Epoch #52: loss=0.014419742846866437
Epoch #53: loss=0.023027166012788848
Epoch #54: loss=0.018685198845629924
Epoch #55: loss=0.017666732771703057
Epoch #56: loss=0.015087570945266051
Epoch #57: loss=0.020572418430134055
Epoch #58: loss=0.0264923126537443
Epoch #59: loss=0.02140134067326813
Epoch #60: loss=0.02029375567615288
Epoch #61: loss=0.01739298682199742
Epoch #62: loss=0.017417348019663284
Epoch #63: loss=0.01862008122029366
Epoch #64: loss=0.01709704274491532
Epoch #65: loss=0.0161244919383568
Epoch #66: loss=0.01788076560653572
Epoch #67: loss=0.014413936145298335
Epoch #68: loss=0.023529079655515348
Epoch #69: loss=0.018009877159966284
Epoch #70: loss=0.015480552599358198
Epoch #71: loss=0.017108381288488572
Epoch #72: loss=0.01554277730903659
Epoch #73: loss=0.014589756962697284
Epoch #74: loss=0.01763063792436841
Epoch #75: loss=0.013654295689799902
Epoch #76: loss=0.01589235988725832
Epoch #77: loss=0.015671534691030626
Epoch #78: loss=0.016587554034305688
Epoch #79: loss=0.018023428101250388
Epoch #80: loss=0.020306866467187573
Epoch #81: loss=0.021456211194503298
Epoch #82: loss=0.014333600886716105
Epoch #83: loss=0.02032884561199907
Epoch #84: loss=0.013991244578679039
Epoch #85: loss=0.013905016762435355
Epoch #86: loss=0.015797781492577625
Epoch #87: loss=0.011211422512704041
Epoch #88: loss=0.015683943569826938
Epoch #89: loss=0.016212275868659927
Epoch #90: loss=0.016360768740860187
Epoch #91: loss=0.01563477021958236
Epoch #92: loss=0.012689323091738779
Epoch #93: loss=0.012496081313076748
Epoch #94: loss=0.011932192711403106
Epoch #95: loss=0.020095599833299647
Epoch #96: loss=0.011812739958301559
Epoch #97: loss=0.010865203288889284
Epoch #98: loss=0.014458014705018778
Epoch #99: loss=0.011802197765434671
Epoch #100: loss=0.016433790837767696
Epoch #101: loss=0.017492169738626294
Epoch #102: loss=0.014014350660484252
Epoch #103: loss=0.015444138843752463
Epoch #104: loss=0.015862571996359036
Epoch #105: loss=0.031913909496560124
Epoch #106: loss=0.011449359073558237
Epoch #107: loss=0.01331458539860976
Epoch #108: loss=0.015323714565786763
Epoch #109: loss=0.015921667801572486
Epoch #110: loss=0.012418891680355107
Epoch #111: loss=0.017090865374545298
Epoch #112: loss=0.01132545025957704
Epoch #113: loss=0.014702066625722059
Epoch #114: loss=0.013260723031176737
Epoch #115: loss=0.015965947026810732
Epoch #116: loss=0.01153954543740182
Epoch #117: loss=0.01379466058298357
Epoch #118: loss=0.01576565876420438
Epoch #119: loss=0.01086435011696241
Epoch #120: loss=0.01975077659750022
Epoch #121: loss=0.01165831822257137
Epoch #122: loss=0.010764830034522659
Epoch #123: loss=0.015587194654616358
Epoch #124: loss=0.016581866337061345
Epoch #125: loss=0.012219964102219509
Epoch #126: loss=0.011639194963108654
Epoch #127: loss=0.018843941455572853
Epoch #128: loss=0.012224234830769237
Epoch #129: loss=0.012532745053216124
Epoch #130: loss=0.011448067879532748
Epoch #131: loss=0.024948732981908032
Epoch #132: loss=0.010330056522261368
Epoch #133: loss=0.00985065740264485
Epoch #134: loss=0.010336633956338511
Epoch #135: loss=0.013785107404901024
Epoch #136: loss=0.012275183224544385
Epoch #137: loss=0.019398082067415206
Epoch #138: loss=0.013779075712976955
Epoch #139: loss=0.019918191245886674
Epoch #140: loss=0.013377386288067679
Epoch #141: loss=0.010958655757613527
Epoch #142: loss=0.014932521982190397
Epoch #143: loss=0.01391453996703438
Epoch #144: loss=0.011172802649926539
Epoch #145: loss=0.01233955620067147
Epoch #146: loss=0.013713015329021997
Epoch #147: loss=0.011110623726021314
Epoch #148: loss=0.011029638996027498
Epoch #149: loss=0.01019210711869853
Epoch #150: loss=0.012055544472688312
Epoch #151: loss=0.012102537577069876
Epoch #152: loss=0.016886990458732907
Epoch #153: loss=0.012472144299536983
Epoch #154: loss=0.012195322383153863
Epoch #155: loss=0.00986157008332473
Epoch #156: loss=0.010011572828056727
Epoch #157: loss=0.011644803978235422
Epoch #158: loss=0.013166832601361386
Epoch #159: loss=0.012498543749541038
Epoch #160: loss=0.01273307914434645
Epoch #161: loss=0.013599102128922312
Epoch #162: loss=0.01042199591912278
Epoch #163: loss=0.01111848275322457
Epoch #164: loss=0.010557993025360948
Epoch #165: loss=0.009785760538462562
Epoch #166: loss=0.013254953860000121
Epoch #167: loss=0.01083661988693389
Epoch #168: loss=0.013427900473823362
Epoch #169: loss=0.0160357876862168
Epoch #170: loss=0.021947056462774645
Epoch #171: loss=0.014565025221414842
Epoch #172: loss=0.008863863190315848
Epoch #173: loss=0.00926467099931455
Epoch #174: loss=0.00907007039007208
Epoch #175: loss=0.015063366053195651
Epoch #176: loss=0.008384237500172998
Epoch #177: loss=0.013362208847405925
Epoch #178: loss=0.011914701171245969
Epoch #179: loss=0.011192530745506588
Epoch #180: loss=0.015109195153195705
Epoch #181: loss=0.008618471773699095
Epoch #182: loss=0.008786316613541066
Epoch #183: loss=0.011805417034806115
Epoch #184: loss=0.014977059800185393
Epoch #185: loss=0.008567722849366632
Epoch #186: loss=0.009910161385445515
Epoch #187: loss=0.010751756223767256
Epoch #188: loss=0.008698035673541911
Epoch #189: loss=0.013623662868268124
Epoch #190: loss=0.010043665676732207
Epoch #191: loss=0.007391303637210416
Epoch #192: loss=0.010125002495462198
Epoch #193: loss=0.013317617399457011
Epoch #194: loss=0.012123025633979807
Epoch #195: loss=0.009424377213476517
Epoch #196: loss=0.014234334624952362
Epoch #197: loss=0.011711714200599011
Epoch #198: loss=0.012583325353975525
Epoch #199: loss=0.013211845479771892
Epoch #200: loss=0.008788012750319497
Epoch #201: loss=0.00956881983573033
Epoch #202: loss=0.008638424643882923
Epoch #203: loss=0.013734197722718673
Epoch #204: loss=0.009326990333653773
Epoch #205: loss=0.008843287740094947
Epoch #206: loss=0.015203830811824963
Epoch #207: loss=0.01197526661752467
Epoch #208: loss=0.009582907112061865
Epoch #209: loss=0.009160857665847288
Epoch #210: loss=0.010996829721603681
Epoch #211: loss=0.011732949089449225
Epoch #212: loss=0.013550018957339762
Epoch #213: loss=0.012225039875033683
Epoch #214: loss=0.010356122677137876
Epoch #215: loss=0.009262698751745317
Epoch #216: loss=0.012773760953901191
Epoch #217: loss=0.010389388622534109
Epoch #218: loss=0.008281866964503275
Epoch #219: loss=0.012634070857053115
Epoch #220: loss=0.012648000516109549
Epoch #221: loss=0.010590570361712227
Epoch #222: loss=0.010567528548957905
Epoch #223: loss=0.011385002556193884
Epoch #224: loss=0.013466160958929696
Epoch #225: loss=0.010572814328668585
Epoch #226: loss=0.008035726219386318
Epoch #227: loss=0.009123256074886612
Epoch #228: loss=0.01217525963318907
Epoch #229: loss=0.011197619740724411
Epoch #230: loss=0.009821435449530645
Epoch #231: loss=0.010488178625760482
Epoch #232: loss=0.01001205059132651
Epoch #233: loss=0.009159371371700982
Epoch #234: loss=0.013214934294843073
Epoch #235: loss=0.016902630197841252
Epoch #236: loss=0.011202631481986424
Epoch #237: loss=0.007957276246935683
Epoch #238: loss=0.006061345753423453
Epoch #239: loss=0.012131748946278841
Epoch #240: loss=0.016430067290775088
Epoch #241: loss=0.011175146263095136
Epoch #242: loss=0.008728671018980701
Epoch #243: loss=0.011714916324158116
Epoch #244: loss=0.01035741713091005
Epoch #245: loss=0.009671297933985903
Epoch #246: loss=0.0077187384594616555
Epoch #247: loss=0.013157628398879939
Epoch #248: loss=0.01088369230608429
Epoch #249: loss=0.0164608367330446

Training time: 4:53:05.077924

Finished.
n2one setting etth1_electricity_traffic_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_electricity_traffic_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_electricity_traffic_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.6357e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.97665e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.3056e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.6357e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3972336279898212, 'MAE': 0.4625609033984276}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_electricity_weather_exchange', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_electricity_weather_exchange_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.6481612770926228
Epoch #1: loss=0.7815992381855927
Epoch #2: loss=0.5576289178422802
Epoch #3: loss=0.4561049523274543
Epoch #4: loss=0.4078257521048435
Epoch #5: loss=0.3446355995552316
Epoch #6: loss=0.3220626916839273
Epoch #7: loss=0.2945502932847205
Epoch #8: loss=0.26881541900377903
Epoch #9: loss=0.23762307126713061
Epoch #10: loss=0.23166579187163333
Epoch #11: loss=0.2201439481516734
Epoch #12: loss=0.19596138777653815
Epoch #13: loss=0.17303985679388376
Epoch #14: loss=0.18686526925277314
Epoch #15: loss=0.17994646293764616
Epoch #16: loss=0.16004067877544223
Epoch #17: loss=0.14286431744283076
Epoch #18: loss=0.1311718372895655
Epoch #19: loss=0.14784756471089072
Epoch #20: loss=0.1248031305766649
Epoch #21: loss=0.10433941849028866
Epoch #22: loss=0.1017624399012459
Epoch #23: loss=0.14761906148587967
Epoch #24: loss=0.13345644918646024
Epoch #25: loss=0.09839488397151726
Epoch #26: loss=0.0849725098313136
Epoch #27: loss=0.07959439260473485
Epoch #28: loss=0.08433676594405214
Epoch #29: loss=0.0895535845299205
Epoch #30: loss=0.07312719628873451
Epoch #31: loss=0.0722237456131994
Epoch #32: loss=0.08532809721722746
Epoch #33: loss=0.06137205306852226
Epoch #34: loss=0.08094728558494077
Epoch #35: loss=0.0692017586009052
Epoch #36: loss=0.056303984666942974
Epoch #37: loss=0.051937790478847265
Epoch #38: loss=0.06061255785338169
Epoch #39: loss=0.06970018953167273
Epoch #40: loss=0.08813015270582014
Epoch #41: loss=0.09227761254872283
Epoch #42: loss=0.05745904403031181
Epoch #43: loss=0.04920395763233325
Epoch #44: loss=0.06766820012319072
Epoch #45: loss=0.057833577622016324
Epoch #46: loss=0.04733586697569066
Epoch #47: loss=0.04928139117752197
Epoch #48: loss=0.059913429470207974
Epoch #49: loss=0.06796556804457793
Epoch #50: loss=0.06318096236457009
Epoch #51: loss=0.04794455379555105
Epoch #52: loss=0.04494046084184035
Epoch #53: loss=0.04301003249714573
Epoch #54: loss=0.04603653575309156
Epoch #55: loss=0.06001819683063919
Epoch #56: loss=0.043566559409228725
Epoch #57: loss=0.06042976450118447
Epoch #58: loss=0.05712655730139032
Epoch #59: loss=0.04559911174239148
Epoch #60: loss=0.044059642595406213
Epoch #61: loss=0.043318528955665965
Epoch #62: loss=0.03912117550932952
Epoch #63: loss=0.06786039616534414
Epoch #64: loss=0.047142705285808495
Epoch #65: loss=0.045400742931196274
Epoch #66: loss=0.030338117319933598
Epoch #67: loss=0.040950810268215156
Epoch #68: loss=0.03848435099491366
Epoch #69: loss=0.036795828444497324
Epoch #70: loss=0.0323238563309012
Epoch #71: loss=0.03813170942089402
Epoch #72: loss=0.04369008661317253
Epoch #73: loss=0.032815214766842925
Epoch #74: loss=0.04726175046448714
Epoch #75: loss=0.046674716009794434
Epoch #76: loss=0.035712188580723024
Epoch #77: loss=0.03335826527050732
Epoch #78: loss=0.03348731642360001
Epoch #79: loss=0.02972635391164437
Epoch #80: loss=0.02423551704641946
Epoch #81: loss=0.04189051262576401
Epoch #82: loss=0.031041544948599058
Epoch #83: loss=0.02862965621862005
Epoch #84: loss=0.04144605150309942
Epoch #85: loss=0.03960705410498735
Epoch #86: loss=0.05379212544381989
Epoch #87: loss=0.03218057121372735
Epoch #88: loss=0.03216167017675998
Epoch #89: loss=0.022939253618872533
Epoch #90: loss=0.027535325708719954
Epoch #91: loss=0.03133499022034249
Epoch #92: loss=0.028686344168195245
Epoch #93: loss=0.028493201175996602
Epoch #94: loss=0.022981088763026992
Epoch #95: loss=0.035810809855501155
Epoch #96: loss=0.03356653621815176
Epoch #97: loss=0.035634447931754534
Epoch #98: loss=0.029956817345080114
Epoch #99: loss=0.03935454128431002
Epoch #100: loss=0.03383952244802363
Epoch #101: loss=0.05887316333423291
Epoch #102: loss=0.0310723823591686
Epoch #103: loss=0.029800777590784724
Epoch #104: loss=0.02843124665948948
Epoch #105: loss=0.037744964070641304
Epoch #106: loss=0.033704959996783
Epoch #107: loss=0.027710512389482942
Epoch #108: loss=0.033114844962738414
Epoch #109: loss=0.049090656887634414
Epoch #110: loss=0.028598100611379174
Epoch #111: loss=0.0508534443726794
Epoch #112: loss=0.0271328123468386
Epoch #113: loss=0.02493721548225396
Epoch #114: loss=0.03556467359178077
Epoch #115: loss=0.020626192096748146
Epoch #116: loss=0.019354489018197703
Epoch #117: loss=0.023131473066294258
Epoch #118: loss=0.03576575455597334
Epoch #119: loss=0.032825637046628484
Epoch #120: loss=0.030382940822888106
Epoch #121: loss=0.02607059163859536
Epoch #122: loss=0.022960098834485795
Epoch #123: loss=0.02541725994528333
Epoch #124: loss=0.03536320380507634
Epoch #125: loss=0.032662571745844894
Epoch #126: loss=0.02202684945444247
Epoch #127: loss=0.020583173659587027
Epoch #128: loss=0.025884446729802994
Epoch #129: loss=0.01818422844295148
Epoch #130: loss=0.016467351747968734
Epoch #131: loss=0.020879965686517156
Epoch #132: loss=0.017986601052158744
Epoch #133: loss=0.030324833622930356
Epoch #134: loss=0.029392903231699224
Epoch #135: loss=0.020188649755179654
Epoch #136: loss=0.03118538425496306
Epoch #137: loss=0.028824042423386435
Epoch #138: loss=0.02031955573839992
Epoch #139: loss=0.01594537066593856
Epoch #140: loss=0.016266818091116374
Epoch #141: loss=0.017207731907908773
Epoch #142: loss=0.03364258876825472
Epoch #143: loss=0.018440943144908874
Epoch #144: loss=0.018011591731357125
Epoch #145: loss=0.03211842431382595
Epoch #146: loss=0.027521862111694967
Epoch #147: loss=0.05437700919683467
Epoch #148: loss=0.031917529503521586
Epoch #149: loss=0.021663872571726386
Epoch #150: loss=0.017394568149652588
Epoch #151: loss=0.020586982361302783
Epoch #152: loss=0.037620295607742146
Epoch #153: loss=0.020539657563486944
Epoch #154: loss=0.026451640221797114
Epoch #155: loss=0.0221432556989294
Epoch #156: loss=0.02144335963204053
Epoch #157: loss=0.025400753421625327
Epoch #158: loss=0.02023512143860391
Epoch #159: loss=0.01880141234238251
Epoch #160: loss=0.020767729895354057
Epoch #161: loss=0.022861007850576008
Epoch #162: loss=0.02036960736719135
Epoch #163: loss=0.04426509097751709
Epoch #164: loss=0.037943690389752364
Epoch #165: loss=0.020617604431666006
Epoch #166: loss=0.023395903379745134
Epoch #167: loss=0.02586531512666293
Epoch #168: loss=0.019956185409280815
Epoch #169: loss=0.019214857097034015
Epoch #170: loss=0.01814120649218621
Epoch #171: loss=0.023541162698658295
Epoch #172: loss=0.02568352271517152
Epoch #173: loss=0.017145163271555585
Epoch #174: loss=0.017950237596642937
Epoch #175: loss=0.017893838050430485
Epoch #176: loss=0.021805031851058806
Epoch #177: loss=0.031866993453210216
Epoch #178: loss=0.018674983973026364
Epoch #179: loss=0.013570084552845316
Epoch #180: loss=0.01794317798452318
Epoch #181: loss=0.014450046864308633
Epoch #182: loss=0.02458657953294524
Epoch #183: loss=0.03813862716631182
Epoch #184: loss=0.03280582420739541
Epoch #185: loss=0.01411018390293704
Epoch #186: loss=0.017477086737042215
Epoch #187: loss=0.013940837765282961
Epoch #188: loss=0.018187435947163082
Epoch #189: loss=0.02494397209021417
Epoch #190: loss=0.019435373977314197
Epoch #191: loss=0.02425629551617624
Epoch #192: loss=0.01896872614990812
Epoch #193: loss=0.015050974406639
Epoch #194: loss=0.03714808364603308
Epoch #195: loss=0.019902388577623477
Epoch #196: loss=0.026327493473358752
Epoch #197: loss=0.05036392805227001
Epoch #198: loss=0.030242475812054543
Epoch #199: loss=0.022307685056851805
Epoch #200: loss=0.01665220806955293
Epoch #201: loss=0.02263272770811374
Epoch #202: loss=0.017652629608692322
Epoch #203: loss=0.01708264737568464
Epoch #204: loss=0.02167537787434573
Epoch #205: loss=0.02104914961405258
Epoch #206: loss=0.022261169618471573
Epoch #207: loss=0.029972296081758644
Epoch #208: loss=0.037230778108420376
Epoch #209: loss=0.021858422966958255
Epoch #210: loss=0.012672239235661492
Epoch #211: loss=0.015582606711589541
Epoch #212: loss=0.01954184879025622
Epoch #213: loss=0.02106307871695685
Epoch #214: loss=0.019450841406591812
Epoch #215: loss=0.019153580197293275
Epoch #216: loss=0.02391815427494575
Epoch #217: loss=0.02268819511354803
Epoch #218: loss=0.016545047746355086
Epoch #219: loss=0.024558777076569102
Epoch #220: loss=0.027724768032862685
Epoch #221: loss=0.024569810339820815
Epoch #222: loss=0.016144048427720426
Epoch #223: loss=0.02597896005117041
Epoch #224: loss=0.019679007980681812
Epoch #225: loss=0.015760498681267755
Epoch #226: loss=0.01890179325613574
Epoch #227: loss=0.019682758255412762
Epoch #228: loss=0.019638999457566263
Epoch #229: loss=0.01916220927680457
Epoch #230: loss=0.023650916428330934
Epoch #231: loss=0.016770020822331293
Epoch #232: loss=0.01763671677077552
Epoch #233: loss=0.013322634828110993
Epoch #234: loss=0.020921781639509335
Epoch #235: loss=0.01509622917328871
Epoch #236: loss=0.01710733806224635
Epoch #237: loss=0.020239869902040346
Epoch #238: loss=0.015796788247464257
Epoch #239: loss=0.028568590273250934
Epoch #240: loss=0.01775993756436645
Epoch #241: loss=0.015400400851404253
Epoch #242: loss=0.01733300084626374
Epoch #243: loss=0.0300096914674495
Epoch #244: loss=0.016920519968268374
Epoch #245: loss=0.02750642522166159
Epoch #246: loss=0.017253003415531987
Epoch #247: loss=0.014518162357017594
Epoch #248: loss=0.014099746680666065
Epoch #249: loss=0.014861974788338296

Training time: 1:40:25.099079

Finished.
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_traffic_weather_exchange', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_traffic_weather_exchange_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.0190024340601591
Epoch #1: loss=0.41653721412418954
Epoch #2: loss=0.28285651708461124
Epoch #3: loss=0.22142802579029322
Epoch #4: loss=0.18854208281913468
Epoch #5: loss=0.16582347233578612
Epoch #6: loss=0.13585888116248157
Epoch #7: loss=0.12582614769641381
Epoch #8: loss=0.12173414824722316
Epoch #9: loss=0.09695779341701026
Epoch #10: loss=0.08961207768544638
Epoch #11: loss=0.08383163219938676
Epoch #12: loss=0.0775296806903393
Epoch #13: loss=0.06390769039832493
Epoch #14: loss=0.06448544986011792
Epoch #15: loss=0.0665507889422356
Epoch #16: loss=0.0602643428069198
Epoch #17: loss=0.05837069722516452
Epoch #18: loss=0.055574512976022686
Epoch #19: loss=0.04825033778082353
Epoch #20: loss=0.04760223938511109
Epoch #21: loss=0.04406844608404221
Epoch #22: loss=0.06044494238623303
Epoch #23: loss=0.03975644047683515
Epoch #24: loss=0.04212310947599003
Epoch #25: loss=0.040713248494135865
Epoch #26: loss=0.046562671734217104
Epoch #27: loss=0.04342503996167831
Epoch #28: loss=0.04530771633577641
Epoch #29: loss=0.040038178288114824
Epoch #30: loss=0.03325435840875397
Epoch #31: loss=0.03282606208262241
Epoch #32: loss=0.03747490249975901
Epoch #33: loss=0.033642913563979394
Epoch #34: loss=0.041026106373183144
Epoch #35: loss=0.027320066126963846
Epoch #36: loss=0.0314329558809918
Epoch #37: loss=0.030684540924450623
Epoch #38: loss=0.02847773561161063
Epoch #39: loss=0.02845460852057078
Epoch #40: loss=0.03045913299629702
Epoch #41: loss=0.028506321698782505
Epoch #42: loss=0.027085248245274935
Epoch #43: loss=0.035548704351385664
Epoch #44: loss=0.026234265210780965
Epoch #45: loss=0.03295560516643927
Epoch #46: loss=0.022419100882888256
Epoch #47: loss=0.026816911943609002
Epoch #48: loss=0.03518345748822866
Epoch #49: loss=0.024016502697922344
Epoch #50: loss=0.024737629867344475
Epoch #51: loss=0.019272159609055622
Epoch #52: loss=0.025947569664732727
Epoch #53: loss=0.02811740368318714
Epoch #54: loss=0.028567320430766818
Epoch #55: loss=0.02410771252035915
Epoch #56: loss=0.02193619863435436
Epoch #57: loss=0.022788298206266166
Epoch #58: loss=0.021173623963676863
Epoch #59: loss=0.01916767747302185
Epoch #60: loss=0.02351377409643567
Epoch #61: loss=0.02639875132602135
Epoch #62: loss=0.025105520645643822
Epoch #63: loss=0.03421667116090288
Epoch #64: loss=0.028633439717690563
Epoch #65: loss=0.0301608408727515
Epoch #66: loss=0.027850919651694735
Epoch #67: loss=0.0251100943957539
Epoch #68: loss=0.023825396380031682
Epoch #69: loss=0.018250406586891504
Epoch #70: loss=0.020812364624194897
Epoch #71: loss=0.022778900821202312
Epoch #72: loss=0.019990518440435468
Epoch #73: loss=0.0226001071557119
Epoch #74: loss=0.02136823120933714
Epoch #75: loss=0.026568544956049465
Epoch #76: loss=0.02233613770445324
Epoch #77: loss=0.013720015344300342
Epoch #78: loss=0.01964938878807562
Epoch #79: loss=0.018518732298977245
Epoch #80: loss=0.027203719167939695
Epoch #81: loss=0.020266290348560003
Epoch #82: loss=0.02315731156952081
Epoch #83: loss=0.02160047636246711
Epoch #84: loss=0.021737713659235564
Epoch #85: loss=0.01888384907938935
Epoch #86: loss=0.02034458237039317
Epoch #87: loss=0.020766101018468933
Epoch #88: loss=0.02104975236876293
Epoch #89: loss=0.020715020724709154
Epoch #90: loss=0.018880681207793914
Epoch #91: loss=0.01357924877412608
Epoch #92: loss=0.02376846896596913
Epoch #93: loss=0.02616670688073814
Epoch #94: loss=0.022555370322728367
Epoch #95: loss=0.021145538951739297
Epoch #96: loss=0.01748328342874445
Epoch #97: loss=0.017706738293173766
Epoch #98: loss=0.026995586136723163
Epoch #99: loss=0.02007460039683204
Epoch #100: loss=0.01661955476081662
Epoch #101: loss=0.021300935657972888
Epoch #102: loss=0.01424443782860277
Epoch #103: loss=0.018250006052531593
Epoch #104: loss=0.015320674552503433
Epoch #105: loss=0.0196633115447809
Epoch #106: loss=0.0211434852100013
Epoch #107: loss=0.011542208165345855
Epoch #108: loss=0.02153838242433557
Epoch #109: loss=0.02301489088867001
Epoch #110: loss=0.021144678713256187
Epoch #111: loss=0.012506529957892483
Epoch #112: loss=0.02062512923768569
Epoch #113: loss=0.020949938087319337
Epoch #114: loss=0.019324537019767715
Epoch #115: loss=0.015546917010804923
Epoch #116: loss=0.013435046306012223
Epoch #117: loss=0.020353605039111558
Epoch #118: loss=0.01911649330379132
Epoch #119: loss=0.017322983744617135
Epoch #120: loss=0.019428124449455363
Epoch #121: loss=0.016597241426251852
Epoch #122: loss=0.020418685340447093
Epoch #123: loss=0.02479406869674389
Epoch #124: loss=0.01905689916459628
Epoch #125: loss=0.017150022008905964
Epoch #126: loss=0.0129982056392069
Epoch #127: loss=0.016983884916936563
Epoch #128: loss=0.02179945481111242
Epoch #129: loss=0.015070222530343569
Epoch #130: loss=0.016427864126196123
Epoch #131: loss=0.013002585643328853
Epoch #132: loss=0.01551415627262571
Epoch #133: loss=0.019896043696469634
Epoch #134: loss=0.019973179822353696
Epoch #135: loss=0.016299971508776
Epoch #136: loss=0.01902741254428515
Epoch #137: loss=0.016539709430132762
Epoch #138: loss=0.013901438472802433
Epoch #139: loss=0.015504364725506575
Epoch #140: loss=0.010906674439059277
Epoch #141: loss=0.018588191123749154
Epoch #142: loss=0.019438632643574812
Epoch #143: loss=0.018134077023352513
Epoch #144: loss=0.015591672454167267
Epoch #145: loss=0.015466580760898843
Epoch #146: loss=0.015159353157796754
Epoch #147: loss=0.016092615449185943
Epoch #148: loss=0.012881353966744023
Epoch #149: loss=0.022670334230380413
Epoch #150: loss=0.017440000244319347
Epoch #151: loss=0.014509119894385832
Epoch #152: loss=0.015321570052146492
Epoch #153: loss=0.023337063323892033
Epoch #154: loss=0.016292980795580243
Epoch #155: loss=0.016378671796403253
Epoch #156: loss=0.014953960043237393
Epoch #157: loss=0.010491943735681405
Epoch #158: loss=0.017506303961233677
Epoch #159: loss=0.014535026846284403
Epoch #160: loss=0.017282589943164183
Epoch #161: loss=0.023654375768818785
Epoch #162: loss=0.01536806332024347
Epoch #163: loss=0.00941130404829799
Epoch #164: loss=0.013980083831018758
Epoch #165: loss=0.01800906826320552
Epoch #166: loss=0.01456781237082301
Epoch #167: loss=0.012473250151946285
Epoch #168: loss=0.014329134042097352
Epoch #169: loss=0.01312328037367654
Epoch #170: loss=0.029960808252393868
Epoch #171: loss=0.011199862478950818
Epoch #172: loss=0.012514082079368839
Epoch #173: loss=0.013265098376730624
Epoch #174: loss=0.013860252763841875
Epoch #175: loss=0.014257488900935844
Epoch #176: loss=0.018764600810978523
Epoch #177: loss=0.014095853487646429
Epoch #178: loss=0.012285808429093222
Epoch #179: loss=0.016143766460620646
Epoch #180: loss=0.01009429843465172
Epoch #181: loss=0.009685755918286035
Epoch #182: loss=0.021026869301239037
Epoch #183: loss=0.01606341914023628
Epoch #184: loss=0.01493208510044432
Epoch #185: loss=0.016043686615474624
Epoch #186: loss=0.01351924056419587
Epoch #187: loss=0.01278455078165183
Epoch #188: loss=0.0116711400124815
Epoch #189: loss=0.01315429745370469
Epoch #190: loss=0.01366776284258743
Epoch #191: loss=0.01285025191933983
Epoch #192: loss=0.020100327047777485
Epoch #193: loss=0.011667983341155186
Epoch #194: loss=0.01828819381206292
Epoch #195: loss=0.015034674266305871
Epoch #196: loss=0.012754470582949338
Epoch #197: loss=0.01287741076644623
Epoch #198: loss=0.012193456182521531
Epoch #199: loss=0.013387590495390964
Epoch #200: loss=0.011316102335927234
Epoch #201: loss=0.01676460877558524
Epoch #202: loss=0.014792891275032593
Epoch #203: loss=0.023447258705863727
Epoch #204: loss=0.011567698574170285
Epoch #205: loss=0.010542972267545985
Epoch #206: loss=0.014472720220147794
Epoch #207: loss=0.015803005815678815
Epoch #208: loss=0.018215385974002723
Epoch #209: loss=0.018905269730372553
Epoch #210: loss=0.015975787022521313
Epoch #211: loss=0.015648470782750397
Epoch #212: loss=0.012653402201142906
Epoch #213: loss=0.015063329939020112
Epoch #214: loss=0.014977376884406954
Epoch #215: loss=0.013354908637906804
Epoch #216: loss=0.013456226579644738
Epoch #217: loss=0.013784969621666698
Epoch #218: loss=0.014905233158000152
Epoch #219: loss=0.012488981434589501
Epoch #220: loss=0.012950071716990662
Epoch #221: loss=0.01491478490528464
Epoch #222: loss=0.018409486825905114
Epoch #223: loss=0.013779257056751966
Epoch #224: loss=0.011655446705299053
Epoch #225: loss=0.0098305423933375
Epoch #226: loss=0.02194705467739097
Epoch #227: loss=0.014125480172397741
Epoch #228: loss=0.010826549489956256
Epoch #229: loss=0.01807355575549962
Epoch #230: loss=0.013547447853000561
Epoch #231: loss=0.01115126833235221
Epoch #232: loss=0.008090470137512856
Epoch #233: loss=0.012079176454135612
Epoch #234: loss=0.0129680483366256
Epoch #235: loss=0.01402162979200306
Epoch #236: loss=0.011082261463429069
Epoch #237: loss=0.012912788638708237
Epoch #238: loss=0.017550135484006985
Epoch #239: loss=0.009905151480301837
Epoch #240: loss=0.012620478230730293
Epoch #241: loss=0.015222240160530715
Epoch #242: loss=0.014875705162903674
Epoch #243: loss=0.013121203702447045
Epoch #244: loss=0.02111061795314017
Epoch #245: loss=0.013807259176661552
Epoch #246: loss=0.010595643111448018
Epoch #247: loss=0.014229751408072023
Epoch #248: loss=0.012395073161568753
Epoch #249: loss=0.016769478789233273

Training time: 3:35:49.857599

Finished.
n2one setting etth1_traffic_weather_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_traffic_weather_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='etth1_traffic_weather_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.41238e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.76272e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.54207e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.41238e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.40237813552869406, 'MAE': 0.45107368622591415}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm1_ettm2_electricity', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm1_ettm2_electricity_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.6201475351197379
Epoch #1: loss=0.6652613362244197
Epoch #2: loss=0.4717332991531917
Epoch #3: loss=0.34515184240681784
Epoch #4: loss=0.30492298505135945
Epoch #5: loss=0.2615246611194951
Epoch #6: loss=0.24653864204883574
Epoch #7: loss=0.2121109685088907
Epoch #8: loss=0.19775750185762134
Epoch #9: loss=0.1649343787665878
Epoch #10: loss=0.1334388238617352
Epoch #11: loss=0.13315774480147022
Epoch #12: loss=0.14279086796300752
Epoch #13: loss=0.12445874856518847
Epoch #14: loss=0.10288899618067912
Epoch #15: loss=0.09928042863628694
Epoch #16: loss=0.11971278634454523
Epoch #17: loss=0.08105553475873811
Epoch #18: loss=0.0793839652995978
Epoch #19: loss=0.08320166766909616
Epoch #20: loss=0.0755204488230603
Epoch #21: loss=0.07170773051945227
Epoch #22: loss=0.06437148014748735
Epoch #23: loss=0.05448803255467542
Epoch #24: loss=0.05777171082528574
Epoch #25: loss=0.06087361246746566
Epoch #26: loss=0.057435663283935616
Epoch #27: loss=0.059121836474431415
Epoch #28: loss=0.056471480514322006
Epoch #29: loss=0.045361997203768364
Epoch #30: loss=0.05945768934674561
Epoch #31: loss=0.04624960659404418
Epoch #32: loss=0.04367250824879323
Epoch #33: loss=0.04416527458333543
Epoch #34: loss=0.03854234317118036
Epoch #35: loss=0.03450070780435843
Epoch #36: loss=0.04256459091590451
Epoch #37: loss=0.03840989785668041
Epoch #38: loss=0.040154739074142916
Epoch #39: loss=0.04367678047956101
Epoch #40: loss=0.04237733738696469
Epoch #41: loss=0.023786904522816517
Epoch #42: loss=0.03167086535865175
Epoch #43: loss=0.027246692484643842
Epoch #44: loss=0.030169425948656032
Epoch #45: loss=0.03369196619771953
Epoch #46: loss=0.033841994224515344
Epoch #47: loss=0.03300177973628576
Epoch #48: loss=0.024866469077034187
Epoch #49: loss=0.028753294804399566
Epoch #50: loss=0.02867884299751105
Epoch #51: loss=0.02051238031176451
Epoch #52: loss=0.040107139643015606
Epoch #53: loss=0.02286484760132485
Epoch #54: loss=0.02183594184794596
Epoch #55: loss=0.035371224664683856
Epoch #56: loss=0.025985403052597705
Epoch #57: loss=0.026058006588968317
Epoch #58: loss=0.021084387738290907
Epoch #59: loss=0.020584327812373106
Epoch #60: loss=0.031324263141224426
Epoch #61: loss=0.020707088208624293
Epoch #62: loss=0.04221597961549248
Epoch #63: loss=0.022951769549233305
Epoch #64: loss=0.01975364423589781
Epoch #65: loss=0.02153393826414166
Epoch #66: loss=0.02159579717487629
Epoch #67: loss=0.0201944637255344
Epoch #68: loss=0.023542319677570568
Epoch #69: loss=0.019132187940912055
Epoch #70: loss=0.01910936194605061
Epoch #71: loss=0.02233970045344904
Epoch #72: loss=0.020037475416902453
Epoch #73: loss=0.019439527471217195
Epoch #74: loss=0.01623693482784022
Epoch #75: loss=0.03476667906091149
Epoch #76: loss=0.020884280780363564
Epoch #77: loss=0.017597755856279818
Epoch #78: loss=0.03103511587151193
Epoch #79: loss=0.029068450966151432
Epoch #80: loss=0.0193160777652104
Epoch #81: loss=0.015004764717138772
Epoch #82: loss=0.013651287809479981
Epoch #83: loss=0.01541328945413365
Epoch #84: loss=0.017570494294798535
Epoch #85: loss=0.021862701527840856
Epoch #86: loss=0.016610415092602904
Epoch #87: loss=0.015644064268230326
Epoch #88: loss=0.015355431899328583
Epoch #89: loss=0.02763241498415092
Epoch #90: loss=0.01867732730561069
Epoch #91: loss=0.01976400835622501
Epoch #92: loss=0.019587188474168734
Epoch #93: loss=0.017781919342232867
Epoch #94: loss=0.014027872626902535
Epoch #95: loss=0.016009225623149957
Epoch #96: loss=0.015069947718709176
Epoch #97: loss=0.02275211087112049
Epoch #98: loss=0.014075524194465418
Epoch #99: loss=0.01589128197170794
Epoch #100: loss=0.016849922908835913
Epoch #101: loss=0.019950262445657115
Epoch #102: loss=0.01338722953938746
Epoch #103: loss=0.01567645084362344
Epoch #104: loss=0.017513741444397185
Epoch #105: loss=0.023770236562870976
Epoch #106: loss=0.020738151755815903
Epoch #107: loss=0.015788941881619393
Epoch #108: loss=0.010412983758059064
Epoch #109: loss=0.014349184985538678
Epoch #110: loss=0.013689921519003941
Epoch #111: loss=0.022914901850578775
Epoch #112: loss=0.03234634149254167
Epoch #113: loss=0.01461738490083787
Epoch #114: loss=0.029144401698306736
Epoch #115: loss=0.019669503570933427
Epoch #116: loss=0.014515930272006828
Epoch #117: loss=0.011422808890264214
Epoch #118: loss=0.011817098034828503
Epoch #119: loss=0.015031373161473311
Epoch #120: loss=0.015979342925794688
Epoch #121: loss=0.013724193159806808
Epoch #122: loss=0.017949045073723288
Epoch #123: loss=0.013172556144584503
Epoch #124: loss=0.016936625880022933
Epoch #125: loss=0.019171429084048473
Epoch #126: loss=0.01930791887438058
Epoch #127: loss=0.012964397962620881
Epoch #128: loss=0.009808760085475763
Epoch #129: loss=0.012243218800452139
Epoch #130: loss=0.011854684959065968
Epoch #131: loss=0.014993303089286201
Epoch #132: loss=0.017218897161406597
Epoch #133: loss=0.014514192911945948
Epoch #134: loss=0.008961812186088146
Epoch #135: loss=0.011614079297869466
Epoch #136: loss=0.01766811267248288
Epoch #137: loss=0.009483831450176824
Epoch #138: loss=0.026632601414707358
Epoch #139: loss=0.016474089459516107
Epoch #140: loss=0.013676703624161226
Epoch #141: loss=0.014212303931209525
Epoch #142: loss=0.010861697478020297
Epoch #143: loss=0.018002939337831255
Epoch #144: loss=0.010952929058527973
Epoch #145: loss=0.012571551580331288
Epoch #146: loss=0.020687505396947796
Epoch #147: loss=0.011252048012434637
Epoch #148: loss=0.011583331294740285
Epoch #149: loss=0.01635146967642608
Epoch #150: loss=0.010348203490970523
Epoch #151: loss=0.020106410082828787
Epoch #152: loss=0.01228679803723935
Epoch #153: loss=0.014123670196360244
Epoch #154: loss=0.009476831409431594
Epoch #155: loss=0.013958620613141518
Epoch #156: loss=0.017149742453059714
Epoch #157: loss=0.012940488150509607
Epoch #158: loss=0.01269102371630392
Epoch #159: loss=0.01829704844825236
Epoch #160: loss=0.011075863794955823
Epoch #161: loss=0.007943248187823753
Epoch #162: loss=0.014538598642019288
Epoch #163: loss=0.014884302693951343
Epoch #164: loss=0.0149484880973718
Epoch #165: loss=0.010600169957781742
Epoch #166: loss=0.014710737540819018
Epoch #167: loss=0.016080524815146678
Epoch #168: loss=0.01623806385705913
Epoch #169: loss=0.011065678575292363
Epoch #170: loss=0.010453671393999164
Epoch #171: loss=0.01687345427294661
Epoch #172: loss=0.012300628793143135
Epoch #173: loss=0.013625133319957449
Epoch #174: loss=0.01604306752178153
Epoch #175: loss=0.007427771324624441
Epoch #176: loss=0.01905199810962326
Epoch #177: loss=0.010104472757749526
Epoch #178: loss=0.016463822499416504
Epoch #179: loss=0.011155371198297612
Epoch #180: loss=0.009231722526352053
Epoch #181: loss=0.008274542424644876
Epoch #182: loss=0.009117952409932123
Epoch #183: loss=0.013052636750591253
Epoch #184: loss=0.011113764122128486
Epoch #185: loss=0.01779495757355887
Epoch #186: loss=0.020350701328134164
Epoch #187: loss=0.011909367288629125
Epoch #188: loss=0.010559292342680108
Epoch #189: loss=0.010487628023506008
Epoch #190: loss=0.009591757166365693
Epoch #191: loss=0.015064735465649782
Epoch #192: loss=0.008701789209652425
Epoch #193: loss=0.012911817794665693
Epoch #194: loss=0.012333910199647238
Epoch #195: loss=0.015065968936375742
Epoch #196: loss=0.013009925515091579
Epoch #197: loss=0.008382780864152924
Epoch #198: loss=0.011644013011828065
Epoch #199: loss=0.01217402770499965
Epoch #200: loss=0.01773114561119915
Epoch #201: loss=0.013779014138272032
Epoch #202: loss=0.01658598434895144
Epoch #203: loss=0.014862792397283817
Epoch #204: loss=0.012519477938102291
Epoch #205: loss=0.013008972784238203
Epoch #206: loss=0.008258396680799446
Epoch #207: loss=0.013543389237519087
Epoch #208: loss=0.009758275072422943
Epoch #209: loss=0.009347570681628505
Epoch #210: loss=0.014456652436305636
Epoch #211: loss=0.010650669511440876
Epoch #212: loss=0.009579404460133186
Epoch #213: loss=0.009621785515503559
Epoch #214: loss=0.011337391825592411
Epoch #215: loss=0.016430321045419468
Epoch #216: loss=0.028924042300786823
Epoch #217: loss=0.008084196916398858
Epoch #218: loss=0.007734580244037456
Epoch #219: loss=0.017852273996936025
Epoch #220: loss=0.0120633597122339
Epoch #221: loss=0.012208919558158544
Epoch #222: loss=0.022255326906867726
Epoch #223: loss=0.011834775670098939
Epoch #224: loss=0.011881598096307634
Epoch #225: loss=0.009543722939145353
Epoch #226: loss=0.009394632365687617
Epoch #227: loss=0.00650768821755524
Epoch #228: loss=0.008774648928332941
Epoch #229: loss=0.007399181536748074
Epoch #230: loss=0.012852751999328445
Epoch #231: loss=0.007270610770959008
Epoch #232: loss=0.010962403379962779
Epoch #233: loss=0.006891922605074277
Epoch #234: loss=0.01046510388621495
Epoch #235: loss=0.009909855161095039
Epoch #236: loss=0.009763499241006295
Epoch #237: loss=0.010416459270927589
Epoch #238: loss=0.011024987820003714
Epoch #239: loss=0.013881140858201043
Epoch #240: loss=0.008326857478657206
Epoch #241: loss=0.005618915464729071
Epoch #242: loss=0.007894219068382101
Epoch #243: loss=0.011405828495376876
Epoch #244: loss=0.008975525474857672
Epoch #245: loss=0.009559062197970758
Epoch #246: loss=0.014565455963269674
Epoch #247: loss=0.011836168606615892
Epoch #248: loss=0.00909301836060227
Epoch #249: loss=0.014959584615093523

Training time: 1:38:16.525548

Finished.
n2one setting etth2_ettm1_ettm2_electricity -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_ettm2_electricity_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_ettm1_ettm2_electricity', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.18899e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.31968e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.77895e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.18899e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 1.2213319597173635, 'MAE': 0.8815239442775574}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm1_ettm2_electricity -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_ettm2_electricity_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_ettm1_ettm2_electricity', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.87487e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.27287092030572757, 'MAE': 0.3593747324434825}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm1_ettm2_traffic', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm1_ettm2_traffic_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.9876672598448667
Epoch #1: loss=0.38752784408570407
Epoch #2: loss=0.26235247280461216
Epoch #3: loss=0.18652178031861716
Epoch #4: loss=0.16138374435848124
Epoch #5: loss=0.13127559247007542
Epoch #6: loss=0.10865902687254646
Epoch #7: loss=0.10407412799407637
Epoch #8: loss=0.08660527980153676
Epoch #9: loss=0.07501495706897927
Epoch #10: loss=0.06608942186765114
Epoch #11: loss=0.07430515176795348
Epoch #12: loss=0.055389661232676406
Epoch #13: loss=0.049270359542394344
Epoch #14: loss=0.05259938206022979
Epoch #15: loss=0.051023895048205016
Epoch #16: loss=0.05145017616594509
Epoch #17: loss=0.03934154732847392
Epoch #18: loss=0.03957753933262703
Epoch #19: loss=0.03842150008420363
Epoch #20: loss=0.037826574446453674
Epoch #21: loss=0.031904447071178996
Epoch #22: loss=0.03836234656722294
Epoch #23: loss=0.03172326749310893
Epoch #24: loss=0.03232312680043878
Epoch #25: loss=0.03269111855677041
Epoch #26: loss=0.026392182366484537
Epoch #27: loss=0.025609594920684618
Epoch #28: loss=0.034919835037554955
Epoch #29: loss=0.024971066234585244
Epoch #30: loss=0.02580961439205599
Epoch #31: loss=0.028750624025084274
Epoch #32: loss=0.028274510433117614
Epoch #33: loss=0.02156320501664522
Epoch #34: loss=0.026045591473032214
Epoch #35: loss=0.022310021791740933
Epoch #36: loss=0.023963351008183333
Epoch #37: loss=0.026206947409591765
Epoch #38: loss=0.025202510120882607
Epoch #39: loss=0.021536691176629805
Epoch #40: loss=0.02190715524423648
Epoch #41: loss=0.022048075408447432
Epoch #42: loss=0.019624253991817768
Epoch #43: loss=0.027274431280755698
Epoch #44: loss=0.02428764951872398
Epoch #45: loss=0.016342115672302614
Epoch #46: loss=0.019406492900789017
Epoch #47: loss=0.020014702788121397
Epoch #48: loss=0.01964136747849528
Epoch #49: loss=0.019889566533941166
Epoch #50: loss=0.020255867478384936
Epoch #51: loss=0.020489971983501547
Epoch #52: loss=0.02243872833888723
Epoch #53: loss=0.016721439430245545
Epoch #54: loss=0.025491731981843537
Epoch #55: loss=0.01558095613474525
Epoch #56: loss=0.019393778055269734
Epoch #57: loss=0.020501131958609885
Epoch #58: loss=0.015592150241297259
Epoch #59: loss=0.018436989628220674
Epoch #60: loss=0.019792235050260013
Epoch #61: loss=0.017372043171444675
Epoch #62: loss=0.01741375220231618
Epoch #63: loss=0.019014439737833472
Epoch #64: loss=0.01712916144559878
Epoch #65: loss=0.017405601446143133
Epoch #66: loss=0.015603948511783238
Epoch #67: loss=0.01750963534037483
Epoch #68: loss=0.018563802545580817
Epoch #69: loss=0.014661311848555805
Epoch #70: loss=0.013597890331334614
Epoch #71: loss=0.01971634226058339
Epoch #72: loss=0.01564422610795829
Epoch #73: loss=0.014117168178131195
Epoch #74: loss=0.01834029427796966
Epoch #75: loss=0.019631999840541283
Epoch #76: loss=0.01683693542070065
Epoch #77: loss=0.014625713520479
Epoch #78: loss=0.015098801254416063
Epoch #79: loss=0.015027960292833223
Epoch #80: loss=0.015711287106178265
Epoch #81: loss=0.015670377483348936
Epoch #82: loss=0.020327746602279363
Epoch #83: loss=0.01568418398588205
Epoch #84: loss=0.01778173952950865
Epoch #85: loss=0.018931492772738593
Epoch #86: loss=0.013935835843429693
Epoch #87: loss=0.017685680744574248
Epoch #88: loss=0.01823348767154429
Epoch #89: loss=0.013330526215680974
Epoch #90: loss=0.01924364201720087
Epoch #91: loss=0.01367236527260999
Epoch #92: loss=0.015584716389131316
Epoch #93: loss=0.013695928063374774
Epoch #94: loss=0.013019110557763534
Epoch #95: loss=0.01829780966418327
Epoch #96: loss=0.011287826110495726
Epoch #97: loss=0.020422570279118157
Epoch #98: loss=0.013462614942744205
Epoch #99: loss=0.016532365992149457
Epoch #100: loss=0.015357793786476222
Epoch #101: loss=0.014003025225439976
Epoch #102: loss=0.016445159760384017
Epoch #103: loss=0.01641868164615343
Epoch #104: loss=0.012399437888422207
Epoch #105: loss=0.011563087134924117
Epoch #106: loss=0.013840824764086808
Epoch #107: loss=0.013323422327882523
Epoch #108: loss=0.01683227088348496
Epoch #109: loss=0.012478432431805622
Epoch #110: loss=0.01894399450635762
Epoch #111: loss=0.011395212469078176
Epoch #112: loss=0.0166565994963018
Epoch #113: loss=0.015028577697115525
Epoch #114: loss=0.010633096191633594
Epoch #115: loss=0.011140693869361002
Epoch #116: loss=0.013862943994461462
Epoch #117: loss=0.014574636092536751
Epoch #118: loss=0.011582162078207633
Epoch #119: loss=0.010897787851256639
Epoch #120: loss=0.024343028429145146
Epoch #121: loss=0.016109424503186955
Epoch #122: loss=0.010631645246591537
Epoch #123: loss=0.014802222864887355
Epoch #124: loss=0.012421723794506697
Epoch #125: loss=0.012994324419084062
Epoch #126: loss=0.012148829067074176
Epoch #127: loss=0.01826579037325469
Epoch #128: loss=0.014613861092958154
Epoch #129: loss=0.009416151669957074
Epoch #130: loss=0.012740779024868677
Epoch #131: loss=0.016494806695306948
Epoch #132: loss=0.012158897414468501
Epoch #133: loss=0.010534666869265427
Epoch #134: loss=0.013104376564248947
Epoch #135: loss=0.0181394373321831
Epoch #136: loss=0.009740712003717455
Epoch #137: loss=0.012804900907931481
Epoch #138: loss=0.009593920707178702
Epoch #139: loss=0.011258774683151606
Epoch #140: loss=0.013669144472257025
Epoch #141: loss=0.013449343089988993
Epoch #142: loss=0.01046183528072542
Epoch #143: loss=0.010392250133143668
Epoch #144: loss=0.011502645126465283
Epoch #145: loss=0.011806389015588928
Epoch #146: loss=0.011709843913922362
Epoch #147: loss=0.014879077963670037
Epoch #148: loss=0.009646965135859668
Epoch #149: loss=0.01753859637512493
Epoch #150: loss=0.016503580573211423
Epoch #151: loss=0.013160738460447166
Epoch #152: loss=0.017261122287131895
Epoch #153: loss=0.011884535157612204
Epoch #154: loss=0.00881469376393966
Epoch #155: loss=0.011993159860956318
Epoch #156: loss=0.013161167539477162
Epoch #157: loss=0.011781694735196553
Epoch #158: loss=0.010995156458490418
Epoch #159: loss=0.009437854770742415
Epoch #160: loss=0.011033575873965435
Epoch #161: loss=0.013960139879509472
Epoch #162: loss=0.013165822755970665
Epoch #163: loss=0.013800853200078608
Epoch #164: loss=0.009819243780378954
Epoch #165: loss=0.016161187986317264
Epoch #166: loss=0.009670049037405303
Epoch #167: loss=0.016371339285534813
Epoch #168: loss=0.010213213718054103
Epoch #169: loss=0.012794960784958676
Epoch #170: loss=0.012200046133431088
Epoch #171: loss=0.009925594023553896
Epoch #172: loss=0.011766134217300078
Epoch #173: loss=0.013907476560686695
Epoch #174: loss=0.010423250672284369
Epoch #175: loss=0.010924354234693873
Epoch #176: loss=0.017776287939953728
Epoch #177: loss=0.009254353563360062
Epoch #178: loss=0.012794896636244616
Epoch #179: loss=0.010505603647683841
Epoch #180: loss=0.012626723077898954
Epoch #181: loss=0.006831189198579507
Epoch #182: loss=0.013069344954859799
Epoch #183: loss=0.01469667040539501
Epoch #184: loss=0.0087969492276767
Epoch #185: loss=0.011778410762611423
Epoch #186: loss=0.007581664355255559
Epoch #187: loss=0.008915474118524273
Epoch #188: loss=0.016088493256286147
Epoch #189: loss=0.01605119638538378
Epoch #190: loss=0.008605067991167772
Epoch #191: loss=0.012487631126768301
Epoch #192: loss=0.009756971133226638
Epoch #193: loss=0.008902604002767017
Epoch #194: loss=0.022290614801254167
Epoch #195: loss=0.009051283987561203
Epoch #196: loss=0.011258809467352183
Epoch #197: loss=0.008367963783251824
Epoch #198: loss=0.013500923089049108
Epoch #199: loss=0.01086340300075989
Epoch #200: loss=0.007803672357897042
Epoch #201: loss=0.012472877888993844
Epoch #202: loss=0.010810852016353149
Epoch #203: loss=0.00860326535176375
Epoch #204: loss=0.015510746692541169
Epoch #205: loss=0.010046446612858664
Epoch #206: loss=0.012555286977537949
Epoch #207: loss=0.0108799648993935
Epoch #208: loss=0.010533630167338976
Epoch #209: loss=0.009004511518135585
Epoch #210: loss=0.013178980431679699
Epoch #211: loss=0.01002260107920985
Epoch #212: loss=0.011742044333917298
Epoch #213: loss=0.009873115994692356
Epoch #214: loss=0.010795853084368619
Epoch #215: loss=0.008672933664177984
Epoch #216: loss=0.011931128561662408
Epoch #217: loss=0.007870229181140463
Epoch #218: loss=0.009899400342538459
Epoch #219: loss=0.011932804864000552
Epoch #220: loss=0.014035662283615798
Epoch #221: loss=0.0070606031811695
Epoch #222: loss=0.00948385192086779
Epoch #223: loss=0.012571632978506386
Epoch #224: loss=0.020772936348173576
Epoch #225: loss=0.009641626421575133
Epoch #226: loss=0.01036593900896715
Epoch #227: loss=0.008909123042408523
Epoch #228: loss=0.008832873222112392
Epoch #229: loss=0.012225112328537104
Epoch #230: loss=0.011302089156259184
Epoch #231: loss=0.009462338093440619
Epoch #232: loss=0.011448114320788533
Epoch #233: loss=0.008199769639383686
Epoch #234: loss=0.012305416420812109
Epoch #235: loss=0.012721036970001952
Epoch #236: loss=0.008048446791466822
Epoch #237: loss=0.014165547438588843
Epoch #238: loss=0.007852565280232713
Epoch #239: loss=0.01121489738746427
Epoch #240: loss=0.010393283871558702
Epoch #241: loss=0.008938910721159826
Epoch #242: loss=0.014127032876485859
Epoch #243: loss=0.011727880149554224
Epoch #244: loss=0.004528684281869755
Epoch #245: loss=0.011700696656564051
Epoch #246: loss=0.009651894785991533
Epoch #247: loss=0.010572682338190949
Epoch #248: loss=0.008649384724121283
Epoch #249: loss=0.013296136684432483

Training time: 3:35:30.736506

Finished.
n2one setting etth2_ettm1_ettm2_traffic -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_ettm2_traffic_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_ettm1_ettm2_traffic', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.07787e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.78474e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.48687e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.07787e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.41616606703130915, 'MAE': 0.4574960482518354}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm1_ettm2_traffic -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_ettm2_traffic_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_ettm1_ettm2_traffic', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.12986e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.35478e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.12986e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.478638095128764, 'MAE': 0.5152654126578229}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm1_ettm2_traffic -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_ettm2_traffic_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_ettm1_ettm2_traffic', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.13433e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.22300918366378095, 'MAE': 0.32068812267453045}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm1_ettm2_weather', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm1_ettm2_weather_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=4.3056383089585735
Epoch #1: loss=2.3352721734480424
Epoch #2: loss=2.255379301851446
Epoch #3: loss=1.9235793482173573
Epoch #4: loss=1.6115502899343317
Epoch #5: loss=1.5347378232262352
Epoch #6: loss=1.394372775337913
Epoch #7: loss=1.3035686904733832
Epoch #8: loss=1.2490298043597827
Epoch #9: loss=1.1609566786072472
Epoch #10: loss=1.0002564961260014
Epoch #11: loss=1.0610038432207975
Epoch #12: loss=0.9818337527188388
Epoch #13: loss=0.8805563449859619
Epoch #14: loss=0.8045364238999106
Epoch #15: loss=0.8247920513153076
Epoch #16: loss=0.8578742449933833
Epoch #17: loss=0.7281032172116366
Epoch #18: loss=0.7596580494533886
Epoch #19: loss=0.6775433096018705
Epoch #20: loss=0.737349700385874
Epoch #21: loss=0.6979558375748721
Epoch #22: loss=0.7110023406418887
Epoch #23: loss=0.8064521085132252
Epoch #24: loss=0.7094918180595745
Epoch #25: loss=0.7099337122657082
Epoch #26: loss=0.5673153535886244
Epoch #27: loss=0.6784539493647489
Epoch #28: loss=0.5198217733339829
Epoch #29: loss=0.5851353119720112
Epoch #30: loss=0.5938130134885962
Epoch #31: loss=0.526623045314442
Epoch #32: loss=0.500407466021451
Epoch #33: loss=0.4628643816167658
Epoch #34: loss=0.47990164323286577
Epoch #35: loss=0.5275601159442554
Epoch #36: loss=0.5445803783156655
Epoch #37: loss=0.4858775718645616
Epoch #38: loss=0.5214626296000047
Epoch #39: loss=0.46162880008870905
Epoch #40: loss=0.43583267656239594
Epoch #41: loss=0.4610050412741574
Epoch #42: loss=0.4025691121816635
Epoch #43: loss=0.35994053130800074
Epoch #44: loss=0.4386080945079977
Epoch #45: loss=0.39449229104952377
Epoch #46: loss=0.4084657346660441
Epoch #47: loss=0.4641884603283622
Epoch #48: loss=0.37750991420312363
Epoch #49: loss=0.35891661129214547
Epoch #50: loss=0.37160562331026253
Epoch #51: loss=0.34299479750069706
Epoch #52: loss=0.35565850843082775
Epoch #53: loss=0.3011244532736865
Epoch #54: loss=0.3631103664636612
Epoch #55: loss=0.34698482670567254
Epoch #56: loss=0.31041814603588797
Epoch #57: loss=0.2958476803519509
Epoch #58: loss=0.23891367641362277
Epoch #59: loss=0.27127910188653254
Epoch #60: loss=0.24873678088188172
Epoch #61: loss=0.23084339228543369
Epoch #62: loss=0.2544913875785741
Epoch #63: loss=0.23304240188815378
Epoch #64: loss=0.2075606186281551
Epoch #65: loss=0.23109879127957605
Epoch #66: loss=0.26588755453174767
Epoch #67: loss=0.2366241772066463
Epoch #68: loss=0.19666347896510905
Epoch #69: loss=0.2058312170884826
Epoch #70: loss=0.2350408298048106
Epoch #71: loss=0.2093764282085679
Epoch #72: loss=0.21521432047540492
Epoch #73: loss=0.22375574978915128
Epoch #74: loss=0.2032258959656412
Epoch #75: loss=0.18851018737662922
Epoch #76: loss=0.17135928178375417
Epoch #77: loss=0.20125903534618292
Epoch #78: loss=0.17616254606030204
Epoch #79: loss=0.16012427427551962
Epoch #80: loss=0.19297051429748535
Epoch #81: loss=0.1816830733960325
Epoch #82: loss=0.19866133935072205
Epoch #83: loss=0.1909374591301788
Epoch #84: loss=0.16518631557171995
Epoch #85: loss=0.15632967664436861
Epoch #86: loss=0.2514716736972332
Epoch #87: loss=0.16348149254918098
Epoch #88: loss=0.1314968701113354
Epoch #89: loss=0.13478628762743688
Epoch #90: loss=0.1564847928556529
Epoch #91: loss=0.2031661110845479
Epoch #92: loss=0.12041856754909862
Epoch #93: loss=0.1261640067127618
Epoch #94: loss=0.12140348021957008
Epoch #95: loss=0.1634463488378308
Epoch #96: loss=0.15187491110780021
Epoch #97: loss=0.14444899765605276
Epoch #98: loss=0.13746499967846004
Epoch #99: loss=0.1693466080860658
Epoch #100: loss=0.1478871557184241
Epoch #101: loss=0.09860011586411432
Epoch #102: loss=0.11959438269788569
Epoch #103: loss=0.16734380322423847
Epoch #104: loss=0.14939312819730152
Epoch #105: loss=0.13753857900473204
Epoch #106: loss=0.09793784960427067
Epoch #107: loss=0.13066545907746663
Epoch #108: loss=0.1481090645898472
Epoch #109: loss=0.16345415501431984
Epoch #110: loss=0.10751247439872134
Epoch #111: loss=0.10262405452403155
Epoch #112: loss=0.10864426371726123
Epoch #113: loss=0.11907512061297894
Epoch #114: loss=0.120143173025413
Epoch #115: loss=0.5988021063872359
Epoch #116: loss=0.2739599537443031
Epoch #117: loss=0.18713060610673643
Epoch #118: loss=0.12548905336721378
Epoch #119: loss=0.174640567837791
Epoch #120: loss=0.12091825912621888
Epoch #121: loss=0.10711267614229159
Epoch #122: loss=0.11515344811434096
Epoch #123: loss=0.09168705547397787
Epoch #124: loss=0.12443466813049534
Epoch #125: loss=0.09539499303156679
Epoch #126: loss=0.13966386572203854
Epoch #127: loss=0.11932364932515405
Epoch #128: loss=0.08595725511285392
Epoch #129: loss=0.09416231546889652
Epoch #130: loss=0.08965757851573554
Epoch #131: loss=0.08612002747302705
Epoch #132: loss=0.14285653965039688
Epoch #133: loss=0.11130867634307254
Epoch #134: loss=0.116402151604945
Epoch #135: loss=0.11299048618159512
Epoch #136: loss=0.10934875847941095
Epoch #137: loss=0.10300055779516697
Epoch #138: loss=0.09416391253471375
Epoch #139: loss=0.08189762033183466
Epoch #140: loss=0.0656014115803621
Epoch #141: loss=0.08176785263825546
Epoch #142: loss=0.0693693381818858
Epoch #143: loss=0.07736484631896019
Epoch #144: loss=0.08256203181702983
Epoch #145: loss=0.06398923027921807
Epoch #146: loss=0.067555431174961
Epoch #147: loss=0.07744255797429518
Epoch #148: loss=0.0862863475118171
Epoch #149: loss=0.06693512150509791
Epoch #150: loss=0.062493712844496424
Epoch #151: loss=0.06671999371187254
Epoch #152: loss=0.07865829757330092
Epoch #153: loss=0.09722072477029128
Epoch #154: loss=0.09687828255647962
Epoch #155: loss=0.06524282431399281
Epoch #156: loss=0.09087193750522353
Epoch #157: loss=0.07315052304078232
Epoch #158: loss=0.05534726709804751
Epoch #159: loss=0.07024984855882146
Epoch #160: loss=0.10918629724871029
Epoch #161: loss=0.09440893962640654
Epoch #162: loss=0.09689524502239444
Epoch #163: loss=0.10663323002782735
Epoch #164: loss=0.0918081519278613
Epoch #165: loss=0.08228066489100457
Epoch #166: loss=0.060170376097614116
Epoch #167: loss=0.06492798065936023
Epoch #168: loss=0.060431507670066574
Epoch #169: loss=0.06798306176946922
Epoch #170: loss=0.0644032427871769
Epoch #171: loss=0.05292537481608716
Epoch #172: loss=0.05794292615557259
Epoch #173: loss=0.13826519951901653
Epoch #174: loss=0.07700926292348992
Epoch #175: loss=0.07682142687792128
Epoch #176: loss=0.07531193977391178
Epoch #177: loss=0.07754409259015864
Epoch #178: loss=0.08444178945977579
Epoch #179: loss=0.056701611558144745
Epoch #180: loss=0.08196210918778724
Epoch #181: loss=0.08604348030957308
Epoch #182: loss=0.06996712989427827
Epoch #183: loss=0.07536038937555119
Epoch #184: loss=0.09864708779549057
Epoch #185: loss=0.08983227420936932
Epoch #186: loss=0.08595624251121825
Epoch #187: loss=0.10285981197587468
Epoch #188: loss=0.05731625450267033
Epoch #189: loss=0.05921837772158059
Epoch #190: loss=0.06282373312860727
Epoch #191: loss=0.06711846122687513
Epoch #192: loss=0.06161219972101125
Epoch #193: loss=0.09692002025178888
Epoch #194: loss=0.058552243712950834
Epoch #195: loss=0.05928634222258221
Epoch #196: loss=0.08415366959842768
Epoch #197: loss=0.07478503810072487
Epoch #198: loss=0.0658867400478233
Epoch #199: loss=0.06468894661150196
Epoch #200: loss=0.048019463204863395
Epoch #201: loss=0.04819311100820249
Epoch #202: loss=0.12642311418259686
Epoch #203: loss=0.061306540210815996
Epoch #204: loss=0.04392894366756082
Epoch #205: loss=0.07007168704135851
Epoch #206: loss=0.04872273653745651
Epoch #207: loss=0.052926900212398986
Epoch #208: loss=0.048035103726116093
Epoch #209: loss=0.09105238042433153
Epoch #210: loss=0.09526350701397115
Epoch #211: loss=0.06048260280354457
Epoch #212: loss=0.051085205901075494
Epoch #213: loss=0.05724356302314184
Epoch #214: loss=0.05410094565965912
Epoch #215: loss=0.058123359693722294
Epoch #216: loss=0.058921127072112126
Epoch #217: loss=0.060081947053020654
Epoch #218: loss=0.047353853175247256
Epoch #219: loss=0.08465834458104589
Epoch #220: loss=0.05380668027157133
Epoch #221: loss=0.04364079118452289
Epoch #222: loss=0.051378502688285976
Epoch #223: loss=0.05581496126780456
Epoch #224: loss=0.043674744843420654
Epoch #225: loss=0.04260720300742171
Epoch #226: loss=0.03930362156507644
Epoch #227: loss=0.05113422006199306
Epoch #228: loss=0.035960583795200694
Epoch #229: loss=0.1068887482481924
Epoch #230: loss=0.07221227664161813
Epoch #231: loss=0.11631745342165231
Epoch #232: loss=0.06475878454406153
Epoch #233: loss=0.04749260177327828
Epoch #234: loss=0.04097906202924523
Epoch #235: loss=0.04694367614151402
Epoch #236: loss=0.040878089669753204
Epoch #237: loss=0.052120688879354435
Epoch #238: loss=0.044266592999073595
Epoch #239: loss=0.05189737206832929
Epoch #240: loss=0.06742857164618644
Epoch #241: loss=0.09138261265206066
Epoch #242: loss=0.06280842352319847
Epoch #243: loss=0.04858051345429637
Epoch #244: loss=0.04611388473686847
Epoch #245: loss=0.06619515606964177
Epoch #246: loss=0.03325228473510255
Epoch #247: loss=0.04398705101656643
Epoch #248: loss=0.05450634617697109
Epoch #249: loss=0.20996337971565399

Training time: 0:19:21.877589

Finished.
n2one setting etth2_ettm1_ettm2_weather -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_ettm2_weather_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_ettm1_ettm2_weather', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.33755e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.45204e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.33755e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.36842469099078196, 'MAE': 0.4306302754449484}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm1_ettm2_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_ettm2_weather_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_ettm1_ettm2_weather', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.36864e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.20653930179792265, 'MAE': 0.3106199966172772}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm1_ettm2_exchange', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm1_ettm2_exchange_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=3.797017883610081
Epoch #1: loss=2.2788514446567847
Epoch #2: loss=1.9768855088465922
Epoch #3: loss=1.7910600224056759
Epoch #4: loss=1.599722688262527
Epoch #5: loss=1.5246943170959886
Epoch #6: loss=1.487004280090332
Epoch #7: loss=1.3557770542196326
Epoch #8: loss=1.1943405045045388
Epoch #9: loss=1.1910863035434
Epoch #10: loss=1.085171233963322
Epoch #11: loss=1.0730247578105412
Epoch #12: loss=1.0422492897188342
Epoch #13: loss=0.9743519215970426
Epoch #14: loss=0.9330357248718674
Epoch #15: loss=0.8919272455009254
Epoch #16: loss=0.8561720751427315
Epoch #17: loss=0.8460199720150715
Epoch #18: loss=0.8192952033635732
Epoch #19: loss=0.8017017809120385
Epoch #20: loss=0.7489867588958224
Epoch #21: loss=0.6635959543086387
Epoch #22: loss=0.7424311960065687
Epoch #23: loss=0.663173491890366
Epoch #24: loss=0.6217958065303596
Epoch #25: loss=0.678940707767332
Epoch #26: loss=0.6940333625754794
Epoch #27: loss=0.776963672927908
Epoch #28: loss=0.761771130400735
Epoch #29: loss=0.6067266713928532
Epoch #30: loss=0.5796064380052928
Epoch #31: loss=0.5640116897789208
Epoch #32: loss=0.5421071076715315
Epoch #33: loss=0.5208917848161749
Epoch #34: loss=0.5675559889625859
Epoch #35: loss=0.6155351617851773
Epoch #36: loss=0.6012494958735801
Epoch #37: loss=0.6452968015864089
Epoch #38: loss=0.5661202781909221
Epoch #39: loss=0.5272069025684047
Epoch #40: loss=0.6220530239311425
Epoch #41: loss=0.5988424976129789
Epoch #42: loss=0.5196284683975013
Epoch #43: loss=0.4695317495513607
Epoch #44: loss=0.4854404032230377
Epoch #45: loss=0.48624643602886714
Epoch #46: loss=0.46250362372076187
Epoch #47: loss=0.4648658480193164
Epoch #48: loss=0.6154329438467283
Epoch #49: loss=0.548943617053934
Epoch #50: loss=0.505001295257259
Epoch #51: loss=0.5017608017534823
Epoch #52: loss=0.481763556599617
Epoch #53: loss=0.44521183661512426
Epoch #54: loss=0.4366210103034973
Epoch #55: loss=0.3724324815982097
Epoch #56: loss=0.3586533154184754
Epoch #57: loss=0.34117911514398214
Epoch #58: loss=0.31688704603427165
Epoch #59: loss=0.3682862612846735
Epoch #60: loss=0.39932882302516215
Epoch #61: loss=0.3198017711574967
Epoch #62: loss=0.41679121231710586
Epoch #63: loss=0.30695966611037384
Epoch #64: loss=0.3384861362141532
Epoch #65: loss=0.35754343222927404
Epoch #66: loss=0.30536092737236536
Epoch #67: loss=0.3678130078557375
Epoch #68: loss=0.3088423331847062
Epoch #69: loss=0.3314691216156289
Epoch #70: loss=0.2881118916981929
Epoch #71: loss=0.38428252109804667
Epoch #72: loss=0.31214962376130595
Epoch #73: loss=0.29751025986027074
Epoch #74: loss=0.2909073316164919
Epoch #75: loss=0.3382257609753995
Epoch #76: loss=0.32661629427929184
Epoch #77: loss=0.3047078318289808
Epoch #78: loss=0.4253502222331795
Epoch #79: loss=0.35900527601306503
Epoch #80: loss=0.3446499936886736
Epoch #81: loss=0.24279237800353282
Epoch #82: loss=0.3142746060683921
Epoch #83: loss=0.20322167953929385
Epoch #84: loss=0.21285022231372627
Epoch #85: loss=0.20373806840664632
Epoch #86: loss=0.2924017114816485
Epoch #87: loss=0.29802934261592656
Epoch #88: loss=0.2283333084873251
Epoch #89: loss=0.260483037579704
Epoch #90: loss=0.22781608142965548
Epoch #91: loss=0.20661275733161616
Epoch #92: loss=0.18128024494728526
Epoch #93: loss=0.17213773848237218
Epoch #94: loss=0.16664116749086896
Epoch #95: loss=0.28774379848225695
Epoch #96: loss=0.16253552032080856
Epoch #97: loss=0.2060531254958462
Epoch #98: loss=0.2735863450813938
Epoch #99: loss=0.32300445296474406
Epoch #100: loss=0.19842506441715602
Epoch #101: loss=0.28141304155862007
Epoch #102: loss=0.2055903071084538
Epoch #103: loss=0.19753459176501711
Epoch #104: loss=0.18301363631680206
Epoch #105: loss=0.20350158617303177
Epoch #106: loss=0.15575451756248604
Epoch #107: loss=0.13782010076416507
Epoch #108: loss=0.14721799339797045
Epoch #109: loss=0.11283334973897483
Epoch #110: loss=0.11959759745042066
Epoch #111: loss=0.17362067556461772
Epoch #112: loss=0.24126833747770335
Epoch #113: loss=0.1973976474758741
Epoch #114: loss=0.19105508651685071
Epoch #115: loss=0.1989283375442028
Epoch #116: loss=0.2126579645114976
Epoch #117: loss=0.17576735849316055
Epoch #118: loss=0.15810081423134417
Epoch #119: loss=0.11228410688203734
Epoch #120: loss=0.14810472102584066
Epoch #121: loss=0.21571315477627354
Epoch #122: loss=0.14728384666346214
Epoch #123: loss=0.16281960471659093
Epoch #124: loss=0.1438177557712471
Epoch #125: loss=0.1371588023832521
Epoch #126: loss=0.1503192355503907
Epoch #127: loss=0.1373354903850201
Epoch #128: loss=0.16422521499161785
Epoch #129: loss=0.26033989450818784
Epoch #130: loss=0.2736670158400729
Epoch #131: loss=0.1879186769192283
Epoch #132: loss=0.1416237198219106
Epoch #133: loss=0.19305813896494942
Epoch #134: loss=0.15717650345853856
Epoch #135: loss=0.15042741757792397
Epoch #136: loss=0.1824657571678226
Epoch #137: loss=0.14382792037685174
Epoch #138: loss=0.13951313999053594
Epoch #139: loss=0.23820765553092635
Epoch #140: loss=0.23033670547443466
Epoch #141: loss=0.14291556139250058
Epoch #142: loss=0.21221770612976035
Epoch #143: loss=0.12656322675379547
Epoch #144: loss=0.1188429705798626
Epoch #145: loss=0.160251801078384
Epoch #146: loss=0.16568083557728175
Epoch #147: loss=0.14791477521931803
Epoch #148: loss=0.09587706736213453
Epoch #149: loss=0.14121880528290529
Epoch #150: loss=0.11912768077407335
Epoch #151: loss=0.125743763873706
Epoch #152: loss=0.12253821943257306
Epoch #153: loss=0.16427901699333577
Epoch #154: loss=0.14801198234026497
Epoch #155: loss=0.19998520899664712
Epoch #156: loss=0.1560633143762479
Epoch #157: loss=0.16542378621729645
Epoch #158: loss=0.28746044766661283
Epoch #159: loss=0.17619542284189044
Epoch #160: loss=0.19011844966459918
Epoch #161: loss=0.15850710934279738
Epoch #162: loss=0.15800948224559025
Epoch #163: loss=0.11617312791782457
Epoch #164: loss=0.134054601897259
Epoch #165: loss=0.1224876017989339
Epoch #166: loss=0.10279312573776052
Epoch #167: loss=0.09011055425916975
Epoch #168: loss=0.1136293083781729
Epoch #169: loss=0.10862135987829517
Epoch #170: loss=0.09768063126987703
Epoch #171: loss=0.10930461949996047
Epoch #172: loss=0.1338633156910136
Epoch #173: loss=0.1158947001236516
Epoch #174: loss=0.14598737863471378
Epoch #175: loss=0.11883099513078058
Epoch #176: loss=0.10032962131741885
Epoch #177: loss=0.09009179777490932
Epoch #178: loss=0.08642097041514274
Epoch #179: loss=0.08047138894530567
Epoch #180: loss=0.08273221340936583
Epoch #181: loss=0.0873764996995797
Epoch #182: loss=0.11380881969691128
Epoch #183: loss=0.12284260336309671
Epoch #184: loss=0.1119462951413683
Epoch #185: loss=0.15260122706358498
Epoch #186: loss=0.11226463584682426
Epoch #187: loss=0.1548976622823928
Epoch #188: loss=0.13688544984403495
Epoch #189: loss=0.13548150618334073
Epoch #190: loss=0.13674349800960436
Epoch #191: loss=0.1275510061532259
Epoch #192: loss=0.0767328426795634
Epoch #193: loss=0.08709104366701197
Epoch #194: loss=0.08835952046855881
Epoch #195: loss=0.09043134839550869
Epoch #196: loss=0.09895265948128056
Epoch #197: loss=0.07844377316635202
Epoch #198: loss=0.07546574305239562
Epoch #199: loss=0.097415208464136
Epoch #200: loss=0.11981127574737813
Epoch #201: loss=0.12421064514264062
Epoch #202: loss=0.09150636493152864
Epoch #203: loss=0.10644552801307794
Epoch #204: loss=0.13703332257431908
Epoch #205: loss=0.11500152291075603
Epoch #206: loss=0.11204923470378728
Epoch #207: loss=0.12427075237438485
Epoch #208: loss=0.09836204032841567
Epoch #209: loss=0.09471212329997404
Epoch #210: loss=0.08436079237710785
Epoch #211: loss=0.07683364087967454
Epoch #212: loss=0.10585082131060394
Epoch #213: loss=0.07448683676586763
Epoch #214: loss=0.14535456513230866
Epoch #215: loss=0.11637536260123188
Epoch #216: loss=0.08201546977097923
Epoch #217: loss=0.10419049592235603
Epoch #218: loss=0.0953057644183974
Epoch #219: loss=0.20310304019398787
Epoch #220: loss=0.1479126222784052
Epoch #221: loss=0.14435397919166731
Epoch #222: loss=0.13415815303655895
Epoch #223: loss=0.08819648147736853
Epoch #224: loss=0.08252313828750237
Epoch #225: loss=0.10705655211633122
Epoch #226: loss=0.09665412584168685
Epoch #227: loss=0.10171348256738605
Epoch #228: loss=0.10887721213637977
Epoch #229: loss=0.18538037974488092
Epoch #230: loss=0.15572510000217604
Epoch #231: loss=0.10928895107999041
Epoch #232: loss=0.11792342689492412
Epoch #233: loss=0.09767359593329397
Epoch #234: loss=0.07818462317054337
Epoch #235: loss=0.09057430132619433
Epoch #236: loss=0.1252245082444436
Epoch #237: loss=0.2564835853975367
Epoch #238: loss=0.14523393237912977
Epoch #239: loss=0.15275142860372323
Epoch #240: loss=0.1576988286263234
Epoch #241: loss=0.19943046635268508
Epoch #242: loss=0.21902585819967696
Epoch #243: loss=0.14558077054853374
Epoch #244: loss=0.10137757971077352
Epoch #245: loss=0.1586201707706661
Epoch #246: loss=0.09147732719980381
Epoch #247: loss=0.09971178592358892
Epoch #248: loss=0.06656918853420664
Epoch #249: loss=0.09268246961103098

Training time: 0:11:21.698662

Finished.
n2one setting etth2_ettm1_ettm2_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_ettm2_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_ettm1_ettm2_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.24893e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.42634e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.95826e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.24893e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3772937669106009, 'MAE': 0.43536710877702606}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm1_ettm2_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_ettm2_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_ettm1_ettm2_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.36082e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.66898e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.42234538124967536, 'MAE': 0.4650823068556742}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm1_electricity_traffic', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm1_electricity_traffic_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.8211531667015535
Epoch #1: loss=0.2827065860252396
Epoch #2: loss=0.18343359497464964
Epoch #3: loss=0.13515186646052146
Epoch #4: loss=0.11927813146849606
Epoch #5: loss=0.09910915319503073
Epoch #6: loss=0.07951774497087626
Epoch #7: loss=0.0686521126394727
Epoch #8: loss=0.06108507176986791
Epoch #9: loss=0.04928761950696351
Epoch #10: loss=0.04561570398435834
Epoch #11: loss=0.0480226029176265
Epoch #12: loss=0.04036198639493904
Epoch #13: loss=0.04729459157696678
Epoch #14: loss=0.03574658687273777
Epoch #15: loss=0.03419856680654064
Epoch #16: loss=0.04162335170174698
Epoch #17: loss=0.030442219922845588
Epoch #18: loss=0.030530681605059205
Epoch #19: loss=0.02758323813697089
Epoch #20: loss=0.034590247897628996
Epoch #21: loss=0.03156401138003608
Epoch #22: loss=0.026428974390839872
Epoch #23: loss=0.025815491396104055
Epoch #24: loss=0.027915648574674105
Epoch #25: loss=0.022648631900556302
Epoch #26: loss=0.019591675899813508
Epoch #27: loss=0.02400023497717275
Epoch #28: loss=0.022394779202242154
Epoch #29: loss=0.025768820069021516
Epoch #30: loss=0.018660757471916836
Epoch #31: loss=0.021250552754849633
Epoch #32: loss=0.021613662830688878
Epoch #33: loss=0.018682128549574777
Epoch #34: loss=0.023735286644582392
Epoch #35: loss=0.019083205671629307
Epoch #36: loss=0.017288181104725978
Epoch #37: loss=0.024846482241284305
Epoch #38: loss=0.020631778885312917
Epoch #39: loss=0.015613631358829448
Epoch #40: loss=0.018765054273164734
Epoch #41: loss=0.016454917415388147
Epoch #42: loss=0.01950233702972507
Epoch #43: loss=0.01646914919633298
Epoch #44: loss=0.018184095979418117
Epoch #45: loss=0.01628171945418515
Epoch #46: loss=0.021452523638834736
Epoch #47: loss=0.017988387432758178
Epoch #48: loss=0.019642031422392042
Epoch #49: loss=0.014810499206969908
Epoch #50: loss=0.017293343721545045
Epoch #51: loss=0.016630883068717718
Epoch #52: loss=0.016316443569881635
Epoch #53: loss=0.016731718969137815
Epoch #54: loss=0.01295078223555963
Epoch #55: loss=0.023414474077257937
Epoch #56: loss=0.01945467694330713
Epoch #57: loss=0.016667605843322296
Epoch #58: loss=0.027533912162346297
Epoch #59: loss=0.011354825984477046
Epoch #60: loss=0.014639937124028182
Epoch #61: loss=0.021043413295478427
Epoch #62: loss=0.012655640319541297
Epoch #63: loss=0.012615740776469514
Epoch #64: loss=0.020921096093294487
Epoch #65: loss=0.017129147280719858
Epoch #66: loss=0.015065139384151627
Epoch #67: loss=0.016120797394741704
Epoch #68: loss=0.013674996312342036
Epoch #69: loss=0.011277422256069645
Epoch #70: loss=0.011550315612306036
Epoch #71: loss=0.016214196963997767
Epoch #72: loss=0.01725578206726722
Epoch #73: loss=0.013250115854289734
Epoch #74: loss=0.01783355802501537
Epoch #75: loss=0.014455164417378364
Epoch #76: loss=0.015114783590090896
Epoch #77: loss=0.012793734719532641
Epoch #78: loss=0.017178319861025214
Epoch #79: loss=0.014783254890056323
Epoch #80: loss=0.017185502967727043
Epoch #81: loss=0.01154283141985041
Epoch #82: loss=0.013374790297036985
Epoch #83: loss=0.01678348623613961
Epoch #84: loss=0.011178579764187856
Epoch #85: loss=0.017605347926446354
Epoch #86: loss=0.011204340863316866
Epoch #87: loss=0.0142646367058326
Epoch #88: loss=0.013401920779249154
Epoch #89: loss=0.011707355492878888
Epoch #90: loss=0.009680467908713927
Epoch #91: loss=0.0168935039324321
Epoch #92: loss=0.01073440970826024
Epoch #93: loss=0.016710385480276438
Epoch #94: loss=0.01133765739640157
Epoch #95: loss=0.012053806882060453
Epoch #96: loss=0.011885890237867137
Epoch #97: loss=0.0171875513593624
Epoch #98: loss=0.010753958373022095
Epoch #99: loss=0.011189456910241377
Epoch #100: loss=0.013704115573075356
Epoch #101: loss=0.011017771476464265
Epoch #102: loss=0.012432479951060576
Epoch #103: loss=0.014325121085031627
Epoch #104: loss=0.012658361935881735
Epoch #105: loss=0.00855708304472764
Epoch #106: loss=0.015374911998150557
Epoch #107: loss=0.012016789836017954
Epoch #108: loss=0.011598888150763258
Epoch #109: loss=0.012469308109544752
Epoch #110: loss=0.012162721247177107
Epoch #111: loss=0.016579571827006066
Epoch #112: loss=0.01504730364374838
Epoch #113: loss=0.009969289880524604
Epoch #114: loss=0.011167412459182785
Epoch #115: loss=0.013767072512949181
Epoch #116: loss=0.01055262616204895
Epoch #117: loss=0.010943768222498934
Epoch #118: loss=0.012226194899570803
Epoch #119: loss=0.010960190115539361
Epoch #120: loss=0.011099130527459885
Epoch #121: loss=0.014313720552787552
Epoch #122: loss=0.008079201887416908
Epoch #123: loss=0.011129473727306957
Epoch #124: loss=0.01158668157597267
Epoch #125: loss=0.010024925381978791
Epoch #126: loss=0.01078906161057783
Epoch #127: loss=0.013572721939665194
Epoch #128: loss=0.010242016510173313
Epoch #129: loss=0.01756412084045243
Epoch #130: loss=0.008034785846169026
Epoch #131: loss=0.011157983794985192
Epoch #132: loss=0.010431889621999393
Epoch #133: loss=0.01053856218887123
Epoch #134: loss=0.006541929708078271
Epoch #135: loss=0.010032663814715497
Epoch #136: loss=0.011812375821149685
Epoch #137: loss=0.014602234925123646
Epoch #138: loss=0.009723875373898525
Epoch #139: loss=0.009845605753670907
Epoch #140: loss=0.010153429592541514
Epoch #141: loss=0.01465300583830179
Epoch #142: loss=0.009912735009119093
Epoch #143: loss=0.010971233936443113
Epoch #144: loss=0.01603161236197594
Epoch #145: loss=0.007873964104412235
Epoch #146: loss=0.0099504057927529
Epoch #147: loss=0.011270815708426248
Epoch #148: loss=0.01729061623234363
Epoch #149: loss=0.00912079813990096
Epoch #150: loss=0.010361659676308622
Epoch #151: loss=0.009167911037193478
Epoch #152: loss=0.013190009644278113
Epoch #153: loss=0.013133780462486084
Epoch #154: loss=0.007898974673767562
Epoch #155: loss=0.011451707959292786
Epoch #156: loss=0.010725677483735473
Epoch #157: loss=0.015056858067386457
Epoch #158: loss=0.008948145241823103
Epoch #159: loss=0.010537535000411595
Epoch #160: loss=0.010095444961514387
Epoch #161: loss=0.011784239786407203
Epoch #162: loss=0.03011120475184801
Epoch #163: loss=0.011513437110314
Epoch #164: loss=0.009966836861666443
Epoch #165: loss=0.008329239144821365
Epoch #166: loss=0.011594949086647648
Epoch #167: loss=0.008730049762700557
Epoch #168: loss=0.008441734858531195
Epoch #169: loss=0.01138675093339327
Epoch #170: loss=0.014552417870111608
Epoch #171: loss=0.008288497468590393
Epoch #172: loss=0.010932078165943182
Epoch #173: loss=0.008258048435426426
Epoch #174: loss=0.011805283195124633
Epoch #175: loss=0.010328011094047948
Epoch #176: loss=0.00877887090992756
Epoch #177: loss=0.012429004666227986
Epoch #178: loss=0.010198237433274769
Epoch #179: loss=0.01111508819609044
Epoch #180: loss=0.008883508504029103
Epoch #181: loss=0.004715885463109488
Epoch #182: loss=0.009537016091575595
Epoch #183: loss=0.008802239737553638
Epoch #184: loss=0.009241674170453937
Epoch #185: loss=0.026473446065623078
Epoch #186: loss=0.00842804487938315
Epoch #187: loss=0.008458151934215216
Epoch #188: loss=0.010404359297006357
Epoch #189: loss=0.008811570505502938
Epoch #190: loss=0.009242624045872314
Epoch #191: loss=0.008518282262578409
Epoch #192: loss=0.012437466590805444
Epoch #193: loss=0.011759863902469511
Epoch #194: loss=0.01260370226510114
Epoch #195: loss=0.010653625796511704
Epoch #196: loss=0.00876896684843402
Epoch #197: loss=0.008324098663767498
Epoch #198: loss=0.012275896796111508
Epoch #199: loss=0.00985634569199118
Epoch #200: loss=0.008080208955709121
Epoch #201: loss=0.008142535735553472
Epoch #202: loss=0.011192996346580367
Epoch #203: loss=0.012539803134231906
Epoch #204: loss=0.011578744591211727
Epoch #205: loss=0.00924456501323843
Epoch #206: loss=0.010766084371298454
Epoch #207: loss=0.010061306112713326
Epoch #208: loss=0.008489528130595983
Epoch #209: loss=0.008418836683710282
Epoch #210: loss=0.008920062714360839
Epoch #211: loss=0.00955909466124539
Epoch #212: loss=0.00933225787753114
Epoch #213: loss=0.012853456329428114
Epoch #214: loss=0.007010282884020111
Epoch #215: loss=0.0072609794215721035
Epoch #216: loss=0.009831121002873918
Epoch #217: loss=0.008317240627907726
Epoch #218: loss=0.018584915897982477
Epoch #219: loss=0.006006224443348936
Epoch #220: loss=0.014036000285328263
Epoch #221: loss=0.00681600522778851
Epoch #222: loss=0.011928513209113967
Epoch #223: loss=0.007022213786216923
Epoch #224: loss=0.01123543177130793
Epoch #225: loss=0.008480057436030678
Epoch #226: loss=0.012040023020577021
Epoch #227: loss=0.008643149546415702
Epoch #228: loss=0.008353653023934671
Epoch #229: loss=0.013072004759439742
Epoch #230: loss=0.008865965000694422
Epoch #231: loss=0.007205357672550194
Epoch #232: loss=0.008875692959241515
Epoch #233: loss=0.008307332721346239
Epoch #234: loss=0.00676197717055305
Epoch #235: loss=0.008785919582532567
Epoch #236: loss=0.009502927258803718
Epoch #237: loss=0.009825744306610946
Epoch #238: loss=0.0077931680617461235
Epoch #239: loss=0.022180197937672615
Epoch #240: loss=0.007721586531201157
Epoch #241: loss=0.007811361746876586
Epoch #242: loss=0.006745505058655898
Epoch #243: loss=0.009409897212952715
Epoch #244: loss=0.008475560756654383
Epoch #245: loss=0.00936268252485566
Epoch #246: loss=0.01340265844428162
Epoch #247: loss=0.0074104307373435265
Epoch #248: loss=0.0071151943222766715
Epoch #249: loss=0.007876985801058186

Training time: 5:01:08.244822

Finished.
n2one setting etth2_ettm1_electricity_traffic -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_electricity_traffic_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_ettm1_electricity_traffic', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.29124e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.99588e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.03872e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.29124e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3305383614127049, 'MAE': 0.4137495174277126}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm1_electricity_traffic -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_electricity_traffic_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_ettm1_electricity_traffic', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.90447e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.24539199330965958, 'MAE': 0.3385822899295274}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm1_electricity_weather', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm1_electricity_weather_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.6836731334255166
Epoch #1: loss=0.7258495327544539
Epoch #2: loss=0.5249865404138826
Epoch #3: loss=0.46087301001973346
Epoch #4: loss=0.3904120649376961
Epoch #5: loss=0.3451462845279746
Epoch #6: loss=0.29672377642295134
Epoch #7: loss=0.2590155305927747
Epoch #8: loss=0.23955846132889186
Epoch #9: loss=0.20557755278806164
Epoch #10: loss=0.19116402759331547
Epoch #11: loss=0.17495696100674263
Epoch #12: loss=0.17099186811749248
Epoch #13: loss=0.21747379180503218
Epoch #14: loss=0.18198604264283832
Epoch #15: loss=0.12705125346371574
Epoch #16: loss=0.11753862345055358
Epoch #17: loss=0.12484355816898281
Epoch #18: loss=0.12544521622563878
Epoch #19: loss=0.09483218396159067
Epoch #20: loss=0.13293490344020603
Epoch #21: loss=0.09334962082746094
Epoch #22: loss=0.08451088487540614
Epoch #23: loss=0.11445538425588445
Epoch #24: loss=0.07721811677137874
Epoch #25: loss=0.08058209187312894
Epoch #26: loss=0.07917132537097556
Epoch #27: loss=0.0958589999362418
Epoch #28: loss=0.07226846957808897
Epoch #29: loss=0.08240537042538189
Epoch #30: loss=0.07599626000817508
Epoch #31: loss=0.06305321801122125
Epoch #32: loss=0.061433496123358404
Epoch #33: loss=0.04999061428673872
Epoch #34: loss=0.0560212445509148
Epoch #35: loss=0.05200735739215392
Epoch #36: loss=0.05106588695963768
Epoch #37: loss=0.04720385639468999
Epoch #38: loss=0.05460481184330603
Epoch #39: loss=0.05574140667736734
Epoch #40: loss=0.06149136783963401
Epoch #41: loss=0.040629922064046746
Epoch #42: loss=0.043366673974677514
Epoch #43: loss=0.04445367777618031
Epoch #44: loss=0.03714057751389042
Epoch #45: loss=0.04308264269174574
Epoch #46: loss=0.04016806533789798
Epoch #47: loss=0.06919334944822404
Epoch #48: loss=0.07148526763313845
Epoch #49: loss=0.03627183123440673
Epoch #50: loss=0.053141489603607726
Epoch #51: loss=0.04579418169666235
Epoch #52: loss=0.03419847983471437
Epoch #53: loss=0.03170522312308368
Epoch #54: loss=0.0315744923835952
Epoch #55: loss=0.036566911580691704
Epoch #56: loss=0.038634146172042985
Epoch #57: loss=0.028286030517942082
Epoch #58: loss=0.02969618402198212
Epoch #59: loss=0.03169755929704653
Epoch #60: loss=0.04255456965901468
Epoch #61: loss=0.028283812587264263
Epoch #62: loss=0.02825657817988006
Epoch #63: loss=0.030515058365752537
Epoch #64: loss=0.028641746975864246
Epoch #65: loss=0.033381965572065485
Epoch #66: loss=0.03058453487991419
Epoch #67: loss=0.03157860858251073
Epoch #68: loss=0.028481695404250735
Epoch #69: loss=0.02703709322193714
Epoch #70: loss=0.0314469741759439
Epoch #71: loss=0.03017665931782749
Epoch #72: loss=0.023557970988921415
Epoch #73: loss=0.02257825773151923
Epoch #74: loss=0.021880666533331962
Epoch #75: loss=0.01733681917468035
Epoch #76: loss=0.02883172138747185
Epoch #77: loss=0.029193500381231002
Epoch #78: loss=0.02070094159411981
Epoch #79: loss=0.027865155454093515
Epoch #80: loss=0.031064255225905918
Epoch #81: loss=0.020282577514195533
Epoch #82: loss=0.025125625184800934
Epoch #83: loss=0.028849763467378456
Epoch #84: loss=0.0380850572646149
Epoch #85: loss=0.022655671346320273
Epoch #86: loss=0.025751929758244183
Epoch #87: loss=0.019363881583159714
Epoch #88: loss=0.030633401308744534
Epoch #89: loss=0.018490237040343145
Epoch #90: loss=0.06067802810862864
Epoch #91: loss=0.022321959901983813
Epoch #92: loss=0.020878355385423063
Epoch #93: loss=0.018737336131744088
Epoch #94: loss=0.018327259825389474
Epoch #95: loss=0.023320954468432967
Epoch #96: loss=0.01754539013913616
Epoch #97: loss=0.018153085222958956
Epoch #98: loss=0.02101868638220205
Epoch #99: loss=0.01879084453302474
Epoch #100: loss=0.01800029209180263
Epoch #101: loss=0.03280837371313868
Epoch #102: loss=0.01757480733826986
Epoch #103: loss=0.025043260613583945
Epoch #104: loss=0.025413826528349764
Epoch #105: loss=0.019847569322015784
Epoch #106: loss=0.02210774613856912
Epoch #107: loss=0.021933161168142336
Epoch #108: loss=0.021370670370030383
Epoch #109: loss=0.03877887742255802
Epoch #110: loss=0.037265137038576375
Epoch #111: loss=0.03603580198569657
Epoch #112: loss=0.04336000025999567
Epoch #113: loss=0.022939679834813084
Epoch #114: loss=0.01510676738841153
Epoch #115: loss=0.05311905744243158
Epoch #116: loss=0.018440807544090467
Epoch #117: loss=0.01532398100594722
Epoch #118: loss=0.014862770759277302
Epoch #119: loss=0.01789519664439156
Epoch #120: loss=0.02459198908740017
Epoch #121: loss=0.013233803630302571
Epoch #122: loss=0.0240633892711118
Epoch #123: loss=0.021144316341625908
Epoch #124: loss=0.02503401277656986
Epoch #125: loss=0.027989986667900715
Epoch #126: loss=0.016033568825693928
Epoch #127: loss=0.01797682256278365
Epoch #128: loss=0.01549152390312161
Epoch #129: loss=0.015449475648506761
Epoch #130: loss=0.01574890241425561
Epoch #131: loss=0.02414470004357959
Epoch #132: loss=0.022397285435757
Epoch #133: loss=0.018651147765802754
Epoch #134: loss=0.01959534555686357
Epoch #135: loss=0.025372295729076004
Epoch #136: loss=0.016406126623360873
Epoch #137: loss=0.01688449460716459
Epoch #138: loss=0.022172706525402833
Epoch #139: loss=0.02451350120157769
Epoch #140: loss=0.016294398690790756
Epoch #141: loss=0.01620827946861351
Epoch #142: loss=0.02259215212431864
Epoch #143: loss=0.03140920304632682
Epoch #144: loss=0.015823145896955458
Epoch #145: loss=0.01664734994139433
Epoch #146: loss=0.03695820405088965
Epoch #147: loss=0.02238666714322179
Epoch #148: loss=0.021480047824068555
Epoch #149: loss=0.0186528979295112
Epoch #150: loss=0.012026753322355296
Epoch #151: loss=0.018194839220545062
Epoch #152: loss=0.015715241743481323
Epoch #153: loss=0.01365140423207378
Epoch #154: loss=0.0167634877325227
Epoch #155: loss=0.020053760545832196
Epoch #156: loss=0.023320380169324167
Epoch #157: loss=0.017413720839867395
Epoch #158: loss=0.013300704467110337
Epoch #159: loss=0.014692764190641194
Epoch #160: loss=0.016232875495916232
Epoch #161: loss=0.015303384386679183
Epoch #162: loss=0.011442585629953251
Epoch #163: loss=0.010954375341311353
Epoch #164: loss=0.018803091914782123
Epoch #165: loss=0.015955897685688957
Epoch #166: loss=0.014382782903474386
Epoch #167: loss=0.019414450838677075
Epoch #168: loss=0.0167051138930431
Epoch #169: loss=0.015205821740498435
Epoch #170: loss=0.015618976042605936
Epoch #171: loss=0.015946317462040085
Epoch #172: loss=0.01160989000720342
Epoch #173: loss=0.016130792933407762
Epoch #174: loss=0.024686272237258517
Epoch #175: loss=0.016432137226076695
Epoch #176: loss=0.014145323343587759
Epoch #177: loss=0.014121168922020557
Epoch #178: loss=0.026286137596168237
Epoch #179: loss=0.017539366326144935
Epoch #180: loss=0.02321934702810959
Epoch #181: loss=0.017961730281280175
Epoch #182: loss=0.026708769713758095
Epoch #183: loss=0.017630868225377565
Epoch #184: loss=0.023444871427746466
Epoch #185: loss=0.0143682036642942
Epoch #186: loss=0.031045430670460457
Epoch #187: loss=0.01831991168405631
Epoch #188: loss=0.01978183532235761
Epoch #189: loss=0.010257186593682415
Epoch #190: loss=0.014706738350501488
Epoch #191: loss=0.016915393335910592
Epoch #192: loss=0.009008645346110738
Epoch #193: loss=0.013903966465843715
Epoch #194: loss=0.015010499105029676
Epoch #195: loss=0.029046695451937898
Epoch #196: loss=0.012701555620400515
Epoch #197: loss=0.014565798956725415
Epoch #198: loss=0.027974474334081456
Epoch #199: loss=0.015878049428064426
Epoch #200: loss=0.01440334787420061
Epoch #201: loss=0.010617531472753274
Epoch #202: loss=0.014959702531213885
Epoch #203: loss=0.01476189069902805
Epoch #204: loss=0.012202142758218393
Epoch #205: loss=0.014852575846223721
Epoch #206: loss=0.018703228682008483
Epoch #207: loss=0.013241957670973921
Epoch #208: loss=0.013629058714834845
Epoch #209: loss=0.012202121743418863
Epoch #210: loss=0.014933255552122854
Epoch #211: loss=0.02181243208421981
Epoch #212: loss=0.02155420025108918
Epoch #213: loss=0.014537482326674876
Epoch #214: loss=0.01170635363294373
Epoch #215: loss=0.014021333006979286
Epoch #216: loss=0.02282071129150995
Epoch #217: loss=0.013681873789915101
Epoch #218: loss=0.012539368314183738
Epoch #219: loss=0.011295785015602022
Epoch #220: loss=0.012516227938403847
Epoch #221: loss=0.010922952114495971
Epoch #222: loss=0.012164741259687006
Epoch #223: loss=0.009753142944568997
Epoch #224: loss=0.011967621372744748
Epoch #225: loss=0.02245643757138567
Epoch #226: loss=0.024247868564569914
Epoch #227: loss=0.01654201023095632
Epoch #228: loss=0.026450505964489883
Epoch #229: loss=0.017987488712700825
Epoch #230: loss=0.012269507715006499
Epoch #231: loss=0.010564546807181116
Epoch #232: loss=0.01236894723563774
Epoch #233: loss=0.010739449312876948
Epoch #234: loss=0.008893015265085237
Epoch #235: loss=0.017833067349170985
Epoch #236: loss=0.027764033534235563
Epoch #237: loss=0.016500064536964214
Epoch #238: loss=0.013188099969666425
Epoch #239: loss=0.027369932762318458
Epoch #240: loss=0.0132255947502802
Epoch #241: loss=0.0092959107493835
Epoch #242: loss=0.010405481009415593
Epoch #243: loss=0.017915677662288184
Epoch #244: loss=0.01976523585665384
Epoch #245: loss=0.010481840816457207
Epoch #246: loss=0.008637171400605688
Epoch #247: loss=0.014780656798114388
Epoch #248: loss=0.0230418898540785
Epoch #249: loss=0.016879936359098742

Training time: 1:42:19.893594

Finished.
n2one setting etth2_ettm1_electricity_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_electricity_weather_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_ettm1_electricity_weather', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.09048e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3416039823186705, 'MAE': 0.386731112497178}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm1_electricity_exchange', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm1_electricity_exchange_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.655916799214113
Epoch #1: loss=0.7038446083364295
Epoch #2: loss=0.49580007452270825
Epoch #3: loss=0.4068454938165049
Epoch #4: loss=0.3427503820111497
Epoch #5: loss=0.31338340743989695
Epoch #6: loss=0.2637457003339223
Epoch #7: loss=0.22902544158422294
Epoch #8: loss=0.215081317473729
Epoch #9: loss=0.18576309314636402
Epoch #10: loss=0.18205727466116378
Epoch #11: loss=0.15347694791316643
Epoch #12: loss=0.1537863432351897
Epoch #13: loss=0.15122716751497142
Epoch #14: loss=0.12352918712180698
Epoch #15: loss=0.13432770480082426
Epoch #16: loss=0.12418914220754798
Epoch #17: loss=0.12977395244264808
Epoch #18: loss=0.12436330158488895
Epoch #19: loss=0.09811672148286694
Epoch #20: loss=0.09745916063422257
Epoch #21: loss=0.10032357850383097
Epoch #22: loss=0.09043283563279024
Epoch #23: loss=0.09059735358577296
Epoch #24: loss=0.08214976886684552
Epoch #25: loss=0.09278606790351421
Epoch #26: loss=0.06896358011531985
Epoch #27: loss=0.0639979611204599
Epoch #28: loss=0.06183984684851826
Epoch #29: loss=0.07164881596749686
Epoch #30: loss=0.05544683495294893
Epoch #31: loss=0.07011603452775209
Epoch #32: loss=0.05447657476380596
Epoch #33: loss=0.053351068544478
Epoch #34: loss=0.062142396444368905
Epoch #35: loss=0.05208074629859682
Epoch #36: loss=0.054800806674429936
Epoch #37: loss=0.05185166721484524
Epoch #38: loss=0.04289274171574487
Epoch #39: loss=0.05438814957167212
Epoch #40: loss=0.04455993221321221
Epoch #41: loss=0.052170990950827854
Epoch #42: loss=0.043146118406952504
Epoch #43: loss=0.03644078907956737
Epoch #44: loss=0.03650283587020245
Epoch #45: loss=0.04450036088133537
Epoch #46: loss=0.04169022603234228
Epoch #47: loss=0.04132832144890303
Epoch #48: loss=0.04636815768768555
Epoch #49: loss=0.05038442110283144
Epoch #50: loss=0.03753637253730867
Epoch #51: loss=0.04216022558928996
Epoch #52: loss=0.028246684061626365
Epoch #53: loss=0.051083634785975
Epoch #54: loss=0.03565645298245564
Epoch #55: loss=0.03696464677542577
Epoch #56: loss=0.03473261124300113
Epoch #57: loss=0.041055390967917695
Epoch #58: loss=0.03519475932624889
Epoch #59: loss=0.03718263753998477
Epoch #60: loss=0.036567563511114516
Epoch #61: loss=0.0330313199095063
Epoch #62: loss=0.02929893544585221
Epoch #63: loss=0.03504828304979649
Epoch #64: loss=0.04396243177130228
Epoch #65: loss=0.03807923304667208
Epoch #66: loss=0.023137753474075207
Epoch #67: loss=0.059881023226590335
Epoch #68: loss=0.04508723859656441
Epoch #69: loss=0.039755088790462106
Epoch #70: loss=0.02645791359735594
Epoch #71: loss=0.02540945651255258
Epoch #72: loss=0.028106221787447663
Epoch #73: loss=0.0334420275981122
Epoch #74: loss=0.033129707182776344
Epoch #75: loss=0.02991393053238562
Epoch #76: loss=0.03197576560620863
Epoch #77: loss=0.03744310894575083
Epoch #78: loss=0.03803652797299585
Epoch #79: loss=0.030534039754574846
Epoch #80: loss=0.041275272530675346
Epoch #81: loss=0.02946786746256569
Epoch #82: loss=0.025607972489388106
Epoch #83: loss=0.02913776763429012
Epoch #84: loss=0.034005614737335925
Epoch #85: loss=0.028411291652058468
Epoch #86: loss=0.02034637660072628
Epoch #87: loss=0.022026028114395156
Epoch #88: loss=0.026401047312697497
Epoch #89: loss=0.028865126456115234
Epoch #90: loss=0.03157305934480512
Epoch #91: loss=0.0213242827922036
Epoch #92: loss=0.022043260098039107
Epoch #93: loss=0.026199282337213605
Epoch #94: loss=0.024543471489455928
Epoch #95: loss=0.02711447715737135
Epoch #96: loss=0.03694930584830841
Epoch #97: loss=0.06554697281935974
Epoch #98: loss=0.02986887719023232
Epoch #99: loss=0.023661165935341646
Epoch #100: loss=0.02021112510855967
Epoch #101: loss=0.01944629416662813
Epoch #102: loss=0.021087824891191192
Epoch #103: loss=0.021089004720554496
Epoch #104: loss=0.022378404966960808
Epoch #105: loss=0.021946023893676784
Epoch #106: loss=0.019632660696599687
Epoch #107: loss=0.023706054299706136
Epoch #108: loss=0.019137904102818754
Epoch #109: loss=0.019311021831086555
Epoch #110: loss=0.021833507294474058
Epoch #111: loss=0.030546597117203842
Epoch #112: loss=0.01924124014327673
Epoch #113: loss=0.020492744350420734
Epoch #114: loss=0.02668193824638234
Epoch #115: loss=0.03446782369875169
Epoch #116: loss=0.02631750848662291
Epoch #117: loss=0.024194600434486704
Epoch #118: loss=0.02558497047576495
Epoch #119: loss=0.028693157363943327
Epoch #120: loss=0.021870613204662874
Epoch #121: loss=0.027377798584670966
Epoch #122: loss=0.026725311552560874
Epoch #123: loss=0.022226734911172143
Epoch #124: loss=0.026471850103785898
Epoch #125: loss=0.015075359627019388
Epoch #126: loss=0.01653620904302815
Epoch #127: loss=0.017401932713391813
Epoch #128: loss=0.02307727041346308
Epoch #129: loss=0.030031288151531305
Epoch #130: loss=0.02497797709019447
Epoch #131: loss=0.025262687007879158
Epoch #132: loss=0.018336488408209645
Epoch #133: loss=0.015651066604027424
Epoch #134: loss=0.02053214775456078
Epoch #135: loss=0.024563127346954143
Epoch #136: loss=0.02496968330285359
Epoch #137: loss=0.018643170273936586
Epoch #138: loss=0.02633493879718722
Epoch #139: loss=0.017045692709792587
Epoch #140: loss=0.016829200768598385
Epoch #141: loss=0.017256442361319388
Epoch #142: loss=0.024708059959929512
Epoch #143: loss=0.041303721258231584
Epoch #144: loss=0.022152098381867692
Epoch #145: loss=0.026468027042398118
Epoch #146: loss=0.020628978401574814
Epoch #147: loss=0.014635458750055126
Epoch #148: loss=0.016810587460882372
Epoch #149: loss=0.012437808073913512
Epoch #150: loss=0.014359934443271764
Epoch #151: loss=0.014762979790049011
Epoch #152: loss=0.025250816793564803
Epoch #153: loss=0.03964608314149189
Epoch #154: loss=0.03766189312081924
Epoch #155: loss=0.020630522851861736
Epoch #156: loss=0.023869517958462667
Epoch #157: loss=0.018095560792916767
Epoch #158: loss=0.015957594304332127
Epoch #159: loss=0.01908699723120956
Epoch #160: loss=0.01833236314757574
Epoch #161: loss=0.020445626548435056
Epoch #162: loss=0.023581769536128564
Epoch #163: loss=0.028138193131762662
Epoch #164: loss=0.02512385345920276
Epoch #165: loss=0.020519450765508374
Epoch #166: loss=0.02555909336417758
Epoch #167: loss=0.026863801432639275
Epoch #168: loss=0.017938899871291356
Epoch #169: loss=0.013550651575417207
Epoch #170: loss=0.013521617067684568
Epoch #171: loss=0.015823794885720353
Epoch #172: loss=0.01967297729741519
Epoch #173: loss=0.016111601646053565
Epoch #174: loss=0.018309451119473703
Epoch #175: loss=0.016090658111048203
Epoch #176: loss=0.028735485000023216
Epoch #177: loss=0.027373734480830216
Epoch #178: loss=0.0187398452338258
Epoch #179: loss=0.029442806005369207
Epoch #180: loss=0.016590396183464404
Epoch #181: loss=0.014802566985046136
Epoch #182: loss=0.014923471122240696
Epoch #183: loss=0.02004434470171498
Epoch #184: loss=0.015098578259865525
Epoch #185: loss=0.020279986846431154
Epoch #186: loss=0.018177487321804554
Epoch #187: loss=0.016335847559928496
Epoch #188: loss=0.013530293335049126
Epoch #189: loss=0.012674503193202668
Epoch #190: loss=0.016270929336398895
Epoch #191: loss=0.014205439113012062
Epoch #192: loss=0.013364522007323522
Epoch #193: loss=0.021059206873782366
Epoch #194: loss=0.02461208667762454
Epoch #195: loss=0.018353029203222748
Epoch #196: loss=0.011662271680808236
Epoch #197: loss=0.012619593183064473
Epoch #198: loss=0.02044407096287163
Epoch #199: loss=0.017185979711646027
Epoch #200: loss=0.016192526120832728
Epoch #201: loss=0.02309879589599748
Epoch #202: loss=0.01950308874800334
Epoch #203: loss=0.01642942250921305
Epoch #204: loss=0.025644711430972276
Epoch #205: loss=0.016179210497656842
Epoch #206: loss=0.017756774194735862
Epoch #207: loss=0.020554118167061455
Epoch #208: loss=0.016094960217962646
Epoch #209: loss=0.011365711221321129
Epoch #210: loss=0.02087426549967738
Epoch #211: loss=0.01918074142648127
Epoch #212: loss=0.022359566927433915
Epoch #213: loss=0.018460295635382228
Epoch #214: loss=0.033834299037816075
Epoch #215: loss=0.024914607214432758
Epoch #216: loss=0.017274337515412085
Epoch #217: loss=0.017818135152851373
Epoch #218: loss=0.012120946591853511
Epoch #219: loss=0.014638780566235677
Epoch #220: loss=0.016450112220570873
Epoch #221: loss=0.027894855744134292
Epoch #222: loss=0.02536262311244327
Epoch #223: loss=0.01824738057139021
Epoch #224: loss=0.016002587034613276
Epoch #225: loss=0.017341366574763366
Epoch #226: loss=0.021678122174231637
Epoch #227: loss=0.01549573874494238
Epoch #228: loss=0.01673177580660483
Epoch #229: loss=0.015472375262583679
Epoch #230: loss=0.01041823035377475
Epoch #231: loss=0.012995748244217927
Epoch #232: loss=0.01303771610864269
Epoch #233: loss=0.01829158664794749
Epoch #234: loss=0.036149915529016446
Epoch #235: loss=0.01908970972447943
Epoch #236: loss=0.015292107645940219
Epoch #237: loss=0.014571186043949455
Epoch #238: loss=0.013454227013059192
Epoch #239: loss=0.009071175347354736
Epoch #240: loss=0.012392307343484796
Epoch #241: loss=0.01702396267647949
Epoch #242: loss=0.017481167886610163
Epoch #243: loss=0.013941341012505605
Epoch #244: loss=0.009712663024056016
Epoch #245: loss=0.027103352108138266
Epoch #246: loss=0.016344133841165044
Epoch #247: loss=0.013628346098034028
Epoch #248: loss=0.013520398619970554
Epoch #249: loss=0.02038196083584328

Training time: 1:35:13.416677

Finished.
n2one setting etth2_ettm1_electricity_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_electricity_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_ettm1_electricity_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.43968e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.88525e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.43968e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.5890610778286232, 'MAE': 0.5941013895483411}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm1_traffic_weather', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm1_traffic_weather_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.0347287202907713
Epoch #1: loss=0.4040195003941359
Epoch #2: loss=0.3025802244199954
Epoch #3: loss=0.22945616140172181
Epoch #4: loss=0.187388006030329
Epoch #5: loss=0.16754388334702444
Epoch #6: loss=0.14186875366093898
Epoch #7: loss=0.12186078765279476
Epoch #8: loss=0.10844951491930396
Epoch #9: loss=0.10855848807738744
Epoch #10: loss=0.08671833371032218
Epoch #11: loss=0.07284213203184356
Epoch #12: loss=0.07488318555217409
Epoch #13: loss=0.06849821571879516
Epoch #14: loss=0.05923048025212985
Epoch #15: loss=0.06179453975625879
Epoch #16: loss=0.059959118653841265
Epoch #17: loss=0.04783889205939246
Epoch #18: loss=0.053878989274444976
Epoch #19: loss=0.04920576199725739
Epoch #20: loss=0.05032248252814648
Epoch #21: loss=0.03714202950471112
Epoch #22: loss=0.041430313881048744
Epoch #23: loss=0.0395508632714044
Epoch #24: loss=0.04138213858919662
Epoch #25: loss=0.04492887147744937
Epoch #26: loss=0.03572514308328693
Epoch #27: loss=0.0341106272773112
Epoch #28: loss=0.03488130566613157
Epoch #29: loss=0.03860290303460639
Epoch #30: loss=0.030741793853148538
Epoch #31: loss=0.031501453106700716
Epoch #32: loss=0.03483462227350635
Epoch #33: loss=0.03168901366170878
Epoch #34: loss=0.02839086346213128
Epoch #35: loss=0.031252791891522115
Epoch #36: loss=0.026080800935437916
Epoch #37: loss=0.03443977633215154
Epoch #38: loss=0.03271188479889324
Epoch #39: loss=0.018159856239889357
Epoch #40: loss=0.023461835318623794
Epoch #41: loss=0.028457076821109244
Epoch #42: loss=0.025876351191251586
Epoch #43: loss=0.027395811631376638
Epoch #44: loss=0.02489442532886206
Epoch #45: loss=0.02448491177189618
Epoch #46: loss=0.02288739483021755
Epoch #47: loss=0.03303174069588161
Epoch #48: loss=0.030627826483733644
Epoch #49: loss=0.023582178258715367
Epoch #50: loss=0.02255497280030026
Epoch #51: loss=0.02374838247503849
Epoch #52: loss=0.022745958496839584
Epoch #53: loss=0.03051063146110147
Epoch #54: loss=0.02180477338111276
Epoch #55: loss=0.023906269609680394
Epoch #56: loss=0.022147891261752605
Epoch #57: loss=0.0191545806005114
Epoch #58: loss=0.018076868937344386
Epoch #59: loss=0.02170429873840717
Epoch #60: loss=0.028163679609965395
Epoch #61: loss=0.025838674069758094
Epoch #62: loss=0.02044138109261863
Epoch #63: loss=0.015476001047970785
Epoch #64: loss=0.015931711055688656
Epoch #65: loss=0.018030331805055432
Epoch #66: loss=0.017199830310784123
Epoch #67: loss=0.025903158247184057
Epoch #68: loss=0.019469420973812365
Epoch #69: loss=0.019107426551726255
Epoch #70: loss=0.028145141441826803
Epoch #71: loss=0.01574191968314577
Epoch #72: loss=0.012874590191753965
Epoch #73: loss=0.01907345776714844
Epoch #74: loss=0.026352334806545755
Epoch #75: loss=0.020800443990199743
Epoch #76: loss=0.019718740978414424
Epoch #77: loss=0.02224394257809241
Epoch #78: loss=0.020172239925087095
Epoch #79: loss=0.015047685899374705
Epoch #80: loss=0.022780766597757254
Epoch #81: loss=0.01540857439164394
Epoch #82: loss=0.021660345530084224
Epoch #83: loss=0.021556724496039296
Epoch #84: loss=0.016188516598217965
Epoch #85: loss=0.02491368304714306
Epoch #86: loss=0.02017977866883185
Epoch #87: loss=0.016952922089921236
Epoch #88: loss=0.013854537835691863
Epoch #89: loss=0.02013437135074268
Epoch #90: loss=0.014215857068667287
Epoch #91: loss=0.01869344259513322
Epoch #92: loss=0.01859459532211508
Epoch #93: loss=0.013880841317747217
Epoch #94: loss=0.011204423648185738
Epoch #95: loss=0.018024684128598988
Epoch #96: loss=0.017681441217389526
Epoch #97: loss=0.024765809742406435
Epoch #98: loss=0.015989060882516472
Epoch #99: loss=0.013782725547888536
Epoch #100: loss=0.016573459427143555
Epoch #101: loss=0.013826598463979371
Epoch #102: loss=0.014313182481896095
Epoch #103: loss=0.02117605505067347
Epoch #104: loss=0.014869869990872062
Epoch #105: loss=0.015458983099848755
Epoch #106: loss=0.027947479888258932
Epoch #107: loss=0.01729035915932942
Epoch #108: loss=0.016461096435357925
Epoch #109: loss=0.014565453543496075
Epoch #110: loss=0.021339109287919503
Epoch #111: loss=0.01713513552048552
Epoch #112: loss=0.012150282012242808
Epoch #113: loss=0.019137850512080223
Epoch #114: loss=0.015476991242101307
Epoch #115: loss=0.020237838867575055
Epoch #116: loss=0.017887534304062227
Epoch #117: loss=0.010723557849575906
Epoch #118: loss=0.022131277654689037
Epoch #119: loss=0.012004237262529287
Epoch #120: loss=0.011718335058851061
Epoch #121: loss=0.02566714724898441
Epoch #122: loss=0.009828162120503428
Epoch #123: loss=0.011232779292370734
Epoch #124: loss=0.018002658351122764
Epoch #125: loss=0.01795449530740567
Epoch #126: loss=0.012887365868792841
Epoch #127: loss=0.014925184803428289
Epoch #128: loss=0.012254907851456665
Epoch #129: loss=0.009861324674432001
Epoch #130: loss=0.01803311398204981
Epoch #131: loss=0.013124288142705734
Epoch #132: loss=0.021607507109634577
Epoch #133: loss=0.01602112586914485
Epoch #134: loss=0.013266266665965469
Epoch #135: loss=0.008853935219890877
Epoch #136: loss=0.019070303553174902
Epoch #137: loss=0.013064149953797562
Epoch #138: loss=0.01327240662298486
Epoch #139: loss=0.02314885424635842
Epoch #140: loss=0.011269918623696201
Epoch #141: loss=0.011047631845502805
Epoch #142: loss=0.022765676676198266
Epoch #143: loss=0.015138941688010023
Epoch #144: loss=0.009449391065890952
Epoch #145: loss=0.0102833596621924
Epoch #146: loss=0.016008883672883317
Epoch #147: loss=0.01273731148842091
Epoch #148: loss=0.010866241742867466
Epoch #149: loss=0.01909106569491876
Epoch #150: loss=0.009320862928498434
Epoch #151: loss=0.017080213365165072
Epoch #152: loss=0.015750952762262238
Epoch #153: loss=0.014442803626654543
Epoch #154: loss=0.010567435115156515
Epoch #155: loss=0.014811894397510095
Epoch #156: loss=0.010255495816060325
Epoch #157: loss=0.01570725821847277
Epoch #158: loss=0.015644636668222977
Epoch #159: loss=0.011944353126822712
Epoch #160: loss=0.011694247763006173
Epoch #161: loss=0.01465717546984134
Epoch #162: loss=0.011195226195903091
Epoch #163: loss=0.011479188380517511
Epoch #164: loss=0.01478716363433235
Epoch #165: loss=0.01119951878437707
Epoch #166: loss=0.012489563023846774
Epoch #167: loss=0.013157888210670782
Epoch #168: loss=0.010049701049528393
Epoch #169: loss=0.011114448335751707
Epoch #170: loss=0.015060956879056767
Epoch #171: loss=0.009310213179560378
Epoch #172: loss=0.012209193857279288
Epoch #173: loss=0.010304186211628572
Epoch #174: loss=0.013175169996869449
Epoch #175: loss=0.013241253049052078
Epoch #176: loss=0.013029358101715478
Epoch #177: loss=0.014147030808619803
Epoch #178: loss=0.014284282818696951
Epoch #179: loss=0.01519271369715377
Epoch #180: loss=0.01377851513257005
Epoch #181: loss=0.011578985975097215
Epoch #182: loss=0.00977605459938204
Epoch #183: loss=0.010986081341077357
Epoch #184: loss=0.01022907252945214
Epoch #185: loss=0.008232080022545909
Epoch #186: loss=0.011108845128807821
Epoch #187: loss=0.018577644751673447
Epoch #188: loss=0.013435598919277977
Epoch #189: loss=0.009478115394078534
Epoch #190: loss=0.012468690256226836
Epoch #191: loss=0.009897565213748419
Epoch #192: loss=0.01241190792474817
Epoch #193: loss=0.010733232422297252
Epoch #194: loss=0.01944858920394888
Epoch #195: loss=0.009319787500475643
Epoch #196: loss=0.007031367768428292
Epoch #197: loss=0.01399353992079847
Epoch #198: loss=0.011123023833861065
Epoch #199: loss=0.009384599385659272
Epoch #200: loss=0.012632886497294849
Epoch #201: loss=0.013831027891002719
Epoch #202: loss=0.013880587888369645
Epoch #203: loss=0.010312853568558253
Epoch #204: loss=0.01223391886237982
Epoch #205: loss=0.00993678607589169
Epoch #206: loss=0.01610943033859079
Epoch #207: loss=0.0127545307371696
Epoch #208: loss=0.009653629518150523
Epoch #209: loss=0.014152600285766115
Epoch #210: loss=0.010455228180486928
Epoch #211: loss=0.009584138148578815
Epoch #212: loss=0.01404018410069915
Epoch #213: loss=0.012255627747584508
Epoch #214: loss=0.017314766993423384
Epoch #215: loss=0.010106832324201152
Epoch #216: loss=0.017225817890323042
Epoch #217: loss=0.00942077490943574
Epoch #218: loss=0.013250119910747888
Epoch #219: loss=0.011521747191798298
Epoch #220: loss=0.00831677184912924
Epoch #221: loss=0.008466346566653352
Epoch #222: loss=0.009590350362978678
Epoch #223: loss=0.009062008841468096
Epoch #224: loss=0.016175955153993234
Epoch #225: loss=0.011798138158238096
Epoch #226: loss=0.009210922671400614
Epoch #227: loss=0.011668646697255298
Epoch #228: loss=0.01019504336827133
Epoch #229: loss=0.013437060101813069
Epoch #230: loss=0.010241486068333736
Epoch #231: loss=0.012533617766022015
Epoch #232: loss=0.011141902393365646
Epoch #233: loss=0.008931817959433973
Epoch #234: loss=0.012229178659964835
Epoch #235: loss=0.009710062071400002
Epoch #236: loss=0.012394563661861
Epoch #237: loss=0.009163344877246748
Epoch #238: loss=0.009729341850892942
Epoch #239: loss=0.01002955915156169
Epoch #240: loss=0.008421127516134778
Epoch #241: loss=0.010212547768613101
Epoch #242: loss=0.014325980709858108
Epoch #243: loss=0.009263349503666977
Epoch #244: loss=0.01131097517205594
Epoch #245: loss=0.008471338962818055
Epoch #246: loss=0.016437760172756163
Epoch #247: loss=0.009006223901102107
Epoch #248: loss=0.014915065582168392
Epoch #249: loss=0.011736521759439811

Training time: 3:38:49.672415

Finished.
n2one setting etth2_ettm1_traffic_weather -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_traffic_weather_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_ettm1_traffic_weather', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.65784e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.80488e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.53804e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.65784e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.43469895859884755, 'MAE': 0.47202650492484904}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm1_traffic_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_traffic_weather_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_ettm1_traffic_weather', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.30534e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.30534e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.49251592124088056, 'MAE': 0.4540180509712328}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm1_traffic_exchange', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm1_traffic_exchange_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.997192123183259
Epoch #1: loss=0.3959447216443919
Epoch #2: loss=0.27664855196400806
Epoch #3: loss=0.2112270240369882
Epoch #4: loss=0.181853457807085
Epoch #5: loss=0.14016149912096626
Epoch #6: loss=0.11641133884345559
Epoch #7: loss=0.10111837948332666
Epoch #8: loss=0.09835336980858801
Epoch #9: loss=0.08234103389298292
Epoch #10: loss=0.075991490983765
Epoch #11: loss=0.06275717892079942
Epoch #12: loss=0.06476113469961838
Epoch #13: loss=0.061819543842297583
Epoch #14: loss=0.05800595772971802
Epoch #15: loss=0.05097484691784327
Epoch #16: loss=0.04502334462338219
Epoch #17: loss=0.04551488201347335
Epoch #18: loss=0.04986676366775305
Epoch #19: loss=0.038427114936623825
Epoch #20: loss=0.04646977983511615
Epoch #21: loss=0.04873455291208056
Epoch #22: loss=0.03507604323543067
Epoch #23: loss=0.03367939930021666
Epoch #24: loss=0.03210056254636026
Epoch #25: loss=0.043321548245306055
Epoch #26: loss=0.029366496752822765
Epoch #27: loss=0.033373370942704775
Epoch #28: loss=0.0333603285091797
Epoch #29: loss=0.031952116713606905
Epoch #30: loss=0.02843744724295165
Epoch #31: loss=0.029970115244567924
Epoch #32: loss=0.036558842684219904
Epoch #33: loss=0.0429098001585042
Epoch #34: loss=0.02873868444923475
Epoch #35: loss=0.03187920939036213
Epoch #36: loss=0.03144302898661343
Epoch #37: loss=0.03209957665646331
Epoch #38: loss=0.023972886214454907
Epoch #39: loss=0.03372154240453194
Epoch #40: loss=0.02329764077142311
Epoch #41: loss=0.028324165686229266
Epoch #42: loss=0.024323931573415572
Epoch #43: loss=0.030585702729981963
Epoch #44: loss=0.028386057987976988
Epoch #45: loss=0.024543838840169908
Epoch #46: loss=0.02608985254463167
Epoch #47: loss=0.02772384635908246
Epoch #48: loss=0.02300802288906804
Epoch #49: loss=0.025059886420143535
Epoch #50: loss=0.0275696800370923
Epoch #51: loss=0.03136594383112105
Epoch #52: loss=0.022690380463688133
Epoch #53: loss=0.02091850918647676
Epoch #54: loss=0.02548373017639647
Epoch #55: loss=0.024274925057758443
Epoch #56: loss=0.030114821047309222
Epoch #57: loss=0.02182335615427357
Epoch #58: loss=0.022199102030958987
Epoch #59: loss=0.018764237631707523
Epoch #60: loss=0.02242979487857303
Epoch #61: loss=0.020651933635432412
Epoch #62: loss=0.022635289776181698
Epoch #63: loss=0.026132982147467922
Epoch #64: loss=0.02709131578946678
Epoch #65: loss=0.021703127865220193
Epoch #66: loss=0.03188826237103287
Epoch #67: loss=0.019393565509630093
Epoch #68: loss=0.0232610820960028
Epoch #69: loss=0.021311635867040185
Epoch #70: loss=0.020976867120626994
Epoch #71: loss=0.017336223086834884
Epoch #72: loss=0.018755156931735843
Epoch #73: loss=0.028655228539981443
Epoch #74: loss=0.022554640960053704
Epoch #75: loss=0.025896143314352853
Epoch #76: loss=0.018690628657324095
Epoch #77: loss=0.018076835422336672
Epoch #78: loss=0.01828939923251636
Epoch #79: loss=0.02055222451553663
Epoch #80: loss=0.020352681302024844
Epoch #81: loss=0.022990049136595945
Epoch #82: loss=0.019980307113344368
Epoch #83: loss=0.027954289395606506
Epoch #84: loss=0.01974719233951439
Epoch #85: loss=0.0161700371162796
Epoch #86: loss=0.01422710822771478
Epoch #87: loss=0.01710694969127265
Epoch #88: loss=0.02311534254912912
Epoch #89: loss=0.023935890940740612
Epoch #90: loss=0.023322062619184646
Epoch #91: loss=0.01618303448096642
Epoch #92: loss=0.015207066119851457
Epoch #93: loss=0.016713047134610016
Epoch #94: loss=0.017097971420954056
Epoch #95: loss=0.017865970074273867
Epoch #96: loss=0.018173993694274016
Epoch #97: loss=0.02037007644419744
Epoch #98: loss=0.022375589376302366
Epoch #99: loss=0.015581424572824413
Epoch #100: loss=0.015636183752478147
Epoch #101: loss=0.016322867028852547
Epoch #102: loss=0.023342226850119815
Epoch #103: loss=0.023312072017778608
Epoch #104: loss=0.016217452261723036
Epoch #105: loss=0.013207796229179876
Epoch #106: loss=0.01931200741835726
Epoch #107: loss=0.016687380621127935
Epoch #108: loss=0.015212639272382509
Epoch #109: loss=0.0110449150624927
Epoch #110: loss=0.02037855981574352
Epoch #111: loss=0.015326361835160479
Epoch #112: loss=0.01558949572413972
Epoch #113: loss=0.01979579544697756
Epoch #114: loss=0.01715710471556097
Epoch #115: loss=0.014590820249010518
Epoch #116: loss=0.01673232274930211
Epoch #117: loss=0.014551219862147951
Epoch #118: loss=0.023390337001589476
Epoch #119: loss=0.016255330911876587
Epoch #120: loss=0.015664651675890765
Epoch #121: loss=0.0200302613616136
Epoch #122: loss=0.0176629675882289
Epoch #123: loss=0.015271558547225993
Epoch #124: loss=0.013036476917379233
Epoch #125: loss=0.019902137575086642
Epoch #126: loss=0.016095688943899296
Epoch #127: loss=0.015846061824295495
Epoch #128: loss=0.01578255255776025
Epoch #129: loss=0.01334523284399561
Epoch #130: loss=0.014033576332957973
Epoch #131: loss=0.01734502038722509
Epoch #132: loss=0.024867007307162764
Epoch #133: loss=0.013442651920634383
Epoch #134: loss=0.016754025063762727
Epoch #135: loss=0.01507133241974369
Epoch #136: loss=0.016383251928427937
Epoch #137: loss=0.017706676218916948
Epoch #138: loss=0.0151569738276898
Epoch #139: loss=0.013365296472034676
Epoch #140: loss=0.017252135938703374
Epoch #141: loss=0.013839873821288583
Epoch #142: loss=0.014319336737948484
Epoch #143: loss=0.01998297371559405
Epoch #144: loss=0.01383687414175887
Epoch #145: loss=0.015191110983020431
Epoch #146: loss=0.01849679033674309
Epoch #147: loss=0.01717058867726738
Epoch #148: loss=0.014231687006473736
Epoch #149: loss=0.01905552770928422
Epoch #150: loss=0.016958911174459662
Epoch #151: loss=0.014489523852561277
Epoch #152: loss=0.015998253665145
Epoch #153: loss=0.012504185484758965
Epoch #154: loss=0.016050875400839874
Epoch #155: loss=0.011318287676584913
Epoch #156: loss=0.012090041720167958
Epoch #157: loss=0.011101694270027938
Epoch #158: loss=0.016090780421281297
Epoch #159: loss=0.015537333097371802
Epoch #160: loss=0.01259102318500801
Epoch #161: loss=0.013822181026761108
Epoch #162: loss=0.012322434393665701
Epoch #163: loss=0.012329295197330564
Epoch #164: loss=0.013459027554278224
Epoch #165: loss=0.013615733145589065
Epoch #166: loss=0.01759602300204311
Epoch #167: loss=0.013199902000934828
Epoch #168: loss=0.014630491516482335
Epoch #169: loss=0.013940367504989996
Epoch #170: loss=0.013630300532846328
Epoch #171: loss=0.017695497425118625
Epoch #172: loss=0.015803226780212957
Epoch #173: loss=0.012292803282754313
Epoch #174: loss=0.013984081137063153
Epoch #175: loss=0.0121657689353244
Epoch #176: loss=0.014961724432568362
Epoch #177: loss=0.013790422502449827
Epoch #178: loss=0.012827305704172226
Epoch #179: loss=0.010494969686561974
Epoch #180: loss=0.014469471359555976
Epoch #181: loss=0.012863797729805155
Epoch #182: loss=0.013217222656109967
Epoch #183: loss=0.02132285080720599
Epoch #184: loss=0.019055190063210815
Epoch #185: loss=0.012880595779049825
Epoch #186: loss=0.01290892131919873
Epoch #187: loss=0.012165649514704332
Epoch #188: loss=0.012625616893847683
Epoch #189: loss=0.01576784947638909
Epoch #190: loss=0.013715014669566069
Epoch #191: loss=0.012791775398049189
Epoch #192: loss=0.01350940716405898
Epoch #193: loss=0.01721134537947856
Epoch #194: loss=0.014933210193539544
Epoch #195: loss=0.011588089793705778
Epoch #196: loss=0.012169554753527665
Epoch #197: loss=0.01288383072856992
Epoch #198: loss=0.024420759355167434
Epoch #199: loss=0.01631225719383282
Epoch #200: loss=0.01882856904502422
Epoch #201: loss=0.012031627692399401
Epoch #202: loss=0.010773668118499781
Epoch #203: loss=0.018714853935192764
Epoch #204: loss=0.011111873171230071
Epoch #205: loss=0.010345642978102882
Epoch #206: loss=0.012810504329667441
Epoch #207: loss=0.012276017452349733
Epoch #208: loss=0.010657696735097078
Epoch #209: loss=0.012920720530690905
Epoch #210: loss=0.016132871629673213
Epoch #211: loss=0.013408702630185216
Epoch #212: loss=0.020755773700649436
Epoch #213: loss=0.011703525139842191
Epoch #214: loss=0.011638003142473503
Epoch #215: loss=0.016056241636630015
Epoch #216: loss=0.017418129446554843
Epoch #217: loss=0.018176615950250306
Epoch #218: loss=0.008799143871763115
Epoch #219: loss=0.015070637660477308
Epoch #220: loss=0.01313186439689686
Epoch #221: loss=0.012154129504992155
Epoch #222: loss=0.011119185099068837
Epoch #223: loss=0.017934596680411766
Epoch #224: loss=0.016204294616293302
Epoch #225: loss=0.014242915649660275
Epoch #226: loss=0.011491255247083164
Epoch #227: loss=0.010368744970971445
Epoch #228: loss=0.012598218491762013
Epoch #229: loss=0.014383856007010731
Epoch #230: loss=0.01145250310635363
Epoch #231: loss=0.011983000807663917
Epoch #232: loss=0.01749064052145931
Epoch #233: loss=0.014179692889130721
Epoch #234: loss=0.018747697287327756
Epoch #235: loss=0.01120132488004684
Epoch #236: loss=0.010351836931985017
Epoch #237: loss=0.010847981061496292
Epoch #238: loss=0.012839974329065765
Epoch #239: loss=0.013282294879982228
Epoch #240: loss=0.012789107613931625
Epoch #241: loss=0.011767854706311089
Epoch #242: loss=0.01475520933069617
Epoch #243: loss=0.01574165830685603
Epoch #244: loss=0.011824143100233135
Epoch #245: loss=0.014096448225065434
Epoch #246: loss=0.00873991678632625
Epoch #247: loss=0.011980585949368926
Epoch #248: loss=0.011041292615773928
Epoch #249: loss=0.01422073464942383

Training time: 4:29:06.218024

Finished.
n2one setting etth2_ettm1_traffic_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_traffic_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_ettm1_traffic_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.04567e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.07004e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.02825e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.04567e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.40367933564743946, 'MAE': 0.4529962604011524}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm1_traffic_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_traffic_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_ettm1_traffic_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.60577e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.18698e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.60577e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.8623430812755836, 'MAE': 0.7553930113317648}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm1_weather_exchange', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm1_weather_exchange_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=4.165683173216307
Epoch #1: loss=2.350664484959382
Epoch #2: loss=2.296263474684495
Epoch #3: loss=1.9717350739699144
Epoch #4: loss=1.874207813006181
Epoch #5: loss=1.7258255963142102
Epoch #6: loss=1.5095069866914015
Epoch #7: loss=1.4267091086277595
Epoch #8: loss=1.330995181432137
Epoch #9: loss=1.264913918880316
Epoch #10: loss=1.1987833380699158
Epoch #11: loss=1.106940827690638
Epoch #12: loss=1.082329619389314
Epoch #13: loss=1.0585306389973714
Epoch #14: loss=1.024795222740907
Epoch #15: loss=0.9561169239190909
Epoch #16: loss=1.0070570283211195
Epoch #17: loss=0.9812986988287705
Epoch #18: loss=0.8881553801206442
Epoch #19: loss=0.888249009847641
Epoch #20: loss=0.8405322249119098
Epoch #21: loss=0.8136113664278617
Epoch #22: loss=0.8112379323977691
Epoch #23: loss=0.7743589557134188
Epoch #24: loss=0.7562733774001782
Epoch #25: loss=0.7766952170775487
Epoch #26: loss=0.744504648905534
Epoch #27: loss=0.660086799126405
Epoch #28: loss=0.7061638310551643
Epoch #29: loss=0.6560717299580574
Epoch #30: loss=0.7081834404514387
Epoch #31: loss=0.7057266779817067
Epoch #32: loss=0.6639252551473104
Epoch #33: loss=0.5780462599717654
Epoch #34: loss=0.6128505382400292
Epoch #35: loss=0.6625494807958603
Epoch #36: loss=0.6098454783742244
Epoch #37: loss=0.6576584760959332
Epoch #38: loss=0.5878606965908637
Epoch #39: loss=0.5452634887053416
Epoch #40: loss=0.5757038203569559
Epoch #41: loss=0.5202699263508503
Epoch #42: loss=0.48373708644738567
Epoch #43: loss=0.4714736935610955
Epoch #44: loss=0.46603443874762607
Epoch #45: loss=0.4732893602206157
Epoch #46: loss=0.4413074217736721
Epoch #47: loss=0.46375905665067524
Epoch #48: loss=0.5220298239817986
Epoch #49: loss=0.4913707725130595
Epoch #50: loss=0.4485006212041928
Epoch #51: loss=0.4490835855786617
Epoch #52: loss=0.41244621460254377
Epoch #53: loss=0.3803536889071648
Epoch #54: loss=0.41364382723203075
Epoch #55: loss=0.4483214831696107
Epoch #56: loss=0.3777914815224134
Epoch #57: loss=0.4416603526243797
Epoch #58: loss=0.41897158983808297
Epoch #59: loss=0.39583857300189823
Epoch #60: loss=0.3783821039474927
Epoch #61: loss=0.36627949573672736
Epoch #62: loss=0.40002809579555804
Epoch #63: loss=0.526620845668591
Epoch #64: loss=0.44892429932951927
Epoch #65: loss=0.36625404541309065
Epoch #66: loss=0.35544224083423615
Epoch #67: loss=0.3240686451586393
Epoch #68: loss=0.35862075078945893
Epoch #69: loss=0.3010227866470814
Epoch #70: loss=0.3212691175823028
Epoch #71: loss=0.30850164477641767
Epoch #72: loss=0.33068065402599484
Epoch #73: loss=0.2622042881468168
Epoch #74: loss=0.24327735230326653
Epoch #75: loss=0.26962617612802064
Epoch #76: loss=0.3254796223571667
Epoch #77: loss=0.24444676821048444
Epoch #78: loss=0.2783619102377158
Epoch #79: loss=0.2369917512226563
Epoch #80: loss=0.2894681566036664
Epoch #81: loss=0.31234220716242606
Epoch #82: loss=0.288923678203271
Epoch #83: loss=0.2418438674738774
Epoch #84: loss=0.29772402661351055
Epoch #85: loss=0.25946813793136525
Epoch #86: loss=0.24809140368149832
Epoch #87: loss=0.32913322202288187
Epoch #88: loss=0.26395169373315114
Epoch #89: loss=0.2695159541013149
Epoch #90: loss=0.2854428391617078
Epoch #91: loss=0.2577744879974769
Epoch #92: loss=0.19390150166761416
Epoch #93: loss=0.25250519009736866
Epoch #94: loss=0.22776708422371975
Epoch #95: loss=0.18965201509686616
Epoch #96: loss=0.20331231526170784
Epoch #97: loss=0.2215786838474182
Epoch #98: loss=0.21765861853670615
Epoch #99: loss=0.21386231224124247
Epoch #100: loss=0.2568157891957806
Epoch #101: loss=0.20045004942669317
Epoch #102: loss=0.1884488770021842
Epoch #103: loss=0.20942990481853485
Epoch #104: loss=0.23173077999112698
Epoch #105: loss=0.17164977711553758
Epoch #106: loss=0.2122535670462709
Epoch #107: loss=0.20496182845762143
Epoch #108: loss=0.1817404839138572
Epoch #109: loss=0.16724609798536852
Epoch #110: loss=0.14260165192759955
Epoch #111: loss=0.17082701430011255
Epoch #112: loss=0.1836979127703951
Epoch #113: loss=0.196271385710973
Epoch #114: loss=0.18710756373520082
Epoch #115: loss=0.22003146798278278
Epoch #116: loss=0.18885449312913877
Epoch #117: loss=0.1717694764956832
Epoch #118: loss=0.17515929154335305
Epoch #119: loss=0.19180181636833227
Epoch #120: loss=0.1726685964072553
Epoch #121: loss=0.18270619163432947
Epoch #122: loss=0.15808196247626954
Epoch #123: loss=0.15852422217050424
Epoch #124: loss=0.19074074232664245
Epoch #125: loss=0.16685763775156096
Epoch #126: loss=0.15619280056741375
Epoch #127: loss=0.17857393371657684
Epoch #128: loss=0.16585236845108178
Epoch #129: loss=0.22174135201538986
Epoch #130: loss=0.31898644072218585
Epoch #131: loss=0.27205528791707295
Epoch #132: loss=0.1723027780938607
Epoch #133: loss=0.162144999521283
Epoch #134: loss=0.20645794745248097
Epoch #135: loss=0.2593556517878404
Epoch #136: loss=0.2689304267987609
Epoch #137: loss=0.24610673156208718
Epoch #138: loss=0.19027181836561516
Epoch #139: loss=0.1624223215935322
Epoch #140: loss=0.1242334981663869
Epoch #141: loss=0.1500456749389951
Epoch #142: loss=0.1284784569333379
Epoch #143: loss=0.11666476952198607
Epoch #144: loss=0.13917302168332613
Epoch #145: loss=0.1701396761032251
Epoch #146: loss=0.1441794536792888
Epoch #147: loss=0.1714344321965025
Epoch #148: loss=0.14992813687198436
Epoch #149: loss=0.13755187051943862
Epoch #150: loss=0.11324590215316185
Epoch #151: loss=0.13588117944219938
Epoch #152: loss=0.1436099005289949
Epoch #153: loss=0.12748975729426512
Epoch #154: loss=0.13762174550300607
Epoch #155: loss=0.12103038277620307
Epoch #156: loss=0.14802398736803576
Epoch #157: loss=0.12474781203155334
Epoch #158: loss=0.13429077338570586
Epoch #159: loss=0.12831575684965804
Epoch #160: loss=0.13501467326512703
Epoch #161: loss=0.15183987733549797
Epoch #162: loss=0.1722990279802336
Epoch #163: loss=0.18317520048899147
Epoch #164: loss=0.211472581857099
Epoch #165: loss=0.15245483371500784
Epoch #166: loss=0.13425472453952983
Epoch #167: loss=0.13647317707252044
Epoch #168: loss=0.1245740930764721
Epoch #169: loss=0.12943486471732074
Epoch #170: loss=0.1338807467299585
Epoch #171: loss=0.1839681942230807
Epoch #172: loss=0.13119377532544044
Epoch #173: loss=0.1108357533096121
Epoch #174: loss=0.12149908984653078
Epoch #175: loss=0.1127511401875661
Epoch #176: loss=0.0972386673809244
Epoch #177: loss=0.16858323763769406
Epoch #178: loss=0.12154612944533046
Epoch #179: loss=0.12003800423386005
Epoch #180: loss=0.10605182215714684
Epoch #181: loss=0.09611820182404839
Epoch #182: loss=0.12416629679501057
Epoch #183: loss=0.09536020457744598
Epoch #184: loss=0.10992396307679322
Epoch #185: loss=0.08739224853567205
Epoch #186: loss=0.1016908001799423
Epoch #187: loss=0.11223072358048879
Epoch #188: loss=0.0903145036695955
Epoch #189: loss=0.11458052868524995
Epoch #190: loss=0.10068858850102586
Epoch #191: loss=0.1300232918180812
Epoch #192: loss=0.10462191627504161
Epoch #193: loss=0.09926068820417501
Epoch #194: loss=0.10309838127488127
Epoch #195: loss=0.12842835596977517
Epoch #196: loss=0.2802272353034753
Epoch #197: loss=0.22117594264161128
Epoch #198: loss=0.15404601531246534
Epoch #199: loss=0.11739906324790074
Epoch #200: loss=0.11267146206675814
Epoch #201: loss=0.1057365584688691
Epoch #202: loss=0.1012063709517511
Epoch #203: loss=0.14083451233231103
Epoch #204: loss=0.11864019695741053
Epoch #205: loss=0.10540803063374299
Epoch #206: loss=0.0941913403893033
Epoch #207: loss=0.17693831359681028
Epoch #208: loss=0.1436679596797778
Epoch #209: loss=0.09883148862550464
Epoch #210: loss=0.09177821018518163
Epoch #211: loss=0.08749602387587611
Epoch #212: loss=0.13244732945727614
Epoch #213: loss=0.08646231875396691
Epoch #214: loss=0.06888011692521664
Epoch #215: loss=0.07806573557452513
Epoch #216: loss=0.08312269867970966
Epoch #217: loss=0.1259162587006218
Epoch #218: loss=0.06044305142803261
Epoch #219: loss=0.06559720198408915
Epoch #220: loss=0.06369113135867967
Epoch #221: loss=0.08345724880480422
Epoch #222: loss=0.10102938703046395
Epoch #223: loss=0.08631970828327422
Epoch #224: loss=0.07614239715397932
Epoch #225: loss=0.07675325804246733
Epoch #226: loss=0.11463717824349609
Epoch #227: loss=0.06706084606524271
Epoch #228: loss=0.09589721369915284
Epoch #229: loss=0.10061509520388566
Epoch #230: loss=0.10087712755641685
Epoch #231: loss=0.1163893045965009
Epoch #232: loss=0.1098357905418827
Epoch #233: loss=0.11965551714484508
Epoch #234: loss=0.14720956071351582
Epoch #235: loss=0.19330253838919675
Epoch #236: loss=0.12354651514369135
Epoch #237: loss=0.11379002939121655
Epoch #238: loss=0.07148198357138497
Epoch #239: loss=0.08251479839404616
Epoch #240: loss=0.08070479816972063
Epoch #241: loss=0.095622173564222
Epoch #242: loss=0.1116278707407988
Epoch #243: loss=0.07958902456224538
Epoch #244: loss=0.07077127329718608
Epoch #245: loss=0.0793148776731239
Epoch #246: loss=0.0651626239817303
Epoch #247: loss=0.06739202324444285
Epoch #248: loss=0.06637232856323513
Epoch #249: loss=0.07603130858534804

Training time: 0:16:04.053802

Finished.
n2one setting etth2_ettm1_weather_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_weather_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_ettm1_weather_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.45436e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.88348e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.45436e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3857681496401988, 'MAE': 0.4386500618235952}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm2_electricity_traffic', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm2_electricity_traffic_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.8343328300810774
Epoch #1: loss=0.286471550808064
Epoch #2: loss=0.18805245636690168
Epoch #3: loss=0.1394048142871144
Epoch #4: loss=0.12478258998306169
Epoch #5: loss=0.10164453586847284
Epoch #6: loss=0.08075248790310881
Epoch #7: loss=0.07143901453293755
Epoch #8: loss=0.057112879883637536
Epoch #9: loss=0.0520211325793199
Epoch #10: loss=0.04716916251784155
Epoch #11: loss=0.04828830759198429
Epoch #12: loss=0.03950572120383239
Epoch #13: loss=0.04428109108993038
Epoch #14: loss=0.04201593677302765
Epoch #15: loss=0.035419526422411036
Epoch #16: loss=0.039035805729609435
Epoch #17: loss=0.03254295372269229
Epoch #18: loss=0.03239739798653024
Epoch #19: loss=0.02389947901552405
Epoch #20: loss=0.03636511252489488
Epoch #21: loss=0.030597126827327896
Epoch #22: loss=0.02807963718361625
Epoch #23: loss=0.025303489012239683
Epoch #24: loss=0.023880448053115212
Epoch #25: loss=0.027872459152127948
Epoch #26: loss=0.021258106793693384
Epoch #27: loss=0.022356755060012327
Epoch #28: loss=0.028134123592175694
Epoch #29: loss=0.02416337111897551
Epoch #30: loss=0.019901979324868497
Epoch #31: loss=0.02084027626983035
Epoch #32: loss=0.021713867741671826
Epoch #33: loss=0.017195809841210094
Epoch #34: loss=0.025480425544587165
Epoch #35: loss=0.01957854523396563
Epoch #36: loss=0.02046881335056414
Epoch #37: loss=0.023738826821724124
Epoch #38: loss=0.023053829169787193
Epoch #39: loss=0.015459656205773121
Epoch #40: loss=0.020800666482725588
Epoch #41: loss=0.015689390654369164
Epoch #42: loss=0.020585049199125342
Epoch #43: loss=0.020677316751759336
Epoch #44: loss=0.01925879869041856
Epoch #45: loss=0.01991953806659683
Epoch #46: loss=0.020214335345959743
Epoch #47: loss=0.018426403665095476
Epoch #48: loss=0.02430324314269148
Epoch #49: loss=0.017017563881463433
Epoch #50: loss=0.017886008774029242
Epoch #51: loss=0.02030224067430988
Epoch #52: loss=0.019080541829918227
Epoch #53: loss=0.016947049358454844
Epoch #54: loss=0.014587954466386647
Epoch #55: loss=0.017306859440157238
Epoch #56: loss=0.017253011493279843
Epoch #57: loss=0.02146099459725571
Epoch #58: loss=0.02345553980151065
Epoch #59: loss=0.01420142484835518
Epoch #60: loss=0.016405305860747895
Epoch #61: loss=0.020160294822283435
Epoch #62: loss=0.012408366205772117
Epoch #63: loss=0.015162901964664209
Epoch #64: loss=0.02075303006899015
Epoch #65: loss=0.014213851509822437
Epoch #66: loss=0.017159668419956593
Epoch #67: loss=0.015591591749368212
Epoch #68: loss=0.011847139579286316
Epoch #69: loss=0.011781680070398473
Epoch #70: loss=0.013951288968507669
Epoch #71: loss=0.017628779712645492
Epoch #72: loss=0.014294780560265192
Epoch #73: loss=0.01147925352317019
Epoch #74: loss=0.015190678630427432
Epoch #75: loss=0.012581439943951
Epoch #76: loss=0.015281896288694734
Epoch #77: loss=0.01326099857753137
Epoch #78: loss=0.012545128266709988
Epoch #79: loss=0.01654367508673203
Epoch #80: loss=0.017204748409590666
Epoch #81: loss=0.013414692283794565
Epoch #82: loss=0.011967052241330184
Epoch #83: loss=0.0185410741540304
Epoch #84: loss=0.012981999978734464
Epoch #85: loss=0.015570411082672877
Epoch #86: loss=0.012725022669712824
Epoch #87: loss=0.015235664293844235
Epoch #88: loss=0.015817165774842653
Epoch #89: loss=0.009877427066633668
Epoch #90: loss=0.011188405435790838
Epoch #91: loss=0.019010523342360534
Epoch #92: loss=0.015375561252200307
Epoch #93: loss=0.018445814379845587
Epoch #94: loss=0.011767498569410461
Epoch #95: loss=0.01041288169055393
Epoch #96: loss=0.013132318160020232
Epoch #97: loss=0.014453915634474016
Epoch #98: loss=0.012243653839951026
Epoch #99: loss=0.012008689404729883
Epoch #100: loss=0.010604974268625923
Epoch #101: loss=0.010182440555837667
Epoch #102: loss=0.013304315032493665
Epoch #103: loss=0.014821515009487645
Epoch #104: loss=0.011698206664305318
Epoch #105: loss=0.008810062099570809
Epoch #106: loss=0.015378593858562257
Epoch #107: loss=0.012314331707205412
Epoch #108: loss=0.011148762981667414
Epoch #109: loss=0.01380704135878419
Epoch #110: loss=0.01331447935545149
Epoch #111: loss=0.013265299051823144
Epoch #112: loss=0.011734556248882626
Epoch #113: loss=0.015595395980074906
Epoch #114: loss=0.010218867717113144
Epoch #115: loss=0.012540424744723416
Epoch #116: loss=0.013521758997608341
Epoch #117: loss=0.011177124530863098
Epoch #118: loss=0.012977034495123736
Epoch #119: loss=0.010371501762921804
Epoch #120: loss=0.011120565816043542
Epoch #121: loss=0.010177715240755633
Epoch #122: loss=0.010496072250815398
Epoch #123: loss=0.01195123852504926
Epoch #124: loss=0.008233880875162289
Epoch #125: loss=0.012003125991549367
Epoch #126: loss=0.012689608739182814
Epoch #127: loss=0.010700040652800885
Epoch #128: loss=0.009694396576208863
Epoch #129: loss=0.01853283465422921
Epoch #130: loss=0.00997617452809333
Epoch #131: loss=0.010490259083440964
Epoch #132: loss=0.010425574392975765
Epoch #133: loss=0.008586493686007399
Epoch #134: loss=0.007578084528680579
Epoch #135: loss=0.009954770240353728
Epoch #136: loss=0.014233840894647553
Epoch #137: loss=0.010379408173169824
Epoch #138: loss=0.009228990281142352
Epoch #139: loss=0.011265613710886439
Epoch #140: loss=0.010209956665645097
Epoch #141: loss=0.013975778743427916
Epoch #142: loss=0.008851117635229194
Epoch #143: loss=0.008142569427281107
Epoch #144: loss=0.016984246751774516
Epoch #145: loss=0.010562064536865059
Epoch #146: loss=0.009993738146876058
Epoch #147: loss=0.010551764161387688
Epoch #148: loss=0.014421297277455341
Epoch #149: loss=0.00891564936694512
Epoch #150: loss=0.010172812627534495
Epoch #151: loss=0.009642675471305082
Epoch #152: loss=0.015223008899557498
Epoch #153: loss=0.015432631145971017
Epoch #154: loss=0.007238075066341663
Epoch #155: loss=0.012744557684608564
Epoch #156: loss=0.007895994928702924
Epoch #157: loss=0.014540785505272012
Epoch #158: loss=0.00836709014681895
Epoch #159: loss=0.009233336110712653
Epoch #160: loss=0.01017788646779875
Epoch #161: loss=0.012479151058168077
Epoch #162: loss=0.020083686739978766
Epoch #163: loss=0.011169188029611046
Epoch #164: loss=0.00997050323401059
Epoch #165: loss=0.008792919627378977
Epoch #166: loss=0.012045608170756637
Epoch #167: loss=0.008194712925975487
Epoch #168: loss=0.010597390633603836
Epoch #169: loss=0.008296333654766896
Epoch #170: loss=0.014043827010385035
Epoch #171: loss=0.009351085429734424
Epoch #172: loss=0.011741139320700276
Epoch #173: loss=0.011146043531211744
Epoch #174: loss=0.007758900561728313
Epoch #175: loss=0.012386965971819274
Epoch #176: loss=0.007668693823497362
Epoch #177: loss=0.010671451960712711
Epoch #178: loss=0.011847105560289017
Epoch #179: loss=0.010821047216590043
Epoch #180: loss=0.012501601294833345
Epoch #181: loss=0.008305785990837084
Epoch #182: loss=0.009975720483032897
Epoch #183: loss=0.010182052475741858
Epoch #184: loss=0.007910928445783427
Epoch #185: loss=0.0282961464473994
Epoch #186: loss=0.01010894926974085
Epoch #187: loss=0.009966080393911657
Epoch #188: loss=0.012129616692944213
Epoch #189: loss=0.008206532370661336
Epoch #190: loss=0.0122562002392901
Epoch #191: loss=0.011331185710722648
Epoch #192: loss=0.008801187970796693
Epoch #193: loss=0.01073439302207219
Epoch #194: loss=0.012801912899295718
Epoch #195: loss=0.010381135205349744
Epoch #196: loss=0.009985965587888695
Epoch #197: loss=0.010461660863616547
Epoch #198: loss=0.011048080182916755
Epoch #199: loss=0.010585849403035261
Epoch #200: loss=0.01096588835140266
Epoch #201: loss=0.007551107662458994
Epoch #202: loss=0.010748507734494738
Epoch #203: loss=0.01271249897237929
Epoch #204: loss=0.009020481459679819
Epoch #205: loss=0.010445548141603023
Epoch #206: loss=0.008683468226678197
Epoch #207: loss=0.008769716740879858
Epoch #208: loss=0.008020341515315806
Epoch #209: loss=0.012839662116912216
Epoch #210: loss=0.00835491134071454
Epoch #211: loss=0.01029644371671924
Epoch #212: loss=0.009077832970774627
Epoch #213: loss=0.011177714260059101
Epoch #214: loss=0.006427367096163935
Epoch #215: loss=0.008334454076720765
Epoch #216: loss=0.01261952393321162
Epoch #217: loss=0.009292282200470563
Epoch #218: loss=0.01932007733900736
Epoch #219: loss=0.005954441816788498
Epoch #220: loss=0.016023738782260245
Epoch #221: loss=0.00835908417557781
Epoch #222: loss=0.010831353021022278
Epoch #223: loss=0.009160804396965247
Epoch #224: loss=0.010813239036485404
Epoch #225: loss=0.007790521187144122
Epoch #226: loss=0.009105801172604898
Epoch #227: loss=0.010207357894646494
Epoch #228: loss=0.007220736102298074
Epoch #229: loss=0.011553303103575671
Epoch #230: loss=0.008166456929817842
Epoch #231: loss=0.011887120088184528
Epoch #232: loss=0.00777997052123294
Epoch #233: loss=0.007278038417744248
Epoch #234: loss=0.008547683812177303
Epoch #235: loss=0.009865496588774824
Epoch #236: loss=0.00906433208249933
Epoch #237: loss=0.009528079066673417
Epoch #238: loss=0.009199606918281143
Epoch #239: loss=0.020953793359957604
Epoch #240: loss=0.006818569600986027
Epoch #241: loss=0.00870885201023321
Epoch #242: loss=0.007900555315191815
Epoch #243: loss=0.007843655864905381
Epoch #244: loss=0.010073571986749304
Epoch #245: loss=0.007310477416609989
Epoch #246: loss=0.014988969660748523
Epoch #247: loss=0.007659607423933559
Epoch #248: loss=0.007867307103037187
Epoch #249: loss=0.010106924822900331

Training time: 4:57:34.966872

Finished.
n2one setting etth2_ettm2_electricity_traffic -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm2_electricity_traffic_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_ettm2_electricity_traffic', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.98225e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.80813e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.51309e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.98225e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.5733866190972465, 'MAE': 0.5906084059393901}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm2_electricity_traffic -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm2_electricity_traffic_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_ettm2_electricity_traffic', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.39734e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.2883219761569552, 'MAE': 0.35985748481507235}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm2_electricity_weather', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm2_electricity_weather_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.7209637823170179
Epoch #1: loss=0.7402092656044111
Epoch #2: loss=0.5314234991187918
Epoch #3: loss=0.4625906792813784
Epoch #4: loss=0.39592049207589397
Epoch #5: loss=0.35478774713326805
Epoch #6: loss=0.3026701213562325
Epoch #7: loss=0.2691888753681967
Epoch #8: loss=0.23838024992648868
Epoch #9: loss=0.20852618588976665
Epoch #10: loss=0.1956021202753668
Epoch #11: loss=0.1773489519851665
Epoch #12: loss=0.17859575456544144
Epoch #13: loss=0.21570196285435597
Epoch #14: loss=0.18137648689420255
Epoch #15: loss=0.1295559554679753
Epoch #16: loss=0.12250521047270461
Epoch #17: loss=0.13512738431765609
Epoch #18: loss=0.12615407262864994
Epoch #19: loss=0.09443284068001459
Epoch #20: loss=0.13137876031129328
Epoch #21: loss=0.10017951481452543
Epoch #22: loss=0.09068971068585573
Epoch #23: loss=0.11524761850141907
Epoch #24: loss=0.07962459563851765
Epoch #25: loss=0.09246206345062141
Epoch #26: loss=0.08359161319900049
Epoch #27: loss=0.0921006767742642
Epoch #28: loss=0.06049244154678428
Epoch #29: loss=0.0625372370500883
Epoch #30: loss=0.05625020396091963
Epoch #31: loss=0.05905010501841364
Epoch #32: loss=0.06672927873489791
Epoch #33: loss=0.051144912258453974
Epoch #34: loss=0.060840919539842706
Epoch #35: loss=0.050569903673221395
Epoch #36: loss=0.04884390143090731
Epoch #37: loss=0.04811729567814363
Epoch #38: loss=0.056226746492368515
Epoch #39: loss=0.06317453303259529
Epoch #40: loss=0.07281400568796041
Epoch #41: loss=0.04637622417410044
Epoch #42: loss=0.042174877616742705
Epoch #43: loss=0.05820566148350449
Epoch #44: loss=0.03668005717918277
Epoch #45: loss=0.043414187313963286
Epoch #46: loss=0.046468516547641114
Epoch #47: loss=0.03720069303598306
Epoch #48: loss=0.05314758117948595
Epoch #49: loss=0.031817799076846204
Epoch #50: loss=0.04462341665009623
Epoch #51: loss=0.040220965955355396
Epoch #52: loss=0.030038531174985308
Epoch #53: loss=0.03092828531947293
Epoch #54: loss=0.03173438102766004
Epoch #55: loss=0.036992368346386376
Epoch #56: loss=0.04087857486654634
Epoch #57: loss=0.02748446984452591
Epoch #58: loss=0.029258213982572907
Epoch #59: loss=0.030078592414852896
Epoch #60: loss=0.0462867902595014
Epoch #61: loss=0.02807670566253364
Epoch #62: loss=0.03390916477911149
Epoch #63: loss=0.033422697460667984
Epoch #64: loss=0.0268341866828986
Epoch #65: loss=0.040631558757262584
Epoch #66: loss=0.02712830134431436
Epoch #67: loss=0.043082692720034246
Epoch #68: loss=0.03336709943370358
Epoch #69: loss=0.020936797548895575
Epoch #70: loss=0.025712957318030194
Epoch #71: loss=0.03203927673916141
Epoch #72: loss=0.02268848340058929
Epoch #73: loss=0.020551575241253187
Epoch #74: loss=0.026197021044726956
Epoch #75: loss=0.017814717523925876
Epoch #76: loss=0.027805754864805264
Epoch #77: loss=0.02596636935972851
Epoch #78: loss=0.0219817857629594
Epoch #79: loss=0.023649920459696386
Epoch #80: loss=0.03015611789425299
Epoch #81: loss=0.02096343489797556
Epoch #82: loss=0.030027869451242462
Epoch #83: loss=0.03063231218823117
Epoch #84: loss=0.03847377025681765
Epoch #85: loss=0.02426338689146589
Epoch #86: loss=0.024888392345188824
Epoch #87: loss=0.02152916459615457
Epoch #88: loss=0.02910438628663143
Epoch #89: loss=0.02046746708554764
Epoch #90: loss=0.05216995486574987
Epoch #91: loss=0.024881107297611154
Epoch #92: loss=0.021719415647564584
Epoch #93: loss=0.01980884114219743
Epoch #94: loss=0.02233409919594223
Epoch #95: loss=0.024345320521866623
Epoch #96: loss=0.014795076683138127
Epoch #97: loss=0.017753793190437534
Epoch #98: loss=0.019260597878856558
Epoch #99: loss=0.02192065751384178
Epoch #100: loss=0.01997093567784161
Epoch #101: loss=0.030272738928970408
Epoch #102: loss=0.019012872971058505
Epoch #103: loss=0.018918569908120145
Epoch #104: loss=0.027217558668990147
Epoch #105: loss=0.020682839909887375
Epoch #106: loss=0.01620420096266683
Epoch #107: loss=0.017401523607438556
Epoch #108: loss=0.02481760189370954
Epoch #109: loss=0.04564463433949915
Epoch #110: loss=0.03233747309431025
Epoch #111: loss=0.027954809369570385
Epoch #112: loss=0.0438315191719209
Epoch #113: loss=0.02214814615627266
Epoch #114: loss=0.015349981117968077
Epoch #115: loss=0.05459457909375787
Epoch #116: loss=0.021508915246024166
Epoch #117: loss=0.01683102253200933
Epoch #118: loss=0.020913117014713687
Epoch #119: loss=0.024487647203703042
Epoch #120: loss=0.02220331022758292
Epoch #121: loss=0.015284862130248843
Epoch #122: loss=0.029088834689910945
Epoch #123: loss=0.018993144444898025
Epoch #124: loss=0.021130253824609497
Epoch #125: loss=0.019041890026331713
Epoch #126: loss=0.013002520467295019
Epoch #127: loss=0.018060764085424886
Epoch #128: loss=0.014479173996170012
Epoch #129: loss=0.012047503862293973
Epoch #130: loss=0.018968798739401854
Epoch #131: loss=0.03448806464184101
Epoch #132: loss=0.03492049183632719
Epoch #133: loss=0.021751711485837266
Epoch #134: loss=0.018473386497887438
Epoch #135: loss=0.021759827477755407
Epoch #136: loss=0.016872714622239646
Epoch #137: loss=0.016512924748511144
Epoch #138: loss=0.02109793385072956
Epoch #139: loss=0.023387033924498684
Epoch #140: loss=0.016987255927691975
Epoch #141: loss=0.015424220725951385
Epoch #142: loss=0.018605565468378823
Epoch #143: loss=0.03334582652354434
Epoch #144: loss=0.01699489068881009
Epoch #145: loss=0.027285633283373835
Epoch #146: loss=0.01918094247381828
Epoch #147: loss=0.01975731229352165
Epoch #148: loss=0.016249364832007927
Epoch #149: loss=0.011835360598960917
Epoch #150: loss=0.012212252373366986
Epoch #151: loss=0.018473327208839815
Epoch #152: loss=0.014487968913234821
Epoch #153: loss=0.014390633674178987
Epoch #154: loss=0.01772086747462721
Epoch #155: loss=0.019914350271454617
Epoch #156: loss=0.02086504012575909
Epoch #157: loss=0.018161283692899988
Epoch #158: loss=0.014542012375760313
Epoch #159: loss=0.013763763118465113
Epoch #160: loss=0.019308212236740487
Epoch #161: loss=0.016952245082061942
Epoch #162: loss=0.01372773104238847
Epoch #163: loss=0.015455771074949266
Epoch #164: loss=0.017565420260397743
Epoch #165: loss=0.01436906850781955
Epoch #166: loss=0.016193812449577533
Epoch #167: loss=0.019056568008031034
Epoch #168: loss=0.01479034954235468
Epoch #169: loss=0.012075771657632
Epoch #170: loss=0.013913895951086426
Epoch #171: loss=0.012952799244691324
Epoch #172: loss=0.014540316273094704
Epoch #173: loss=0.017286947189689907
Epoch #174: loss=0.026889940230207746
Epoch #175: loss=0.01799456003976807
Epoch #176: loss=0.01280059629910919
Epoch #177: loss=0.014179845151494652
Epoch #178: loss=0.02631636953335383
Epoch #179: loss=0.015777014808295523
Epoch #180: loss=0.02385799913278028
Epoch #181: loss=0.01419799318010855
Epoch #182: loss=0.020820434664117735
Epoch #183: loss=0.014532440089403766
Epoch #184: loss=0.02739921684906346
Epoch #185: loss=0.015598409607119806
Epoch #186: loss=0.03110338549834536
Epoch #187: loss=0.021265471109575017
Epoch #188: loss=0.01918027058613729
Epoch #189: loss=0.030995766579951733
Epoch #190: loss=0.024717989349291238
Epoch #191: loss=0.02149049569653309
Epoch #192: loss=0.011069967142267994
Epoch #193: loss=0.01229332992384427
Epoch #194: loss=0.010388570867976404
Epoch #195: loss=0.02263619700344662
Epoch #196: loss=0.011947167876387041
Epoch #197: loss=0.013404690427227226
Epoch #198: loss=0.02931923615691979
Epoch #199: loss=0.020164078089714765
Epoch #200: loss=0.013959181984034941
Epoch #201: loss=0.011377470686310927
Epoch #202: loss=0.009839289749443071
Epoch #203: loss=0.017394793557070118
Epoch #204: loss=0.016029085146346166
Epoch #205: loss=0.013678487060967935
Epoch #206: loss=0.018178571616092137
Epoch #207: loss=0.013807621748148374
Epoch #208: loss=0.013572109666133095
Epoch #209: loss=0.011484549739892429
Epoch #210: loss=0.01912168080787723
Epoch #211: loss=0.02088954095802053
Epoch #212: loss=0.017256119816359897
Epoch #213: loss=0.021440166562368253
Epoch #214: loss=0.01793217741779039
Epoch #215: loss=0.013629584579588207
Epoch #216: loss=0.02893365739592772
Epoch #217: loss=0.013965449656825512
Epoch #218: loss=0.012794485183876034
Epoch #219: loss=0.010005986773925642
Epoch #220: loss=0.009399738128230053
Epoch #221: loss=0.014606009563829826
Epoch #222: loss=0.01075622702889744
Epoch #223: loss=0.010720746421609202
Epoch #224: loss=0.01098790045290203
Epoch #225: loss=0.018112118011946496
Epoch #226: loss=0.023116084490304698
Epoch #227: loss=0.018882735222514258
Epoch #228: loss=0.029168934841506337
Epoch #229: loss=0.022733369684771774
Epoch #230: loss=0.012148470514611825
Epoch #231: loss=0.011695976711631025
Epoch #232: loss=0.018454609784833473
Epoch #233: loss=0.010736669694577433
Epoch #234: loss=0.01031622680355412
Epoch #235: loss=0.02210547539456556
Epoch #236: loss=0.01521200382378756
Epoch #237: loss=0.009590564325829802
Epoch #238: loss=0.012514465583818454
Epoch #239: loss=0.023250823615562195
Epoch #240: loss=0.013425639589406449
Epoch #241: loss=0.009716521572379063
Epoch #242: loss=0.011323367771277943
Epoch #243: loss=0.015804967879076898
Epoch #244: loss=0.01958359241731184
Epoch #245: loss=0.010114045494494399
Epoch #246: loss=0.013941411521566445
Epoch #247: loss=0.014452883873090199
Epoch #248: loss=0.012922754151545694
Epoch #249: loss=0.021319795466563984

Training time: 1:42:21.299319

Finished.
n2one setting etth2_ettm2_electricity_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm2_electricity_weather_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_ettm2_electricity_weather', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.02135e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.31514310659271655, 'MAE': 0.377269060881558}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm2_electricity_exchange', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm2_electricity_exchange_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.6913970933867464
Epoch #1: loss=0.7148659729991935
Epoch #2: loss=0.4998072243217776
Epoch #3: loss=0.4100334956511984
Epoch #4: loss=0.3491619222445859
Epoch #5: loss=0.3079298173187445
Epoch #6: loss=0.26818584940619017
Epoch #7: loss=0.23134955304328578
Epoch #8: loss=0.2151605298565513
Epoch #9: loss=0.18837562977451755
Epoch #10: loss=0.18109467771623594
Epoch #11: loss=0.15640173856737977
Epoch #12: loss=0.14746898169003922
Epoch #13: loss=0.14527026562272471
Epoch #14: loss=0.12274987721327231
Epoch #15: loss=0.13587422909413704
Epoch #16: loss=0.1192770170675918
Epoch #17: loss=0.12062943807295833
Epoch #18: loss=0.11559481897340385
Epoch #19: loss=0.09080202929589694
Epoch #20: loss=0.0936204069710044
Epoch #21: loss=0.10284678361000177
Epoch #22: loss=0.09109491827261637
Epoch #23: loss=0.08802986268748553
Epoch #24: loss=0.08282122769465493
Epoch #25: loss=0.08559213808981933
Epoch #26: loss=0.07113469393939982
Epoch #27: loss=0.06628717267912644
Epoch #28: loss=0.06580785076705584
Epoch #29: loss=0.06961984646047656
Epoch #30: loss=0.05557322213949598
Epoch #31: loss=0.06963656188635645
Epoch #32: loss=0.06333584889436747
Epoch #33: loss=0.05331598174012124
Epoch #34: loss=0.06005179013799264
Epoch #35: loss=0.0555280414463614
Epoch #36: loss=0.062049126261254764
Epoch #37: loss=0.0453194214590699
Epoch #38: loss=0.04702537870490843
Epoch #39: loss=0.05340562559669617
Epoch #40: loss=0.04140806041311698
Epoch #41: loss=0.050478985505608
Epoch #42: loss=0.04078000245725881
Epoch #43: loss=0.03940443471020426
Epoch #44: loss=0.03385389420627925
Epoch #45: loss=0.0415947565672012
Epoch #46: loss=0.038232423844868024
Epoch #47: loss=0.05131682664993345
Epoch #48: loss=0.05227108025434896
Epoch #49: loss=0.05362490500807923
Epoch #50: loss=0.04418950352914395
Epoch #51: loss=0.04912642437578192
Epoch #52: loss=0.03130037181018328
Epoch #53: loss=0.04654005402665564
Epoch #54: loss=0.03332525807210064
Epoch #55: loss=0.03569052990805089
Epoch #56: loss=0.03877440156443286
Epoch #57: loss=0.042534781360236515
Epoch #58: loss=0.03213224380836696
Epoch #59: loss=0.035880380124256275
Epoch #60: loss=0.034037464649902295
Epoch #61: loss=0.03576361038051116
Epoch #62: loss=0.03683013815140239
Epoch #63: loss=0.03493225552686503
Epoch #64: loss=0.04618581051714128
Epoch #65: loss=0.03303905113423055
Epoch #66: loss=0.026001756357952353
Epoch #67: loss=0.06377313948324975
Epoch #68: loss=0.04206854927015386
Epoch #69: loss=0.05260002521545726
Epoch #70: loss=0.03214822211255848
Epoch #71: loss=0.030566663247793485
Epoch #72: loss=0.029034091856851314
Epoch #73: loss=0.03401304197347366
Epoch #74: loss=0.04010868264913763
Epoch #75: loss=0.03235129526546574
Epoch #76: loss=0.024797569345401047
Epoch #77: loss=0.029419768513086378
Epoch #78: loss=0.03254303618626782
Epoch #79: loss=0.03166063927162321
Epoch #80: loss=0.028108051377690804
Epoch #81: loss=0.02779758699581843
Epoch #82: loss=0.02353835024874958
Epoch #83: loss=0.027754910683101017
Epoch #84: loss=0.04992483445357327
Epoch #85: loss=0.03090341772913654
Epoch #86: loss=0.02044552265933476
Epoch #87: loss=0.023864333126331634
Epoch #88: loss=0.03008409819038322
Epoch #89: loss=0.029737004819017452
Epoch #90: loss=0.025573754797371572
Epoch #91: loss=0.020182422321170342
Epoch #92: loss=0.03752376123999785
Epoch #93: loss=0.031491978354993615
Epoch #94: loss=0.029091101746183554
Epoch #95: loss=0.02321877532289028
Epoch #96: loss=0.02477652432131299
Epoch #97: loss=0.0477546973144555
Epoch #98: loss=0.027635519011670814
Epoch #99: loss=0.024115866319020077
Epoch #100: loss=0.024860528828636597
Epoch #101: loss=0.02658400090767932
Epoch #102: loss=0.0247454186487119
Epoch #103: loss=0.023380649295536217
Epoch #104: loss=0.023831548952458623
Epoch #105: loss=0.03246990739507467
Epoch #106: loss=0.034835591603450275
Epoch #107: loss=0.03282359317002109
Epoch #108: loss=0.019392407885571453
Epoch #109: loss=0.014189955243144335
Epoch #110: loss=0.02231969691994828
Epoch #111: loss=0.030985864369810615
Epoch #112: loss=0.020306129490296417
Epoch #113: loss=0.016958162591286723
Epoch #114: loss=0.02486791689554766
Epoch #115: loss=0.03128745846795213
Epoch #116: loss=0.03122448956463701
Epoch #117: loss=0.028924622812331185
Epoch #118: loss=0.01966055901939189
Epoch #119: loss=0.020933437186644897
Epoch #120: loss=0.01698900632169742
Epoch #121: loss=0.02163949907607713
Epoch #122: loss=0.03087131298611461
Epoch #123: loss=0.02838907788624391
Epoch #124: loss=0.02827098874458426
Epoch #125: loss=0.013551079440809603
Epoch #126: loss=0.016873033841238533
Epoch #127: loss=0.019113291428700864
Epoch #128: loss=0.021146344485953022
Epoch #129: loss=0.0328992719403723
Epoch #130: loss=0.02110286031816804
Epoch #131: loss=0.020228653194155323
Epoch #132: loss=0.02110734636917501
Epoch #133: loss=0.025107418713096116
Epoch #134: loss=0.026516493422285216
Epoch #135: loss=0.024905439877382047
Epoch #136: loss=0.0301551999128692
Epoch #137: loss=0.020799401557906355
Epoch #138: loss=0.029386381586639195
Epoch #139: loss=0.018899936310682576
Epoch #140: loss=0.018375474901823594
Epoch #141: loss=0.01926888962966049
Epoch #142: loss=0.0297860599653688
Epoch #143: loss=0.04954134687255955
Epoch #144: loss=0.025958388842681226
Epoch #145: loss=0.032820702007077956
Epoch #146: loss=0.01995777121756121
Epoch #147: loss=0.013866374299070403
Epoch #148: loss=0.0155107966801675
Epoch #149: loss=0.010127628679549649
Epoch #150: loss=0.015916671388197464
Epoch #151: loss=0.014903142968104128
Epoch #152: loss=0.02423820649448149
Epoch #153: loss=0.027184434595916376
Epoch #154: loss=0.029179454158444054
Epoch #155: loss=0.019576092148991437
Epoch #156: loss=0.025230549368470565
Epoch #157: loss=0.022775615971590463
Epoch #158: loss=0.021438925873262737
Epoch #159: loss=0.024613732531276244
Epoch #160: loss=0.03359701792489447
Epoch #161: loss=0.029672585418367335
Epoch #162: loss=0.023521795029307766
Epoch #163: loss=0.03256729148228999
Epoch #164: loss=0.019112652722076493
Epoch #165: loss=0.0182756333176103
Epoch #166: loss=0.021956425176608653
Epoch #167: loss=0.030446910516423325
Epoch #168: loss=0.021705814166969463
Epoch #169: loss=0.015097118479163474
Epoch #170: loss=0.014530593819543183
Epoch #171: loss=0.012737072235971732
Epoch #172: loss=0.020246393664911797
Epoch #173: loss=0.014466091555339266
Epoch #174: loss=0.0161989183495256
Epoch #175: loss=0.02166540640800848
Epoch #176: loss=0.025966083234033793
Epoch #177: loss=0.03382191816827964
Epoch #178: loss=0.019613850517909683
Epoch #179: loss=0.02504684408034281
Epoch #180: loss=0.015239748738686653
Epoch #181: loss=0.01950483928201049
Epoch #182: loss=0.020274918318742226
Epoch #183: loss=0.020394536009681028
Epoch #184: loss=0.012591370459835874
Epoch #185: loss=0.021537401054956717
Epoch #186: loss=0.01716299282782107
Epoch #187: loss=0.024478083437591152
Epoch #188: loss=0.02434636051337146
Epoch #189: loss=0.02064220711500961
Epoch #190: loss=0.031982764305133554
Epoch #191: loss=0.01604778007339144
Epoch #192: loss=0.01449430736963723
Epoch #193: loss=0.0214453085172339
Epoch #194: loss=0.023337968874733456
Epoch #195: loss=0.01905266733730067
Epoch #196: loss=0.011860010775090638
Epoch #197: loss=0.014458059403717905
Epoch #198: loss=0.022708084070850405
Epoch #199: loss=0.022983599310071188
Epoch #200: loss=0.0153565266357818
Epoch #201: loss=0.01706914744775686
Epoch #202: loss=0.021316791500212484
Epoch #203: loss=0.017662260582840327
Epoch #204: loss=0.022470731395048488
Epoch #205: loss=0.017196821728224735
Epoch #206: loss=0.013293161996477888
Epoch #207: loss=0.01928028333878483
Epoch #208: loss=0.016678080967525478
Epoch #209: loss=0.014681252664503956
Epoch #210: loss=0.025368644726752525
Epoch #211: loss=0.01930108910070206
Epoch #212: loss=0.02845243179666748
Epoch #213: loss=0.02624756408089058
Epoch #214: loss=0.02200216526490695
Epoch #215: loss=0.01710923374006498
Epoch #216: loss=0.014574164177357522
Epoch #217: loss=0.014353152031517756
Epoch #218: loss=0.013199260161440787
Epoch #219: loss=0.013120654342452505
Epoch #220: loss=0.02447654971948849
Epoch #221: loss=0.024996391373420784
Epoch #222: loss=0.02538240947654962
Epoch #223: loss=0.02549769534254366
Epoch #224: loss=0.015287636946490898
Epoch #225: loss=0.014741932306477601
Epoch #226: loss=0.023501343895887195
Epoch #227: loss=0.012398238150404245
Epoch #228: loss=0.01677898862211286
Epoch #229: loss=0.013615651052815555
Epoch #230: loss=0.011560364526539493
Epoch #231: loss=0.017634304521655025
Epoch #232: loss=0.011300976572927994
Epoch #233: loss=0.017871053044795613
Epoch #234: loss=0.017571080580215514
Epoch #235: loss=0.015295680312061365
Epoch #236: loss=0.014614479714247695
Epoch #237: loss=0.010017004548618973
Epoch #238: loss=0.019998372385230705
Epoch #239: loss=0.016738424480554542
Epoch #240: loss=0.015844559006766023
Epoch #241: loss=0.019258305618538783
Epoch #242: loss=0.015007325395675354
Epoch #243: loss=0.013241436092420521
Epoch #244: loss=0.011678889459898154
Epoch #245: loss=0.024349690924072503
Epoch #246: loss=0.013957931152182586
Epoch #247: loss=0.01651026680000376
Epoch #248: loss=0.019346526248067864
Epoch #249: loss=0.016559309415436707

Training time: 1:34:35.337623

Finished.
n2one setting etth2_ettm2_electricity_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm2_electricity_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_ettm2_electricity_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.38737e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.84037e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.38737e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.545982406690919, 'MAE': 0.5719121595899275}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm2_traffic_weather', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm2_traffic_weather_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.0413969925565698
Epoch #1: loss=0.40248406015616117
Epoch #2: loss=0.30020469311156023
Epoch #3: loss=0.22796536570057174
Epoch #4: loss=0.1863341396078303
Epoch #5: loss=0.15111348174808437
Epoch #6: loss=0.13603645225135697
Epoch #7: loss=0.11850420218043309
Epoch #8: loss=0.10035785685024054
Epoch #9: loss=0.0993146218429371
Epoch #10: loss=0.08339242538988229
Epoch #11: loss=0.07156736488920733
Epoch #12: loss=0.0746201970961426
Epoch #13: loss=0.06338533521737805
Epoch #14: loss=0.051328704747418664
Epoch #15: loss=0.060459579470121275
Epoch #16: loss=0.053732012556588264
Epoch #17: loss=0.04628813900536637
Epoch #18: loss=0.049790666386984685
Epoch #19: loss=0.05201211833615045
Epoch #20: loss=0.049385579620800486
Epoch #21: loss=0.03854562543645074
Epoch #22: loss=0.037016429367478294
Epoch #23: loss=0.03782306568235545
Epoch #24: loss=0.03673744638384655
Epoch #25: loss=0.03584522811172193
Epoch #26: loss=0.04035125258090858
Epoch #27: loss=0.03281292980385196
Epoch #28: loss=0.028258836253997964
Epoch #29: loss=0.046937239252002064
Epoch #30: loss=0.030304676573582212
Epoch #31: loss=0.03072208154712193
Epoch #32: loss=0.03880046299688526
Epoch #33: loss=0.030014319871793857
Epoch #34: loss=0.024515295107221894
Epoch #35: loss=0.029191517087355436
Epoch #36: loss=0.02718399835724248
Epoch #37: loss=0.03025476193293481
Epoch #38: loss=0.03829058642572647
Epoch #39: loss=0.01942107715202181
Epoch #40: loss=0.022080167127047433
Epoch #41: loss=0.02834195125473881
Epoch #42: loss=0.028026692098776028
Epoch #43: loss=0.02702365112553914
Epoch #44: loss=0.0263879222534011
Epoch #45: loss=0.023398817552134875
Epoch #46: loss=0.03066929687874877
Epoch #47: loss=0.03490556059117381
Epoch #48: loss=0.024879769730434608
Epoch #49: loss=0.02107744723359646
Epoch #50: loss=0.02333370156015144
Epoch #51: loss=0.02204455466120952
Epoch #52: loss=0.02535681733445246
Epoch #53: loss=0.025282097488570295
Epoch #54: loss=0.02087904206058473
Epoch #55: loss=0.026953108834036447
Epoch #56: loss=0.022127870636749047
Epoch #57: loss=0.018937714642109596
Epoch #58: loss=0.02105450549612781
Epoch #59: loss=0.020085045612002382
Epoch #60: loss=0.025136708010362756
Epoch #61: loss=0.02189346479639261
Epoch #62: loss=0.02281916897268385
Epoch #63: loss=0.017014990234946695
Epoch #64: loss=0.017559109662032932
Epoch #65: loss=0.022853026927241164
Epoch #66: loss=0.017780282206951704
Epoch #67: loss=0.020499886398084942
Epoch #68: loss=0.018686122567445312
Epoch #69: loss=0.018303084631605182
Epoch #70: loss=0.02693992887803371
Epoch #71: loss=0.0184130391577453
Epoch #72: loss=0.015545862138076792
Epoch #73: loss=0.018901743632756693
Epoch #74: loss=0.025597932995975462
Epoch #75: loss=0.019019919821356986
Epoch #76: loss=0.023766788786924013
Epoch #77: loss=0.014867333485558578
Epoch #78: loss=0.018295404781407787
Epoch #79: loss=0.020241265216144316
Epoch #80: loss=0.014852495248580844
Epoch #81: loss=0.018986394009028643
Epoch #82: loss=0.02579857293221119
Epoch #83: loss=0.02054945369325342
Epoch #84: loss=0.015766395741179853
Epoch #85: loss=0.022729241260961902
Epoch #86: loss=0.02327085399376249
Epoch #87: loss=0.018040847881738493
Epoch #88: loss=0.017232537470010384
Epoch #89: loss=0.020690150620593387
Epoch #90: loss=0.012878202480519968
Epoch #91: loss=0.017462476322376765
Epoch #92: loss=0.020511801956130487
Epoch #93: loss=0.012056188968674046
Epoch #94: loss=0.011919116272267443
Epoch #95: loss=0.01424642912988568
Epoch #96: loss=0.023136963511984972
Epoch #97: loss=0.023805960916437847
Epoch #98: loss=0.014350155062278862
Epoch #99: loss=0.016223297796145834
Epoch #100: loss=0.014753534700659826
Epoch #101: loss=0.01488299832920771
Epoch #102: loss=0.013651890035685399
Epoch #103: loss=0.019363564423923525
Epoch #104: loss=0.01428396377245285
Epoch #105: loss=0.01736875410396277
Epoch #106: loss=0.03211272559878463
Epoch #107: loss=0.020867729860376702
Epoch #108: loss=0.012714963403561772
Epoch #109: loss=0.010365604040942517
Epoch #110: loss=0.014478509596112866
Epoch #111: loss=0.015989730919751255
Epoch #112: loss=0.014043111488709811
Epoch #113: loss=0.020343201986078953
Epoch #114: loss=0.01619551464325875
Epoch #115: loss=0.01650804174771259
Epoch #116: loss=0.01639574670042533
Epoch #117: loss=0.011817454873372454
Epoch #118: loss=0.02188206598096862
Epoch #119: loss=0.01390510529462684
Epoch #120: loss=0.01506841130504949
Epoch #121: loss=0.01631570175551528
Epoch #122: loss=0.009342700197196357
Epoch #123: loss=0.013813535002318088
Epoch #124: loss=0.013914838260521924
Epoch #125: loss=0.019517457039621256
Epoch #126: loss=0.01848845831782194
Epoch #127: loss=0.012091894068775897
Epoch #128: loss=0.012910187101418072
Epoch #129: loss=0.009178603387397413
Epoch #130: loss=0.010613979791264331
Epoch #131: loss=0.015597510919315128
Epoch #132: loss=0.01473781632792705
Epoch #133: loss=0.015683339014434805
Epoch #134: loss=0.012249347353918184
Epoch #135: loss=0.012803221421527509
Epoch #136: loss=0.021763742133249296
Epoch #137: loss=0.011601510736172573
Epoch #138: loss=0.013697632697151838
Epoch #139: loss=0.02840471511006692
Epoch #140: loss=0.009629991406568549
Epoch #141: loss=0.00938939103600916
Epoch #142: loss=0.022110135279358845
Epoch #143: loss=0.016439900521001888
Epoch #144: loss=0.016311247049381833
Epoch #145: loss=0.012393024326201244
Epoch #146: loss=0.013622487093504264
Epoch #147: loss=0.011088493308188624
Epoch #148: loss=0.013032624493673019
Epoch #149: loss=0.01726171361886003
Epoch #150: loss=0.010205412345457689
Epoch #151: loss=0.013409666942173479
Epoch #152: loss=0.018074172412288602
Epoch #153: loss=0.012574272339551445
Epoch #154: loss=0.015971717392246055
Epoch #155: loss=0.010565248629388967
Epoch #156: loss=0.01094656354507606
Epoch #157: loss=0.017930416978801093
Epoch #158: loss=0.015240798469150498
Epoch #159: loss=0.010578453594576629
Epoch #160: loss=0.010369380889993694
Epoch #161: loss=0.012847642753945013
Epoch #162: loss=0.015370689645736858
Epoch #163: loss=0.011585014653652978
Epoch #164: loss=0.014062672049002712
Epoch #165: loss=0.010949944852885767
Epoch #166: loss=0.010030249546540394
Epoch #167: loss=0.012744874178514679
Epoch #168: loss=0.009910166018350033
Epoch #169: loss=0.010077114530604397
Epoch #170: loss=0.0165617865385389
Epoch #171: loss=0.010884980323082494
Epoch #172: loss=0.012008051518844577
Epoch #173: loss=0.012914053328171712
Epoch #174: loss=0.01239783028867296
Epoch #175: loss=0.011680204456352573
Epoch #176: loss=0.013146969909799258
Epoch #177: loss=0.01625098801854274
Epoch #178: loss=0.0158164796726092
Epoch #179: loss=0.012298880550704811
Epoch #180: loss=0.01357525029444808
Epoch #181: loss=0.012806933200517238
Epoch #182: loss=0.00907883157286866
Epoch #183: loss=0.015081937268718659
Epoch #184: loss=0.010893487241243786
Epoch #185: loss=0.007930344339947383
Epoch #186: loss=0.01169220757676547
Epoch #187: loss=0.017762443667512066
Epoch #188: loss=0.012930912225627084
Epoch #189: loss=0.009472954108883606
Epoch #190: loss=0.013509651323530882
Epoch #191: loss=0.01733288018762239
Epoch #192: loss=0.012479099031825211
Epoch #193: loss=0.008414688054745257
Epoch #194: loss=0.011316595337586607
Epoch #195: loss=0.01158897934141186
Epoch #196: loss=0.008616849364212737
Epoch #197: loss=0.011334676379379105
Epoch #198: loss=0.010185605607395266
Epoch #199: loss=0.011962101440827252
Epoch #200: loss=0.00823096536431039
Epoch #201: loss=0.012780867542725347
Epoch #202: loss=0.012470510055044529
Epoch #203: loss=0.011934705108492693
Epoch #204: loss=0.010465906786692028
Epoch #205: loss=0.012334494923839446
Epoch #206: loss=0.020974844579617534
Epoch #207: loss=0.010618892828077485
Epoch #208: loss=0.010933436969164465
Epoch #209: loss=0.01382327065183289
Epoch #210: loss=0.009479540124395246
Epoch #211: loss=0.015477249135849067
Epoch #212: loss=0.013271299829256436
Epoch #213: loss=0.017286527047468817
Epoch #214: loss=0.010975756483193884
Epoch #215: loss=0.009219117752484778
Epoch #216: loss=0.014906573567529367
Epoch #217: loss=0.00988183617996292
Epoch #218: loss=0.013243683356158647
Epoch #219: loss=0.014870190740509394
Epoch #220: loss=0.010824347845840583
Epoch #221: loss=0.007566035445341077
Epoch #222: loss=0.010853083396571274
Epoch #223: loss=0.00985627434114994
Epoch #224: loss=0.010838157069751383
Epoch #225: loss=0.016395620243157678
Epoch #226: loss=0.009817542934104868
Epoch #227: loss=0.012588284406318867
Epoch #228: loss=0.011025275975577821
Epoch #229: loss=0.0101904836908614
Epoch #230: loss=0.01206567703635626
Epoch #231: loss=0.01166233379854723
Epoch #232: loss=0.009831286655974351
Epoch #233: loss=0.012349966732992237
Epoch #234: loss=0.012976909696622279
Epoch #235: loss=0.01058991482830478
Epoch #236: loss=0.010781750773591356
Epoch #237: loss=0.010817546413284439
Epoch #238: loss=0.010454378918683975
Epoch #239: loss=0.011763602138960669
Epoch #240: loss=0.008836834954469486
Epoch #241: loss=0.010113774126434901
Epoch #242: loss=0.011886416644259627
Epoch #243: loss=0.008763165626226832
Epoch #244: loss=0.007834116587819193
Epoch #245: loss=0.008383673134384005
Epoch #246: loss=0.0214452871302559
Epoch #247: loss=0.00903052259947787
Epoch #248: loss=0.013724880793253829
Epoch #249: loss=0.011173517331594697

Training time: 3:40:00.504930

Finished.
n2one setting etth2_ettm2_traffic_weather -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm2_traffic_weather_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_ettm2_traffic_weather', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.48744e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.94021e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.90765e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.48744e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4271469503562852, 'MAE': 0.46588369157958526}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm2_traffic_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm2_traffic_weather_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_ettm2_traffic_weather', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.46512e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.279884213733909, 'MAE': 0.35146398458663225}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm2_traffic_exchange', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm2_traffic_exchange_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.005843609890288
Epoch #1: loss=0.3931820752887844
Epoch #2: loss=0.274678477262323
Epoch #3: loss=0.20765856614437056
Epoch #4: loss=0.17808147240430117
Epoch #5: loss=0.14076962084341627
Epoch #6: loss=0.11287719423689686
Epoch #7: loss=0.09755868182165196
Epoch #8: loss=0.09371739895573843
Epoch #9: loss=0.08383805775356286
Epoch #10: loss=0.07524236910378661
Epoch #11: loss=0.06249608838960092
Epoch #12: loss=0.06505424903835766
Epoch #13: loss=0.062362246889975506
Epoch #14: loss=0.05893699920590472
Epoch #15: loss=0.054092116324338003
Epoch #16: loss=0.04992622543343443
Epoch #17: loss=0.044086553012036615
Epoch #18: loss=0.0498082101314123
Epoch #19: loss=0.0409917774360348
Epoch #20: loss=0.04761595549329335
Epoch #21: loss=0.048371554689396905
Epoch #22: loss=0.03815183815780213
Epoch #23: loss=0.03697466600105808
Epoch #24: loss=0.03248994607598466
Epoch #25: loss=0.04269912383578894
Epoch #26: loss=0.03235276296697054
Epoch #27: loss=0.028820365055113914
Epoch #28: loss=0.03592856841813143
Epoch #29: loss=0.036443155823075654
Epoch #30: loss=0.03077058467071667
Epoch #31: loss=0.031497760973047455
Epoch #32: loss=0.03233224296153666
Epoch #33: loss=0.03569795700414935
Epoch #34: loss=0.030412646417316207
Epoch #35: loss=0.03551465672569828
Epoch #36: loss=0.033542508293304546
Epoch #37: loss=0.026724096782558476
Epoch #38: loss=0.028034809563725324
Epoch #39: loss=0.035133474051657655
Epoch #40: loss=0.025545714205043885
Epoch #41: loss=0.027275064218433277
Epoch #42: loss=0.02567544786057903
Epoch #43: loss=0.03197550832798394
Epoch #44: loss=0.030202018256917457
Epoch #45: loss=0.025643865320825507
Epoch #46: loss=0.027914229154572107
Epoch #47: loss=0.024367820859445166
Epoch #48: loss=0.023196558813094622
Epoch #49: loss=0.02268020655623053
Epoch #50: loss=0.028958148981834162
Epoch #51: loss=0.03387092994959964
Epoch #52: loss=0.024545443535316736
Epoch #53: loss=0.01865617458417284
Epoch #54: loss=0.02390110856399301
Epoch #55: loss=0.025835700621862523
Epoch #56: loss=0.037264763810034726
Epoch #57: loss=0.020006650025475987
Epoch #58: loss=0.021730422428329288
Epoch #59: loss=0.01842428228773569
Epoch #60: loss=0.02664159265226739
Epoch #61: loss=0.022642305831968686
Epoch #62: loss=0.026198092548896115
Epoch #63: loss=0.01878503052671681
Epoch #64: loss=0.024792308821758466
Epoch #65: loss=0.025520106046151177
Epoch #66: loss=0.03613045385393455
Epoch #67: loss=0.019638538189512375
Epoch #68: loss=0.024132198761746933
Epoch #69: loss=0.022148209676267905
Epoch #70: loss=0.02248343701301581
Epoch #71: loss=0.021240161756092373
Epoch #72: loss=0.020600995980924193
Epoch #73: loss=0.023441459670360567
Epoch #74: loss=0.025376449840739557
Epoch #75: loss=0.025397077777597588
Epoch #76: loss=0.01812245202817648
Epoch #77: loss=0.016122727085776452
Epoch #78: loss=0.019671243909829786
Epoch #79: loss=0.018178787690795527
Epoch #80: loss=0.02424130715148708
Epoch #81: loss=0.021440272408752306
Epoch #82: loss=0.020987219853129506
Epoch #83: loss=0.02477760277149689
Epoch #84: loss=0.015938199911328707
Epoch #85: loss=0.018980038472921127
Epoch #86: loss=0.01779495298238167
Epoch #87: loss=0.016136948090813046
Epoch #88: loss=0.01869616473322002
Epoch #89: loss=0.022099350319573812
Epoch #90: loss=0.016166656216113438
Epoch #91: loss=0.018324163670002037
Epoch #92: loss=0.018727641096398934
Epoch #93: loss=0.018290484329210467
Epoch #94: loss=0.013756669090825043
Epoch #95: loss=0.018275126294316282
Epoch #96: loss=0.016506596878989022
Epoch #97: loss=0.023396191248884698
Epoch #98: loss=0.0223834777932204
Epoch #99: loss=0.017950144668698608
Epoch #100: loss=0.013509380773652706
Epoch #101: loss=0.019926107789115532
Epoch #102: loss=0.020333422104617516
Epoch #103: loss=0.02309968423847946
Epoch #104: loss=0.016969196326720743
Epoch #105: loss=0.01778938899758384
Epoch #106: loss=0.0194334413383724
Epoch #107: loss=0.01726225767718436
Epoch #108: loss=0.015297065121263291
Epoch #109: loss=0.01728433135842253
Epoch #110: loss=0.013905719492171769
Epoch #111: loss=0.015877773752599914
Epoch #112: loss=0.018667362861559192
Epoch #113: loss=0.018458476216822804
Epoch #114: loss=0.019192535621957038
Epoch #115: loss=0.01532887698818855
Epoch #116: loss=0.017617262413828563
Epoch #117: loss=0.01328674380269362
Epoch #118: loss=0.02090074762423142
Epoch #119: loss=0.012821780362968525
Epoch #120: loss=0.01710295676493515
Epoch #121: loss=0.019881258600484265
Epoch #122: loss=0.016272346913922833
Epoch #123: loss=0.01773415108123896
Epoch #124: loss=0.016039682951609516
Epoch #125: loss=0.018778743938251078
Epoch #126: loss=0.013599551304028241
Epoch #127: loss=0.01597022465078201
Epoch #128: loss=0.015181563840857823
Epoch #129: loss=0.01228229386486435
Epoch #130: loss=0.016559624286618363
Epoch #131: loss=0.015384510940133917
Epoch #132: loss=0.027032827968657518
Epoch #133: loss=0.014906050669712902
Epoch #134: loss=0.01651567376036116
Epoch #135: loss=0.01301606159835796
Epoch #136: loss=0.01970986872992079
Epoch #137: loss=0.018219203653725428
Epoch #138: loss=0.013505287986763424
Epoch #139: loss=0.01627079430204708
Epoch #140: loss=0.01236000780884317
Epoch #141: loss=0.017776829323912016
Epoch #142: loss=0.0137509413050318
Epoch #143: loss=0.013397200663848297
Epoch #144: loss=0.012830873906316376
Epoch #145: loss=0.018883798921042645
Epoch #146: loss=0.01435651536349224
Epoch #147: loss=0.016188191885334702
Epoch #148: loss=0.016054066662921262
Epoch #149: loss=0.017117710804955055
Epoch #150: loss=0.013306928004460936
Epoch #151: loss=0.016300423219781642
Epoch #152: loss=0.01652721935973098
Epoch #153: loss=0.019647444893249683
Epoch #154: loss=0.010697707485592177
Epoch #155: loss=0.012641865616436966
Epoch #156: loss=0.012251065617264275
Epoch #157: loss=0.013453454335503592
Epoch #158: loss=0.016638141633151676
Epoch #159: loss=0.013896064578361105
Epoch #160: loss=0.012917554408944
Epoch #161: loss=0.015260528462886624
Epoch #162: loss=0.015239635499374918
Epoch #163: loss=0.01286410356190138
Epoch #164: loss=0.013599449800584897
Epoch #165: loss=0.01300762470585854
Epoch #166: loss=0.017013064628454314
Epoch #167: loss=0.01629369406149275
Epoch #168: loss=0.014661282658388708
Epoch #169: loss=0.015254309004900803
Epoch #170: loss=0.014260103738362543
Epoch #171: loss=0.015856958902749047
Epoch #172: loss=0.015315238229418724
Epoch #173: loss=0.013785591879298465
Epoch #174: loss=0.01455974715294737
Epoch #175: loss=0.013915358034438698
Epoch #176: loss=0.014111790885467886
Epoch #177: loss=0.01502167077823951
Epoch #178: loss=0.016160508414818527
Epoch #179: loss=0.011992227017250476
Epoch #180: loss=0.014849780660320853
Epoch #181: loss=0.011261861298473444
Epoch #182: loss=0.013421614281223565
Epoch #183: loss=0.024734554079800176
Epoch #184: loss=0.02050846812441402
Epoch #185: loss=0.011040364504715235
Epoch #186: loss=0.01159648164199704
Epoch #187: loss=0.015110498780183031
Epoch #188: loss=0.012532587546170485
Epoch #189: loss=0.015076875762780866
Epoch #190: loss=0.016823839837580873
Epoch #191: loss=0.012523738762497119
Epoch #192: loss=0.010770593800394258
Epoch #193: loss=0.01616562186606094
Epoch #194: loss=0.014723751279496617
Epoch #195: loss=0.01281846513194142
Epoch #196: loss=0.010560556968804114
Epoch #197: loss=0.01433868071030333
Epoch #198: loss=0.020522192615710477
Epoch #199: loss=0.01445937821318665
Epoch #200: loss=0.014459996627494122
Epoch #201: loss=0.015131896680703666
Epoch #202: loss=0.012647206657830949
Epoch #203: loss=0.015354908255389304
Epoch #204: loss=0.012552836901499881
Epoch #205: loss=0.009062073092397302
Epoch #206: loss=0.014457916952270753
Epoch #207: loss=0.011295322148644036
Epoch #208: loss=0.011751476402161381
Epoch #209: loss=0.012618857718792299
Epoch #210: loss=0.02118010473908283
Epoch #211: loss=0.0176673579581794
Epoch #212: loss=0.020914458424568193
Epoch #213: loss=0.013610924696590414
Epoch #214: loss=0.009205507544433826
Epoch #215: loss=0.011906271014251272
Epoch #216: loss=0.015205414667762271
Epoch #217: loss=0.017571609797504696
Epoch #218: loss=0.009869043904243651
Epoch #219: loss=0.013470852068273522
Epoch #220: loss=0.01332135867427873
Epoch #221: loss=0.015703317497690814
Epoch #222: loss=0.010067837693183007
Epoch #223: loss=0.014645596282305731
Epoch #224: loss=0.012211336134331193
Epoch #225: loss=0.015020259731754122
Epoch #226: loss=0.010553769845763134
Epoch #227: loss=0.013667560951866485
Epoch #228: loss=0.009092409841844175
Epoch #229: loss=0.012253071306380056
Epoch #230: loss=0.011888728324577044
Epoch #231: loss=0.009678767791925353
Epoch #232: loss=0.01874693208717233
Epoch #233: loss=0.016021510567723225
Epoch #234: loss=0.01600344403178079
Epoch #235: loss=0.015362146005639073
Epoch #236: loss=0.010468622534693798
Epoch #237: loss=0.00980486379337169
Epoch #238: loss=0.014660047568680524
Epoch #239: loss=0.01237926920906715
Epoch #240: loss=0.012508627051559145
Epoch #241: loss=0.01324371684936236
Epoch #242: loss=0.01735682763665118
Epoch #243: loss=0.019109805316819238
Epoch #244: loss=0.011003363813198358
Epoch #245: loss=0.010918290416583175
Epoch #246: loss=0.009849217766181405
Epoch #247: loss=0.011589861647784395
Epoch #248: loss=0.011813791607498136
Epoch #249: loss=0.010167418715207384

Training time: 3:27:27.591033

Finished.
n2one setting etth2_ettm2_traffic_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm2_traffic_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_ettm2_traffic_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.8474e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.03709e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.08034e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.8474e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4182028618315343, 'MAE': 0.4605238180951777}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm2_traffic_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm2_traffic_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_ettm2_traffic_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.27567e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.62448e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.27567e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.5485116516159355, 'MAE': 0.5717914656094896}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm2_weather_exchange', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm2_weather_exchange_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=4.173216180159495
Epoch #1: loss=2.343906675393765
Epoch #2: loss=2.2865958099181833
Epoch #3: loss=1.9713420065549703
Epoch #4: loss=1.8982120981583228
Epoch #5: loss=1.7411191646869366
Epoch #6: loss=1.5157816134966338
Epoch #7: loss=1.4218802314538221
Epoch #8: loss=1.3046385175906694
Epoch #9: loss=1.2615301677813897
Epoch #10: loss=1.1987665513387094
Epoch #11: loss=1.110536434329473
Epoch #12: loss=1.1057935265394359
Epoch #13: loss=1.0972134184378843
Epoch #14: loss=1.0284652744348233
Epoch #15: loss=0.9698711026173371
Epoch #16: loss=1.0381995370754828
Epoch #17: loss=1.0007266356394842
Epoch #18: loss=0.8996632592036173
Epoch #19: loss=0.9038210522670013
Epoch #20: loss=0.8576507201561561
Epoch #21: loss=0.8129631200662026
Epoch #22: loss=0.8080355536479217
Epoch #23: loss=0.7604067274011098
Epoch #24: loss=0.7503875494003296
Epoch #25: loss=0.7741647821206313
Epoch #26: loss=0.7377062841103628
Epoch #27: loss=0.6535158071380395
Epoch #28: loss=0.7102861656592443
Epoch #29: loss=0.6676932716598878
Epoch #30: loss=0.7320753364608839
Epoch #31: loss=0.6970243826508522
Epoch #32: loss=0.6436201402774224
Epoch #33: loss=0.5735208741747416
Epoch #34: loss=0.615257957806954
Epoch #35: loss=0.6926738419211828
Epoch #36: loss=0.6004829527093813
Epoch #37: loss=0.6593273528493367
Epoch #38: loss=0.5874362192474879
Epoch #39: loss=0.544613639322611
Epoch #40: loss=0.5557362242386892
Epoch #41: loss=0.5165045817310994
Epoch #42: loss=0.479662319788566
Epoch #43: loss=0.4665311792722115
Epoch #44: loss=0.4741154012198632
Epoch #45: loss=0.50043285294221
Epoch #46: loss=0.4542112940779099
Epoch #47: loss=0.4708243115590169
Epoch #48: loss=0.5422793237062601
Epoch #49: loss=0.49509281435838115
Epoch #50: loss=0.44427381541866523
Epoch #51: loss=0.45466465617601687
Epoch #52: loss=0.41941321841799295
Epoch #53: loss=0.372897727558246
Epoch #54: loss=0.4229129400963967
Epoch #55: loss=0.46927293504659945
Epoch #56: loss=0.4040084234797038
Epoch #57: loss=0.4639062915857022
Epoch #58: loss=0.43048942633546317
Epoch #59: loss=0.40544352623132557
Epoch #60: loss=0.371593420035564
Epoch #61: loss=0.3586515231201282
Epoch #62: loss=0.40231548794187033
Epoch #63: loss=0.46852028742432594
Epoch #64: loss=0.4390901897389155
Epoch #65: loss=0.35671696668634045
Epoch #66: loss=0.3854857408083402
Epoch #67: loss=0.34488972935539025
Epoch #68: loss=0.3528129630363904
Epoch #69: loss=0.29321279720618176
Epoch #70: loss=0.28836306227514374
Epoch #71: loss=0.28694916731463027
Epoch #72: loss=0.33305992300693804
Epoch #73: loss=0.27661213436378884
Epoch #74: loss=0.24859450542582914
Epoch #75: loss=0.2836422539101197
Epoch #76: loss=0.3384000508544537
Epoch #77: loss=0.2566984328799523
Epoch #78: loss=0.2961657621826117
Epoch #79: loss=0.3361876214352938
Epoch #80: loss=0.3762124703767208
Epoch #81: loss=0.42115608488137907
Epoch #82: loss=0.3650168643261378
Epoch #83: loss=0.2457479085200108
Epoch #84: loss=0.29797177403592146
Epoch #85: loss=0.2434284666982981
Epoch #86: loss=0.2539586675568269
Epoch #87: loss=0.33858710169219053
Epoch #88: loss=0.25623154633033735
Epoch #89: loss=0.2566060640920813
Epoch #90: loss=0.2656039979595404
Epoch #91: loss=0.24905061105696055
Epoch #92: loss=0.19213405466423586
Epoch #93: loss=0.24979012817717516
Epoch #94: loss=0.22481195241785967
Epoch #95: loss=0.18213721952186182
Epoch #96: loss=0.19447349907400516
Epoch #97: loss=0.21580005035950586
Epoch #98: loss=0.20198789439522302
Epoch #99: loss=0.19861629132467967
Epoch #100: loss=0.22235880584384388
Epoch #101: loss=0.17859585174860862
Epoch #102: loss=0.17363394897144574
Epoch #103: loss=0.18078575311945036
Epoch #104: loss=0.2081021424382925
Epoch #105: loss=0.17483663881340852
Epoch #106: loss=0.24762191558973148
Epoch #107: loss=0.24591445184957522
Epoch #108: loss=0.21797996694938496
Epoch #109: loss=0.18959305055726033
Epoch #110: loss=0.1511451336196982
Epoch #111: loss=0.16770043689757586
Epoch #112: loss=0.17566104870862687
Epoch #113: loss=0.1735617324280051
Epoch #114: loss=0.15450995265004727
Epoch #115: loss=0.18846429318476182
Epoch #116: loss=0.1656897391837377
Epoch #117: loss=0.1656843675300479
Epoch #118: loss=0.19806777069774958
Epoch #119: loss=0.21131610340223864
Epoch #120: loss=0.19889768141393477
Epoch #121: loss=0.21797497219477707
Epoch #122: loss=0.17908651202630538
Epoch #123: loss=0.16960047206913048
Epoch #124: loss=0.2177182327096279
Epoch #125: loss=0.17299973828574786
Epoch #126: loss=0.16309311946567434
Epoch #127: loss=0.1694725284066338
Epoch #128: loss=0.1530462114426952
Epoch #129: loss=0.20629962325955814
Epoch #130: loss=0.15940948941100103
Epoch #131: loss=0.1620807540602982
Epoch #132: loss=0.1525091826915741
Epoch #133: loss=0.15639085379930642
Epoch #134: loss=0.19926739219002998
Epoch #135: loss=0.2544916823076514
Epoch #136: loss=0.25100103808710206
Epoch #137: loss=0.22713509796617123
Epoch #138: loss=0.17540492593812254
Epoch #139: loss=0.16839543722856504
Epoch #140: loss=0.14689031866594002
Epoch #141: loss=0.19325342147539443
Epoch #142: loss=0.17237618587051445
Epoch #143: loss=0.15346677107020065
Epoch #144: loss=0.1699421523998563
Epoch #145: loss=0.18312717236291903
Epoch #146: loss=0.15265748714311764
Epoch #147: loss=0.17842117202683136
Epoch #148: loss=0.163149669014204
Epoch #149: loss=0.13852327818480822
Epoch #150: loss=0.1161760609382047
Epoch #151: loss=0.13848133553535893
Epoch #152: loss=0.1504493560642004
Epoch #153: loss=0.13529587168103227
Epoch #154: loss=0.1372556798518277
Epoch #155: loss=0.12858936767308757
Epoch #156: loss=0.16654523422655004
Epoch #157: loss=0.13034867892901486
Epoch #158: loss=0.13439380588869637
Epoch #159: loss=0.1270029774078956
Epoch #160: loss=0.13318852618193397
Epoch #161: loss=0.12940076942770526
Epoch #162: loss=0.1508791186631872
Epoch #163: loss=0.1423629155346694
Epoch #164: loss=0.18150970142764541
Epoch #165: loss=0.2653381171134802
Epoch #166: loss=0.25936728350531596
Epoch #167: loss=0.22834801852989656
Epoch #168: loss=0.1657211656610553
Epoch #169: loss=0.12672312579189354
Epoch #170: loss=0.13072856752058634
Epoch #171: loss=0.17673059757082507
Epoch #172: loss=0.1403268865811137
Epoch #173: loss=0.11518888913381559
Epoch #174: loss=0.11732679845478672
Epoch #175: loss=0.11080962260110447
Epoch #176: loss=0.10168620560748073
Epoch #177: loss=0.1640214412831343
Epoch #178: loss=0.1277102373826962
Epoch #179: loss=0.12408956917575918
Epoch #180: loss=0.1031030726690705
Epoch #181: loss=0.09924338883362137
Epoch #182: loss=0.14583497358342776
Epoch #183: loss=0.165365687947577
Epoch #184: loss=0.14454249204852834
Epoch #185: loss=0.10978559952659103
Epoch #186: loss=0.11899687339050266
Epoch #187: loss=0.12916052527725697
Epoch #188: loss=0.1284366476421173
Epoch #189: loss=0.1627912760998767
Epoch #190: loss=0.14967505565772837
Epoch #191: loss=0.1781561832803373
Epoch #192: loss=0.12173853338194582
Epoch #193: loss=0.08878341908208452
Epoch #194: loss=0.09992797361113705
Epoch #195: loss=0.09063436671231802
Epoch #196: loss=0.20527468213381675
Epoch #197: loss=0.14300120403417027
Epoch #198: loss=0.12528665327968505
Epoch #199: loss=0.09685091366274999
Epoch #200: loss=0.09868229689219823
Epoch #201: loss=0.09263513668870124
Epoch #202: loss=0.07622631925802964
Epoch #203: loss=0.11401346694821349
Epoch #204: loss=0.09026130222572157
Epoch #205: loss=0.09924949712764758
Epoch #206: loss=0.13124566870884827
Epoch #207: loss=0.21708861620237047
Epoch #208: loss=0.1756074925741324
Epoch #209: loss=0.1301918406970799
Epoch #210: loss=0.10408864868804812
Epoch #211: loss=0.100104377605021
Epoch #212: loss=0.13053176580713347
Epoch #213: loss=0.08541110054088327
Epoch #214: loss=0.06883505989725773
Epoch #215: loss=0.07787849883047435
Epoch #216: loss=0.08433047900549494
Epoch #217: loss=0.12718375414036787
Epoch #218: loss=0.06600496801547706
Epoch #219: loss=0.0709451732154076
Epoch #220: loss=0.07735658245376097
Epoch #221: loss=0.09765200390337178
Epoch #222: loss=0.09922732971608639
Epoch #223: loss=0.07631429347496194
Epoch #224: loss=0.06360385300090107
Epoch #225: loss=0.06666786920350905
Epoch #226: loss=0.1118818351175063
Epoch #227: loss=0.06445776114168648
Epoch #228: loss=0.08728732800899217
Epoch #229: loss=0.10795804181207831
Epoch #230: loss=0.11134706650717327
Epoch #231: loss=0.11450800804707867
Epoch #232: loss=0.10139094791016899
Epoch #233: loss=0.11118188163695428
Epoch #234: loss=0.11899860258787297
Epoch #235: loss=0.10055554009830722
Epoch #236: loss=0.0960157524364499
Epoch #237: loss=0.09791116774655305
Epoch #238: loss=0.06463791501636688
Epoch #239: loss=0.07864014009157053
Epoch #240: loss=0.07344620977528393
Epoch #241: loss=0.08464570406179589
Epoch #242: loss=0.11533946348712422
Epoch #243: loss=0.09221548880808629
Epoch #244: loss=0.08292403310322417
Epoch #245: loss=0.0720855281688273
Epoch #246: loss=0.06309566808004792
Epoch #247: loss=0.06393383058289495
Epoch #248: loss=0.061287106319258995
Epoch #249: loss=0.07502796771362998

Training time: 0:16:07.121177

Finished.
n2one setting etth2_ettm2_weather_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm2_weather_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_ettm2_weather_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.32936e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.57497e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.32936e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.37864968834988066, 'MAE': 0.4362460093484479}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_electricity_traffic_weather', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_electricity_traffic_weather_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.8291974706991919
Epoch #1: loss=0.3062662462164697
Epoch #2: loss=0.20702281074083753
Epoch #3: loss=0.1595562198566959
Epoch #4: loss=0.13607830506455348
Epoch #5: loss=0.11361395125966642
Epoch #6: loss=0.08876617779452844
Epoch #7: loss=0.07225138823636562
Epoch #8: loss=0.06877733248754674
Epoch #9: loss=0.05470347593999529
Epoch #10: loss=0.05255785650871602
Epoch #11: loss=0.04530249319213908
Epoch #12: loss=0.0472669443709157
Epoch #13: loss=0.04774609267932599
Epoch #14: loss=0.0438701851549252
Epoch #15: loss=0.04440598345938365
Epoch #16: loss=0.03441046052351961
Epoch #17: loss=0.03417406509585195
Epoch #18: loss=0.032920682521331686
Epoch #19: loss=0.031139965893233142
Epoch #20: loss=0.025306018298196203
Epoch #21: loss=0.03375188784947999
Epoch #22: loss=0.03808570609896235
Epoch #23: loss=0.023476065645522078
Epoch #24: loss=0.023601075143185306
Epoch #25: loss=0.031071897588605537
Epoch #26: loss=0.023266981869351423
Epoch #27: loss=0.025506503341076542
Epoch #28: loss=0.026922881345423155
Epoch #29: loss=0.03052466670961669
Epoch #30: loss=0.03900937906985889
Epoch #31: loss=0.022950029513642795
Epoch #32: loss=0.0273174428522524
Epoch #33: loss=0.02198857043788992
Epoch #34: loss=0.023333529495606565
Epoch #35: loss=0.028446464862291146
Epoch #36: loss=0.021296180159855505
Epoch #37: loss=0.022464532218428326
Epoch #38: loss=0.019483350015338817
Epoch #39: loss=0.018478282203671512
Epoch #40: loss=0.025501174814148965
Epoch #41: loss=0.02002992578515037
Epoch #42: loss=0.01772236977898214
Epoch #43: loss=0.01673175403103462
Epoch #44: loss=0.029164761892819736
Epoch #45: loss=0.017611290735466786
Epoch #46: loss=0.03147714619255662
Epoch #47: loss=0.021323929730322943
Epoch #48: loss=0.01857129544379476
Epoch #49: loss=0.019236382949250248
Epoch #50: loss=0.02173899170649843
Epoch #51: loss=0.017740726769608573
Epoch #52: loss=0.017901948285917138
Epoch #53: loss=0.021342085950341004
Epoch #54: loss=0.015162400942627803
Epoch #55: loss=0.017744663008622746
Epoch #56: loss=0.022730276780868353
Epoch #57: loss=0.019479451150705006
Epoch #58: loss=0.013903984913835493
Epoch #59: loss=0.01620813247750687
Epoch #60: loss=0.015467367518795072
Epoch #61: loss=0.019894405972679937
Epoch #62: loss=0.014912267068738353
Epoch #63: loss=0.01860593848581821
Epoch #64: loss=0.022928636314765372
Epoch #65: loss=0.024741728831462462
Epoch #66: loss=0.017425231591053154
Epoch #67: loss=0.024909568241463075
Epoch #68: loss=0.017483924134514956
Epoch #69: loss=0.014456016290990336
Epoch #70: loss=0.014087702133709076
Epoch #71: loss=0.020884801418129716
Epoch #72: loss=0.017186179447890026
Epoch #73: loss=0.02196201001318418
Epoch #74: loss=0.01148757548927087
Epoch #75: loss=0.017643929697777293
Epoch #76: loss=0.01338267074885679
Epoch #77: loss=0.015140965248304527
Epoch #78: loss=0.020581000414662605
Epoch #79: loss=0.01397606146618177
Epoch #80: loss=0.016692077653930795
Epoch #81: loss=0.013208639495946715
Epoch #82: loss=0.013605134532195064
Epoch #83: loss=0.014358899937729132
Epoch #84: loss=0.012404533563564033
Epoch #85: loss=0.01929681872381575
Epoch #86: loss=0.015200250048277858
Epoch #87: loss=0.015015249854825111
Epoch #88: loss=0.012403031235838793
Epoch #89: loss=0.01820691602796686
Epoch #90: loss=0.014719958604114493
Epoch #91: loss=0.012842613725632347
Epoch #92: loss=0.013596777349077552
Epoch #93: loss=0.015485068820692649
Epoch #94: loss=0.013431567078800742
Epoch #95: loss=0.012377224102261894
Epoch #96: loss=0.01410901053140578
Epoch #97: loss=0.016191073717293062
Epoch #98: loss=0.012061999188075023
Epoch #99: loss=0.014265437884755795
Epoch #100: loss=0.014748780470989388
Epoch #101: loss=0.012806539495177037
Epoch #102: loss=0.022855593156667676
Epoch #103: loss=0.0145999879584547
Epoch #104: loss=0.014044369279597384
Epoch #105: loss=0.015201831021733213
Epoch #106: loss=0.012140614138268958
Epoch #107: loss=0.01874364077335294
Epoch #108: loss=0.016175545873107024
Epoch #109: loss=0.011560304254101683
Epoch #110: loss=0.022710389861769823
Epoch #111: loss=0.015949595735779247
Epoch #112: loss=0.01619110446867317
Epoch #113: loss=0.009643944601425335
Epoch #114: loss=0.01606621010287917
Epoch #115: loss=0.019185992599791223
Epoch #116: loss=0.011953625443529865
Epoch #117: loss=0.013317531211082735
Epoch #118: loss=0.012549117948454199
Epoch #119: loss=0.014891621995957394
Epoch #120: loss=0.01195536166075104
Epoch #121: loss=0.010906324275729753
Epoch #122: loss=0.017760569443273772
Epoch #123: loss=0.015058062909079845
Epoch #124: loss=0.015124606633865991
Epoch #125: loss=0.01001280216460624
Epoch #126: loss=0.014564330804049811
Epoch #127: loss=0.014109287765653502
Epoch #128: loss=0.01431274506488104
Epoch #129: loss=0.012709936234123712
Epoch #130: loss=0.012460578748842684
Epoch #131: loss=0.015195499453415993
Epoch #132: loss=0.015591167674517093
Epoch #133: loss=0.013059597143530098
Epoch #134: loss=0.01058901798607119
Epoch #135: loss=0.011604463383384044
Epoch #136: loss=0.014173741640481814
Epoch #137: loss=0.011306072140469999
Epoch #138: loss=0.012391846982337173
Epoch #139: loss=0.013756139407923073
Epoch #140: loss=0.01145614562366111
Epoch #141: loss=0.012211805299102707
Epoch #142: loss=0.012333979724452979
Epoch #143: loss=0.013948556348203694
Epoch #144: loss=0.008683912363374858
Epoch #145: loss=0.012395879631807665
Epoch #146: loss=0.009716048363794758
Epoch #147: loss=0.012615901981557966
Epoch #148: loss=0.01196584308392726
Epoch #149: loss=0.010171996874706374
Epoch #150: loss=0.020002022692740172
Epoch #151: loss=0.012687430740183308
Epoch #152: loss=0.01311339237485012
Epoch #153: loss=0.012831964366269906
Epoch #154: loss=0.011731947832291362
Epoch #155: loss=0.011029597614579919
Epoch #156: loss=0.016142626250544516
Epoch #157: loss=0.009585174829752711
Epoch #158: loss=0.016622535108964304
Epoch #159: loss=0.012109359212421336
Epoch #160: loss=0.010517558223347422
Epoch #161: loss=0.010390945908475738
Epoch #162: loss=0.01932429859796589
Epoch #163: loss=0.009892569695430689
Epoch #164: loss=0.013623078528493543
Epoch #165: loss=0.011390556113347453
Epoch #166: loss=0.014082102217535544
Epoch #167: loss=0.013038819919230312
Epoch #168: loss=0.009261886921158771
Epoch #169: loss=0.013501834532450485
Epoch #170: loss=0.011871861613665888
Epoch #171: loss=0.013060821975793595
Epoch #172: loss=0.012273760142318823
Epoch #173: loss=0.011568116433792104
Epoch #174: loss=0.017168724560609628
Epoch #175: loss=0.009540440544840652
Epoch #176: loss=0.01103119545392043
Epoch #177: loss=0.010190761263737315
Epoch #178: loss=0.00900937708416007
Epoch #179: loss=0.013942337923427467
Epoch #180: loss=0.010274936024864857
Epoch #181: loss=0.01140186531467024
Epoch #182: loss=0.012488742673201015
Epoch #183: loss=0.010480238878759146
Epoch #184: loss=0.010467110671163033
Epoch #185: loss=0.011792241141307613
Epoch #186: loss=0.007656997224773333
Epoch #187: loss=0.009865633012587319
Epoch #188: loss=0.008431552724459834
Epoch #189: loss=0.012151934138106108
Epoch #190: loss=0.010082305205257495
Epoch #191: loss=0.01813107250901387
Epoch #192: loss=0.013077498734901383
Epoch #193: loss=0.009867740391224575
Epoch #194: loss=0.011302980246886076
Epoch #195: loss=0.009067707849764798
Epoch #196: loss=0.010402423189958794
Epoch #197: loss=0.01018046027657922
Epoch #198: loss=0.010844191849038884
Epoch #199: loss=0.012277803242472816
Epoch #200: loss=0.009329361811302605
Epoch #201: loss=0.013004426088137302
Epoch #202: loss=0.011151758168233229
Epoch #203: loss=0.014161763357145375
Epoch #204: loss=0.014745485406628608
Epoch #205: loss=0.011699119876778385
Epoch #206: loss=0.009858997167171424
Epoch #207: loss=0.010019860533046048
Epoch #208: loss=0.011340026586840156
Epoch #209: loss=0.008529692468952913
Epoch #210: loss=0.011885375215073461
Epoch #211: loss=0.010352081146217978
Epoch #212: loss=0.009383863886389582
Epoch #213: loss=0.011897368588602387
Epoch #214: loss=0.011267105514749567
Epoch #215: loss=0.0085541299466473
Epoch #216: loss=0.01523402815862602
Epoch #217: loss=0.00765908067073365
Epoch #218: loss=0.011943511107514687
Epoch #219: loss=0.011994974231643746
Epoch #220: loss=0.006393364664871258
Epoch #221: loss=0.00985901556280049
Epoch #222: loss=0.010614630935031911
Epoch #223: loss=0.010845627882405862
Epoch #224: loss=0.012461855909627298
Epoch #225: loss=0.009830857274766314
Epoch #226: loss=0.009851091930679439
Epoch #227: loss=0.009782916427471528
Epoch #228: loss=0.013734306273501093
Epoch #229: loss=0.010218277556233309
Epoch #230: loss=0.00749186080686645
Epoch #231: loss=0.01182132982972019
Epoch #232: loss=0.009826347790294676
Epoch #233: loss=0.009628750677620701
Epoch #234: loss=0.010969647529565774
Epoch #235: loss=0.01160132796076515
Epoch #236: loss=0.009060665719337186
Epoch #237: loss=0.0071659571406323605
Epoch #238: loss=0.01292618444198237
Epoch #239: loss=0.01339006833316154
Epoch #240: loss=0.010202156723290787
Epoch #241: loss=0.007917092026517773
Epoch #242: loss=0.013126610244638104
Epoch #243: loss=0.016237255010064712
Epoch #244: loss=0.010280019904416205
Epoch #245: loss=0.008274014771114037
Epoch #246: loss=0.009236872197789125
Epoch #247: loss=0.007855633028540117
Epoch #248: loss=0.01339582088283726
Epoch #249: loss=0.01245806135390419

Training time: 5:01:35.168186

Finished.
n2one setting etth2_electricity_traffic_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_electricity_traffic_weather_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_electricity_traffic_weather', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.63769e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.31661489724535735, 'MAE': 0.3618209090947326}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_electricity_traffic_exchange', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_electricity_traffic_exchange_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.8032166109434352
Epoch #1: loss=0.29125513174323886
Epoch #2: loss=0.18410748865250157
Epoch #3: loss=0.15121852557403417
Epoch #4: loss=0.1242898205242342
Epoch #5: loss=0.09069197558842985
Epoch #6: loss=0.08548409933261636
Epoch #7: loss=0.06651417065282758
Epoch #8: loss=0.06491768968801553
Epoch #9: loss=0.05301262413828676
Epoch #10: loss=0.043800022957989564
Epoch #11: loss=0.045657760661891436
Epoch #12: loss=0.04522466211725891
Epoch #13: loss=0.044353020072328504
Epoch #14: loss=0.03594399794943177
Epoch #15: loss=0.03608290606848071
Epoch #16: loss=0.036143172104265354
Epoch #17: loss=0.02947310927982453
Epoch #18: loss=0.03208524126517517
Epoch #19: loss=0.033890884315096716
Epoch #20: loss=0.02902494523044946
Epoch #21: loss=0.032713739486245626
Epoch #22: loss=0.02502158149381678
Epoch #23: loss=0.023215245039741397
Epoch #24: loss=0.02689552406558086
Epoch #25: loss=0.027650355232305412
Epoch #26: loss=0.027918670936728607
Epoch #27: loss=0.024169854887456824
Epoch #28: loss=0.0243325807787855
Epoch #29: loss=0.027270643167107915
Epoch #30: loss=0.02038598204956107
Epoch #31: loss=0.029711177222827567
Epoch #32: loss=0.027111079927086085
Epoch #33: loss=0.017476953425025258
Epoch #34: loss=0.020808308577402696
Epoch #35: loss=0.026210591304489102
Epoch #36: loss=0.018209326604069466
Epoch #37: loss=0.021158369266840463
Epoch #38: loss=0.02103230998338665
Epoch #39: loss=0.029264321579150498
Epoch #40: loss=0.018583312994985723
Epoch #41: loss=0.017337020722873592
Epoch #42: loss=0.020417063787170626
Epoch #43: loss=0.021284391982108703
Epoch #44: loss=0.021206631796045435
Epoch #45: loss=0.017736789440807695
Epoch #46: loss=0.02263599149142322
Epoch #47: loss=0.018700586211516247
Epoch #48: loss=0.017096926402693183
Epoch #49: loss=0.017929421128844686
Epoch #50: loss=0.020974686632886333
Epoch #51: loss=0.019058524163261845
Epoch #52: loss=0.018022315136932626
Epoch #53: loss=0.022677828908614382
Epoch #54: loss=0.017849241510563305
Epoch #55: loss=0.018549015488177622
Epoch #56: loss=0.014508656725868154
Epoch #57: loss=0.022471719335543865
Epoch #58: loss=0.02050878258474686
Epoch #59: loss=0.017343607901705145
Epoch #60: loss=0.019613659951179165
Epoch #61: loss=0.017008310318591176
Epoch #62: loss=0.020229399402854998
Epoch #63: loss=0.016183090588267005
Epoch #64: loss=0.01621385038214641
Epoch #65: loss=0.020460016272172258
Epoch #66: loss=0.016312404553226557
Epoch #67: loss=0.014466426911229775
Epoch #68: loss=0.021182231501318927
Epoch #69: loss=0.020127703725323992
Epoch #70: loss=0.015667016240697197
Epoch #71: loss=0.017157982806172742
Epoch #72: loss=0.015262746474698252
Epoch #73: loss=0.014383433579028687
Epoch #74: loss=0.016688568475792743
Epoch #75: loss=0.016985392451689785
Epoch #76: loss=0.01642960864806257
Epoch #77: loss=0.016143343767762174
Epoch #78: loss=0.013262947468635726
Epoch #79: loss=0.020560028710185266
Epoch #80: loss=0.018313269852237888
Epoch #81: loss=0.016240538704822786
Epoch #82: loss=0.016543381970683044
Epoch #83: loss=0.019052739963266813
Epoch #84: loss=0.014500386510808129
Epoch #85: loss=0.014026751084173412
Epoch #86: loss=0.014726609836872986
Epoch #87: loss=0.012533539313281139
Epoch #88: loss=0.016911426520512248
Epoch #89: loss=0.01679276170296799
Epoch #90: loss=0.013812958450055738
Epoch #91: loss=0.016242141895664145
Epoch #92: loss=0.015659573849330255
Epoch #93: loss=0.014626998656990242
Epoch #94: loss=0.01256091197706193
Epoch #95: loss=0.02255083957404436
Epoch #96: loss=0.01270922060613948
Epoch #97: loss=0.01164126906893119
Epoch #98: loss=0.011887028760669126
Epoch #99: loss=0.014966007429888342
Epoch #100: loss=0.016332098949249314
Epoch #101: loss=0.01781803617864254
Epoch #102: loss=0.014720661042254063
Epoch #103: loss=0.015044817974875417
Epoch #104: loss=0.016116489009183048
Epoch #105: loss=0.025136460341883975
Epoch #106: loss=0.014646780843672946
Epoch #107: loss=0.013034460910222123
Epoch #108: loss=0.013055116534062066
Epoch #109: loss=0.014733753232710034
Epoch #110: loss=0.01581329725653486
Epoch #111: loss=0.015225435906967913
Epoch #112: loss=0.01504130675726106
Epoch #113: loss=0.012967521368919674
Epoch #114: loss=0.012393424523289044
Epoch #115: loss=0.014935665486893734
Epoch #116: loss=0.014099619188134615
Epoch #117: loss=0.014307103894613232
Epoch #118: loss=0.014774918571979979
Epoch #119: loss=0.012746980957559991
Epoch #120: loss=0.016945580646279268
Epoch #121: loss=0.012703574396976353
Epoch #122: loss=0.011397116176885295
Epoch #123: loss=0.01780037741673444
Epoch #124: loss=0.016084496258589508
Epoch #125: loss=0.00977919395127128
Epoch #126: loss=0.01336844712438896
Epoch #127: loss=0.015533291288455816
Epoch #128: loss=0.014149979163386481
Epoch #129: loss=0.014330840662879443
Epoch #130: loss=0.013697146323396013
Epoch #131: loss=0.026275520678925426
Epoch #132: loss=0.00937118460829706
Epoch #133: loss=0.010575374733646538
Epoch #134: loss=0.01030738565608292
Epoch #135: loss=0.015183280376820065
Epoch #136: loss=0.01137529743775033
Epoch #137: loss=0.01620087418551689
Epoch #138: loss=0.012027536129031078
Epoch #139: loss=0.01810237959908228
Epoch #140: loss=0.013959058715521866
Epoch #141: loss=0.012016895137672746
Epoch #142: loss=0.013840365235396326
Epoch #143: loss=0.011885005938288996
Epoch #144: loss=0.011186104923011914
Epoch #145: loss=0.013921121889782175
Epoch #146: loss=0.014029579163323551
Epoch #147: loss=0.013200345745143824
Epoch #148: loss=0.011607103396328757
Epoch #149: loss=0.009398078810704836
Epoch #150: loss=0.012160179966699972
Epoch #151: loss=0.014687576532481142
Epoch #152: loss=0.013947761412231245
Epoch #153: loss=0.012924253650795095
Epoch #154: loss=0.013001916729867639
Epoch #155: loss=0.012112289178074932
Epoch #156: loss=0.014286513616701304
Epoch #157: loss=0.010181122256351755
Epoch #158: loss=0.010337446809196122
Epoch #159: loss=0.011647132539099688
Epoch #160: loss=0.01307359986513591
Epoch #161: loss=0.010288904638982238
Epoch #162: loss=0.012836249259377104
Epoch #163: loss=0.013029356878320804
Epoch #164: loss=0.010946047313305167
Epoch #165: loss=0.013075462297727575
Epoch #166: loss=0.01218635865067072
Epoch #167: loss=0.011574327171111266
Epoch #168: loss=0.011842739103357711
Epoch #169: loss=0.011248914691435012
Epoch #170: loss=0.01753681511175809
Epoch #171: loss=0.01490972135993031
Epoch #172: loss=0.010341050538066495
Epoch #173: loss=0.011480224214588537
Epoch #174: loss=0.010105005395627862
Epoch #175: loss=0.012106780407085233
Epoch #176: loss=0.009444975543529185
Epoch #177: loss=0.011019509025490924
Epoch #178: loss=0.012609185292011639
Epoch #179: loss=0.01332463427658083
Epoch #180: loss=0.018741622530541947
Epoch #181: loss=0.012735075500764796
Epoch #182: loss=0.010438539414704589
Epoch #183: loss=0.012462891752349943
Epoch #184: loss=0.012603338478593303
Epoch #185: loss=0.009963406312084762
Epoch #186: loss=0.011077669185151125
Epoch #187: loss=0.011545990755284386
Epoch #188: loss=0.00946458064068559
Epoch #189: loss=0.012692157415834836
Epoch #190: loss=0.01018115098792102
Epoch #191: loss=0.009411893191159024
Epoch #192: loss=0.011624138149957546
Epoch #193: loss=0.010980028882886548
Epoch #194: loss=0.0139074216884468
Epoch #195: loss=0.008347871337292314
Epoch #196: loss=0.009895993663323712
Epoch #197: loss=0.014653762156002493
Epoch #198: loss=0.011866109034435522
Epoch #199: loss=0.013123200965952653
Epoch #200: loss=0.00880787327069676
Epoch #201: loss=0.010291606187383149
Epoch #202: loss=0.00945460686451586
Epoch #203: loss=0.00965100971326822
Epoch #204: loss=0.012981243669670519
Epoch #205: loss=0.010156878107866309
Epoch #206: loss=0.01121303418869672
Epoch #207: loss=0.010293700363828477
Epoch #208: loss=0.010925375336859807
Epoch #209: loss=0.010600934369523174
Epoch #210: loss=0.011524689388420597
Epoch #211: loss=0.008227108958628063
Epoch #212: loss=0.011622559854149828
Epoch #213: loss=0.008912039705573199
Epoch #214: loss=0.01144338080241949
Epoch #215: loss=0.009544672622875573
Epoch #216: loss=0.008709159484079921
Epoch #217: loss=0.012170429682529738
Epoch #218: loss=0.009882710406208646
Epoch #219: loss=0.012393626501508336
Epoch #220: loss=0.016348244602404628
Epoch #221: loss=0.012186277444289318
Epoch #222: loss=0.009268580822756731
Epoch #223: loss=0.010332824642637737
Epoch #224: loss=0.012236191538547438
Epoch #225: loss=0.00948868057473521
Epoch #226: loss=0.011270185666938526
Epoch #227: loss=0.01047367552489531
Epoch #228: loss=0.01431240409544196
Epoch #229: loss=0.011114348981531224
Epoch #230: loss=0.008851663102848666
Epoch #231: loss=0.00965742715075165
Epoch #232: loss=0.012747996442800447
Epoch #233: loss=0.010421948928291907
Epoch #234: loss=0.011689777783405242
Epoch #235: loss=0.013384574917828698
Epoch #236: loss=0.01149569411770513
Epoch #237: loss=0.008581469582175802
Epoch #238: loss=0.007084862496719533
Epoch #239: loss=0.01243788470809627
Epoch #240: loss=0.013720537658505031
Epoch #241: loss=0.009102662733620398
Epoch #242: loss=0.008103150055831065
Epoch #243: loss=0.012939094802432268
Epoch #244: loss=0.009367482061014423
Epoch #245: loss=0.008649796405342643
Epoch #246: loss=0.008469244901807572
Epoch #247: loss=0.014217610706327244
Epoch #248: loss=0.013359731193703797
Epoch #249: loss=0.012757331408597786

Training time: 4:52:37.571266

Finished.
n2one setting etth2_electricity_traffic_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_electricity_traffic_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_electricity_traffic_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.05886e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.21312e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.05886e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.47862070147152597, 'MAE': 0.5119261115975559}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_electricity_weather_exchange', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_electricity_weather_exchange_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.6311488497323094
Epoch #1: loss=0.775289056215497
Epoch #2: loss=0.555160198834061
Epoch #3: loss=0.45415606263263447
Epoch #4: loss=0.40892019666196233
Epoch #5: loss=0.34612747936288296
Epoch #6: loss=0.3153713155764243
Epoch #7: loss=0.2920620947952758
Epoch #8: loss=0.2648852092949725
Epoch #9: loss=0.23470752200533673
Epoch #10: loss=0.22821886351753995
Epoch #11: loss=0.21015196493235083
Epoch #12: loss=0.19540285228530346
Epoch #13: loss=0.17311763522621676
Epoch #14: loss=0.19490391398826357
Epoch #15: loss=0.16965749211485873
Epoch #16: loss=0.15090103775201089
Epoch #17: loss=0.13417878980074305
Epoch #18: loss=0.1280092782294635
Epoch #19: loss=0.1371230814626533
Epoch #20: loss=0.11906667320747237
Epoch #21: loss=0.10455928627113446
Epoch #22: loss=0.0997896294562321
Epoch #23: loss=0.14818200626467143
Epoch #24: loss=0.11196482389167116
Epoch #25: loss=0.09005749168244927
Epoch #26: loss=0.08619359887632135
Epoch #27: loss=0.07288734220966532
Epoch #28: loss=0.07748308283076184
Epoch #29: loss=0.09006480380213557
Epoch #30: loss=0.07521430241684969
Epoch #31: loss=0.07263368387701433
Epoch #32: loss=0.08116534824910167
Epoch #33: loss=0.061112997712546864
Epoch #34: loss=0.08906859383938927
Epoch #35: loss=0.07854837877289984
Epoch #36: loss=0.06268758894824192
Epoch #37: loss=0.06479742772779454
Epoch #38: loss=0.06586024550481787
Epoch #39: loss=0.06256722879868762
Epoch #40: loss=0.08395962209314704
Epoch #41: loss=0.060622006284268525
Epoch #42: loss=0.05341544300150538
Epoch #43: loss=0.0508870472964311
Epoch #44: loss=0.05792859966033113
Epoch #45: loss=0.05840413562261412
Epoch #46: loss=0.045778118998831066
Epoch #47: loss=0.04355226931141597
Epoch #48: loss=0.04726830780639915
Epoch #49: loss=0.050978543375778264
Epoch #50: loss=0.05745766335102673
Epoch #51: loss=0.0441680614494343
Epoch #52: loss=0.04936354651980267
Epoch #53: loss=0.04462774422724644
Epoch #54: loss=0.04994783264543676
Epoch #55: loss=0.04955239375301981
Epoch #56: loss=0.0438905038776967
Epoch #57: loss=0.062343768500825854
Epoch #58: loss=0.060768733320124856
Epoch #59: loss=0.04137264271536893
Epoch #60: loss=0.04298952123946485
Epoch #61: loss=0.04127774134024885
Epoch #62: loss=0.03337510185154124
Epoch #63: loss=0.058027758039868545
Epoch #64: loss=0.03810140543819266
Epoch #65: loss=0.05079400585674892
Epoch #66: loss=0.036682599330274644
Epoch #67: loss=0.03243718567742961
Epoch #68: loss=0.03235002051883259
Epoch #69: loss=0.04321780797571345
Epoch #70: loss=0.029542829803427813
Epoch #71: loss=0.03652509862270196
Epoch #72: loss=0.04492160065185783
Epoch #73: loss=0.037427793985016604
Epoch #74: loss=0.03301871690136324
Epoch #75: loss=0.03800814699488358
Epoch #76: loss=0.04120991066502129
Epoch #77: loss=0.03613473653332819
Epoch #78: loss=0.02820413671459653
Epoch #79: loss=0.025307024880865517
Epoch #80: loss=0.023053727745598194
Epoch #81: loss=0.03853958222059307
Epoch #82: loss=0.03527384767539089
Epoch #83: loss=0.034711396728786356
Epoch #84: loss=0.05364709156398142
Epoch #85: loss=0.038140452947037926
Epoch #86: loss=0.04910986927319935
Epoch #87: loss=0.048670047150284196
Epoch #88: loss=0.03739599923851503
Epoch #89: loss=0.025360503149712818
Epoch #90: loss=0.026105041684485065
Epoch #91: loss=0.030497223799996778
Epoch #92: loss=0.02896017209853133
Epoch #93: loss=0.02730306386912257
Epoch #94: loss=0.01959169305827551
Epoch #95: loss=0.03248776140711553
Epoch #96: loss=0.044000790517800356
Epoch #97: loss=0.03432160729538516
Epoch #98: loss=0.0297646770311342
Epoch #99: loss=0.03608532224473729
Epoch #100: loss=0.043325654422035904
Epoch #101: loss=0.06869216865823907
Epoch #102: loss=0.028064125439072368
Epoch #103: loss=0.027511659595737162
Epoch #104: loss=0.02488686129655329
Epoch #105: loss=0.026377696132619262
Epoch #106: loss=0.025104232826102937
Epoch #107: loss=0.029611150611440255
Epoch #108: loss=0.030414009464516185
Epoch #109: loss=0.039237555779853724
Epoch #110: loss=0.03188388222103002
Epoch #111: loss=0.03240305220805371
Epoch #112: loss=0.02575838782352483
Epoch #113: loss=0.020567242660558427
Epoch #114: loss=0.03437970061104704
Epoch #115: loss=0.01888495220822663
Epoch #116: loss=0.02505157472924664
Epoch #117: loss=0.022994671935229742
Epoch #118: loss=0.0300797531514709
Epoch #119: loss=0.03265003803171969
Epoch #120: loss=0.04515208190246563
Epoch #121: loss=0.027101915267949604
Epoch #122: loss=0.019704005364052056
Epoch #123: loss=0.022481090137870075
Epoch #124: loss=0.027055623327531125
Epoch #125: loss=0.029333006945478562
Epoch #126: loss=0.024304414563555043
Epoch #127: loss=0.01916001706936613
Epoch #128: loss=0.022269306288104636
Epoch #129: loss=0.019542076468155128
Epoch #130: loss=0.02148403067788809
Epoch #131: loss=0.03025533321673097
Epoch #132: loss=0.020787710046076643
Epoch #133: loss=0.02859303349058545
Epoch #134: loss=0.03564371267019756
Epoch #135: loss=0.021759447572689803
Epoch #136: loss=0.021141591474307105
Epoch #137: loss=0.022377330095903404
Epoch #138: loss=0.02510463544897586
Epoch #139: loss=0.016668987216026578
Epoch #140: loss=0.014379611538960444
Epoch #141: loss=0.01877302260640417
Epoch #142: loss=0.03667845712792648
Epoch #143: loss=0.018225503074988023
Epoch #144: loss=0.01800369484432412
Epoch #145: loss=0.028960037247942844
Epoch #146: loss=0.019924477200526796
Epoch #147: loss=0.03627455550103155
Epoch #148: loss=0.027661203973713067
Epoch #149: loss=0.021340835654435328
Epoch #150: loss=0.01893362982644962
Epoch #151: loss=0.026614640727163245
Epoch #152: loss=0.04688755660163475
Epoch #153: loss=0.029412825198558503
Epoch #154: loss=0.02169207385300597
Epoch #155: loss=0.019999705737093927
Epoch #156: loss=0.025055408022653963
Epoch #157: loss=0.021977326043853176
Epoch #158: loss=0.030677452833791783
Epoch #159: loss=0.020998328529830215
Epoch #160: loss=0.022454223841414607
Epoch #161: loss=0.023132668608395662
Epoch #162: loss=0.018067043852617384
Epoch #163: loss=0.04236162985830686
Epoch #164: loss=0.030512248445688155
Epoch #165: loss=0.023758679361774674
Epoch #166: loss=0.021187778993799783
Epoch #167: loss=0.027127749694367223
Epoch #168: loss=0.017705934554420783
Epoch #169: loss=0.02020791351479396
Epoch #170: loss=0.019094871239381642
Epoch #171: loss=0.02208900848147588
Epoch #172: loss=0.02312728406498672
Epoch #173: loss=0.017556994397209917
Epoch #174: loss=0.022518343836305795
Epoch #175: loss=0.02574801077253895
Epoch #176: loss=0.02259116195005915
Epoch #177: loss=0.028480337227380175
Epoch #178: loss=0.0184954192442112
Epoch #179: loss=0.015107915918995596
Epoch #180: loss=0.018588243681231246
Epoch #181: loss=0.018124350269121833
Epoch #182: loss=0.01833988598331446
Epoch #183: loss=0.01966962924245449
Epoch #184: loss=0.023948355610366623
Epoch #185: loss=0.01539059481210492
Epoch #186: loss=0.01731246256077204
Epoch #187: loss=0.024983830626015887
Epoch #188: loss=0.01912964143432054
Epoch #189: loss=0.020783219111180293
Epoch #190: loss=0.01726381317221943
Epoch #191: loss=0.020525567232758495
Epoch #192: loss=0.014499186035998176
Epoch #193: loss=0.019489676633866464
Epoch #194: loss=0.025449995834329577
Epoch #195: loss=0.019941973733749157
Epoch #196: loss=0.03022964377586861
Epoch #197: loss=0.051170129234579684
Epoch #198: loss=0.021250633590401906
Epoch #199: loss=0.023871935343174316
Epoch #200: loss=0.01935782179156658
Epoch #201: loss=0.027417678478912282
Epoch #202: loss=0.020292845887012356
Epoch #203: loss=0.018556890708203967
Epoch #204: loss=0.018770446593327144
Epoch #205: loss=0.01720219576079784
Epoch #206: loss=0.020118050633232465
Epoch #207: loss=0.0314768920152497
Epoch #208: loss=0.03065388328836361
Epoch #209: loss=0.01829154017279748
Epoch #210: loss=0.019337856319786993
Epoch #211: loss=0.014867052478485519
Epoch #212: loss=0.016916669168907026
Epoch #213: loss=0.015988035910268886
Epoch #214: loss=0.015341512126769635
Epoch #215: loss=0.021117358044457482
Epoch #216: loss=0.024258386079210388
Epoch #217: loss=0.02658458754487171
Epoch #218: loss=0.01932858526629514
Epoch #219: loss=0.01612678018245185
Epoch #220: loss=0.02275807535231116
Epoch #221: loss=0.019853947795760298
Epoch #222: loss=0.015646449911365677
Epoch #223: loss=0.024189295395610606
Epoch #224: loss=0.01845302764510926
Epoch #225: loss=0.013871191609592964
Epoch #226: loss=0.014199628678468206
Epoch #227: loss=0.018366142286236002
Epoch #228: loss=0.017312060754012332
Epoch #229: loss=0.022193188817626688
Epoch #230: loss=0.02657317946801986
Epoch #231: loss=0.030174882358450762
Epoch #232: loss=0.01804513226389288
Epoch #233: loss=0.019171209881745938
Epoch #234: loss=0.028482692421495
Epoch #235: loss=0.020414186239989283
Epoch #236: loss=0.017136748587742875
Epoch #237: loss=0.02142587070400281
Epoch #238: loss=0.01302208379976283
Epoch #239: loss=0.026381899729256586
Epoch #240: loss=0.01513920931045213
Epoch #241: loss=0.019367495414708325
Epoch #242: loss=0.015413649808644389
Epoch #243: loss=0.021454119742256254
Epoch #244: loss=0.015146695925289435
Epoch #245: loss=0.018950688873304478
Epoch #246: loss=0.015427654273184118
Epoch #247: loss=0.012997543815448135
Epoch #248: loss=0.013231924960604555
Epoch #249: loss=0.014400567575608694

Training time: 1:40:26.359143

Finished.
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_traffic_weather_exchange', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_traffic_weather_exchange_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.0277897077442404
Epoch #1: loss=0.4191487894897841
Epoch #2: loss=0.2930582865891134
Epoch #3: loss=0.2245949509399938
Epoch #4: loss=0.19229059300054346
Epoch #5: loss=0.17072720234081198
Epoch #6: loss=0.14132781960441423
Epoch #7: loss=0.12587838910173538
Epoch #8: loss=0.11650472521938689
Epoch #9: loss=0.099953562418331
Epoch #10: loss=0.08572214096114204
Epoch #11: loss=0.0829193159506748
Epoch #12: loss=0.08434152418535083
Epoch #13: loss=0.0639653952481846
Epoch #14: loss=0.061479537452314284
Epoch #15: loss=0.06650814827292299
Epoch #16: loss=0.0661661820218033
Epoch #17: loss=0.05269031766245135
Epoch #18: loss=0.05600712945708512
Epoch #19: loss=0.046032984587616586
Epoch #20: loss=0.050003792176019
Epoch #21: loss=0.04118037147082364
Epoch #22: loss=0.05782134932463789
Epoch #23: loss=0.04139951037620488
Epoch #24: loss=0.03944760091692531
Epoch #25: loss=0.03827023498803183
Epoch #26: loss=0.0508185450908401
Epoch #27: loss=0.04597876089416725
Epoch #28: loss=0.04523786686756365
Epoch #29: loss=0.04157836020950966
Epoch #30: loss=0.03579879378805046
Epoch #31: loss=0.03195343979331123
Epoch #32: loss=0.03514586696991695
Epoch #33: loss=0.03399869531555749
Epoch #34: loss=0.04387216839567033
Epoch #35: loss=0.030838993992806017
Epoch #36: loss=0.02998194086238028
Epoch #37: loss=0.03335082887995221
Epoch #38: loss=0.028925495715074422
Epoch #39: loss=0.03250507787934887
Epoch #40: loss=0.02900391791721317
Epoch #41: loss=0.02573238712368566
Epoch #42: loss=0.028324333686203153
Epoch #43: loss=0.040256113572196224
Epoch #44: loss=0.028767655121746803
Epoch #45: loss=0.030495002735710413
Epoch #46: loss=0.024550018591134874
Epoch #47: loss=0.029158524299583967
Epoch #48: loss=0.03635572654502992
Epoch #49: loss=0.024316824100997222
Epoch #50: loss=0.02968804962933837
Epoch #51: loss=0.024218428925936474
Epoch #52: loss=0.028140464165872726
Epoch #53: loss=0.026572225115621403
Epoch #54: loss=0.0271985720428468
Epoch #55: loss=0.022946394490764466
Epoch #56: loss=0.01888080339402178
Epoch #57: loss=0.024717950610279447
Epoch #58: loss=0.027335136792282673
Epoch #59: loss=0.024191743447169442
Epoch #60: loss=0.024752245578362586
Epoch #61: loss=0.027393157287397146
Epoch #62: loss=0.024223832480657376
Epoch #63: loss=0.024987713773121204
Epoch #64: loss=0.029125252427574008
Epoch #65: loss=0.026471210441501566
Epoch #66: loss=0.03146718919111141
Epoch #67: loss=0.02784149556710557
Epoch #68: loss=0.02998646178091608
Epoch #69: loss=0.02359167938089722
Epoch #70: loss=0.02119852834542185
Epoch #71: loss=0.029560368975566687
Epoch #72: loss=0.01738281955618663
Epoch #73: loss=0.029292452189058543
Epoch #74: loss=0.026750222210561423
Epoch #75: loss=0.018565132582221377
Epoch #76: loss=0.021070117155177124
Epoch #77: loss=0.01575101009013254
Epoch #78: loss=0.02107514401602302
Epoch #79: loss=0.018093128630812545
Epoch #80: loss=0.02460296690145715
Epoch #81: loss=0.016909737858189278
Epoch #82: loss=0.02296574410701641
Epoch #83: loss=0.02773584922870254
Epoch #84: loss=0.025413261961456438
Epoch #85: loss=0.016953322837217673
Epoch #86: loss=0.018614217326594754
Epoch #87: loss=0.030103406578545787
Epoch #88: loss=0.02203973232564008
Epoch #89: loss=0.02004948995381146
Epoch #90: loss=0.019872045747980637
Epoch #91: loss=0.01701196133786171
Epoch #92: loss=0.022899329680146276
Epoch #93: loss=0.03193032091438609
Epoch #94: loss=0.026007906197552732
Epoch #95: loss=0.019885393888525848
Epoch #96: loss=0.015184858321018336
Epoch #97: loss=0.018952285200522456
Epoch #98: loss=0.023549763184243965
Epoch #99: loss=0.018124848791685085
Epoch #100: loss=0.01701224366176876
Epoch #101: loss=0.022530490916314126
Epoch #102: loss=0.019214729589535438
Epoch #103: loss=0.024548010414779282
Epoch #104: loss=0.01666043971280762
Epoch #105: loss=0.01908068991157124
Epoch #106: loss=0.022009862813820644
Epoch #107: loss=0.013342787171602491
Epoch #108: loss=0.020288435018563113
Epoch #109: loss=0.016712085404199963
Epoch #110: loss=0.021011308876677404
Epoch #111: loss=0.016596250331629033
Epoch #112: loss=0.024558266303280278
Epoch #113: loss=0.017027070631013896
Epoch #114: loss=0.017736407785775947
Epoch #115: loss=0.018322646184361583
Epoch #116: loss=0.017879289795053092
Epoch #117: loss=0.015627383043006392
Epoch #118: loss=0.018446862115266867
Epoch #119: loss=0.023511345369633285
Epoch #120: loss=0.02061711080300267
Epoch #121: loss=0.018163511428974544
Epoch #122: loss=0.022646691142527257
Epoch #123: loss=0.021600524517413587
Epoch #124: loss=0.021540221995851982
Epoch #125: loss=0.01620279807980422
Epoch #126: loss=0.01152684489221058
Epoch #127: loss=0.01698290944720308
Epoch #128: loss=0.025257212276815964
Epoch #129: loss=0.022073919584282085
Epoch #130: loss=0.017199529296129886
Epoch #131: loss=0.015168299465158684
Epoch #132: loss=0.014819344079730066
Epoch #133: loss=0.018639752555426863
Epoch #134: loss=0.023683557087418355
Epoch #135: loss=0.024558422526196142
Epoch #136: loss=0.01837058469712691
Epoch #137: loss=0.01800240913736309
Epoch #138: loss=0.013050042269421393
Epoch #139: loss=0.013928096484885874
Epoch #140: loss=0.014162648950502585
Epoch #141: loss=0.015061112441340924
Epoch #142: loss=0.018337025499984144
Epoch #143: loss=0.01457070919538354
Epoch #144: loss=0.018435922665776764
Epoch #145: loss=0.014237466843871983
Epoch #146: loss=0.014868891516622776
Epoch #147: loss=0.01873136410754739
Epoch #148: loss=0.014048069813592357
Epoch #149: loss=0.019632360141323146
Epoch #150: loss=0.017267311321452733
Epoch #151: loss=0.013533925950460926
Epoch #152: loss=0.019668487967993673
Epoch #153: loss=0.026297392543358368
Epoch #154: loss=0.014356502189996739
Epoch #155: loss=0.010646784120455388
Epoch #156: loss=0.015646406991158393
Epoch #157: loss=0.02067371874863714
Epoch #158: loss=0.01897505495689138
Epoch #159: loss=0.013972768379772543
Epoch #160: loss=0.016784887142799916
Epoch #161: loss=0.024361817948612363
Epoch #162: loss=0.017261699757610674
Epoch #163: loss=0.013097988390837848
Epoch #164: loss=0.01620683451428734
Epoch #165: loss=0.017742426979752847
Epoch #166: loss=0.016626425601619605
Epoch #167: loss=0.010872363450123226
Epoch #168: loss=0.015538570743017666
Epoch #169: loss=0.011154956242277423
Epoch #170: loss=0.033411736730955426
Epoch #171: loss=0.012763417307027035
Epoch #172: loss=0.011219004999097448
Epoch #173: loss=0.01766878759112394
Epoch #174: loss=0.015372814812167864
Epoch #175: loss=0.02125264979717925
Epoch #176: loss=0.014356438850328158
Epoch #177: loss=0.015067394977202253
Epoch #178: loss=0.012397835977429139
Epoch #179: loss=0.014176685817273858
Epoch #180: loss=0.01144231519220484
Epoch #181: loss=0.009352980813737092
Epoch #182: loss=0.025350285443284725
Epoch #183: loss=0.011693852027543744
Epoch #184: loss=0.018446664396541426
Epoch #185: loss=0.014639066407394596
Epoch #186: loss=0.015032510966912648
Epoch #187: loss=0.012029757247946369
Epoch #188: loss=0.01366048519986791
Epoch #189: loss=0.01555134500733668
Epoch #190: loss=0.017351092563133486
Epoch #191: loss=0.014379118260108079
Epoch #192: loss=0.019747021540185986
Epoch #193: loss=0.014437005830615923
Epoch #194: loss=0.018249027014210828
Epoch #195: loss=0.01339444669804694
Epoch #196: loss=0.010446934744066962
Epoch #197: loss=0.01082940725069805
Epoch #198: loss=0.016412025049700997
Epoch #199: loss=0.011541382709526753
Epoch #200: loss=0.016486362942796384
Epoch #201: loss=0.022988950773601236
Epoch #202: loss=0.012164007956947222
Epoch #203: loss=0.01735125411034212
Epoch #204: loss=0.011506354523203073
Epoch #205: loss=0.014322175424335089
Epoch #206: loss=0.01618080365466772
Epoch #207: loss=0.014137152494128601
Epoch #208: loss=0.01783965729433679
Epoch #209: loss=0.01468368550127729
Epoch #210: loss=0.016809979561476656
Epoch #211: loss=0.01795854695198814
Epoch #212: loss=0.014314558684120314
Epoch #213: loss=0.014538256318022467
Epoch #214: loss=0.012150413190349338
Epoch #215: loss=0.010585333386919945
Epoch #216: loss=0.01421480957674072
Epoch #217: loss=0.013957217803231625
Epoch #218: loss=0.011309037062794961
Epoch #219: loss=0.011578254483774014
Epoch #220: loss=0.014667527205154768
Epoch #221: loss=0.01507743247727949
Epoch #222: loss=0.016681589896350806
Epoch #223: loss=0.011173729657687082
Epoch #224: loss=0.012557436629012975
Epoch #225: loss=0.010848960857695935
Epoch #226: loss=0.01967577191756886
Epoch #227: loss=0.015447453363060618
Epoch #228: loss=0.01306394636266489
Epoch #229: loss=0.016150443680548944
Epoch #230: loss=0.014650750138584405
Epoch #231: loss=0.012258693325221266
Epoch #232: loss=0.01181130470612287
Epoch #233: loss=0.010582060307813659
Epoch #234: loss=0.013480091322206192
Epoch #235: loss=0.013812810450017242
Epoch #236: loss=0.010115540307733912
Epoch #237: loss=0.013850681371487943
Epoch #238: loss=0.020741376639805978
Epoch #239: loss=0.01643579150839333
Epoch #240: loss=0.020420009042618453
Epoch #241: loss=0.014661526505799966
Epoch #242: loss=0.011465828220180394
Epoch #243: loss=0.01365681751502602
Epoch #244: loss=0.018032742624864928
Epoch #245: loss=0.01477370129261387
Epoch #246: loss=0.013756807122375932
Epoch #247: loss=0.010410729174973786
Epoch #248: loss=0.011982590401586937
Epoch #249: loss=0.018110353003451596

Training time: 3:28:48.076303

Finished.
n2one setting etth2_traffic_weather_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_traffic_weather_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='etth2_traffic_weather_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.43418e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.86614e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.76693e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.43418e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.41355762897316356, 'MAE': 0.45858771118873753}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='ettm1_ettm2_electricity_traffic', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/ettm1_ettm2_electricity_traffic_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.8275039437153527
Epoch #1: loss=0.30112498248637465
Epoch #2: loss=0.192604776270904
Epoch #3: loss=0.14123083671779058
Epoch #4: loss=0.11218847192329243
Epoch #5: loss=0.09081467546955431
Epoch #6: loss=0.08357484040712296
Epoch #7: loss=0.06424839916094148
Epoch #8: loss=0.058718105146267234
Epoch #9: loss=0.0601086998226979
Epoch #10: loss=0.051019846000302876
Epoch #11: loss=0.05573579231876091
Epoch #12: loss=0.0375277032959758
Epoch #13: loss=0.03818087691356161
Epoch #14: loss=0.042855312687603765
Epoch #15: loss=0.030995746234265695
Epoch #16: loss=0.03838160390003403
Epoch #17: loss=0.03388646605040074
Epoch #18: loss=0.027970590800987905
Epoch #19: loss=0.028886701460856232
Epoch #20: loss=0.02886957910995838
Epoch #21: loss=0.024292706273384083
Epoch #22: loss=0.033899199675007326
Epoch #23: loss=0.02222882719455418
Epoch #24: loss=0.022628578297065424
Epoch #25: loss=0.029083358371703734
Epoch #26: loss=0.02032423622667581
Epoch #27: loss=0.02360378226658515
Epoch #28: loss=0.024443628837033736
Epoch #29: loss=0.02246398389024498
Epoch #30: loss=0.022883206251617404
Epoch #31: loss=0.02651711589399787
Epoch #32: loss=0.027351271115867538
Epoch #33: loss=0.01694904541496779
Epoch #34: loss=0.017156157242153535
Epoch #35: loss=0.022948943333520603
Epoch #36: loss=0.024631881863757952
Epoch #37: loss=0.021917861643492697
Epoch #38: loss=0.017182606407315604
Epoch #39: loss=0.014600759062085751
Epoch #40: loss=0.023616729596633603
Epoch #41: loss=0.015375701628028341
Epoch #42: loss=0.01885792408737497
Epoch #43: loss=0.018124176538259533
Epoch #44: loss=0.018219726760118148
Epoch #45: loss=0.01597611139580623
Epoch #46: loss=0.016378755744399804
Epoch #47: loss=0.018007297826608686
Epoch #48: loss=0.019373220516778374
Epoch #49: loss=0.016199009448890786
Epoch #50: loss=0.016462192597076358
Epoch #51: loss=0.016621214964357495
Epoch #52: loss=0.021523857974839546
Epoch #53: loss=0.016313903198936854
Epoch #54: loss=0.0189896331748131
Epoch #55: loss=0.016339146524003062
Epoch #56: loss=0.01653221581595915
Epoch #57: loss=0.01702630531721018
Epoch #58: loss=0.015838517222400848
Epoch #59: loss=0.016615314293904927
Epoch #60: loss=0.015268530500729093
Epoch #61: loss=0.028951665778915857
Epoch #62: loss=0.01450828112221296
Epoch #63: loss=0.016144601073677853
Epoch #64: loss=0.01590206559650364
Epoch #65: loss=0.01443869635152159
Epoch #66: loss=0.01321873609072609
Epoch #67: loss=0.016084727643664417
Epoch #68: loss=0.0167511598523455
Epoch #69: loss=0.01403347747400403
Epoch #70: loss=0.013714537104128965
Epoch #71: loss=0.012910369728040723
Epoch #72: loss=0.012810314700929583
Epoch #73: loss=0.01931695807932903
Epoch #74: loss=0.011321785667050374
Epoch #75: loss=0.011318484259961575
Epoch #76: loss=0.013635861225987986
Epoch #77: loss=0.01482396153474702
Epoch #78: loss=0.016381408057066407
Epoch #79: loss=0.014872144738620889
Epoch #80: loss=0.015340269192825245
Epoch #81: loss=0.013009935198641572
Epoch #82: loss=0.012284334979869745
Epoch #83: loss=0.015895730427853257
Epoch #84: loss=0.01321686466595958
Epoch #85: loss=0.011476480171419641
Epoch #86: loss=0.015255896095065708
Epoch #87: loss=0.013421758589662295
Epoch #88: loss=0.016842495757314526
Epoch #89: loss=0.013727802085121166
Epoch #90: loss=0.01273763176890407
Epoch #91: loss=0.01007093405392102
Epoch #92: loss=0.010448788827624756
Epoch #93: loss=0.016227375889168973
Epoch #94: loss=0.014259510632734543
Epoch #95: loss=0.011463531008023088
Epoch #96: loss=0.01993097469968532
Epoch #97: loss=0.011454623500421389
Epoch #98: loss=0.011367325867629546
Epoch #99: loss=0.013400140365211803
Epoch #100: loss=0.01275301246613523
Epoch #101: loss=0.012474825434170323
Epoch #102: loss=0.017985178115057926
Epoch #103: loss=0.014205743078962626
Epoch #104: loss=0.010156348403522704
Epoch #105: loss=0.013238780271828066
Epoch #106: loss=0.010559008203816882
Epoch #107: loss=0.014535716108888912
Epoch #108: loss=0.009318781369829481
Epoch #109: loss=0.012438583770511803
Epoch #110: loss=0.010027642701863586
Epoch #111: loss=0.012481976368008529
Epoch #112: loss=0.015121616011147804
Epoch #113: loss=0.012312644364865868
Epoch #114: loss=0.011994487754841184
Epoch #115: loss=0.011765720572538049
Epoch #116: loss=0.010724380095291272
Epoch #117: loss=0.012094828506344272
Epoch #118: loss=0.014216819316843385
Epoch #119: loss=0.012564164352568477
Epoch #120: loss=0.012351099804973311
Epoch #121: loss=0.010075639199351514
Epoch #122: loss=0.010893053330767984
Epoch #123: loss=0.022538515406586346
Epoch #124: loss=0.009482662707950758
Epoch #125: loss=0.00999733545931918
Epoch #126: loss=0.011210125780889486
Epoch #127: loss=0.011272777647719367
Epoch #128: loss=0.009428648358774641
Epoch #129: loss=0.00927679742904065
Epoch #130: loss=0.011482093985051426
Epoch #131: loss=0.018240544817536487
Epoch #132: loss=0.008641560087671226
Epoch #133: loss=0.010474722543178239
Epoch #134: loss=0.009106144396886732
Epoch #135: loss=0.012232856655557865
Epoch #136: loss=0.008365560728654214
Epoch #137: loss=0.011784697375422115
Epoch #138: loss=0.010478936166454714
Epoch #139: loss=0.016408189988940957
Epoch #140: loss=0.009018668758342839
Epoch #141: loss=0.010247365736749885
Epoch #142: loss=0.009421561133390374
Epoch #143: loss=0.011719577280474592
Epoch #144: loss=0.012751141180626934
Epoch #145: loss=0.010967420094962429
Epoch #146: loss=0.009103815209896293
Epoch #147: loss=0.008979187686398675
Epoch #148: loss=0.013597269807662042
Epoch #149: loss=0.010855919599443233
Epoch #150: loss=0.010224073664845582
Epoch #151: loss=0.00880406979492337
Epoch #152: loss=0.018551102177775176
Epoch #153: loss=0.009049771910270529
Epoch #154: loss=0.009896933808540186
Epoch #155: loss=0.010013041858157023
Epoch #156: loss=0.010745424605423924
Epoch #157: loss=0.00770348226341189
Epoch #158: loss=0.011645582743729097
Epoch #159: loss=0.010368982169553925
Epoch #160: loss=0.010642273949740523
Epoch #161: loss=0.009201892318855681
Epoch #162: loss=0.012426621387268251
Epoch #163: loss=0.009285425317002253
Epoch #164: loss=0.010031035455647581
Epoch #165: loss=0.010553921059024456
Epoch #166: loss=0.010427933608569907
Epoch #167: loss=0.011568314059466246
Epoch #168: loss=0.009016771246659805
Epoch #169: loss=0.01025152021484774
Epoch #170: loss=0.009864901424000993
Epoch #171: loss=0.008986514869869011
Epoch #172: loss=0.010366653524798942
Epoch #173: loss=0.012884366488713613
Epoch #174: loss=0.009975406970072554
Epoch #175: loss=0.009443208247401918
Epoch #176: loss=0.012401908954236651
Epoch #177: loss=0.008845271425379
Epoch #178: loss=0.020788825765596045
Epoch #179: loss=0.010424026138714614
Epoch #180: loss=0.00866928483499359
Epoch #181: loss=0.008503543974105191
Epoch #182: loss=0.009223166516985883
Epoch #183: loss=0.009898464821814753
Epoch #184: loss=0.009363022572437013
Epoch #185: loss=0.009436147617357562
Epoch #186: loss=0.009354847496862356
Epoch #187: loss=0.010798149456268107
Epoch #188: loss=0.008381054707944367
Epoch #189: loss=0.009775466503103503
Epoch #190: loss=0.008819781658965447
Epoch #191: loss=0.0092527681166795
Epoch #192: loss=0.010336383223918623
Epoch #193: loss=0.008075648795123042
Epoch #194: loss=0.01270969626308985
Epoch #195: loss=0.009209258301368107
Epoch #196: loss=0.0105567668239645
Epoch #197: loss=0.006633244853806576
Epoch #198: loss=0.012869189337380927
Epoch #199: loss=0.007871294918789382
Epoch #200: loss=0.010162038783421083
Epoch #201: loss=0.007982586921821638
Epoch #202: loss=0.008101060606973512
Epoch #203: loss=0.00833409619950257
Epoch #204: loss=0.010133252085280252
Epoch #205: loss=0.008350252932393309
Epoch #206: loss=0.011358496234476899
Epoch #207: loss=0.013742989206761973
Epoch #208: loss=0.00890115455370947
Epoch #209: loss=0.005709327809669969
Epoch #210: loss=0.009754826660901772
Epoch #211: loss=0.011195578055755289
Epoch #212: loss=0.008951549382102134
Epoch #213: loss=0.007301152250207806
Epoch #214: loss=0.009155096184811072
Epoch #215: loss=0.00901604899704863
Epoch #216: loss=0.0091018031868133
Epoch #217: loss=0.011326539379373217
Epoch #218: loss=0.007927563087036543
Epoch #219: loss=0.008962289747106746
Epoch #220: loss=0.009635028279654116
Epoch #221: loss=0.00894246861013522
Epoch #222: loss=0.01336537096244853
Epoch #223: loss=0.011127975613303401
Epoch #224: loss=0.007834106238659846
Epoch #225: loss=0.006923050970538071
Epoch #226: loss=0.010298765540195202
Epoch #227: loss=0.011625922409997755
Epoch #228: loss=0.008046448817795444
Epoch #229: loss=0.008396001565887375
Epoch #230: loss=0.011412214924465319
Epoch #231: loss=0.011731558387646335
Epoch #232: loss=0.005874522720458502
Epoch #233: loss=0.00968536343796254
Epoch #234: loss=0.008627288967110864
Epoch #235: loss=0.00951630499983676
Epoch #236: loss=0.012374007942892139
Epoch #237: loss=0.012755080907235088
Epoch #238: loss=0.006858048028314073
Epoch #239: loss=0.006357361120666973
Epoch #240: loss=0.018057632224411604
Epoch #241: loss=0.008622275384556486
Epoch #242: loss=0.00615064586103419
Epoch #243: loss=0.00868297473404796
Epoch #244: loss=0.011364498534321947
Epoch #245: loss=0.005063014271980295
Epoch #246: loss=0.006562300996878571
Epoch #247: loss=0.010396279517563129
Epoch #248: loss=0.009101349832116929
Epoch #249: loss=0.006662987844763214

Training time: 5:00:08.034367

Finished.
n2one setting ettm1_ettm2_electricity_traffic -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm1_ettm2_electricity_traffic_epochs_250_seed_2022/model.pkl', muti_dataset='ettm1_ettm2_electricity_traffic', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.19621e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.20477e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.68404e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4719976917697759, 'MAE': 0.5278247510232944}
Finished.
------------------------- record done -------------------------
n2one setting ettm1_ettm2_electricity_traffic -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm1_ettm2_electricity_traffic_epochs_250_seed_2022/model.pkl', muti_dataset='ettm1_ettm2_electricity_traffic', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
Evaluation result: {'MSE': 0.20403433096111895, 'MAE': 0.3114188743987021}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='ettm1_ettm2_electricity_weather', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/ettm1_ettm2_electricity_weather_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.6651318113655256
Epoch #1: loss=0.833625081431898
Epoch #2: loss=0.5598066358708431
Epoch #3: loss=0.46038164961628797
Epoch #4: loss=0.4149190787942752
Epoch #5: loss=0.33394186715608043
Epoch #6: loss=0.34316903148805544
Epoch #7: loss=0.2732760712585152
Epoch #8: loss=0.24448890547926833
Epoch #9: loss=0.21422375601320084
Epoch #10: loss=0.20111698685542032
Epoch #11: loss=0.18764373643934565
Epoch #12: loss=0.16838051327239206
Epoch #13: loss=0.16096888660253872
Epoch #14: loss=0.15336747428144865
Epoch #15: loss=0.13044373331172518
Epoch #16: loss=0.1342295345151166
Epoch #17: loss=0.1286632857843224
Epoch #18: loss=0.1237149305116678
Epoch #19: loss=0.10716647767590556
Epoch #20: loss=0.13452527556709723
Epoch #21: loss=0.1043578977406348
Epoch #22: loss=0.09274612450189787
Epoch #23: loss=0.08785127942780976
Epoch #24: loss=0.07495893664698453
Epoch #25: loss=0.08951335601119935
Epoch #26: loss=0.07705967325520346
Epoch #27: loss=0.07869064808522823
Epoch #28: loss=0.06060978334629277
Epoch #29: loss=0.0638617279871208
Epoch #30: loss=0.054853855757179056
Epoch #31: loss=0.055340760586869105
Epoch #32: loss=0.0723822715220251
Epoch #33: loss=0.09833706519377183
Epoch #34: loss=0.057937365993201165
Epoch #35: loss=0.04939072357419989
Epoch #36: loss=0.038085670260268295
Epoch #37: loss=0.03762397490540231
Epoch #38: loss=0.03209577255496165
Epoch #39: loss=0.05170591642858011
Epoch #40: loss=0.05365911925395794
Epoch #41: loss=0.03804173480421506
Epoch #42: loss=0.040001840483041375
Epoch #43: loss=0.044006303242385025
Epoch #44: loss=0.033010644112905455
Epoch #45: loss=0.05182274660034999
Epoch #46: loss=0.03494173709901307
Epoch #47: loss=0.030018104201808653
Epoch #48: loss=0.04499426840578628
Epoch #49: loss=0.05327195579187344
Epoch #50: loss=0.06817167942528297
Epoch #51: loss=0.04097622127315095
Epoch #52: loss=0.03534753466950007
Epoch #53: loss=0.032467480491768556
Epoch #54: loss=0.04195088604155948
Epoch #55: loss=0.040741787254204596
Epoch #56: loss=0.03945861149170413
Epoch #57: loss=0.04082521403001414
Epoch #58: loss=0.03149424297236623
Epoch #59: loss=0.03276865500899986
Epoch #60: loss=0.02947304016868849
Epoch #61: loss=0.026438773810979595
Epoch #62: loss=0.029554622171782362
Epoch #63: loss=0.02251090688869448
Epoch #64: loss=0.03173005956996151
Epoch #65: loss=0.03272724777256924
Epoch #66: loss=0.030626852987498187
Epoch #67: loss=0.026232623465978832
Epoch #68: loss=0.03845193890190928
Epoch #69: loss=0.026713739679608908
Epoch #70: loss=0.03123108102709085
Epoch #71: loss=0.024695111224572942
Epoch #72: loss=0.025179681531910792
Epoch #73: loss=0.027742479600045115
Epoch #74: loss=0.023663836133825344
Epoch #75: loss=0.024308874280170506
Epoch #76: loss=0.04083995635780256
Epoch #77: loss=0.03355305842351078
Epoch #78: loss=0.053034479208643924
Epoch #79: loss=0.021042633951555808
Epoch #80: loss=0.029327102191935527
Epoch #81: loss=0.02255156441234547
Epoch #82: loss=0.02589454293928707
Epoch #83: loss=0.024535616746533227
Epoch #84: loss=0.025147267928988064
Epoch #85: loss=0.021476997961075647
Epoch #86: loss=0.021069974932399375
Epoch #87: loss=0.023764091777945882
Epoch #88: loss=0.020526265583681272
Epoch #89: loss=0.024820173352320746
Epoch #90: loss=0.016527213309866284
Epoch #91: loss=0.026244036063487543
Epoch #92: loss=0.04043303093832582
Epoch #93: loss=0.024755825055763125
Epoch #94: loss=0.022603896106587
Epoch #95: loss=0.022850866030099067
Epoch #96: loss=0.028499956926719607
Epoch #97: loss=0.023598134667842288
Epoch #98: loss=0.021496346232993655
Epoch #99: loss=0.015426512953521165
Epoch #100: loss=0.01630243138163439
Epoch #101: loss=0.020124450976503533
Epoch #102: loss=0.024616145936306566
Epoch #103: loss=0.020394545276889067
Epoch #104: loss=0.023969406162345715
Epoch #105: loss=0.01914333967478734
Epoch #106: loss=0.02569819232912704
Epoch #107: loss=0.019000505864636613
Epoch #108: loss=0.019025961047721154
Epoch #109: loss=0.0214616788233672
Epoch #110: loss=0.037806989171423604
Epoch #111: loss=0.023338237191805347
Epoch #112: loss=0.026861895484657995
Epoch #113: loss=0.017765111096208375
Epoch #114: loss=0.01611995436238544
Epoch #115: loss=0.01818450656246273
Epoch #116: loss=0.025004746845884242
Epoch #117: loss=0.018713290298510304
Epoch #118: loss=0.015550810729814719
Epoch #119: loss=0.014692146972775823
Epoch #120: loss=0.012652871903122925
Epoch #121: loss=0.029304983676568957
Epoch #122: loss=0.028542638697338397
Epoch #123: loss=0.027254446932880667
Epoch #124: loss=0.02251507531596615
Epoch #125: loss=0.021789123790514047
Epoch #126: loss=0.018610392019328053
Epoch #127: loss=0.017377967319828595
Epoch #128: loss=0.021150416796957585
Epoch #129: loss=0.013410685006920298
Epoch #130: loss=0.017272117630506647
Epoch #131: loss=0.029150276418351304
Epoch #132: loss=0.026787504400940597
Epoch #133: loss=0.02856239082299925
Epoch #134: loss=0.018252461763454707
Epoch #135: loss=0.01742073414982284
Epoch #136: loss=0.020248129327060924
Epoch #137: loss=0.02411276740126115
Epoch #138: loss=0.018843697978065004
Epoch #139: loss=0.012809379592122697
Epoch #140: loss=0.0138872822244692
Epoch #141: loss=0.016036922941684753
Epoch #142: loss=0.012951610979168526
Epoch #143: loss=0.020140129409201676
Epoch #144: loss=0.016088979298388963
Epoch #145: loss=0.01718198032314614
Epoch #146: loss=0.01409432913024019
Epoch #147: loss=0.025151576899840097
Epoch #148: loss=0.01773593282856446
Epoch #149: loss=0.017125196482350186
Epoch #150: loss=0.025372797993660417
Epoch #151: loss=0.015551130698904203
Epoch #152: loss=0.010911666910491535
Epoch #153: loss=0.015232253050463789
Epoch #154: loss=0.023662269802582337
Epoch #155: loss=0.012838551641011555
Epoch #156: loss=0.025067303683211254
Epoch #157: loss=0.014755209331491553
Epoch #158: loss=0.027633533950809575
Epoch #159: loss=0.012985703386940557
Epoch #160: loss=0.021589562440572464
Epoch #161: loss=0.01917277916453193
Epoch #162: loss=0.011230186343307892
Epoch #163: loss=0.015977765107432727
Epoch #164: loss=0.015494511241432744
Epoch #165: loss=0.016023906270391623
Epoch #166: loss=0.02428427936419653
Epoch #167: loss=0.015538773521355688
Epoch #168: loss=0.023849600691633516
Epoch #169: loss=0.01379441961060533
Epoch #170: loss=0.009660149246471907
Epoch #171: loss=0.018299706921935444
Epoch #172: loss=0.016856788359468848
Epoch #173: loss=0.016713028538547493
Epoch #174: loss=0.014931494262836732
Epoch #175: loss=0.012503376406955667
Epoch #176: loss=0.016735148708731048
Epoch #177: loss=0.01628509607023451
Epoch #178: loss=0.015740122740424484
Epoch #179: loss=0.016859919166644824
Epoch #180: loss=0.01601638485958956
Epoch #181: loss=0.022810983403269102
Epoch #182: loss=0.01861776049841362
Epoch #183: loss=0.017617323242606175
Epoch #184: loss=0.01399009910962345
Epoch #185: loss=0.012055022901505848
Epoch #186: loss=0.01143520317203807
Epoch #187: loss=0.012188118838939846
Epoch #188: loss=0.024201472700311016
Epoch #189: loss=0.022382542011889613
Epoch #190: loss=0.015556885037671516
Epoch #191: loss=0.012541756700524974
Epoch #192: loss=0.024864740491633966
Epoch #193: loss=0.020228068319213675
Epoch #194: loss=0.01620520420402773
Epoch #195: loss=0.014759768445586135
Epoch #196: loss=0.017516454792963872
Epoch #197: loss=0.010614066760795226
Epoch #198: loss=0.015957781436941765
Epoch #199: loss=0.023992022725410865
Epoch #200: loss=0.02602813328502114
Epoch #201: loss=0.014985930052100678
Epoch #202: loss=0.010163678863523705
Epoch #203: loss=0.014653680296750427
Epoch #204: loss=0.022966377002134702
Epoch #205: loss=0.014252799533690555
Epoch #206: loss=0.010033654794065398
Epoch #207: loss=0.020288854071016733
Epoch #208: loss=0.014849879073015689
Epoch #209: loss=0.011886411838815232
Epoch #210: loss=0.01040006360271157
Epoch #211: loss=0.012458408786315813
Epoch #212: loss=0.016884376441061038
Epoch #213: loss=0.01145017870574392
Epoch #214: loss=0.01441985565696106
Epoch #215: loss=0.01549554307239009
Epoch #216: loss=0.011028710844453934
Epoch #217: loss=0.01691663698315353
Epoch #218: loss=0.019593436261487563
Epoch #219: loss=0.010420915324759587
Epoch #220: loss=0.016998346557091103
Epoch #221: loss=0.015208763420281473
Epoch #222: loss=0.010444204772722865
Epoch #223: loss=0.017837006985894494
Epoch #224: loss=0.010049530955742625
Epoch #225: loss=0.022505307114100384
Epoch #226: loss=0.015492952403282434
Epoch #227: loss=0.010983768731389109
Epoch #228: loss=0.01287607558662839
Epoch #229: loss=0.013146592697761524
Epoch #230: loss=0.020309819420768063
Epoch #231: loss=0.015477241704216464
Epoch #232: loss=0.021609306067283843
Epoch #233: loss=0.01174134233053761
Epoch #234: loss=0.009815632396719613
Epoch #235: loss=0.022616007766114714
Epoch #236: loss=0.014599146716723214
Epoch #237: loss=0.017243387204876327
Epoch #238: loss=0.011986662776475686
Epoch #239: loss=0.011233051000765543
Epoch #240: loss=0.024405695956473576
Epoch #241: loss=0.027482470938384403
Epoch #242: loss=0.018226995448983176
Epoch #243: loss=0.008920200624021128
Epoch #244: loss=0.010410586454754766
Epoch #245: loss=0.007258406171192186
Epoch #246: loss=0.011457834493348041
Epoch #247: loss=0.018107700271741425
Epoch #248: loss=0.013983479989023733
Epoch #249: loss=0.01806206664780021

Training time: 1:45:08.047007

Finished.
n2one setting ettm1_ettm2_electricity_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm1_ettm2_electricity_weather_epochs_250_seed_2022/model.pkl', muti_dataset='ettm1_ettm2_electricity_weather', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.56163e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.56163e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3688113630097451, 'MAE': 0.399634741489312}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='ettm1_ettm2_electricity_exchange', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/ettm1_ettm2_electricity_exchange_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.6663773992122748
Epoch #1: loss=0.7487339662690448
Epoch #2: loss=0.5100356015214893
Epoch #3: loss=0.4108949124473452
Epoch #4: loss=0.3690216335815582
Epoch #5: loss=0.31392810425782136
Epoch #6: loss=0.2803008724693899
Epoch #7: loss=0.2470703695149843
Epoch #8: loss=0.22174687630515494
Epoch #9: loss=0.1959106968530053
Epoch #10: loss=0.18317904879479666
Epoch #11: loss=0.18130917542553016
Epoch #12: loss=0.16588551641317176
Epoch #13: loss=0.14296490366854558
Epoch #14: loss=0.14199136868331508
Epoch #15: loss=0.13024743715370143
Epoch #16: loss=0.13836023598336256
Epoch #17: loss=0.12123632743063135
Epoch #18: loss=0.11536497987828023
Epoch #19: loss=0.09169349877529928
Epoch #20: loss=0.09684295343643749
Epoch #21: loss=0.08527894991256318
Epoch #22: loss=0.0968607931777283
Epoch #23: loss=0.08637344503398464
Epoch #24: loss=0.0771298359885833
Epoch #25: loss=0.09130416461465578
Epoch #26: loss=0.07850092460409316
Epoch #27: loss=0.06830571388210199
Epoch #28: loss=0.062379865625878515
Epoch #29: loss=0.05859391884798677
Epoch #30: loss=0.06614077142426517
Epoch #31: loss=0.08314035500285674
Epoch #32: loss=0.0547542496414542
Epoch #33: loss=0.054261704559233626
Epoch #34: loss=0.04858401484662757
Epoch #35: loss=0.06731010656644645
Epoch #36: loss=0.05719578711905031
Epoch #37: loss=0.0657143598990223
Epoch #38: loss=0.050610583365106813
Epoch #39: loss=0.05285634507525956
Epoch #40: loss=0.06909728516291222
Epoch #41: loss=0.05890343876083268
Epoch #42: loss=0.04365722111564268
Epoch #43: loss=0.03916997241156117
Epoch #44: loss=0.050356389280737636
Epoch #45: loss=0.05476648013367506
Epoch #46: loss=0.07572349825836824
Epoch #47: loss=0.04515085053202986
Epoch #48: loss=0.04890498688425922
Epoch #49: loss=0.0590748699319594
Epoch #50: loss=0.045962252100913696
Epoch #51: loss=0.03705054710146857
Epoch #52: loss=0.03228748215036069
Epoch #53: loss=0.028880282632868598
Epoch #54: loss=0.03827666877065798
Epoch #55: loss=0.040179078134859346
Epoch #56: loss=0.040003396728556295
Epoch #57: loss=0.04331467738189334
Epoch #58: loss=0.030454234566348486
Epoch #59: loss=0.039541561605091716
Epoch #60: loss=0.0403340445702731
Epoch #61: loss=0.036022895610456136
Epoch #62: loss=0.043049424792841566
Epoch #63: loss=0.03995367526932436
Epoch #64: loss=0.03191097603216661
Epoch #65: loss=0.030293147071520733
Epoch #66: loss=0.02762318044692607
Epoch #67: loss=0.03097188175490731
Epoch #68: loss=0.03441999981327757
Epoch #69: loss=0.03341624666266727
Epoch #70: loss=0.042559121257129344
Epoch #71: loss=0.04172210726240899
Epoch #72: loss=0.0318598770795183
Epoch #73: loss=0.02857456130885713
Epoch #74: loss=0.028265824610768073
Epoch #75: loss=0.032745814501132786
Epoch #76: loss=0.045674155217176174
Epoch #77: loss=0.028266296976383914
Epoch #78: loss=0.027132571877863925
Epoch #79: loss=0.032393898273966784
Epoch #80: loss=0.02536489601788294
Epoch #81: loss=0.026198838248900656
Epoch #82: loss=0.030395797035256213
Epoch #83: loss=0.0365894404880071
Epoch #84: loss=0.03504669031810196
Epoch #85: loss=0.023135962952930012
Epoch #86: loss=0.025589204091178066
Epoch #87: loss=0.029503607165607015
Epoch #88: loss=0.026581033482547967
Epoch #89: loss=0.02239333894906401
Epoch #90: loss=0.02905128602876442
Epoch #91: loss=0.026607581794373374
Epoch #92: loss=0.026845973407242055
Epoch #93: loss=0.02196493945077879
Epoch #94: loss=0.023211707591219804
Epoch #95: loss=0.028569704567432467
Epoch #96: loss=0.024856135028578936
Epoch #97: loss=0.029114122767176513
Epoch #98: loss=0.021913816520222527
Epoch #99: loss=0.0232625065667905
Epoch #100: loss=0.023668696058441772
Epoch #101: loss=0.022421626917065316
Epoch #102: loss=0.03936192409620962
Epoch #103: loss=0.023105466600037858
Epoch #104: loss=0.014563052086199388
Epoch #105: loss=0.022365331288096774
Epoch #106: loss=0.022506879994339254
Epoch #107: loss=0.0195840097376095
Epoch #108: loss=0.021021626445105263
Epoch #109: loss=0.022024111761054836
Epoch #110: loss=0.031215453574147362
Epoch #111: loss=0.0230617765304062
Epoch #112: loss=0.019840530290479302
Epoch #113: loss=0.05461679028822746
Epoch #114: loss=0.046750802540106225
Epoch #115: loss=0.026886769885494457
Epoch #116: loss=0.02019541960161848
Epoch #117: loss=0.021153116672438438
Epoch #118: loss=0.024652839608276873
Epoch #119: loss=0.021226550916414125
Epoch #120: loss=0.01915377234727306
Epoch #121: loss=0.018755281939896944
Epoch #122: loss=0.021208483265929105
Epoch #123: loss=0.023530982886978354
Epoch #124: loss=0.015355668629505048
Epoch #125: loss=0.02163055459331944
Epoch #126: loss=0.025908194905368512
Epoch #127: loss=0.017079552704869026
Epoch #128: loss=0.014120224789080165
Epoch #129: loss=0.020768666974410807
Epoch #130: loss=0.01836873433735763
Epoch #131: loss=0.027224896701372514
Epoch #132: loss=0.028076494765000955
Epoch #133: loss=0.02215861709472694
Epoch #134: loss=0.031052254550981512
Epoch #135: loss=0.028405089832131254
Epoch #136: loss=0.03262855778905985
Epoch #137: loss=0.022013532025825785
Epoch #138: loss=0.021946159648799212
Epoch #139: loss=0.018712592356476106
Epoch #140: loss=0.02381055178173799
Epoch #141: loss=0.021171202096408843
Epoch #142: loss=0.024192409586901657
Epoch #143: loss=0.026859529358878774
Epoch #144: loss=0.024185694975677633
Epoch #145: loss=0.024027732813096024
Epoch #146: loss=0.023458129976095997
Epoch #147: loss=0.03574620502516017
Epoch #148: loss=0.023556050956262505
Epoch #149: loss=0.014830637116919131
Epoch #150: loss=0.013996033418686143
Epoch #151: loss=0.020487154049744452
Epoch #152: loss=0.01768183757659138
Epoch #153: loss=0.02141412197608246
Epoch #154: loss=0.02111878596625007
Epoch #155: loss=0.015398994567100904
Epoch #156: loss=0.01620882327270036
Epoch #157: loss=0.014916274901807833
Epoch #158: loss=0.023332962060169427
Epoch #159: loss=0.02046381080918813
Epoch #160: loss=0.029747954723319075
Epoch #161: loss=0.021698256411445075
Epoch #162: loss=0.020240029660577585
Epoch #163: loss=0.01371642359838545
Epoch #164: loss=0.015351308859782585
Epoch #165: loss=0.025788989284558705
Epoch #166: loss=0.020269739463297846
Epoch #167: loss=0.017569030764740905
Epoch #168: loss=0.018108155442971573
Epoch #169: loss=0.014422864577052398
Epoch #170: loss=0.018523340540980534
Epoch #171: loss=0.019049971616091312
Epoch #172: loss=0.015543866437508928
Epoch #173: loss=0.01532508957322801
Epoch #174: loss=0.017031387935234683
Epoch #175: loss=0.01286775365082462
Epoch #176: loss=0.025091210532431994
Epoch #177: loss=0.024243659801858126
Epoch #178: loss=0.014344133414292278
Epoch #179: loss=0.018125253094959225
Epoch #180: loss=0.012816216613887743
Epoch #181: loss=0.017021515780623386
Epoch #182: loss=0.019708628283662356
Epoch #183: loss=0.029857340713888618
Epoch #184: loss=0.016944116242233256
Epoch #185: loss=0.020122791820390156
Epoch #186: loss=0.026691943554816626
Epoch #187: loss=0.025694283956935113
Epoch #188: loss=0.018887497720997144
Epoch #189: loss=0.01630347338911382
Epoch #190: loss=0.01546934208974635
Epoch #191: loss=0.018861596463938004
Epoch #192: loss=0.012349895254524419
Epoch #193: loss=0.01331867477800193
Epoch #194: loss=0.015432615169095793
Epoch #195: loss=0.014091209204028529
Epoch #196: loss=0.012154664178949347
Epoch #197: loss=0.012643920549389209
Epoch #198: loss=0.025413858317710362
Epoch #199: loss=0.020872668474760075
Epoch #200: loss=0.016247199944312025
Epoch #201: loss=0.01351589857958167
Epoch #202: loss=0.017343801038556643
Epoch #203: loss=0.01663253688488283
Epoch #204: loss=0.017716104725071964
Epoch #205: loss=0.015140581156652516
Epoch #206: loss=0.01609400461404319
Epoch #207: loss=0.026803870349087648
Epoch #208: loss=0.017114923325164292
Epoch #209: loss=0.02156531780661665
Epoch #210: loss=0.012183617979242995
Epoch #211: loss=0.010681653249610156
Epoch #212: loss=0.022258960412738265
Epoch #213: loss=0.014406722522223967
Epoch #214: loss=0.010368087901345765
Epoch #215: loss=0.01475051676183196
Epoch #216: loss=0.012750863449424478
Epoch #217: loss=0.020500930769772312
Epoch #218: loss=0.02503305555774334
Epoch #219: loss=0.01964108083606764
Epoch #220: loss=0.015675663893168098
Epoch #221: loss=0.013819219783247658
Epoch #222: loss=0.021314226162631164
Epoch #223: loss=0.019297925131846527
Epoch #224: loss=0.011617701411933141
Epoch #225: loss=0.009973835413084841
Epoch #226: loss=0.014135688749368188
Epoch #227: loss=0.011709292064950883
Epoch #228: loss=0.013479269356178278
Epoch #229: loss=0.012195285690113892
Epoch #230: loss=0.015849548096564914
Epoch #231: loss=0.014127545958458502
Epoch #232: loss=0.015514871748033288
Epoch #233: loss=0.017779999093345447
Epoch #234: loss=0.01797082691627191
Epoch #235: loss=0.01653491331385767
Epoch #236: loss=0.013281472452831298
Epoch #237: loss=0.009654752146555482
Epoch #238: loss=0.01189893457391485
Epoch #239: loss=0.01182686832970263
Epoch #240: loss=0.013010266039121175
Epoch #241: loss=0.012563657039027539
Epoch #242: loss=0.02146822627409271
Epoch #243: loss=0.03299191664553452
Epoch #244: loss=0.015472316142105952
Epoch #245: loss=0.01697268445201303
Epoch #246: loss=0.013671010314500852
Epoch #247: loss=0.014990769223786992
Epoch #248: loss=0.016518258282790715
Epoch #249: loss=0.018107737479048206

Training time: 1:37:16.746953

Finished.
n2one setting ettm1_ettm2_electricity_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm1_ettm2_electricity_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='ettm1_ettm2_electricity_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.36924e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.77457e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.36924e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.5082561161666593, 'MAE': 0.540080069444113}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='ettm1_ettm2_traffic_weather', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/ettm1_ettm2_traffic_weather_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.0477124722776832
Epoch #1: loss=0.41541224559257317
Epoch #2: loss=0.30569373964444624
Epoch #3: loss=0.2234160367849764
Epoch #4: loss=0.1874408834010035
Epoch #5: loss=0.15188393666930905
Epoch #6: loss=0.15546934147785
Epoch #7: loss=0.13195160670758604
Epoch #8: loss=0.1100513697479043
Epoch #9: loss=0.09363121383076349
Epoch #10: loss=0.07443041490124805
Epoch #11: loss=0.08051273564572682
Epoch #12: loss=0.06697002332299375
Epoch #13: loss=0.07354234880844521
Epoch #14: loss=0.053069920599419666
Epoch #15: loss=0.05958320958166291
Epoch #16: loss=0.04760632610721206
Epoch #17: loss=0.04313862155061113
Epoch #18: loss=0.05063230814181964
Epoch #19: loss=0.04509629292393124
Epoch #20: loss=0.04169434303824616
Epoch #21: loss=0.042335262243088416
Epoch #22: loss=0.03386875145907442
Epoch #23: loss=0.04719247053950452
Epoch #24: loss=0.04828935689139333
Epoch #25: loss=0.043029598367098555
Epoch #26: loss=0.03107510226155672
Epoch #27: loss=0.034096282394858755
Epoch #28: loss=0.03326941353657825
Epoch #29: loss=0.03840564969999992
Epoch #30: loss=0.035032202921562144
Epoch #31: loss=0.028621631481039984
Epoch #32: loss=0.03718759341428957
Epoch #33: loss=0.0482753289406761
Epoch #34: loss=0.031402376957319594
Epoch #35: loss=0.03337255407900007
Epoch #36: loss=0.024138446565164805
Epoch #37: loss=0.028956738374948214
Epoch #38: loss=0.025103282157439167
Epoch #39: loss=0.026189675315278122
Epoch #40: loss=0.025265632640406654
Epoch #41: loss=0.02458363413244005
Epoch #42: loss=0.024958245744826375
Epoch #43: loss=0.023546172680069723
Epoch #44: loss=0.027177287483937107
Epoch #45: loss=0.025299112087084942
Epoch #46: loss=0.02313407932818806
Epoch #47: loss=0.022378889159273847
Epoch #48: loss=0.020259900389886513
Epoch #49: loss=0.02818223904206796
Epoch #50: loss=0.022495913447538433
Epoch #51: loss=0.02607372972959458
Epoch #52: loss=0.02681305962326875
Epoch #53: loss=0.020218594023474278
Epoch #54: loss=0.019422421724552157
Epoch #55: loss=0.02361477899510966
Epoch #56: loss=0.02081279627470924
Epoch #57: loss=0.02736464315960772
Epoch #58: loss=0.02832092284679075
Epoch #59: loss=0.030046753934712487
Epoch #60: loss=0.015804685303010046
Epoch #61: loss=0.023149347038054328
Epoch #62: loss=0.017930065334140027
Epoch #63: loss=0.016826249261202474
Epoch #64: loss=0.02880216642547716
Epoch #65: loss=0.01815803634702576
Epoch #66: loss=0.025196937084515262
Epoch #67: loss=0.02197621866330187
Epoch #68: loss=0.025536944801090183
Epoch #69: loss=0.016069069532402485
Epoch #70: loss=0.016398185732164214
Epoch #71: loss=0.018442190561032915
Epoch #72: loss=0.015584993058467632
Epoch #73: loss=0.019033483468340887
Epoch #74: loss=0.02289166743329798
Epoch #75: loss=0.016146363181146477
Epoch #76: loss=0.01645401784434408
Epoch #77: loss=0.025654140764919037
Epoch #78: loss=0.02356490312620056
Epoch #79: loss=0.02395185812496053
Epoch #80: loss=0.01869817956684638
Epoch #81: loss=0.017728058110595076
Epoch #82: loss=0.02522637039057752
Epoch #83: loss=0.019091396198632288
Epoch #84: loss=0.016898447635985275
Epoch #85: loss=0.013453874622591884
Epoch #86: loss=0.023027545851840803
Epoch #87: loss=0.02096982496773957
Epoch #88: loss=0.016005515384329178
Epoch #89: loss=0.03166663172967594
Epoch #90: loss=0.01640330527232356
Epoch #91: loss=0.02009915664825962
Epoch #92: loss=0.01324127602424846
Epoch #93: loss=0.019085530540234267
Epoch #94: loss=0.016038886077093105
Epoch #95: loss=0.01597884090916013
Epoch #96: loss=0.015367538821442145
Epoch #97: loss=0.017870102488630257
Epoch #98: loss=0.025214645540524674
Epoch #99: loss=0.014682663363095304
Epoch #100: loss=0.02340725059880092
Epoch #101: loss=0.013662713783176534
Epoch #102: loss=0.014400153675572026
Epoch #103: loss=0.016134399788871222
Epoch #104: loss=0.0226681644074583
Epoch #105: loss=0.021600428244654232
Epoch #106: loss=0.01191282214057647
Epoch #107: loss=0.012799739565925448
Epoch #108: loss=0.02339970211176698
Epoch #109: loss=0.011532767588681424
Epoch #110: loss=0.017505443284760107
Epoch #111: loss=0.0148742699534773
Epoch #112: loss=0.014005931039087495
Epoch #113: loss=0.011708398556156381
Epoch #114: loss=0.025355945675471378
Epoch #115: loss=0.022831441840645603
Epoch #116: loss=0.014327884413964617
Epoch #117: loss=0.015817493098426724
Epoch #118: loss=0.012162904697742215
Epoch #119: loss=0.012999010111017704
Epoch #120: loss=0.01539047776425902
Epoch #121: loss=0.017334856038272208
Epoch #122: loss=0.016757067834707692
Epoch #123: loss=0.011473099978456459
Epoch #124: loss=0.01816582356596872
Epoch #125: loss=0.019934020613596497
Epoch #126: loss=0.020180211162832976
Epoch #127: loss=0.012731546801508528
Epoch #128: loss=0.014256257542081504
Epoch #129: loss=0.01857512527633814
Epoch #130: loss=0.012974823150252232
Epoch #131: loss=0.01722712013934442
Epoch #132: loss=0.016649063955672637
Epoch #133: loss=0.012587331669343697
Epoch #134: loss=0.013525834596737615
Epoch #135: loss=0.018883273682133602
Epoch #136: loss=0.014170405554750187
Epoch #137: loss=0.01345889437384008
Epoch #138: loss=0.021214798720877177
Epoch #139: loss=0.015199610696987833
Epoch #140: loss=0.01638161011537854
Epoch #141: loss=0.018428691818505514
Epoch #142: loss=0.018418089466381838
Epoch #143: loss=0.013376178991901536
Epoch #144: loss=0.012132227461056523
Epoch #145: loss=0.013964578334859682
Epoch #146: loss=0.012179005841176399
Epoch #147: loss=0.017636715207577702
Epoch #148: loss=0.013981158323656349
Epoch #149: loss=0.01416883920699967
Epoch #150: loss=0.01160939384464035
Epoch #151: loss=0.01661844320550809
Epoch #152: loss=0.012924346540271622
Epoch #153: loss=0.01352919815563777
Epoch #154: loss=0.015561198519052206
Epoch #155: loss=0.013706303893519402
Epoch #156: loss=0.016979697567380703
Epoch #157: loss=0.01759132343893845
Epoch #158: loss=0.01973322572568457
Epoch #159: loss=0.01548998353337283
Epoch #160: loss=0.009066777335317387
Epoch #161: loss=0.013024002123639437
Epoch #162: loss=0.014403678173986698
Epoch #163: loss=0.013848674224697119
Epoch #164: loss=0.00987539192596719
Epoch #165: loss=0.008381001645562259
Epoch #166: loss=0.015762410129313
Epoch #167: loss=0.011724317295842671
Epoch #168: loss=0.012689912508722045
Epoch #169: loss=0.016257252917972975
Epoch #170: loss=0.015589034821979502
Epoch #171: loss=0.010445200792605896
Epoch #172: loss=0.017362911275739572
Epoch #173: loss=0.01764721674806244
Epoch #174: loss=0.016577414484313373
Epoch #175: loss=0.011649192221351428
Epoch #176: loss=0.009465366643169066
Epoch #177: loss=0.01667186329240404
Epoch #178: loss=0.01204099136799354
Epoch #179: loss=0.023282924707906043
Epoch #180: loss=0.012504739339007986
Epoch #181: loss=0.013471860059180071
Epoch #182: loss=0.016030551836305237
Epoch #183: loss=0.010508727249695796
Epoch #184: loss=0.010997299588676209
Epoch #185: loss=0.017478509461703894
Epoch #186: loss=0.008521349298154327
Epoch #187: loss=0.015375680857207523
Epoch #188: loss=0.018394899342668365
Epoch #189: loss=0.011860155052112692
Epoch #190: loss=0.012589481528426245
Epoch #191: loss=0.013943698975848608
Epoch #192: loss=0.01084250300207334
Epoch #193: loss=0.012726252324049071
Epoch #194: loss=0.017997533651957914
Epoch #195: loss=0.016802011648446302
Epoch #196: loss=0.009437233552139683
Epoch #197: loss=0.010544129084499239
Epoch #198: loss=0.012622292628041648
Epoch #199: loss=0.0075830427967418105
Epoch #200: loss=0.017481237921446745
Epoch #201: loss=0.011725523590991672
Epoch #202: loss=0.023442820199508767
Epoch #203: loss=0.019793292135927714
Epoch #204: loss=0.011105699492791145
Epoch #205: loss=0.010049852415627706
Epoch #206: loss=0.009035786178879629
Epoch #207: loss=0.011370391829912698
Epoch #208: loss=0.013517516825791413
Epoch #209: loss=0.00919516322680795
Epoch #210: loss=0.013040320267744111
Epoch #211: loss=0.009521014173131354
Epoch #212: loss=0.014712867865391372
Epoch #213: loss=0.012383894967318227
Epoch #214: loss=0.013974190295986053
Epoch #215: loss=0.016437565652873614
Epoch #216: loss=0.008195637807887748
Epoch #217: loss=0.010816259932567386
Epoch #218: loss=0.011235693060031166
Epoch #219: loss=0.013695402917737439
Epoch #220: loss=0.02147704750037503
Epoch #221: loss=0.007869038827073302
Epoch #222: loss=0.01103658722286627
Epoch #223: loss=0.015335255121517349
Epoch #224: loss=0.014109692066827287
Epoch #225: loss=0.01165288846839378
Epoch #226: loss=0.010933555493046207
Epoch #227: loss=0.01042096596155226
Epoch #228: loss=0.0114252847021287
Epoch #229: loss=0.01002647746110477
Epoch #230: loss=0.014151033341077382
Epoch #231: loss=0.010452097643372746
Epoch #232: loss=0.01795996112602182
Epoch #233: loss=0.010243607225561141
Epoch #234: loss=0.011480466771732048
Epoch #235: loss=0.00871471509730287
Epoch #236: loss=0.009370357600398295
Epoch #237: loss=0.007147580166545615
Epoch #238: loss=0.01236021218083896
Epoch #239: loss=0.013318346107841066
Epoch #240: loss=0.010962410017938445
Epoch #241: loss=0.012755774261825207
Epoch #242: loss=0.010355725160391828
Epoch #243: loss=0.012271914588927757
Epoch #244: loss=0.008807377654059334
Epoch #245: loss=0.010354487895393094
Epoch #246: loss=0.010842707098982917
Epoch #247: loss=0.01829655785789997
Epoch #248: loss=0.013159252751946762
Epoch #249: loss=0.008852167971203776

Training time: 3:39:56.804181

Finished.
n2one setting ettm1_ettm2_traffic_weather -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm1_ettm2_traffic_weather_epochs_250_seed_2022/model.pkl', muti_dataset='ettm1_ettm2_traffic_weather', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.70027e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.80946e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.56139e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.70027e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.41911297307997225, 'MAE': 0.4605849168561047}
Finished.
------------------------- record done -------------------------
n2one setting ettm1_ettm2_traffic_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm1_ettm2_traffic_weather_epochs_250_seed_2022/model.pkl', muti_dataset='ettm1_ettm2_traffic_weather', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.79347e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.33179055279145164, 'MAE': 0.3755295039065031}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='ettm1_ettm2_traffic_exchange', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/ettm1_ettm2_traffic_exchange_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.0266522358885795
Epoch #1: loss=0.3984842901807195
Epoch #2: loss=0.2745779034819437
Epoch #3: loss=0.20396676988261564
Epoch #4: loss=0.16596516917121384
Epoch #5: loss=0.14583709679811258
Epoch #6: loss=0.11782044032588601
Epoch #7: loss=0.11275912391548065
Epoch #8: loss=0.09792657410976531
Epoch #9: loss=0.08916645174775055
Epoch #10: loss=0.08221026378811123
Epoch #11: loss=0.07044397520774248
Epoch #12: loss=0.06400653221091097
Epoch #13: loss=0.06620865235378706
Epoch #14: loss=0.05415780519134252
Epoch #15: loss=0.054694627924569604
Epoch #16: loss=0.05713684627245443
Epoch #17: loss=0.04401887551048194
Epoch #18: loss=0.05057413962767814
Epoch #19: loss=0.04958470102327546
Epoch #20: loss=0.04421007163214994
Epoch #21: loss=0.04398614261638699
Epoch #22: loss=0.03393747262873858
Epoch #23: loss=0.048385381165342696
Epoch #24: loss=0.038816920031230655
Epoch #25: loss=0.03377686383624482
Epoch #26: loss=0.03255412807597282
Epoch #27: loss=0.037050673180972875
Epoch #28: loss=0.03351950352555225
Epoch #29: loss=0.04722594082978817
Epoch #30: loss=0.03165826655504338
Epoch #31: loss=0.032673759783217224
Epoch #32: loss=0.03190809948802633
Epoch #33: loss=0.03229369054472224
Epoch #34: loss=0.03587693282984607
Epoch #35: loss=0.02933749591609601
Epoch #36: loss=0.028791477752201082
Epoch #37: loss=0.04143171865522294
Epoch #38: loss=0.02410107164308554
Epoch #39: loss=0.02046076365885682
Epoch #40: loss=0.026855334911141504
Epoch #41: loss=0.03512872081545428
Epoch #42: loss=0.02554013628561954
Epoch #43: loss=0.028128198602676888
Epoch #44: loss=0.025860665839937028
Epoch #45: loss=0.021671085413273908
Epoch #46: loss=0.024510323293815105
Epoch #47: loss=0.02706941904204129
Epoch #48: loss=0.023342143627880205
Epoch #49: loss=0.02609156567172404
Epoch #50: loss=0.03687229042459329
Epoch #51: loss=0.030096687585642174
Epoch #52: loss=0.025956347003822412
Epoch #53: loss=0.022717857307121742
Epoch #54: loss=0.02034005312906315
Epoch #55: loss=0.02959656149486702
Epoch #56: loss=0.03425161820557595
Epoch #57: loss=0.020117461008193064
Epoch #58: loss=0.01933938922939223
Epoch #59: loss=0.01676968273657401
Epoch #60: loss=0.021591976407725852
Epoch #61: loss=0.022378436584844445
Epoch #62: loss=0.02066819710265339
Epoch #63: loss=0.01971303946016233
Epoch #64: loss=0.02123749710052643
Epoch #65: loss=0.02168576137463963
Epoch #66: loss=0.02262394784367904
Epoch #67: loss=0.02135181564791624
Epoch #68: loss=0.02543290106202747
Epoch #69: loss=0.02244468841238695
Epoch #70: loss=0.018707889403010856
Epoch #71: loss=0.02771487417763972
Epoch #72: loss=0.01929580909467559
Epoch #73: loss=0.019742754800728055
Epoch #74: loss=0.020721208436210743
Epoch #75: loss=0.023217411583030832
Epoch #76: loss=0.018050793712361478
Epoch #77: loss=0.018833448088100398
Epoch #78: loss=0.01863888674030642
Epoch #79: loss=0.019961299994917883
Epoch #80: loss=0.023867401247752742
Epoch #81: loss=0.016987704497035343
Epoch #82: loss=0.014295183938435664
Epoch #83: loss=0.022633648934752802
Epoch #84: loss=0.02081007019971913
Epoch #85: loss=0.020490174323493707
Epoch #86: loss=0.01932474027592438
Epoch #87: loss=0.015862121122085016
Epoch #88: loss=0.02088837212309473
Epoch #89: loss=0.02303777191720876
Epoch #90: loss=0.020733039469273882
Epoch #91: loss=0.014531594229250783
Epoch #92: loss=0.01898849067281991
Epoch #93: loss=0.019269932433943246
Epoch #94: loss=0.01368937852962497
Epoch #95: loss=0.01807835532441467
Epoch #96: loss=0.023971190594458815
Epoch #97: loss=0.015584702971917337
Epoch #98: loss=0.01730858097791921
Epoch #99: loss=0.013847011517675388
Epoch #100: loss=0.015144866412754
Epoch #101: loss=0.0157269272736494
Epoch #102: loss=0.014712992361429589
Epoch #103: loss=0.017353300494285438
Epoch #104: loss=0.01585217005816093
Epoch #105: loss=0.01996459163468401
Epoch #106: loss=0.019288867457362358
Epoch #107: loss=0.019947639371707227
Epoch #108: loss=0.01629705607804032
Epoch #109: loss=0.012551317673365507
Epoch #110: loss=0.0177772663722732
Epoch #111: loss=0.021252800800714636
Epoch #112: loss=0.01675355513272139
Epoch #113: loss=0.017152393476683476
Epoch #114: loss=0.01846932585936117
Epoch #115: loss=0.016027735594324372
Epoch #116: loss=0.013161138058332059
Epoch #117: loss=0.017763021332890448
Epoch #118: loss=0.020866243312468922
Epoch #119: loss=0.013057123652292361
Epoch #120: loss=0.02210827164252491
Epoch #121: loss=0.015344391124743385
Epoch #122: loss=0.017976939653183074
Epoch #123: loss=0.012913554117420005
Epoch #124: loss=0.016965771870664895
Epoch #125: loss=0.015125614588826143
Epoch #126: loss=0.012880063313020355
Epoch #127: loss=0.024587336491959533
Epoch #128: loss=0.02145489415372727
Epoch #129: loss=0.012926819960254186
Epoch #130: loss=0.016266365075426364
Epoch #131: loss=0.01589545470008819
Epoch #132: loss=0.016120610852825516
Epoch #133: loss=0.019413372363585608
Epoch #134: loss=0.013461734356851716
Epoch #135: loss=0.012292192168747187
Epoch #136: loss=0.01813101568928491
Epoch #137: loss=0.016004508974488966
Epoch #138: loss=0.019594009818409773
Epoch #139: loss=0.017590508098076378
Epoch #140: loss=0.011010536508916067
Epoch #141: loss=0.01482659488003607
Epoch #142: loss=0.018421182761633365
Epoch #143: loss=0.01631136426653592
Epoch #144: loss=0.01383261318647628
Epoch #145: loss=0.015307781607038686
Epoch #146: loss=0.01827603755480946
Epoch #147: loss=0.01382546781091387
Epoch #148: loss=0.015726627640154957
Epoch #149: loss=0.010960950541679096
Epoch #150: loss=0.015269589214788012
Epoch #151: loss=0.02140302684768158
Epoch #152: loss=0.01877442327026025
Epoch #153: loss=0.016848295623708816
Epoch #154: loss=0.015807436160456635
Epoch #155: loss=0.014478541592594377
Epoch #156: loss=0.010773676913639457
Epoch #157: loss=0.012846890571691626
Epoch #158: loss=0.018352724611954953
Epoch #159: loss=0.012675588111365224
Epoch #160: loss=0.013185159885707912
Epoch #161: loss=0.013345782412705481
Epoch #162: loss=0.013375213868962236
Epoch #163: loss=0.016938215780410982
Epoch #164: loss=0.012687629555660558
Epoch #165: loss=0.019800666168757825
Epoch #166: loss=0.01736714470064118
Epoch #167: loss=0.015116247410610352
Epoch #168: loss=0.011222295631313146
Epoch #169: loss=0.00997593424176863
Epoch #170: loss=0.014077717799054758
Epoch #171: loss=0.020491235349181153
Epoch #172: loss=0.010188416823463654
Epoch #173: loss=0.017834079257985722
Epoch #174: loss=0.015219126997547926
Epoch #175: loss=0.010519537971253353
Epoch #176: loss=0.016832278988618016
Epoch #177: loss=0.015852445395405753
Epoch #178: loss=0.015134569443931966
Epoch #179: loss=0.009944128810450661
Epoch #180: loss=0.015479894990199078
Epoch #181: loss=0.011958936698288545
Epoch #182: loss=0.01419763641272444
Epoch #183: loss=0.013319972171563672
Epoch #184: loss=0.011144421327320938
Epoch #185: loss=0.01109936286275319
Epoch #186: loss=0.01051653178750092
Epoch #187: loss=0.01670122470373508
Epoch #188: loss=0.010643925579039499
Epoch #189: loss=0.015796267878662375
Epoch #190: loss=0.011152775206766509
Epoch #191: loss=0.015647819194660288
Epoch #192: loss=0.0147411201394487
Epoch #193: loss=0.009417751588994525
Epoch #194: loss=0.01598796815921515
Epoch #195: loss=0.013970584505935349
Epoch #196: loss=0.014306559043191478
Epoch #197: loss=0.013791462575266087
Epoch #198: loss=0.010637384942712066
Epoch #199: loss=0.011470019073549786
Epoch #200: loss=0.014257202757886719
Epoch #201: loss=0.012222027107325409
Epoch #202: loss=0.010815406287831073
Epoch #203: loss=0.02075453697576009
Epoch #204: loss=0.01021840787821489
Epoch #205: loss=0.0110979674644301
Epoch #206: loss=0.012341974366260765
Epoch #207: loss=0.012019550732177454
Epoch #208: loss=0.01105008559134638
Epoch #209: loss=0.014491554879500674
Epoch #210: loss=0.014160121902520664
Epoch #211: loss=0.009049654208873988
Epoch #212: loss=0.011735441852261124
Epoch #213: loss=0.011343284353169857
Epoch #214: loss=0.009909751725569342
Epoch #215: loss=0.01388888272181513
Epoch #216: loss=0.013034230507767995
Epoch #217: loss=0.01272575090727192
Epoch #218: loss=0.03827884314621427
Epoch #219: loss=0.01799074666551236
Epoch #220: loss=0.009821992534265755
Epoch #221: loss=0.007174706211447509
Epoch #222: loss=0.01583375442602331
Epoch #223: loss=0.014576723208484415
Epoch #224: loss=0.014866524285596644
Epoch #225: loss=0.013971363354153969
Epoch #226: loss=0.010280653640355486
Epoch #227: loss=0.013564942129479143
Epoch #228: loss=0.01398687242608462
Epoch #229: loss=0.014440300813659445
Epoch #230: loss=0.01361052686004793
Epoch #231: loss=0.01429863086818209
Epoch #232: loss=0.013140160949118206
Epoch #233: loss=0.013225988162068844
Epoch #234: loss=0.01194235054787688
Epoch #235: loss=0.008098900596557171
Epoch #236: loss=0.017493879170627637
Epoch #237: loss=0.015041605959012253
Epoch #238: loss=0.009421763849454104
Epoch #239: loss=0.012560308932456852
Epoch #240: loss=0.011766480188258854
Epoch #241: loss=0.013119771837315839
Epoch #242: loss=0.015476624095003798
Epoch #243: loss=0.012423564750118982
Epoch #244: loss=0.012140803028861502
Epoch #245: loss=0.011318314040581265
Epoch #246: loss=0.010345878985618694
Epoch #247: loss=0.013014506600529174
Epoch #248: loss=0.016541949507596746
Epoch #249: loss=0.008953620821606648

Training time: 3:30:58.141167

Finished.
n2one setting ettm1_ettm2_traffic_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm1_ettm2_traffic_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='ettm1_ettm2_traffic_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.64568e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.93287e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.9128e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.64568e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3995989573662438, 'MAE': 0.451254160881872}
Finished.
------------------------- record done -------------------------
n2one setting ettm1_ettm2_traffic_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm1_ettm2_traffic_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='ettm1_ettm2_traffic_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.50366e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.99514e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.50366e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.9236925987972994, 'MAE': 0.7554024145576013}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='ettm1_ettm2_weather_exchange', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/ettm1_ettm2_weather_exchange_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=3.9813074320554733
Epoch #1: loss=2.4191638231277466
Epoch #2: loss=2.00345070872988
Epoch #3: loss=1.7607024567467826
Epoch #4: loss=1.5924192943743296
Epoch #5: loss=1.4418584725686483
Epoch #6: loss=1.3894134845052446
Epoch #7: loss=1.300979612129075
Epoch #8: loss=1.1818858629890852
Epoch #9: loss=1.145430099751268
Epoch #10: loss=1.0211506975548608
Epoch #11: loss=1.0106353600110327
Epoch #12: loss=1.0421513521245547
Epoch #13: loss=0.8955335808651788
Epoch #14: loss=0.8131170379264014
Epoch #15: loss=0.8141855118530137
Epoch #16: loss=0.8134048953652382
Epoch #17: loss=0.7732898018189839
Epoch #18: loss=0.7600776106119156
Epoch #19: loss=0.7168711833655834
Epoch #20: loss=0.7523128911852837
Epoch #21: loss=0.824285911662238
Epoch #22: loss=0.7429379267351968
Epoch #23: loss=0.7453911873911109
Epoch #24: loss=0.6760186712656703
Epoch #25: loss=0.7540621730898108
Epoch #26: loss=0.6315879124615874
Epoch #27: loss=0.64855163491198
Epoch #28: loss=0.607964750379324
Epoch #29: loss=0.612385635397264
Epoch #30: loss=0.530422897211143
Epoch #31: loss=0.4932160313640322
Epoch #32: loss=0.4906517703618322
Epoch #33: loss=0.5261679419449398
Epoch #34: loss=0.5684207853462014
Epoch #35: loss=0.47687896926488194
Epoch #36: loss=0.5284172812742847
Epoch #37: loss=0.48073855095676016
Epoch #38: loss=0.4414640132869993
Epoch #39: loss=0.46109720479164806
Epoch #40: loss=0.43440677944038597
Epoch #41: loss=0.4234350451401302
Epoch #42: loss=0.4145352579653263
Epoch #43: loss=0.3665250074118376
Epoch #44: loss=0.43364859239331316
Epoch #45: loss=0.3971285117524011
Epoch #46: loss=0.4782896973192692
Epoch #47: loss=0.4237196692930801
Epoch #48: loss=0.3856350508119379
Epoch #49: loss=0.3487737415624516
Epoch #50: loss=0.34464795754424166
Epoch #51: loss=0.4364520790321486
Epoch #52: loss=0.36872644922030823
Epoch #53: loss=0.3574075254478625
Epoch #54: loss=0.34623072549168554
Epoch #55: loss=0.34590887411364485
Epoch #56: loss=0.34464793505945374
Epoch #57: loss=0.3549672421067953
Epoch #58: loss=0.29987019393593073
Epoch #59: loss=0.3038475670452629
Epoch #60: loss=0.2945473877979176
Epoch #61: loss=0.30451286238219055
Epoch #62: loss=0.4210137812686818
Epoch #63: loss=0.25705095659941435
Epoch #64: loss=0.29488572890737225
Epoch #65: loss=0.3198616935738495
Epoch #66: loss=0.33204470335372854
Epoch #67: loss=0.22710779735020228
Epoch #68: loss=0.27587210653083666
Epoch #69: loss=0.23908117400216206
Epoch #70: loss=0.2066220977742757
Epoch #71: loss=0.2561549496437822
Epoch #72: loss=0.24090885224619082
Epoch #73: loss=0.2696734078760658
Epoch #74: loss=0.2393658211055611
Epoch #75: loss=0.23207126917051418
Epoch #76: loss=0.28119264476533445
Epoch #77: loss=0.2915421084367803
Epoch #78: loss=0.36722046243292944
Epoch #79: loss=0.24713003196354424
Epoch #80: loss=0.28516047607575146
Epoch #81: loss=0.22384130289512022
Epoch #82: loss=0.20325272929455554
Epoch #83: loss=0.20059573543923243
Epoch #84: loss=0.19263380912265607
Epoch #85: loss=0.2360901026321309
Epoch #86: loss=0.20881415537691542
Epoch #87: loss=0.23658455362809555
Epoch #88: loss=0.2487352754521583
Epoch #89: loss=0.2843844350427389
Epoch #90: loss=0.2047196203576667
Epoch #91: loss=0.19097766120518958
Epoch #92: loss=0.170461651536503
Epoch #93: loss=0.1680312169316624
Epoch #94: loss=0.16844044353014656
Epoch #95: loss=0.14708094458494866
Epoch #96: loss=0.15675017423927784
Epoch #97: loss=0.16251074436253735
Epoch #98: loss=0.17331823759845325
Epoch #99: loss=0.21040973479726485
Epoch #100: loss=0.1470892222465149
Epoch #101: loss=0.12731386341952852
Epoch #102: loss=0.11985489020922355
Epoch #103: loss=0.11751152814498969
Epoch #104: loss=0.14048010782737816
Epoch #105: loss=0.1722655796578952
Epoch #106: loss=0.14098930012966907
Epoch #107: loss=0.12421907035500876
Epoch #108: loss=0.11764129094912537
Epoch #109: loss=0.16992478870919772
Epoch #110: loss=0.15319551959899919
Epoch #111: loss=0.19127007400883095
Epoch #112: loss=0.1723832464444318
Epoch #113: loss=0.19893651189548628
Epoch #114: loss=0.12603796453082136
Epoch #115: loss=0.12443665119021066
Epoch #116: loss=0.298789691512606
Epoch #117: loss=0.1821278325015945
Epoch #118: loss=0.1379926547275058
Epoch #119: loss=0.12230854870618454
Epoch #120: loss=0.1272223593134965
Epoch #121: loss=0.11438837218364435
Epoch #122: loss=0.11926083938617792
Epoch #123: loss=0.13701984924929483
Epoch #124: loss=0.13811143530931855
Epoch #125: loss=0.1311067318809884
Epoch #126: loss=0.11600835425113994
Epoch #127: loss=0.10212022345513105
Epoch #128: loss=0.10862896062566765
Epoch #129: loss=0.11229631238217865
Epoch #130: loss=0.13022866605647973
Epoch #131: loss=0.14277969683254405
Epoch #132: loss=0.09982752024994365
Epoch #133: loss=0.11698340418349419
Epoch #134: loss=0.10778690625115164
Epoch #135: loss=0.12103684170038573
Epoch #136: loss=0.113289037020877
Epoch #137: loss=0.09941353944928519
Epoch #138: loss=0.09310281782277993
Epoch #139: loss=0.12179759909797992
Epoch #140: loss=0.14138177017282164
Epoch #141: loss=0.14445358967142446
Epoch #142: loss=0.16128872907055275
Epoch #143: loss=0.15516614145599306
Epoch #144: loss=0.12046217609063856
Epoch #145: loss=0.16802429923388576
Epoch #146: loss=0.10772999419298555
Epoch #147: loss=0.09627423911089343
Epoch #148: loss=0.09051279351115227
Epoch #149: loss=0.08883743220940232
Epoch #150: loss=0.08189376224098462
Epoch #151: loss=0.09061695562143411
Epoch #152: loss=0.07619430049921253
Epoch #153: loss=0.06940426845436118
Epoch #154: loss=0.09719283606058784
Epoch #155: loss=0.15918563060196383
Epoch #156: loss=0.11929583729111723
Epoch #157: loss=0.12364830509094256
Epoch #158: loss=0.07939346906329904
Epoch #159: loss=0.09896625556783485
Epoch #160: loss=0.10149513301439583
Epoch #161: loss=0.08225144993048161
Epoch #162: loss=0.06840146775357425
Epoch #163: loss=0.09982043943767037
Epoch #164: loss=0.09268037317919411
Epoch #165: loss=0.0726517205725291
Epoch #166: loss=0.07063448392519993
Epoch #167: loss=0.0887786791427061
Epoch #168: loss=0.1609332294070295
Epoch #169: loss=0.11944692525347429
Epoch #170: loss=0.07371660122381789
Epoch #171: loss=0.0650518917412098
Epoch #172: loss=0.07090859013676111
Epoch #173: loss=0.09797212135578905
Epoch #174: loss=0.1003252665146387
Epoch #175: loss=0.10892156330269895
Epoch #176: loss=0.10112139941858393
Epoch #177: loss=0.08989924152514764
Epoch #178: loss=0.07394395613976355
Epoch #179: loss=0.07454526276394192
Epoch #180: loss=0.07242021969120417
Epoch #181: loss=0.07066699601377227
Epoch #182: loss=0.07174229452253453
Epoch #183: loss=0.14053931004101677
Epoch #184: loss=0.06961311882228724
Epoch #185: loss=0.07481632478136037
Epoch #186: loss=0.1162656018776553
Epoch #187: loss=0.0707993959741933
Epoch #188: loss=0.08304968301672488
Epoch #189: loss=0.059926080933239846
Epoch #190: loss=0.054287513152563145
Epoch #191: loss=0.0639010108009513
Epoch #192: loss=0.08113187679555267
Epoch #193: loss=0.06738941135284092
Epoch #194: loss=0.060876480237181695
Epoch #195: loss=0.07801275979727507
Epoch #196: loss=0.07028999937964338
Epoch #197: loss=0.058028020713079186
Epoch #198: loss=0.0689557241941137
Epoch #199: loss=0.06886783992272935
Epoch #200: loss=0.07682599724336926
Epoch #201: loss=0.09083190576971642
Epoch #202: loss=0.0897864199443055
Epoch #203: loss=0.15034085891342588
Epoch #204: loss=0.19414245343900152
Epoch #205: loss=0.1116045853455684
Epoch #206: loss=0.10956407517993025
Epoch #207: loss=0.12659591127053968
Epoch #208: loss=0.08871002651617996
Epoch #209: loss=0.07544026194539454
Epoch #210: loss=0.0934577025805733
Epoch #211: loss=0.12710167648869433
Epoch #212: loss=0.06893637398856559
Epoch #213: loss=0.05962960538454354
Epoch #214: loss=0.05115230499567198
Epoch #215: loss=0.07128304271360061
Epoch #216: loss=0.05140409610300724
Epoch #217: loss=0.05371285113506019
Epoch #218: loss=0.04694122375388231
Epoch #219: loss=0.08344043387166623
Epoch #220: loss=0.06465593283064663
Epoch #221: loss=0.05169740625258003
Epoch #222: loss=0.041052159537295144
Epoch #223: loss=0.048229399004152844
Epoch #224: loss=0.05198205965072183
Epoch #225: loss=0.05999237245747021
Epoch #226: loss=0.05416135278729988
Epoch #227: loss=0.06766568365440305
Epoch #228: loss=0.07186336653207295
Epoch #229: loss=0.05920179447691355
Epoch #230: loss=0.07535836952073234
Epoch #231: loss=0.06155122166299926
Epoch #232: loss=0.06720855050454182
Epoch #233: loss=0.0610737701645121
Epoch #234: loss=0.05820442671288869
Epoch #235: loss=0.06374469937457304
Epoch #236: loss=0.10405187457633604
Epoch #237: loss=0.10412851862409818
Epoch #238: loss=0.1070540378568694
Epoch #239: loss=0.08670256790771548
Epoch #240: loss=0.08447294444444456
Epoch #241: loss=0.05484023383386167
Epoch #242: loss=0.05258584745960044
Epoch #243: loss=0.0782521402247117
Epoch #244: loss=0.048772036347405186
Epoch #245: loss=0.053756080667621324
Epoch #246: loss=0.04650725672088031
Epoch #247: loss=0.04199364553538284
Epoch #248: loss=0.03831888300399961
Epoch #249: loss=0.04190556077186817

Training time: 0:18:27.411469

Finished.
n2one setting ettm1_ettm2_weather_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm1_ettm2_weather_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='ettm1_ettm2_weather_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.11628e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.2579e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.74704e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.11628e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.40083599540152304, 'MAE': 0.4453956822099291}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='ettm1_electricity_traffic_weather', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/ettm1_electricity_traffic_weather_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.8529231599241983
Epoch #1: loss=0.3179749357956843
Epoch #2: loss=0.21276156352680237
Epoch #3: loss=0.17413319647312164
Epoch #4: loss=0.13092924650056195
Epoch #5: loss=0.11571187751642505
Epoch #6: loss=0.11356131548260445
Epoch #7: loss=0.08255257881246507
Epoch #8: loss=0.06791477757658748
Epoch #9: loss=0.05886257496990691
Epoch #10: loss=0.060752611814570597
Epoch #11: loss=0.06424956605750609
Epoch #12: loss=0.051050667676189154
Epoch #13: loss=0.04570212642467565
Epoch #14: loss=0.046113235229382016
Epoch #15: loss=0.041816482190271745
Epoch #16: loss=0.04727028256328013
Epoch #17: loss=0.04457805659297518
Epoch #18: loss=0.033408726707814626
Epoch #19: loss=0.033138415458245724
Epoch #20: loss=0.03723131013045576
Epoch #21: loss=0.02732337796984271
Epoch #22: loss=0.03786523009785909
Epoch #23: loss=0.025296683597844094
Epoch #24: loss=0.025874938045487145
Epoch #25: loss=0.03617223689397492
Epoch #26: loss=0.024599465153506406
Epoch #27: loss=0.032309291599467244
Epoch #28: loss=0.02496862269715658
Epoch #29: loss=0.02733501731284482
Epoch #30: loss=0.02206930662157037
Epoch #31: loss=0.02069181928832893
Epoch #32: loss=0.02290103990225824
Epoch #33: loss=0.02377437829048579
Epoch #34: loss=0.026125205515981194
Epoch #35: loss=0.029555456423425865
Epoch #36: loss=0.025847426340743503
Epoch #37: loss=0.02813405782107424
Epoch #38: loss=0.02613965794234155
Epoch #39: loss=0.02241910963694252
Epoch #40: loss=0.018420995675627577
Epoch #41: loss=0.01980292490534637
Epoch #42: loss=0.021447643604307037
Epoch #43: loss=0.0362701509486632
Epoch #44: loss=0.02098978256065299
Epoch #45: loss=0.018329385720760195
Epoch #46: loss=0.02444227180647908
Epoch #47: loss=0.017607958485815124
Epoch #48: loss=0.02171349331171664
Epoch #49: loss=0.02113729250296706
Epoch #50: loss=0.025074844612128323
Epoch #51: loss=0.016350469416385273
Epoch #52: loss=0.023062949789688945
Epoch #53: loss=0.017035760128461246
Epoch #54: loss=0.020163533316074
Epoch #55: loss=0.017681199996722633
Epoch #56: loss=0.016298123511994358
Epoch #57: loss=0.018951081734324318
Epoch #58: loss=0.02317344785332069
Epoch #59: loss=0.01647883721870145
Epoch #60: loss=0.019703324469518238
Epoch #61: loss=0.018415768875990474
Epoch #62: loss=0.01819426457952998
Epoch #63: loss=0.019414389118305064
Epoch #64: loss=0.019588221498592337
Epoch #65: loss=0.01554564966647943
Epoch #66: loss=0.0215155995592974
Epoch #67: loss=0.017750269604954662
Epoch #68: loss=0.014112277220186518
Epoch #69: loss=0.019440229540045723
Epoch #70: loss=0.014119523313310624
Epoch #71: loss=0.016787048231129968
Epoch #72: loss=0.017938808439615313
Epoch #73: loss=0.02099061267598118
Epoch #74: loss=0.01739333459564015
Epoch #75: loss=0.017673408832629096
Epoch #76: loss=0.0135975833610559
Epoch #77: loss=0.01796268452680288
Epoch #78: loss=0.015531715863316557
Epoch #79: loss=0.013605045193312957
Epoch #80: loss=0.015591539204937452
Epoch #81: loss=0.014781791884017932
Epoch #82: loss=0.017905076874835613
Epoch #83: loss=0.013927795056498908
Epoch #84: loss=0.015762276624159535
Epoch #85: loss=0.015641239457348643
Epoch #86: loss=0.018303228154483625
Epoch #87: loss=0.02147535652675586
Epoch #88: loss=0.014953978352554497
Epoch #89: loss=0.019583344397437568
Epoch #90: loss=0.013585013185664019
Epoch #91: loss=0.014793317255227192
Epoch #92: loss=0.01883078426063086
Epoch #93: loss=0.013817882183371455
Epoch #94: loss=0.012346289518836038
Epoch #95: loss=0.013358340092403165
Epoch #96: loss=0.017193218135524477
Epoch #97: loss=0.01315237665200629
Epoch #98: loss=0.017439536770188335
Epoch #99: loss=0.022386730132031935
Epoch #100: loss=0.013770561883718417
Epoch #101: loss=0.01371683587895546
Epoch #102: loss=0.01446531763642389
Epoch #103: loss=0.013061946096923583
Epoch #104: loss=0.022332540073801314
Epoch #105: loss=0.01891443377456601
Epoch #106: loss=0.020661886619951685
Epoch #107: loss=0.014063032727581679
Epoch #108: loss=0.012124315667281988
Epoch #109: loss=0.018828960461348184
Epoch #110: loss=0.013930902218677058
Epoch #111: loss=0.013764046978734559
Epoch #112: loss=0.011740242693736408
Epoch #113: loss=0.016972769378588083
Epoch #114: loss=0.016690621198370642
Epoch #115: loss=0.013033072166008871
Epoch #116: loss=0.01376854151954443
Epoch #117: loss=0.012142172978249127
Epoch #118: loss=0.017329550815583628
Epoch #119: loss=0.010093325006408898
Epoch #120: loss=0.015599891086911484
Epoch #121: loss=0.009429972315152167
Epoch #122: loss=0.013786337762421233
Epoch #123: loss=0.017151292441849365
Epoch #124: loss=0.015216684232052744
Epoch #125: loss=0.014374098954407392
Epoch #126: loss=0.014293798728756316
Epoch #127: loss=0.012994645398096315
Epoch #128: loss=0.0151018481256467
Epoch #129: loss=0.013349477051099816
Epoch #130: loss=0.011067265836909874
Epoch #131: loss=0.015011283495037848
Epoch #132: loss=0.011230032458222952
Epoch #133: loss=0.012631922378729586
Epoch #134: loss=0.014032401421038648
Epoch #135: loss=0.010163031992303078
Epoch #136: loss=0.01216460384943961
Epoch #137: loss=0.015214563730734851
Epoch #138: loss=0.010715557868424498
Epoch #139: loss=0.01263843866695648
Epoch #140: loss=0.012856665471607827
Epoch #141: loss=0.010540768329543634
Epoch #142: loss=0.010655276255062343
Epoch #143: loss=0.014581383054419497
Epoch #144: loss=0.013399501794819876
Epoch #145: loss=0.0123827816684946
Epoch #146: loss=0.010963422369610778
Epoch #147: loss=0.014847972841821726
Epoch #148: loss=0.012058850770747503
Epoch #149: loss=0.008474626817704
Epoch #150: loss=0.013749249219311378
Epoch #151: loss=0.0124029361042571
Epoch #152: loss=0.01367124772641844
Epoch #153: loss=0.012032176493263906
Epoch #154: loss=0.01047396885688449
Epoch #155: loss=0.016733708490066987
Epoch #156: loss=0.008066050321761649
Epoch #157: loss=0.013132768970905597
Epoch #158: loss=0.01870734465609545
Epoch #159: loss=0.01710730797206109
Epoch #160: loss=0.014572020022727675
Epoch #161: loss=0.008547627530585532
Epoch #162: loss=0.013842866924048887
Epoch #163: loss=0.011963239387627195
Epoch #164: loss=0.014709238375734622
Epoch #165: loss=0.007898873621817357
Epoch #166: loss=0.009049080840510423
Epoch #167: loss=0.012466157874048983
Epoch #168: loss=0.013275023145872153
Epoch #169: loss=0.009481631022232458
Epoch #170: loss=0.011449731826759802
Epoch #171: loss=0.012046782739463332
Epoch #172: loss=0.012489472380810662
Epoch #173: loss=0.014600983393554133
Epoch #174: loss=0.00921314212159143
Epoch #175: loss=0.013076794247321171
Epoch #176: loss=0.01045920675583222
Epoch #177: loss=0.009977010470997737
Epoch #178: loss=0.01069140568569772
Epoch #179: loss=0.008902045369371185
Epoch #180: loss=0.014325731504981913
Epoch #181: loss=0.01007699933248719
Epoch #182: loss=0.013721910283481416
Epoch #183: loss=0.011931131208102222
Epoch #184: loss=0.011626945260757596
Epoch #185: loss=0.01815376858337645
Epoch #186: loss=0.010742389537174813
Epoch #187: loss=0.0177228782153686
Epoch #188: loss=0.01064834567054068
Epoch #189: loss=0.010763983123579833
Epoch #190: loss=0.011429264917626183
Epoch #191: loss=0.010098610145145298
Epoch #192: loss=0.01318378846289172
Epoch #193: loss=0.009272519861096059
Epoch #194: loss=0.011761469072371255
Epoch #195: loss=0.011083244372573853
Epoch #196: loss=0.011508332783926219
Epoch #197: loss=0.010644771781016225
Epoch #198: loss=0.009465666512622819
Epoch #199: loss=0.009018031988584805
Epoch #200: loss=0.011732453612868815
Epoch #201: loss=0.016040250735470003
Epoch #202: loss=0.01642153845321326
Epoch #203: loss=0.0096291816422696
Epoch #204: loss=0.010034605820489605
Epoch #205: loss=0.014599941681844343
Epoch #206: loss=0.012919862534575065
Epoch #207: loss=0.009058635527438382
Epoch #208: loss=0.009685238255811694
Epoch #209: loss=0.012039081670421883
Epoch #210: loss=0.009149920167167648
Epoch #211: loss=0.00940970493101617
Epoch #212: loss=0.01004795964341372
Epoch #213: loss=0.012985588805263359
Epoch #214: loss=0.012938624788595738
Epoch #215: loss=0.010732213018860928
Epoch #216: loss=0.011103477705683708
Epoch #217: loss=0.011059226649460291
Epoch #218: loss=0.00790671604533048
Epoch #219: loss=0.0100669182197083
Epoch #220: loss=0.006979542192153739
Epoch #221: loss=0.012714256357301446
Epoch #222: loss=0.01971382545676444
Epoch #223: loss=0.01034335887403567
Epoch #224: loss=0.010099138231298191
Epoch #225: loss=0.010821683997978728
Epoch #226: loss=0.013981831250137355
Epoch #227: loss=0.008176268646794134
Epoch #228: loss=0.010591664623590062
Epoch #229: loss=0.02820936843677
Epoch #230: loss=0.009696428070847253
Epoch #231: loss=0.012665344178225735
Epoch #232: loss=0.012776336324025236
Epoch #233: loss=0.008387158755985944
Epoch #234: loss=0.010793458347545878
Epoch #235: loss=0.009084796919186837
Epoch #236: loss=0.010825959527073046
Epoch #237: loss=0.016214051163043506
Epoch #238: loss=0.008800960190622197
Epoch #239: loss=0.014552110554872284
Epoch #240: loss=0.008217565015580536
Epoch #241: loss=0.009984692646506373
Epoch #242: loss=0.01061959148409202
Epoch #243: loss=0.010617454074432674
Epoch #244: loss=0.006445543768972666
Epoch #245: loss=0.008507016668471671
Epoch #246: loss=0.010757110367260002
Epoch #247: loss=0.006579972087566886
Epoch #248: loss=0.011481001369366957
Epoch #249: loss=0.009291608647032023

Training time: 5:04:48.053078

Finished.
n2one setting ettm1_electricity_traffic_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm1_electricity_traffic_weather_epochs_250_seed_2022/model.pkl', muti_dataset='ettm1_electricity_traffic_weather', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.86884e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.35207680636932015, 'MAE': 0.3948484633486159}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='ettm1_electricity_traffic_exchange', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/ettm1_electricity_traffic_exchange_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.8272187435711283
Epoch #1: loss=0.3005904960515793
Epoch #2: loss=0.20313570449150442
Epoch #3: loss=0.15469221875517816
Epoch #4: loss=0.11635300617497693
Epoch #5: loss=0.09223184573964624
Epoch #6: loss=0.08421641363128524
Epoch #7: loss=0.07159864935619499
Epoch #8: loss=0.06654572850224963
Epoch #9: loss=0.0697091925232989
Epoch #10: loss=0.05359575242643243
Epoch #11: loss=0.051816052080793755
Epoch #12: loss=0.05006040307691634
Epoch #13: loss=0.04378062090197246
Epoch #14: loss=0.04020129620216124
Epoch #15: loss=0.04067011294729958
Epoch #16: loss=0.040794017389684
Epoch #17: loss=0.03418565794839888
Epoch #18: loss=0.03569911331900654
Epoch #19: loss=0.03546488330768849
Epoch #20: loss=0.03573357822505615
Epoch #21: loss=0.031050617614750923
Epoch #22: loss=0.03167672703322914
Epoch #23: loss=0.033013268477247004
Epoch #24: loss=0.0327555456708868
Epoch #25: loss=0.03314732300137369
Epoch #26: loss=0.030452112630652745
Epoch #27: loss=0.0265043653083749
Epoch #28: loss=0.028937092701557362
Epoch #29: loss=0.031476173566742656
Epoch #30: loss=0.02423882068791206
Epoch #31: loss=0.023904965670171897
Epoch #32: loss=0.02710937707047265
Epoch #33: loss=0.0266856242182584
Epoch #34: loss=0.02251947769672825
Epoch #35: loss=0.03495123549043929
Epoch #36: loss=0.02035449376565516
Epoch #37: loss=0.021406695740493076
Epoch #38: loss=0.0345352262878572
Epoch #39: loss=0.021880393144779197
Epoch #40: loss=0.03131212132786108
Epoch #41: loss=0.02489160799207135
Epoch #42: loss=0.02526670795585069
Epoch #43: loss=0.01896898912942113
Epoch #44: loss=0.022565010956278577
Epoch #45: loss=0.018152071191242024
Epoch #46: loss=0.021790870545966977
Epoch #47: loss=0.020508822153669903
Epoch #48: loss=0.029783815595706052
Epoch #49: loss=0.022571991056797736
Epoch #50: loss=0.02018251768707049
Epoch #51: loss=0.0171910980647099
Epoch #52: loss=0.022160379296558414
Epoch #53: loss=0.023130888221857097
Epoch #54: loss=0.020157280642447834
Epoch #55: loss=0.02054695206291016
Epoch #56: loss=0.01653325842073987
Epoch #57: loss=0.022065010711708775
Epoch #58: loss=0.019147526150340363
Epoch #59: loss=0.01949027591340783
Epoch #60: loss=0.02128420487025806
Epoch #61: loss=0.02211539628530989
Epoch #62: loss=0.016643401742407266
Epoch #63: loss=0.014616465522039305
Epoch #64: loss=0.013215962676799193
Epoch #65: loss=0.021904130336888965
Epoch #66: loss=0.021533100069566366
Epoch #67: loss=0.020580402810104075
Epoch #68: loss=0.01804258526232076
Epoch #69: loss=0.01707214206594086
Epoch #70: loss=0.017141528567599484
Epoch #71: loss=0.017933841923320586
Epoch #72: loss=0.01709291673207868
Epoch #73: loss=0.017358495539195485
Epoch #74: loss=0.01726538809043102
Epoch #75: loss=0.016131378580101715
Epoch #76: loss=0.018759906359079655
Epoch #77: loss=0.016606642863131224
Epoch #78: loss=0.015298811569646235
Epoch #79: loss=0.015924241789466526
Epoch #80: loss=0.016780574058487426
Epoch #81: loss=0.01704497929887367
Epoch #82: loss=0.015975485859335534
Epoch #83: loss=0.01716182794542588
Epoch #84: loss=0.017514174961229742
Epoch #85: loss=0.015928548248102168
Epoch #86: loss=0.01205737472582239
Epoch #87: loss=0.01794779011147746
Epoch #88: loss=0.017321856851390635
Epoch #89: loss=0.01672353492159677
Epoch #90: loss=0.01765183348779314
Epoch #91: loss=0.012822971213197362
Epoch #92: loss=0.016287997136283403
Epoch #93: loss=0.016582443681768314
Epoch #94: loss=0.018356979098120632
Epoch #95: loss=0.015574416255826532
Epoch #96: loss=0.015637176450126543
Epoch #97: loss=0.014986746578340569
Epoch #98: loss=0.017597314522622195
Epoch #99: loss=0.013755009047363667
Epoch #100: loss=0.015759061601756958
Epoch #101: loss=0.010614904828364581
Epoch #102: loss=0.013981196700275516
Epoch #103: loss=0.014382783045877777
Epoch #104: loss=0.014229059586838583
Epoch #105: loss=0.018256624864064507
Epoch #106: loss=0.015029813013347128
Epoch #107: loss=0.016401176734870952
Epoch #108: loss=0.01863299984505831
Epoch #109: loss=0.017522630189035434
Epoch #110: loss=0.012257886176498664
Epoch #111: loss=0.013682811634939321
Epoch #112: loss=0.01744324859207885
Epoch #113: loss=0.014399251951581331
Epoch #114: loss=0.01374480812007948
Epoch #115: loss=0.019361746627814175
Epoch #116: loss=0.014332736419965537
Epoch #117: loss=0.014322903075294872
Epoch #118: loss=0.010964161197447834
Epoch #119: loss=0.015820834122873422
Epoch #120: loss=0.016188174883105533
Epoch #121: loss=0.023024027488515373
Epoch #122: loss=0.01519050136698941
Epoch #123: loss=0.010175977767831197
Epoch #124: loss=0.01727624307552435
Epoch #125: loss=0.011785229867074937
Epoch #126: loss=0.01192384360352986
Epoch #127: loss=0.01767672545033195
Epoch #128: loss=0.015760509909122207
Epoch #129: loss=0.013804903979692725
Epoch #130: loss=0.012901090471422747
Epoch #131: loss=0.010698648375881675
Epoch #132: loss=0.014863506101967032
Epoch #133: loss=0.013232933502174958
Epoch #134: loss=0.012052389020302897
Epoch #135: loss=0.011827144690083913
Epoch #136: loss=0.01231894158016487
Epoch #137: loss=0.012647995472661554
Epoch #138: loss=0.011199843853291942
Epoch #139: loss=0.012370464046912933
Epoch #140: loss=0.010856352404579836
Epoch #141: loss=0.010226695691631486
Epoch #142: loss=0.01301151387073962
Epoch #143: loss=0.012969369368012467
Epoch #144: loss=0.010940366992968083
Epoch #145: loss=0.013067823633702298
Epoch #146: loss=0.011788656947226419
Epoch #147: loss=0.012433611022415199
Epoch #148: loss=0.013003357606749167
Epoch #149: loss=0.010082208715920056
Epoch #150: loss=0.01170319192398511
Epoch #151: loss=0.012278448808665144
Epoch #152: loss=0.013517825780718112
Epoch #153: loss=0.012600858251644784
Epoch #154: loss=0.01355825387458716
Epoch #155: loss=0.016260404414621284
Epoch #156: loss=0.012593173090548507
Epoch #157: loss=0.01586551669640604
Epoch #158: loss=0.013468248864046775
Epoch #159: loss=0.009658329194259482
Epoch #160: loss=0.014425511454748158
Epoch #161: loss=0.020683420707328135
Epoch #162: loss=0.012187910170337733
Epoch #163: loss=0.013215809038477236
Epoch #164: loss=0.010112667828444787
Epoch #165: loss=0.012826032481807519
Epoch #166: loss=0.012438201178725307
Epoch #167: loss=0.014335564043170063
Epoch #168: loss=0.013779126679394127
Epoch #169: loss=0.012289919269040883
Epoch #170: loss=0.010087038054712177
Epoch #171: loss=0.016217050516105565
Epoch #172: loss=0.009110053519582467
Epoch #173: loss=0.010654796019584691
Epoch #174: loss=0.012501307594880056
Epoch #175: loss=0.010387105674435619
Epoch #176: loss=0.012284179423874114
Epoch #177: loss=0.01171294773628146
Epoch #178: loss=0.009855771603115
Epoch #179: loss=0.013209718407662767
Epoch #180: loss=0.008738860951880104
Epoch #181: loss=0.013613248702785435
Epoch #182: loss=0.010827290035916736
Epoch #183: loss=0.011083441365576279
Epoch #184: loss=0.00990579588350654
Epoch #185: loss=0.012327062891984705
Epoch #186: loss=0.010090784344598636
Epoch #187: loss=0.011887550000012225
Epoch #188: loss=0.014736329445477108
Epoch #189: loss=0.009291663811366889
Epoch #190: loss=0.013334233261135984
Epoch #191: loss=0.01202383033965686
Epoch #192: loss=0.009370745284539107
Epoch #193: loss=0.010808416456366678
Epoch #194: loss=0.01105470450370762
Epoch #195: loss=0.015347111627392988
Epoch #196: loss=0.01104551437349615
Epoch #197: loss=0.007579713292670175
Epoch #198: loss=0.01922058646151056
Epoch #199: loss=0.011053342982366744
Epoch #200: loss=0.012700735955537272
Epoch #201: loss=0.008507139433567743
Epoch #202: loss=0.01459603687569707
Epoch #203: loss=0.009853917587881034
Epoch #204: loss=0.012147284276755283
Epoch #205: loss=0.014904088967993756
Epoch #206: loss=0.015901302944784253
Epoch #207: loss=0.012615927445861866
Epoch #208: loss=0.012149126099360783
Epoch #209: loss=0.009698110656339087
Epoch #210: loss=0.01515329119204772
Epoch #211: loss=0.011702913069489484
Epoch #212: loss=0.016576007925684512
Epoch #213: loss=0.01270095493183527
Epoch #214: loss=0.013356773743404049
Epoch #215: loss=0.010330173974595382
Epoch #216: loss=0.010323587825468364
Epoch #217: loss=0.011207283080864746
Epoch #218: loss=0.008528458292910943
Epoch #219: loss=0.008641616063092827
Epoch #220: loss=0.012777070040625137
Epoch #221: loss=0.011412315908611206
Epoch #222: loss=0.013057003422861957
Epoch #223: loss=0.010070774508287632
Epoch #224: loss=0.013464776194899827
Epoch #225: loss=0.01063669106783263
Epoch #226: loss=0.010888944963236264
Epoch #227: loss=0.011774211454863513
Epoch #228: loss=0.011669074239719895
Epoch #229: loss=0.012589549282588958
Epoch #230: loss=0.010510648125011188
Epoch #231: loss=0.007766549786129643
Epoch #232: loss=0.013047834546606447
Epoch #233: loss=0.0150906817007474
Epoch #234: loss=0.008645622677308794
Epoch #235: loss=0.012669583219278331
Epoch #236: loss=0.014019628268394025
Epoch #237: loss=0.012693326867859208
Epoch #238: loss=0.00816041209411965
Epoch #239: loss=0.009255286066865496
Epoch #240: loss=0.009604359995367224
Epoch #241: loss=0.0112652342440667
Epoch #242: loss=0.011885228554924781
Epoch #243: loss=0.013985420495067858
Epoch #244: loss=0.00861525086556428
Epoch #245: loss=0.011539335885658912
Epoch #246: loss=0.010478960929532708
Epoch #247: loss=0.012427708343782195
Epoch #248: loss=0.013216340102233746
Epoch #249: loss=0.009046827142244824

Training time: 4:49:57.777352

Finished.
n2one setting ettm1_electricity_traffic_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm1_electricity_traffic_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='ettm1_electricity_traffic_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.47423e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.02766e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.17681e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.5622155234688881, 'MAE': 0.5822378557782256}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='ettm1_electricity_weather_exchange', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/ettm1_electricity_weather_exchange_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.744282340579997
Epoch #1: loss=0.8305480853944528
Epoch #2: loss=0.5885976273668269
Epoch #3: loss=0.5053697859491807
Epoch #4: loss=0.42198455012072633
Epoch #5: loss=0.37129374137504506
Epoch #6: loss=0.3330670134291623
Epoch #7: loss=0.31148616263205237
Epoch #8: loss=0.28607075404925425
Epoch #9: loss=0.26975022960718864
Epoch #10: loss=0.24039249295175402
Epoch #11: loss=0.2289182867630909
Epoch #12: loss=0.21432619729165822
Epoch #13: loss=0.19490724907872456
Epoch #14: loss=0.19271999402124373
Epoch #15: loss=0.20180141742600768
Epoch #16: loss=0.1614746487358473
Epoch #17: loss=0.15718312793070338
Epoch #18: loss=0.1274389966233262
Epoch #19: loss=0.12847040061294382
Epoch #20: loss=0.13675850187046606
Epoch #21: loss=0.13077906674395004
Epoch #22: loss=0.10866573632852546
Epoch #23: loss=0.09754936973935838
Epoch #24: loss=0.1060486324793084
Epoch #25: loss=0.08134070869860917
Epoch #26: loss=0.07999687748223218
Epoch #27: loss=0.10143183572014254
Epoch #28: loss=0.07966786341568649
Epoch #29: loss=0.09833742057792638
Epoch #30: loss=0.10389449537472158
Epoch #31: loss=0.09924757161401619
Epoch #32: loss=0.07557778261713888
Epoch #33: loss=0.06523956861245177
Epoch #34: loss=0.07123215039403183
Epoch #35: loss=0.11353453928528384
Epoch #36: loss=0.09758621361615553
Epoch #37: loss=0.0771289249332469
Epoch #38: loss=0.06094770015235176
Epoch #39: loss=0.06348843070426498
Epoch #40: loss=0.05686180928055339
Epoch #41: loss=0.04846588741540094
Epoch #42: loss=0.056233454386250735
Epoch #43: loss=0.06873978628990714
Epoch #44: loss=0.06988932823131237
Epoch #45: loss=0.07116919755617594
Epoch #46: loss=0.055527871687733696
Epoch #47: loss=0.07687005810019729
Epoch #48: loss=0.049752427184893214
Epoch #49: loss=0.04982857478024245
Epoch #50: loss=0.03739403015927569
Epoch #51: loss=0.05727247911049918
Epoch #52: loss=0.05176310856505984
Epoch #53: loss=0.04441057176735059
Epoch #54: loss=0.04578479292326673
Epoch #55: loss=0.04009128655650516
Epoch #56: loss=0.06631212630576347
Epoch #57: loss=0.04214045093038572
Epoch #58: loss=0.04307562292393175
Epoch #59: loss=0.04038354883236363
Epoch #60: loss=0.05213751363958603
Epoch #61: loss=0.05344989317815364
Epoch #62: loss=0.040268239230261044
Epoch #63: loss=0.035513305881053024
Epoch #64: loss=0.042204644920971104
Epoch #65: loss=0.05039226924434376
Epoch #66: loss=0.04154251014834138
Epoch #67: loss=0.056064678313747514
Epoch #68: loss=0.05239976432729166
Epoch #69: loss=0.051264976229215845
Epoch #70: loss=0.05004067138019349
Epoch #71: loss=0.039172843761508015
Epoch #72: loss=0.031691808702011943
Epoch #73: loss=0.05413315962342281
Epoch #74: loss=0.04135330053570533
Epoch #75: loss=0.0346439148307666
Epoch #76: loss=0.03536429868144609
Epoch #77: loss=0.04008460512541901
Epoch #78: loss=0.03322921519210979
Epoch #79: loss=0.03416649437884169
Epoch #80: loss=0.030549612355258195
Epoch #81: loss=0.03110787171273762
Epoch #82: loss=0.03842622628390962
Epoch #83: loss=0.055379425196480925
Epoch #84: loss=0.05506177806636431
Epoch #85: loss=0.029728779346934048
Epoch #86: loss=0.0708929138494111
Epoch #87: loss=0.02864390017834996
Epoch #88: loss=0.033864708326927444
Epoch #89: loss=0.028606948100031695
Epoch #90: loss=0.027742768856194228
Epoch #91: loss=0.03385298857000998
Epoch #92: loss=0.03211199734239111
Epoch #93: loss=0.035622345805906085
Epoch #94: loss=0.030480481103403605
Epoch #95: loss=0.023853385602467556
Epoch #96: loss=0.033703537246745456
Epoch #97: loss=0.06734482097233356
Epoch #98: loss=0.03262846940896815
Epoch #99: loss=0.026319113093882525
Epoch #100: loss=0.028441114177007502
Epoch #101: loss=0.022441792165856716
Epoch #102: loss=0.02000445432632098
Epoch #103: loss=0.02453975586088303
Epoch #104: loss=0.02486398918337896
Epoch #105: loss=0.027287059584110873
Epoch #106: loss=0.029191489457699872
Epoch #107: loss=0.040443875371412336
Epoch #108: loss=0.03107669564056887
Epoch #109: loss=0.0432442299095415
Epoch #110: loss=0.03883113037642789
Epoch #111: loss=0.03145181657517421
Epoch #112: loss=0.02462050682786201
Epoch #113: loss=0.029995393242255676
Epoch #114: loss=0.03765908029385909
Epoch #115: loss=0.022893988496186263
Epoch #116: loss=0.0242179181633353
Epoch #117: loss=0.023072101966518644
Epoch #118: loss=0.024728406087242197
Epoch #119: loss=0.03502388272811074
Epoch #120: loss=0.01878695889812502
Epoch #121: loss=0.021136639813881093
Epoch #122: loss=0.0306752746865278
Epoch #123: loss=0.03112977946875617
Epoch #124: loss=0.04315058104859289
Epoch #125: loss=0.04014148874541673
Epoch #126: loss=0.03309453548825361
Epoch #127: loss=0.025267891669798582
Epoch #128: loss=0.019683586860545072
Epoch #129: loss=0.020033878786680212
Epoch #130: loss=0.02786971814572605
Epoch #131: loss=0.03956981503918049
Epoch #132: loss=0.04086498949865052
Epoch #133: loss=0.027301351003198696
Epoch #134: loss=0.0307972175813448
Epoch #135: loss=0.038417131054759676
Epoch #136: loss=0.07065483927026982
Epoch #137: loss=0.029359054299710124
Epoch #138: loss=0.02694465543504148
Epoch #139: loss=0.026070638836165533
Epoch #140: loss=0.019851997065932943
Epoch #141: loss=0.01624254744052709
Epoch #142: loss=0.025796432368224487
Epoch #143: loss=0.03005736358314269
Epoch #144: loss=0.02282712467382484
Epoch #145: loss=0.021461562219023695
Epoch #146: loss=0.01893362623047468
Epoch #147: loss=0.019026738868535197
Epoch #148: loss=0.027729669132726675
Epoch #149: loss=0.04996625827390019
Epoch #150: loss=0.023815559943892377
Epoch #151: loss=0.022254952179939776
Epoch #152: loss=0.022533422874880298
Epoch #153: loss=0.022132214447903278
Epoch #154: loss=0.026076977977896862
Epoch #155: loss=0.015990753306166262
Epoch #156: loss=0.031246411845360277
Epoch #157: loss=0.02229677067396531
Epoch #158: loss=0.03578430497646713
Epoch #159: loss=0.02991662268454331
Epoch #160: loss=0.028038445035061834
Epoch #161: loss=0.02635688949812107
Epoch #162: loss=0.021714982113392536
Epoch #163: loss=0.025369639188840686
Epoch #164: loss=0.03065020126933766
Epoch #165: loss=0.02504123185438109
Epoch #166: loss=0.022865333040136732
Epoch #167: loss=0.01872378643576687
Epoch #168: loss=0.0215704417935397
Epoch #169: loss=0.0454827812487575
Epoch #170: loss=0.020655951035034696
Epoch #171: loss=0.019278767233545244
Epoch #172: loss=0.01847233878966431
Epoch #173: loss=0.02884290265835455
Epoch #174: loss=0.02873277044909131
Epoch #175: loss=0.03458499257268939
Epoch #176: loss=0.013962355364893965
Epoch #177: loss=0.01791290378374877
Epoch #178: loss=0.022130211358959914
Epoch #179: loss=0.025377482223379186
Epoch #180: loss=0.021984269657545047
Epoch #181: loss=0.021645037602707033
Epoch #182: loss=0.021848892632113575
Epoch #183: loss=0.019183315395389026
Epoch #184: loss=0.01795030838782553
Epoch #185: loss=0.028194013009066668
Epoch #186: loss=0.04734474797259197
Epoch #187: loss=0.022850541413673885
Epoch #188: loss=0.017193581876497655
Epoch #189: loss=0.0136977141860445
Epoch #190: loss=0.02102252131124737
Epoch #191: loss=0.0221474545074581
Epoch #192: loss=0.019776158279639446
Epoch #193: loss=0.028615594675584412
Epoch #194: loss=0.030526549362051403
Epoch #195: loss=0.026825102170658314
Epoch #196: loss=0.028818497522524175
Epoch #197: loss=0.017924556440353786
Epoch #198: loss=0.01757479479117828
Epoch #199: loss=0.014061633581448286
Epoch #200: loss=0.016543791552161406
Epoch #201: loss=0.01199931410634941
Epoch #202: loss=0.014945252820921939
Epoch #203: loss=0.02360717382897811
Epoch #204: loss=0.01808700645520591
Epoch #205: loss=0.01967009252937297
Epoch #206: loss=0.01914069611614804
Epoch #207: loss=0.03430344243572078
Epoch #208: loss=0.02532572762692688
Epoch #209: loss=0.0212899464354475
Epoch #210: loss=0.02887290374893069
Epoch #211: loss=0.013308848864290752
Epoch #212: loss=0.023257038896697283
Epoch #213: loss=0.01817562844546364
Epoch #214: loss=0.01610838629424959
Epoch #215: loss=0.016948993755135523
Epoch #216: loss=0.018803918295090795
Epoch #217: loss=0.017500146897128005
Epoch #218: loss=0.01826294997129386
Epoch #219: loss=0.020595461874993524
Epoch #220: loss=0.016042395015380757
Epoch #221: loss=0.016899382929976704
Epoch #222: loss=0.016808677425123292
Epoch #223: loss=0.019087764768097218
Epoch #224: loss=0.029050602629313835
Epoch #225: loss=0.018203910789850085
Epoch #226: loss=0.019764650702766586
Epoch #227: loss=0.016489700507992863
Epoch #228: loss=0.017715447922326277
Epoch #229: loss=0.05438039655142904
Epoch #230: loss=0.022256397166037473
Epoch #231: loss=0.017561078993931205
Epoch #232: loss=0.017973075365893227
Epoch #233: loss=0.016451949792099185
Epoch #234: loss=0.02067297565002666
Epoch #235: loss=0.016319313467940813
Epoch #236: loss=0.015455976971396489
Epoch #237: loss=0.026461958784522243
Epoch #238: loss=0.023535411683091884
Epoch #239: loss=0.02209468229700521
Epoch #240: loss=0.019022445247541667
Epoch #241: loss=0.024307872094687894
Epoch #242: loss=0.0183955172292794
Epoch #243: loss=0.020515537479462335
Epoch #244: loss=0.016611914600969592
Epoch #245: loss=0.014793783095646192
Epoch #246: loss=0.01623790547109522
Epoch #247: loss=0.022110272783815003
Epoch #248: loss=0.01706392466829507
Epoch #249: loss=0.016512026611774082

Training time: 1:44:22.521173

Finished.
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='ettm1_traffic_weather_exchange', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/ettm1_traffic_weather_exchange_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.0462498208785136
Epoch #1: loss=0.42013526973217036
Epoch #2: loss=0.3119767720851115
Epoch #3: loss=0.23517382575369458
Epoch #4: loss=0.19468701326482352
Epoch #5: loss=0.17364239344391827
Epoch #6: loss=0.14758846620477678
Epoch #7: loss=0.13016863321308395
Epoch #8: loss=0.10991229217133948
Epoch #9: loss=0.11113923336990186
Epoch #10: loss=0.10449392252520565
Epoch #11: loss=0.08610690414983586
Epoch #12: loss=0.07382159506698789
Epoch #13: loss=0.06880790403866452
Epoch #14: loss=0.08190013484591915
Epoch #15: loss=0.06333189719441822
Epoch #16: loss=0.06918882280808916
Epoch #17: loss=0.05541161515790037
Epoch #18: loss=0.047887929979108006
Epoch #19: loss=0.05113084194411615
Epoch #20: loss=0.04990085800149598
Epoch #21: loss=0.06268360041356065
Epoch #22: loss=0.04310598970049953
Epoch #23: loss=0.05763788603935719
Epoch #24: loss=0.044778527340532386
Epoch #25: loss=0.04325493991266127
Epoch #26: loss=0.032164880273827225
Epoch #27: loss=0.037631232165675016
Epoch #28: loss=0.040087104802607236
Epoch #29: loss=0.03840442599632183
Epoch #30: loss=0.0347613083726707
Epoch #31: loss=0.03359098855779294
Epoch #32: loss=0.06489897977040676
Epoch #33: loss=0.03686184859067066
Epoch #34: loss=0.03587396095023986
Epoch #35: loss=0.040819921742820786
Epoch #36: loss=0.029446960235301554
Epoch #37: loss=0.02980742719474422
Epoch #38: loss=0.03294639928957454
Epoch #39: loss=0.02825512274352232
Epoch #40: loss=0.03203814725404145
Epoch #41: loss=0.05446759967840366
Epoch #42: loss=0.035281215490703496
Epoch #43: loss=0.030966327157433225
Epoch #44: loss=0.028315441313473345
Epoch #45: loss=0.045312323184455966
Epoch #46: loss=0.03010217142224624
Epoch #47: loss=0.030350181443861642
Epoch #48: loss=0.03160389422077343
Epoch #49: loss=0.026964560034684837
Epoch #50: loss=0.028899799961526904
Epoch #51: loss=0.02818410276211213
Epoch #52: loss=0.033485823949270646
Epoch #53: loss=0.028752048293171222
Epoch #54: loss=0.02439030518143334
Epoch #55: loss=0.024995216788467875
Epoch #56: loss=0.02163384366638562
Epoch #57: loss=0.02615147056684407
Epoch #58: loss=0.02493659431178199
Epoch #59: loss=0.03607632484016971
Epoch #60: loss=0.021404271057225217
Epoch #61: loss=0.027592082027550747
Epoch #62: loss=0.025171211367609574
Epoch #63: loss=0.027932262462638257
Epoch #64: loss=0.025500280386870963
Epoch #65: loss=0.024561043248702837
Epoch #66: loss=0.02512099500745535
Epoch #67: loss=0.02287447774696011
Epoch #68: loss=0.021142200087689998
Epoch #69: loss=0.024928851334915663
Epoch #70: loss=0.02284815318708163
Epoch #71: loss=0.02672992297172261
Epoch #72: loss=0.023875678287289703
Epoch #73: loss=0.01622834229416213
Epoch #74: loss=0.018484763582642658
Epoch #75: loss=0.024013073792209533
Epoch #76: loss=0.028263540001526526
Epoch #77: loss=0.020884289878511406
Epoch #78: loss=0.022393352789923708
Epoch #79: loss=0.023401272633614696
Epoch #80: loss=0.02040829912361729
Epoch #81: loss=0.025502337272816436
Epoch #82: loss=0.023321122965401155
Epoch #83: loss=0.017171193690649147
Epoch #84: loss=0.019969817976220362
Epoch #85: loss=0.01981624866528498
Epoch #86: loss=0.018858068564986553
Epoch #87: loss=0.02709487538636881
Epoch #88: loss=0.024724412145174714
Epoch #89: loss=0.017958713538496516
Epoch #90: loss=0.020944935819064807
Epoch #91: loss=0.027768027322387884
Epoch #92: loss=0.016722019183478456
Epoch #93: loss=0.017432859737083087
Epoch #94: loss=0.02326457703466447
Epoch #95: loss=0.023011100107950006
Epoch #96: loss=0.016638207737594647
Epoch #97: loss=0.01767876862874049
Epoch #98: loss=0.019419449386856896
Epoch #99: loss=0.03830399145899739
Epoch #100: loss=0.02144474558112655
Epoch #101: loss=0.015767169055443456
Epoch #102: loss=0.01755560003224244
Epoch #103: loss=0.021835810970065782
Epoch #104: loss=0.02072597141998852
Epoch #105: loss=0.01603367620601746
Epoch #106: loss=0.018754982436005214
Epoch #107: loss=0.023171217004111903
Epoch #108: loss=0.016792970579449968
Epoch #109: loss=0.01599320801924257
Epoch #110: loss=0.02041935390213791
Epoch #111: loss=0.01677729127527001
Epoch #112: loss=0.019315286719123706
Epoch #113: loss=0.019887508183284924
Epoch #114: loss=0.01910644258073297
Epoch #115: loss=0.017184138817627887
Epoch #116: loss=0.01274481704922587
Epoch #117: loss=0.014865081527709276
Epoch #118: loss=0.01864536917330289
Epoch #119: loss=0.01649276019302361
Epoch #120: loss=0.012853386406897123
Epoch #121: loss=0.02208379388016355
Epoch #122: loss=0.022182963664810068
Epoch #123: loss=0.016856204701473067
Epoch #124: loss=0.023675956839568246
Epoch #125: loss=0.023995836220141047
Epoch #126: loss=0.01741145156332766
Epoch #127: loss=0.015412872619636853
Epoch #128: loss=0.01891766683358438
Epoch #129: loss=0.012778288000075237
Epoch #130: loss=0.01853788272560345
Epoch #131: loss=0.032500697103202705
Epoch #132: loss=0.012892533212705323
Epoch #133: loss=0.015024271583864032
Epoch #134: loss=0.017628281599529602
Epoch #135: loss=0.016576773643845594
Epoch #136: loss=0.02024719628950534
Epoch #137: loss=0.017992300446498976
Epoch #138: loss=0.01607077451083448
Epoch #139: loss=0.014433937331124044
Epoch #140: loss=0.028688931971549158
Epoch #141: loss=0.018615877410589975
Epoch #142: loss=0.015014002131496616
Epoch #143: loss=0.021231720931836364
Epoch #144: loss=0.01799622433976416
Epoch #145: loss=0.012875552386125805
Epoch #146: loss=0.017893013842638774
Epoch #147: loss=0.014337092972661666
Epoch #148: loss=0.016621893213435754
Epoch #149: loss=0.017246172348477095
Epoch #150: loss=0.020477293792152223
Epoch #151: loss=0.01347000740734255
Epoch #152: loss=0.018237635591564095
Epoch #153: loss=0.015974927155168517
Epoch #154: loss=0.017968191576218272
Epoch #155: loss=0.015353144637994158
Epoch #156: loss=0.012330083089976332
Epoch #157: loss=0.021971368395843797
Epoch #158: loss=0.015623375576024397
Epoch #159: loss=0.014315038605981024
Epoch #160: loss=0.017979776559562125
Epoch #161: loss=0.011873527905125173
Epoch #162: loss=0.016279834268899975
Epoch #163: loss=0.02071209468869436
Epoch #164: loss=0.018929984898328506
Epoch #165: loss=0.012357083020232421
Epoch #166: loss=0.02205982381062284
Epoch #167: loss=0.01985878401598662
Epoch #168: loss=0.021747433171239696
Epoch #169: loss=0.013675013930613048
Epoch #170: loss=0.016338852867024592
Epoch #171: loss=0.014151619289417175
Epoch #172: loss=0.017207071062519733
Epoch #173: loss=0.015733308351908552
Epoch #174: loss=0.010215435342934695
Epoch #175: loss=0.013201020262370968
Epoch #176: loss=0.01426796010932079
Epoch #177: loss=0.01776971464351979
Epoch #178: loss=0.012035060846328924
Epoch #179: loss=0.01152031159501324
Epoch #180: loss=0.014013161471373731
Epoch #181: loss=0.01159623798583683
Epoch #182: loss=0.014401360571431536
Epoch #183: loss=0.014544027735291268
Epoch #184: loss=0.018660101072025634
Epoch #185: loss=0.013972693097445489
Epoch #186: loss=0.015312268873315988
Epoch #187: loss=0.01194857896855132
Epoch #188: loss=0.013037536838170846
Epoch #189: loss=0.014111744180354937
Epoch #190: loss=0.014539137956936092
Epoch #191: loss=0.023476478445668147
Epoch #192: loss=0.029809877429352077
Epoch #193: loss=0.01710795314242327
Epoch #194: loss=0.011326912746993443
Epoch #195: loss=0.01493335697016845
Epoch #196: loss=0.017021015690738574
Epoch #197: loss=0.011843740614406649
Epoch #198: loss=0.017594833722867662
Epoch #199: loss=0.010993181170939078
Epoch #200: loss=0.017613903699504867
Epoch #201: loss=0.012093059689184145
Epoch #202: loss=0.016086554995201494
Epoch #203: loss=0.014104889232928165
Epoch #204: loss=0.012343088044641641
Epoch #205: loss=0.019862295562273174
Epoch #206: loss=0.01664476732588902
Epoch #207: loss=0.010685681993633487
Epoch #208: loss=0.019848676145607102
Epoch #209: loss=0.015467719457761328
Epoch #210: loss=0.015949968796556732
Epoch #211: loss=0.01937427566346136
Epoch #212: loss=0.012333426721265838
Epoch #213: loss=0.016139116591997023
Epoch #214: loss=0.011858523305452376
Epoch #215: loss=0.01112332220375448
Epoch #216: loss=0.011944583919580334
Epoch #217: loss=0.01270402607252519
Epoch #218: loss=0.014911695151107721
Epoch #219: loss=0.009033524498697142
Epoch #220: loss=0.014822056981735702
Epoch #221: loss=0.015080867634212486
Epoch #222: loss=0.014166366876107284
Epoch #223: loss=0.013700581987952154
Epoch #224: loss=0.019237375081708818
Epoch #225: loss=0.0163136408391538
Epoch #226: loss=0.013196173610678225
Epoch #227: loss=0.015584498088880799
Epoch #228: loss=0.015128755531918238
Epoch #229: loss=0.01350262319310576
Epoch #230: loss=0.014463599913282773
Epoch #231: loss=0.011270234638042047
Epoch #232: loss=0.009383435047731802
Epoch #233: loss=0.011666382925480048
Epoch #234: loss=0.011649335481837015
Epoch #235: loss=0.015500067872217447
Epoch #236: loss=0.01578638272199142
Epoch #237: loss=0.011640270001870038
Epoch #238: loss=0.01593727137812705
Epoch #239: loss=0.019742241318293594
Epoch #240: loss=0.01756216702316187
Epoch #241: loss=0.012034402540659012
Epoch #242: loss=0.010882169601069067
Epoch #243: loss=0.010610385653688229
Epoch #244: loss=0.016082921858156633
Epoch #245: loss=0.013335962429675536
Epoch #246: loss=0.01204342653914822
Epoch #247: loss=0.01457687346566989
Epoch #248: loss=0.019920035410808994
Epoch #249: loss=0.012091479881958217

Training time: 3:31:18.359943

Finished.
n2one setting ettm1_traffic_weather_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm1_traffic_weather_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='ettm1_traffic_weather_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.75814e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.91827e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.96978e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.75814e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4062901202075097, 'MAE': 0.4563447106942469}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='ettm2_electricity_traffic_weather', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/ettm2_electricity_traffic_weather_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.8870275296515129
Epoch #1: loss=0.3296554310216767
Epoch #2: loss=0.21378429844120486
Epoch #3: loss=0.18241842589722793
Epoch #4: loss=0.13852621545618185
Epoch #5: loss=0.11624271114066732
Epoch #6: loss=0.10568629528288959
Epoch #7: loss=0.08612453821038858
Epoch #8: loss=0.07213018472329331
Epoch #9: loss=0.062425097541456094
Epoch #10: loss=0.06123266431968659
Epoch #11: loss=0.06510211001722845
Epoch #12: loss=0.05011995393786671
Epoch #13: loss=0.049210849809307664
Epoch #14: loss=0.043318877920325176
Epoch #15: loss=0.04358669452743269
Epoch #16: loss=0.04989593843977181
Epoch #17: loss=0.0505584223194002
Epoch #18: loss=0.03399830779316453
Epoch #19: loss=0.03590344532362384
Epoch #20: loss=0.03141770376518491
Epoch #21: loss=0.024204011862242563
Epoch #22: loss=0.03585721111281958
Epoch #23: loss=0.02563808008495978
Epoch #24: loss=0.03355237304358972
Epoch #25: loss=0.03334754544279737
Epoch #26: loss=0.024921536249190676
Epoch #27: loss=0.02604059267876914
Epoch #28: loss=0.024527380417375903
Epoch #29: loss=0.03145323522201907
Epoch #30: loss=0.02148513118187767
Epoch #31: loss=0.022286386889802504
Epoch #32: loss=0.02766299678430679
Epoch #33: loss=0.02548524927558782
Epoch #34: loss=0.02411321896981433
Epoch #35: loss=0.02882944620228716
Epoch #36: loss=0.023614858846050368
Epoch #37: loss=0.032956501538292736
Epoch #38: loss=0.02292883939590254
Epoch #39: loss=0.022969567367724014
Epoch #40: loss=0.016474958539078453
Epoch #41: loss=0.022515800850920104
Epoch #42: loss=0.0187747510593312
Epoch #43: loss=0.033874231545859564
Epoch #44: loss=0.01873240935760283
Epoch #45: loss=0.016324266959764216
Epoch #46: loss=0.024065283803673856
Epoch #47: loss=0.02085534696554055
Epoch #48: loss=0.020831060318131246
Epoch #49: loss=0.019560834773354324
Epoch #50: loss=0.023948966851553375
Epoch #51: loss=0.01800738575440816
Epoch #52: loss=0.018742060054930454
Epoch #53: loss=0.016264597777626476
Epoch #54: loss=0.022113303953951575
Epoch #55: loss=0.018521257586224714
Epoch #56: loss=0.015617402090016394
Epoch #57: loss=0.022081898850938458
Epoch #58: loss=0.019147204274271586
Epoch #59: loss=0.02407974762869851
Epoch #60: loss=0.01758078410832658
Epoch #61: loss=0.017840009384390662
Epoch #62: loss=0.01770296594140895
Epoch #63: loss=0.01615011316712671
Epoch #64: loss=0.02000612764393617
Epoch #65: loss=0.014326633437733226
Epoch #66: loss=0.024832373099343386
Epoch #67: loss=0.017051663184629137
Epoch #68: loss=0.01867771010870232
Epoch #69: loss=0.01490454121548148
Epoch #70: loss=0.015137336101405873
Epoch #71: loss=0.0158007917248455
Epoch #72: loss=0.01842581019767839
Epoch #73: loss=0.019696612938996175
Epoch #74: loss=0.018866264586862688
Epoch #75: loss=0.013646482082978884
Epoch #76: loss=0.020704960029240178
Epoch #77: loss=0.020519935203139807
Epoch #78: loss=0.010424024826186753
Epoch #79: loss=0.014036165518432352
Epoch #80: loss=0.02007681744779817
Epoch #81: loss=0.01563726830967515
Epoch #82: loss=0.014064061845378182
Epoch #83: loss=0.016619069945376336
Epoch #84: loss=0.011988745613625278
Epoch #85: loss=0.019986909870370807
Epoch #86: loss=0.022752244109368967
Epoch #87: loss=0.01804178212046505
Epoch #88: loss=0.014106219350687156
Epoch #89: loss=0.018586286842597832
Epoch #90: loss=0.013845949201652833
Epoch #91: loss=0.015516392954925292
Epoch #92: loss=0.01820495259863626
Epoch #93: loss=0.014204341489616515
Epoch #94: loss=0.012029512474536666
Epoch #95: loss=0.015048850581482183
Epoch #96: loss=0.011895799066071765
Epoch #97: loss=0.012510548154756686
Epoch #98: loss=0.015442577437578785
Epoch #99: loss=0.02719775879763727
Epoch #100: loss=0.013312898285817698
Epoch #101: loss=0.0160183766468659
Epoch #102: loss=0.013185026225264516
Epoch #103: loss=0.010525618349636149
Epoch #104: loss=0.016560059571810462
Epoch #105: loss=0.01699880696234358
Epoch #106: loss=0.016719189778098657
Epoch #107: loss=0.013161827446000657
Epoch #108: loss=0.0146674937232241
Epoch #109: loss=0.020465742460158358
Epoch #110: loss=0.013078614344036009
Epoch #111: loss=0.01279309374369971
Epoch #112: loss=0.013729835401461402
Epoch #113: loss=0.01809241679018997
Epoch #114: loss=0.015049393717953401
Epoch #115: loss=0.01316718786710837
Epoch #116: loss=0.0125083126041959
Epoch #117: loss=0.011896856962461929
Epoch #118: loss=0.012791802781559508
Epoch #119: loss=0.0156560915856375
Epoch #120: loss=0.016062277937036
Epoch #121: loss=0.010415125641610175
Epoch #122: loss=0.01434951706039891
Epoch #123: loss=0.020329490346098357
Epoch #124: loss=0.011647230205658086
Epoch #125: loss=0.009826524527760158
Epoch #126: loss=0.01504562527476142
Epoch #127: loss=0.01096318069050808
Epoch #128: loss=0.016406673172056546
Epoch #129: loss=0.01444295470669129
Epoch #130: loss=0.009991204789822987
Epoch #131: loss=0.020684394290845853
Epoch #132: loss=0.010954275185606809
Epoch #133: loss=0.01057336732507688
Epoch #134: loss=0.018611506828522983
Epoch #135: loss=0.010786974898429271
Epoch #136: loss=0.012027059823332343
Epoch #137: loss=0.011670112070028974
Epoch #138: loss=0.014065002771972328
Epoch #139: loss=0.013780682837685044
Epoch #140: loss=0.008792044965146666
Epoch #141: loss=0.013616330426705897
Epoch #142: loss=0.010563529809170162
Epoch #143: loss=0.014651796015143609
Epoch #144: loss=0.00963943336979862
Epoch #145: loss=0.01371730959751597
Epoch #146: loss=0.013941458651922894
Epoch #147: loss=0.01893298982055266
Epoch #148: loss=0.012222186839527673
Epoch #149: loss=0.00904761722922558
Epoch #150: loss=0.011515229434675735
Epoch #151: loss=0.013610682804347398
Epoch #152: loss=0.015199043599938303
Epoch #153: loss=0.011891292047769892
Epoch #154: loss=0.011798022779159928
Epoch #155: loss=0.012229290909728333
Epoch #156: loss=0.010347058079781566
Epoch #157: loss=0.017802373601109853
Epoch #158: loss=0.014044032828034509
Epoch #159: loss=0.018766215319108777
Epoch #160: loss=0.01583408161695172
Epoch #161: loss=0.012451343872041927
Epoch #162: loss=0.01056747875456912
Epoch #163: loss=0.01108198319190825
Epoch #164: loss=0.01574190700969174
Epoch #165: loss=0.013395484427937697
Epoch #166: loss=0.009664369697947834
Epoch #167: loss=0.013055611683050868
Epoch #168: loss=0.010415707983195374
Epoch #169: loss=0.013309363114593475
Epoch #170: loss=0.01232433120264728
Epoch #171: loss=0.013807439014784845
Epoch #172: loss=0.009339750116660219
Epoch #173: loss=0.01774946344673078
Epoch #174: loss=0.008641506482588917
Epoch #175: loss=0.011483253626528361
Epoch #176: loss=0.010067041254529374
Epoch #177: loss=0.011749948558299068
Epoch #178: loss=0.011476566023267252
Epoch #179: loss=0.007162230872074629
Epoch #180: loss=0.012900392751705157
Epoch #181: loss=0.010564613808697896
Epoch #182: loss=0.016770199746059037
Epoch #183: loss=0.00963043234867834
Epoch #184: loss=0.007698888546244726
Epoch #185: loss=0.01846503490061102
Epoch #186: loss=0.009727868111016892
Epoch #187: loss=0.016741876380964655
Epoch #188: loss=0.01149883148645444
Epoch #189: loss=0.012140287138086545
Epoch #190: loss=0.009065197617096824
Epoch #191: loss=0.009051504162186471
Epoch #192: loss=0.011746284554816962
Epoch #193: loss=0.011501539027836979
Epoch #194: loss=0.01118615494920721
Epoch #195: loss=0.01184307920212617
Epoch #196: loss=0.007391251601252109
Epoch #197: loss=0.014687776767704101
Epoch #198: loss=0.009934572736361946
Epoch #199: loss=0.008445892624400049
Epoch #200: loss=0.009322753327689467
Epoch #201: loss=0.011245141165606777
Epoch #202: loss=0.022619441224086302
Epoch #203: loss=0.011347371127793267
Epoch #204: loss=0.0108618335501142
Epoch #205: loss=0.011990044918370512
Epoch #206: loss=0.011365544382620175
Epoch #207: loss=0.00758310027092387
Epoch #208: loss=0.012294095111279662
Epoch #209: loss=0.009374874645231266
Epoch #210: loss=0.01059059576541362
Epoch #211: loss=0.012253539346432366
Epoch #212: loss=0.01093593700787126
Epoch #213: loss=0.014503652143023038
Epoch #214: loss=0.010773962737417963
Epoch #215: loss=0.009822146749490352
Epoch #216: loss=0.011936021428536166
Epoch #217: loss=0.009961883484249454
Epoch #218: loss=0.009020551333306969
Epoch #219: loss=0.011302076822521783
Epoch #220: loss=0.010698564655050162
Epoch #221: loss=0.010912285227167275
Epoch #222: loss=0.015532416211767743
Epoch #223: loss=0.00822329636542191
Epoch #224: loss=0.012176853619953885
Epoch #225: loss=0.01156582055893344
Epoch #226: loss=0.010404569045142842
Epoch #227: loss=0.01053509901845007
Epoch #228: loss=0.012094907770691951
Epoch #229: loss=0.031046335558196126
Epoch #230: loss=0.009816003377600878
Epoch #231: loss=0.00989208358578402
Epoch #232: loss=0.011262979986528737
Epoch #233: loss=0.00967038679512773
Epoch #234: loss=0.011572208466108737
Epoch #235: loss=0.007100291618547492
Epoch #236: loss=0.009733369897945581
Epoch #237: loss=0.02087524435797813
Epoch #238: loss=0.010974921504277488
Epoch #239: loss=0.010238245746097432
Epoch #240: loss=0.008005887286961923
Epoch #241: loss=0.011215998406707334
Epoch #242: loss=0.009331922853077424
Epoch #243: loss=0.009548010840015076
Epoch #244: loss=0.010161258278058681
Epoch #245: loss=0.010978733676917027
Epoch #246: loss=0.009531789946789208
Epoch #247: loss=0.008132170991755958
Epoch #248: loss=0.01360711264424026
Epoch #249: loss=0.008952023710298818

Training time: 5:05:59.612095

Finished.
n2one setting ettm2_electricity_traffic_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm2_electricity_traffic_weather_epochs_250_seed_2022/model.pkl', muti_dataset='ettm2_electricity_traffic_weather', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.16623e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.40780885221795693, 'MAE': 0.4203641834290122}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='ettm2_electricity_traffic_exchange', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/ettm2_electricity_traffic_exchange_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.8629440331270611
Epoch #1: loss=0.30675603144998953
Epoch #2: loss=0.20553049272524437
Epoch #3: loss=0.1560366153438109
Epoch #4: loss=0.12130539684700539
Epoch #5: loss=0.09576284465071638
Epoch #6: loss=0.08593246387705182
Epoch #7: loss=0.07319168225876033
Epoch #8: loss=0.06614878926946845
Epoch #9: loss=0.06874993012733013
Epoch #10: loss=0.050617893385474635
Epoch #11: loss=0.05243839200461336
Epoch #12: loss=0.05164920903406046
Epoch #13: loss=0.047050740186686
Epoch #14: loss=0.039845417963399764
Epoch #15: loss=0.0393083469443234
Epoch #16: loss=0.03994442647696471
Epoch #17: loss=0.034842456682444164
Epoch #18: loss=0.03454322098814781
Epoch #19: loss=0.03841550929459066
Epoch #20: loss=0.03228505010765624
Epoch #21: loss=0.033233421419618554
Epoch #22: loss=0.033105757521847405
Epoch #23: loss=0.03381928626758615
Epoch #24: loss=0.034370366569349664
Epoch #25: loss=0.03257850554800583
Epoch #26: loss=0.029176605854754085
Epoch #27: loss=0.026045458489758182
Epoch #28: loss=0.02925814709890736
Epoch #29: loss=0.030061577859442346
Epoch #30: loss=0.023868743229732762
Epoch #31: loss=0.02056099705050096
Epoch #32: loss=0.02629507345035277
Epoch #33: loss=0.027168252869571533
Epoch #34: loss=0.025172992446004627
Epoch #35: loss=0.02656378013811333
Epoch #36: loss=0.02121865384287655
Epoch #37: loss=0.019779647167225037
Epoch #38: loss=0.02923665077031548
Epoch #39: loss=0.020231572437055947
Epoch #40: loss=0.028855979536009563
Epoch #41: loss=0.027407259058835644
Epoch #42: loss=0.026230381367685112
Epoch #43: loss=0.0171800248569227
Epoch #44: loss=0.023172179920052237
Epoch #45: loss=0.021242542853326142
Epoch #46: loss=0.017285237260081087
Epoch #47: loss=0.021194058417837707
Epoch #48: loss=0.021340522916093407
Epoch #49: loss=0.025343332191334167
Epoch #50: loss=0.019646044904371947
Epoch #51: loss=0.016548494559080463
Epoch #52: loss=0.022557412191083384
Epoch #53: loss=0.020078184938132057
Epoch #54: loss=0.018855740956496447
Epoch #55: loss=0.016148606636486876
Epoch #56: loss=0.01965244488155577
Epoch #57: loss=0.02160824260507058
Epoch #58: loss=0.01694795120653821
Epoch #59: loss=0.017121382605748563
Epoch #60: loss=0.01906677851207518
Epoch #61: loss=0.019748337543753523
Epoch #62: loss=0.017757819802795703
Epoch #63: loss=0.014765165338897603
Epoch #64: loss=0.016780212805545407
Epoch #65: loss=0.021174072638045945
Epoch #66: loss=0.019312399256367782
Epoch #67: loss=0.015468502085999362
Epoch #68: loss=0.019016136217241745
Epoch #69: loss=0.017379142312085434
Epoch #70: loss=0.014982982584402761
Epoch #71: loss=0.015918383991922802
Epoch #72: loss=0.013593447024515306
Epoch #73: loss=0.019895172190360265
Epoch #74: loss=0.018455310399351974
Epoch #75: loss=0.01714613296517412
Epoch #76: loss=0.01855489802263025
Epoch #77: loss=0.015857172950272072
Epoch #78: loss=0.016597257706602243
Epoch #79: loss=0.016336243544544826
Epoch #80: loss=0.014971417670741371
Epoch #81: loss=0.015514133065386194
Epoch #82: loss=0.015260446600534817
Epoch #83: loss=0.017655041333341805
Epoch #84: loss=0.016904552535943942
Epoch #85: loss=0.015600080260784775
Epoch #86: loss=0.015780375418872124
Epoch #87: loss=0.016489238397711454
Epoch #88: loss=0.016098249095031828
Epoch #89: loss=0.019572048688459655
Epoch #90: loss=0.01740456803616298
Epoch #91: loss=0.012465877825640856
Epoch #92: loss=0.016217491391001863
Epoch #93: loss=0.013863422945697234
Epoch #94: loss=0.019546077114874893
Epoch #95: loss=0.015243808341893629
Epoch #96: loss=0.014763045974562036
Epoch #97: loss=0.018491871233078647
Epoch #98: loss=0.018536212983190203
Epoch #99: loss=0.012933367693759176
Epoch #100: loss=0.018939753511541688
Epoch #101: loss=0.011988311044117529
Epoch #102: loss=0.012759219047305648
Epoch #103: loss=0.011254285270592353
Epoch #104: loss=0.016482352036574548
Epoch #105: loss=0.017084963328791773
Epoch #106: loss=0.016577734810255814
Epoch #107: loss=0.014708955588736207
Epoch #108: loss=0.017234038179177118
Epoch #109: loss=0.01973113568004096
Epoch #110: loss=0.011848094700952836
Epoch #111: loss=0.01437088709132639
Epoch #112: loss=0.015348549552898917
Epoch #113: loss=0.012836058152543758
Epoch #114: loss=0.014898074325053029
Epoch #115: loss=0.0196006491456507
Epoch #116: loss=0.015405391721554083
Epoch #117: loss=0.016579399064386914
Epoch #118: loss=0.013854672907411544
Epoch #119: loss=0.014030944804627368
Epoch #120: loss=0.012487933797890222
Epoch #121: loss=0.018560204738248397
Epoch #122: loss=0.015505203539580176
Epoch #123: loss=0.011494763724928367
Epoch #124: loss=0.018735810305505602
Epoch #125: loss=0.01158751615128891
Epoch #126: loss=0.01388112573716681
Epoch #127: loss=0.01459543198686943
Epoch #128: loss=0.016684470583395932
Epoch #129: loss=0.015337499962034795
Epoch #130: loss=0.012798344564155177
Epoch #131: loss=0.008759823191612002
Epoch #132: loss=0.013991652572550384
Epoch #133: loss=0.013251872384970014
Epoch #134: loss=0.011878434168054283
Epoch #135: loss=0.012595738719503482
Epoch #136: loss=0.011942888954698404
Epoch #137: loss=0.012991810545087315
Epoch #138: loss=0.009573179153791024
Epoch #139: loss=0.014952304512914153
Epoch #140: loss=0.011923132210684407
Epoch #141: loss=0.010063349858089854
Epoch #142: loss=0.01412824874525613
Epoch #143: loss=0.015454540380971575
Epoch #144: loss=0.01142607764849891
Epoch #145: loss=0.010465029383309886
Epoch #146: loss=0.01188337055006897
Epoch #147: loss=0.012500088547394489
Epoch #148: loss=0.014492870829688554
Epoch #149: loss=0.009892701678297866
Epoch #150: loss=0.012615623345070544
Epoch #151: loss=0.011377020781603246
Epoch #152: loss=0.016003011058706645
Epoch #153: loss=0.01055278690992826
Epoch #154: loss=0.01600640131442551
Epoch #155: loss=0.01890724288130335
Epoch #156: loss=0.011219251902812038
Epoch #157: loss=0.012170574460893377
Epoch #158: loss=0.01233236108814655
Epoch #159: loss=0.010209735049945073
Epoch #160: loss=0.015374180615589816
Epoch #161: loss=0.01771882877926241
Epoch #162: loss=0.011481541275483953
Epoch #163: loss=0.011254683151879323
Epoch #164: loss=0.012510317011460355
Epoch #165: loss=0.012924399109411122
Epoch #166: loss=0.012042692623906203
Epoch #167: loss=0.01510030180910986
Epoch #168: loss=0.012813396502887934
Epoch #169: loss=0.011707175128397643
Epoch #170: loss=0.01148395177070187
Epoch #171: loss=0.011512507292547205
Epoch #172: loss=0.012148673639227147
Epoch #173: loss=0.010441676487702195
Epoch #174: loss=0.011798964686379513
Epoch #175: loss=0.016695222810460698
Epoch #176: loss=0.012357165899773526
Epoch #177: loss=0.010314420167596776
Epoch #178: loss=0.014950446940753852
Epoch #179: loss=0.0106962168351319
Epoch #180: loss=0.010670178751885417
Epoch #181: loss=0.011672222462714038
Epoch #182: loss=0.012309117846477318
Epoch #183: loss=0.012361122169305249
Epoch #184: loss=0.010337732140128682
Epoch #185: loss=0.010056339830649047
Epoch #186: loss=0.013522933228174806
Epoch #187: loss=0.010130474699243512
Epoch #188: loss=0.017892297772510415
Epoch #189: loss=0.009223946770241026
Epoch #190: loss=0.014643319142041894
Epoch #191: loss=0.01204266392963589
Epoch #192: loss=0.009243443350847057
Epoch #193: loss=0.009971292346588858
Epoch #194: loss=0.010512698518274577
Epoch #195: loss=0.016150141518299056
Epoch #196: loss=0.01086337161611668
Epoch #197: loss=0.00875392350517722
Epoch #198: loss=0.015836764336675024
Epoch #199: loss=0.01308873977514591
Epoch #200: loss=0.010608551695962927
Epoch #201: loss=0.009174537413241032
Epoch #202: loss=0.016880203377288502
Epoch #203: loss=0.011683733806106747
Epoch #204: loss=0.009779305133576392
Epoch #205: loss=0.014341114603706283
Epoch #206: loss=0.0172177887695266
Epoch #207: loss=0.011076766478597806
Epoch #208: loss=0.011802292658569495
Epoch #209: loss=0.010172033757440604
Epoch #210: loss=0.014851558666843642
Epoch #211: loss=0.009750304289962562
Epoch #212: loss=0.01543700395041998
Epoch #213: loss=0.010270791634595447
Epoch #214: loss=0.012295542239762003
Epoch #215: loss=0.010483878310735172
Epoch #216: loss=0.009888234997660963
Epoch #217: loss=0.013334438692823481
Epoch #218: loss=0.00882324321635818
Epoch #219: loss=0.011158616902935629
Epoch #220: loss=0.013133495629811292
Epoch #221: loss=0.011449240500303725
Epoch #222: loss=0.011955572383600026
Epoch #223: loss=0.012047925912303433
Epoch #224: loss=0.01213573504764933
Epoch #225: loss=0.01276725276250374
Epoch #226: loss=0.010191872088613557
Epoch #227: loss=0.010004295048085211
Epoch #228: loss=0.010993753976808254
Epoch #229: loss=0.012317901315500134
Epoch #230: loss=0.01169371114923034
Epoch #231: loss=0.00894848173301036
Epoch #232: loss=0.012494637488355173
Epoch #233: loss=0.01741516761617935
Epoch #234: loss=0.007655781464949051
Epoch #235: loss=0.01162473464336443
Epoch #236: loss=0.01120850737567167
Epoch #237: loss=0.012668406266324966
Epoch #238: loss=0.008904036460355954
Epoch #239: loss=0.010196337702151373
Epoch #240: loss=0.009058688155800005
Epoch #241: loss=0.01205969842163834
Epoch #242: loss=0.011763834308873755
Epoch #243: loss=0.010700628291695423
Epoch #244: loss=0.00877980847720765
Epoch #245: loss=0.010532537334600151
Epoch #246: loss=0.010760689831494318
Epoch #247: loss=0.009183231986360943
Epoch #248: loss=0.011115200100933432
Epoch #249: loss=0.010484426419245631

Training time: 4:53:10.776090

Finished.
n2one setting ettm2_electricity_traffic_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm2_electricity_traffic_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='ettm2_electricity_traffic_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.9249e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.16733e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.49897e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.9249e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.7577544281474131, 'MAE': 0.6791803327288112}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='ettm2_electricity_weather_exchange', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/ettm2_electricity_weather_exchange_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.815392328090355
Epoch #1: loss=0.858470479973027
Epoch #2: loss=0.603467727538015
Epoch #3: loss=0.5122642859490842
Epoch #4: loss=0.42530376427486294
Epoch #5: loss=0.37595935927225593
Epoch #6: loss=0.3331895385935007
Epoch #7: loss=0.3065806065833634
Epoch #8: loss=0.29240931381211904
Epoch #9: loss=0.2600938386482293
Epoch #10: loss=0.23437685961198937
Epoch #11: loss=0.21510922539307445
Epoch #12: loss=0.21924365781084762
Epoch #13: loss=0.19490806041845207
Epoch #14: loss=0.18957662373740491
Epoch #15: loss=0.19370343538174212
Epoch #16: loss=0.15645989510001707
Epoch #17: loss=0.15020582146046918
Epoch #18: loss=0.1240238281516511
Epoch #19: loss=0.1231254267104255
Epoch #20: loss=0.13162495891812964
Epoch #21: loss=0.12913959002621023
Epoch #22: loss=0.10692077337463941
Epoch #23: loss=0.10277536981917225
Epoch #24: loss=0.10300783092115338
Epoch #25: loss=0.08161864751349382
Epoch #26: loss=0.07902370424193071
Epoch #27: loss=0.096040058504444
Epoch #28: loss=0.0816448562030421
Epoch #29: loss=0.0912105632523492
Epoch #30: loss=0.10741041217106165
Epoch #31: loss=0.09425704701437203
Epoch #32: loss=0.06764118704700568
Epoch #33: loss=0.06588579214921048
Epoch #34: loss=0.059552455285329965
Epoch #35: loss=0.0766197200406526
Epoch #36: loss=0.07988301439775673
Epoch #37: loss=0.06855237818847262
Epoch #38: loss=0.05914204201630515
Epoch #39: loss=0.06388584628212647
Epoch #40: loss=0.05741853901513348
Epoch #41: loss=0.04949230871664594
Epoch #42: loss=0.050992830469440975
Epoch #43: loss=0.06334553419706498
Epoch #44: loss=0.06484149577340385
Epoch #45: loss=0.08662643017695168
Epoch #46: loss=0.06975837247229888
Epoch #47: loss=0.06684268563807703
Epoch #48: loss=0.040312221177721326
Epoch #49: loss=0.04246722385185501
Epoch #50: loss=0.03621241458802347
Epoch #51: loss=0.05262091261801651
Epoch #52: loss=0.05428018812166496
Epoch #53: loss=0.045069463130231704
Epoch #54: loss=0.047227911706797555
Epoch #55: loss=0.03697079952228611
Epoch #56: loss=0.04283238690959727
Epoch #57: loss=0.04292655537156846
Epoch #58: loss=0.04147517743082768
Epoch #59: loss=0.03979869059870997
Epoch #60: loss=0.051650450892855866
Epoch #61: loss=0.055465044976654845
Epoch #62: loss=0.04985847083286794
Epoch #63: loss=0.04091981385835788
Epoch #64: loss=0.0471226645645029
Epoch #65: loss=0.05952823820318442
Epoch #66: loss=0.05231296947694134
Epoch #67: loss=0.061259629920855305
Epoch #68: loss=0.05459795104208672
Epoch #69: loss=0.056253682559895546
Epoch #70: loss=0.04864799747621396
Epoch #71: loss=0.03855734562330823
Epoch #72: loss=0.029097484124765878
Epoch #73: loss=0.051452656440968664
Epoch #74: loss=0.04087281447855624
Epoch #75: loss=0.038161288671732414
Epoch #76: loss=0.034205621885151034
Epoch #77: loss=0.03122152213695525
Epoch #78: loss=0.029824310894597503
Epoch #79: loss=0.03902120023260982
Epoch #80: loss=0.029839886799791847
Epoch #81: loss=0.03760786341055413
Epoch #82: loss=0.043749460977212086
Epoch #83: loss=0.06377511826735702
Epoch #84: loss=0.0662323383307797
Epoch #85: loss=0.03129337178199689
Epoch #86: loss=0.0744135752083324
Epoch #87: loss=0.02706692174021053
Epoch #88: loss=0.03216313481581514
Epoch #89: loss=0.0264017013032969
Epoch #90: loss=0.02939720274537008
Epoch #91: loss=0.04445819101325628
Epoch #92: loss=0.03846502387221862
Epoch #93: loss=0.04255074341278879
Epoch #94: loss=0.03984624676659571
Epoch #95: loss=0.024695744028358207
Epoch #96: loss=0.03469085864324499
Epoch #97: loss=0.053845529915266185
Epoch #98: loss=0.03101105765341603
Epoch #99: loss=0.02503096165349885
Epoch #100: loss=0.030607396610783506
Epoch #101: loss=0.020406645825584394
Epoch #102: loss=0.021302443314496367
Epoch #103: loss=0.02836703444093776
Epoch #104: loss=0.01730564371615908
Epoch #105: loss=0.0246104592501308
Epoch #106: loss=0.030112086885444606
Epoch #107: loss=0.035824694552890134
Epoch #108: loss=0.03789040823327123
Epoch #109: loss=0.05428052590883215
Epoch #110: loss=0.04603969840723461
Epoch #111: loss=0.03346517953186428
Epoch #112: loss=0.02209142376757812
Epoch #113: loss=0.026363896352335648
Epoch #114: loss=0.03244421499605733
Epoch #115: loss=0.021468137340655783
Epoch #116: loss=0.026042497991978653
Epoch #117: loss=0.030354410737544257
Epoch #118: loss=0.03669554020673841
Epoch #119: loss=0.027584071821072573
Epoch #120: loss=0.019033323553558745
Epoch #121: loss=0.018726672975857273
Epoch #122: loss=0.031303072095049615
Epoch #123: loss=0.0278707122952802
Epoch #124: loss=0.03153729698919091
Epoch #125: loss=0.029124303606225563
Epoch #126: loss=0.03112831510539177
Epoch #127: loss=0.02695133256862103
Epoch #128: loss=0.02192419263581323
Epoch #129: loss=0.02307517404058602
Epoch #130: loss=0.02941274747813548
Epoch #131: loss=0.04640481491809166
Epoch #132: loss=0.0399124458587418
Epoch #133: loss=0.02415170554737077
Epoch #134: loss=0.02457728814950742
Epoch #135: loss=0.023544488711453735
Epoch #136: loss=0.06591224593587176
Epoch #137: loss=0.032367751715116994
Epoch #138: loss=0.0332335843483579
Epoch #139: loss=0.02851815898794569
Epoch #140: loss=0.017147782873209626
Epoch #141: loss=0.016571313622989692
Epoch #142: loss=0.028165289606387558
Epoch #143: loss=0.0288566108344535
Epoch #144: loss=0.03136458768174714
Epoch #145: loss=0.01991142626677492
Epoch #146: loss=0.017693430054430276
Epoch #147: loss=0.019249701185188196
Epoch #148: loss=0.02482321641224696
Epoch #149: loss=0.04506639566602023
Epoch #150: loss=0.01855752195830869
Epoch #151: loss=0.022059704191394944
Epoch #152: loss=0.021618250782822278
Epoch #153: loss=0.023929270816288758
Epoch #154: loss=0.027773049186731947
Epoch #155: loss=0.014614964781909203
Epoch #156: loss=0.024766778328158268
Epoch #157: loss=0.023803371392493264
Epoch #158: loss=0.027026542117456583
Epoch #159: loss=0.027398091439848584
Epoch #160: loss=0.027212105333758008
Epoch #161: loss=0.02635598798136766
Epoch #162: loss=0.020692054227934742
Epoch #163: loss=0.019756160784227126
Epoch #164: loss=0.02496888290656873
Epoch #165: loss=0.02506728806820618
Epoch #166: loss=0.02108628236780279
Epoch #167: loss=0.018129988306308867
Epoch #168: loss=0.014003305152202371
Epoch #169: loss=0.03480832999103952
Epoch #170: loss=0.020445746179610296
Epoch #171: loss=0.02039928614006688
Epoch #172: loss=0.026330473120935016
Epoch #173: loss=0.0270703525169208
Epoch #174: loss=0.026942394288158797
Epoch #175: loss=0.04376767001409323
Epoch #176: loss=0.019432991397897253
Epoch #177: loss=0.020469813805157472
Epoch #178: loss=0.017468394643227605
Epoch #179: loss=0.028946780023779567
Epoch #180: loss=0.022749804821351412
Epoch #181: loss=0.019940124377350658
Epoch #182: loss=0.01997460615076888
Epoch #183: loss=0.022446956887238155
Epoch #184: loss=0.012553890592522304
Epoch #185: loss=0.019721656513229886
Epoch #186: loss=0.01863665885945319
Epoch #187: loss=0.018349991074083832
Epoch #188: loss=0.01869901720274754
Epoch #189: loss=0.016324703780189284
Epoch #190: loss=0.018378251171454564
Epoch #191: loss=0.014646845501389538
Epoch #192: loss=0.016547187729745016
Epoch #193: loss=0.02097218348154839
Epoch #194: loss=0.025126680723423916
Epoch #195: loss=0.027344000763692408
Epoch #196: loss=0.027318837507430697
Epoch #197: loss=0.01695066729949818
Epoch #198: loss=0.01893049199102304
Epoch #199: loss=0.016815852128920946
Epoch #200: loss=0.020198654954523977
Epoch #201: loss=0.01263583486752147
Epoch #202: loss=0.012464187767786353
Epoch #203: loss=0.020942914901146043
Epoch #204: loss=0.015321371188406995
Epoch #205: loss=0.02064357439146372
Epoch #206: loss=0.025268982992510063
Epoch #207: loss=0.031055618668658292
Epoch #208: loss=0.022770748558629792
Epoch #209: loss=0.01863076188569746
Epoch #210: loss=0.02703967325747537
Epoch #211: loss=0.01573755659396465
Epoch #212: loss=0.026987542882065486
Epoch #213: loss=0.018330126327762757
Epoch #214: loss=0.016793286911010886
Epoch #215: loss=0.020187434651065095
Epoch #216: loss=0.018899427189000582
Epoch #217: loss=0.026280046994707235
Epoch #218: loss=0.022297606523571118
Epoch #219: loss=0.018087205868847336
Epoch #220: loss=0.014630377178603295
Epoch #221: loss=0.016792233812920443
Epoch #222: loss=0.023985872700711192
Epoch #223: loss=0.022108525314013337
Epoch #224: loss=0.025211941939237897
Epoch #225: loss=0.018116101714664094
Epoch #226: loss=0.018885287703040356
Epoch #227: loss=0.018572902395657155
Epoch #228: loss=0.019278880108457665
Epoch #229: loss=0.047562836819198595
Epoch #230: loss=0.021002681096672218
Epoch #231: loss=0.010819215049345016
Epoch #232: loss=0.01067760200516443
Epoch #233: loss=0.015363627136621339
Epoch #234: loss=0.021284629604486554
Epoch #235: loss=0.020146745821821143
Epoch #236: loss=0.01581600270205581
Epoch #237: loss=0.02978920504599339
Epoch #238: loss=0.019992736517133628
Epoch #239: loss=0.017360401674761574
Epoch #240: loss=0.018179443663815062
Epoch #241: loss=0.016860422458502215
Epoch #242: loss=0.01632609523432342
Epoch #243: loss=0.0237629255115295
Epoch #244: loss=0.025594541453597356
Epoch #245: loss=0.02171810248089303
Epoch #246: loss=0.028340348465905062
Epoch #247: loss=0.024886074027935898
Epoch #248: loss=0.01846929334313672
Epoch #249: loss=0.01713779674614894

Training time: 1:41:47.308908

Finished.
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='ettm2_traffic_weather_exchange', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/ettm2_traffic_weather_exchange_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.0759513732025352
Epoch #1: loss=0.42474392112323966
Epoch #2: loss=0.3169514425139969
Epoch #3: loss=0.23709021887383624
Epoch #4: loss=0.1961942719954837
Epoch #5: loss=0.16892696303842217
Epoch #6: loss=0.14745865732250693
Epoch #7: loss=0.13065708359619221
Epoch #8: loss=0.10807266985933894
Epoch #9: loss=0.10860704305009812
Epoch #10: loss=0.09924397925828823
Epoch #11: loss=0.09085396427533855
Epoch #12: loss=0.07634614190741831
Epoch #13: loss=0.06783531218214739
Epoch #14: loss=0.07592426195110234
Epoch #15: loss=0.06407463322152294
Epoch #16: loss=0.0652920743301634
Epoch #17: loss=0.058001826318851625
Epoch #18: loss=0.054182475188371236
Epoch #19: loss=0.04950159597297865
Epoch #20: loss=0.052033184655960504
Epoch #21: loss=0.058466382961450174
Epoch #22: loss=0.04422628916499678
Epoch #23: loss=0.05926288242191035
Epoch #24: loss=0.04865266198444857
Epoch #25: loss=0.042227214116417285
Epoch #26: loss=0.03383106926756181
Epoch #27: loss=0.03865695745343303
Epoch #28: loss=0.04007833974015958
Epoch #29: loss=0.03710166421344621
Epoch #30: loss=0.035579331933347204
Epoch #31: loss=0.032741653569434925
Epoch #32: loss=0.05456729343326818
Epoch #33: loss=0.03245219485264358
Epoch #34: loss=0.03299957969991692
Epoch #35: loss=0.03919786199208045
Epoch #36: loss=0.031701984399567174
Epoch #37: loss=0.02944962229284991
Epoch #38: loss=0.02774084812894519
Epoch #39: loss=0.035212198712017445
Epoch #40: loss=0.029217264380435898
Epoch #41: loss=0.052383157578907914
Epoch #42: loss=0.03106732242327397
Epoch #43: loss=0.03062484072950795
Epoch #44: loss=0.03349461219755598
Epoch #45: loss=0.04325809698587062
Epoch #46: loss=0.031389840312898695
Epoch #47: loss=0.034482297085814975
Epoch #48: loss=0.036565171061299306
Epoch #49: loss=0.02517415472904945
Epoch #50: loss=0.021147144646096315
Epoch #51: loss=0.026314876646972997
Epoch #52: loss=0.03071565315157664
Epoch #53: loss=0.023857024291380338
Epoch #54: loss=0.022824510673595984
Epoch #55: loss=0.02564491864328212
Epoch #56: loss=0.02100370659885924
Epoch #57: loss=0.023511026928056535
Epoch #58: loss=0.027761166530209228
Epoch #59: loss=0.02814116060153387
Epoch #60: loss=0.02018969470016143
Epoch #61: loss=0.030800937646505638
Epoch #62: loss=0.02277239700040011
Epoch #63: loss=0.026957937816487546
Epoch #64: loss=0.029335090729509107
Epoch #65: loss=0.022290708574434576
Epoch #66: loss=0.027653979651108558
Epoch #67: loss=0.020719137243343035
Epoch #68: loss=0.021085334179044752
Epoch #69: loss=0.022906184780153178
Epoch #70: loss=0.019431568458813032
Epoch #71: loss=0.025477048739764734
Epoch #72: loss=0.025868003144695978
Epoch #73: loss=0.01632921279358237
Epoch #74: loss=0.021691879353952177
Epoch #75: loss=0.022341367376474366
Epoch #76: loss=0.026391731996607506
Epoch #77: loss=0.02082139202025221
Epoch #78: loss=0.018409777555513054
Epoch #79: loss=0.029321381782572657
Epoch #80: loss=0.019977663977052647
Epoch #81: loss=0.01912613979760504
Epoch #82: loss=0.021334941255483447
Epoch #83: loss=0.018605016729044355
Epoch #84: loss=0.024695804169865648
Epoch #85: loss=0.019801708806133876
Epoch #86: loss=0.01913521491483859
Epoch #87: loss=0.026621210900643098
Epoch #88: loss=0.02333974226850978
Epoch #89: loss=0.01700077853387616
Epoch #90: loss=0.02401466957050737
Epoch #91: loss=0.02385269808062494
Epoch #92: loss=0.021138635300235388
Epoch #93: loss=0.014667748280254356
Epoch #94: loss=0.021904307580386136
Epoch #95: loss=0.02293346873904263
Epoch #96: loss=0.018504040533560712
Epoch #97: loss=0.017126011549672575
Epoch #98: loss=0.02237794437623981
Epoch #99: loss=0.03567139867932819
Epoch #100: loss=0.021511210040615455
Epoch #101: loss=0.01543746667939378
Epoch #102: loss=0.019075037622228758
Epoch #103: loss=0.02096265117992578
Epoch #104: loss=0.019258995273660318
Epoch #105: loss=0.01634644851975565
Epoch #106: loss=0.01851630702869178
Epoch #107: loss=0.023093802294322438
Epoch #108: loss=0.0175700073888091
Epoch #109: loss=0.016766474361778128
Epoch #110: loss=0.018258053004893637
Epoch #111: loss=0.016049531655596073
Epoch #112: loss=0.016775381273632126
Epoch #113: loss=0.019872726947392616
Epoch #114: loss=0.01483395608471113
Epoch #115: loss=0.021031932157408877
Epoch #116: loss=0.015407326263390983
Epoch #117: loss=0.013743599753703895
Epoch #118: loss=0.018707319112183207
Epoch #119: loss=0.019802635837160975
Epoch #120: loss=0.012764596697062251
Epoch #121: loss=0.01805271283253517
Epoch #122: loss=0.019576050918087874
Epoch #123: loss=0.01658539553867913
Epoch #124: loss=0.02376549588989332
Epoch #125: loss=0.02321539766988445
Epoch #126: loss=0.01421125274579746
Epoch #127: loss=0.011198244390027576
Epoch #128: loss=0.018904668149805823
Epoch #129: loss=0.014826836773153813
Epoch #130: loss=0.019787549825169965
Epoch #131: loss=0.03240935924844052
Epoch #132: loss=0.015084681329224978
Epoch #133: loss=0.01354085503628592
Epoch #134: loss=0.015882536164760104
Epoch #135: loss=0.017405513659484895
Epoch #136: loss=0.02458552546340196
Epoch #137: loss=0.01882324756122869
Epoch #138: loss=0.015580785683332609
Epoch #139: loss=0.015030499346367656
Epoch #140: loss=0.016808716512822713
Epoch #141: loss=0.013871659692125924
Epoch #142: loss=0.01662387843679533
Epoch #143: loss=0.02202564839196295
Epoch #144: loss=0.01727657745406314
Epoch #145: loss=0.010410479864833596
Epoch #146: loss=0.018967331277443815
Epoch #147: loss=0.015845309526650822
Epoch #148: loss=0.017258547867728267
Epoch #149: loss=0.016793095081449175
Epoch #150: loss=0.021376056336531314
Epoch #151: loss=0.011730875600471553
Epoch #152: loss=0.017802245201106064
Epoch #153: loss=0.016661810838525484
Epoch #154: loss=0.015748741506780378
Epoch #155: loss=0.014010518674352108
Epoch #156: loss=0.012174821564288391
Epoch #157: loss=0.016118738487364916
Epoch #158: loss=0.014546607523562814
Epoch #159: loss=0.012843768987529978
Epoch #160: loss=0.017970313190973117
Epoch #161: loss=0.014140038798957096
Epoch #162: loss=0.015888331804170132
Epoch #163: loss=0.026319062212809906
Epoch #164: loss=0.012413286903913901
Epoch #165: loss=0.012529653718447581
Epoch #166: loss=0.014309719135383963
Epoch #167: loss=0.01961657863177432
Epoch #168: loss=0.019118840971728272
Epoch #169: loss=0.012283916361044677
Epoch #170: loss=0.011756995992663536
Epoch #171: loss=0.014891547223553158
Epoch #172: loss=0.018859953387479207
Epoch #173: loss=0.01749034002258354
Epoch #174: loss=0.009050731077408284
Epoch #175: loss=0.015126687354218757
Epoch #176: loss=0.010560124435187642
Epoch #177: loss=0.01597244883617449
Epoch #178: loss=0.011587827204285233
Epoch #179: loss=0.015541752458511787
Epoch #180: loss=0.012701685137063821
Epoch #181: loss=0.013949256188772303
Epoch #182: loss=0.014072644556492625
Epoch #183: loss=0.013526384186809149
Epoch #184: loss=0.01406811205098429
Epoch #185: loss=0.010856623424094785
Epoch #186: loss=0.017716013805989778
Epoch #187: loss=0.01830225525171801
Epoch #188: loss=0.014717531085571776
Epoch #189: loss=0.0146005265313798
Epoch #190: loss=0.0195920040634174
Epoch #191: loss=0.012698001087117734
Epoch #192: loss=0.02393454717266319
Epoch #193: loss=0.014113468586946216
Epoch #194: loss=0.011559180102678547
Epoch #195: loss=0.012759971661143295
Epoch #196: loss=0.017753371917652923
Epoch #197: loss=0.013068887212826093
Epoch #198: loss=0.01866550732381147
Epoch #199: loss=0.01202714557292519
Epoch #200: loss=0.017251165058930245
Epoch #201: loss=0.010265264559540124
Epoch #202: loss=0.01748468298265747
Epoch #203: loss=0.013451964594038714
Epoch #204: loss=0.011318213075429946
Epoch #205: loss=0.02263057787038587
Epoch #206: loss=0.013463660232360036
Epoch #207: loss=0.01335607585439442
Epoch #208: loss=0.014515608522517078
Epoch #209: loss=0.013030908425719002
Epoch #210: loss=0.01693207077119066
Epoch #211: loss=0.018526687462957395
Epoch #212: loss=0.01302626589483216
Epoch #213: loss=0.014383578527189137
Epoch #214: loss=0.01206549661714828
Epoch #215: loss=0.012355881941404918
Epoch #216: loss=0.014136184996539854
Epoch #217: loss=0.012551314225541649
Epoch #218: loss=0.011605436432557443
Epoch #219: loss=0.012248491135197655
Epoch #220: loss=0.012855030800127466
Epoch #221: loss=0.015997191321511898
Epoch #222: loss=0.012931976344313445
Epoch #223: loss=0.014620082845702716
Epoch #224: loss=0.01570731154874354
Epoch #225: loss=0.016305661475649894
Epoch #226: loss=0.013577663687861534
Epoch #227: loss=0.014936723494568448
Epoch #228: loss=0.01693477932154663
Epoch #229: loss=0.014286786705127669
Epoch #230: loss=0.01346764913504705
Epoch #231: loss=0.012572894964838347
Epoch #232: loss=0.00937693988743243
Epoch #233: loss=0.013478018911165861
Epoch #234: loss=0.013490527469384749
Epoch #235: loss=0.014233128843109495
Epoch #236: loss=0.015823759484845917
Epoch #237: loss=0.010976805348529932
Epoch #238: loss=0.014400666417511537
Epoch #239: loss=0.017883154584174204
Epoch #240: loss=0.013686168593511882
Epoch #241: loss=0.010670180300420171
Epoch #242: loss=0.014835363855104007
Epoch #243: loss=0.013004796796058234
Epoch #244: loss=0.013546892140181828
Epoch #245: loss=0.010655313519630175
Epoch #246: loss=0.010962475396680816
Epoch #247: loss=0.016409418383410306
Epoch #248: loss=0.019287558770119964
Epoch #249: loss=0.009070410146646236

Training time: 3:36:47.037331

Finished.
n2one setting ettm2_traffic_weather_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/ettm2_traffic_weather_exchange_epochs_250_seed_2022/model.pkl', muti_dataset='ettm2_traffic_weather_exchange', random_seed=2022, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.67312e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.27474e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.0605e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.67312e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.40964490176996715, 'MAE': 0.4575544452234125}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='electricity_traffic_weather_exchange', random_seed=2022, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/electricity_traffic_weather_exchange_epochs_250_seed_2022
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.8368550385964534
Epoch #1: loss=0.35416460353131163
Epoch #2: loss=0.23197193788448708
Epoch #3: loss=0.18376646930736015
Epoch #4: loss=0.1540487419841421
Epoch #5: loss=0.12840424259189415
Epoch #6: loss=0.11522437575454583
Epoch #7: loss=0.09928970466136026
Epoch #8: loss=0.08316581045761827
Epoch #9: loss=0.06706052219216622
Epoch #10: loss=0.07187250714394017
Epoch #11: loss=0.07132564770898053
Epoch #12: loss=0.05544983523483821
Epoch #13: loss=0.055816550500156784
Epoch #14: loss=0.05693137466401664
Epoch #15: loss=0.053037837480409904
Epoch #16: loss=0.0440581637315472
Epoch #17: loss=0.042882217104441886
Epoch #18: loss=0.05074531330174905
Epoch #19: loss=0.037680225928647684
Epoch #20: loss=0.037932282690141136
Epoch #21: loss=0.04052540735933155
Epoch #22: loss=0.04135983005051647
Epoch #23: loss=0.039467613391261376
Epoch #24: loss=0.03367050517770946
Epoch #25: loss=0.03533972633725924
Epoch #26: loss=0.027037996681238356
Epoch #27: loss=0.03214074615863571
Epoch #28: loss=0.030142535795970385
Epoch #29: loss=0.033551438191732286
Epoch #30: loss=0.03014969794364147
Epoch #31: loss=0.03446398459709898
Epoch #32: loss=0.029370604569887115
Epoch #33: loss=0.0257460191262765
Epoch #34: loss=0.02299982307040865
Epoch #35: loss=0.028607183917377363
Epoch #36: loss=0.03865616352430521
Epoch #37: loss=0.041330243321652194
Epoch #38: loss=0.02622261206904884
Epoch #39: loss=0.02444805886557987
Epoch #40: loss=0.026079556845521115
Epoch #41: loss=0.029009845760274426
Epoch #42: loss=0.02578972870510396
Epoch #43: loss=0.022463083059563137
Epoch #44: loss=0.029021122190428267
Epoch #45: loss=0.023776453446012202
Epoch #46: loss=0.0220407512769866
Epoch #47: loss=0.03474893455706222
Epoch #48: loss=0.0310042404712024
Epoch #49: loss=0.018208353527673905
Epoch #50: loss=0.02344315942909091
Epoch #51: loss=0.022751361109642924
Epoch #52: loss=0.028983953477913896
Epoch #53: loss=0.024603643232398654
Epoch #54: loss=0.025276749393781807
Epoch #55: loss=0.025556208154933882
Epoch #56: loss=0.0188417297508118
Epoch #57: loss=0.020648962833750083
Epoch #58: loss=0.022759073963341928
Epoch #59: loss=0.029467456777799713
Epoch #60: loss=0.02259729794197794
Epoch #61: loss=0.018646866017787075
Epoch #62: loss=0.020615462419753334
Epoch #63: loss=0.018254139663554922
Epoch #64: loss=0.018068748249681153
Epoch #65: loss=0.020980995055297644
Epoch #66: loss=0.017925081207199236
Epoch #67: loss=0.018994836079112835
Epoch #68: loss=0.022875607129866613
Epoch #69: loss=0.01602780178603523
Epoch #70: loss=0.017932370729948566
Epoch #71: loss=0.018593559292314005
Epoch #72: loss=0.019964873085839975
Epoch #73: loss=0.019475002151259833
Epoch #74: loss=0.019132086616786215
Epoch #75: loss=0.025506412688229115
Epoch #76: loss=0.017302016167694452
Epoch #77: loss=0.018206882061968247
Epoch #78: loss=0.02048954325830472
Epoch #79: loss=0.01575176264490835
Epoch #80: loss=0.020820616339037774
Epoch #81: loss=0.018279169884436872
Epoch #82: loss=0.015126907432020619
Epoch #83: loss=0.021392050544534646
Epoch #84: loss=0.015768733804014487
Epoch #85: loss=0.023839202239554054
Epoch #86: loss=0.022915505828298956
Epoch #87: loss=0.028333151102335412
Epoch #88: loss=0.018100316190619394
Epoch #89: loss=0.017118673507198225
Epoch #90: loss=0.021546443723235508
Epoch #91: loss=0.017018268559786744
Epoch #92: loss=0.019154626352055535
Epoch #93: loss=0.015270633263187828
Epoch #94: loss=0.02023558011994029
Epoch #95: loss=0.020201482544307314
Epoch #96: loss=0.01761840207935288
Epoch #97: loss=0.016873314463782027
Epoch #98: loss=0.01516366177560412
Epoch #99: loss=0.01685198505575315
Epoch #100: loss=0.016575622326891866
Epoch #101: loss=0.014340275025293468
Epoch #102: loss=0.015528532326411442
Epoch #103: loss=0.0177604506583253
Epoch #104: loss=0.011533248074093127
Epoch #105: loss=0.019040367098785548
Epoch #106: loss=0.014804724455036162
Epoch #107: loss=0.019823133155380986
Epoch #108: loss=0.014525446253557993
Epoch #109: loss=0.01608099466015741
Epoch #110: loss=0.01676831329492018
Epoch #111: loss=0.016161999425925135
Epoch #112: loss=0.01651469024514566
Epoch #113: loss=0.013447473019125892
Epoch #114: loss=0.017257374730862685
Epoch #115: loss=0.014789330357160142
Epoch #116: loss=0.014891647107238386
Epoch #117: loss=0.01455268807943674
Epoch #118: loss=0.021949315457864056
Epoch #119: loss=0.015624617393236763
Epoch #120: loss=0.015000744939782873
Epoch #121: loss=0.015535006334482107
Epoch #122: loss=0.010863505285556223
Epoch #123: loss=0.019156099434566264
Epoch #124: loss=0.018531809818584453
Epoch #125: loss=0.017357212392040876
Epoch #126: loss=0.0129911880069595
Epoch #127: loss=0.013334850293888168
Epoch #128: loss=0.01317522131770992
Epoch #129: loss=0.01948850022582701
Epoch #130: loss=0.011667636880185647
Epoch #131: loss=0.016343302949701512
Epoch #132: loss=0.01506864858348983
Epoch #133: loss=0.013299096849635
Epoch #134: loss=0.014868314402619294
Epoch #135: loss=0.012840147418790361
Epoch #136: loss=0.01643492616123796
Epoch #137: loss=0.016615482369016346
Epoch #138: loss=0.013458252003458843
Epoch #139: loss=0.015305914322124092
Epoch #140: loss=0.014882805002450077
Epoch #141: loss=0.02264467363059254
Epoch #142: loss=0.013785739036644453
Epoch #143: loss=0.0265402945994957
Epoch #144: loss=0.018646030891682375
Epoch #145: loss=0.013184794644903026
Epoch #146: loss=0.015278892144420197
Epoch #147: loss=0.017036940831254444
Epoch #148: loss=0.012568982427840719
Epoch #149: loss=0.014251989224357336
Epoch #150: loss=0.015388992330462701
Epoch #151: loss=0.014264084886432944
Epoch #152: loss=0.013342115304815152
Epoch #153: loss=0.013242001645255052
Epoch #154: loss=0.014395098276495637
Epoch #155: loss=0.010718099498201464
Epoch #156: loss=0.013187284825816246
Epoch #157: loss=0.010871437711403196
Epoch #158: loss=0.015171961431793203
Epoch #159: loss=0.013779859230599168
Epoch #160: loss=0.013997510694725046
Epoch #161: loss=0.01468489379404182
Epoch #162: loss=0.01237671710733252
Epoch #163: loss=0.013183499448639039
Epoch #164: loss=0.01584875853228591
Epoch #165: loss=0.012314369918156955
Epoch #166: loss=0.013888468871473953
Epoch #167: loss=0.013045799048307171
Epoch #168: loss=0.014431125576525235
Epoch #169: loss=0.011249645559528275
Epoch #170: loss=0.014592173326151286
Epoch #171: loss=0.013181979342194174
Epoch #172: loss=0.01805068396977181
Epoch #173: loss=0.014609515539569636
Epoch #174: loss=0.009975752487710076
Epoch #175: loss=0.01241237704891353
Epoch #176: loss=0.013277985385328114
Epoch #177: loss=0.0191640591552535
Epoch #178: loss=0.011366655228530564
Epoch #179: loss=0.014943331849145081
Epoch #180: loss=0.01987400908047177
Epoch #181: loss=0.014856029892017553
Epoch #182: loss=0.01494632700906014
Epoch #183: loss=0.01177629775169379
Epoch #184: loss=0.013613882974507984
Epoch #185: loss=0.009329518942196257
Epoch #186: loss=0.012311218743457978
Epoch #187: loss=0.010507693677730651
Epoch #188: loss=0.01314826739736069
Epoch #189: loss=0.014327391272953679
Epoch #190: loss=0.010397283440845981
Epoch #191: loss=0.0132233805366712
Epoch #192: loss=0.01635177647455323
Epoch #193: loss=0.011087992753871413
Epoch #194: loss=0.010660476922209665
Epoch #195: loss=0.011103895667528525
Epoch #196: loss=0.013425226222327986
Epoch #197: loss=0.012446754148411994
Epoch #198: loss=0.01911155352414783
Epoch #199: loss=0.01230946329771254
Epoch #200: loss=0.011697792039047536
Epoch #201: loss=0.015604018015742668
Epoch #202: loss=0.009109436704327244
Epoch #203: loss=0.011599693311344257
Epoch #204: loss=0.013411113741865896
Epoch #205: loss=0.01210837542762528
Epoch #206: loss=0.011011640157381451
Epoch #207: loss=0.020386807475604066
Epoch #208: loss=0.018071962789744395
Epoch #209: loss=0.010363702400414454
Epoch #210: loss=0.01226193533434148
Epoch #211: loss=0.010815710100041506
Epoch #212: loss=0.013747570938923842
Epoch #213: loss=0.008448226452758134
Epoch #214: loss=0.010341437973869615
Epoch #215: loss=0.014280510245049075
Epoch #216: loss=0.009969263200068634
Epoch #217: loss=0.00983858713402491
Epoch #218: loss=0.015296937615133135
Epoch #219: loss=0.017931666858532067
Epoch #220: loss=0.010283083418958762
Epoch #221: loss=0.011310763827782112
Epoch #222: loss=0.018439409304120375
Epoch #223: loss=0.013157666080598122
Epoch #224: loss=0.01189164817591497
Epoch #225: loss=0.015920685037323707
Epoch #226: loss=0.015621104207864236
Epoch #227: loss=0.009175801763103739
Epoch #228: loss=0.008602036992287407
Epoch #229: loss=0.013583992574602709
Epoch #230: loss=0.02008456908551526
Epoch #231: loss=0.015603913205047119
Epoch #232: loss=0.014976492472465614
Epoch #233: loss=0.007488538564719505
Epoch #234: loss=0.012012848874020076
Epoch #235: loss=0.011083086663848492
Epoch #236: loss=0.013218734332626447
Epoch #237: loss=0.012070597170823141
Epoch #238: loss=0.010620123420275412
Epoch #239: loss=0.02049031995475034
Epoch #240: loss=0.011258588956445421
Epoch #241: loss=0.009936446494679885
Epoch #242: loss=0.009835107942039952
Epoch #243: loss=0.011785170884489467
Epoch #244: loss=0.010931770467642184
Epoch #245: loss=0.01164108825613241
Epoch #246: loss=0.010614860386096669
Epoch #247: loss=0.011847449798924594
Epoch #248: loss=0.030606741823910124
Epoch #249: loss=0.016111223661917973

Training time: 5:11:48.868802

Finished.
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_ettm1_ettm2', random_seed=2023, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_ettm1_ettm2_epochs_250_seed_2023
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=4.0313660105069475
Epoch #1: loss=2.3277828759617276
Epoch #2: loss=1.9886894192960527
Epoch #3: loss=1.7472971611552768
Epoch #4: loss=1.5909967753622267
Epoch #5: loss=1.4358750184377034
Epoch #6: loss=1.2524838811821408
Epoch #7: loss=1.2060217046075397
Epoch #8: loss=1.1613520996438131
Epoch #9: loss=1.0546389751964145
Epoch #10: loss=0.9859717852539487
Epoch #11: loss=0.934832470284568
Epoch #12: loss=0.9534182813432481
Epoch #13: loss=0.8730485323402617
Epoch #14: loss=0.8156014978885651
Epoch #15: loss=0.7468977967898051
Epoch #16: loss=0.7683417267269559
Epoch #17: loss=0.6795307902826203
Epoch #18: loss=0.7056914683845308
Epoch #19: loss=0.640130452811718
Epoch #20: loss=0.7087431591418054
Epoch #21: loss=0.67395647863547
Epoch #22: loss=0.5831627580854628
Epoch #23: loss=0.5627428731984563
Epoch #24: loss=0.5929405002130402
Epoch #25: loss=0.5170226883557107
Epoch #26: loss=0.5568309823671976
Epoch #27: loss=0.4824769472082456
Epoch #28: loss=0.5765907218058904
Epoch #29: loss=0.5535423987441592
Epoch #30: loss=0.5265697778926955
Epoch #31: loss=0.5791506990790367
Epoch #32: loss=0.7017830395036273
Epoch #33: loss=0.5617601937717862
Epoch #34: loss=0.44827284001641804
Epoch #35: loss=0.43705594456858105
Epoch #36: loss=0.49269848979181713
Epoch #37: loss=0.41742002136177486
Epoch #38: loss=0.42424167030387455
Epoch #39: loss=0.41959941304392284
Epoch #40: loss=0.38402339071035385
Epoch #41: loss=0.36314276191923356
Epoch #42: loss=0.35195479542016983
Epoch #43: loss=0.3792532744506995
Epoch #44: loss=0.33082329854369164
Epoch #45: loss=0.3401759953962432
Epoch #46: loss=0.2823399549557103
Epoch #47: loss=0.4155125489665402
Epoch #48: loss=0.3576987758278847
Epoch #49: loss=0.3816960963110129
Epoch #50: loss=0.35455290724833805
Epoch #51: loss=0.38581040874123573
Epoch #52: loss=0.4152590048809846
Epoch #53: loss=0.37381019898586804
Epoch #54: loss=0.2971192043688562
Epoch #55: loss=0.2673790541787942
Epoch #56: loss=0.27450819354918266
Epoch #57: loss=0.28384396847751403
Epoch #58: loss=0.2828454085522228
Epoch #59: loss=0.2269348953333166
Epoch #60: loss=0.2665047273039818
Epoch #61: loss=0.30649652311371434
Epoch #62: loss=0.35341953734556836
Epoch #63: loss=0.3002743410567443
Epoch #64: loss=0.23947788630094793
Epoch #65: loss=0.19293628674414423
Epoch #66: loss=0.22257930330104297
Epoch #67: loss=0.18032577882210413
Epoch #68: loss=0.19932522479858664
Epoch #69: loss=0.21301621198654175
Epoch #70: loss=0.2698916797008779
Epoch #71: loss=0.2700421352767282
Epoch #72: loss=0.38592085656192565
Epoch #73: loss=0.24809270227948824
Epoch #74: loss=0.1972942352294922
Epoch #75: loss=0.24003995437588957
Epoch #76: loss=0.19181371542314687
Epoch #77: loss=0.16690691581202877
Epoch #78: loss=0.18927960822151768
Epoch #79: loss=0.19616897714634737
Epoch #80: loss=0.18053206232272917
Epoch #81: loss=0.2288995941893922
Epoch #82: loss=0.19509095139801502
Epoch #83: loss=0.17212306801229715
Epoch #84: loss=0.1785477978280849
Epoch #85: loss=0.18040305107004112
Epoch #86: loss=0.17483364842418167
Epoch #87: loss=0.19348210986289713
Epoch #88: loss=0.17957177447776
Epoch #89: loss=0.21295999311324623
Epoch #90: loss=0.18972782894141144
Epoch #91: loss=0.17311994710730183
Epoch #92: loss=0.14592095298899543
Epoch #93: loss=0.15230624388075537
Epoch #94: loss=0.14488416930867565
Epoch #95: loss=0.11750125724615322
Epoch #96: loss=0.11416525828341643
Epoch #97: loss=0.12023730338033703
Epoch #98: loss=0.1383097010354201
Epoch #99: loss=0.14169137759341133
Epoch #100: loss=0.143880982676314
Epoch #101: loss=0.13707135498730671
Epoch #102: loss=0.1410654310343994
Epoch #103: loss=0.14945168948421875
Epoch #104: loss=0.12370117981400755
Epoch #105: loss=0.17840667151742512
Epoch #106: loss=0.12175762084209257
Epoch #107: loss=0.11171932114909093
Epoch #108: loss=0.14877076923019356
Epoch #109: loss=0.12101396669944127
Epoch #110: loss=0.16314460192289618
Epoch #111: loss=0.13917259385602343
Epoch #112: loss=0.12381991630213128
Epoch #113: loss=0.12696747331776553
Epoch #114: loss=0.10772066878982717
Epoch #115: loss=0.12592030777078536
Epoch #116: loss=0.12121781287714839
Epoch #117: loss=0.13266255246061417
Epoch #118: loss=0.13257576742519936
Epoch #119: loss=0.12737603035445014
Epoch #120: loss=0.09956106222752067
Epoch #121: loss=0.11894158977601263
Epoch #122: loss=0.13705808120883173
Epoch #123: loss=0.11717059737485316
Epoch #124: loss=0.10684784662185444
Epoch #125: loss=0.09511634893715382
Epoch #126: loss=0.08595970086753368
Epoch #127: loss=0.12415571267613107
Epoch #128: loss=0.15146952443238762
Epoch #129: loss=0.12742890645232466
Epoch #130: loss=0.10870268413176139
Epoch #131: loss=0.0981971249760439
Epoch #132: loss=0.0825969834242844
Epoch #133: loss=0.08328740971369876
Epoch #134: loss=0.1119247719955941
Epoch #135: loss=0.15904433880415228
Epoch #136: loss=0.11687797613234983
Epoch #137: loss=0.10102159002174933
Epoch #138: loss=0.12020921717501348
Epoch #139: loss=0.10463254655607873
Epoch #140: loss=0.11309256782341334
Epoch #141: loss=0.08275038034965594
Epoch #142: loss=0.10986828923018442
Epoch #143: loss=0.13179232004202074
Epoch #144: loss=0.1015766497908367
Epoch #145: loss=0.11043964455732042
Epoch #146: loss=0.07936997421913677
Epoch #147: loss=0.08044899177427094
Epoch #148: loss=0.07061247980325586
Epoch #149: loss=0.06779853477039272
Epoch #150: loss=0.09645907601548566
Epoch #151: loss=0.10905456667145093
Epoch #152: loss=0.10001380640702943
Epoch #153: loss=0.12392457641868128
Epoch #154: loss=0.11593290785741475
Epoch #155: loss=0.10188036652592321
Epoch #156: loss=0.08591840126448208
Epoch #157: loss=0.09511076612398028
Epoch #158: loss=0.128514195430196
Epoch #159: loss=0.10300319181341264
Epoch #160: loss=0.14996795118268993
Epoch #161: loss=0.09552068935914172
Epoch #162: loss=0.07454532330545287
Epoch #163: loss=0.06871891922007005
Epoch #164: loss=0.06680008644858997
Epoch #165: loss=0.06880332470043665
Epoch #166: loss=0.09154950643682645
Epoch #167: loss=0.05866905588967105
Epoch #168: loss=0.0817959799638225
Epoch #169: loss=0.079584248105271
Epoch #170: loss=0.07032751566213039
Epoch #171: loss=0.0773435561503801
Epoch #172: loss=0.08222740565219687
Epoch #173: loss=0.21359414824595055
Epoch #174: loss=0.13321024583031735
Epoch #175: loss=0.11204985229091512
Epoch #176: loss=0.08696956927370694
Epoch #177: loss=0.07036311495014363
Epoch #178: loss=0.08142221059339742
Epoch #179: loss=0.09085189481265843
Epoch #180: loss=0.07801429466861817
Epoch #181: loss=0.07983795527575745
Epoch #182: loss=0.12929412872634
Epoch #183: loss=0.10916506426615848
Epoch #184: loss=0.09697010078363949
Epoch #185: loss=0.0784840554309388
Epoch #186: loss=0.07187059074122873
Epoch #187: loss=0.06123242459984289
Epoch #188: loss=0.05793093364789254
Epoch #189: loss=0.05947040823391742
Epoch #190: loss=0.09654509454655151
Epoch #191: loss=0.05907472129911184
Epoch #192: loss=0.0663013923395839
Epoch #193: loss=0.0859641982242465
Epoch #194: loss=0.05695655240884258
Epoch #195: loss=0.08095437874241422
Epoch #196: loss=0.08468312581276728
Epoch #197: loss=0.04818535588371257
Epoch #198: loss=0.05222787824459374
Epoch #199: loss=0.07593503520668794
Epoch #200: loss=0.0706420134132107
Epoch #201: loss=0.061033699894323945
Epoch #202: loss=0.05437878084679445
Epoch #203: loss=0.07269940719318886
Epoch #204: loss=0.051658945416824684
Epoch #205: loss=0.04964232955697096
Epoch #206: loss=0.08507038660657902
Epoch #207: loss=0.08255189802083704
Epoch #208: loss=0.08849582492580844
Epoch #209: loss=0.12260339357372788
Epoch #210: loss=0.09451783257019189
Epoch #211: loss=0.11188847625938554
Epoch #212: loss=0.09939868458443218
Epoch #213: loss=0.0613501308641086
Epoch #214: loss=0.09338358942315811
Epoch #215: loss=0.045679144742381245
Epoch #216: loss=0.13469816961636147
Epoch #217: loss=0.09740446047443482
Epoch #218: loss=0.09624766607561873
Epoch #219: loss=0.07553111187492807
Epoch #220: loss=0.06798594602797595
Epoch #221: loss=0.045178354122779436
Epoch #222: loss=0.07918999226401663
Epoch #223: loss=0.060977981684522495
Epoch #224: loss=0.0655840943670935
Epoch #225: loss=0.0523407815489918
Epoch #226: loss=0.051347308843914
Epoch #227: loss=0.064749718307414
Epoch #228: loss=0.07621304487757799
Epoch #229: loss=0.08021270485025728
Epoch #230: loss=0.0940657392816825
Epoch #231: loss=0.05505859939795402
Epoch #232: loss=0.06952274417401189
Epoch #233: loss=0.06310564033790594
Epoch #234: loss=0.05556398949637595
Epoch #235: loss=0.04053518729698327
Epoch #236: loss=0.054330677854725055
Epoch #237: loss=0.06440695279484822
Epoch #238: loss=0.07448810758069158
Epoch #239: loss=0.05501896142959595
Epoch #240: loss=0.10480383589553337
Epoch #241: loss=0.059913318862931594
Epoch #242: loss=0.0526948282495141
Epoch #243: loss=0.05011133343860921
Epoch #244: loss=0.04252199554401967
Epoch #245: loss=0.056543265534047454
Epoch #246: loss=0.061533698346465826
Epoch #247: loss=0.07164288596767518
Epoch #248: loss=0.058197995026906334
Epoch #249: loss=0.06005534255463216

Training time: 0:11:27.079785

Finished.
n2one setting etth1_etth2_ettm1_ettm2 -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm1_ettm2_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_etth2_ettm1_ettm2', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.66027e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.18167e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.66027e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.37282929302674905, 'MAE': 0.4332601833837172}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_ettm1_ettm2 -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm1_ettm2_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_etth2_ettm1_ettm2', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.63662e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.13838e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.63662e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.8254173240684145, 'MAE': 0.7403768152197342}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_ettm1_ettm2 -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm1_ettm2_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_etth2_ettm1_ettm2', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.39468e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.2465496406779002, 'MAE': 0.3396274004770684}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_ettm1_electricity', random_seed=2023, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_ettm1_electricity_epochs_250_seed_2023
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.620610068815981
Epoch #1: loss=0.6655102304985069
Epoch #2: loss=0.4775235985831029
Epoch #3: loss=0.3682793350405776
Epoch #4: loss=0.3379477644070035
Epoch #5: loss=0.28397610568242265
Epoch #6: loss=0.24288282360386299
Epoch #7: loss=0.2083103242034168
Epoch #8: loss=0.18101811908573084
Epoch #9: loss=0.1644487266961722
Epoch #10: loss=0.1582942068081543
Epoch #11: loss=0.15555369242422842
Epoch #12: loss=0.13043238273202684
Epoch #13: loss=0.1059462095723848
Epoch #14: loss=0.10705977148037253
Epoch #15: loss=0.09583549228405332
Epoch #16: loss=0.09279477769358224
Epoch #17: loss=0.09300228729682593
Epoch #18: loss=0.10475323543577009
Epoch #19: loss=0.07442096885390623
Epoch #20: loss=0.08063650154643234
Epoch #21: loss=0.06982963459264767
Epoch #22: loss=0.0672690854959642
Epoch #23: loss=0.06309079692289879
Epoch #24: loss=0.06181899396126627
Epoch #25: loss=0.05304962316409528
Epoch #26: loss=0.05677228499166237
Epoch #27: loss=0.04656836273676226
Epoch #28: loss=0.045802556425117685
Epoch #29: loss=0.04967887025337257
Epoch #30: loss=0.041707293643896075
Epoch #31: loss=0.041614847678308926
Epoch #32: loss=0.04253504190976177
Epoch #33: loss=0.03576629343536828
Epoch #34: loss=0.04952202147381606
Epoch #35: loss=0.06071748027734114
Epoch #36: loss=0.039536707176600794
Epoch #37: loss=0.034482480274416465
Epoch #38: loss=0.04139257545819818
Epoch #39: loss=0.042609367571431994
Epoch #40: loss=0.025270639343060702
Epoch #41: loss=0.03468792257370223
Epoch #42: loss=0.04373776568220982
Epoch #43: loss=0.03626975893834337
Epoch #44: loss=0.026065832014044887
Epoch #45: loss=0.025357417470231826
Epoch #46: loss=0.05071238044250993
Epoch #47: loss=0.027877859773943362
Epoch #48: loss=0.028629366990119608
Epoch #49: loss=0.030889429522454846
Epoch #50: loss=0.03150016736276878
Epoch #51: loss=0.018411981428413507
Epoch #52: loss=0.020546718627400158
Epoch #53: loss=0.02302494098875144
Epoch #54: loss=0.04141781867933971
Epoch #55: loss=0.030974034528178027
Epoch #56: loss=0.03432468766672268
Epoch #57: loss=0.023798409289871533
Epoch #58: loss=0.03203421093508698
Epoch #59: loss=0.02409806623556947
Epoch #60: loss=0.024083877945954055
Epoch #61: loss=0.025091579886465577
Epoch #62: loss=0.034212554583253306
Epoch #63: loss=0.02055412184344766
Epoch #64: loss=0.022784319133941904
Epoch #65: loss=0.029617731194644413
Epoch #66: loss=0.04992794065004096
Epoch #67: loss=0.027476285814073454
Epoch #68: loss=0.016477215879851133
Epoch #69: loss=0.024080510198904437
Epoch #70: loss=0.030603297080002145
Epoch #71: loss=0.028442993698200223
Epoch #72: loss=0.021447101873386047
Epoch #73: loss=0.021590402178907755
Epoch #74: loss=0.03377680641106422
Epoch #75: loss=0.022670959032307557
Epoch #76: loss=0.021473447151611307
Epoch #77: loss=0.016559075403990858
Epoch #78: loss=0.021521096727797343
Epoch #79: loss=0.040284976509878834
Epoch #80: loss=0.020668168897091846
Epoch #81: loss=0.01657586114587413
Epoch #82: loss=0.015338016815572396
Epoch #83: loss=0.01578407392687719
Epoch #84: loss=0.029838213970281743
Epoch #85: loss=0.018281323743736467
Epoch #86: loss=0.014765524839702455
Epoch #87: loss=0.022406633167946173
Epoch #88: loss=0.020210910261463308
Epoch #89: loss=0.015099930962732041
Epoch #90: loss=0.02280798923265259
Epoch #91: loss=0.017828295211411334
Epoch #92: loss=0.03039566749562859
Epoch #93: loss=0.017414813902130823
Epoch #94: loss=0.01883422052171458
Epoch #95: loss=0.025652657934556032
Epoch #96: loss=0.016546695763675894
Epoch #97: loss=0.01593558559671308
Epoch #98: loss=0.01799059208065966
Epoch #99: loss=0.02369723517267367
Epoch #100: loss=0.01627635542283809
Epoch #101: loss=0.012245065131563844
Epoch #102: loss=0.021338052767048983
Epoch #103: loss=0.019430441444913314
Epoch #104: loss=0.013603491523919486
Epoch #105: loss=0.017992858434966737
Epoch #106: loss=0.01885094182687607
Epoch #107: loss=0.008995671023502327
Epoch #108: loss=0.021982397279174556
Epoch #109: loss=0.01986321889744221
Epoch #110: loss=0.016215861707352466
Epoch #111: loss=0.013567916996106828
Epoch #112: loss=0.025094793769302157
Epoch #113: loss=0.01486964336526782
Epoch #114: loss=0.013697260814265354
Epoch #115: loss=0.016262459330044745
Epoch #116: loss=0.015326218958304808
Epoch #117: loss=0.01514655142806193
Epoch #118: loss=0.02182378482027787
Epoch #119: loss=0.009963632356277882
Epoch #120: loss=0.013631682474125106
Epoch #121: loss=0.01632031312025949
Epoch #122: loss=0.014948690541268924
Epoch #123: loss=0.020670737403329205
Epoch #124: loss=0.011813404193152055
Epoch #125: loss=0.015947636106856317
Epoch #126: loss=0.014924613471247924
Epoch #127: loss=0.017455718051904618
Epoch #128: loss=0.01871156835988449
Epoch #129: loss=0.015360587174402593
Epoch #130: loss=0.01587669573494804
Epoch #131: loss=0.017638922303597405
Epoch #132: loss=0.014612092523979605
Epoch #133: loss=0.009985646430296672
Epoch #134: loss=0.01806654936531047
Epoch #135: loss=0.013136729126327773
Epoch #136: loss=0.02302568838874422
Epoch #137: loss=0.011010475165676326
Epoch #138: loss=0.013183262299933347
Epoch #139: loss=0.02662710275783976
Epoch #140: loss=0.012402121409403047
Epoch #141: loss=0.014040894099986288
Epoch #142: loss=0.014328452709872501
Epoch #143: loss=0.014174519491992955
Epoch #144: loss=0.014388593234393659
Epoch #145: loss=0.01453262910894872
Epoch #146: loss=0.01338286160049298
Epoch #147: loss=0.007936684613676628
Epoch #148: loss=0.02056411402337011
Epoch #149: loss=0.013402021155511621
Epoch #150: loss=0.010543917916947976
Epoch #151: loss=0.015214174605601177
Epoch #152: loss=0.02340979185281725
Epoch #153: loss=0.019212754030619086
Epoch #154: loss=0.016695076150037725
Epoch #155: loss=0.011305133611599058
Epoch #156: loss=0.011532286939166103
Epoch #157: loss=0.01139522312515862
Epoch #158: loss=0.011068862249517565
Epoch #159: loss=0.016459133295844326
Epoch #160: loss=0.015214510566845665
Epoch #161: loss=0.01203533626291726
Epoch #162: loss=0.03886828534379117
Epoch #163: loss=0.017777287869780146
Epoch #164: loss=0.013433789796948923
Epoch #165: loss=0.010015360876948794
Epoch #166: loss=0.013145815472743027
Epoch #167: loss=0.00814971189757182
Epoch #168: loss=0.011348683250269912
Epoch #169: loss=0.015062733420616318
Epoch #170: loss=0.01483874545349185
Epoch #171: loss=0.009590536503510206
Epoch #172: loss=0.014063500826155519
Epoch #173: loss=0.009985152053454288
Epoch #174: loss=0.015510423507367636
Epoch #175: loss=0.01845470574436133
Epoch #176: loss=0.018532764436603077
Epoch #177: loss=0.016225721671264834
Epoch #178: loss=0.010877749912919897
Epoch #179: loss=0.009810429980246232
Epoch #180: loss=0.01533810383467962
Epoch #181: loss=0.022388973270140514
Epoch #182: loss=0.010881675180179642
Epoch #183: loss=0.012870254815688001
Epoch #184: loss=0.020786498541704168
Epoch #185: loss=0.015104235966677771
Epoch #186: loss=0.010167220479376732
Epoch #187: loss=0.01091855162536965
Epoch #188: loss=0.014976167655537326
Epoch #189: loss=0.012332010244653894
Epoch #190: loss=0.010281178771216702
Epoch #191: loss=0.008024558384574389
Epoch #192: loss=0.016799450758945553
Epoch #193: loss=0.010683056901275002
Epoch #194: loss=0.008928263362855758
Epoch #195: loss=0.00903484105888547
Epoch #196: loss=0.01212484460864741
Epoch #197: loss=0.012658722581095573
Epoch #198: loss=0.014243570211659068
Epoch #199: loss=0.02028383399683557
Epoch #200: loss=0.014717823149154577
Epoch #201: loss=0.01166795981962791
Epoch #202: loss=0.008385219954417189
Epoch #203: loss=0.011085356398104727
Epoch #204: loss=0.012201420232102496
Epoch #205: loss=0.011760303007813595
Epoch #206: loss=0.009675137924247105
Epoch #207: loss=0.012833947777688218
Epoch #208: loss=0.011021407056216964
Epoch #209: loss=0.013505355580312852
Epoch #210: loss=0.010669967159124178
Epoch #211: loss=0.018645592915389492
Epoch #212: loss=0.01022116124284766
Epoch #213: loss=0.012612895590570793
Epoch #214: loss=0.018289860540101267
Epoch #215: loss=0.011645490656077936
Epoch #216: loss=0.006773444040893103
Epoch #217: loss=0.005864769169798988
Epoch #218: loss=0.013380919358806786
Epoch #219: loss=0.01111429748835306
Epoch #220: loss=0.012685977894378116
Epoch #221: loss=0.019263889659243243
Epoch #222: loss=0.012336896833724133
Epoch #223: loss=0.007644696656252511
Epoch #224: loss=0.012095123811219846
Epoch #225: loss=0.01621961382103645
Epoch #226: loss=0.017076509921257033
Epoch #227: loss=0.014666568554670016
Epoch #228: loss=0.01293143817945148
Epoch #229: loss=0.013064123393706654
Epoch #230: loss=0.01265036099811752
Epoch #231: loss=0.010665536056356128
Epoch #232: loss=0.01308073021382002
Epoch #233: loss=0.009674640436238889
Epoch #234: loss=0.010156388064130408
Epoch #235: loss=0.018408426609343845
Epoch #236: loss=0.00997826186551462
Epoch #237: loss=0.01310787535017838
Epoch #238: loss=0.009780820370638323
Epoch #239: loss=0.009871099473236632
Epoch #240: loss=0.010496831556070176
Epoch #241: loss=0.009891014923748689
Epoch #242: loss=0.015769795564102882
Epoch #243: loss=0.011124819625139431
Epoch #244: loss=0.00926836848239121
Epoch #245: loss=0.01785667898584927
Epoch #246: loss=0.015820217421958008
Epoch #247: loss=0.010014316322641296
Epoch #248: loss=0.010289745854322846
Epoch #249: loss=0.011804822576888353

Training time: 1:35:43.773989

Finished.
n2one setting etth1_etth2_ettm1_electricity -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm1_electricity_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_etth2_ettm1_electricity', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=6.29506e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.46872e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.68389e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.9447138990881639, 'MAE': 0.8044417347944767}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_ettm1_electricity -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm1_electricity_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_etth2_ettm1_electricity', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.59369e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.2746350038880666, 'MAE': 0.35970471796377207}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_ettm1_traffic', random_seed=2023, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_ettm1_traffic_epochs_250_seed_2023
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.9657610336312312
Epoch #1: loss=0.3598971388553686
Epoch #2: loss=0.2676968298172064
Epoch #3: loss=0.21156922417872384
Epoch #4: loss=0.1657023656285938
Epoch #5: loss=0.12129525921760041
Epoch #6: loss=0.10339053413119868
Epoch #7: loss=0.10299451117694647
Epoch #8: loss=0.09161775260785723
Epoch #9: loss=0.06777740576700333
Epoch #10: loss=0.06637573954434026
Epoch #11: loss=0.07211903298720969
Epoch #12: loss=0.06313556054787628
Epoch #13: loss=0.050727148208527785
Epoch #14: loss=0.05093795987945407
Epoch #15: loss=0.04882005282615762
Epoch #16: loss=0.044702491726413406
Epoch #17: loss=0.04477618338451999
Epoch #18: loss=0.04866355388890427
Epoch #19: loss=0.03911588662865718
Epoch #20: loss=0.036715858849290475
Epoch #21: loss=0.031232217381358684
Epoch #22: loss=0.03434242348629234
Epoch #23: loss=0.032779460009675694
Epoch #24: loss=0.02643151697085849
Epoch #25: loss=0.03423238939630852
Epoch #26: loss=0.03224825137636069
Epoch #27: loss=0.03049474647817262
Epoch #28: loss=0.029586155214682934
Epoch #29: loss=0.02467434355649696
Epoch #30: loss=0.024246681162802947
Epoch #31: loss=0.02887439484479118
Epoch #32: loss=0.02052612694235216
Epoch #33: loss=0.03242693489678351
Epoch #34: loss=0.03176677619748074
Epoch #35: loss=0.03398712023146652
Epoch #36: loss=0.03045384383987711
Epoch #37: loss=0.021808378414627325
Epoch #38: loss=0.030279571655612722
Epoch #39: loss=0.028228045947951596
Epoch #40: loss=0.02431546006446994
Epoch #41: loss=0.021855702096771706
Epoch #42: loss=0.02232310287868331
Epoch #43: loss=0.0165748464051485
Epoch #44: loss=0.02054797267976239
Epoch #45: loss=0.024427234407397788
Epoch #46: loss=0.018705606761846794
Epoch #47: loss=0.020395278002491395
Epoch #48: loss=0.02690825270637954
Epoch #49: loss=0.015556745784944648
Epoch #50: loss=0.019652691829357433
Epoch #51: loss=0.018891971226410967
Epoch #52: loss=0.01870739141831137
Epoch #53: loss=0.01918526053946219
Epoch #54: loss=0.02255115372328541
Epoch #55: loss=0.02603843931748932
Epoch #56: loss=0.017675338902803643
Epoch #57: loss=0.013975506075335039
Epoch #58: loss=0.02852041283627634
Epoch #59: loss=0.02063568367655867
Epoch #60: loss=0.014364102764338362
Epoch #61: loss=0.020729227698819654
Epoch #62: loss=0.01646913581576593
Epoch #63: loss=0.016454205705152703
Epoch #64: loss=0.018278989675370796
Epoch #65: loss=0.014035825228269749
Epoch #66: loss=0.01681360715883784
Epoch #67: loss=0.019871104799217325
Epoch #68: loss=0.017520666464332705
Epoch #69: loss=0.018327673850357933
Epoch #70: loss=0.02630112426579387
Epoch #71: loss=0.012044030133127671
Epoch #72: loss=0.016437317750104593
Epoch #73: loss=0.014428352499987064
Epoch #74: loss=0.01790151108474851
Epoch #75: loss=0.02143697117309227
Epoch #76: loss=0.01539226031595507
Epoch #77: loss=0.014365655766157465
Epoch #78: loss=0.019208070251008173
Epoch #79: loss=0.01819544661890667
Epoch #80: loss=0.014165309528566124
Epoch #81: loss=0.012166498066917043
Epoch #82: loss=0.019695301241742232
Epoch #83: loss=0.016427060241917025
Epoch #84: loss=0.013529571128756872
Epoch #85: loss=0.013410569623920105
Epoch #86: loss=0.01556156066083848
Epoch #87: loss=0.017741675610315966
Epoch #88: loss=0.012699903662394199
Epoch #89: loss=0.01491443864220156
Epoch #90: loss=0.013149902655520207
Epoch #91: loss=0.011805327713718951
Epoch #92: loss=0.029980383805014253
Epoch #93: loss=0.014836823565172364
Epoch #94: loss=0.01280815276911056
Epoch #95: loss=0.012532887967020429
Epoch #96: loss=0.01628450700364064
Epoch #97: loss=0.015668375938522456
Epoch #98: loss=0.011738580402771428
Epoch #99: loss=0.011914658065240362
Epoch #100: loss=0.014662944145352089
Epoch #101: loss=0.013843535669667704
Epoch #102: loss=0.01735204659574828
Epoch #103: loss=0.029153316604470143
Epoch #104: loss=0.013387662145536732
Epoch #105: loss=0.012396106580352378
Epoch #106: loss=0.01692917044863804
Epoch #107: loss=0.01285293352283698
Epoch #108: loss=0.011696311473146107
Epoch #109: loss=0.012407978232388239
Epoch #110: loss=0.01429752511198852
Epoch #111: loss=0.012666141477428176
Epoch #112: loss=0.011379989899167622
Epoch #113: loss=0.016660622859900248
Epoch #114: loss=0.011843759728175102
Epoch #115: loss=0.023480951800839263
Epoch #116: loss=0.014752864613543708
Epoch #117: loss=0.017547825949380473
Epoch #118: loss=0.019315250391914146
Epoch #119: loss=0.01060493428751211
Epoch #120: loss=0.014254836070408
Epoch #121: loss=0.010186845078931679
Epoch #122: loss=0.013339417226197305
Epoch #123: loss=0.01338651932102944
Epoch #124: loss=0.014791424543075232
Epoch #125: loss=0.012091317056330302
Epoch #126: loss=0.01427644411683489
Epoch #127: loss=0.00941820998584417
Epoch #128: loss=0.013622962007351039
Epoch #129: loss=0.010060857848556693
Epoch #130: loss=0.015638727840859592
Epoch #131: loss=0.010659304162110186
Epoch #132: loss=0.015353285907454035
Epoch #133: loss=0.0124050197813315
Epoch #134: loss=0.013019741226620017
Epoch #135: loss=0.010080163861972568
Epoch #136: loss=0.012012989375178687
Epoch #137: loss=0.012464150206045837
Epoch #138: loss=0.012546072363669185
Epoch #139: loss=0.011035228285246768
Epoch #140: loss=0.013843213462899727
Epoch #141: loss=0.009342717857654847
Epoch #142: loss=0.009889963397377508
Epoch #143: loss=0.012898842576159355
Epoch #144: loss=0.013618233382446995
Epoch #145: loss=0.01699623925495027
Epoch #146: loss=0.014481043218095076
Epoch #147: loss=0.011130254336379746
Epoch #148: loss=0.009301669970721746
Epoch #149: loss=0.014713360724518293
Epoch #150: loss=0.014695565470696711
Epoch #151: loss=0.010924356878659527
Epoch #152: loss=0.00982769976489208
Epoch #153: loss=0.01104579497560656
Epoch #154: loss=0.014250467548625498
Epoch #155: loss=0.01116921693801128
Epoch #156: loss=0.008723166749330871
Epoch #157: loss=0.013084859122772068
Epoch #158: loss=0.012755318355072355
Epoch #159: loss=0.010300024942938016
Epoch #160: loss=0.010741831208676365
Epoch #161: loss=0.011753862854708202
Epoch #162: loss=0.0135240188680102
Epoch #163: loss=0.01652577090002423
Epoch #164: loss=0.010157903266956205
Epoch #165: loss=0.007971584393028348
Epoch #166: loss=0.01032607143890772
Epoch #167: loss=0.011620758663963478
Epoch #168: loss=0.009850291550007077
Epoch #169: loss=0.016228847832273557
Epoch #170: loss=0.007126188094630836
Epoch #171: loss=0.01236637299458429
Epoch #172: loss=0.010078390655470035
Epoch #173: loss=0.009450557361425293
Epoch #174: loss=0.011917146522115512
Epoch #175: loss=0.012031017126951376
Epoch #176: loss=0.014192386333125993
Epoch #177: loss=0.009768478800109377
Epoch #178: loss=0.008410500638476854
Epoch #179: loss=0.009836263568775797
Epoch #180: loss=0.011946925368293749
Epoch #181: loss=0.01164736943584229
Epoch #182: loss=0.011591347819332007
Epoch #183: loss=0.007575489682954024
Epoch #184: loss=0.007725410028578556
Epoch #185: loss=0.016267436601568312
Epoch #186: loss=0.011896676886191523
Epoch #187: loss=0.008183309761633421
Epoch #188: loss=0.008205423777090527
Epoch #189: loss=0.012426044208350934
Epoch #190: loss=0.010575521968264686
Epoch #191: loss=0.013100963927899396
Epoch #192: loss=0.010725031916339597
Epoch #193: loss=0.010535532735280793
Epoch #194: loss=0.009282448667293773
Epoch #195: loss=0.008126900830002146
Epoch #196: loss=0.015941613370982096
Epoch #197: loss=0.012274940311803725
Epoch #198: loss=0.011758086991305027
Epoch #199: loss=0.02160112076819446
Epoch #200: loss=0.008795390102716705
Epoch #201: loss=0.00676625463837098
Epoch #202: loss=0.006818989184312969
Epoch #203: loss=0.0099926794086379
Epoch #204: loss=0.013402807921308471
Epoch #205: loss=0.010984902714242373
Epoch #206: loss=0.015322963286242674
Epoch #207: loss=0.007798549061414829
Epoch #208: loss=0.009868005233633846
Epoch #209: loss=0.008301088990203749
Epoch #210: loss=0.012402731718962987
Epoch #211: loss=0.010885853790623288
Epoch #212: loss=0.009372431419372362
Epoch #213: loss=0.010417649474516854
Epoch #214: loss=0.008770394964825326
Epoch #215: loss=0.007179574001811601
Epoch #216: loss=0.013237388084144904
Epoch #217: loss=0.01138080428217618
Epoch #218: loss=0.008840924262613443
Epoch #219: loss=0.0073634017198312435
Epoch #220: loss=0.012963622822163439
Epoch #221: loss=0.00847572027709219
Epoch #222: loss=0.011079364517101757
Epoch #223: loss=0.012864371795491936
Epoch #224: loss=0.010204822954170778
Epoch #225: loss=0.009703386632272534
Epoch #226: loss=0.009470929907430242
Epoch #227: loss=0.02321522003706448
Epoch #228: loss=0.01117949906449577
Epoch #229: loss=0.00926158748127233
Epoch #230: loss=0.006894848388073737
Epoch #231: loss=0.011829364333630635
Epoch #232: loss=0.008108652120431097
Epoch #233: loss=0.010512453490486809
Epoch #234: loss=0.012750421609004262
Epoch #235: loss=0.009679963226423097
Epoch #236: loss=0.00809229433323517
Epoch #237: loss=0.008151417560263809
Epoch #238: loss=0.010769306198703523
Epoch #239: loss=0.010278724848710197
Epoch #240: loss=0.009802334991206542
Epoch #241: loss=0.01138808319350104
Epoch #242: loss=0.010909470754876768
Epoch #243: loss=0.009264753334042251
Epoch #244: loss=0.010406932080513798
Epoch #245: loss=0.010390867398429154
Epoch #246: loss=0.00962202882715682
Epoch #247: loss=0.013356914324777803
Epoch #248: loss=0.014362362749901367
Epoch #249: loss=0.009865967492622049

Training time: 3:27:33.039917

Finished.
n2one setting etth1_etth2_ettm1_traffic -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm1_traffic_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_etth2_ettm1_traffic', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.7414e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.5818e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.94937e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.7414e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.39440584621560915, 'MAE': 0.4456230128139936}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_ettm1_traffic -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm1_traffic_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_etth2_ettm1_traffic', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.72919e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.29503e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.35874e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.5210615335541766, 'MAE': 0.5475752963110594}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_ettm1_traffic -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm1_traffic_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_etth2_ettm1_traffic', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.33295e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.18670040965692689, 'MAE': 0.3032820579900872}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_ettm1_weather', random_seed=2023, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_ettm1_weather_epochs_250_seed_2023
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=3.891418929193534
Epoch #1: loss=2.5959870932148954
Epoch #2: loss=2.2264397494933186
Epoch #3: loss=1.8926724592844646
Epoch #4: loss=1.6719301378025728
Epoch #5: loss=1.52016192557765
Epoch #6: loss=1.5568073006237255
Epoch #7: loss=1.3240949453092088
Epoch #8: loss=1.2316682736078899
Epoch #9: loss=1.1938702861467998
Epoch #10: loss=1.099740300692764
Epoch #11: loss=1.028259092686223
Epoch #12: loss=0.9642967383066813
Epoch #13: loss=0.8992649831023871
Epoch #14: loss=0.9036745452413372
Epoch #15: loss=0.8775070134331199
Epoch #16: loss=0.7968299762875426
Epoch #17: loss=0.8241241176923116
Epoch #18: loss=0.819059384804146
Epoch #19: loss=0.7554213533214494
Epoch #20: loss=0.7279927134513855
Epoch #21: loss=0.6789941682535059
Epoch #22: loss=0.7500322700715533
Epoch #23: loss=0.6826161426656386
Epoch #24: loss=0.6141565231715932
Epoch #25: loss=0.6353945691211551
Epoch #26: loss=0.6084904115574032
Epoch #27: loss=0.6049378467541114
Epoch #28: loss=0.5340780633337358
Epoch #29: loss=0.5429432631707659
Epoch #30: loss=0.5589571682845845
Epoch #31: loss=0.5086736229120516
Epoch #32: loss=0.49654234156889077
Epoch #33: loss=0.4623463983629264
Epoch #34: loss=0.4964206271311816
Epoch #35: loss=0.532465896770066
Epoch #36: loss=0.5710295000497032
Epoch #37: loss=0.4219855268796285
Epoch #38: loss=0.4590638461066227
Epoch #39: loss=0.49886256865426604
Epoch #40: loss=0.5142987458144918
Epoch #41: loss=0.45423108456181543
Epoch #42: loss=0.429551641146342
Epoch #43: loss=0.37855807910947237
Epoch #44: loss=0.40103017348869174
Epoch #45: loss=0.4622885765982609
Epoch #46: loss=0.35701801700919283
Epoch #47: loss=0.384896655293072
Epoch #48: loss=0.3378384773637734
Epoch #49: loss=0.3364081067197463
Epoch #50: loss=0.2952328902833602
Epoch #51: loss=0.37028033417813916
Epoch #52: loss=0.325185953986411
Epoch #53: loss=0.2979039225508185
Epoch #54: loss=0.29574308237608743
Epoch #55: loss=0.3669037196566077
Epoch #56: loss=0.29205893418368173
Epoch #57: loss=0.3559756655903423
Epoch #58: loss=0.4083082415893966
Epoch #59: loss=0.29913056831733853
Epoch #60: loss=0.28023825527406204
Epoch #61: loss=0.27696897732276543
Epoch #62: loss=0.3034034064587425
Epoch #63: loss=0.2585146139357604
Epoch #64: loss=0.29997889507634967
Epoch #65: loss=0.3261082081818113
Epoch #66: loss=0.2960982534523104
Epoch #67: loss=0.2285874772305582
Epoch #68: loss=0.25098852784025905
Epoch #69: loss=0.2587367697965865
Epoch #70: loss=0.29064471654447854
Epoch #71: loss=0.243971232836153
Epoch #72: loss=0.23347924372144774
Epoch #73: loss=0.22733030804232054
Epoch #74: loss=0.2160847837141916
Epoch #75: loss=0.211282671520523
Epoch #76: loss=0.21800506217222587
Epoch #77: loss=0.241673683491992
Epoch #78: loss=0.2040917335772047
Epoch #79: loss=0.18921175241178156
Epoch #80: loss=0.19016233575986882
Epoch #81: loss=0.14711435957282198
Epoch #82: loss=0.14583253071588628
Epoch #83: loss=0.15811781424517726
Epoch #84: loss=0.19809710300144026
Epoch #85: loss=0.26159749063206655
Epoch #86: loss=0.16643120837854405
Epoch #87: loss=0.17797813389231176
Epoch #88: loss=0.18847447166255876
Epoch #89: loss=0.16095550489776275
Epoch #90: loss=0.18931729470690092
Epoch #91: loss=0.21025851756042124
Epoch #92: loss=0.2085817086638189
Epoch #93: loss=0.14750031600980198
Epoch #94: loss=0.168264733663961
Epoch #95: loss=0.31388403738246246
Epoch #96: loss=0.3866925482072082
Epoch #97: loss=0.23597570253061315
Epoch #98: loss=0.18939932202007256
Epoch #99: loss=0.15067998977268443
Epoch #100: loss=0.13939629816541485
Epoch #101: loss=0.1752238112191359
Epoch #102: loss=0.14384542222993046
Epoch #103: loss=0.13529896739797265
Epoch #104: loss=0.12600094467109324
Epoch #105: loss=0.20024597491411603
Epoch #106: loss=0.13632727173321388
Epoch #107: loss=0.11959786997998462
Epoch #108: loss=0.12586174047022475
Epoch #109: loss=0.16470834357189199
Epoch #110: loss=0.17839504727253727
Epoch #111: loss=0.11186325834954486
Epoch #112: loss=0.13945995972437017
Epoch #113: loss=0.12071054695429755
Epoch #114: loss=0.16518195364259036
Epoch #115: loss=0.13496822936862124
Epoch #116: loss=0.12510623187557154
Epoch #117: loss=0.15897497286399206
Epoch #118: loss=0.1663138552331457
Epoch #119: loss=0.11336711363172998
Epoch #120: loss=0.12510708642794804
Epoch #121: loss=0.11145958739022414
Epoch #122: loss=0.08336751038829486
Epoch #123: loss=0.15914338750436025
Epoch #124: loss=0.13912932837710662
Epoch #125: loss=0.13034282274105968
Epoch #126: loss=0.09897338317743704
Epoch #127: loss=0.09817720357986058
Epoch #128: loss=0.09587153766815569
Epoch #129: loss=0.1267208570943159
Epoch #130: loss=0.1568814356829606
Epoch #131: loss=0.15071802673970952
Epoch #132: loss=0.122205830672208
Epoch #133: loss=0.10163469656425364
Epoch #134: loss=0.09322838532720126
Epoch #135: loss=0.08820655047163076
Epoch #136: loss=0.11968810564162684
Epoch #137: loss=0.09796910218017943
Epoch #138: loss=0.10268665495894704
Epoch #139: loss=0.08938484584145687
Epoch #140: loss=0.10850737287717707
Epoch #141: loss=0.10291847853245688
Epoch #142: loss=0.0871950818189219
Epoch #143: loss=0.10175758092572876
Epoch #144: loss=0.08973162968223002
Epoch #145: loss=0.10888286902770108
Epoch #146: loss=0.10863000344412
Epoch #147: loss=0.11478305706644759
Epoch #148: loss=0.10649181182916258
Epoch #149: loss=0.12783201831374683
Epoch #150: loss=0.17673547193408012
Epoch #151: loss=0.11386136254113094
Epoch #152: loss=0.09175288571300459
Epoch #153: loss=0.09953021338465166
Epoch #154: loss=0.12088192334654284
Epoch #155: loss=0.0812036318558396
Epoch #156: loss=0.08859701653686809
Epoch #157: loss=0.07500506422537215
Epoch #158: loss=0.06474856175847497
Epoch #159: loss=0.06550406865483406
Epoch #160: loss=0.06955744914126162
Epoch #161: loss=0.08759558414492537
Epoch #162: loss=0.0890571164222909
Epoch #163: loss=0.09252242188827664
Epoch #164: loss=0.061375257084328755
Epoch #165: loss=0.0825727554038167
Epoch #166: loss=0.0887073861690713
Epoch #167: loss=0.09660224176431988
Epoch #168: loss=0.1329466874765999
Epoch #169: loss=0.11666129427213295
Epoch #170: loss=0.10841284053144502
Epoch #171: loss=0.08445039869961786
Epoch #172: loss=0.09352781884737459
Epoch #173: loss=0.08308112831311483
Epoch #174: loss=0.08284157971102818
Epoch #175: loss=0.07866832564639695
Epoch #176: loss=0.08344552306202697
Epoch #177: loss=0.07607620218586103
Epoch #178: loss=0.062334603812618586
Epoch #179: loss=0.06417420371344276
Epoch #180: loss=0.0637993524581486
Epoch #181: loss=0.06865781591292106
Epoch #182: loss=0.16775875757722294
Epoch #183: loss=0.09472980773916431
Epoch #184: loss=0.13510619069212207
Epoch #185: loss=0.08373778660361673
Epoch #186: loss=0.06913085871686538
Epoch #187: loss=0.07967234937948924
Epoch #188: loss=0.07789898428189404
Epoch #189: loss=0.09030872618085613
Epoch #190: loss=0.09229528593520324
Epoch #191: loss=0.10277573537884974
Epoch #192: loss=0.09902502514202804
Epoch #193: loss=0.08959759468687516
Epoch #194: loss=0.07364263082397919
Epoch #195: loss=0.07513369712978601
Epoch #196: loss=0.10517330937014491
Epoch #197: loss=0.053951485265119406
Epoch #198: loss=0.06016487038383881
Epoch #199: loss=0.05805098868029959
Epoch #200: loss=0.08576224589099486
Epoch #201: loss=0.10262599985535238
Epoch #202: loss=0.05506451373152873
Epoch #203: loss=0.07415226894412555
Epoch #204: loss=0.05973818805068731
Epoch #205: loss=0.06178484871691348
Epoch #206: loss=0.07140042640122712
Epoch #207: loss=0.0968577880960177
Epoch #208: loss=0.13526456269855594
Epoch #209: loss=0.0828816690390893
Epoch #210: loss=0.05710046608731443
Epoch #211: loss=0.053179058921979924
Epoch #212: loss=0.07768573677715133
Epoch #213: loss=0.08524198338900711
Epoch #214: loss=0.06397365700161341
Epoch #215: loss=0.059963024641368906
Epoch #216: loss=0.06910499884728707
Epoch #217: loss=0.05314733760029662
Epoch #218: loss=0.05291044744936859
Epoch #219: loss=0.0653768779856025
Epoch #220: loss=0.05386427467615873
Epoch #221: loss=0.05769924236023251
Epoch #222: loss=0.052029184074889795
Epoch #223: loss=0.09853480752630561
Epoch #224: loss=0.14718212296857552
Epoch #225: loss=0.1285385855784019
Epoch #226: loss=0.10178089969079285
Epoch #227: loss=0.10677875600316945
Epoch #228: loss=0.1545739666211839
Epoch #229: loss=0.09154972916140276
Epoch #230: loss=0.07993329559251958
Epoch #231: loss=0.07261780567248077
Epoch #232: loss=0.05695851899537386
Epoch #233: loss=0.05490893225970806
Epoch #234: loss=0.06460845957090165
Epoch #235: loss=0.059454574770129776
Epoch #236: loss=0.14907066779685954
Epoch #237: loss=0.07589807573194597
Epoch #238: loss=0.06280164701827601
Epoch #239: loss=0.06005936223721387
Epoch #240: loss=0.06414970268915389
Epoch #241: loss=0.051706644313811674
Epoch #242: loss=0.065790450803059
Epoch #243: loss=0.04270357108108845
Epoch #244: loss=0.06338660413508906
Epoch #245: loss=0.05465362061216843
Epoch #246: loss=0.05920706250175249
Epoch #247: loss=0.06321883915613095
Epoch #248: loss=0.07808853057669658
Epoch #249: loss=0.07964315986735564

Training time: 0:16:25.997635

Finished.
n2one setting etth1_etth2_ettm1_weather -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm1_weather_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_etth2_ettm1_weather', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.64851e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.29593e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.64851e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.36716905309106873, 'MAE': 0.4293665693178772}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_ettm1_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm1_weather_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_etth2_ettm1_weather', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.21697e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.20868728403269002, 'MAE': 0.3170237659737967}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_ettm1_exchange', random_seed=2023, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_ettm1_exchange_epochs_250_seed_2023
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=3.886191071886005
Epoch #1: loss=2.2169676982995234
Epoch #2: loss=2.054696700789712
Epoch #3: loss=1.8611798033569797
Epoch #4: loss=1.7402987118923303
Epoch #5: loss=1.5928441900195498
Epoch #6: loss=1.4811912522171482
Epoch #7: loss=1.3465613199002815
Epoch #8: loss=1.2188322869214145
Epoch #9: loss=1.1724981755921335
Epoch #10: loss=1.0982816995996418
Epoch #11: loss=1.0447909795876704
Epoch #12: loss=1.0886308785640832
Epoch #13: loss=1.0622977451844648
Epoch #14: loss=1.0083367770368403
Epoch #15: loss=0.9605081243948503
Epoch #16: loss=0.9158240285786715
Epoch #17: loss=0.8907541650714297
Epoch #18: loss=0.8822259632023898
Epoch #19: loss=0.8263942545110529
Epoch #20: loss=0.8193217678503557
Epoch #21: loss=0.7805874808268114
Epoch #22: loss=0.8514758917418394
Epoch #23: loss=0.8133606161132003
Epoch #24: loss=0.8072883748646938
Epoch #25: loss=0.8159481964328072
Epoch #26: loss=0.8235040758595322
Epoch #27: loss=0.6818407105677056
Epoch #28: loss=0.6756636518420596
Epoch #29: loss=0.7052411283507491
Epoch #30: loss=0.6997062428431078
Epoch #31: loss=0.7571223333026423
Epoch #32: loss=0.6609301115527297
Epoch #33: loss=0.6946988476045204
Epoch #34: loss=0.64066789096052
Epoch #35: loss=0.5786904575246753
Epoch #36: loss=0.5571525873559894
Epoch #37: loss=0.6022254951072462
Epoch #38: loss=0.5543347732587294
Epoch #39: loss=0.5348211192723477
Epoch #40: loss=0.6178948861179929
Epoch #41: loss=0.6185753679636753
Epoch #42: loss=0.5677358417799978
Epoch #43: loss=0.5550895595189297
Epoch #44: loss=0.523281561605858
Epoch #45: loss=0.5109523616053842
Epoch #46: loss=0.49602329460057343
Epoch #47: loss=0.5746422662879481
Epoch #48: loss=0.5863815428632678
Epoch #49: loss=0.5539243519306183
Epoch #50: loss=0.49471441543463507
Epoch #51: loss=0.4707736824498032
Epoch #52: loss=0.46025966243310407
Epoch #53: loss=0.47795795130007196
Epoch #54: loss=0.4985239559953863
Epoch #55: loss=0.4425416959054542
Epoch #56: loss=0.5136335338606979
Epoch #57: loss=0.41364169482028845
Epoch #58: loss=0.40282948179678485
Epoch #59: loss=0.44513255628672516
Epoch #60: loss=0.41085793710116186
Epoch #61: loss=0.5261723128232089
Epoch #62: loss=0.5897319958065496
Epoch #63: loss=0.5544080987121119
Epoch #64: loss=0.48203827485893713
Epoch #65: loss=0.4175259412238092
Epoch #66: loss=0.37822731335957843
Epoch #67: loss=0.3920578979181521
Epoch #68: loss=0.4414115837126067
Epoch #69: loss=0.38852789998054504
Epoch #70: loss=0.3708488200650071
Epoch #71: loss=0.4511533804012067
Epoch #72: loss=0.3847180672667243
Epoch #73: loss=0.49950688761292084
Epoch #74: loss=0.4612100991335782
Epoch #75: loss=0.42188761405872577
Epoch #76: loss=0.4144251346588135
Epoch #77: loss=0.4343004217653563
Epoch #78: loss=0.3911621557040648
Epoch #79: loss=0.3451440225947987
Epoch #80: loss=0.3380127409190843
Epoch #81: loss=0.3164577845371131
Epoch #82: loss=0.315979232842272
Epoch #83: loss=0.3690237646753138
Epoch #84: loss=0.3417539835879297
Epoch #85: loss=0.33618005861838657
Epoch #86: loss=0.29374657119765424
Epoch #87: loss=0.2997896820306778
Epoch #88: loss=0.26298648051240225
Epoch #89: loss=0.29218850533167523
Epoch #90: loss=0.3178059630321734
Epoch #91: loss=0.3131384140614307
Epoch #92: loss=0.3154132720647436
Epoch #93: loss=0.3702328410564047
Epoch #94: loss=0.3092164623014855
Epoch #95: loss=0.3249181838649692
Epoch #96: loss=0.267016689434196
Epoch #97: loss=0.2581935028235118
Epoch #98: loss=0.3060822428175897
Epoch #99: loss=0.29103838245977054
Epoch #100: loss=0.3113007644812266
Epoch #101: loss=0.3538489206270738
Epoch #102: loss=0.3242814920165322
Epoch #103: loss=0.29328631903185987
Epoch #104: loss=0.2696777162226764
Epoch #105: loss=0.2844096625393087
Epoch #106: loss=0.2660674023808855
Epoch #107: loss=0.2591165478030841
Epoch #108: loss=0.28023859136032336
Epoch #109: loss=0.3098054392771287
Epoch #110: loss=0.23846658703052637
Epoch #111: loss=0.2635259732152476
Epoch #112: loss=0.25981315744645667
Epoch #113: loss=0.22565478650909482
Epoch #114: loss=0.21562289852987637
Epoch #115: loss=0.2643320887829318
Epoch #116: loss=0.253978994308096
Epoch #117: loss=0.26680101815498236
Epoch #118: loss=0.20427761655865292
Epoch #119: loss=0.273363461774407
Epoch #120: loss=0.2915321584000732
Epoch #121: loss=0.2909026069171501
Epoch #122: loss=0.25742757026896335
Epoch #123: loss=0.20653433939724258
Epoch #124: loss=0.21306486743869205
Epoch #125: loss=0.23043363428477084
Epoch #126: loss=0.18604953632210242
Epoch #127: loss=0.18653321717724655
Epoch #128: loss=0.32585497290799115
Epoch #129: loss=0.21244924854148517
Epoch #130: loss=0.25094873729077255
Epoch #131: loss=0.19847356482888712
Epoch #132: loss=0.2264612874749935
Epoch #133: loss=0.15671840535871912
Epoch #134: loss=0.18185529643387505
Epoch #135: loss=0.16796431600144415
Epoch #136: loss=0.17665606985489526
Epoch #137: loss=0.1366970631660837
Epoch #138: loss=0.19699729392022797
Epoch #139: loss=0.192780509478215
Epoch #140: loss=0.23794257573106073
Epoch #141: loss=0.1887814330332207
Epoch #142: loss=0.14543479681015015
Epoch #143: loss=0.18917960752591942
Epoch #144: loss=0.19562402096661655
Epoch #145: loss=0.15506452841289114
Epoch #146: loss=0.1609600627738418
Epoch #147: loss=0.1461823946147254
Epoch #148: loss=0.14470343314337009
Epoch #149: loss=0.16413832715514934
Epoch #150: loss=0.1872871879375342
Epoch #151: loss=0.1755635697733272
Epoch #152: loss=0.16097157877503018
Epoch #153: loss=0.22644284999731815
Epoch #154: loss=0.19819290100625067
Epoch #155: loss=0.26256366683678195
Epoch #156: loss=0.23133860009186197
Epoch #157: loss=0.18537873255484033
Epoch #158: loss=0.1946360274697795
Epoch #159: loss=0.2057052284027591
Epoch #160: loss=0.21408877047625455
Epoch #161: loss=0.2010842820234371
Epoch #162: loss=0.20303488996895877
Epoch #163: loss=0.18612943950927618
Epoch #164: loss=0.1992863088168881
Epoch #165: loss=0.17359766939824278
Epoch #166: loss=0.16866506432945078
Epoch #167: loss=0.1983062834902243
Epoch #168: loss=0.1510398525631789
Epoch #169: loss=0.21015944173841766
Epoch #170: loss=0.17132686417211185
Epoch #171: loss=0.16479980742389505
Epoch #172: loss=0.19122443382035603
Epoch #173: loss=0.14600847684072726
Epoch #174: loss=0.16398922997442159
Epoch #175: loss=0.18738721728776442
Epoch #176: loss=0.18440853996258794
Epoch #177: loss=0.20651787993582812
Epoch #178: loss=0.13522488578702463
Epoch #179: loss=0.12205376859867212
Epoch #180: loss=0.12979612036636382
Epoch #181: loss=0.11390247478178053
Epoch #182: loss=0.13150959540948723
Epoch #183: loss=0.16505546833981166
Epoch #184: loss=0.13754695055611205
Epoch #185: loss=0.17461259335731016
Epoch #186: loss=0.17192777675209622
Epoch #187: loss=0.13611340477611078
Epoch #188: loss=0.13207304026141312
Epoch #189: loss=0.17885661644465994
Epoch #190: loss=0.16402901144641818
Epoch #191: loss=0.11579023990215677
Epoch #192: loss=0.12103825502774933
Epoch #193: loss=0.10971723733977838
Epoch #194: loss=0.14661781410827782
Epoch #195: loss=0.15586730634624307
Epoch #196: loss=0.15291513073624988
Epoch #197: loss=0.17458647241195044
Epoch #198: loss=0.16195861475937295
Epoch #199: loss=0.19099189973238742
Epoch #200: loss=0.1500460161178401
Epoch #201: loss=0.15305759125586713
Epoch #202: loss=0.10414449859297636
Epoch #203: loss=0.10169264324235194
Epoch #204: loss=0.12221455257950407
Epoch #205: loss=0.1578031282759074
Epoch #206: loss=0.13385378083947932
Epoch #207: loss=0.1770516922415206
Epoch #208: loss=0.13710656287995251
Epoch #209: loss=0.16288204671758594
Epoch #210: loss=0.2006205628541383
Epoch #211: loss=0.2052064204983639
Epoch #212: loss=0.22470539977604692
Epoch #213: loss=0.18866792513114033
Epoch #214: loss=0.14461184067256522
Epoch #215: loss=0.15162342233639775
Epoch #216: loss=0.1797945789541259
Epoch #217: loss=0.14543204032110446
Epoch #218: loss=0.1766815326656356
Epoch #219: loss=0.1636350074726524
Epoch #220: loss=0.1113104811220458
Epoch #221: loss=0.11002694894418572
Epoch #222: loss=0.12886953816720934
Epoch #223: loss=0.10177664272487164
Epoch #224: loss=0.09706272235648199
Epoch #225: loss=0.11381450137405684
Epoch #226: loss=0.09917013437458963
Epoch #227: loss=0.12270909909046057
Epoch #228: loss=0.14603185032804808
Epoch #229: loss=0.09977567828062808
Epoch #230: loss=0.11823024341102803
Epoch #231: loss=0.085078071407748
Epoch #232: loss=0.09241919084028764
Epoch #233: loss=0.07738177647644823
Epoch #234: loss=0.0969294731251218
Epoch #235: loss=0.11528850504846284
Epoch #236: loss=0.12302828501119759
Epoch #237: loss=0.12126331381273991
Epoch #238: loss=0.11688165011053736
Epoch #239: loss=0.11206804080442949
Epoch #240: loss=0.1651121410117908
Epoch #241: loss=0.2395049212782672
Epoch #242: loss=0.1217095669020306
Epoch #243: loss=0.15220058844848114
Epoch #244: loss=0.09334166455223705
Epoch #245: loss=0.1957832286981019
Epoch #246: loss=0.1199058811885841
Epoch #247: loss=0.08631544300552571
Epoch #248: loss=0.1260040444180821
Epoch #249: loss=0.08661573075435379

Training time: 0:09:00.970475

Finished.
n2one setting etth1_etth2_ettm1_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm1_exchange_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_etth2_ettm1_exchange', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.7361e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.15265e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.7361e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3824756511769453, 'MAE': 0.4356514534579631}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_ettm1_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm1_exchange_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_etth2_ettm1_exchange', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.49562e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.89246e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.49562e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 1.4042472210179837, 'MAE': 0.9818817313918576}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_ettm2_electricity', random_seed=2023, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_ettm2_electricity_epochs_250_seed_2023
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.6347954154359123
Epoch #1: loss=0.668449449659772
Epoch #2: loss=0.4803624719036797
Epoch #3: loss=0.3648287443325699
Epoch #4: loss=0.3397932982427536
Epoch #5: loss=0.2872060390479992
Epoch #6: loss=0.24192968521245642
Epoch #7: loss=0.21315244158912947
Epoch #8: loss=0.18272629298398949
Epoch #9: loss=0.17073550803123871
Epoch #10: loss=0.15530387897884226
Epoch #11: loss=0.1620595911571573
Epoch #12: loss=0.12359773696028772
Epoch #13: loss=0.1058236225750405
Epoch #14: loss=0.10624707802979416
Epoch #15: loss=0.09863780929863109
Epoch #16: loss=0.08668428443566051
Epoch #17: loss=0.09814806467169798
Epoch #18: loss=0.0957080643311832
Epoch #19: loss=0.06815730205419436
Epoch #20: loss=0.08562758358496893
Epoch #21: loss=0.0715183418061089
Epoch #22: loss=0.07111301086843014
Epoch #23: loss=0.0602889660883135
Epoch #24: loss=0.05458737889471642
Epoch #25: loss=0.05583450780653885
Epoch #26: loss=0.05409324755945991
Epoch #27: loss=0.04490355044371863
Epoch #28: loss=0.04107890379173692
Epoch #29: loss=0.046737685377677265
Epoch #30: loss=0.043812315540948096
Epoch #31: loss=0.04476486984842236
Epoch #32: loss=0.04293980875262463
Epoch #33: loss=0.039164037976650835
Epoch #34: loss=0.04495584712608723
Epoch #35: loss=0.05911606591735896
Epoch #36: loss=0.0416403871441443
Epoch #37: loss=0.03383795941124719
Epoch #38: loss=0.0437813488426053
Epoch #39: loss=0.035949282568874044
Epoch #40: loss=0.030085066875787398
Epoch #41: loss=0.044749260760273114
Epoch #42: loss=0.03874628929989251
Epoch #43: loss=0.03796311479931256
Epoch #44: loss=0.028548929900889194
Epoch #45: loss=0.02242579326138568
Epoch #46: loss=0.04738007199202228
Epoch #47: loss=0.03257559276403956
Epoch #48: loss=0.026964199788144363
Epoch #49: loss=0.027254315379823993
Epoch #50: loss=0.03199654629432483
Epoch #51: loss=0.02020207081175802
Epoch #52: loss=0.025887810024217504
Epoch #53: loss=0.022489175927553413
Epoch #54: loss=0.04117445696570582
Epoch #55: loss=0.038594683562943745
Epoch #56: loss=0.031152382343967118
Epoch #57: loss=0.02202078318216628
Epoch #58: loss=0.030841214868315425
Epoch #59: loss=0.022817563509495896
Epoch #60: loss=0.019716184200366388
Epoch #61: loss=0.02611444158091969
Epoch #62: loss=0.03179644746773182
Epoch #63: loss=0.026059959623141678
Epoch #64: loss=0.025740052292774825
Epoch #65: loss=0.027508228500790873
Epoch #66: loss=0.04886832489023749
Epoch #67: loss=0.02915524480147072
Epoch #68: loss=0.022173791519848017
Epoch #69: loss=0.030996956500982477
Epoch #70: loss=0.029892460387563494
Epoch #71: loss=0.022036822958219515
Epoch #72: loss=0.021754734586713016
Epoch #73: loss=0.028764956524444885
Epoch #74: loss=0.030344605892344858
Epoch #75: loss=0.019761835710102465
Epoch #76: loss=0.019723858690357664
Epoch #77: loss=0.014546824593771239
Epoch #78: loss=0.017671604006553897
Epoch #79: loss=0.03807194070685978
Epoch #80: loss=0.021100989607670154
Epoch #81: loss=0.01768366714557256
Epoch #82: loss=0.02147551283551208
Epoch #83: loss=0.020612037835193185
Epoch #84: loss=0.020132503199230913
Epoch #85: loss=0.020493103249800644
Epoch #86: loss=0.01733549280954132
Epoch #87: loss=0.02405081771622342
Epoch #88: loss=0.016709187952936168
Epoch #89: loss=0.01665816988528173
Epoch #90: loss=0.023147797431376887
Epoch #91: loss=0.01570989218364857
Epoch #92: loss=0.03949274633461986
Epoch #93: loss=0.013197512344680619
Epoch #94: loss=0.01927062990248198
Epoch #95: loss=0.028232447750869104
Epoch #96: loss=0.01573968837606301
Epoch #97: loss=0.0161126977168535
Epoch #98: loss=0.017324334223966002
Epoch #99: loss=0.02168085835766413
Epoch #100: loss=0.015920303988901662
Epoch #101: loss=0.01872130085793566
Epoch #102: loss=0.015830014924003308
Epoch #103: loss=0.016063671324918895
Epoch #104: loss=0.015562651846813566
Epoch #105: loss=0.017056963379754594
Epoch #106: loss=0.019263529999994516
Epoch #107: loss=0.01088959748323097
Epoch #108: loss=0.018998604030378643
Epoch #109: loss=0.01925245979921946
Epoch #110: loss=0.016466644966222528
Epoch #111: loss=0.01540571835424988
Epoch #112: loss=0.01993269654195433
Epoch #113: loss=0.01674849138261395
Epoch #114: loss=0.012657701112518377
Epoch #115: loss=0.011800233117571219
Epoch #116: loss=0.021408289423141078
Epoch #117: loss=0.015218129535804563
Epoch #118: loss=0.025133016372888183
Epoch #119: loss=0.011396544605777518
Epoch #120: loss=0.016426824098870137
Epoch #121: loss=0.01721581915306665
Epoch #122: loss=0.010465619489052629
Epoch #123: loss=0.02059206038994736
Epoch #124: loss=0.013060112852223669
Epoch #125: loss=0.01919411222256634
Epoch #126: loss=0.01282575329906318
Epoch #127: loss=0.012678001572514582
Epoch #128: loss=0.010373721045416355
Epoch #129: loss=0.012998860100175879
Epoch #130: loss=0.016072154860685153
Epoch #131: loss=0.017940124729648232
Epoch #132: loss=0.01360721921376989
Epoch #133: loss=0.011516517025184404
Epoch #134: loss=0.017226323064125946
Epoch #135: loss=0.014674934235231876
Epoch #136: loss=0.023591281017463526
Epoch #137: loss=0.012347875469474585
Epoch #138: loss=0.016029562277085487
Epoch #139: loss=0.027342336202030894
Epoch #140: loss=0.013739215141778671
Epoch #141: loss=0.014250956480108696
Epoch #142: loss=0.013947848172729156
Epoch #143: loss=0.012038887071125801
Epoch #144: loss=0.015043857280380964
Epoch #145: loss=0.014570299476772719
Epoch #146: loss=0.01356055755381852
Epoch #147: loss=0.009503583421690437
Epoch #148: loss=0.017231335547955227
Epoch #149: loss=0.014591084411579745
Epoch #150: loss=0.011675393360941482
Epoch #151: loss=0.017593267597318656
Epoch #152: loss=0.01636154101246354
Epoch #153: loss=0.01365125328477343
Epoch #154: loss=0.01712995745715042
Epoch #155: loss=0.013960645216815927
Epoch #156: loss=0.013730834340683394
Epoch #157: loss=0.01445898681951719
Epoch #158: loss=0.008884371606470893
Epoch #159: loss=0.012697680381337326
Epoch #160: loss=0.014131188288504645
Epoch #161: loss=0.015600869388015392
Epoch #162: loss=0.04093158635380813
Epoch #163: loss=0.01371060474994431
Epoch #164: loss=0.012801426939088905
Epoch #165: loss=0.009155023698708463
Epoch #166: loss=0.013533737122335585
Epoch #167: loss=0.009763534357293503
Epoch #168: loss=0.01446422916985752
Epoch #169: loss=0.019257778467037148
Epoch #170: loss=0.013193965215078485
Epoch #171: loss=0.010828008163132237
Epoch #172: loss=0.01652013328146106
Epoch #173: loss=0.01085906198555792
Epoch #174: loss=0.017505566300514742
Epoch #175: loss=0.018268174445054713
Epoch #176: loss=0.02013787814376289
Epoch #177: loss=0.02042696633658135
Epoch #178: loss=0.010116904195666588
Epoch #179: loss=0.008502240024484839
Epoch #180: loss=0.01230564393134077
Epoch #181: loss=0.018868509920181388
Epoch #182: loss=0.013684448684132362
Epoch #183: loss=0.0104260772009578
Epoch #184: loss=0.011674658484427888
Epoch #185: loss=0.012973488898304523
Epoch #186: loss=0.01223439371298778
Epoch #187: loss=0.012824358558719655
Epoch #188: loss=0.012515100317393467
Epoch #189: loss=0.011036883674749049
Epoch #190: loss=0.013282340481733322
Epoch #191: loss=0.006503405729934541
Epoch #192: loss=0.014428720228788524
Epoch #193: loss=0.016883493289237068
Epoch #194: loss=0.012507556742403758
Epoch #195: loss=0.01403234835772646
Epoch #196: loss=0.01924291235240677
Epoch #197: loss=0.015679486857483573
Epoch #198: loss=0.009713588975658613
Epoch #199: loss=0.019033341792868343
Epoch #200: loss=0.011518324838380592
Epoch #201: loss=0.01573314335728145
Epoch #202: loss=0.008025897140083081
Epoch #203: loss=0.01339068894783934
Epoch #204: loss=0.012616432033767897
Epoch #205: loss=0.010747534327287728
Epoch #206: loss=0.006751956490663855
Epoch #207: loss=0.013180660170949108
Epoch #208: loss=0.017736685172435315
Epoch #209: loss=0.016274553438987732
Epoch #210: loss=0.01107848855711229
Epoch #211: loss=0.01306509849073967
Epoch #212: loss=0.011206213446775441
Epoch #213: loss=0.013002705722616588
Epoch #214: loss=0.019320055536893494
Epoch #215: loss=0.01323238713195752
Epoch #216: loss=0.007344157512890541
Epoch #217: loss=0.0070027249755547786
Epoch #218: loss=0.011149203115175855
Epoch #219: loss=0.013959548698712647
Epoch #220: loss=0.012534383661517432
Epoch #221: loss=0.010362599166248107
Epoch #222: loss=0.015911795758114685
Epoch #223: loss=0.008059744799181258
Epoch #224: loss=0.013581891232895237
Epoch #225: loss=0.012457546209825627
Epoch #226: loss=0.014854987491914098
Epoch #227: loss=0.019494076267341044
Epoch #228: loss=0.010552846716674492
Epoch #229: loss=0.012388192020986509
Epoch #230: loss=0.01359701083545409
Epoch #231: loss=0.010184908144171296
Epoch #232: loss=0.014583016364452311
Epoch #233: loss=0.010314498481447028
Epoch #234: loss=0.020988447927954644
Epoch #235: loss=0.019230757752245673
Epoch #236: loss=0.014609486191174166
Epoch #237: loss=0.011164402154326772
Epoch #238: loss=0.010802647364366197
Epoch #239: loss=0.012635516767885342
Epoch #240: loss=0.00972186292372267
Epoch #241: loss=0.011323088668172403
Epoch #242: loss=0.01184969104360789
Epoch #243: loss=0.011443321395267037
Epoch #244: loss=0.010609325085264614
Epoch #245: loss=0.015817519457508793
Epoch #246: loss=0.012309815927584941
Epoch #247: loss=0.007194228935229721
Epoch #248: loss=0.011059998221627457
Epoch #249: loss=0.011562166395873057

Training time: 1:35:36.719190

Finished.
n2one setting etth1_etth2_ettm2_electricity -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm2_electricity_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_etth2_ettm2_electricity', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.39061e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.48701e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.70567e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.39061e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 1.1777493414313571, 'MAE': 0.9254239920741295}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_ettm2_electricity -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm2_electricity_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_etth2_ettm2_electricity', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.4298e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.4298e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3360211484331393, 'MAE': 0.3885412307858875}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_ettm2_traffic', random_seed=2023, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_ettm2_traffic_epochs_250_seed_2023
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.9762997737127065
Epoch #1: loss=0.3639992700287024
Epoch #2: loss=0.2665815780352982
Epoch #3: loss=0.21548679099746862
Epoch #4: loss=0.16510124346230856
Epoch #5: loss=0.12586010640787365
Epoch #6: loss=0.11162322113897312
Epoch #7: loss=0.0993702261632029
Epoch #8: loss=0.09400713267256301
Epoch #9: loss=0.07338435750658358
Epoch #10: loss=0.06280481063402778
Epoch #11: loss=0.07026817967901017
Epoch #12: loss=0.06448153432578335
Epoch #13: loss=0.05109508388246312
Epoch #14: loss=0.05173665881309167
Epoch #15: loss=0.04649328204657223
Epoch #16: loss=0.04156960670052993
Epoch #17: loss=0.04348070289427257
Epoch #18: loss=0.052947291722568436
Epoch #19: loss=0.03649938401840669
Epoch #20: loss=0.035336787684446806
Epoch #21: loss=0.035400809512789684
Epoch #22: loss=0.04001459760749933
Epoch #23: loss=0.0309251013142083
Epoch #24: loss=0.026115418886639843
Epoch #25: loss=0.029965425432284847
Epoch #26: loss=0.03722634832789489
Epoch #27: loss=0.0317577793464493
Epoch #28: loss=0.027382833218535886
Epoch #29: loss=0.02178021637513381
Epoch #30: loss=0.028381720218025756
Epoch #31: loss=0.027467247346083277
Epoch #32: loss=0.020786920586010817
Epoch #33: loss=0.03458084655401172
Epoch #34: loss=0.02858486651650839
Epoch #35: loss=0.032355433176906846
Epoch #36: loss=0.0298546487443189
Epoch #37: loss=0.02079446215141594
Epoch #38: loss=0.02622880667348034
Epoch #39: loss=0.030859138526541117
Epoch #40: loss=0.02102804876138953
Epoch #41: loss=0.023040217575548888
Epoch #42: loss=0.019725883802781754
Epoch #43: loss=0.01904280841348718
Epoch #44: loss=0.024368529757072682
Epoch #45: loss=0.027204766136929057
Epoch #46: loss=0.01927203780723675
Epoch #47: loss=0.020872132439510697
Epoch #48: loss=0.02458898401762734
Epoch #49: loss=0.016045851300703098
Epoch #50: loss=0.025481033675661867
Epoch #51: loss=0.015306891805230899
Epoch #52: loss=0.01956274466511133
Epoch #53: loss=0.019202349487975084
Epoch #54: loss=0.02456189825717573
Epoch #55: loss=0.026598847494473766
Epoch #56: loss=0.018179732524336283
Epoch #57: loss=0.011927494387492263
Epoch #58: loss=0.03168035359884399
Epoch #59: loss=0.01769921025628116
Epoch #60: loss=0.015745758402678146
Epoch #61: loss=0.019128001035950245
Epoch #62: loss=0.020741431548965208
Epoch #63: loss=0.014539119176711102
Epoch #64: loss=0.015179013470048663
Epoch #65: loss=0.01924754973358434
Epoch #66: loss=0.014253005080153166
Epoch #67: loss=0.017670718149262087
Epoch #68: loss=0.01946278729894972
Epoch #69: loss=0.01605579882438621
Epoch #70: loss=0.02143573844760736
Epoch #71: loss=0.012862188919403264
Epoch #72: loss=0.01978393405968042
Epoch #73: loss=0.009499743986532791
Epoch #74: loss=0.015554476254694468
Epoch #75: loss=0.02002726801796231
Epoch #76: loss=0.01804817222556721
Epoch #77: loss=0.01432507774877134
Epoch #78: loss=0.01628847093189612
Epoch #79: loss=0.017669201428173038
Epoch #80: loss=0.013302272825104168
Epoch #81: loss=0.01416121909033999
Epoch #82: loss=0.016372509097769435
Epoch #83: loss=0.016578196222566302
Epoch #84: loss=0.013169499882208151
Epoch #85: loss=0.012228003356729977
Epoch #86: loss=0.015362984038674952
Epoch #87: loss=0.021196489728629704
Epoch #88: loss=0.01440469726938896
Epoch #89: loss=0.01424046750609598
Epoch #90: loss=0.014315043339326509
Epoch #91: loss=0.014302521781432058
Epoch #92: loss=0.02678291902123644
Epoch #93: loss=0.01803866644500699
Epoch #94: loss=0.012246067241123502
Epoch #95: loss=0.020458758414540285
Epoch #96: loss=0.01814938177615945
Epoch #97: loss=0.011789920867827333
Epoch #98: loss=0.012043980914170029
Epoch #99: loss=0.012398105966846753
Epoch #100: loss=0.01576396296173019
Epoch #101: loss=0.015581043916401372
Epoch #102: loss=0.011609088772542464
Epoch #103: loss=0.031032111099944134
Epoch #104: loss=0.013869122250305893
Epoch #105: loss=0.011481321235445907
Epoch #106: loss=0.018577781627088546
Epoch #107: loss=0.01238549276748688
Epoch #108: loss=0.010027364003729273
Epoch #109: loss=0.014585145066114007
Epoch #110: loss=0.013449736616404659
Epoch #111: loss=0.011156834030010462
Epoch #112: loss=0.014881133209666438
Epoch #113: loss=0.01421587338659998
Epoch #114: loss=0.013292920875557033
Epoch #115: loss=0.01890711279518628
Epoch #116: loss=0.015319956868234392
Epoch #117: loss=0.01870729912392923
Epoch #118: loss=0.020647927480964372
Epoch #119: loss=0.009507565083532891
Epoch #120: loss=0.012290901401691274
Epoch #121: loss=0.011854597161880462
Epoch #122: loss=0.010099644241128757
Epoch #123: loss=0.015181852044626123
Epoch #124: loss=0.01413288921766926
Epoch #125: loss=0.015294660364522828
Epoch #126: loss=0.01207051603133061
Epoch #127: loss=0.009630426440435361
Epoch #128: loss=0.014300669115320217
Epoch #129: loss=0.010497232619712388
Epoch #130: loss=0.013380089483722329
Epoch #131: loss=0.013584094490345254
Epoch #132: loss=0.01673598756797516
Epoch #133: loss=0.009703690945369001
Epoch #134: loss=0.011942898435938133
Epoch #135: loss=0.011935731502814982
Epoch #136: loss=0.011097403756520536
Epoch #137: loss=0.01633600518732474
Epoch #138: loss=0.01293145232041064
Epoch #139: loss=0.010813091083219366
Epoch #140: loss=0.011996312043747709
Epoch #141: loss=0.009757926118826697
Epoch #142: loss=0.014030923766905354
Epoch #143: loss=0.01046584744757517
Epoch #144: loss=0.009519661054605243
Epoch #145: loss=0.015516084175024826
Epoch #146: loss=0.01475132211669807
Epoch #147: loss=0.015053301305832182
Epoch #148: loss=0.009575813207537143
Epoch #149: loss=0.016492780403089956
Epoch #150: loss=0.013353855258875355
Epoch #151: loss=0.008938085170097995
Epoch #152: loss=0.011340729325565875
Epoch #153: loss=0.014060225161086461
Epoch #154: loss=0.00880479980704894
Epoch #155: loss=0.010197488076081515
Epoch #156: loss=0.013486524272839756
Epoch #157: loss=0.01110153611789572
Epoch #158: loss=0.015034917145073698
Epoch #159: loss=0.007792163231379768
Epoch #160: loss=0.012208856685032486
Epoch #161: loss=0.012123809328925242
Epoch #162: loss=0.014526096082235011
Epoch #163: loss=0.01711572423837701
Epoch #164: loss=0.009496161014654305
Epoch #165: loss=0.008917730235806842
Epoch #166: loss=0.012642842525275179
Epoch #167: loss=0.010897293274425781
Epoch #168: loss=0.007863498904667228
Epoch #169: loss=0.013672002963734877
Epoch #170: loss=0.00853908740471221
Epoch #171: loss=0.01022716709369323
Epoch #172: loss=0.010773248962715837
Epoch #173: loss=0.010824755933747026
Epoch #174: loss=0.011316219707647115
Epoch #175: loss=0.011260746125812487
Epoch #176: loss=0.013140437086954742
Epoch #177: loss=0.007439183035983285
Epoch #178: loss=0.013730236320229948
Epoch #179: loss=0.011708741651640852
Epoch #180: loss=0.012385859533121728
Epoch #181: loss=0.008828478219709307
Epoch #182: loss=0.0132776945085554
Epoch #183: loss=0.007522713668442178
Epoch #184: loss=0.015057247436439105
Epoch #185: loss=0.012651041552428105
Epoch #186: loss=0.011223699240066587
Epoch #187: loss=0.011393733718721228
Epoch #188: loss=0.008780376932845642
Epoch #189: loss=0.008834136108822018
Epoch #190: loss=0.011601633175111243
Epoch #191: loss=0.00893261458359151
Epoch #192: loss=0.009943110405478869
Epoch #193: loss=0.010689131589783586
Epoch #194: loss=0.009749902097091341
Epoch #195: loss=0.008750968125626878
Epoch #196: loss=0.014007127407535054
Epoch #197: loss=0.015107728923381419
Epoch #198: loss=0.013801180889156437
Epoch #199: loss=0.0279258415118052
Epoch #200: loss=0.008718962002136238
Epoch #201: loss=0.009178965329606005
Epoch #202: loss=0.00933487418682809
Epoch #203: loss=0.007899903122992165
Epoch #204: loss=0.012407692296200111
Epoch #205: loss=0.011664004865697802
Epoch #206: loss=0.013032019984840942
Epoch #207: loss=0.007961505989354049
Epoch #208: loss=0.014327032433914887
Epoch #209: loss=0.007994701127493344
Epoch #210: loss=0.012940464691920972
Epoch #211: loss=0.013966591269150062
Epoch #212: loss=0.010555294812479101
Epoch #213: loss=0.005624521171433033
Epoch #214: loss=0.014621729032287959
Epoch #215: loss=0.008802043068579166
Epoch #216: loss=0.01198711621464253
Epoch #217: loss=0.01011427178187309
Epoch #218: loss=0.013105262324683252
Epoch #219: loss=0.008213966293884182
Epoch #220: loss=0.008240242182173327
Epoch #221: loss=0.009698043675258035
Epoch #222: loss=0.007160835674161452
Epoch #223: loss=0.016199649077655878
Epoch #224: loss=0.008916757690455876
Epoch #225: loss=0.010701573824195579
Epoch #226: loss=0.00922950117809046
Epoch #227: loss=0.025983989793122688
Epoch #228: loss=0.010277162529424457
Epoch #229: loss=0.006868382100980013
Epoch #230: loss=0.007635362361720002
Epoch #231: loss=0.012148126287590828
Epoch #232: loss=0.007194243982388205
Epoch #233: loss=0.011659515059657165
Epoch #234: loss=0.010690057938146088
Epoch #235: loss=0.011194891599735367
Epoch #236: loss=0.006833651616776692
Epoch #237: loss=0.014207069906618724
Epoch #238: loss=0.008863405689448559
Epoch #239: loss=0.010880747810416286
Epoch #240: loss=0.009146686073499529
Epoch #241: loss=0.010865351336939536
Epoch #242: loss=0.012012024047239049
Epoch #243: loss=0.009199771562717136
Epoch #244: loss=0.009372554761774968
Epoch #245: loss=0.009928171591458658
Epoch #246: loss=0.011334745631391932
Epoch #247: loss=0.01279421198199559
Epoch #248: loss=0.015228929024033791
Epoch #249: loss=0.007961246014532387

Training time: 3:26:25.689594

Finished.
n2one setting etth1_etth2_ettm2_traffic -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm2_traffic_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_etth2_ettm2_traffic', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.1028e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.80997e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.62409e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.1028e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.39581793202383647, 'MAE': 0.4465209446536017}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_ettm2_traffic -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm2_traffic_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_etth2_ettm2_traffic', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=6.48009e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.4742e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.21893e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4260508905266195, 'MAE': 0.4817126058339635}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_ettm2_traffic -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm2_traffic_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_etth2_ettm2_traffic', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.27393e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.24152264062490394, 'MAE': 0.3311921053396234}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_ettm2_weather', random_seed=2023, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_ettm2_weather_epochs_250_seed_2023
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=3.9336313546872606
Epoch #1: loss=2.6129475925482955
Epoch #2: loss=2.249224403325249
Epoch #3: loss=1.916854458696702
Epoch #4: loss=1.6928992341546452
Epoch #5: loss=1.550032337506612
Epoch #6: loss=1.5790575345357258
Epoch #7: loss=1.3406604551801495
Epoch #8: loss=1.2390047171536613
Epoch #9: loss=1.207944557947271
Epoch #10: loss=1.1135460886300779
Epoch #11: loss=1.0494155907163434
Epoch #12: loss=0.9780076707110685
Epoch #13: loss=0.9020533105906319
Epoch #14: loss=0.9012975797933691
Epoch #15: loss=0.8695579112744799
Epoch #16: loss=0.7877584403636408
Epoch #17: loss=0.8120977750011519
Epoch #18: loss=0.8261602263824612
Epoch #19: loss=0.7754430291699428
Epoch #20: loss=0.7237553736742806
Epoch #21: loss=0.7016578854299059
Epoch #22: loss=0.7307983274553337
Epoch #23: loss=0.67087022171301
Epoch #24: loss=0.6082524628031487
Epoch #25: loss=0.6435083670943391
Epoch #26: loss=0.6312861027670842
Epoch #27: loss=0.6076601732010934
Epoch #28: loss=0.533498920062009
Epoch #29: loss=0.5461475399194979
Epoch #30: loss=0.5395789111361784
Epoch #31: loss=0.5138105130663105
Epoch #32: loss=0.5206364258831623
Epoch #33: loss=0.46144287375842824
Epoch #34: loss=0.5075594724393359
Epoch #35: loss=0.6185514582138435
Epoch #36: loss=0.6204612313532362
Epoch #37: loss=0.44610340104383583
Epoch #38: loss=0.4621763638421601
Epoch #39: loss=0.48418965760399313
Epoch #40: loss=0.4292518216020921
Epoch #41: loss=0.4069864083738888
Epoch #42: loss=0.3895187541550281
Epoch #43: loss=0.37335097117751254
Epoch #44: loss=0.4095128818469889
Epoch #45: loss=0.47201849929257933
Epoch #46: loss=0.3640757261538038
Epoch #47: loss=0.40490594243302064
Epoch #48: loss=0.36370042287835885
Epoch #49: loss=0.3532309970434974
Epoch #50: loss=0.3025456693242578
Epoch #51: loss=0.3747027671220256
Epoch #52: loss=0.3339158357942806
Epoch #53: loss=0.29381626639880387
Epoch #54: loss=0.30178692148012276
Epoch #55: loss=0.36941663102776395
Epoch #56: loss=0.2981327006629869
Epoch #57: loss=0.34422337702092004
Epoch #58: loss=0.38718824117791417
Epoch #59: loss=0.29983094597564025
Epoch #60: loss=0.28721675072230546
Epoch #61: loss=0.27925018381838707
Epoch #62: loss=0.30808160833868325
Epoch #63: loss=0.2626007837699909
Epoch #64: loss=0.30321767429510754
Epoch #65: loss=0.338989738740173
Epoch #66: loss=0.3056185483640316
Epoch #67: loss=0.23143356585619496
Epoch #68: loss=0.23908528320345224
Epoch #69: loss=0.2410553036367192
Epoch #70: loss=0.26415206813344766
Epoch #71: loss=0.22333913311070086
Epoch #72: loss=0.208812403693503
Epoch #73: loss=0.2176036722958088
Epoch #74: loss=0.22150833086640226
Epoch #75: loss=0.22412175290724812
Epoch #76: loss=0.2733302460435559
Epoch #77: loss=0.2653571454917683
Epoch #78: loss=0.2528489788665491
Epoch #79: loss=0.22603878130515417
Epoch #80: loss=0.23129538505100736
Epoch #81: loss=0.20187620599480235
Epoch #82: loss=0.3226994475459351
Epoch #83: loss=0.23088009144161262
Epoch #84: loss=0.22234600446387834
Epoch #85: loss=0.2545280433168598
Epoch #86: loss=0.16940663835289432
Epoch #87: loss=0.17738695340413674
Epoch #88: loss=0.18872098464007472
Epoch #89: loss=0.15821525439912199
Epoch #90: loss=0.20164680342171706
Epoch #91: loss=0.18754248759325812
Epoch #92: loss=0.1939872964924457
Epoch #93: loss=0.14645612393231952
Epoch #94: loss=0.1512833691987337
Epoch #95: loss=0.15993318027433226
Epoch #96: loss=0.21193118130459504
Epoch #97: loss=0.17534982982803793
Epoch #98: loss=0.15273613460800228
Epoch #99: loss=0.13127115237362244
Epoch #100: loss=0.12069401002543814
Epoch #101: loss=0.17678006022584206
Epoch #102: loss=0.1434654102605932
Epoch #103: loss=0.13655272798210966
Epoch #104: loss=0.116865789335148
Epoch #105: loss=0.19526291419478023
Epoch #106: loss=0.1426650866062618
Epoch #107: loss=0.13658197362925492
Epoch #108: loss=0.13533378253672637
Epoch #109: loss=0.17880841140069215
Epoch #110: loss=0.2131434706788437
Epoch #111: loss=0.11835224590465135
Epoch #112: loss=0.14339545924289554
Epoch #113: loss=0.1313502106304262
Epoch #114: loss=0.16835795313704247
Epoch #115: loss=0.13684742017557808
Epoch #116: loss=0.13417532594472753
Epoch #117: loss=0.15765323329205608
Epoch #118: loss=0.1656713584328399
Epoch #119: loss=0.11011161107350798
Epoch #120: loss=0.1261362468860313
Epoch #121: loss=0.113231319313248
Epoch #122: loss=0.09268181296248063
Epoch #123: loss=0.18084803387960968
Epoch #124: loss=0.17296036814942078
Epoch #125: loss=0.13773928177269065
Epoch #126: loss=0.10512701703198984
Epoch #127: loss=0.10021754485719345
Epoch #128: loss=0.10795222577072826
Epoch #129: loss=0.12985133218999004
Epoch #130: loss=0.1349224510292212
Epoch #131: loss=0.13238242425608868
Epoch #132: loss=0.11261577002119784
Epoch #133: loss=0.100578860580629
Epoch #134: loss=0.09175377003118104
Epoch #135: loss=0.09282674965466939
Epoch #136: loss=0.11735452276964982
Epoch #137: loss=0.10183413808836657
Epoch #138: loss=0.11019584364896896
Epoch #139: loss=0.09036749524666983
Epoch #140: loss=0.11491729216832741
Epoch #141: loss=0.11470978707075119
Epoch #142: loss=0.09680073156806768
Epoch #143: loss=0.09621194183972537
Epoch #144: loss=0.0818836984827238
Epoch #145: loss=0.10432549160631265
Epoch #146: loss=0.10174749375266187
Epoch #147: loss=0.10628102708827047
Epoch #148: loss=0.09867762843621712
Epoch #149: loss=0.09437369569843891
Epoch #150: loss=0.16332877449253025
Epoch #151: loss=0.11083865589370914
Epoch #152: loss=0.09571802283765055
Epoch #153: loss=0.11129963679202631
Epoch #154: loss=0.1301689574166256
Epoch #155: loss=0.08257448996472008
Epoch #156: loss=0.09751064122161444
Epoch #157: loss=0.08267283936341603
Epoch #158: loss=0.07033176166827187
Epoch #159: loss=0.07546966773110862
Epoch #160: loss=0.07414871647807897
Epoch #161: loss=0.0942244344007443
Epoch #162: loss=0.10611990627412703
Epoch #163: loss=0.10271471154456045
Epoch #164: loss=0.07389922679274105
Epoch #165: loss=0.09908064801757242
Epoch #166: loss=0.10856473343629464
Epoch #167: loss=0.09231178548333108
Epoch #168: loss=0.11596760975525659
Epoch #169: loss=0.0993101384454206
Epoch #170: loss=0.10022427649328522
Epoch #171: loss=0.08031349015586517
Epoch #172: loss=0.09724654385126104
Epoch #173: loss=0.09753838933858217
Epoch #174: loss=0.09074652017842905
Epoch #175: loss=0.09064580730217345
Epoch #176: loss=0.08683826652008529
Epoch #177: loss=0.07544983518035973
Epoch #178: loss=0.06481944333177571
Epoch #179: loss=0.06732671989091471
Epoch #180: loss=0.06944445714208425
Epoch #181: loss=0.07529730143427264
Epoch #182: loss=0.14748420792759634
Epoch #183: loss=0.08719769383178037
Epoch #184: loss=0.12519864544418513
Epoch #185: loss=0.08454657994283765
Epoch #186: loss=0.07787969971404356
Epoch #187: loss=0.08753218611373621
Epoch #188: loss=0.12267347757576727
Epoch #189: loss=0.12099762768575958
Epoch #190: loss=0.11368049374398063
Epoch #191: loss=0.11322506387517148
Epoch #192: loss=0.09055389438335802
Epoch #193: loss=0.15771651656969504
Epoch #194: loss=0.15260408504628667
Epoch #195: loss=0.11149485708743918
Epoch #196: loss=0.1345297453158042
Epoch #197: loss=0.08407902337756812
Epoch #198: loss=0.076493315069991
Epoch #199: loss=0.07216154097342024
Epoch #200: loss=0.0910944347908976
Epoch #201: loss=0.10847862048403305
Epoch #202: loss=0.06232132623885192
Epoch #203: loss=0.08049989572050524
Epoch #204: loss=0.055572590662860404
Epoch #205: loss=0.0582530354423558
Epoch #206: loss=0.07625935036762088
Epoch #207: loss=0.10287132185390767
Epoch #208: loss=0.14160072551492384
Epoch #209: loss=0.0775736431207727
Epoch #210: loss=0.059037785940602716
Epoch #211: loss=0.05259548450874932
Epoch #212: loss=0.0755649139264635
Epoch #213: loss=0.08206476590723968
Epoch #214: loss=0.0610249163582921
Epoch #215: loss=0.06479811785267849
Epoch #216: loss=0.06681294514633276
Epoch #217: loss=0.050221039110100736
Epoch #218: loss=0.05988448083985085
Epoch #219: loss=0.07341193287249874
Epoch #220: loss=0.05250168835525127
Epoch #221: loss=0.054796431715801064
Epoch #222: loss=0.05438482409854438
Epoch #223: loss=0.08505301940820965
Epoch #224: loss=0.11398063695021704
Epoch #225: loss=0.10415635257959366
Epoch #226: loss=0.0868668300921426
Epoch #227: loss=0.06126767400579125
Epoch #228: loss=0.08035020146738081
Epoch #229: loss=0.06207786734197654
Epoch #230: loss=0.06159242181399582
Epoch #231: loss=0.07103129857968465
Epoch #232: loss=0.06714170950227509
Epoch #233: loss=0.05302370186237728
Epoch #234: loss=0.05150654497465082
Epoch #235: loss=0.060768960956849305
Epoch #236: loss=0.1603923593008635
Epoch #237: loss=0.07870247273468504
Epoch #238: loss=0.06566752665037033
Epoch #239: loss=0.06056039981251838
Epoch #240: loss=0.06847800376514594
Epoch #241: loss=0.057486493779602
Epoch #242: loss=0.06905775456050155
Epoch #243: loss=0.0509984201075984
Epoch #244: loss=0.07133768778294325
Epoch #245: loss=0.05951613175007058
Epoch #246: loss=0.051900042759656324
Epoch #247: loss=0.06724908363585379
Epoch #248: loss=0.09445981714217101
Epoch #249: loss=0.08016100673771956

Training time: 0:16:26.646170

Finished.
n2one setting etth1_etth2_ettm2_weather -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm2_weather_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_etth2_ettm2_weather', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.61541e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.04865e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.61541e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.36945349163652313, 'MAE': 0.42997140776818266}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_ettm2_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm2_weather_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_etth2_ettm2_weather', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.24459e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.20211764337923707, 'MAE': 0.3074005300565654}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_ettm2_exchange', random_seed=2023, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_ettm2_exchange_epochs_250_seed_2023
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=3.9161573901320947
Epoch #1: loss=2.2601566206325185
Epoch #2: loss=2.073627804264878
Epoch #3: loss=1.8748066389199458
Epoch #4: loss=1.7584469824126272
Epoch #5: loss=1.6247860337748672
Epoch #6: loss=1.5063053116653904
Epoch #7: loss=1.388986293113593
Epoch #8: loss=1.2478388981385664
Epoch #9: loss=1.1867986520131428
Epoch #10: loss=1.1301543098507505
Epoch #11: loss=1.04919228589896
Epoch #12: loss=1.1049846988735776
Epoch #13: loss=1.0839787721633911
Epoch #14: loss=1.0160266468019197
Epoch #15: loss=0.9708003004391988
Epoch #16: loss=0.9122303850723036
Epoch #17: loss=0.897169272104899
Epoch #18: loss=0.9047879919861302
Epoch #19: loss=0.8499445156617598
Epoch #20: loss=0.8614999814466997
Epoch #21: loss=0.7843743075023998
Epoch #22: loss=0.8347127934296926
Epoch #23: loss=0.8138249715169271
Epoch #24: loss=0.7981860457044659
Epoch #25: loss=0.810118396173824
Epoch #26: loss=0.8196106092496351
Epoch #27: loss=0.6987099214033647
Epoch #28: loss=0.6576382951302961
Epoch #29: loss=0.6946236066745989
Epoch #30: loss=0.6934938385631099
Epoch #31: loss=0.7630211999922087
Epoch #32: loss=0.6662514227809329
Epoch #33: loss=0.7149180643486254
Epoch #34: loss=0.6587016880512238
Epoch #35: loss=0.6049870505477443
Epoch #36: loss=0.5612832768396898
Epoch #37: loss=0.6195753343177565
Epoch #38: loss=0.5615519294233033
Epoch #39: loss=0.5390323256001328
Epoch #40: loss=0.5942122087334142
Epoch #41: loss=0.5903648201263312
Epoch #42: loss=0.5087316686456854
Epoch #43: loss=0.5442395074801012
Epoch #44: loss=0.5288631247751641
Epoch #45: loss=0.5239005630666559
Epoch #46: loss=0.5224240250659712
Epoch #47: loss=0.598099517099785
Epoch #48: loss=0.608365204298135
Epoch #49: loss=0.565731350219611
Epoch #50: loss=0.5009589953856035
Epoch #51: loss=0.4885848927678484
Epoch #52: loss=0.46914322177569073
Epoch #53: loss=0.4705802256410772
Epoch #54: loss=0.5038028567126303
Epoch #55: loss=0.45031657814979553
Epoch #56: loss=0.4861980044480526
Epoch #57: loss=0.4023441130464727
Epoch #58: loss=0.4009077643806284
Epoch #59: loss=0.4551395010767561
Epoch #60: loss=0.4152017104806322
Epoch #61: loss=0.516354832685355
Epoch #62: loss=0.49799176960280445
Epoch #63: loss=0.49227157641540875
Epoch #64: loss=0.48237471553412353
Epoch #65: loss=0.42168575615593884
Epoch #66: loss=0.3953979236610008
Epoch #67: loss=0.41630161034338403
Epoch #68: loss=0.45868181911381806
Epoch #69: loss=0.3936842761256478
Epoch #70: loss=0.37588395088007953
Epoch #71: loss=0.4573043639009649
Epoch #72: loss=0.38538721835974493
Epoch #73: loss=0.470842591289318
Epoch #74: loss=0.3818954184199824
Epoch #75: loss=0.3621040560079343
Epoch #76: loss=0.3811375259449988
Epoch #77: loss=0.41905908512346673
Epoch #78: loss=0.39313661871534406
Epoch #79: loss=0.34465261300404865
Epoch #80: loss=0.3308176064130032
Epoch #81: loss=0.3076998812682701
Epoch #82: loss=0.29343597545768274
Epoch #83: loss=0.3142210701198289
Epoch #84: loss=0.30483188276941126
Epoch #85: loss=0.31516009027307684
Epoch #86: loss=0.3015382953665473
Epoch #87: loss=0.3194797043547486
Epoch #88: loss=0.29601228914477606
Epoch #89: loss=0.3408297869292172
Epoch #90: loss=0.34107559738737164
Epoch #91: loss=0.3471502724922065
Epoch #92: loss=0.33790108109965467
Epoch #93: loss=0.3891273910800616
Epoch #94: loss=0.30015588009899313
Epoch #95: loss=0.3055732710794969
Epoch #96: loss=0.25881376320665533
Epoch #97: loss=0.2474606748331677
Epoch #98: loss=0.2764982416322737
Epoch #99: loss=0.265020416541533
Epoch #100: loss=0.25913424451242795
Epoch #101: loss=0.30170785951795
Epoch #102: loss=0.257578264809016
Epoch #103: loss=0.2560253734841491
Epoch #104: loss=0.26665398117267725
Epoch #105: loss=0.2983428691372727
Epoch #106: loss=0.2714036134156314
Epoch #107: loss=0.2731217042063222
Epoch #108: loss=0.271370287871722
Epoch #109: loss=0.3184143327402346
Epoch #110: loss=0.23707789182662964
Epoch #111: loss=0.28424074929772003
Epoch #112: loss=0.3052563260902058
Epoch #113: loss=0.2824591863335985
Epoch #114: loss=0.23851534633925467
Epoch #115: loss=0.2666282762180675
Epoch #116: loss=0.2548003745349971
Epoch #117: loss=0.24217473602656162
Epoch #118: loss=0.1724937427224535
Epoch #119: loss=0.23485126120574545
Epoch #120: loss=0.26550566337325354
Epoch #121: loss=0.2521335322296981
Epoch #122: loss=0.2527866212256027
Epoch #123: loss=0.21894260066928287
Epoch #124: loss=0.20895449726870566
Epoch #125: loss=0.22823098437352615
Epoch #126: loss=0.1837159234917525
Epoch #127: loss=0.1897292620304859
Epoch #128: loss=0.354337654782064
Epoch #129: loss=0.22252511729796728
Epoch #130: loss=0.2683637914332477
Epoch #131: loss=0.21168812454649896
Epoch #132: loss=0.2354043356396935
Epoch #133: loss=0.16605013450889877
Epoch #134: loss=0.1919544686873754
Epoch #135: loss=0.1728164702653885
Epoch #136: loss=0.18402238641724442
Epoch #137: loss=0.1673846332864328
Epoch #138: loss=0.21093056396101462
Epoch #139: loss=0.18488754140156688
Epoch #140: loss=0.23765621108539176
Epoch #141: loss=0.1865384845119534
Epoch #142: loss=0.14353010193868118
Epoch #143: loss=0.18681450255892493
Epoch #144: loss=0.19178043599381592
Epoch #145: loss=0.16273144045562454
Epoch #146: loss=0.16337785824681772
Epoch #147: loss=0.14392575294230925
Epoch #148: loss=0.14496608676783967
Epoch #149: loss=0.15698300731001477
Epoch #150: loss=0.17569109233039798
Epoch #151: loss=0.1438031237233769
Epoch #152: loss=0.1781191017591592
Epoch #153: loss=0.2593663627225341
Epoch #154: loss=0.22216093291838965
Epoch #155: loss=0.25498137939156906
Epoch #156: loss=0.2384461613767075
Epoch #157: loss=0.22697867565985883
Epoch #158: loss=0.260870162962061
Epoch #159: loss=0.22695950689640912
Epoch #160: loss=0.23091860544500928
Epoch #161: loss=0.17623427871501807
Epoch #162: loss=0.20530304019198273
Epoch #163: loss=0.17818560406114115
Epoch #164: loss=0.18404167506730917
Epoch #165: loss=0.16767648980021477
Epoch #166: loss=0.1583533532014399
Epoch #167: loss=0.1949921278565219
Epoch #168: loss=0.14076996007651993
Epoch #169: loss=0.2076263992172299
Epoch #170: loss=0.16340466329094136
Epoch #171: loss=0.15477348672169627
Epoch #172: loss=0.18734346386609654
Epoch #173: loss=0.1283361062859044
Epoch #174: loss=0.13891050840417543
Epoch #175: loss=0.15948483404336553
Epoch #176: loss=0.16522134298628027
Epoch #177: loss=0.19521210320068128
Epoch #178: loss=0.13756136110786235
Epoch #179: loss=0.13181859435457172
Epoch #180: loss=0.13946898947611
Epoch #181: loss=0.12684267149730163
Epoch #182: loss=0.13347924850655324
Epoch #183: loss=0.1705885695462877
Epoch #184: loss=0.17959136651320892
Epoch #185: loss=0.21537896968198544
Epoch #186: loss=0.2000311084768989
Epoch #187: loss=0.15773810480128636
Epoch #188: loss=0.12652287169387846
Epoch #189: loss=0.17325999553908
Epoch #190: loss=0.16505662035761456
Epoch #191: loss=0.12034825438802893
Epoch #192: loss=0.12415994737635959
Epoch #193: loss=0.12841665022300952
Epoch #194: loss=0.14721007419354987
Epoch #195: loss=0.17533051098386446
Epoch #196: loss=0.17550306473717545
Epoch #197: loss=0.17073201602607063
Epoch #198: loss=0.13424879572156703
Epoch #199: loss=0.16077548400922256
Epoch #200: loss=0.13901673590369296
Epoch #201: loss=0.15671923858198253
Epoch #202: loss=0.09107202359221199
Epoch #203: loss=0.09472578064058766
Epoch #204: loss=0.12331787914489255
Epoch #205: loss=0.1524373781161778
Epoch #206: loss=0.12947862663052298
Epoch #207: loss=0.16011114599126758
Epoch #208: loss=0.09798541602989037
Epoch #209: loss=0.09246258663408684
Epoch #210: loss=0.13829875421343427
Epoch #211: loss=0.13931763990584647
Epoch #212: loss=0.15866445930618228
Epoch #213: loss=0.12006766066858263
Epoch #214: loss=0.13134419500376238
Epoch #215: loss=0.13287927097443378
Epoch #216: loss=0.16470835007952922
Epoch #217: loss=0.17017094785291137
Epoch #218: loss=0.252089732637008
Epoch #219: loss=0.17237212847579608
Epoch #220: loss=0.1121039255098863
Epoch #221: loss=0.10725159745550517
Epoch #222: loss=0.10954312731822331
Epoch #223: loss=0.10222978127950971
Epoch #224: loss=0.09634920909549251
Epoch #225: loss=0.10442074591463263
Epoch #226: loss=0.09358801472593438
Epoch #227: loss=0.12324337621755672
Epoch #228: loss=0.14000221279760203
Epoch #229: loss=0.10073971612886949
Epoch #230: loss=0.12904347603519759
Epoch #231: loss=0.09690926952118223
Epoch #232: loss=0.11627424305135553
Epoch #233: loss=0.09640674016466647
Epoch #234: loss=0.1105672786520286
Epoch #235: loss=0.1634157601405274
Epoch #236: loss=0.13111025896487813
Epoch #237: loss=0.14852938078569644
Epoch #238: loss=0.15128433738242497
Epoch #239: loss=0.13445746131015546
Epoch #240: loss=0.2012722600590099
Epoch #241: loss=0.2724815196160114
Epoch #242: loss=0.13845854139689243
Epoch #243: loss=0.16106939631881137
Epoch #244: loss=0.10404142330993306
Epoch #245: loss=0.18355087619839291
Epoch #246: loss=0.11141136215265954
Epoch #247: loss=0.09332281746196025
Epoch #248: loss=0.12632874726797594
Epoch #249: loss=0.08101219779840022

Training time: 0:08:49.453140

Finished.
n2one setting etth1_etth2_ettm2_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm2_exchange_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_etth2_ettm2_exchange', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.73022e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.44016e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.73022e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.37813382115243727, 'MAE': 0.4350736875802369}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_ettm2_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_ettm2_exchange_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_etth2_ettm2_exchange', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.67774e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.09097e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.67774e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 1.673914789013307, 'MAE': 1.0841471357608592}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_electricity_traffic', random_seed=2023, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_electricity_traffic_epochs_250_seed_2023
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.8111363584385779
Epoch #1: loss=0.2913656272834405
Epoch #2: loss=0.19630888527696494
Epoch #3: loss=0.15420448953408744
Epoch #4: loss=0.11007450889319853
Epoch #5: loss=0.08493429417243428
Epoch #6: loss=0.06768103242511787
Epoch #7: loss=0.058731875431380774
Epoch #8: loss=0.05421175369362634
Epoch #9: loss=0.04117890399022521
Epoch #10: loss=0.046604265412004506
Epoch #11: loss=0.039017659803594125
Epoch #12: loss=0.04019851807357842
Epoch #13: loss=0.03582578300179037
Epoch #14: loss=0.031075706745909468
Epoch #15: loss=0.033888632327465244
Epoch #16: loss=0.03192032496579094
Epoch #17: loss=0.027254046022436064
Epoch #18: loss=0.028532616680028166
Epoch #19: loss=0.03101913656676834
Epoch #20: loss=0.028210454127965644
Epoch #21: loss=0.025792694527853464
Epoch #22: loss=0.024943441979539616
Epoch #23: loss=0.02372845487465651
Epoch #24: loss=0.02522574347876084
Epoch #25: loss=0.02146427636049375
Epoch #26: loss=0.024735307652546435
Epoch #27: loss=0.019526877389161063
Epoch #28: loss=0.01692999914693008
Epoch #29: loss=0.02119275622758213
Epoch #30: loss=0.022853402022372328
Epoch #31: loss=0.02106662446897712
Epoch #32: loss=0.019502949257917724
Epoch #33: loss=0.018017852930496032
Epoch #34: loss=0.018139398338564157
Epoch #35: loss=0.01765609273338391
Epoch #36: loss=0.021035658349011697
Epoch #37: loss=0.02020507607470541
Epoch #38: loss=0.01897173442294488
Epoch #39: loss=0.014935087462925682
Epoch #40: loss=0.01842192653739228
Epoch #41: loss=0.01616424119203844
Epoch #42: loss=0.015501279720837835
Epoch #43: loss=0.013182071402446042
Epoch #44: loss=0.01721850123568442
Epoch #45: loss=0.01852517527603578
Epoch #46: loss=0.01570059661174803
Epoch #47: loss=0.023098661115114112
Epoch #48: loss=0.023536382747114594
Epoch #49: loss=0.016048568459065264
Epoch #50: loss=0.013583183690095235
Epoch #51: loss=0.01694482855463584
Epoch #52: loss=0.014244269757651596
Epoch #53: loss=0.018115777895447806
Epoch #54: loss=0.019391526053617797
Epoch #55: loss=0.016885521134734894
Epoch #56: loss=0.014599380741962667
Epoch #57: loss=0.013459008697673419
Epoch #58: loss=0.013004124428582462
Epoch #59: loss=0.01460152548075414
Epoch #60: loss=0.01779984133579685
Epoch #61: loss=0.013641644613319385
Epoch #62: loss=0.012697950614948987
Epoch #63: loss=0.02099092117270125
Epoch #64: loss=0.021659346642301385
Epoch #65: loss=0.017243775329659573
Epoch #66: loss=0.012714767147816676
Epoch #67: loss=0.01267397865787154
Epoch #68: loss=0.013410564685616185
Epoch #69: loss=0.013240790106575456
Epoch #70: loss=0.014074117123269348
Epoch #71: loss=0.013826786424398054
Epoch #72: loss=0.014375575703335149
Epoch #73: loss=0.013169896402229955
Epoch #74: loss=0.01373025942567645
Epoch #75: loss=0.01690703405742475
Epoch #76: loss=0.012031295365813821
Epoch #77: loss=0.012124684904297424
Epoch #78: loss=0.01189532141003185
Epoch #79: loss=0.012083078372459526
Epoch #80: loss=0.014046067147911156
Epoch #81: loss=0.012268324863655203
Epoch #82: loss=0.012751010948871946
Epoch #83: loss=0.012277401482675507
Epoch #84: loss=0.010733511344179665
Epoch #85: loss=0.01768651866876215
Epoch #86: loss=0.014514850071396402
Epoch #87: loss=0.012271190231828192
Epoch #88: loss=0.013631035524739245
Epoch #89: loss=0.009481589708766303
Epoch #90: loss=0.01085037486133638
Epoch #91: loss=0.011533054718386915
Epoch #92: loss=0.01611885034036492
Epoch #93: loss=0.012866351426158523
Epoch #94: loss=0.010844362090680343
Epoch #95: loss=0.00932038859516017
Epoch #96: loss=0.012939301569659788
Epoch #97: loss=0.010139836312090564
Epoch #98: loss=0.010874703147429828
Epoch #99: loss=0.011702624230075483
Epoch #100: loss=0.009909677922263906
Epoch #101: loss=0.012400083345011272
Epoch #102: loss=0.010274330960503602
Epoch #103: loss=0.010126115798327952
Epoch #104: loss=0.015275960448707642
Epoch #105: loss=0.010924757673278095
Epoch #106: loss=0.016178180540006595
Epoch #107: loss=0.009074036570649759
Epoch #108: loss=0.009471716912607344
Epoch #109: loss=0.011210084174123563
Epoch #110: loss=0.011551253058477973
Epoch #111: loss=0.010946551160370455
Epoch #112: loss=0.013771815602324317
Epoch #113: loss=0.009068576611345828
Epoch #114: loss=0.009093188973035354
Epoch #115: loss=0.012792709344765464
Epoch #116: loss=0.011624739073437102
Epoch #117: loss=0.009182982734724865
Epoch #118: loss=0.013771789977191803
Epoch #119: loss=0.014466951933311867
Epoch #120: loss=0.008395489394080554
Epoch #121: loss=0.010476187014409711
Epoch #122: loss=0.012568864494650847
Epoch #123: loss=0.01082000378438088
Epoch #124: loss=0.008495020287130561
Epoch #125: loss=0.017372404901500355
Epoch #126: loss=0.01559394462240386
Epoch #127: loss=0.009120968380804255
Epoch #128: loss=0.012610550981680003
Epoch #129: loss=0.0075630258755837575
Epoch #130: loss=0.013882456953749048
Epoch #131: loss=0.010834122004770633
Epoch #132: loss=0.012863963254236865
Epoch #133: loss=0.00782327032670639
Epoch #134: loss=0.009005734960158778
Epoch #135: loss=0.0088782357513691
Epoch #136: loss=0.012967134283829493
Epoch #137: loss=0.011400245151567815
Epoch #138: loss=0.006907443918848118
Epoch #139: loss=0.009134975716210476
Epoch #140: loss=0.01915092112455356
Epoch #141: loss=0.011224684943025854
Epoch #142: loss=0.009057163167680899
Epoch #143: loss=0.008788349734755516
Epoch #144: loss=0.013837347518889593
Epoch #145: loss=0.008415131219349562
Epoch #146: loss=0.01022039862784023
Epoch #147: loss=0.009568275828874635
Epoch #148: loss=0.010740532919234911
Epoch #149: loss=0.012614333010357906
Epoch #150: loss=0.011399963335117069
Epoch #151: loss=0.007586215495913555
Epoch #152: loss=0.010671899244037544
Epoch #153: loss=0.010353191604795177
Epoch #154: loss=0.014983162461000408
Epoch #155: loss=0.013151061615428936
Epoch #156: loss=0.008041591022904039
Epoch #157: loss=0.011362151554072298
Epoch #158: loss=0.009665454169211104
Epoch #159: loss=0.009605481953135188
Epoch #160: loss=0.009491093161695037
Epoch #161: loss=0.009052352888300945
Epoch #162: loss=0.009955210322112752
Epoch #163: loss=0.011122574254856507
Epoch #164: loss=0.011269893125856937
Epoch #165: loss=0.008074015264104955
Epoch #166: loss=0.007326408229004355
Epoch #167: loss=0.01395493498793278
Epoch #168: loss=0.008928097313458686
Epoch #169: loss=0.008414836269521789
Epoch #170: loss=0.008441004755073473
Epoch #171: loss=0.011239991646548679
Epoch #172: loss=0.010250395053344125
Epoch #173: loss=0.007356218156004731
Epoch #174: loss=0.008470745189472578
Epoch #175: loss=0.01042977482453047
Epoch #176: loss=0.010092584253111313
Epoch #177: loss=0.009844899528523528
Epoch #178: loss=0.015891803797811375
Epoch #179: loss=0.012652869049979577
Epoch #180: loss=0.006727216751085176
Epoch #181: loss=0.008544511698974072
Epoch #182: loss=0.008483568839425637
Epoch #183: loss=0.006707482029759115
Epoch #184: loss=0.010094279776309903
Epoch #185: loss=0.010096240742112617
Epoch #186: loss=0.009314047558808021
Epoch #187: loss=0.012599012744717543
Epoch #188: loss=0.010723262729747423
Epoch #189: loss=0.010282030345836255
Epoch #190: loss=0.009303665059850509
Epoch #191: loss=0.013711386133998664
Epoch #192: loss=0.00844703153152242
Epoch #193: loss=0.008252673734254406
Epoch #194: loss=0.007006160530092762
Epoch #195: loss=0.011496341543859272
Epoch #196: loss=0.006779678834540917
Epoch #197: loss=0.020738128313381687
Epoch #198: loss=0.012912298256450442
Epoch #199: loss=0.015499282988551924
Epoch #200: loss=0.017120869381220212
Epoch #201: loss=0.007729631208567845
Epoch #202: loss=0.008367909613176683
Epoch #203: loss=0.007892813903548564
Epoch #204: loss=0.009609640362565916
Epoch #205: loss=0.0076714044722453
Epoch #206: loss=0.011828700837955123
Epoch #207: loss=0.008802680769678155
Epoch #208: loss=0.00874598488936091
Epoch #209: loss=0.007342575749601875
Epoch #210: loss=0.014180283536039427
Epoch #211: loss=0.006631570512091596
Epoch #212: loss=0.007798426682334712
Epoch #213: loss=0.01215805545247305
Epoch #214: loss=0.006910572444302866
Epoch #215: loss=0.00984901182174959
Epoch #216: loss=0.01010133397769822
Epoch #217: loss=0.008438786892473365
Epoch #218: loss=0.0076455148645692625
Epoch #219: loss=0.009332546047577883
Epoch #220: loss=0.007598371853971322
Epoch #221: loss=0.006978442963240592
Epoch #222: loss=0.01290297579328952
Epoch #223: loss=0.006956528014685385
Epoch #224: loss=0.008519093728258821
Epoch #225: loss=0.009292900645490326
Epoch #226: loss=0.007515545913759668
Epoch #227: loss=0.008740245306508132
Epoch #228: loss=0.011037742033558113
Epoch #229: loss=0.007267421505922306
Epoch #230: loss=0.006795766974434431
Epoch #231: loss=0.013801349158368998
Epoch #232: loss=0.006877643382069775
Epoch #233: loss=0.007067534247260561
Epoch #234: loss=0.00793541904336383
Epoch #235: loss=0.017404001637392287
Epoch #236: loss=0.00850711831195788
Epoch #237: loss=0.007280485073587425
Epoch #238: loss=0.007902326185593526
Epoch #239: loss=0.008137870914749268
Epoch #240: loss=0.007892470726576645
Epoch #241: loss=0.011477289135512311
Epoch #242: loss=0.005989414748387599
Epoch #243: loss=0.012420452507910082
Epoch #244: loss=0.0068715177922081296
Epoch #245: loss=0.008894554901087237
Epoch #246: loss=0.006634678351302859
Epoch #247: loss=0.008905733307001553
Epoch #248: loss=0.009643458142897438
Epoch #249: loss=0.006456451428273851

Training time: 4:58:59.073482

Finished.
n2one setting etth1_etth2_electricity_traffic -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_electricity_traffic_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_etth2_electricity_traffic', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.13826e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.33988e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.5951e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.13826e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4654599756759935, 'MAE': 0.5105346099212701}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_electricity_traffic -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_electricity_traffic_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_etth2_electricity_traffic', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
Evaluation result: {'MSE': 0.23030069923297397, 'MAE': 0.32459471586267585}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_electricity_weather', random_seed=2023, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_electricity_weather_epochs_250_seed_2023
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.6705880049523225
Epoch #1: loss=0.7437204485784937
Epoch #2: loss=0.5484690151056094
Epoch #3: loss=0.444515660859211
Epoch #4: loss=0.381551392520894
Epoch #5: loss=0.32983304007066583
Epoch #6: loss=0.3096502786940815
Epoch #7: loss=0.2794689691504283
Epoch #8: loss=0.2539087812573626
Epoch #9: loss=0.20946785204958718
Epoch #10: loss=0.1985509081477934
Epoch #11: loss=0.1812338554132678
Epoch #12: loss=0.16082978501420603
Epoch #13: loss=0.15346129393395955
Epoch #14: loss=0.1580278995315289
Epoch #15: loss=0.13669578930223747
Epoch #16: loss=0.12924452618259802
Epoch #17: loss=0.12659823672634413
Epoch #18: loss=0.12259005854251973
Epoch #19: loss=0.11272689228015759
Epoch #20: loss=0.09229550900716861
Epoch #21: loss=0.09107919648764372
Epoch #22: loss=0.0904813249907624
Epoch #23: loss=0.06876309761400863
Epoch #24: loss=0.07048191928622052
Epoch #25: loss=0.0542654109076491
Epoch #26: loss=0.09149893831559702
Epoch #27: loss=0.0629589122634928
Epoch #28: loss=0.054181729109281894
Epoch #29: loss=0.05092897584372899
Epoch #30: loss=0.08643688266152655
Epoch #31: loss=0.05947085092272455
Epoch #32: loss=0.08108419805269823
Epoch #33: loss=0.05201279025375224
Epoch #34: loss=0.04245662894499826
Epoch #35: loss=0.046222160513566965
Epoch #36: loss=0.04835756774217798
Epoch #37: loss=0.050020182838694416
Epoch #38: loss=0.05321633768489796
Epoch #39: loss=0.05270346128601075
Epoch #40: loss=0.038466492595558684
Epoch #41: loss=0.04367758289245254
Epoch #42: loss=0.03964517228408534
Epoch #43: loss=0.04514398091599098
Epoch #44: loss=0.04821079124637216
Epoch #45: loss=0.052973581521212024
Epoch #46: loss=0.04316356662632459
Epoch #47: loss=0.035067938866707754
Epoch #48: loss=0.04241689645564003
Epoch #49: loss=0.05284187869927291
Epoch #50: loss=0.04291098607237092
Epoch #51: loss=0.04423898015780132
Epoch #52: loss=0.034232782799146884
Epoch #53: loss=0.028258591672661006
Epoch #54: loss=0.028782198930525547
Epoch #55: loss=0.04739273615230463
Epoch #56: loss=0.035868133395688395
Epoch #57: loss=0.031886949908527494
Epoch #58: loss=0.026492101659835766
Epoch #59: loss=0.028210558105902513
Epoch #60: loss=0.031220829283297474
Epoch #61: loss=0.03816610377751435
Epoch #62: loss=0.037513830177898715
Epoch #63: loss=0.0274802522451315
Epoch #64: loss=0.027497924563418197
Epoch #65: loss=0.034374657368230685
Epoch #66: loss=0.027375522309880693
Epoch #67: loss=0.03570647361295535
Epoch #68: loss=0.04071735529779841
Epoch #69: loss=0.028163639203596273
Epoch #70: loss=0.027389316768656354
Epoch #71: loss=0.05125452710736099
Epoch #72: loss=0.028100401154071752
Epoch #73: loss=0.022434571483482057
Epoch #74: loss=0.02429300760869659
Epoch #75: loss=0.025490446827068688
Epoch #76: loss=0.026078824618175997
Epoch #77: loss=0.021321741829579827
Epoch #78: loss=0.029247770418649684
Epoch #79: loss=0.026941918142699736
Epoch #80: loss=0.029491832170253647
Epoch #81: loss=0.018826604195176483
Epoch #82: loss=0.020819936348660657
Epoch #83: loss=0.01738769095391035
Epoch #84: loss=0.024724268624713837
Epoch #85: loss=0.019702760635557846
Epoch #86: loss=0.023092263967374085
Epoch #87: loss=0.033977376914020745
Epoch #88: loss=0.020858302606989492
Epoch #89: loss=0.040932345199863066
Epoch #90: loss=0.02093288100129793
Epoch #91: loss=0.031706645365654804
Epoch #92: loss=0.016043960645026077
Epoch #93: loss=0.01573607495371923
Epoch #94: loss=0.014570363694376252
Epoch #95: loss=0.017439867663771234
Epoch #96: loss=0.034448329129364665
Epoch #97: loss=0.02202228549255156
Epoch #98: loss=0.03240462575092334
Epoch #99: loss=0.022864824655456754
Epoch #100: loss=0.02972683555674236
Epoch #101: loss=0.01596337533362437
Epoch #102: loss=0.021640614785577772
Epoch #103: loss=0.019845915508909292
Epoch #104: loss=0.01878252619338271
Epoch #105: loss=0.020689951765597372
Epoch #106: loss=0.019161721945764792
Epoch #107: loss=0.02077382302957837
Epoch #108: loss=0.016860098777489785
Epoch #109: loss=0.03979025086097115
Epoch #110: loss=0.026272870505414388
Epoch #111: loss=0.023876869967826474
Epoch #112: loss=0.016837794142949378
Epoch #113: loss=0.03654990944359322
Epoch #114: loss=0.027561603469865713
Epoch #115: loss=0.018359717390231706
Epoch #116: loss=0.024113686532788288
Epoch #117: loss=0.02153965882641596
Epoch #118: loss=0.021821909393519266
Epoch #119: loss=0.020319096404166473
Epoch #120: loss=0.014178635480370594
Epoch #121: loss=0.01588790223290731
Epoch #122: loss=0.01480533009416932
Epoch #123: loss=0.014133804868919636
Epoch #124: loss=0.022900080934735764
Epoch #125: loss=0.01793016849822233
Epoch #126: loss=0.015176712255892693
Epoch #127: loss=0.016735997641300446
Epoch #128: loss=0.0433164232004488
Epoch #129: loss=0.023458665750057815
Epoch #130: loss=0.023580400869792063
Epoch #131: loss=0.01386615490299647
Epoch #132: loss=0.012355925543511085
Epoch #133: loss=0.017143702417143834
Epoch #134: loss=0.013433321299311289
Epoch #135: loss=0.020645312959192207
Epoch #136: loss=0.020812050722232425
Epoch #137: loss=0.017417646766675073
Epoch #138: loss=0.015326130622643153
Epoch #139: loss=0.01663370299752198
Epoch #140: loss=0.014055880431812695
Epoch #141: loss=0.014728713337715117
Epoch #142: loss=0.011249234057721678
Epoch #143: loss=0.02595059904563331
Epoch #144: loss=0.01999818895135005
Epoch #145: loss=0.021801132086885014
Epoch #146: loss=0.02038698706569751
Epoch #147: loss=0.01585216464592825
Epoch #148: loss=0.014595929499382767
Epoch #149: loss=0.01911363602734243
Epoch #150: loss=0.012665461463604762
Epoch #151: loss=0.01724988747216565
Epoch #152: loss=0.018513500994962056
Epoch #153: loss=0.03552286343444577
Epoch #154: loss=0.0605382271929466
Epoch #155: loss=0.017486567058538568
Epoch #156: loss=0.010747027660009303
Epoch #157: loss=0.013163112161501758
Epoch #158: loss=0.015743838942985738
Epoch #159: loss=0.014314219086312294
Epoch #160: loss=0.01130835007216041
Epoch #161: loss=0.010811049012122856
Epoch #162: loss=0.01563556425627663
Epoch #163: loss=0.020082613333790123
Epoch #164: loss=0.012062539342485131
Epoch #165: loss=0.02034694086689337
Epoch #166: loss=0.029781982237202246
Epoch #167: loss=0.012636900842034999
Epoch #168: loss=0.009075728034338761
Epoch #169: loss=0.012787484529784846
Epoch #170: loss=0.011308932307026662
Epoch #171: loss=0.02794181396349506
Epoch #172: loss=0.030544501916992987
Epoch #173: loss=0.029813731148731933
Epoch #174: loss=0.03784112934406248
Epoch #175: loss=0.01905801642664845
Epoch #176: loss=0.013327293006227276
Epoch #177: loss=0.014414272664522448
Epoch #178: loss=0.011661895349398616
Epoch #179: loss=0.017018888928344435
Epoch #180: loss=0.011264824599009574
Epoch #181: loss=0.011589680348733863
Epoch #182: loss=0.011765333404313062
Epoch #183: loss=0.015387311060548907
Epoch #184: loss=0.01581096940924737
Epoch #185: loss=0.02238303496243711
Epoch #186: loss=0.011172506504274848
Epoch #187: loss=0.014288771863049025
Epoch #188: loss=0.013131900173560342
Epoch #189: loss=0.015521692344273887
Epoch #190: loss=0.01701943325623741
Epoch #191: loss=0.011012526450487153
Epoch #192: loss=0.014074399784514345
Epoch #193: loss=0.011619863550290285
Epoch #194: loss=0.01278508735325775
Epoch #195: loss=0.010596387927553299
Epoch #196: loss=0.0165480878605595
Epoch #197: loss=0.01389551297355175
Epoch #198: loss=0.014456720825044794
Epoch #199: loss=0.013158662778946475
Epoch #200: loss=0.012675683880518282
Epoch #201: loss=0.01172400006440396
Epoch #202: loss=0.015408799913260374
Epoch #203: loss=0.009514178790411993
Epoch #204: loss=0.014289992507044071
Epoch #205: loss=0.010244715867329961
Epoch #206: loss=0.013670157496056356
Epoch #207: loss=0.013114286528434604
Epoch #208: loss=0.015627784001959587
Epoch #209: loss=0.010611760509045604
Epoch #210: loss=0.015784685527054473
Epoch #211: loss=0.014853796966495173
Epoch #212: loss=0.01295584130408552
Epoch #213: loss=0.011022016009811822
Epoch #214: loss=0.017895301916814536
Epoch #215: loss=0.010243200918709875
Epoch #216: loss=0.011527293471205423
Epoch #217: loss=0.00888593984021898
Epoch #218: loss=0.01946714827342609
Epoch #219: loss=0.01576318707409988
Epoch #220: loss=0.012576005313870526
Epoch #221: loss=0.01057704795752407
Epoch #222: loss=0.010199484194856565
Epoch #223: loss=0.010664118656055316
Epoch #224: loss=0.009789329162044863
Epoch #225: loss=0.02102619459384335
Epoch #226: loss=0.01813558005702674
Epoch #227: loss=0.012479925053477947
Epoch #228: loss=0.013435608800887608
Epoch #229: loss=0.01107150766259405
Epoch #230: loss=0.01146130262487252
Epoch #231: loss=0.027577679704502613
Epoch #232: loss=0.02404627010816066
Epoch #233: loss=0.015249411549375307
Epoch #234: loss=0.01755540939841234
Epoch #235: loss=0.00711939971591862
Epoch #236: loss=0.010852384125874146
Epoch #237: loss=0.011538482280970496
Epoch #238: loss=0.010145114783060264
Epoch #239: loss=0.015057162507637107
Epoch #240: loss=0.012131365172505647
Epoch #241: loss=0.010497788068905493
Epoch #242: loss=0.014498022462901146
Epoch #243: loss=0.012936242109866313
Epoch #244: loss=0.012103837334139432
Epoch #245: loss=0.015336863173109316
Epoch #246: loss=0.012277211038504762
Epoch #247: loss=0.007828979314525948
Epoch #248: loss=0.012609872324463145
Epoch #249: loss=0.011004857261828985

Training time: 1:43:12.738431

Finished.
n2one setting etth1_etth2_electricity_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_electricity_weather_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_etth2_electricity_weather', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.72767e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.23466879445661074, 'MAE': 0.3345116744933521}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_electricity_exchange', random_seed=2023, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_electricity_exchange_epochs_250_seed_2023
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.6036067022874125
Epoch #1: loss=0.6387899019280259
Epoch #2: loss=0.48422061836580493
Epoch #3: loss=0.3649295933392583
Epoch #4: loss=0.32458407890171076
Epoch #5: loss=0.2804893736371841
Epoch #6: loss=0.26095356516344553
Epoch #7: loss=0.250118249055248
Epoch #8: loss=0.2025015134983438
Epoch #9: loss=0.1776873596859743
Epoch #10: loss=0.173945510211474
Epoch #11: loss=0.1633548124777506
Epoch #12: loss=0.1362621315887996
Epoch #13: loss=0.13608123279521486
Epoch #14: loss=0.11750292638995558
Epoch #15: loss=0.10589036651759384
Epoch #16: loss=0.0900543192157158
Epoch #17: loss=0.10111201421490737
Epoch #18: loss=0.10203719890673724
Epoch #19: loss=0.099266126719317
Epoch #20: loss=0.09143945537018794
Epoch #21: loss=0.09384637487286555
Epoch #22: loss=0.07235450025799932
Epoch #23: loss=0.0731899834973819
Epoch #24: loss=0.07425356419816743
Epoch #25: loss=0.06486486075527466
Epoch #26: loss=0.0632186496953423
Epoch #27: loss=0.0556964002557794
Epoch #28: loss=0.05354773495807896
Epoch #29: loss=0.05695310019570302
Epoch #30: loss=0.06462520563095243
Epoch #31: loss=0.050196033214156464
Epoch #32: loss=0.043235318170474844
Epoch #33: loss=0.057625942854020666
Epoch #34: loss=0.042556602172499236
Epoch #35: loss=0.04963558386202152
Epoch #36: loss=0.047413207617732246
Epoch #37: loss=0.04899580681115476
Epoch #38: loss=0.044644118890128266
Epoch #39: loss=0.05185698947744341
Epoch #40: loss=0.041314541310636714
Epoch #41: loss=0.0451727564271496
Epoch #42: loss=0.054899842225479466
Epoch #43: loss=0.04355083818346501
Epoch #44: loss=0.047754463568633915
Epoch #45: loss=0.042080506061966755
Epoch #46: loss=0.035386683277476245
Epoch #47: loss=0.03915758645053377
Epoch #48: loss=0.03077854884587467
Epoch #49: loss=0.044994326173287136
Epoch #50: loss=0.04628377700083327
Epoch #51: loss=0.03253895118723979
Epoch #52: loss=0.03816921002151439
Epoch #53: loss=0.028081968932075877
Epoch #54: loss=0.03720396673496889
Epoch #55: loss=0.0473621444268907
Epoch #56: loss=0.0480687544241944
Epoch #57: loss=0.05639032646470619
Epoch #58: loss=0.054928014314198546
Epoch #59: loss=0.03414058669215019
Epoch #60: loss=0.02846640280044689
Epoch #61: loss=0.037401400758333654
Epoch #62: loss=0.02584657815940754
Epoch #63: loss=0.04107438012483766
Epoch #64: loss=0.04240721622963895
Epoch #65: loss=0.03983842276319123
Epoch #66: loss=0.03727734593522488
Epoch #67: loss=0.04323472678030056
Epoch #68: loss=0.03732511966690182
Epoch #69: loss=0.026476403292398844
Epoch #70: loss=0.04024462429731921
Epoch #71: loss=0.021887861805867524
Epoch #72: loss=0.03200589048909702
Epoch #73: loss=0.0289281368477585
Epoch #74: loss=0.02627811998413311
Epoch #75: loss=0.03683825436118805
Epoch #76: loss=0.036022624176039034
Epoch #77: loss=0.047656214746793206
Epoch #78: loss=0.032080832977423514
Epoch #79: loss=0.032374673881418674
Epoch #80: loss=0.03063171707010901
Epoch #81: loss=0.0339240164512296
Epoch #82: loss=0.04114849140946333
Epoch #83: loss=0.028221549244961393
Epoch #84: loss=0.020730611706137624
Epoch #85: loss=0.017284355221948187
Epoch #86: loss=0.02486349653052818
Epoch #87: loss=0.03404171313020012
Epoch #88: loss=0.06746403608266155
Epoch #89: loss=0.027171882991163118
Epoch #90: loss=0.03193750449472566
Epoch #91: loss=0.023026812184397023
Epoch #92: loss=0.023946440555684748
Epoch #93: loss=0.023126799870165658
Epoch #94: loss=0.02587485654974009
Epoch #95: loss=0.03543935975897514
Epoch #96: loss=0.031002011232936087
Epoch #97: loss=0.026970779712301062
Epoch #98: loss=0.025331587108454883
Epoch #99: loss=0.025244991889674183
Epoch #100: loss=0.03118981209698299
Epoch #101: loss=0.026267158301647633
Epoch #102: loss=0.0628726330331904
Epoch #103: loss=0.026831617583615745
Epoch #104: loss=0.02141318923903021
Epoch #105: loss=0.01601723900506729
Epoch #106: loss=0.019291954501443772
Epoch #107: loss=0.014794590764844644
Epoch #108: loss=0.017468405922103684
Epoch #109: loss=0.020006843595650133
Epoch #110: loss=0.02221767941005148
Epoch #111: loss=0.022699587818394
Epoch #112: loss=0.022858242122130605
Epoch #113: loss=0.018743992804002515
Epoch #114: loss=0.03424061831757535
Epoch #115: loss=0.019534057446785335
Epoch #116: loss=0.026295394713565456
Epoch #117: loss=0.02186008169941615
Epoch #118: loss=0.021558042347693204
Epoch #119: loss=0.016703318912263027
Epoch #120: loss=0.028900863777550138
Epoch #121: loss=0.01928686784646873
Epoch #122: loss=0.019767708664199298
Epoch #123: loss=0.02943899296190177
Epoch #124: loss=0.02686198592340742
Epoch #125: loss=0.03252843543856592
Epoch #126: loss=0.02632176563053449
Epoch #127: loss=0.016877688679290234
Epoch #128: loss=0.018533152511137
Epoch #129: loss=0.022428808036347194
Epoch #130: loss=0.023112656604111704
Epoch #131: loss=0.023236482583037944
Epoch #132: loss=0.027006717010824764
Epoch #133: loss=0.016557002519515314
Epoch #134: loss=0.014759221144509976
Epoch #135: loss=0.017234816217459682
Epoch #136: loss=0.02195052661574595
Epoch #137: loss=0.021391952363163255
Epoch #138: loss=0.014449643988519332
Epoch #139: loss=0.023157283907950348
Epoch #140: loss=0.015977362378699973
Epoch #141: loss=0.02346461031361247
Epoch #142: loss=0.02515665226306769
Epoch #143: loss=0.03875908741772273
Epoch #144: loss=0.022606161248404533
Epoch #145: loss=0.028721268315943443
Epoch #146: loss=0.01453869385558585
Epoch #147: loss=0.012377345316456876
Epoch #148: loss=0.012204050709922464
Epoch #149: loss=0.02311166627831491
Epoch #150: loss=0.02039306141410984
Epoch #151: loss=0.020636125798381283
Epoch #152: loss=0.021802526961811126
Epoch #153: loss=0.021982878182692938
Epoch #154: loss=0.027740403216463885
Epoch #155: loss=0.01764731434528219
Epoch #156: loss=0.020318191086821823
Epoch #157: loss=0.015108144763855769
Epoch #158: loss=0.01804891923094934
Epoch #159: loss=0.012568242260751806
Epoch #160: loss=0.023824746603738116
Epoch #161: loss=0.01355221073154045
Epoch #162: loss=0.029477998986297202
Epoch #163: loss=0.027036539111938054
Epoch #164: loss=0.020815323144278922
Epoch #165: loss=0.01763984925774097
Epoch #166: loss=0.01851761026680266
Epoch #167: loss=0.017491610866866777
Epoch #168: loss=0.027771039702997435
Epoch #169: loss=0.0250509297291941
Epoch #170: loss=0.011402636909407344
Epoch #171: loss=0.02082034010364085
Epoch #172: loss=0.0165260882057798
Epoch #173: loss=0.009856843975295907
Epoch #174: loss=0.013312829983791977
Epoch #175: loss=0.01826715221782636
Epoch #176: loss=0.017070896293948954
Epoch #177: loss=0.013321855435699073
Epoch #178: loss=0.01845163619977289
Epoch #179: loss=0.018018464877798953
Epoch #180: loss=0.021703251744260736
Epoch #181: loss=0.017186868606008314
Epoch #182: loss=0.026591989788384267
Epoch #183: loss=0.018602118572171332
Epoch #184: loss=0.014406463654328995
Epoch #185: loss=0.016110501647519582
Epoch #186: loss=0.014612228333941218
Epoch #187: loss=0.017893862578292914
Epoch #188: loss=0.017850730193129934
Epoch #189: loss=0.0162757047438117
Epoch #190: loss=0.014637763792534873
Epoch #191: loss=0.022805075442354647
Epoch #192: loss=0.0181801527656775
Epoch #193: loss=0.017567189858341183
Epoch #194: loss=0.021459640718524076
Epoch #195: loss=0.02218898649801943
Epoch #196: loss=0.015733912518776073
Epoch #197: loss=0.011996473783576921
Epoch #198: loss=0.016027949052610308
Epoch #199: loss=0.02065437108294566
Epoch #200: loss=0.020253232628332434
Epoch #201: loss=0.02183966811015963
Epoch #202: loss=0.01670575321892293
Epoch #203: loss=0.01708114964689967
Epoch #204: loss=0.015177723650417342
Epoch #205: loss=0.01390091390574674
Epoch #206: loss=0.01937539104094631
Epoch #207: loss=0.020473479956989896
Epoch #208: loss=0.017726502679346084
Epoch #209: loss=0.02038601758559275
Epoch #210: loss=0.019545201878755764
Epoch #211: loss=0.014380551039196453
Epoch #212: loss=0.022739195364066496
Epoch #213: loss=0.009134375779674343
Epoch #214: loss=0.013871453538348318
Epoch #215: loss=0.01624042058428722
Epoch #216: loss=0.014068202632845925
Epoch #217: loss=0.012624737938815788
Epoch #218: loss=0.01983393062331711
Epoch #219: loss=0.014020496727688287
Epoch #220: loss=0.014795085681336266
Epoch #221: loss=0.01787281223761499
Epoch #222: loss=0.018890624924436612
Epoch #223: loss=0.022137289657817513
Epoch #224: loss=0.013718734551003914
Epoch #225: loss=0.011624125128156443
Epoch #226: loss=0.015630300284218065
Epoch #227: loss=0.012621461373242026
Epoch #228: loss=0.017176034953988242
Epoch #229: loss=0.010282994402719644
Epoch #230: loss=0.011599083461441674
Epoch #231: loss=0.02142229104352132
Epoch #232: loss=0.01342489257381561
Epoch #233: loss=0.013055531488447762
Epoch #234: loss=0.021539397516156175
Epoch #235: loss=0.015501712948157189
Epoch #236: loss=0.01709220837071978
Epoch #237: loss=0.026807598904238162
Epoch #238: loss=0.02072170467092859
Epoch #239: loss=0.011829904106828458
Epoch #240: loss=0.013495048657385496
Epoch #241: loss=0.014229807112625266
Epoch #242: loss=0.011322161056248623
Epoch #243: loss=0.019558921593371047
Epoch #244: loss=0.02063872271866345
Epoch #245: loss=0.017861875464105247
Epoch #246: loss=0.014572605641464412
Epoch #247: loss=0.027648699679106485
Epoch #248: loss=0.015657994728677963
Epoch #249: loss=0.015119185859663955

Training time: 1:33:45.907711

Finished.
n2one setting etth1_etth2_electricity_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_electricity_exchange_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_etth2_electricity_exchange', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.20261e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.52289e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.20261e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.6180719357546511, 'MAE': 0.6040611263367923}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_traffic_weather', random_seed=2023, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_traffic_weather_epochs_250_seed_2023
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.0276960569976967
Epoch #1: loss=0.3902577555628944
Epoch #2: loss=0.28830912112033286
Epoch #3: loss=0.22863273984213625
Epoch #4: loss=0.18834604889550918
Epoch #5: loss=0.1515856560427043
Epoch #6: loss=0.14118204252823296
Epoch #7: loss=0.11173176470557496
Epoch #8: loss=0.09676690411520605
Epoch #9: loss=0.08335154861038316
Epoch #10: loss=0.07815022240165712
Epoch #11: loss=0.06486513746278712
Epoch #12: loss=0.07130045118326622
Epoch #13: loss=0.07392240051043833
Epoch #14: loss=0.057388164637096124
Epoch #15: loss=0.052737844344631184
Epoch #16: loss=0.06015822312489003
Epoch #17: loss=0.053584838527907304
Epoch #18: loss=0.04185578513228667
Epoch #19: loss=0.046629744707327954
Epoch #20: loss=0.043243398610605735
Epoch #21: loss=0.04272563407673065
Epoch #22: loss=0.04772845127603283
Epoch #23: loss=0.04512838820527781
Epoch #24: loss=0.02781370105575502
Epoch #25: loss=0.03272047304166811
Epoch #26: loss=0.037388140345616945
Epoch #27: loss=0.028746495461282412
Epoch #28: loss=0.030287041593298623
Epoch #29: loss=0.03441148310432008
Epoch #30: loss=0.031309010472072255
Epoch #31: loss=0.02644241627441521
Epoch #32: loss=0.03740608592790256
Epoch #33: loss=0.04765777525343848
Epoch #34: loss=0.03088757347151897
Epoch #35: loss=0.025373037347140023
Epoch #36: loss=0.028145175485083412
Epoch #37: loss=0.02967503549055632
Epoch #38: loss=0.026524825737798203
Epoch #39: loss=0.02511458212470774
Epoch #40: loss=0.023982709720901146
Epoch #41: loss=0.025417226206789004
Epoch #42: loss=0.023331066759245393
Epoch #43: loss=0.03018916609983307
Epoch #44: loss=0.022163360457719734
Epoch #45: loss=0.02624796309694622
Epoch #46: loss=0.026534575624445642
Epoch #47: loss=0.02040675467303789
Epoch #48: loss=0.018674760909380386
Epoch #49: loss=0.020696555462471226
Epoch #50: loss=0.022426193656437016
Epoch #51: loss=0.0403924943451272
Epoch #52: loss=0.030116443433865964
Epoch #53: loss=0.018968074437772375
Epoch #54: loss=0.023265482786257632
Epoch #55: loss=0.019316484699022654
Epoch #56: loss=0.021414102907919792
Epoch #57: loss=0.019167378607080596
Epoch #58: loss=0.020806310775892668
Epoch #59: loss=0.023732938472039073
Epoch #60: loss=0.02629990977461774
Epoch #61: loss=0.028064103192028213
Epoch #62: loss=0.016532308311357026
Epoch #63: loss=0.02379861763333117
Epoch #64: loss=0.015766702603327163
Epoch #65: loss=0.018241186943913173
Epoch #66: loss=0.03048445851213718
Epoch #67: loss=0.01508305552960198
Epoch #68: loss=0.026432259091760234
Epoch #69: loss=0.018959395541239554
Epoch #70: loss=0.01799980975726739
Epoch #71: loss=0.023301986494276335
Epoch #72: loss=0.028703618834302152
Epoch #73: loss=0.020614402498244547
Epoch #74: loss=0.013164815928162583
Epoch #75: loss=0.019762161709437922
Epoch #76: loss=0.018444217398664357
Epoch #77: loss=0.014026172872096612
Epoch #78: loss=0.022995904251059855
Epoch #79: loss=0.01943572070679324
Epoch #80: loss=0.014534945450827712
Epoch #81: loss=0.014850574306310711
Epoch #82: loss=0.0206947203789721
Epoch #83: loss=0.017205310891842636
Epoch #84: loss=0.015143168838252005
Epoch #85: loss=0.020181039203887086
Epoch #86: loss=0.025671111566574464
Epoch #87: loss=0.01716941573020554
Epoch #88: loss=0.017513589864473662
Epoch #89: loss=0.011855501890391062
Epoch #90: loss=0.016593782913925575
Epoch #91: loss=0.01801279497948762
Epoch #92: loss=0.01883972240742265
Epoch #93: loss=0.015366788913339414
Epoch #94: loss=0.015765679073541945
Epoch #95: loss=0.016294538664235064
Epoch #96: loss=0.015728497139812305
Epoch #97: loss=0.01991418668687418
Epoch #98: loss=0.01866196451468358
Epoch #99: loss=0.015474709541566963
Epoch #100: loss=0.01747668404382511
Epoch #101: loss=0.01604900457038665
Epoch #102: loss=0.013541476645322615
Epoch #103: loss=0.021131863448838033
Epoch #104: loss=0.016743555286989037
Epoch #105: loss=0.01644054215894821
Epoch #106: loss=0.015505025431228813
Epoch #107: loss=0.013820546996362332
Epoch #108: loss=0.010937142546131599
Epoch #109: loss=0.014494343334176533
Epoch #110: loss=0.020611250727964534
Epoch #111: loss=0.01596365531950625
Epoch #112: loss=0.02067360954268571
Epoch #113: loss=0.013616869519814433
Epoch #114: loss=0.014256048171061861
Epoch #115: loss=0.014800649970700705
Epoch #116: loss=0.016272829940570714
Epoch #117: loss=0.015554974481347017
Epoch #118: loss=0.011837565074698662
Epoch #119: loss=0.02071893038952846
Epoch #120: loss=0.012782423734624133
Epoch #121: loss=0.012889664793267542
Epoch #122: loss=0.015230955553163377
Epoch #123: loss=0.009365288709297093
Epoch #124: loss=0.014400171228312008
Epoch #125: loss=0.020397502418283912
Epoch #126: loss=0.015251041998713874
Epoch #127: loss=0.011867787853655656
Epoch #128: loss=0.011301117012250917
Epoch #129: loss=0.017061171276674777
Epoch #130: loss=0.011552658496018522
Epoch #131: loss=0.016914486815441016
Epoch #132: loss=0.017803162585119478
Epoch #133: loss=0.010941948631260556
Epoch #134: loss=0.01576912694320843
Epoch #135: loss=0.013222209825390845
Epoch #136: loss=0.012487121968761917
Epoch #137: loss=0.010443915000879473
Epoch #138: loss=0.015877268110810284
Epoch #139: loss=0.014447171347425628
Epoch #140: loss=0.010929022924663518
Epoch #141: loss=0.01828381499620681
Epoch #142: loss=0.015167521115494666
Epoch #143: loss=0.011467236497774622
Epoch #144: loss=0.016469432726388553
Epoch #145: loss=0.012926640060632577
Epoch #146: loss=0.013507541282615622
Epoch #147: loss=0.011321297935852905
Epoch #148: loss=0.012037724279553347
Epoch #149: loss=0.012987529992075851
Epoch #150: loss=0.0129871992744413
Epoch #151: loss=0.015706740575968395
Epoch #152: loss=0.01447663675254663
Epoch #153: loss=0.011484197209147916
Epoch #154: loss=0.017682510683200533
Epoch #155: loss=0.013572661188476772
Epoch #156: loss=0.012887968185642038
Epoch #157: loss=0.0126917317098003
Epoch #158: loss=0.01213531947325339
Epoch #159: loss=0.015256255033701925
Epoch #160: loss=0.012315867899593375
Epoch #161: loss=0.014855544035099168
Epoch #162: loss=0.0071289574415501706
Epoch #163: loss=0.012454399904204577
Epoch #164: loss=0.015716576800806712
Epoch #165: loss=0.0110436407350362
Epoch #166: loss=0.011940215945686781
Epoch #167: loss=0.01084490299997202
Epoch #168: loss=0.017338597310622178
Epoch #169: loss=0.014844805918112006
Epoch #170: loss=0.01188757211829436
Epoch #171: loss=0.013866900755904311
Epoch #172: loss=0.009394961664413268
Epoch #173: loss=0.011820630865992911
Epoch #174: loss=0.013018011239392398
Epoch #175: loss=0.013069915656501256
Epoch #176: loss=0.009141473080939665
Epoch #177: loss=0.01174331370079291
Epoch #178: loss=0.011597099646238921
Epoch #179: loss=0.014324374172358104
Epoch #180: loss=0.013303353209988737
Epoch #181: loss=0.012207500457276069
Epoch #182: loss=0.012324350817199549
Epoch #183: loss=0.024999847278249825
Epoch #184: loss=0.01424094406563165
Epoch #185: loss=0.010999386148128974
Epoch #186: loss=0.013283541843179843
Epoch #187: loss=0.010838353001569247
Epoch #188: loss=0.012434185224597835
Epoch #189: loss=0.012099627871259927
Epoch #190: loss=0.01242266232014232
Epoch #191: loss=0.008212115111419551
Epoch #192: loss=0.01207776011016577
Epoch #193: loss=0.012451342591963644
Epoch #194: loss=0.017961476683210364
Epoch #195: loss=0.013316288263045387
Epoch #196: loss=0.01584082764796417
Epoch #197: loss=0.009256908822507973
Epoch #198: loss=0.009651449482700584
Epoch #199: loss=0.011910908931167393
Epoch #200: loss=0.010044086416239342
Epoch #201: loss=0.006584884427164417
Epoch #202: loss=0.017600786341853726
Epoch #203: loss=0.009432776426992476
Epoch #204: loss=0.019132089353024035
Epoch #205: loss=0.011175605899177375
Epoch #206: loss=0.008132168584223668
Epoch #207: loss=0.014249396270622154
Epoch #208: loss=0.022472139517686323
Epoch #209: loss=0.010337774394719682
Epoch #210: loss=0.009818263930331698
Epoch #211: loss=0.013851872697734443
Epoch #212: loss=0.015259198542698384
Epoch #213: loss=0.009983569016790341
Epoch #214: loss=0.013201348506277653
Epoch #215: loss=0.012797058596511417
Epoch #216: loss=0.010051130828276477
Epoch #217: loss=0.011078695020285547
Epoch #218: loss=0.009172208081892027
Epoch #219: loss=0.012409845295355012
Epoch #220: loss=0.014479576797305814
Epoch #221: loss=0.009208228869890632
Epoch #222: loss=0.011435834085709142
Epoch #223: loss=0.009246597622618417
Epoch #224: loss=0.012890804232784265
Epoch #225: loss=0.008634809611048734
Epoch #226: loss=0.012084670696614574
Epoch #227: loss=0.013079659322658675
Epoch #228: loss=0.0117880838638797
Epoch #229: loss=0.017231726020968473
Epoch #230: loss=0.013363916077392957
Epoch #231: loss=0.009031366359689888
Epoch #232: loss=0.00691443672203322
Epoch #233: loss=0.011212475446176493
Epoch #234: loss=0.014333884419662725
Epoch #235: loss=0.008414726692953064
Epoch #236: loss=0.01697879707697054
Epoch #237: loss=0.009043103903610435
Epoch #238: loss=0.00917510673096375
Epoch #239: loss=0.01357945846413064
Epoch #240: loss=0.008812033472085286
Epoch #241: loss=0.010318426000046108
Epoch #242: loss=0.014127505587838946
Epoch #243: loss=0.010984259672710613
Epoch #244: loss=0.01170853718319516
Epoch #245: loss=0.011664178666622303
Epoch #246: loss=0.009746098413365477
Epoch #247: loss=0.00988139788694676
Epoch #248: loss=0.009570503459513716
Epoch #249: loss=0.007165454915654226

Training time: 3:39:53.658769

Finished.
n2one setting etth1_etth2_traffic_weather -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_traffic_weather_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_etth2_traffic_weather', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.10592e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.67429e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.25275e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.10592e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.42886630774604106, 'MAE': 0.4681055037285442}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_traffic_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_traffic_weather_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_etth2_traffic_weather', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.53502e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.480102999362091, 'MAE': 0.44936304653087134}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_traffic_exchange', random_seed=2023, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_traffic_exchange_epochs_250_seed_2023
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.9904177655461687
Epoch #1: loss=0.36139537984024883
Epoch #2: loss=0.25975229394752786
Epoch #3: loss=0.21217183122301803
Epoch #4: loss=0.1620045414792871
Epoch #5: loss=0.12650622426199293
Epoch #6: loss=0.10988624767522534
Epoch #7: loss=0.09508296679831806
Epoch #8: loss=0.07951846588834935
Epoch #9: loss=0.08999437066553607
Epoch #10: loss=0.06250957024865257
Epoch #11: loss=0.0667618066446468
Epoch #12: loss=0.05539607402986565
Epoch #13: loss=0.052998278851039304
Epoch #14: loss=0.0536998671106046
Epoch #15: loss=0.05078777663353873
Epoch #16: loss=0.05813814905088614
Epoch #17: loss=0.04322254322168978
Epoch #18: loss=0.05451403100152049
Epoch #19: loss=0.03614230541490246
Epoch #20: loss=0.04774976228716745
Epoch #21: loss=0.03559884170204089
Epoch #22: loss=0.03940837220889327
Epoch #23: loss=0.0308740945868468
Epoch #24: loss=0.03729355885442852
Epoch #25: loss=0.0344382719680924
Epoch #26: loss=0.042536754824713134
Epoch #27: loss=0.026587844942959776
Epoch #28: loss=0.030921535223787776
Epoch #29: loss=0.03123869537086146
Epoch #30: loss=0.03918946035955906
Epoch #31: loss=0.029869743273000873
Epoch #32: loss=0.026658952401580113
Epoch #33: loss=0.027157006141499455
Epoch #34: loss=0.0299979088221133
Epoch #35: loss=0.024958731971388235
Epoch #36: loss=0.028119920462431024
Epoch #37: loss=0.026126216201278134
Epoch #38: loss=0.025377331784351125
Epoch #39: loss=0.023212006102907114
Epoch #40: loss=0.02763987767467448
Epoch #41: loss=0.027055442037639772
Epoch #42: loss=0.02596631683451355
Epoch #43: loss=0.01976598100137541
Epoch #44: loss=0.027040390565631095
Epoch #45: loss=0.03757630383030341
Epoch #46: loss=0.027399343069578516
Epoch #47: loss=0.02231061075371848
Epoch #48: loss=0.022624928777686074
Epoch #49: loss=0.021426357748592695
Epoch #50: loss=0.017282261346386243
Epoch #51: loss=0.022060862781345104
Epoch #52: loss=0.03811864038835579
Epoch #53: loss=0.019052292125739948
Epoch #54: loss=0.01893969664636713
Epoch #55: loss=0.021873702044910605
Epoch #56: loss=0.020494765787539747
Epoch #57: loss=0.026996823609181063
Epoch #58: loss=0.02372548138001503
Epoch #59: loss=0.027116349053872554
Epoch #60: loss=0.019460565188324935
Epoch #61: loss=0.019106393679581387
Epoch #62: loss=0.02985327660912865
Epoch #63: loss=0.020277664817056337
Epoch #64: loss=0.02011902532690143
Epoch #65: loss=0.017225904190044734
Epoch #66: loss=0.022212081628773105
Epoch #67: loss=0.021115230557448714
Epoch #68: loss=0.0171340828773574
Epoch #69: loss=0.022070016583353513
Epoch #70: loss=0.023929368939495127
Epoch #71: loss=0.020448629619902403
Epoch #72: loss=0.02658967636292537
Epoch #73: loss=0.028345262335797212
Epoch #74: loss=0.017916035356269507
Epoch #75: loss=0.0192800478975376
Epoch #76: loss=0.01532361742520728
Epoch #77: loss=0.015060013140421635
Epoch #78: loss=0.01823179078453748
Epoch #79: loss=0.017701134901681844
Epoch #80: loss=0.015885005022978703
Epoch #81: loss=0.015215036893947992
Epoch #82: loss=0.016818494061497987
Epoch #83: loss=0.018120192777856918
Epoch #84: loss=0.01607235662886853
Epoch #85: loss=0.016578381190099384
Epoch #86: loss=0.020950028596104047
Epoch #87: loss=0.018923927718648113
Epoch #88: loss=0.01606421315339573
Epoch #89: loss=0.021828030409239762
Epoch #90: loss=0.022540528110989128
Epoch #91: loss=0.01798172614636475
Epoch #92: loss=0.018702165293964908
Epoch #93: loss=0.018068536613910877
Epoch #94: loss=0.016212235934841678
Epoch #95: loss=0.01645197965440707
Epoch #96: loss=0.011429694584078035
Epoch #97: loss=0.015307127744937829
Epoch #98: loss=0.015532279206402716
Epoch #99: loss=0.014443429716603569
Epoch #100: loss=0.01864841461150825
Epoch #101: loss=0.017838605605231754
Epoch #102: loss=0.019038181157774246
Epoch #103: loss=0.021157461862178303
Epoch #104: loss=0.014106549554711472
Epoch #105: loss=0.01824010193242051
Epoch #106: loss=0.016363174712783982
Epoch #107: loss=0.018232641799050927
Epoch #108: loss=0.012457108581171326
Epoch #109: loss=0.013630101020878279
Epoch #110: loss=0.014533220168907138
Epoch #111: loss=0.013377077365504805
Epoch #112: loss=0.014368635528019312
Epoch #113: loss=0.018530379745731077
Epoch #114: loss=0.024705889292801566
Epoch #115: loss=0.018348070839670175
Epoch #116: loss=0.013593164588797762
Epoch #117: loss=0.014222432910107819
Epoch #118: loss=0.012128810419943879
Epoch #119: loss=0.015276003099964275
Epoch #120: loss=0.011181029999818036
Epoch #121: loss=0.01783733794977151
Epoch #122: loss=0.023084320132309842
Epoch #123: loss=0.01667457115923358
Epoch #124: loss=0.016001203153273184
Epoch #125: loss=0.012803612873342722
Epoch #126: loss=0.013305529682276756
Epoch #127: loss=0.01124035230610364
Epoch #128: loss=0.018773236776349435
Epoch #129: loss=0.016138497411492817
Epoch #130: loss=0.01422644723979788
Epoch #131: loss=0.014406301186517343
Epoch #132: loss=0.01393084979984315
Epoch #133: loss=0.01592932899206786
Epoch #134: loss=0.012734492292205753
Epoch #135: loss=0.015423045085319814
Epoch #136: loss=0.01466678538506801
Epoch #137: loss=0.01848530460142992
Epoch #138: loss=0.011759952916139505
Epoch #139: loss=0.011807902340697018
Epoch #140: loss=0.015461233331849778
Epoch #141: loss=0.014167609918730626
Epoch #142: loss=0.01683389222050798
Epoch #143: loss=0.01251561785515422
Epoch #144: loss=0.01177792069454766
Epoch #145: loss=0.011951472343214154
Epoch #146: loss=0.0143372326865039
Epoch #147: loss=0.014059806490264047
Epoch #148: loss=0.011729456327497848
Epoch #149: loss=0.014697108644341162
Epoch #150: loss=0.011862171612258809
Epoch #151: loss=0.01119570864816997
Epoch #152: loss=0.014951041014028799
Epoch #153: loss=0.017416032168335215
Epoch #154: loss=0.015154724741737544
Epoch #155: loss=0.01213191625117867
Epoch #156: loss=0.011953144559844258
Epoch #157: loss=0.014961771938271744
Epoch #158: loss=0.010827086992457517
Epoch #159: loss=0.013600656216265107
Epoch #160: loss=0.01342352775317444
Epoch #161: loss=0.013907827210875452
Epoch #162: loss=0.01554903196366093
Epoch #163: loss=0.011533839701205662
Epoch #164: loss=0.017187978610440767
Epoch #165: loss=0.014482559278133016
Epoch #166: loss=0.014137166928916346
Epoch #167: loss=0.013870678305655151
Epoch #168: loss=0.02021863642848614
Epoch #169: loss=0.012807638010661206
Epoch #170: loss=0.00946928931631496
Epoch #171: loss=0.011678801659727817
Epoch #172: loss=0.01305835048328454
Epoch #173: loss=0.013466434131869104
Epoch #174: loss=0.012348655804698577
Epoch #175: loss=0.01720806306209078
Epoch #176: loss=0.01795070547596957
Epoch #177: loss=0.010168738572131863
Epoch #178: loss=0.012235621149001546
Epoch #179: loss=0.015279105705217242
Epoch #180: loss=0.013537072294038232
Epoch #181: loss=0.011694532398354263
Epoch #182: loss=0.011323908964244173
Epoch #183: loss=0.013052329392981524
Epoch #184: loss=0.019189276098804674
Epoch #185: loss=0.012135156254627535
Epoch #186: loss=0.011972078952176285
Epoch #187: loss=0.012465976588865236
Epoch #188: loss=0.01256429006654255
Epoch #189: loss=0.01804437207776647
Epoch #190: loss=0.010300829848767115
Epoch #191: loss=0.01035359306602683
Epoch #192: loss=0.014033629303251955
Epoch #193: loss=0.009786866888122336
Epoch #194: loss=0.00864527344669632
Epoch #195: loss=0.016151008866188733
Epoch #196: loss=0.010671966367522866
Epoch #197: loss=0.01183336775015939
Epoch #198: loss=0.00943140410648936
Epoch #199: loss=0.013027590711774121
Epoch #200: loss=0.031040765286230468
Epoch #201: loss=0.013123377264450712
Epoch #202: loss=0.010568223804487253
Epoch #203: loss=0.011498758242797683
Epoch #204: loss=0.010176341565867372
Epoch #205: loss=0.014574406514789827
Epoch #206: loss=0.0089640884658423
Epoch #207: loss=0.009954288628147767
Epoch #208: loss=0.012824565816010684
Epoch #209: loss=0.01795511212519542
Epoch #210: loss=0.012214419911572093
Epoch #211: loss=0.013999340053462993
Epoch #212: loss=0.007215187190498852
Epoch #213: loss=0.012235228187321343
Epoch #214: loss=0.013974389061167134
Epoch #215: loss=0.009692286588688148
Epoch #216: loss=0.009413576508902895
Epoch #217: loss=0.01464627732764308
Epoch #218: loss=0.00998530709577147
Epoch #219: loss=0.008817828243987129
Epoch #220: loss=0.01790631357450707
Epoch #221: loss=0.011581643951346421
Epoch #222: loss=0.014077194434078621
Epoch #223: loss=0.016377219647483593
Epoch #224: loss=0.01227136560978723
Epoch #225: loss=0.015780660310448426
Epoch #226: loss=0.007503054182163553
Epoch #227: loss=0.009805764891406731
Epoch #228: loss=0.013083338842396566
Epoch #229: loss=0.01216703909627063
Epoch #230: loss=0.011385732242461305
Epoch #231: loss=0.014471484226099852
Epoch #232: loss=0.010127702583036701
Epoch #233: loss=0.017309748671331407
Epoch #234: loss=0.011969985983140105
Epoch #235: loss=0.011523028656603148
Epoch #236: loss=0.010290126930310563
Epoch #237: loss=0.010437869979623388
Epoch #238: loss=0.008139219783873764
Epoch #239: loss=0.01032415173204544
Epoch #240: loss=0.020055626900403075
Epoch #241: loss=0.011221004635732917
Epoch #242: loss=0.015932997697130784
Epoch #243: loss=0.009312453211692233
Epoch #244: loss=0.010694038720113517
Epoch #245: loss=0.010555264032600915
Epoch #246: loss=0.01089201720548455
Epoch #247: loss=0.010787655725970872
Epoch #248: loss=0.013445560162650855
Epoch #249: loss=0.008850604639840587

Training time: 3:28:25.716446

Finished.
n2one setting etth1_etth2_traffic_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_traffic_exchange_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_etth2_traffic_exchange', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.97573e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.0511e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.11055e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.97573e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4081963944458032, 'MAE': 0.45596744981405507}
Finished.
------------------------- record done -------------------------
n2one setting etth1_etth2_traffic_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_traffic_exchange_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_etth2_traffic_exchange', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.11294e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.17138e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.41635e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.11294e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.5573367038538412, 'MAE': 0.5768016288004805}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_etth2_weather_exchange', random_seed=2023, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_etth2_weather_exchange_epochs_250_seed_2023
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=3.785212536652883
Epoch #1: loss=2.3488381753365197
Epoch #2: loss=2.34699888775746
Epoch #3: loss=2.0695961813131967
Epoch #4: loss=1.8629556149244308
Epoch #5: loss=1.714050367474556
Epoch #6: loss=1.6034841785828273
Epoch #7: loss=1.576668235162894
Epoch #8: loss=1.388309307396412
Epoch #9: loss=1.28536061445872
Epoch #10: loss=1.244194708764553
Epoch #11: loss=1.1805476397275925
Epoch #12: loss=1.2205354621013005
Epoch #13: loss=1.0815259392062824
Epoch #14: loss=1.0971936372419198
Epoch #15: loss=1.0271244285007317
Epoch #16: loss=0.9180113958815733
Epoch #17: loss=0.9332185387611389
Epoch #18: loss=0.9720146755377451
Epoch #19: loss=0.8596946684022745
Epoch #20: loss=0.8527159951627254
Epoch #21: loss=0.8044361633559068
Epoch #22: loss=0.825309673945109
Epoch #23: loss=0.7440207985540231
Epoch #24: loss=0.8033774942159653
Epoch #25: loss=0.7137773334980011
Epoch #26: loss=0.7473976314067841
Epoch #27: loss=0.7027945301185051
Epoch #28: loss=0.7720636123170456
Epoch #29: loss=0.6766152524699768
Epoch #30: loss=0.676583589365085
Epoch #31: loss=0.6213714927434921
Epoch #32: loss=0.5893133698652188
Epoch #33: loss=0.6335071499149004
Epoch #34: loss=0.6118587876359621
Epoch #35: loss=0.5651648193597794
Epoch #36: loss=0.588273549452424
Epoch #37: loss=0.5219711847603321
Epoch #38: loss=0.5322025244434675
Epoch #39: loss=0.5732591450214386
Epoch #40: loss=0.5697021602342526
Epoch #41: loss=0.516844209904472
Epoch #42: loss=0.5392865141232809
Epoch #43: loss=0.5637390222400427
Epoch #44: loss=0.5302276810010275
Epoch #45: loss=0.458528437341253
Epoch #46: loss=0.46297446979830664
Epoch #47: loss=0.42466465880473453
Epoch #48: loss=0.44265176355838776
Epoch #49: loss=0.5006497151528796
Epoch #50: loss=0.46786208885411423
Epoch #51: loss=0.448860052973032
Epoch #52: loss=0.36797575280070305
Epoch #53: loss=0.45357998088002205
Epoch #54: loss=0.415587001790603
Epoch #55: loss=0.4560155939931671
Epoch #56: loss=0.5420504972959558
Epoch #57: loss=0.42569356970489025
Epoch #58: loss=0.3849847611660759
Epoch #59: loss=0.4107854263857007
Epoch #60: loss=0.3327397784839074
Epoch #61: loss=0.39898002954820794
Epoch #62: loss=0.40118966934581596
Epoch #63: loss=0.37509650519738597
Epoch #64: loss=0.4036331322665016
Epoch #65: loss=0.38351276361693937
Epoch #66: loss=0.6622468686352173
Epoch #67: loss=0.3081254142646988
Epoch #68: loss=0.31748390663415194
Epoch #69: loss=0.4168527539198597
Epoch #70: loss=0.31152475035438937
Epoch #71: loss=0.3215798658008377
Epoch #72: loss=0.2936964637289445
Epoch #73: loss=0.3705662344582379
Epoch #74: loss=0.2575979493558407
Epoch #75: loss=0.265451832053562
Epoch #76: loss=0.32323484231407446
Epoch #77: loss=0.23857364493111768
Epoch #78: loss=0.24406446997697154
Epoch #79: loss=0.25383535601819557
Epoch #80: loss=0.3523298801543812
Epoch #81: loss=0.312811529263854
Epoch #82: loss=0.2765016299672425
Epoch #83: loss=0.24309919231260815
Epoch #84: loss=0.2420054992350439
Epoch #85: loss=0.285769567048798
Epoch #86: loss=0.2538953684270382
Epoch #87: loss=0.3052752024183671
Epoch #88: loss=0.2701341803185642
Epoch #89: loss=0.28217167624582845
Epoch #90: loss=0.3074135663919151
Epoch #91: loss=0.23420911856616536
Epoch #92: loss=0.26785209123045206
Epoch #93: loss=0.20682618658368787
Epoch #94: loss=0.20883945298070708
Epoch #95: loss=0.24635993891085187
Epoch #96: loss=0.26200790827473003
Epoch #97: loss=0.3072010379595061
Epoch #98: loss=0.23791909435143074
Epoch #99: loss=0.2657874533906579
Epoch #100: loss=0.34789901490633685
Epoch #101: loss=0.22479561048870286
Epoch #102: loss=0.21998496524368724
Epoch #103: loss=0.18403099764448902
Epoch #104: loss=0.20158916913593808
Epoch #105: loss=0.21263511525467038
Epoch #106: loss=0.2705721158223848
Epoch #107: loss=0.2602712968364358
Epoch #108: loss=0.2724597603082657
Epoch #109: loss=0.23552088517074785
Epoch #110: loss=0.19957712781615555
Epoch #111: loss=0.2067029947259774
Epoch #112: loss=0.23161188854525486
Epoch #113: loss=0.2269851426438739
Epoch #114: loss=0.16768870518232384
Epoch #115: loss=0.1892664518672973
Epoch #116: loss=0.1669424711726606
Epoch #117: loss=0.19557441864162683
Epoch #118: loss=0.1990960919453452
Epoch #119: loss=0.19329777740252516
Epoch #120: loss=0.17856539979887506
Epoch #121: loss=0.15235072607174516
Epoch #122: loss=0.13050999748520553
Epoch #123: loss=0.16721358732320368
Epoch #124: loss=0.20992211904376745
Epoch #125: loss=0.15184306089455882
Epoch #126: loss=0.23124616678493717
Epoch #127: loss=0.20990210181723037
Epoch #128: loss=0.17596594360657036
Epoch #129: loss=0.13414674368686974
Epoch #130: loss=0.13319687622909746
Epoch #131: loss=0.20145773786740998
Epoch #132: loss=0.17809426054979363
Epoch #133: loss=0.18680118047632277
Epoch #134: loss=0.16250792463930944
Epoch #135: loss=0.20237549922118583
Epoch #136: loss=0.15757280153532824
Epoch #137: loss=0.1793550526102384
Epoch #138: loss=0.17074491269886494
Epoch #139: loss=0.18913376331329346
Epoch #140: loss=0.1654807353237023
Epoch #141: loss=0.254488569451496
Epoch #142: loss=0.18454454963405928
Epoch #143: loss=0.15677800914272666
Epoch #144: loss=0.151842035081548
Epoch #145: loss=0.1925820044707507
Epoch #146: loss=0.1403877870955815
Epoch #147: loss=0.12519678488994637
Epoch #148: loss=0.13154286173327515
Epoch #149: loss=0.1229364515747875
Epoch #150: loss=0.14095998590346426
Epoch #151: loss=0.13470999423104027
Epoch #152: loss=0.21355210795688132
Epoch #153: loss=0.19078923327227434
Epoch #154: loss=0.20261747506447136
Epoch #155: loss=0.13736236669744054
Epoch #156: loss=0.10533034168959905
Epoch #157: loss=0.12896481478431573
Epoch #158: loss=0.135662077460438
Epoch #159: loss=0.10757391504012048
Epoch #160: loss=0.11178556763722251
Epoch #161: loss=0.12640858724868545
Epoch #162: loss=0.12130764573036383
Epoch #163: loss=0.14330270203451315
Epoch #164: loss=0.15410603024065495
Epoch #165: loss=0.1640809898963198
Epoch #166: loss=0.15101855349106094
Epoch #167: loss=0.11852815983972202
Epoch #168: loss=0.11799677298404276
Epoch #169: loss=0.11373627368205537
Epoch #170: loss=0.11324154364410788
Epoch #171: loss=0.1550030152235801
Epoch #172: loss=0.14418160329417637
Epoch #173: loss=0.27113445778377354
Epoch #174: loss=0.24538988969288766
Epoch #175: loss=0.23568552445309857
Epoch #176: loss=0.19211433556241295
Epoch #177: loss=0.16512019676156342
Epoch #178: loss=0.11894181506553043
Epoch #179: loss=0.1740719995383794
Epoch #180: loss=0.14523177912148336
Epoch #181: loss=0.12101465370506048
Epoch #182: loss=0.11885290472613026
Epoch #183: loss=0.14655330028229704
Epoch #184: loss=0.1487478734149287
Epoch #185: loss=0.1389291569357738
Epoch #186: loss=0.11592627308952312
Epoch #187: loss=0.12307489426651348
Epoch #188: loss=0.11661529498330007
Epoch #189: loss=0.12613411212805659
Epoch #190: loss=0.159974719514139
Epoch #191: loss=0.1063993334537372
Epoch #192: loss=0.13088986176686981
Epoch #193: loss=0.10779340006411076
Epoch #194: loss=0.088484561497656
Epoch #195: loss=0.08779348068249722
Epoch #196: loss=0.10971761778152238
Epoch #197: loss=0.0899567377443115
Epoch #198: loss=0.10772980353794992
Epoch #199: loss=0.1212508066285712
Epoch #200: loss=0.14606059753956893
Epoch #201: loss=0.1389701250785341
Epoch #202: loss=0.14119016542099416
Epoch #203: loss=0.13112259101277837
Epoch #204: loss=0.10737722386450817
Epoch #205: loss=0.13737065391615033
Epoch #206: loss=0.13455683609936386
Epoch #207: loss=0.12535521906102076
Epoch #208: loss=0.1652398620111247
Epoch #209: loss=0.12322131920761119
Epoch #210: loss=0.12398225687987481
Epoch #211: loss=0.13035496906377375
Epoch #212: loss=0.07731634991553922
Epoch #213: loss=0.11535293345029156
Epoch #214: loss=0.09395776374731213
Epoch #215: loss=0.11643866127512108
Epoch #216: loss=0.08296671224525198
Epoch #217: loss=0.07325043513750036
Epoch #218: loss=0.0756663386321937
Epoch #219: loss=0.07679602870484814
Epoch #220: loss=0.08940754025631274
Epoch #221: loss=0.07255252902784075
Epoch #222: loss=0.11553585092769936
Epoch #223: loss=0.07302229116127516
Epoch #224: loss=0.06459372219008704
Epoch #225: loss=0.08517160499468446
Epoch #226: loss=0.09474905842216685
Epoch #227: loss=0.10573656888057788
Epoch #228: loss=0.11123368885212888
Epoch #229: loss=0.10014044755371287
Epoch #230: loss=0.10001679207198322
Epoch #231: loss=0.0838659499034596
Epoch #232: loss=0.08433541087045644
Epoch #233: loss=0.1224718582816422
Epoch #234: loss=0.11365200447229047
Epoch #235: loss=0.11378022811065118
Epoch #236: loss=0.09848636823395888
Epoch #237: loss=0.06988848348070557
Epoch #238: loss=0.0992083649810714
Epoch #239: loss=0.07162504024260367
Epoch #240: loss=0.08729729764551546
Epoch #241: loss=0.07355701244280984
Epoch #242: loss=0.07679234274352591
Epoch #243: loss=0.10176287137437612
Epoch #244: loss=0.11979710636660457
Epoch #245: loss=0.15727750460306802
Epoch #246: loss=0.17043549456866458
Epoch #247: loss=0.10842756294490148
Epoch #248: loss=0.0779286229905362
Epoch #249: loss=0.12183408811688423

Training time: 0:14:40.363813

Finished.
n2one setting etth1_etth2_weather_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_etth2_weather_exchange_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_etth2_weather_exchange', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.56609e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.91934e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.56609e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.37485408169134543, 'MAE': 0.436819190367524}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm1_ettm2_electricity', random_seed=2023, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm1_ettm2_electricity_epochs_250_seed_2023
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.6846650973388126
Epoch #1: loss=0.7145574514354979
Epoch #2: loss=0.4878310626745224
Epoch #3: loss=0.3714151552745274
Epoch #4: loss=0.34625987474407466
Epoch #5: loss=0.2826948835168566
Epoch #6: loss=0.25617113964898247
Epoch #7: loss=0.24854659152882438
Epoch #8: loss=0.20015197981681143
Epoch #9: loss=0.1559905425778457
Epoch #10: loss=0.1668358215796096
Epoch #11: loss=0.1444531983775752
Epoch #12: loss=0.12912630940122263
Epoch #13: loss=0.11975567404180765
Epoch #14: loss=0.0981076944353325
Epoch #15: loss=0.11209182350763253
Epoch #16: loss=0.09133183967056019
Epoch #17: loss=0.08466784141159484
Epoch #18: loss=0.0734825887331473
Epoch #19: loss=0.05988094619076167
Epoch #20: loss=0.07894807974940964
Epoch #21: loss=0.07254623030711498
Epoch #22: loss=0.0683960217224168
Epoch #23: loss=0.06600904539227485
Epoch #24: loss=0.05003122231789998
Epoch #25: loss=0.055238957311958076
Epoch #26: loss=0.05980626396302666
Epoch #27: loss=0.04308863346464932
Epoch #28: loss=0.08293795378745666
Epoch #29: loss=0.059393080921311465
Epoch #30: loss=0.039883514850267344
Epoch #31: loss=0.04505290016132806
Epoch #32: loss=0.0525038437139509
Epoch #33: loss=0.035026351431650775
Epoch #34: loss=0.04476580329106322
Epoch #35: loss=0.037745061432277516
Epoch #36: loss=0.038487516989532324
Epoch #37: loss=0.06240552306308278
Epoch #38: loss=0.041770395674476664
Epoch #39: loss=0.046098148003885786
Epoch #40: loss=0.033027078303109324
Epoch #41: loss=0.03231247541162052
Epoch #42: loss=0.0370295654709584
Epoch #43: loss=0.031070876374973782
Epoch #44: loss=0.035132435921446555
Epoch #45: loss=0.03138646962819621
Epoch #46: loss=0.024871503751658437
Epoch #47: loss=0.046413718764670195
Epoch #48: loss=0.050519420196568326
Epoch #49: loss=0.025926630946674516
Epoch #50: loss=0.026892161651714038
Epoch #51: loss=0.033369267215020953
Epoch #52: loss=0.04140867229750646
Epoch #53: loss=0.027011368818847196
Epoch #54: loss=0.030893508263065347
Epoch #55: loss=0.022988837521656282
Epoch #56: loss=0.03229976459572624
Epoch #57: loss=0.021729596660339405
Epoch #58: loss=0.023129928337210524
Epoch #59: loss=0.0317980473920969
Epoch #60: loss=0.02194927039423159
Epoch #61: loss=0.025647318283362048
Epoch #62: loss=0.023358609223339176
Epoch #63: loss=0.02604969790172098
Epoch #64: loss=0.03069676323195121
Epoch #65: loss=0.025898052058847886
Epoch #66: loss=0.023253322905262132
Epoch #67: loss=0.02409924889814907
Epoch #68: loss=0.020830683262819158
Epoch #69: loss=0.021161360196336836
Epoch #70: loss=0.027582813408059466
Epoch #71: loss=0.017965730237441937
Epoch #72: loss=0.020099234439964805
Epoch #73: loss=0.022266892735247634
Epoch #74: loss=0.020594460538455418
Epoch #75: loss=0.01854573899031883
Epoch #76: loss=0.030990750651607023
Epoch #77: loss=0.018018320800204362
Epoch #78: loss=0.02756588533687006
Epoch #79: loss=0.014821319759524028
Epoch #80: loss=0.024780834209107396
Epoch #81: loss=0.022505055450435196
Epoch #82: loss=0.017693349366808043
Epoch #83: loss=0.019414865165849084
Epoch #84: loss=0.022258050057903996
Epoch #85: loss=0.017171629211432966
Epoch #86: loss=0.011029193464200943
Epoch #87: loss=0.024077198745217174
Epoch #88: loss=0.021199025510743794
Epoch #89: loss=0.02189451880021287
Epoch #90: loss=0.024449495724734982
Epoch #91: loss=0.0188143386545458
Epoch #92: loss=0.019074748915819718
Epoch #93: loss=0.019985766609232607
Epoch #94: loss=0.01912351332671408
Epoch #95: loss=0.015466555963503197
Epoch #96: loss=0.027821230172495624
Epoch #97: loss=0.028649064627742128
Epoch #98: loss=0.029308362218019152
Epoch #99: loss=0.021179594942035952
Epoch #100: loss=0.015520968516523551
Epoch #101: loss=0.0143330810362074
Epoch #102: loss=0.016414397271083934
Epoch #103: loss=0.03299625808971801
Epoch #104: loss=0.016975626583942877
Epoch #105: loss=0.010898811495946055
Epoch #106: loss=0.014006279419409112
Epoch #107: loss=0.0551602509388301
Epoch #108: loss=0.018910884236185147
Epoch #109: loss=0.01660869314933994
Epoch #110: loss=0.013364473489678598
Epoch #111: loss=0.012365666788703362
Epoch #112: loss=0.01643817947545488
Epoch #113: loss=0.013874006202178341
Epoch #114: loss=0.015648406184211906
Epoch #115: loss=0.01293511977568934
Epoch #116: loss=0.025685764149197245
Epoch #117: loss=0.009586061710724608
Epoch #118: loss=0.0187103077802541
Epoch #119: loss=0.019636444924399258
Epoch #120: loss=0.01774648918537423
Epoch #121: loss=0.01406085857788899
Epoch #122: loss=0.015155340690481743
Epoch #123: loss=0.016322772629459255
Epoch #124: loss=0.018852653003497314
Epoch #125: loss=0.011435990126919933
Epoch #126: loss=0.01566815323013413
Epoch #127: loss=0.015269264586635732
Epoch #128: loss=0.032268689562333745
Epoch #129: loss=0.012016362862777897
Epoch #130: loss=0.018588634108808556
Epoch #131: loss=0.01502283827168867
Epoch #132: loss=0.013266482486422839
Epoch #133: loss=0.013421546379436872
Epoch #134: loss=0.01435027462796175
Epoch #135: loss=0.01726581650569902
Epoch #136: loss=0.0164141290797852
Epoch #137: loss=0.011334823762382647
Epoch #138: loss=0.009089343630143309
Epoch #139: loss=0.018745111436084178
Epoch #140: loss=0.01358055481379519
Epoch #141: loss=0.015944017863865675
Epoch #142: loss=0.014675343714355091
Epoch #143: loss=0.010432511091348715
Epoch #144: loss=0.01669403374827068
Epoch #145: loss=0.012716184649367019
Epoch #146: loss=0.018886302334722133
Epoch #147: loss=0.015755744336472293
Epoch #148: loss=0.014168781595737008
Epoch #149: loss=0.011681962178554385
Epoch #150: loss=0.011413383807770775
Epoch #151: loss=0.01228247646807826
Epoch #152: loss=0.014769777060885515
Epoch #153: loss=0.015738553943561523
Epoch #154: loss=0.012579425777158966
Epoch #155: loss=0.014826529445126652
Epoch #156: loss=0.01652014447243086
Epoch #157: loss=0.013938974878650957
Epoch #158: loss=0.010522935042806368
Epoch #159: loss=0.017094743565955597
Epoch #160: loss=0.013859953147683492
Epoch #161: loss=0.015866918211769578
Epoch #162: loss=0.016979482666023876
Epoch #163: loss=0.011047415874283095
Epoch #164: loss=0.009308421201505034
Epoch #165: loss=0.011699637951844904
Epoch #166: loss=0.018929814531667425
Epoch #167: loss=0.017775362985807338
Epoch #168: loss=0.014624861719951567
Epoch #169: loss=0.016624737340690834
Epoch #170: loss=0.01415677285329106
Epoch #171: loss=0.014532340706958037
Epoch #172: loss=0.012398057023528964
Epoch #173: loss=0.022010155936004593
Epoch #174: loss=0.01735808533134072
Epoch #175: loss=0.01347970623656043
Epoch #176: loss=0.017028157297255736
Epoch #177: loss=0.008968243770983203
Epoch #178: loss=0.01585445458269013
Epoch #179: loss=0.014616665273289463
Epoch #180: loss=0.009571546574755172
Epoch #181: loss=0.009567846478478585
Epoch #182: loss=0.013302903553870107
Epoch #183: loss=0.010145168532534237
Epoch #184: loss=0.008654947506854244
Epoch #185: loss=0.013530820459044272
Epoch #186: loss=0.012622006435412914
Epoch #187: loss=0.015247908753475972
Epoch #188: loss=0.018784239588504923
Epoch #189: loss=0.014875609453634493
Epoch #190: loss=0.01529920219477
Epoch #191: loss=0.019549300811236858
Epoch #192: loss=0.00896719134479229
Epoch #193: loss=0.01037972935475409
Epoch #194: loss=0.011227707189391367
Epoch #195: loss=0.015013609740666912
Epoch #196: loss=0.00905755248465409
Epoch #197: loss=0.00937773940436143
Epoch #198: loss=0.010042873470145942
Epoch #199: loss=0.015080958632752299
Epoch #200: loss=0.02015919963280404
Epoch #201: loss=0.013709795986401981
Epoch #202: loss=0.01320427986377451
Epoch #203: loss=0.009931478990058947
Epoch #204: loss=0.016712082841716307
Epoch #205: loss=0.007549284182771641
Epoch #206: loss=0.014613952744486076
Epoch #207: loss=0.008505721538261112
Epoch #208: loss=0.013888740531734323
Epoch #209: loss=0.01262542485425781
Epoch #210: loss=0.014018076604781007
Epoch #211: loss=0.007097241024852597
Epoch #212: loss=0.013564080762942987
Epoch #213: loss=0.011812096693070739
Epoch #214: loss=0.009609253064928842
Epoch #215: loss=0.018184698645075385
Epoch #216: loss=0.009048854961625434
Epoch #217: loss=0.008957923968680136
Epoch #218: loss=0.034090992859814186
Epoch #219: loss=0.012372370156559296
Epoch #220: loss=0.011559147795986584
Epoch #221: loss=0.008683498703758232
Epoch #222: loss=0.005447788485866373
Epoch #223: loss=0.007040214823791757
Epoch #224: loss=0.020495034559696382
Epoch #225: loss=0.013397732097156612
Epoch #226: loss=0.010422602577517474
Epoch #227: loss=0.01239434679263338
Epoch #228: loss=0.015228938012483663
Epoch #229: loss=0.011566389059797594
Epoch #230: loss=0.012649756504522104
Epoch #231: loss=0.009562112120662018
Epoch #232: loss=0.006626756515969256
Epoch #233: loss=0.013936750582901627
Epoch #234: loss=0.010447625015596195
Epoch #235: loss=0.006556399405318578
Epoch #236: loss=0.012561595932514007
Epoch #237: loss=0.01274543513111504
Epoch #238: loss=0.012296346069030862
Epoch #239: loss=0.008778661753998936
Epoch #240: loss=0.007121910089543755
Epoch #241: loss=0.007927464663766192
Epoch #242: loss=0.013814719324166487
Epoch #243: loss=0.010332573038675557
Epoch #244: loss=0.013092094450257719
Epoch #245: loss=0.017952044821909763
Epoch #246: loss=0.010560515529858613
Epoch #247: loss=0.009026409972824955
Epoch #248: loss=0.008564727323745112
Epoch #249: loss=0.009819030719975542

Training time: 1:38:35.411865

Finished.
n2one setting etth1_ettm1_ettm2_electricity -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_ettm2_electricity_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_ettm1_ettm2_electricity', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.87498e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.61613e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.78036e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.87498e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.5246025795809003, 'MAE': 0.5622545397670194}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm1_ettm2_electricity -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_ettm2_electricity_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_ettm1_ettm2_electricity', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.39516e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.39516e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3526520772214272, 'MAE': 0.3947504227668655}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm1_ettm2_traffic', random_seed=2023, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm1_ettm2_traffic_epochs_250_seed_2023
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.9976199987427019
Epoch #1: loss=0.37217885386261473
Epoch #2: loss=0.27913389823218654
Epoch #3: loss=0.20652148181072924
Epoch #4: loss=0.15848545825441276
Epoch #5: loss=0.13177386650190542
Epoch #6: loss=0.11371088754197564
Epoch #7: loss=0.08750953461230637
Epoch #8: loss=0.08843246747464711
Epoch #9: loss=0.07377494881232713
Epoch #10: loss=0.07505336401547179
Epoch #11: loss=0.0628056452185225
Epoch #12: loss=0.06202411459806959
Epoch #13: loss=0.059193299001962886
Epoch #14: loss=0.05462266274834497
Epoch #15: loss=0.06719157012183676
Epoch #16: loss=0.04765682863766656
Epoch #17: loss=0.04485490402404332
Epoch #18: loss=0.04379997677723726
Epoch #19: loss=0.04134910744047848
Epoch #20: loss=0.035981656883934184
Epoch #21: loss=0.03321764233608873
Epoch #22: loss=0.0377648626859211
Epoch #23: loss=0.04139812449573442
Epoch #24: loss=0.02674130497092128
Epoch #25: loss=0.04795766419610353
Epoch #26: loss=0.034374658843057126
Epoch #27: loss=0.03830947812453778
Epoch #28: loss=0.03294790839681278
Epoch #29: loss=0.0268325741069891
Epoch #30: loss=0.029673208574415317
Epoch #31: loss=0.02559490143802272
Epoch #32: loss=0.024848195264080913
Epoch #33: loss=0.025831539122250315
Epoch #34: loss=0.02577721607619447
Epoch #35: loss=0.024161950919090423
Epoch #36: loss=0.021721549352197715
Epoch #37: loss=0.022484067092975235
Epoch #38: loss=0.02307128267840657
Epoch #39: loss=0.024708291900231306
Epoch #40: loss=0.022315778754657817
Epoch #41: loss=0.020309696290900722
Epoch #42: loss=0.02220340503838831
Epoch #43: loss=0.021965354164397526
Epoch #44: loss=0.023738741335996315
Epoch #45: loss=0.016873357779574796
Epoch #46: loss=0.022224438428856835
Epoch #47: loss=0.01798605777539614
Epoch #48: loss=0.018616474389441428
Epoch #49: loss=0.019757301836560964
Epoch #50: loss=0.021308259175048763
Epoch #51: loss=0.018838198749752514
Epoch #52: loss=0.021468108590368514
Epoch #53: loss=0.018270477817210137
Epoch #54: loss=0.016943810825935417
Epoch #55: loss=0.02304387650567271
Epoch #56: loss=0.015381171593445694
Epoch #57: loss=0.019932485723870103
Epoch #58: loss=0.015062414674994072
Epoch #59: loss=0.0210593268413104
Epoch #60: loss=0.02009253903804556
Epoch #61: loss=0.016504310482972344
Epoch #62: loss=0.020031143607862824
Epoch #63: loss=0.017419404528567863
Epoch #64: loss=0.018760313483228954
Epoch #65: loss=0.02067580594478424
Epoch #66: loss=0.02382821874305246
Epoch #67: loss=0.016580947394845755
Epoch #68: loss=0.015165499840731346
Epoch #69: loss=0.019949872437961227
Epoch #70: loss=0.017627514667906217
Epoch #71: loss=0.016312474134238593
Epoch #72: loss=0.01547367442239862
Epoch #73: loss=0.01805939182806232
Epoch #74: loss=0.01491502052541863
Epoch #75: loss=0.016652300099695393
Epoch #76: loss=0.01631882421448725
Epoch #77: loss=0.01171002440192051
Epoch #78: loss=0.015137547336869709
Epoch #79: loss=0.02153171563261543
Epoch #80: loss=0.017626826927733766
Epoch #81: loss=0.013994614897658013
Epoch #82: loss=0.018600299642078984
Epoch #83: loss=0.018034869616277104
Epoch #84: loss=0.01656981406627039
Epoch #85: loss=0.016894382159745657
Epoch #86: loss=0.016073892773918214
Epoch #87: loss=0.01586801090229911
Epoch #88: loss=0.015844299179276055
Epoch #89: loss=0.013734901911576721
Epoch #90: loss=0.016490494647092322
Epoch #91: loss=0.014161878135436822
Epoch #92: loss=0.01183625509386961
Epoch #93: loss=0.026455188104224325
Epoch #94: loss=0.01484121527724602
Epoch #95: loss=0.02508534013530695
Epoch #96: loss=0.024411329740473393
Epoch #97: loss=0.01183089351627242
Epoch #98: loss=0.014189849592490263
Epoch #99: loss=0.011912758143427135
Epoch #100: loss=0.014124936487564375
Epoch #101: loss=0.012895014274807378
Epoch #102: loss=0.013142937670481301
Epoch #103: loss=0.012099475661593445
Epoch #104: loss=0.016680040900040456
Epoch #105: loss=0.014599377617918585
Epoch #106: loss=0.014039720990270425
Epoch #107: loss=0.00967903422577765
Epoch #108: loss=0.01143339085342351
Epoch #109: loss=0.014301608606920015
Epoch #110: loss=0.015897434499177625
Epoch #111: loss=0.018893587596861616
Epoch #112: loss=0.011270322497325503
Epoch #113: loss=0.012879805375361193
Epoch #114: loss=0.013124065142819726
Epoch #115: loss=0.01134827674152779
Epoch #116: loss=0.013631304822168098
Epoch #117: loss=0.010708910582744435
Epoch #118: loss=0.013014002817438725
Epoch #119: loss=0.012716300171421314
Epoch #120: loss=0.012048842953474916
Epoch #121: loss=0.0138574280701707
Epoch #122: loss=0.013844179805155475
Epoch #123: loss=0.010159364798427408
Epoch #124: loss=0.011488605497611893
Epoch #125: loss=0.013931872030288412
Epoch #126: loss=0.015437827900710058
Epoch #127: loss=0.014852031947245015
Epoch #128: loss=0.012189660629641169
Epoch #129: loss=0.01053824193823213
Epoch #130: loss=0.0311202762575818
Epoch #131: loss=0.011310845099638586
Epoch #132: loss=0.012345626646421293
Epoch #133: loss=0.011509483407529705
Epoch #134: loss=0.009935897183020502
Epoch #135: loss=0.01201212497200194
Epoch #136: loss=0.012190800164081143
Epoch #137: loss=0.009655564798822984
Epoch #138: loss=0.01840818100662128
Epoch #139: loss=0.012643824866012536
Epoch #140: loss=0.01377285217225952
Epoch #141: loss=0.014210233864602358
Epoch #142: loss=0.010444951312260819
Epoch #143: loss=0.011935952180502479
Epoch #144: loss=0.01148455939967735
Epoch #145: loss=0.02061153715303273
Epoch #146: loss=0.009450060467563824
Epoch #147: loss=0.01105979168001044
Epoch #148: loss=0.007996741855648274
Epoch #149: loss=0.012358609192108884
Epoch #150: loss=0.012626463983971761
Epoch #151: loss=0.014236508720633067
Epoch #152: loss=0.013462521398754103
Epoch #153: loss=0.0076584458385040724
Epoch #154: loss=0.01131873565546525
Epoch #155: loss=0.025326058091898893
Epoch #156: loss=0.012929434762944522
Epoch #157: loss=0.011773294030623898
Epoch #158: loss=0.009624043053179257
Epoch #159: loss=0.011557166310059645
Epoch #160: loss=0.01282490539763935
Epoch #161: loss=0.013389139126169137
Epoch #162: loss=0.010785368224331538
Epoch #163: loss=0.012442380256013649
Epoch #164: loss=0.008293751390619773
Epoch #165: loss=0.007627789255879155
Epoch #166: loss=0.009658595659281675
Epoch #167: loss=0.014045362616699726
Epoch #168: loss=0.012033547207627024
Epoch #169: loss=0.014443254995386625
Epoch #170: loss=0.010744601168330575
Epoch #171: loss=0.009966223537342769
Epoch #172: loss=0.012754953590561542
Epoch #173: loss=0.010758686787409627
Epoch #174: loss=0.008472821674563211
Epoch #175: loss=0.01270511253119494
Epoch #176: loss=0.009544586701360824
Epoch #177: loss=0.010193704582181655
Epoch #178: loss=0.010259206020435936
Epoch #179: loss=0.011596341210115109
Epoch #180: loss=0.010227665378076864
Epoch #181: loss=0.011866542283590234
Epoch #182: loss=0.01167965409541649
Epoch #183: loss=0.011316213931896312
Epoch #184: loss=0.005746762145019406
Epoch #185: loss=0.01084632855306555
Epoch #186: loss=0.009114849110747543
Epoch #187: loss=0.012102033251997482
Epoch #188: loss=0.012440138278694264
Epoch #189: loss=0.008332846259257174
Epoch #190: loss=0.008225520899706556
Epoch #191: loss=0.009618864898570143
Epoch #192: loss=0.011077850132916168
Epoch #193: loss=0.010645330068981954
Epoch #194: loss=0.009436836942013062
Epoch #195: loss=0.015128873040154629
Epoch #196: loss=0.005699728627371353
Epoch #197: loss=0.008918560251778992
Epoch #198: loss=0.01123505157732975
Epoch #199: loss=0.00957737597956008
Epoch #200: loss=0.011276573495837201
Epoch #201: loss=0.010922760907637675
Epoch #202: loss=0.007767010956213995
Epoch #203: loss=0.009984813284327796
Epoch #204: loss=0.008696853883367703
Epoch #205: loss=0.011948373160704157
Epoch #206: loss=0.0122244089841712
Epoch #207: loss=0.010099117821465298
Epoch #208: loss=0.013022932590598996
Epoch #209: loss=0.009663720722224338
Epoch #210: loss=0.01147904198872308
Epoch #211: loss=0.00835281543812212
Epoch #212: loss=0.014234318419154623
Epoch #213: loss=0.006098571315088851
Epoch #214: loss=0.006738019265234609
Epoch #215: loss=0.00879248682928625
Epoch #216: loss=0.015701290596885777
Epoch #217: loss=0.010300299317849588
Epoch #218: loss=0.007493337227293425
Epoch #219: loss=0.009129858986840675
Epoch #220: loss=0.007895800594522679
Epoch #221: loss=0.008935560301361332
Epoch #222: loss=0.009193449276256429
Epoch #223: loss=0.013756619443569266
Epoch #224: loss=0.012790007357503623
Epoch #225: loss=0.012332755065057219
Epoch #226: loss=0.007239256278929641
Epoch #227: loss=0.009758816335349491
Epoch #228: loss=0.008621132030155965
Epoch #229: loss=0.00968774245514189
Epoch #230: loss=0.00926140574407168
Epoch #231: loss=0.009406890680441971
Epoch #232: loss=0.008991120938843668
Epoch #233: loss=0.015876487147774575
Epoch #234: loss=0.007111149905875323
Epoch #235: loss=0.00976934998113151
Epoch #236: loss=0.010797571941566785
Epoch #237: loss=0.014014060639093738
Epoch #238: loss=0.00915082179148868
Epoch #239: loss=0.00896717177541072
Epoch #240: loss=0.010554909449374861
Epoch #241: loss=0.007927934395611354
Epoch #242: loss=0.01575294737381049
Epoch #243: loss=0.00975435799428942
Epoch #244: loss=0.021849208095923115
Epoch #245: loss=0.008558139077425118
Epoch #246: loss=0.007049024134032946
Epoch #247: loss=0.00994002924259704
Epoch #248: loss=0.00995761146344946
Epoch #249: loss=0.009928480265641823

Training time: 3:38:39.074100

Finished.
n2one setting etth1_ettm1_ettm2_traffic -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_ettm2_traffic_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_ettm1_ettm2_traffic', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.19565e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.64001e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.18595e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.19565e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4051641836108709, 'MAE': 0.4520807403482531}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm1_ettm2_traffic -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_ettm2_traffic_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_ettm1_ettm2_traffic', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.47668e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.77218e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.51929e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.51929e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.9582228733591187, 'MAE': 0.799225989952093}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm1_ettm2_traffic -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_ettm2_traffic_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_ettm1_ettm2_traffic', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
Evaluation result: {'MSE': 0.1754236726241055, 'MAE': 0.2950466547684487}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm1_ettm2_weather', random_seed=2023, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm1_ettm2_weather_epochs_250_seed_2023
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=3.9396447745236483
Epoch #1: loss=2.339619913968173
Epoch #2: loss=2.1300413500178945
Epoch #3: loss=1.8008776079524647
Epoch #4: loss=1.6195505358956077
Epoch #5: loss=1.4888260559602218
Epoch #6: loss=1.303323162685741
Epoch #7: loss=1.2983873454007235
Epoch #8: loss=1.1758470004255122
Epoch #9: loss=1.1460381865501403
Epoch #10: loss=1.016368725083091
Epoch #11: loss=0.9500215129418806
Epoch #12: loss=0.9634360595182939
Epoch #13: loss=0.8986510721119967
Epoch #14: loss=0.867683394388719
Epoch #15: loss=0.7898327827453613
Epoch #16: loss=0.8065830263224515
Epoch #17: loss=0.7918072407895869
Epoch #18: loss=0.7408979220823808
Epoch #19: loss=0.6675071407448162
Epoch #20: loss=0.6906905862418088
Epoch #21: loss=0.6270147318189795
Epoch #22: loss=0.6176715774969621
Epoch #23: loss=0.6073719279332594
Epoch #24: loss=0.6498339447108182
Epoch #25: loss=0.6222487438808788
Epoch #26: loss=0.6500915218483317
Epoch #27: loss=0.5741303075443615
Epoch #28: loss=0.5820601680062034
Epoch #29: loss=0.5669074210253628
Epoch #30: loss=0.5586991077119654
Epoch #31: loss=0.4723044671795585
Epoch #32: loss=0.4396940995346416
Epoch #33: loss=0.4500755423849279
Epoch #34: loss=0.5232310408895666
Epoch #35: loss=0.5007221232761037
Epoch #36: loss=0.41373680884187874
Epoch #37: loss=0.43702474399046465
Epoch #38: loss=0.3956913498314944
Epoch #39: loss=0.3805201078003103
Epoch #40: loss=0.4393964480270039
Epoch #41: loss=0.37656461786140094
Epoch #42: loss=0.40644515698606315
Epoch #43: loss=0.46621430543336
Epoch #44: loss=0.41375807306983253
Epoch #45: loss=0.4874638627875935
Epoch #46: loss=0.42817816029895434
Epoch #47: loss=0.36747810325839303
Epoch #48: loss=0.3157435162500902
Epoch #49: loss=0.30195355117321016
Epoch #50: loss=0.28936597894538535
Epoch #51: loss=0.3150716459209269
Epoch #52: loss=0.3570993586020036
Epoch #53: loss=0.3289557928388769
Epoch #54: loss=0.28394034572622995
Epoch #55: loss=0.2830092763358896
Epoch #56: loss=0.2494132457809015
Epoch #57: loss=0.24664060026407242
Epoch #58: loss=0.2141522239555012
Epoch #59: loss=0.21844535117799585
Epoch #60: loss=0.22768469750881196
Epoch #61: loss=0.2576223572546786
Epoch #62: loss=0.2568409344012087
Epoch #63: loss=0.2447091368111697
Epoch #64: loss=0.22264845330606808
Epoch #65: loss=0.2190946653485298
Epoch #66: loss=0.17811923237009483
Epoch #67: loss=0.18474732637405394
Epoch #68: loss=0.1833367065272548
Epoch #69: loss=0.20042046349156986
Epoch #70: loss=0.18698973554101858
Epoch #71: loss=0.16060364070263775
Epoch #72: loss=0.17318440249020403
Epoch #73: loss=0.20140407837250016
Epoch #74: loss=0.18766460743817417
Epoch #75: loss=0.1870146643031727
Epoch #76: loss=0.1851957462050698
Epoch #77: loss=0.21197890835729513
Epoch #78: loss=0.16331858614628966
Epoch #79: loss=0.1635017367926511
Epoch #80: loss=0.17299750250848858
Epoch #81: loss=0.1705343606119806
Epoch #82: loss=0.1475433663888411
Epoch #83: loss=0.1323792192068967
Epoch #84: loss=0.22192712290720507
Epoch #85: loss=0.13882352391427213
Epoch #86: loss=0.1553434770892967
Epoch #87: loss=0.1373751277950677
Epoch #88: loss=0.24633384279229426
Epoch #89: loss=0.14155529974536463
Epoch #90: loss=0.13862957781688734
Epoch #91: loss=0.15121400545943867
Epoch #92: loss=0.14649801938371224
Epoch #93: loss=0.10890465730970555
Epoch #94: loss=0.2145772623744878
Epoch #95: loss=0.13648811930959875
Epoch #96: loss=0.11715703538872979
Epoch #97: loss=0.10842539332807064
Epoch #98: loss=0.15584367337551983
Epoch #99: loss=0.11794327321377668
Epoch #100: loss=0.14827941141345286
Epoch #101: loss=0.0966017081994902
Epoch #102: loss=0.10938346975229003
Epoch #103: loss=0.10328002358702096
Epoch #104: loss=0.11685796993022615
Epoch #105: loss=0.10307613682340491
Epoch #106: loss=0.11082329980351709
Epoch #107: loss=0.09991140206429092
Epoch #108: loss=0.10227057354694064
Epoch #109: loss=0.09501672901890494
Epoch #110: loss=0.12137384038757194
Epoch #111: loss=0.11782417398962107
Epoch #112: loss=0.11759556426920674
Epoch #113: loss=0.1547363577918573
Epoch #114: loss=0.10659125237302347
Epoch #115: loss=0.10429951931265267
Epoch #116: loss=0.1352265919812701
Epoch #117: loss=0.09750987938181921
Epoch #118: loss=0.094283590702848
Epoch #119: loss=0.15859070359305902
Epoch #120: loss=0.24430255497043782
Epoch #121: loss=0.11924950236623938
Epoch #122: loss=0.12932949096641758
Epoch #123: loss=0.09922666316005317
Epoch #124: loss=0.20219362327321008
Epoch #125: loss=0.1536031240089373
Epoch #126: loss=0.12622308957983147
Epoch #127: loss=0.10114514851434664
Epoch #128: loss=0.15538576170802115
Epoch #129: loss=0.138975607434457
Epoch #130: loss=0.10578853863884102
Epoch #131: loss=0.07337575527754697
Epoch #132: loss=0.11645148840140213
Epoch #133: loss=0.07820555195212364
Epoch #134: loss=0.09798533222214742
Epoch #135: loss=0.08992674791000106
Epoch #136: loss=0.12565308274193243
Epoch #137: loss=0.1131044253706932
Epoch #138: loss=0.08475443311035633
Epoch #139: loss=0.07646852044219321
Epoch #140: loss=0.06187652706761252
Epoch #141: loss=0.10332526346160607
Epoch #142: loss=0.061711947128854014
Epoch #143: loss=0.0850770944560116
Epoch #144: loss=0.05461053563789888
Epoch #145: loss=0.060313866033472795
Epoch #146: loss=0.05667704941535538
Epoch #147: loss=0.05901721001348712
Epoch #148: loss=0.0736486680297689
Epoch #149: loss=0.09078865941952576
Epoch #150: loss=0.07179987213828347
Epoch #151: loss=0.08047330911186608
Epoch #152: loss=0.09296432554044506
Epoch #153: loss=0.0869501699947498
Epoch #154: loss=0.10656330991875042
Epoch #155: loss=0.14108014687557113
Epoch #156: loss=0.1066370204091072
Epoch #157: loss=0.06684797821058468
Epoch #158: loss=0.08867828458208929
Epoch #159: loss=0.09162617703391747
Epoch #160: loss=0.15475340444933283
Epoch #161: loss=0.13855154781856321
Epoch #162: loss=0.09350811073725873
Epoch #163: loss=0.07802762282504276
Epoch #164: loss=0.06730412561446428
Epoch #165: loss=0.05617302893237634
Epoch #166: loss=0.11569709605114027
Epoch #167: loss=0.09972187016497959
Epoch #168: loss=0.09976416667076675
Epoch #169: loss=0.08267577918754383
Epoch #170: loss=0.07597850042987954
Epoch #171: loss=0.05762685029344125
Epoch #172: loss=0.07791908923536539
Epoch #173: loss=0.0642002375627106
Epoch #174: loss=0.0676484177397056
Epoch #175: loss=0.0896878145635128
Epoch #176: loss=0.0907706173475493
Epoch #177: loss=0.08372133338654583
Epoch #178: loss=0.06922868822108616
Epoch #179: loss=0.07929365504533052
Epoch #180: loss=0.06352054734121669
Epoch #181: loss=0.05976020608266646
Epoch #182: loss=0.05903604533523321
Epoch #183: loss=0.056036963635547596
Epoch #184: loss=0.041625563901933754
Epoch #185: loss=0.055931311693381176
Epoch #186: loss=0.15393891842527824
Epoch #187: loss=0.0892122399400581
Epoch #188: loss=0.05257225316017866
Epoch #189: loss=0.12174144717441364
Epoch #190: loss=0.08517813494598324
Epoch #191: loss=0.0742782470854846
Epoch #192: loss=0.07157032919878309
Epoch #193: loss=0.07985693487254056
Epoch #194: loss=0.06616345383226871
Epoch #195: loss=0.10380068849772214
Epoch #196: loss=0.09031049935993823
Epoch #197: loss=0.06349521331827748
Epoch #198: loss=0.05671186003495347
Epoch #199: loss=0.06240608092736114
Epoch #200: loss=0.09066512523726984
Epoch #201: loss=0.07516150670972738
Epoch #202: loss=0.0692863685332916
Epoch #203: loss=0.04458831106735901
Epoch #204: loss=0.04300981846384027
Epoch #205: loss=0.07978218409486793
Epoch #206: loss=0.041795700026506725
Epoch #207: loss=0.0669843468899754
Epoch #208: loss=0.05655072685331106
Epoch #209: loss=0.04094626670703292
Epoch #210: loss=0.05432209137149833
Epoch #211: loss=0.042980820829556746
Epoch #212: loss=0.04395488892597231
Epoch #213: loss=0.0568579468452795
Epoch #214: loss=0.034987725088880824
Epoch #215: loss=0.06500628746368668
Epoch #216: loss=0.1706003402275118
Epoch #217: loss=0.3386428064582023
Epoch #218: loss=0.1457163572988727
Epoch #219: loss=0.09814070751043884
Epoch #220: loss=0.09139616314999081
Epoch #221: loss=0.05225636386735873
Epoch #222: loss=0.0636537095870484
Epoch #223: loss=0.05785774991593578
Epoch #224: loss=0.06232480300082402
Epoch #225: loss=0.04611862548203631
Epoch #226: loss=0.0441228316673501
Epoch #227: loss=0.03690204316411506
Epoch #228: loss=0.046188950504768976
Epoch #229: loss=0.05660855047066103
Epoch #230: loss=0.044166880380362275
Epoch #231: loss=0.06546390501104972
Epoch #232: loss=0.05586285756223581
Epoch #233: loss=0.03574817803773013
Epoch #234: loss=0.05319595545191656
Epoch #235: loss=0.0515439633788033
Epoch #236: loss=0.10442285111004657
Epoch #237: loss=0.06144269511780955
Epoch #238: loss=0.04699402272023938
Epoch #239: loss=0.047415692562406714
Epoch #240: loss=0.046827422692017125
Epoch #241: loss=0.06107838294384155
Epoch #242: loss=0.07694537075744434
Epoch #243: loss=0.09513243206522681
Epoch #244: loss=0.04135404396802187
Epoch #245: loss=0.04136037249964747
Epoch #246: loss=0.02835790379480882
Epoch #247: loss=0.05418628399175676
Epoch #248: loss=0.05385537130588835
Epoch #249: loss=0.08993009088391607

Training time: 0:18:53.655020

Finished.
n2one setting etth1_ettm1_ettm2_weather -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_ettm2_weather_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_ettm1_ettm2_weather', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.46626e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.8607e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.46626e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3640167781243674, 'MAE': 0.4244417241946138}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm1_ettm2_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_ettm2_weather_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_ettm1_ettm2_weather', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.98666e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.2327704570083725, 'MAE': 0.33161160857133926}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm1_ettm2_exchange', random_seed=2023, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm1_ettm2_exchange_epochs_250_seed_2023
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=4.051309820767996
Epoch #1: loss=2.322329166773203
Epoch #2: loss=2.016230960150023
Epoch #3: loss=1.8562629577275869
Epoch #4: loss=1.6734434913944554
Epoch #5: loss=1.4912298853332933
Epoch #6: loss=1.3775826080425366
Epoch #7: loss=1.3853725517118298
Epoch #8: loss=1.269901697700088
Epoch #9: loss=1.1706925405038369
Epoch #10: loss=1.1468699332830068
Epoch #11: loss=1.1298010864773311
Epoch #12: loss=1.0667796102730003
Epoch #13: loss=1.002249253762735
Epoch #14: loss=0.9677323376810228
Epoch #15: loss=0.8957797401660198
Epoch #16: loss=0.941016253587362
Epoch #17: loss=0.8258651076136408
Epoch #18: loss=0.8533720374107361
Epoch #19: loss=0.8302632393063726
Epoch #20: loss=0.8156213196548255
Epoch #21: loss=0.8389872956920315
Epoch #22: loss=0.7659894445457974
Epoch #23: loss=0.789570946145702
Epoch #24: loss=0.7683983243800498
Epoch #25: loss=0.701450606455674
Epoch #26: loss=0.7075370638757139
Epoch #27: loss=0.6546165210169714
Epoch #28: loss=0.6346065990022711
Epoch #29: loss=0.6206639868182104
Epoch #30: loss=0.5850411798502948
Epoch #31: loss=0.6680506322834943
Epoch #32: loss=0.5849172472953796
Epoch #33: loss=0.5561254604442699
Epoch #34: loss=0.6266984053560205
Epoch #35: loss=0.5447623101440636
Epoch #36: loss=0.5967885876024092
Epoch #37: loss=0.6505443034945307
Epoch #38: loss=0.6117190444791639
Epoch #39: loss=0.5975558250337034
Epoch #40: loss=0.5797238148547508
Epoch #41: loss=0.49806923399100433
Epoch #42: loss=0.5285641792658213
Epoch #43: loss=0.5396032897201745
Epoch #44: loss=0.5697091237918751
Epoch #45: loss=0.4972053862906791
Epoch #46: loss=0.45032895900107717
Epoch #47: loss=0.4698231196081316
Epoch #48: loss=0.510756422136281
Epoch #49: loss=0.41518274916184916
Epoch #50: loss=0.37851414124707916
Epoch #51: loss=0.3917526864522212
Epoch #52: loss=0.3892170323713406
Epoch #53: loss=0.3696054647097716
Epoch #54: loss=0.40456699116809947
Epoch #55: loss=0.3594013533076724
Epoch #56: loss=0.402563965401134
Epoch #57: loss=0.38192561107712825
Epoch #58: loss=0.3581990345909789
Epoch #59: loss=0.3536114910164395
Epoch #60: loss=0.3171759783416181
Epoch #61: loss=0.34333357899575623
Epoch #62: loss=0.3671589711227933
Epoch #63: loss=0.2824624809058937
Epoch #64: loss=0.2664020603170266
Epoch #65: loss=0.30504703199541244
Epoch #66: loss=0.3222435092603838
Epoch #67: loss=0.30349788955740026
Epoch #68: loss=0.33290838208552953
Epoch #69: loss=0.34653083738443013
Epoch #70: loss=0.3201394193881267
Epoch #71: loss=0.32855812963601705
Epoch #72: loss=0.3779317442629788
Epoch #73: loss=0.2859825536205962
Epoch #74: loss=0.2843953367020633
Epoch #75: loss=0.2506590233864011
Epoch #76: loss=0.3441062201116536
Epoch #77: loss=0.25431969198020726
Epoch #78: loss=0.2260503930014533
Epoch #79: loss=0.20550315847267975
Epoch #80: loss=0.22662890299751953
Epoch #81: loss=0.19957625926346392
Epoch #82: loss=0.23269702765989947
Epoch #83: loss=0.22792290966655757
Epoch #84: loss=0.3449033764568535
Epoch #85: loss=0.34997839339681575
Epoch #86: loss=0.33529959739865484
Epoch #87: loss=0.32650890946388245
Epoch #88: loss=0.32974741386400686
Epoch #89: loss=0.2657057638909366
Epoch #90: loss=0.30592616325294647
Epoch #91: loss=0.20023137592786067
Epoch #92: loss=0.22222240893421946
Epoch #93: loss=0.21662051995863785
Epoch #94: loss=0.24496929438130274
Epoch #95: loss=0.19312533132127813
Epoch #96: loss=0.23150965410309868
Epoch #97: loss=0.18957888868612213
Epoch #98: loss=0.25874720554094055
Epoch #99: loss=0.25527631924361793
Epoch #100: loss=0.19616643782403018
Epoch #101: loss=0.21535982070742427
Epoch #102: loss=0.2706842745679456
Epoch #103: loss=0.18897676065161423
Epoch #104: loss=0.18468621655090436
Epoch #105: loss=0.19072398241307284
Epoch #106: loss=0.17778925889649907
Epoch #107: loss=0.17155387232432495
Epoch #108: loss=0.20853369018516024
Epoch #109: loss=0.1492366648807719
Epoch #110: loss=0.23404833422722043
Epoch #111: loss=0.2791662401444203
Epoch #112: loss=0.2575287263135652
Epoch #113: loss=0.18803617740805084
Epoch #114: loss=0.1973186380959846
Epoch #115: loss=0.22311943386857575
Epoch #116: loss=0.20225612809126442
Epoch #117: loss=0.16968512917692596
Epoch #118: loss=0.23678876912674388
Epoch #119: loss=0.16927137870240855
Epoch #120: loss=0.16759833794187856
Epoch #121: loss=0.12770646322216536
Epoch #122: loss=0.1318219176720123
Epoch #123: loss=0.1297117166623876
Epoch #124: loss=0.15024472219315735
Epoch #125: loss=0.11504963483359362
Epoch #126: loss=0.18081427717933785
Epoch #127: loss=0.3093103384850798
Epoch #128: loss=0.1621891811892793
Epoch #129: loss=0.1654852209864436
Epoch #130: loss=0.10890204222822511
Epoch #131: loss=0.14894087758620042
Epoch #132: loss=0.1348720584064722
Epoch #133: loss=0.1735237202028165
Epoch #134: loss=0.1514240247071595
Epoch #135: loss=0.15454841188683704
Epoch #136: loss=0.17713834566844477
Epoch #137: loss=0.1444329846448995
Epoch #138: loss=0.11505233355470605
Epoch #139: loss=0.14886475676620328
Epoch #140: loss=0.1751775616226164
Epoch #141: loss=0.16839990694377874
Epoch #142: loss=0.15564805062840115
Epoch #143: loss=0.2755443406467502
Epoch #144: loss=0.11800431148023219
Epoch #145: loss=0.2244257362106362
Epoch #146: loss=0.1386464502964471
Epoch #147: loss=0.18610179273260608
Epoch #148: loss=0.14155596675905022
Epoch #149: loss=0.1290954664550923
Epoch #150: loss=0.16257924526124387
Epoch #151: loss=0.16884330997394548
Epoch #152: loss=0.2170422707961218
Epoch #153: loss=0.15050138583457148
Epoch #154: loss=0.15339533909148462
Epoch #155: loss=0.183084320830735
Epoch #156: loss=0.11604151175030179
Epoch #157: loss=0.13886065866697478
Epoch #158: loss=0.15019659728214546
Epoch #159: loss=0.14968707548404062
Epoch #160: loss=0.11816858892907968
Epoch #161: loss=0.11425151222863712
Epoch #162: loss=0.11031547299510724
Epoch #163: loss=0.08736346020187075
Epoch #164: loss=0.09065341529109187
Epoch #165: loss=0.16840991971863284
Epoch #166: loss=0.12271865935543098
Epoch #167: loss=0.13899365847779288
Epoch #168: loss=0.21451823891618768
Epoch #169: loss=0.14540604089160222
Epoch #170: loss=0.1152572216516411
Epoch #171: loss=0.14185844459948507
Epoch #172: loss=0.1459402500374897
Epoch #173: loss=0.12204429039077179
Epoch #174: loss=0.1847149884781322
Epoch #175: loss=0.18146207108086831
Epoch #176: loss=0.1828875948448439
Epoch #177: loss=0.12752316731053429
Epoch #178: loss=0.13335809594876058
Epoch #179: loss=0.13308505910272533
Epoch #180: loss=0.09473435306367842
Epoch #181: loss=0.08939820185706422
Epoch #182: loss=0.10675422487327375
Epoch #183: loss=0.19867359630360798
Epoch #184: loss=0.1302573867645618
Epoch #185: loss=0.12867783281851458
Epoch #186: loss=0.08582812006509788
Epoch #187: loss=0.09803470714974243
Epoch #188: loss=0.10987257698198429
Epoch #189: loss=0.10586611403001321
Epoch #190: loss=0.13384364583101627
Epoch #191: loss=0.11654099769185523
Epoch #192: loss=0.10075980752102427
Epoch #193: loss=0.09431554226053727
Epoch #194: loss=0.10541760533846714
Epoch #195: loss=0.14097425019418872
Epoch #196: loss=0.11946533705938507
Epoch #197: loss=0.0797033712418901
Epoch #198: loss=0.07385326076198269
Epoch #199: loss=0.09432750263226193
Epoch #200: loss=0.07150943333132041
Epoch #201: loss=0.09957642664478437
Epoch #202: loss=0.10871954878943192
Epoch #203: loss=0.10016919722830928
Epoch #204: loss=0.0900094579603221
Epoch #205: loss=0.09256038067207949
Epoch #206: loss=0.06906888920914482
Epoch #207: loss=0.10203943601683588
Epoch #208: loss=0.12038020183005042
Epoch #209: loss=0.11924932036246802
Epoch #210: loss=0.12123525822283449
Epoch #211: loss=0.112136538719406
Epoch #212: loss=0.14417785642718947
Epoch #213: loss=0.11279406056210801
Epoch #214: loss=0.10564172267913818
Epoch #215: loss=0.10163536597345327
Epoch #216: loss=0.06700996790282629
Epoch #217: loss=0.06956663252030676
Epoch #218: loss=0.13621129093037262
Epoch #219: loss=0.10311106700651548
Epoch #220: loss=0.12886048387736082
Epoch #221: loss=0.10056629870086908
Epoch #222: loss=0.08167800317342216
Epoch #223: loss=0.0783562946661904
Epoch #224: loss=0.11168389201063562
Epoch #225: loss=0.13333792113573165
Epoch #226: loss=0.12555874712966583
Epoch #227: loss=0.10688961478503975
Epoch #228: loss=0.10302592813968658
Epoch #229: loss=0.09169635815998993
Epoch #230: loss=0.12569543865282792
Epoch #231: loss=0.08627412430438641
Epoch #232: loss=0.1381968713390666
Epoch #233: loss=0.15514228392291712
Epoch #234: loss=0.16046912751689152
Epoch #235: loss=0.1195922579012207
Epoch #236: loss=0.1093663407388974
Epoch #237: loss=0.1067465822640303
Epoch #238: loss=0.0885461488537289
Epoch #239: loss=0.11226620522604601
Epoch #240: loss=0.07450850499240128
Epoch #241: loss=0.05817906873149646
Epoch #242: loss=0.09963558205227191
Epoch #243: loss=0.15318015884809397
Epoch #244: loss=0.10011971918110912
Epoch #245: loss=0.09105619476050944
Epoch #246: loss=0.10396238119416945
Epoch #247: loss=0.11962663523248725
Epoch #248: loss=0.1952139395918395
Epoch #249: loss=0.18916309483953425

Training time: 0:11:26.486414

Finished.
n2one setting etth1_ettm1_ettm2_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_ettm2_exchange_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_ettm1_ettm2_exchange', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.66479e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.22136e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.66479e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3661222260906597, 'MAE': 0.4283301874435862}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm1_ettm2_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_ettm2_exchange_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_ettm1_ettm2_exchange', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.62015e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.10181e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.62015e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.8886780394657706, 'MAE': 0.7629700428087913}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm1_electricity_traffic', random_seed=2023, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm1_electricity_traffic_epochs_250_seed_2023
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.8381346524704704
Epoch #1: loss=0.3086351575911492
Epoch #2: loss=0.21285487895677926
Epoch #3: loss=0.1488321175477735
Epoch #4: loss=0.1149459838646958
Epoch #5: loss=0.09052164453336911
Epoch #6: loss=0.07047103100272514
Epoch #7: loss=0.06751861141414554
Epoch #8: loss=0.05972652765825316
Epoch #9: loss=0.05087454101597296
Epoch #10: loss=0.04885543092385828
Epoch #11: loss=0.04100811797067008
Epoch #12: loss=0.04611529822156553
Epoch #13: loss=0.03558164328235131
Epoch #14: loss=0.03526006526320313
Epoch #15: loss=0.03544302764676316
Epoch #16: loss=0.03712626773102921
Epoch #17: loss=0.04216685455752309
Epoch #18: loss=0.031259489036242726
Epoch #19: loss=0.030950652796590546
Epoch #20: loss=0.034115915543025205
Epoch #21: loss=0.02748749652244678
Epoch #22: loss=0.03790898425638332
Epoch #23: loss=0.025920954034157753
Epoch #24: loss=0.02308456033028563
Epoch #25: loss=0.029283540658567482
Epoch #26: loss=0.024173739478092867
Epoch #27: loss=0.02489285814640989
Epoch #28: loss=0.02498461855292401
Epoch #29: loss=0.022634930398672287
Epoch #30: loss=0.02734238705841117
Epoch #31: loss=0.020625348358460045
Epoch #32: loss=0.018646905781884604
Epoch #33: loss=0.01909661509670363
Epoch #34: loss=0.023043261050265267
Epoch #35: loss=0.02333167677377463
Epoch #36: loss=0.020879896650487072
Epoch #37: loss=0.02917116376506219
Epoch #38: loss=0.020902740911190567
Epoch #39: loss=0.020598543390911227
Epoch #40: loss=0.020247394301869257
Epoch #41: loss=0.017669653023890126
Epoch #42: loss=0.017642078579852838
Epoch #43: loss=0.020803187944863123
Epoch #44: loss=0.019371302294586362
Epoch #45: loss=0.017082084169842807
Epoch #46: loss=0.024779246082608133
Epoch #47: loss=0.016668390453875307
Epoch #48: loss=0.019267947404351872
Epoch #49: loss=0.016100899608135783
Epoch #50: loss=0.017500609711182266
Epoch #51: loss=0.014973635378700419
Epoch #52: loss=0.017758485190837888
Epoch #53: loss=0.01808222383202568
Epoch #54: loss=0.024113952144332925
Epoch #55: loss=0.01527512969803352
Epoch #56: loss=0.017045860889231667
Epoch #57: loss=0.012503229510351817
Epoch #58: loss=0.01882692765782616
Epoch #59: loss=0.02873442338542667
Epoch #60: loss=0.014573543699889394
Epoch #61: loss=0.017194960922920544
Epoch #62: loss=0.014778211314301336
Epoch #63: loss=0.01795477012640426
Epoch #64: loss=0.01688474586198989
Epoch #65: loss=0.01486485723758812
Epoch #66: loss=0.015945403539680034
Epoch #67: loss=0.016900911679368105
Epoch #68: loss=0.012520161392827318
Epoch #69: loss=0.01617966575600784
Epoch #70: loss=0.01971074533288202
Epoch #71: loss=0.01605191019181884
Epoch #72: loss=0.010923056423673883
Epoch #73: loss=0.010568364572253382
Epoch #74: loss=0.020923908705596107
Epoch #75: loss=0.013615275212938895
Epoch #76: loss=0.013965457294087432
Epoch #77: loss=0.01683526089321221
Epoch #78: loss=0.012550111756197318
Epoch #79: loss=0.0128080447443203
Epoch #80: loss=0.01590207918974031
Epoch #81: loss=0.011866322009660693
Epoch #82: loss=0.01625300198279672
Epoch #83: loss=0.01252206461530758
Epoch #84: loss=0.014495338583091735
Epoch #85: loss=0.015412618989065959
Epoch #86: loss=0.01253559152422142
Epoch #87: loss=0.013774793867309105
Epoch #88: loss=0.01129757403170703
Epoch #89: loss=0.015539248676287813
Epoch #90: loss=0.011001514759099655
Epoch #91: loss=0.014466859252717646
Epoch #92: loss=0.010054748216866145
Epoch #93: loss=0.012082693633649302
Epoch #94: loss=0.015845535753632053
Epoch #95: loss=0.01074994526393035
Epoch #96: loss=0.014426088846631954
Epoch #97: loss=0.012059600368460259
Epoch #98: loss=0.010483122035138097
Epoch #99: loss=0.013755975760283767
Epoch #100: loss=0.01362308437361589
Epoch #101: loss=0.011712595080569283
Epoch #102: loss=0.012034842639322665
Epoch #103: loss=0.012229105109726152
Epoch #104: loss=0.009689492420808826
Epoch #105: loss=0.016117257085554365
Epoch #106: loss=0.011019808925162362
Epoch #107: loss=0.009827918165750155
Epoch #108: loss=0.017530725900497486
Epoch #109: loss=0.012757782237535438
Epoch #110: loss=0.012308226423515442
Epoch #111: loss=0.011120683000817576
Epoch #112: loss=0.014645089786864688
Epoch #113: loss=0.01173760360192126
Epoch #114: loss=0.011477699176054113
Epoch #115: loss=0.016389625291716635
Epoch #116: loss=0.009854097514194037
Epoch #117: loss=0.012880248735039138
Epoch #118: loss=0.012356369924145308
Epoch #119: loss=0.01175074595910013
Epoch #120: loss=0.013398064852851494
Epoch #121: loss=0.011251626429782438
Epoch #122: loss=0.012476200722863378
Epoch #123: loss=0.01015912306018687
Epoch #124: loss=0.009865322178315475
Epoch #125: loss=0.010420328187877647
Epoch #126: loss=0.01414519395610123
Epoch #127: loss=0.010662607224275008
Epoch #128: loss=0.013379137325898351
Epoch #129: loss=0.01123548254564214
Epoch #130: loss=0.009568841795169845
Epoch #131: loss=0.00859986840315695
Epoch #132: loss=0.011412126079914051
Epoch #133: loss=0.011547441685661056
Epoch #134: loss=0.009387413304558095
Epoch #135: loss=0.011365483152063321
Epoch #136: loss=0.012755760718889219
Epoch #137: loss=0.010340505640514775
Epoch #138: loss=0.010121843727580043
Epoch #139: loss=0.017602771612112367
Epoch #140: loss=0.01335870991035599
Epoch #141: loss=0.007217065254494829
Epoch #142: loss=0.010627849080827053
Epoch #143: loss=0.01495058955311473
Epoch #144: loss=0.010351768886210238
Epoch #145: loss=0.007977992607922623
Epoch #146: loss=0.02005905435009775
Epoch #147: loss=0.01207277349479755
Epoch #148: loss=0.01332473856854056
Epoch #149: loss=0.011355121297337041
Epoch #150: loss=0.010031063244917017
Epoch #151: loss=0.01140945526461259
Epoch #152: loss=0.010267532769911752
Epoch #153: loss=0.009639893266592774
Epoch #154: loss=0.011561688781636397
Epoch #155: loss=0.011666701207490235
Epoch #156: loss=0.009059433440433456
Epoch #157: loss=0.015092367731737706
Epoch #158: loss=0.010021410476715675
Epoch #159: loss=0.011841098768632222
Epoch #160: loss=0.014197551885632943
Epoch #161: loss=0.010692635809043154
Epoch #162: loss=0.009720026941155617
Epoch #163: loss=0.00926082565697421
Epoch #164: loss=0.011405019464076332
Epoch #165: loss=0.00834617744836581
Epoch #166: loss=0.008646398373113682
Epoch #167: loss=0.01164667311250612
Epoch #168: loss=0.010559325189124964
Epoch #169: loss=0.012773504168186593
Epoch #170: loss=0.00947829249671213
Epoch #171: loss=0.011905434985110439
Epoch #172: loss=0.01081207433096455
Epoch #173: loss=0.009305477686122079
Epoch #174: loss=0.009289302443247016
Epoch #175: loss=0.010623563671422651
Epoch #176: loss=0.015804300113208127
Epoch #177: loss=0.00906285347106233
Epoch #178: loss=0.009397995926211584
Epoch #179: loss=0.008736620619730228
Epoch #180: loss=0.009435500330013736
Epoch #181: loss=0.009583762947859174
Epoch #182: loss=0.009116490594129606
Epoch #183: loss=0.009594265297437232
Epoch #184: loss=0.010653841829289535
Epoch #185: loss=0.009896446614246369
Epoch #186: loss=0.007302190824932304
Epoch #187: loss=0.009931182025949593
Epoch #188: loss=0.00954215062835384
Epoch #189: loss=0.011354389517324462
Epoch #190: loss=0.010233079974359672
Epoch #191: loss=0.009365611724496781
Epoch #192: loss=0.012690676151656373
Epoch #193: loss=0.009312918197763363
Epoch #194: loss=0.01661654608266011
Epoch #195: loss=0.012812949926369466
Epoch #196: loss=0.008605590165302128
Epoch #197: loss=0.008458333734509094
Epoch #198: loss=0.011143582850327963
Epoch #199: loss=0.012192264634960141
Epoch #200: loss=0.011261769822912032
Epoch #201: loss=0.013396308700514137
Epoch #202: loss=0.009975115389498296
Epoch #203: loss=0.012227468053698051
Epoch #204: loss=0.01287579608206132
Epoch #205: loss=0.009735360889545632
Epoch #206: loss=0.010664414888053789
Epoch #207: loss=0.010492476833440274
Epoch #208: loss=0.008256043307592244
Epoch #209: loss=0.009187207913292195
Epoch #210: loss=0.006544298343406307
Epoch #211: loss=0.015246731597710351
Epoch #212: loss=0.01177884627508756
Epoch #213: loss=0.008645933010189101
Epoch #214: loss=0.010804698415731227
Epoch #215: loss=0.008105238857205072
Epoch #216: loss=0.010642043922752866
Epoch #217: loss=0.012258441546804591
Epoch #218: loss=0.008554804912816964
Epoch #219: loss=0.01079330228205949
Epoch #220: loss=0.00833072880802602
Epoch #221: loss=0.009301797894440703
Epoch #222: loss=0.007789467620109088
Epoch #223: loss=0.005696111814046272
Epoch #224: loss=0.012354534271720457
Epoch #225: loss=0.014733791697244404
Epoch #226: loss=0.008182734620006082
Epoch #227: loss=0.009472834800766392
Epoch #228: loss=0.008014804219828838
Epoch #229: loss=0.012232884446698044
Epoch #230: loss=0.008718676829405655
Epoch #231: loss=0.012520186905903022
Epoch #232: loss=0.008056384842657915
Epoch #233: loss=0.00817528899995229
Epoch #234: loss=0.01171068270953861
Epoch #235: loss=0.00877387876354895
Epoch #236: loss=0.007809366360671204
Epoch #237: loss=0.00871046541315301
Epoch #238: loss=0.009325010301188067
Epoch #239: loss=0.010141479073599729
Epoch #240: loss=0.00977618503460626
Epoch #241: loss=0.00868842995844229
Epoch #242: loss=0.00851673381881448
Epoch #243: loss=0.009008809712026358
Epoch #244: loss=0.007797005250450713
Epoch #245: loss=0.008616779725290794
Epoch #246: loss=0.010955231743356306
Epoch #247: loss=0.006986214953477914
Epoch #248: loss=0.010656699884556786
Epoch #249: loss=0.007805606885009852

Training time: 5:01:22.848759

Finished.
n2one setting etth1_ettm1_electricity_traffic -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_electricity_traffic_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_ettm1_electricity_traffic', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.18481e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.45256e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.18481e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.5505520597018613, 'MAE': 0.5703692651897055}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm1_electricity_traffic -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_electricity_traffic_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_ettm1_electricity_traffic', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
Evaluation result: {'MSE': 0.2640274758639759, 'MAE': 0.34341650194639783}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm1_electricity_weather', random_seed=2023, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm1_electricity_weather_epochs_250_seed_2023
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.7533360765404897
Epoch #1: loss=0.789802446593977
Epoch #2: loss=0.5860990567566597
Epoch #3: loss=0.47963805292567163
Epoch #4: loss=0.39427198457391294
Epoch #5: loss=0.3522207750441277
Epoch #6: loss=0.31920746287254437
Epoch #7: loss=0.28858236109148966
Epoch #8: loss=0.2505739875035743
Epoch #9: loss=0.24483443018916534
Epoch #10: loss=0.21514516529971606
Epoch #11: loss=0.20610634631490055
Epoch #12: loss=0.19503777766064423
Epoch #13: loss=0.18067691585380738
Epoch #14: loss=0.15278423990901202
Epoch #15: loss=0.1589526226055132
Epoch #16: loss=0.14357149539234704
Epoch #17: loss=0.11779787184747115
Epoch #18: loss=0.11387151774172097
Epoch #19: loss=0.12590153017783
Epoch #20: loss=0.10070608458290362
Epoch #21: loss=0.0960622023357308
Epoch #22: loss=0.08746179891622638
Epoch #23: loss=0.1034205306767907
Epoch #24: loss=0.09579067858165666
Epoch #25: loss=0.06785305464538197
Epoch #26: loss=0.07032049261288692
Epoch #27: loss=0.06346710970982501
Epoch #28: loss=0.07942606672670131
Epoch #29: loss=0.05200267908967113
Epoch #30: loss=0.06734051010890366
Epoch #31: loss=0.0490955838780493
Epoch #32: loss=0.07447816726100975
Epoch #33: loss=0.04465176014369992
Epoch #34: loss=0.06481725853191664
Epoch #35: loss=0.053752409757357344
Epoch #36: loss=0.0956502870816023
Epoch #37: loss=0.05664977565190869
Epoch #38: loss=0.04503193590790033
Epoch #39: loss=0.042872845597743785
Epoch #40: loss=0.04276737266456172
Epoch #41: loss=0.04138958844330723
Epoch #42: loss=0.042549892784134576
Epoch #43: loss=0.04823107101431448
Epoch #44: loss=0.05592064642577037
Epoch #45: loss=0.04084314063370024
Epoch #46: loss=0.06086788065221212
Epoch #47: loss=0.04554355967254059
Epoch #48: loss=0.03677233892065562
Epoch #49: loss=0.0344844020533133
Epoch #50: loss=0.03291271288069093
Epoch #51: loss=0.027996573566892887
Epoch #52: loss=0.03791375291495495
Epoch #53: loss=0.06821054988604498
Epoch #54: loss=0.040376179690204864
Epoch #55: loss=0.03166154820873874
Epoch #56: loss=0.02991728773468161
Epoch #57: loss=0.034778345688820295
Epoch #58: loss=0.053345506861231816
Epoch #59: loss=0.043799467615413236
Epoch #60: loss=0.029458923692406755
Epoch #61: loss=0.032592319937945945
Epoch #62: loss=0.0501804388944723
Epoch #63: loss=0.040170142512883325
Epoch #64: loss=0.0258680318169653
Epoch #65: loss=0.034041026939178674
Epoch #66: loss=0.03135306627030344
Epoch #67: loss=0.03031580753158778
Epoch #68: loss=0.024738589080994668
Epoch #69: loss=0.03669606382059163
Epoch #70: loss=0.031031223220355196
Epoch #71: loss=0.03146275564906991
Epoch #72: loss=0.02886194517797701
Epoch #73: loss=0.029760944941846577
Epoch #74: loss=0.023480298078765657
Epoch #75: loss=0.030735197365092597
Epoch #76: loss=0.035646137216587694
Epoch #77: loss=0.03157060616426425
Epoch #78: loss=0.02437927878066285
Epoch #79: loss=0.022871579636806902
Epoch #80: loss=0.030740043485205468
Epoch #81: loss=0.021579829317976862
Epoch #82: loss=0.022460529189046525
Epoch #83: loss=0.021961733812230242
Epoch #84: loss=0.0225388241671855
Epoch #85: loss=0.018151497423221447
Epoch #86: loss=0.03193429975885234
Epoch #87: loss=0.04483796192416028
Epoch #88: loss=0.020372149323062232
Epoch #89: loss=0.020355154625108236
Epoch #90: loss=0.022413233235918546
Epoch #91: loss=0.024691914367387453
Epoch #92: loss=0.016259047825348705
Epoch #93: loss=0.022247305440027523
Epoch #94: loss=0.029512058509743377
Epoch #95: loss=0.020065604843843524
Epoch #96: loss=0.016468796702516456
Epoch #97: loss=0.02227454565159262
Epoch #98: loss=0.02202135232175152
Epoch #99: loss=0.020190913094150234
Epoch #100: loss=0.024580231610660072
Epoch #101: loss=0.0346490603307109
Epoch #102: loss=0.036705680468202606
Epoch #103: loss=0.02424322000373002
Epoch #104: loss=0.020997452702092592
Epoch #105: loss=0.02528463346590224
Epoch #106: loss=0.03548711666834145
Epoch #107: loss=0.02392011625143661
Epoch #108: loss=0.028638994529179923
Epoch #109: loss=0.0223378387383466
Epoch #110: loss=0.038132692077069555
Epoch #111: loss=0.017265495016759464
Epoch #112: loss=0.043672770006926605
Epoch #113: loss=0.019397441413387503
Epoch #114: loss=0.019522317251898604
Epoch #115: loss=0.03299733396150708
Epoch #116: loss=0.02038130689083841
Epoch #117: loss=0.01470916764061158
Epoch #118: loss=0.015116805602215894
Epoch #119: loss=0.025548089396731595
Epoch #120: loss=0.015520258287561114
Epoch #121: loss=0.01788130769735738
Epoch #122: loss=0.012812248527786809
Epoch #123: loss=0.0206030854799032
Epoch #124: loss=0.02298522942208315
Epoch #125: loss=0.019798425873996665
Epoch #126: loss=0.02133560750540984
Epoch #127: loss=0.017909956547233902
Epoch #128: loss=0.018451889335139565
Epoch #129: loss=0.0299637087968446
Epoch #130: loss=0.01413766739520002
Epoch #131: loss=0.015853907838814622
Epoch #132: loss=0.020393032425127872
Epoch #133: loss=0.013595482621227123
Epoch #134: loss=0.019141403971397804
Epoch #135: loss=0.018161470838503477
Epoch #136: loss=0.020295800402926358
Epoch #137: loss=0.021472203283098668
Epoch #138: loss=0.02745304200575011
Epoch #139: loss=0.022433618979994206
Epoch #140: loss=0.0181445267151129
Epoch #141: loss=0.01856505524467562
Epoch #142: loss=0.013549130350392796
Epoch #143: loss=0.020852426374937113
Epoch #144: loss=0.017096224937696417
Epoch #145: loss=0.013379414664734511
Epoch #146: loss=0.016456762375469537
Epoch #147: loss=0.03147071259278064
Epoch #148: loss=0.02691346551307592
Epoch #149: loss=0.02016871608761841
Epoch #150: loss=0.0130595238595461
Epoch #151: loss=0.025096979792618945
Epoch #152: loss=0.020653827782490686
Epoch #153: loss=0.015212742664232493
Epoch #154: loss=0.013543075375252544
Epoch #155: loss=0.01433838747237643
Epoch #156: loss=0.03236407554877463
Epoch #157: loss=0.01948630222747715
Epoch #158: loss=0.022158530521468094
Epoch #159: loss=0.017058378482741395
Epoch #160: loss=0.017599795951527122
Epoch #161: loss=0.014889878137292315
Epoch #162: loss=0.01262487597653502
Epoch #163: loss=0.019533920069607868
Epoch #164: loss=0.01165307452304174
Epoch #165: loss=0.012855074927450017
Epoch #166: loss=0.022963096444137802
Epoch #167: loss=0.01867645684077902
Epoch #168: loss=0.015279742438754398
Epoch #169: loss=0.014918051286734487
Epoch #170: loss=0.023891859324824398
Epoch #171: loss=0.03198845497801364
Epoch #172: loss=0.0271781562156146
Epoch #173: loss=0.01583067708702962
Epoch #174: loss=0.012835176529088504
Epoch #175: loss=0.013497150598463846
Epoch #176: loss=0.019470819113504984
Epoch #177: loss=0.021109307122939867
Epoch #178: loss=0.013053204062114125
Epoch #179: loss=0.008348227686117952
Epoch #180: loss=0.014966530260695336
Epoch #181: loss=0.013361954856472574
Epoch #182: loss=0.01933237682583053
Epoch #183: loss=0.010587113282534817
Epoch #184: loss=0.018548242632165705
Epoch #185: loss=0.02716824734098699
Epoch #186: loss=0.022592059425349437
Epoch #187: loss=0.01922896325951825
Epoch #188: loss=0.014972287008765293
Epoch #189: loss=0.013431288699590767
Epoch #190: loss=0.011263320631545344
Epoch #191: loss=0.011832636464801809
Epoch #192: loss=0.01374648311175406
Epoch #193: loss=0.01439873253534331
Epoch #194: loss=0.02347926486742823
Epoch #195: loss=0.012105302608887702
Epoch #196: loss=0.0139749295678634
Epoch #197: loss=0.01033727202711193
Epoch #198: loss=0.013186183466084862
Epoch #199: loss=0.01609248376956962
Epoch #200: loss=0.014631595775446765
Epoch #201: loss=0.01486345087760128
Epoch #202: loss=0.011854352349214486
Epoch #203: loss=0.00993458400643909
Epoch #204: loss=0.010664734443209504
Epoch #205: loss=0.01635960913733707
Epoch #206: loss=0.013080849055175299
Epoch #207: loss=0.013069720987441044
Epoch #208: loss=0.02813843174523368
Epoch #209: loss=0.01496789085324726
Epoch #210: loss=0.015275583105091618
Epoch #211: loss=0.010019564343543008
Epoch #212: loss=0.013288224841649836
Epoch #213: loss=0.014869768033681233
Epoch #214: loss=0.01719373185897233
Epoch #215: loss=0.010346562917940701
Epoch #216: loss=0.020863003646699737
Epoch #217: loss=0.01299969073487063
Epoch #218: loss=0.014091015101349849
Epoch #219: loss=0.01644190757269078
Epoch #220: loss=0.01223715728504443
Epoch #221: loss=0.012857812761699092
Epoch #222: loss=0.03748903064749344
Epoch #223: loss=0.02051930610849586
Epoch #224: loss=0.014804273343418585
Epoch #225: loss=0.010050942076765613
Epoch #226: loss=0.015765668286571968
Epoch #227: loss=0.009837264894772551
Epoch #228: loss=0.017392465876405805
Epoch #229: loss=0.01574077737351803
Epoch #230: loss=0.010753540506694874
Epoch #231: loss=0.013910351956122849
Epoch #232: loss=0.018242101186538778
Epoch #233: loss=0.01497175784794333
Epoch #234: loss=0.012924972873050337
Epoch #235: loss=0.014262037251817624
Epoch #236: loss=0.019375746263899166
Epoch #237: loss=0.014946920976157569
Epoch #238: loss=0.012117256099048823
Epoch #239: loss=0.015017262565080484
Epoch #240: loss=0.010634697222291198
Epoch #241: loss=0.00956839033855406
Epoch #242: loss=0.01783420774824152
Epoch #243: loss=0.016135739728055692
Epoch #244: loss=0.020975899380434
Epoch #245: loss=0.014346251813439678
Epoch #246: loss=0.01383234747360167
Epoch #247: loss=0.014242689083298439
Epoch #248: loss=0.009781837070676536
Epoch #249: loss=0.013072929197239805

Training time: 1:49:08.085919

Finished.
n2one setting etth1_ettm1_electricity_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_electricity_weather_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_ettm1_electricity_weather', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.80096e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.291238087671292, 'MAE': 0.3596692801811672}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm1_electricity_exchange', random_seed=2023, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm1_electricity_exchange_epochs_250_seed_2023
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.6970929240630752
Epoch #1: loss=0.7179437341538905
Epoch #2: loss=0.5211754917926679
Epoch #3: loss=0.4368606503054457
Epoch #4: loss=0.3645712715662178
Epoch #5: loss=0.3103006372620118
Epoch #6: loss=0.2869456477184117
Epoch #7: loss=0.24629518205047685
Epoch #8: loss=0.22054522825936418
Epoch #9: loss=0.21275716704405007
Epoch #10: loss=0.18596252526347162
Epoch #11: loss=0.17815715056288484
Epoch #12: loss=0.17563653644979516
Epoch #13: loss=0.1444045533385847
Epoch #14: loss=0.12675552113083666
Epoch #15: loss=0.13320921420492768
Epoch #16: loss=0.11602734357805691
Epoch #17: loss=0.09898029272887394
Epoch #18: loss=0.11561130752158955
Epoch #19: loss=0.10519386419988846
Epoch #20: loss=0.10803736186712465
Epoch #21: loss=0.09086724098836224
Epoch #22: loss=0.08632258097681429
Epoch #23: loss=0.08615149523773008
Epoch #24: loss=0.09105510545105429
Epoch #25: loss=0.07515385986764725
Epoch #26: loss=0.07396284962792261
Epoch #27: loss=0.0795337592321381
Epoch #28: loss=0.06736207266018782
Epoch #29: loss=0.06132483244028147
Epoch #30: loss=0.0623474831743869
Epoch #31: loss=0.056829038787343314
Epoch #32: loss=0.06076592397782146
Epoch #33: loss=0.04711268084614889
Epoch #34: loss=0.04637997654422323
Epoch #35: loss=0.06453943910930703
Epoch #36: loss=0.05497148465995894
Epoch #37: loss=0.047490922216814474
Epoch #38: loss=0.055455701524305887
Epoch #39: loss=0.06201992979842193
Epoch #40: loss=0.051831558798990006
Epoch #41: loss=0.061280340252857474
Epoch #42: loss=0.05063492423312615
Epoch #43: loss=0.04577089222322516
Epoch #44: loss=0.0445137036976375
Epoch #45: loss=0.04246294500221705
Epoch #46: loss=0.048382574959419215
Epoch #47: loss=0.040535431150588545
Epoch #48: loss=0.044328351942916275
Epoch #49: loss=0.036478834358575386
Epoch #50: loss=0.0384987144773257
Epoch #51: loss=0.035302883918901705
Epoch #52: loss=0.04387258010130021
Epoch #53: loss=0.03570989063190785
Epoch #54: loss=0.03624962910846069
Epoch #55: loss=0.040951910855782675
Epoch #56: loss=0.032334153069403314
Epoch #57: loss=0.0321223320327404
Epoch #58: loss=0.028451461656963835
Epoch #59: loss=0.028504987914915
Epoch #60: loss=0.04779109676363167
Epoch #61: loss=0.040184761124451025
Epoch #62: loss=0.02584448241580396
Epoch #63: loss=0.047533481149673894
Epoch #64: loss=0.0329423079787826
Epoch #65: loss=0.0415434182936229
Epoch #66: loss=0.028293956596181547
Epoch #67: loss=0.029596245614476286
Epoch #68: loss=0.024682517218140493
Epoch #69: loss=0.02787477570426213
Epoch #70: loss=0.022854489116977784
Epoch #71: loss=0.027196421511726243
Epoch #72: loss=0.03595894344032927
Epoch #73: loss=0.023404390869027417
Epoch #74: loss=0.03194470136286825
Epoch #75: loss=0.03417812052192247
Epoch #76: loss=0.03423352526522293
Epoch #77: loss=0.03036721559242756
Epoch #78: loss=0.0301796398653987
Epoch #79: loss=0.028747943086047747
Epoch #80: loss=0.03379813745793664
Epoch #81: loss=0.03378690698758433
Epoch #82: loss=0.03149928526801221
Epoch #83: loss=0.045403532622790004
Epoch #84: loss=0.027666154946770886
Epoch #85: loss=0.025433693559214966
Epoch #86: loss=0.02339130322890415
Epoch #87: loss=0.02542783921954869
Epoch #88: loss=0.03451754437371691
Epoch #89: loss=0.03177887398577819
Epoch #90: loss=0.03757604807065075
Epoch #91: loss=0.029625936899124846
Epoch #92: loss=0.031795095557733424
Epoch #93: loss=0.02002412152660458
Epoch #94: loss=0.022701366566509406
Epoch #95: loss=0.02145885297963503
Epoch #96: loss=0.028361267984243543
Epoch #97: loss=0.01865325975352603
Epoch #98: loss=0.02323779743265425
Epoch #99: loss=0.032422533696946775
Epoch #100: loss=0.04213446740668954
Epoch #101: loss=0.04145692462626287
Epoch #102: loss=0.024632651467541882
Epoch #103: loss=0.02499952003418841
Epoch #104: loss=0.02672193913203221
Epoch #105: loss=0.024040611743791462
Epoch #106: loss=0.030796800780657583
Epoch #107: loss=0.02619980449985541
Epoch #108: loss=0.02279310317854974
Epoch #109: loss=0.022630404722903685
Epoch #110: loss=0.0183654408584891
Epoch #111: loss=0.017476503611126275
Epoch #112: loss=0.04992010519485545
Epoch #113: loss=0.022852283163044485
Epoch #114: loss=0.03526856157169154
Epoch #115: loss=0.02885363490695821
Epoch #116: loss=0.02491587657153993
Epoch #117: loss=0.021313211150931714
Epoch #118: loss=0.021497629430065848
Epoch #119: loss=0.0294408639664802
Epoch #120: loss=0.023552895102231235
Epoch #121: loss=0.03476690676671208
Epoch #122: loss=0.030636190548834395
Epoch #123: loss=0.020081916883029582
Epoch #124: loss=0.016762206373670506
Epoch #125: loss=0.020350639394991724
Epoch #126: loss=0.019908879074718944
Epoch #127: loss=0.017714252479720635
Epoch #128: loss=0.023586001907245815
Epoch #129: loss=0.021216937225051653
Epoch #130: loss=0.013788699709725773
Epoch #131: loss=0.014989540672838227
Epoch #132: loss=0.03643642120990601
Epoch #133: loss=0.01787185421579528
Epoch #134: loss=0.02113947113227738
Epoch #135: loss=0.029168812492969702
Epoch #136: loss=0.023492247225117523
Epoch #137: loss=0.015587066869876785
Epoch #138: loss=0.024848874981759347
Epoch #139: loss=0.020506886966655338
Epoch #140: loss=0.018470174296804694
Epoch #141: loss=0.020611291315798416
Epoch #142: loss=0.021135096609497157
Epoch #143: loss=0.023842841702156434
Epoch #144: loss=0.013130974956527782
Epoch #145: loss=0.03565757694101949
Epoch #146: loss=0.038381250666438334
Epoch #147: loss=0.021909897103610444
Epoch #148: loss=0.022925618481392882
Epoch #149: loss=0.01854514409818147
Epoch #150: loss=0.01721783010429979
Epoch #151: loss=0.021010414426488752
Epoch #152: loss=0.02218856380380803
Epoch #153: loss=0.014851223954176719
Epoch #154: loss=0.022222994692537728
Epoch #155: loss=0.01753683405443865
Epoch #156: loss=0.01701825266966988
Epoch #157: loss=0.03445898406663829
Epoch #158: loss=0.019642068906051444
Epoch #159: loss=0.030932161145137693
Epoch #160: loss=0.022185272299644326
Epoch #161: loss=0.03347513584674387
Epoch #162: loss=0.03007932180526696
Epoch #163: loss=0.02250272418779619
Epoch #164: loss=0.01705536782799922
Epoch #165: loss=0.019106683576270208
Epoch #166: loss=0.01671955388214477
Epoch #167: loss=0.015026627385570139
Epoch #168: loss=0.02284852285521851
Epoch #169: loss=0.02949812770193786
Epoch #170: loss=0.01926813970899655
Epoch #171: loss=0.018205104209214278
Epoch #172: loss=0.0158415516192276
Epoch #173: loss=0.014937957252495887
Epoch #174: loss=0.01565016506934909
Epoch #175: loss=0.019643196940283835
Epoch #176: loss=0.01951052092357273
Epoch #177: loss=0.01899946813880243
Epoch #178: loss=0.017916094225909163
Epoch #179: loss=0.013067499257812695
Epoch #180: loss=0.01630810520607342
Epoch #181: loss=0.01471127399480942
Epoch #182: loss=0.013942035163520576
Epoch #183: loss=0.01400584532840376
Epoch #184: loss=0.024944861461435274
Epoch #185: loss=0.022531771471103926
Epoch #186: loss=0.017930396116923767
Epoch #187: loss=0.025471195168940818
Epoch #188: loss=0.01827411229641013
Epoch #189: loss=0.019124059626391098
Epoch #190: loss=0.014798673446845767
Epoch #191: loss=0.015077357088911458
Epoch #192: loss=0.015474899002919188
Epoch #193: loss=0.018358522771303447
Epoch #194: loss=0.02160657788690593
Epoch #195: loss=0.016431930710283787
Epoch #196: loss=0.021604100150500374
Epoch #197: loss=0.016369964463283343
Epoch #198: loss=0.02759657646198918
Epoch #199: loss=0.01748985505356891
Epoch #200: loss=0.01794539117797812
Epoch #201: loss=0.011545280886006136
Epoch #202: loss=0.019172744719886628
Epoch #203: loss=0.012723579475560872
Epoch #204: loss=0.016083423532790474
Epoch #205: loss=0.028081732361593555
Epoch #206: loss=0.017520591004275898
Epoch #207: loss=0.01501456679353928
Epoch #208: loss=0.012888781506194456
Epoch #209: loss=0.02458760819648814
Epoch #210: loss=0.016187836622560306
Epoch #211: loss=0.011253062175031248
Epoch #212: loss=0.013801083024571078
Epoch #213: loss=0.01409154604370263
Epoch #214: loss=0.01704731475131087
Epoch #215: loss=0.014258248132894417
Epoch #216: loss=0.014452564291456737
Epoch #217: loss=0.013208614277733243
Epoch #218: loss=0.023372286879685667
Epoch #219: loss=0.01123167298355419
Epoch #220: loss=0.01994509369838427
Epoch #221: loss=0.026148475611465646
Epoch #222: loss=0.026291165555312676
Epoch #223: loss=0.017807944089486948
Epoch #224: loss=0.014282014257353743
Epoch #225: loss=0.014892361436833652
Epoch #226: loss=0.013137045301468801
Epoch #227: loss=0.013045307846172237
Epoch #228: loss=0.017281479833604667
Epoch #229: loss=0.01643881521710082
Epoch #230: loss=0.014753154713894651
Epoch #231: loss=0.02007904653058331
Epoch #232: loss=0.027818225285069217
Epoch #233: loss=0.028159213583327306
Epoch #234: loss=0.011494809068267714
Epoch #235: loss=0.016951264232891592
Epoch #236: loss=0.012312013678882077
Epoch #237: loss=0.01153279125696499
Epoch #238: loss=0.02520959362788904
Epoch #239: loss=0.01741001376414521
Epoch #240: loss=0.015803479058775376
Epoch #241: loss=0.01987817037744268
Epoch #242: loss=0.02148820266465761
Epoch #243: loss=0.0145725998491544
Epoch #244: loss=0.011382007229887352
Epoch #245: loss=0.023107095200988473
Epoch #246: loss=0.018155119917791614
Epoch #247: loss=0.016417529813909062
Epoch #248: loss=0.015157255558136002
Epoch #249: loss=0.01618353344551395

Training time: 1:37:14.768689

Finished.
n2one setting etth1_ettm1_electricity_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_electricity_exchange_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_ettm1_electricity_exchange', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.08631e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.79751e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.44406e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 1.020822369172179, 'MAE': 0.8265455335938091}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm1_traffic_weather', random_seed=2023, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm1_traffic_weather_epochs_250_seed_2023
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.0588745348171946
Epoch #1: loss=0.4093428175674369
Epoch #2: loss=0.3044237362891107
Epoch #3: loss=0.23340652837000672
Epoch #4: loss=0.18259787637222286
Epoch #5: loss=0.14822655232010562
Epoch #6: loss=0.14365664858033853
Epoch #7: loss=0.11739650930567885
Epoch #8: loss=0.10382321159094243
Epoch #9: loss=0.08603071651388593
Epoch #10: loss=0.08719376314412926
Epoch #11: loss=0.07863425620714364
Epoch #12: loss=0.0686885878010951
Epoch #13: loss=0.06896789051478247
Epoch #14: loss=0.06479571807063565
Epoch #15: loss=0.05853236059346761
Epoch #16: loss=0.057031043934703665
Epoch #17: loss=0.0484572331139419
Epoch #18: loss=0.04590113907224945
Epoch #19: loss=0.05119083579999722
Epoch #20: loss=0.03789439754227534
Epoch #21: loss=0.038852870034127934
Epoch #22: loss=0.048941248378954895
Epoch #23: loss=0.042602284844588514
Epoch #24: loss=0.04317206138756258
Epoch #25: loss=0.0405246131537147
Epoch #26: loss=0.03280050312343648
Epoch #27: loss=0.03213701795029277
Epoch #28: loss=0.03723535345297792
Epoch #29: loss=0.03655062168880281
Epoch #30: loss=0.028243033823500147
Epoch #31: loss=0.030116408201274782
Epoch #32: loss=0.02962158856349103
Epoch #33: loss=0.035136083424297956
Epoch #34: loss=0.030742494547719067
Epoch #35: loss=0.025488295066571295
Epoch #36: loss=0.025076561170461444
Epoch #37: loss=0.034520374454771706
Epoch #38: loss=0.022329869724822458
Epoch #39: loss=0.0213665141401595
Epoch #40: loss=0.028527719273476575
Epoch #41: loss=0.03158018169093262
Epoch #42: loss=0.022366444040422644
Epoch #43: loss=0.027540932133235912
Epoch #44: loss=0.022348583911417853
Epoch #45: loss=0.0199798559965941
Epoch #46: loss=0.027599235168140623
Epoch #47: loss=0.020196117390024016
Epoch #48: loss=0.025545843333626788
Epoch #49: loss=0.02256534331282611
Epoch #50: loss=0.0210850628005959
Epoch #51: loss=0.01823252023725306
Epoch #52: loss=0.01886353068390119
Epoch #53: loss=0.02318079900289485
Epoch #54: loss=0.03265852464891602
Epoch #55: loss=0.02359453894118403
Epoch #56: loss=0.0287144698459469
Epoch #57: loss=0.01986453809341617
Epoch #58: loss=0.0235359365635533
Epoch #59: loss=0.02026282904149757
Epoch #60: loss=0.022252498743372044
Epoch #61: loss=0.024971720220821253
Epoch #62: loss=0.022408053052902558
Epoch #63: loss=0.014269262037065732
Epoch #64: loss=0.018145228342847514
Epoch #65: loss=0.018910823767378303
Epoch #66: loss=0.020676285428201643
Epoch #67: loss=0.01616382969862452
Epoch #68: loss=0.014888462294576686
Epoch #69: loss=0.020735137024920056
Epoch #70: loss=0.017412038914197295
Epoch #71: loss=0.01836880475521539
Epoch #72: loss=0.018491511421587017
Epoch #73: loss=0.01941057451684326
Epoch #74: loss=0.017388519216448357
Epoch #75: loss=0.04713162422177863
Epoch #76: loss=0.014318744699676545
Epoch #77: loss=0.016797157048761762
Epoch #78: loss=0.026881273257547154
Epoch #79: loss=0.018550547167556525
Epoch #80: loss=0.015582422592544056
Epoch #81: loss=0.019979010734881356
Epoch #82: loss=0.019621237041390138
Epoch #83: loss=0.021711417290881576
Epoch #84: loss=0.01811510441041239
Epoch #85: loss=0.01864127478206111
Epoch #86: loss=0.018412908282060027
Epoch #87: loss=0.021310081668252077
Epoch #88: loss=0.012036674501395951
Epoch #89: loss=0.018883967099140274
Epoch #90: loss=0.015579150304403638
Epoch #91: loss=0.021558744537980228
Epoch #92: loss=0.017057993997585605
Epoch #93: loss=0.01832370163174346
Epoch #94: loss=0.017892424021591843
Epoch #95: loss=0.015295322262836213
Epoch #96: loss=0.02147738509600089
Epoch #97: loss=0.02509330401611982
Epoch #98: loss=0.020102752865010474
Epoch #99: loss=0.014296499502383302
Epoch #100: loss=0.015128589890082367
Epoch #101: loss=0.015031277031430082
Epoch #102: loss=0.027296948482797206
Epoch #103: loss=0.024046707336443155
Epoch #104: loss=0.012206386261992002
Epoch #105: loss=0.019250571431863744
Epoch #106: loss=0.01582293407521884
Epoch #107: loss=0.018867544497180175
Epoch #108: loss=0.019040785494613077
Epoch #109: loss=0.0128139447707762
Epoch #110: loss=0.013574745591657151
Epoch #111: loss=0.009473619162633519
Epoch #112: loss=0.018721563479694524
Epoch #113: loss=0.01313007755514125
Epoch #114: loss=0.018177522215394076
Epoch #115: loss=0.018562405579941856
Epoch #116: loss=0.014097588443506722
Epoch #117: loss=0.018753651470925288
Epoch #118: loss=0.018640097228311763
Epoch #119: loss=0.010358159847801168
Epoch #120: loss=0.020070534741398558
Epoch #121: loss=0.013621822925170531
Epoch #122: loss=0.01483647064570539
Epoch #123: loss=0.015901920134871097
Epoch #124: loss=0.017810277616726974
Epoch #125: loss=0.012742174720404738
Epoch #126: loss=0.010642518372153251
Epoch #127: loss=0.017926612181816955
Epoch #128: loss=0.027272952251231646
Epoch #129: loss=0.01361234002349853
Epoch #130: loss=0.02072424403933765
Epoch #131: loss=0.014519430001234948
Epoch #132: loss=0.009359713851884891
Epoch #133: loss=0.014409499467043056
Epoch #134: loss=0.015811917939636842
Epoch #135: loss=0.01658964610475354
Epoch #136: loss=0.016843609304045774
Epoch #137: loss=0.01340277506777771
Epoch #138: loss=0.012819718158578117
Epoch #139: loss=0.014962293068518828
Epoch #140: loss=0.013039038534120454
Epoch #141: loss=0.01736725523306746
Epoch #142: loss=0.0162353401945631
Epoch #143: loss=0.018427023472629075
Epoch #144: loss=0.009881027365481392
Epoch #145: loss=0.013965706916038293
Epoch #146: loss=0.012576386840319134
Epoch #147: loss=0.009668508987225157
Epoch #148: loss=0.014610304862747038
Epoch #149: loss=0.010863699058009295
Epoch #150: loss=0.014046778137359776
Epoch #151: loss=0.015139452321397061
Epoch #152: loss=0.013668386484524564
Epoch #153: loss=0.011653363873104557
Epoch #154: loss=0.01685001013029411
Epoch #155: loss=0.01054747024295717
Epoch #156: loss=0.015283866980488035
Epoch #157: loss=0.012910570255915658
Epoch #158: loss=0.013920208154745794
Epoch #159: loss=0.013004672453326743
Epoch #160: loss=0.014841142197484695
Epoch #161: loss=0.011320267130515285
Epoch #162: loss=0.023951657825891263
Epoch #163: loss=0.012379731676103362
Epoch #164: loss=0.01286525895757905
Epoch #165: loss=0.014376366500964771
Epoch #166: loss=0.008205121994383894
Epoch #167: loss=0.023015348379763365
Epoch #168: loss=0.013620306081728338
Epoch #169: loss=0.028966851262654542
Epoch #170: loss=0.010909733926149719
Epoch #171: loss=0.011511443723367052
Epoch #172: loss=0.015338989629141141
Epoch #173: loss=0.01053397472115582
Epoch #174: loss=0.01208548440493743
Epoch #175: loss=0.010772776616175471
Epoch #176: loss=0.016736896921746652
Epoch #177: loss=0.01682513566847935
Epoch #178: loss=0.007904660807450654
Epoch #179: loss=0.01214024980378257
Epoch #180: loss=0.019748016170554467
Epoch #181: loss=0.009987848228566163
Epoch #182: loss=0.008581354409346648
Epoch #183: loss=0.013740547266123183
Epoch #184: loss=0.015035824409419918
Epoch #185: loss=0.008741932400069497
Epoch #186: loss=0.010387785287643834
Epoch #187: loss=0.014973034260069944
Epoch #188: loss=0.018729073398038677
Epoch #189: loss=0.01376109744775367
Epoch #190: loss=0.007931633162651818
Epoch #191: loss=0.009569864482392719
Epoch #192: loss=0.012590077418915435
Epoch #193: loss=0.011609146536212768
Epoch #194: loss=0.017092783955991304
Epoch #195: loss=0.008340465443517969
Epoch #196: loss=0.013243437710224685
Epoch #197: loss=0.010646708817232788
Epoch #198: loss=0.009367793541518418
Epoch #199: loss=0.014057122924573007
Epoch #200: loss=0.010252081440512985
Epoch #201: loss=0.01859610988273762
Epoch #202: loss=0.010567437697189888
Epoch #203: loss=0.015695084746682627
Epoch #204: loss=0.015547927832556015
Epoch #205: loss=0.009073466880906298
Epoch #206: loss=0.014487556188658216
Epoch #207: loss=0.008695237402083089
Epoch #208: loss=0.010902688588460581
Epoch #209: loss=0.01582241196096497
Epoch #210: loss=0.014721315259987152
Epoch #211: loss=0.009147900842913611
Epoch #212: loss=0.01660294126171596
Epoch #213: loss=0.014140937007111358
Epoch #214: loss=0.012083496110091609
Epoch #215: loss=0.01077665346928075
Epoch #216: loss=0.011976605454957314
Epoch #217: loss=0.008587751745190851
Epoch #218: loss=0.011535292467818503
Epoch #219: loss=0.010422755192752483
Epoch #220: loss=0.011865559780646283
Epoch #221: loss=0.011721288886976945
Epoch #222: loss=0.013922394183637814
Epoch #223: loss=0.013851586987962046
Epoch #224: loss=0.014002476520754117
Epoch #225: loss=0.008233416656338791
Epoch #226: loss=0.0183257464409638
Epoch #227: loss=0.012537782452059328
Epoch #228: loss=0.007368661926942331
Epoch #229: loss=0.013057277864609767
Epoch #230: loss=0.012709975878939803
Epoch #231: loss=0.011733957903737408
Epoch #232: loss=0.017367380788421545
Epoch #233: loss=0.01495318604912943
Epoch #234: loss=0.014629449410397826
Epoch #235: loss=0.009546526654399999
Epoch #236: loss=0.010478439896265852
Epoch #237: loss=0.02420709216210397
Epoch #238: loss=0.009267786185165392
Epoch #239: loss=0.006964078765718686
Epoch #240: loss=0.01349976199806157
Epoch #241: loss=0.010862104391502682
Epoch #242: loss=0.011560977899324108
Epoch #243: loss=0.01181545069077048
Epoch #244: loss=0.012317652593016785
Epoch #245: loss=0.00808575853454715
Epoch #246: loss=0.010946814321511796
Epoch #247: loss=0.01478212031656717
Epoch #248: loss=0.010255914176796912
Epoch #249: loss=0.011776343072089277

Training time: 3:56:55.476346

Finished.
n2one setting etth1_ettm1_traffic_weather -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_traffic_weather_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_ettm1_traffic_weather', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.47008e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.80514e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.53982e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.47008e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.43231880037903725, 'MAE': 0.46988109744793416}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm1_traffic_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_traffic_weather_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_ettm1_traffic_weather', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.6911e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4438760546560569, 'MAE': 0.43043678593676565}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm1_traffic_exchange', random_seed=2023, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm1_traffic_exchange_epochs_250_seed_2023
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.0164307941691026
Epoch #1: loss=0.3916145495835457
Epoch #2: loss=0.27891138337787474
Epoch #3: loss=0.21863129058315814
Epoch #4: loss=0.17968276193415797
Epoch #5: loss=0.1388762775506522
Epoch #6: loss=0.12173101886360159
Epoch #7: loss=0.10342748807785143
Epoch #8: loss=0.09574622439476452
Epoch #9: loss=0.08742143599125599
Epoch #10: loss=0.07756464472533464
Epoch #11: loss=0.06842715227252778
Epoch #12: loss=0.06478296481450466
Epoch #13: loss=0.061055390918858116
Epoch #14: loss=0.0625965976455723
Epoch #15: loss=0.0518693603045068
Epoch #16: loss=0.05500164099047086
Epoch #17: loss=0.0471572880271344
Epoch #18: loss=0.04458997630776926
Epoch #19: loss=0.05457014293472287
Epoch #20: loss=0.04967483085672463
Epoch #21: loss=0.04227418550864378
Epoch #22: loss=0.03770231482492097
Epoch #23: loss=0.04188645372024594
Epoch #24: loss=0.03724091425868431
Epoch #25: loss=0.043604424001092115
Epoch #26: loss=0.0327952700817322
Epoch #27: loss=0.05045062012413017
Epoch #28: loss=0.04373584584207672
Epoch #29: loss=0.030563118446226074
Epoch #30: loss=0.037748409423878554
Epoch #31: loss=0.032091567492734445
Epoch #32: loss=0.03170155608926392
Epoch #33: loss=0.032353352693560836
Epoch #34: loss=0.031639988322428696
Epoch #35: loss=0.028561744936949025
Epoch #36: loss=0.027143401602508086
Epoch #37: loss=0.02780303846704375
Epoch #38: loss=0.03365763822000952
Epoch #39: loss=0.03280553879727728
Epoch #40: loss=0.024945079752633156
Epoch #41: loss=0.026154724110588053
Epoch #42: loss=0.027015750596956833
Epoch #43: loss=0.032520435776573035
Epoch #44: loss=0.021423041594381496
Epoch #45: loss=0.030506863676720543
Epoch #46: loss=0.027953752690361423
Epoch #47: loss=0.0275464494195009
Epoch #48: loss=0.027939679195303657
Epoch #49: loss=0.030375877377967275
Epoch #50: loss=0.027500659596347482
Epoch #51: loss=0.022195424777319287
Epoch #52: loss=0.022775591615386104
Epoch #53: loss=0.021813549633743032
Epoch #54: loss=0.022192841646592406
Epoch #55: loss=0.02352346739211793
Epoch #56: loss=0.02578291721783079
Epoch #57: loss=0.01989808870030584
Epoch #58: loss=0.023010601905208115
Epoch #59: loss=0.022540776225985215
Epoch #60: loss=0.018632646311252266
Epoch #61: loss=0.0226026200523536
Epoch #62: loss=0.02061068555013736
Epoch #63: loss=0.0277908485203715
Epoch #64: loss=0.020325400958074728
Epoch #65: loss=0.0180504089869107
Epoch #66: loss=0.0264724778155125
Epoch #67: loss=0.02372038223617343
Epoch #68: loss=0.019953785594086046
Epoch #69: loss=0.019036900795703054
Epoch #70: loss=0.020062737160261097
Epoch #71: loss=0.020115382924773217
Epoch #72: loss=0.019947447668134888
Epoch #73: loss=0.0237151908254705
Epoch #74: loss=0.02505746323633404
Epoch #75: loss=0.017979023405640473
Epoch #76: loss=0.01749448257262204
Epoch #77: loss=0.016175725750915124
Epoch #78: loss=0.03015896427376418
Epoch #79: loss=0.015964224359678966
Epoch #80: loss=0.021705050863389048
Epoch #81: loss=0.018077276053379325
Epoch #82: loss=0.023386510219187674
Epoch #83: loss=0.01639169304689858
Epoch #84: loss=0.019174988952465093
Epoch #85: loss=0.0183604937659651
Epoch #86: loss=0.018585211776004504
Epoch #87: loss=0.01399195818485496
Epoch #88: loss=0.018673134151204314
Epoch #89: loss=0.02024018347603143
Epoch #90: loss=0.03326032472007986
Epoch #91: loss=0.01632403538380524
Epoch #92: loss=0.017766325454431353
Epoch #93: loss=0.01653735107472974
Epoch #94: loss=0.01589905656716862
Epoch #95: loss=0.019237648259674257
Epoch #96: loss=0.016432611758146604
Epoch #97: loss=0.01674043448849818
Epoch #98: loss=0.017656237869494624
Epoch #99: loss=0.01602416459905185
Epoch #100: loss=0.017053663185285037
Epoch #101: loss=0.01610590770357154
Epoch #102: loss=0.017304614482798585
Epoch #103: loss=0.024306594136735814
Epoch #104: loss=0.011741077782275382
Epoch #105: loss=0.019719769932323886
Epoch #106: loss=0.019867644833596446
Epoch #107: loss=0.011900509600292918
Epoch #108: loss=0.012845660470604245
Epoch #109: loss=0.014581378990815129
Epoch #110: loss=0.019412622309958737
Epoch #111: loss=0.013705484900227119
Epoch #112: loss=0.015820689795234374
Epoch #113: loss=0.01848242619828172
Epoch #114: loss=0.01688852502745765
Epoch #115: loss=0.015150633879350173
Epoch #116: loss=0.01880139336055829
Epoch #117: loss=0.017613865660956712
Epoch #118: loss=0.013573240211576581
Epoch #119: loss=0.01968561215443851
Epoch #120: loss=0.0157976501138143
Epoch #121: loss=0.013977573784244555
Epoch #122: loss=0.018603027103086492
Epoch #123: loss=0.020478150916886505
Epoch #124: loss=0.015292278142533998
Epoch #125: loss=0.015307862677562642
Epoch #126: loss=0.015986184098830958
Epoch #127: loss=0.01997007245960491
Epoch #128: loss=0.014593264312671628
Epoch #129: loss=0.011700502106225587
Epoch #130: loss=0.022768573250990205
Epoch #131: loss=0.012399545884978285
Epoch #132: loss=0.011391565220185078
Epoch #133: loss=0.019360434510737243
Epoch #134: loss=0.012230676527988262
Epoch #135: loss=0.01924965374630185
Epoch #136: loss=0.01947944283063669
Epoch #137: loss=0.014048751250975492
Epoch #138: loss=0.022358912204721047
Epoch #139: loss=0.013358904961539854
Epoch #140: loss=0.012096228788511514
Epoch #141: loss=0.01255216148117167
Epoch #142: loss=0.013978573365707521
Epoch #143: loss=0.014047144808910571
Epoch #144: loss=0.01768227863329492
Epoch #145: loss=0.011236489536115498
Epoch #146: loss=0.024931650178185518
Epoch #147: loss=0.011172243110883533
Epoch #148: loss=0.014497396404614256
Epoch #149: loss=0.013321368426159507
Epoch #150: loss=0.020183060280884943
Epoch #151: loss=0.016005468662066
Epoch #152: loss=0.0139478609622152
Epoch #153: loss=0.013563393970528253
Epoch #154: loss=0.009430710841869612
Epoch #155: loss=0.012928792448554566
Epoch #156: loss=0.016900703723270755
Epoch #157: loss=0.01579173607738617
Epoch #158: loss=0.013809889970575527
Epoch #159: loss=0.014969164091133542
Epoch #160: loss=0.015071625552770234
Epoch #161: loss=0.01565036999202241
Epoch #162: loss=0.011608122916817313
Epoch #163: loss=0.010043941318488922
Epoch #164: loss=0.011002400854530614
Epoch #165: loss=0.013602122260963698
Epoch #166: loss=0.01705269617895619
Epoch #167: loss=0.014749140326301556
Epoch #168: loss=0.012739593460004849
Epoch #169: loss=0.01193545078874465
Epoch #170: loss=0.010826106713835002
Epoch #171: loss=0.015545655261670257
Epoch #172: loss=0.013127428734650993
Epoch #173: loss=0.012084171758098885
Epoch #174: loss=0.016702830621996016
Epoch #175: loss=0.020272862168394978
Epoch #176: loss=0.013526638377181764
Epoch #177: loss=0.013472800920209903
Epoch #178: loss=0.0158833619070146
Epoch #179: loss=0.010477750525702455
Epoch #180: loss=0.019270910309412127
Epoch #181: loss=0.014669127258703401
Epoch #182: loss=0.011005300162700273
Epoch #183: loss=0.014450593838282165
Epoch #184: loss=0.013472266400410942
Epoch #185: loss=0.019604987917888252
Epoch #186: loss=0.011368026090175598
Epoch #187: loss=0.019195064539212377
Epoch #188: loss=0.01069993210016086
Epoch #189: loss=0.010085242371231387
Epoch #190: loss=0.012523035044281854
Epoch #191: loss=0.011813552937415839
Epoch #192: loss=0.010705693084886874
Epoch #193: loss=0.015572627198740552
Epoch #194: loss=0.015339234410078518
Epoch #195: loss=0.021277343005708604
Epoch #196: loss=0.009706265571186852
Epoch #197: loss=0.017884101056486478
Epoch #198: loss=0.012831262843623866
Epoch #199: loss=0.01194439400271287
Epoch #200: loss=0.014936255033709123
Epoch #201: loss=0.010454830492603874
Epoch #202: loss=0.010404169181751681
Epoch #203: loss=0.01260938026894704
Epoch #204: loss=0.01209883383480783
Epoch #205: loss=0.011823660776195817
Epoch #206: loss=0.010147583187161316
Epoch #207: loss=0.014285863168019254
Epoch #208: loss=0.011230660897159428
Epoch #209: loss=0.01947261879585976
Epoch #210: loss=0.010700866080295381
Epoch #211: loss=0.011113477314833912
Epoch #212: loss=0.01590553987599534
Epoch #213: loss=0.009634437186422973
Epoch #214: loss=0.010693179478449066
Epoch #215: loss=0.013832029174220946
Epoch #216: loss=0.010768883472599817
Epoch #217: loss=0.01338008335943078
Epoch #218: loss=0.00976555323306768
Epoch #219: loss=0.011156484463844298
Epoch #220: loss=0.012379533129164842
Epoch #221: loss=0.01320682200601876
Epoch #222: loss=0.011111920630945541
Epoch #223: loss=0.01638280463216565
Epoch #224: loss=0.023792459169681434
Epoch #225: loss=0.02062063243892664
Epoch #226: loss=0.011197916231525072
Epoch #227: loss=0.010118236773131365
Epoch #228: loss=0.007258173471855771
Epoch #229: loss=0.016974235444977566
Epoch #230: loss=0.013708386465654573
Epoch #231: loss=0.011124759456874968
Epoch #232: loss=0.012159461917968935
Epoch #233: loss=0.01245997528599833
Epoch #234: loss=0.012011682445845837
Epoch #235: loss=0.010157428914992436
Epoch #236: loss=0.010148621697566227
Epoch #237: loss=0.008886416742522366
Epoch #238: loss=0.013065138650474822
Epoch #239: loss=0.014884621870215916
Epoch #240: loss=0.010163471672992298
Epoch #241: loss=0.013137388380192197
Epoch #242: loss=0.009574978619803168
Epoch #243: loss=0.017076137248738167
Epoch #244: loss=0.012678433214950765
Epoch #245: loss=0.010716016273429043
Epoch #246: loss=0.00918055651631188
Epoch #247: loss=0.011143636778699048
Epoch #248: loss=0.01405234420845109
Epoch #249: loss=0.011591115483849888

Training time: 3:39:41.980132

Finished.
n2one setting etth1_ettm1_traffic_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_traffic_exchange_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_ettm1_traffic_exchange', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.57276e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.77687e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.43166e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.57276e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4164347317304213, 'MAE': 0.4620049247908981}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm1_traffic_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_traffic_exchange_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_ettm1_traffic_exchange', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.47021e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.52767e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.80418e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.47021e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4728768648550554, 'MAE': 0.5052169962270917}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm1_weather_exchange', random_seed=2023, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm1_weather_exchange_epochs_250_seed_2023
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=4.150358275725291
Epoch #1: loss=2.7170752241061282
Epoch #2: loss=2.1981337872835307
Epoch #3: loss=2.0826579951322994
Epoch #4: loss=1.9193002375272603
Epoch #5: loss=1.7320030652559721
Epoch #6: loss=1.643192788729301
Epoch #7: loss=1.508658562715237
Epoch #8: loss=1.3983841561354124
Epoch #9: loss=1.3301058480372796
Epoch #10: loss=1.260700231561294
Epoch #11: loss=1.2294743255927012
Epoch #12: loss=1.1163224222568364
Epoch #13: loss=1.0591030991994417
Epoch #14: loss=0.9858906750495617
Epoch #15: loss=1.0230060506325502
Epoch #16: loss=1.0189947038888931
Epoch #17: loss=0.9615626369531338
Epoch #18: loss=0.9472883148835256
Epoch #19: loss=0.9731650581726661
Epoch #20: loss=1.0103693306446075
Epoch #21: loss=0.8758732401407682
Epoch #22: loss=0.8920564364928466
Epoch #23: loss=0.7820962839401685
Epoch #24: loss=0.8301121558134372
Epoch #25: loss=0.7376817350204175
Epoch #26: loss=0.7517712379877384
Epoch #27: loss=0.7183272225352434
Epoch #28: loss=0.6965748363962541
Epoch #29: loss=0.7099121894973975
Epoch #30: loss=0.6653268480530152
Epoch #31: loss=0.6585818448892007
Epoch #32: loss=0.6883937819645956
Epoch #33: loss=0.6336733521177218
Epoch #34: loss=0.6004203603817866
Epoch #35: loss=0.5352395211274807
Epoch #36: loss=0.5079273633085765
Epoch #37: loss=0.5892481116148142
Epoch #38: loss=0.5148447992709967
Epoch #39: loss=0.5277716104800885
Epoch #40: loss=0.5167629346251488
Epoch #41: loss=0.4818851729998222
Epoch #42: loss=0.5309638862426465
Epoch #43: loss=0.48119527330765355
Epoch #44: loss=0.5154944956302643
Epoch #45: loss=0.49080260671102083
Epoch #46: loss=0.493293529519668
Epoch #47: loss=0.5094978279219224
Epoch #48: loss=0.5012060673190997
Epoch #49: loss=0.4221106137220676
Epoch #50: loss=0.41704647873456663
Epoch #51: loss=0.39243450961433923
Epoch #52: loss=0.41192134698996175
Epoch #53: loss=0.3622760239702005
Epoch #54: loss=0.3963152061288173
Epoch #55: loss=0.40288198395417285
Epoch #56: loss=0.3768805434497503
Epoch #57: loss=0.3799918442964554
Epoch #58: loss=0.41073769617539185
Epoch #59: loss=0.4274813492710774
Epoch #60: loss=0.4359778091311455
Epoch #61: loss=0.34620488062500954
Epoch #62: loss=0.39954351691099316
Epoch #63: loss=0.3493249767388289
Epoch #64: loss=0.3355144921403665
Epoch #65: loss=0.35055472114338326
Epoch #66: loss=0.31298232895250505
Epoch #67: loss=0.3180488915397571
Epoch #68: loss=0.37500854309361714
Epoch #69: loss=0.3489365061888328
Epoch #70: loss=0.3739659512558809
Epoch #71: loss=0.29442283439521605
Epoch #72: loss=0.3757475999971995
Epoch #73: loss=0.2958743759932426
Epoch #74: loss=0.25155900375774276
Epoch #75: loss=0.2875628853933169
Epoch #76: loss=0.31737036988712275
Epoch #77: loss=0.2917114974787602
Epoch #78: loss=0.2796755424485757
Epoch #79: loss=0.23322765457515532
Epoch #80: loss=0.2472994624135586
Epoch #81: loss=0.24456005471830183
Epoch #82: loss=0.21579062437208799
Epoch #83: loss=0.21605950422011888
Epoch #84: loss=0.2956497235796772
Epoch #85: loss=0.23581336639248407
Epoch #86: loss=0.19043595143235648
Epoch #87: loss=0.25643703298499954
Epoch #88: loss=0.30327272916642517
Epoch #89: loss=0.2608488451402921
Epoch #90: loss=0.27046580182818264
Epoch #91: loss=0.3175950263841794
Epoch #92: loss=0.696435587767225
Epoch #93: loss=0.2985575550164168
Epoch #94: loss=0.23448261332053405
Epoch #95: loss=0.2697667425068525
Epoch #96: loss=0.2478369568976072
Epoch #97: loss=0.21404897364286277
Epoch #98: loss=0.19628821714566305
Epoch #99: loss=0.21844861491654927
Epoch #100: loss=0.23334466845083696
Epoch #101: loss=0.20443920282503733
Epoch #102: loss=0.16835642520051736
Epoch #103: loss=0.20450505062651175
Epoch #104: loss=0.22403955946748072
Epoch #105: loss=0.2190202957449051
Epoch #106: loss=0.24097883235663176
Epoch #107: loss=0.18845350173516914
Epoch #108: loss=0.21520723581600648
Epoch #109: loss=0.2020212049381091
Epoch #110: loss=0.16304782398331624
Epoch #111: loss=0.16111483238637447
Epoch #112: loss=0.16352294163348582
Epoch #113: loss=0.15019393103340498
Epoch #114: loss=0.17473425723325747
Epoch #115: loss=0.1959391343049132
Epoch #116: loss=0.23171831753391486
Epoch #117: loss=0.19338560878084257
Epoch #118: loss=0.1616914592540035
Epoch #119: loss=0.19441532608694756
Epoch #120: loss=0.19343198663913286
Epoch #121: loss=0.16129438650722688
Epoch #122: loss=0.28285084306620634
Epoch #123: loss=0.21036250781841004
Epoch #124: loss=0.15006983935689697
Epoch #125: loss=0.20250641124752852
Epoch #126: loss=0.16886764843589985
Epoch #127: loss=0.13770986470178917
Epoch #128: loss=0.1816454274006761
Epoch #129: loss=0.14411346030493194
Epoch #130: loss=0.12361894150336201
Epoch #131: loss=0.1618517436660253
Epoch #132: loss=0.16850846275114095
Epoch #133: loss=0.14521407923446253
Epoch #134: loss=0.14797474214663872
Epoch #135: loss=0.14449626827039397
Epoch #136: loss=0.1191363068870627
Epoch #137: loss=0.1460012445011391
Epoch #138: loss=0.15927644467984253
Epoch #139: loss=0.14603688313554114
Epoch #140: loss=0.11286058774791084
Epoch #141: loss=0.11992823285982013
Epoch #142: loss=0.13599234625983697
Epoch #143: loss=0.14418896323499772
Epoch #144: loss=0.12707560548845392
Epoch #145: loss=0.15857907796565157
Epoch #146: loss=0.13679854324660623
Epoch #147: loss=0.14732136484235525
Epoch #148: loss=0.15225610724435404
Epoch #149: loss=0.12622485811320636
Epoch #150: loss=0.1337586849784622
Epoch #151: loss=0.12424290738999844
Epoch #152: loss=0.14171686091531926
Epoch #153: loss=0.10471743227054293
Epoch #154: loss=0.10679639883052844
Epoch #155: loss=0.12480610960091536
Epoch #156: loss=0.13308863080321595
Epoch #157: loss=0.11550874760947548
Epoch #158: loss=0.11992028903645965
Epoch #159: loss=0.1603360723417539
Epoch #160: loss=0.13018986210227013
Epoch #161: loss=0.15521500438738328
Epoch #162: loss=0.124692428463067
Epoch #163: loss=0.11301343100002179
Epoch #164: loss=0.16394495197500175
Epoch #165: loss=0.19195207068696618
Epoch #166: loss=0.1827909369021654
Epoch #167: loss=0.14424623914349538
Epoch #168: loss=0.12082379382963364
Epoch #169: loss=0.11938956630631135
Epoch #170: loss=0.11759482517551917
Epoch #171: loss=0.11810634564608335
Epoch #172: loss=0.09003361017228319
Epoch #173: loss=0.14451747889129016
Epoch #174: loss=0.1555388945226486
Epoch #175: loss=0.14549086257242239
Epoch #176: loss=0.16126621951564
Epoch #177: loss=0.12194169617186372
Epoch #178: loss=0.11668777974465719
Epoch #179: loss=0.1184537958425398
Epoch #180: loss=0.09038633167242202
Epoch #181: loss=0.09968565352475987
Epoch #182: loss=0.10103422834967765
Epoch #183: loss=0.10369064300679244
Epoch #184: loss=0.09726583742751525
Epoch #185: loss=0.07941172286294974
Epoch #186: loss=0.10645920557614702
Epoch #187: loss=0.10880478518083692
Epoch #188: loss=0.10327109316578852
Epoch #189: loss=0.09032224004085247
Epoch #190: loss=0.10145350140877642
Epoch #191: loss=0.10554054805722374
Epoch #192: loss=0.10831574212688093
Epoch #193: loss=0.11974776815623045
Epoch #194: loss=0.1032072606926354
Epoch #195: loss=0.1121805314010439
Epoch #196: loss=0.1217446129840727
Epoch #197: loss=0.10421790279304752
Epoch #198: loss=0.13428772409231618
Epoch #199: loss=0.11318479696861826
Epoch #200: loss=0.11608225830758993
Epoch #201: loss=0.08196345147175285
Epoch #202: loss=0.08950829312491876
Epoch #203: loss=0.10124714319737485
Epoch #204: loss=0.1138969929709744
Epoch #205: loss=0.145794156114929
Epoch #206: loss=0.14030842239466998
Epoch #207: loss=0.10469016457836215
Epoch #208: loss=0.12145722625204004
Epoch #209: loss=0.10459910456735927
Epoch #210: loss=0.09716467964104734
Epoch #211: loss=0.07982045954738098
Epoch #212: loss=0.10566077196898942
Epoch #213: loss=0.12088081108119625
Epoch #214: loss=0.0758422097692696
Epoch #215: loss=0.08622790715442254
Epoch #216: loss=0.1136425176026443
Epoch #217: loss=0.07655319021656536
Epoch #218: loss=0.09472492693636853
Epoch #219: loss=0.12717975242636526
Epoch #220: loss=0.10256215047019605
Epoch #221: loss=0.08738471540765694
Epoch #222: loss=0.09290335993640698
Epoch #223: loss=0.09459757593532021
Epoch #224: loss=0.1153577199169936
Epoch #225: loss=0.07909367717086123
Epoch #226: loss=0.0877526135971913
Epoch #227: loss=0.08114585088780867
Epoch #228: loss=0.09495613521609741
Epoch #229: loss=0.07233295324616708
Epoch #230: loss=0.10674991061051305
Epoch #231: loss=0.1194165234740537
Epoch #232: loss=0.11324033257551491
Epoch #233: loss=0.094313509708557
Epoch #234: loss=0.08259631607394952
Epoch #235: loss=0.0890872329294395
Epoch #236: loss=0.06931077169540983
Epoch #237: loss=0.11950146802701056
Epoch #238: loss=0.0893840256254547
Epoch #239: loss=0.06084542671361795
Epoch #240: loss=0.06932338264484245
Epoch #241: loss=0.15811827485091412
Epoch #242: loss=0.14216961321206048
Epoch #243: loss=0.13712157325174373
Epoch #244: loss=0.11219904562816597
Epoch #245: loss=0.07935042435733172
Epoch #246: loss=0.08512757464240377
Epoch #247: loss=0.06374466723690812
Epoch #248: loss=0.10111577986166455
Epoch #249: loss=0.08948754932946311

Training time: 0:16:32.619124

Finished.
n2one setting etth1_ettm1_weather_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm1_weather_exchange_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_ettm1_weather_exchange', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.35675e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.7382e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.35675e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.37365647192659085, 'MAE': 0.43529469917464364}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm2_electricity_traffic', random_seed=2023, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm2_electricity_traffic_epochs_250_seed_2023
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.8436967781267992
Epoch #1: loss=0.3043620633480948
Epoch #2: loss=0.21517547718144575
Epoch #3: loss=0.14883227174873653
Epoch #4: loss=0.11460649643053024
Epoch #5: loss=0.08965177700655545
Epoch #6: loss=0.07224082002039381
Epoch #7: loss=0.06834105281764137
Epoch #8: loss=0.05804793561710282
Epoch #9: loss=0.05270565175245843
Epoch #10: loss=0.05226424723172671
Epoch #11: loss=0.041828132026303845
Epoch #12: loss=0.04288920174220222
Epoch #13: loss=0.0377561595899826
Epoch #14: loss=0.037978688686008996
Epoch #15: loss=0.03616167592961841
Epoch #16: loss=0.03801293960802698
Epoch #17: loss=0.04345262729501558
Epoch #18: loss=0.03230583599611937
Epoch #19: loss=0.030767754104134196
Epoch #20: loss=0.030794788064255993
Epoch #21: loss=0.027440707118725007
Epoch #22: loss=0.037867852804413085
Epoch #23: loss=0.02567193352429857
Epoch #24: loss=0.020914276152816047
Epoch #25: loss=0.031018309378151244
Epoch #26: loss=0.023809354543219863
Epoch #27: loss=0.025941285512014235
Epoch #28: loss=0.02456562582558125
Epoch #29: loss=0.02195038035320336
Epoch #30: loss=0.024206742940897658
Epoch #31: loss=0.02177747911015614
Epoch #32: loss=0.02076394074049962
Epoch #33: loss=0.019232958415784887
Epoch #34: loss=0.022282449961473216
Epoch #35: loss=0.019722001152629728
Epoch #36: loss=0.021684616364075916
Epoch #37: loss=0.03187181785792658
Epoch #38: loss=0.023320336200546576
Epoch #39: loss=0.01977550320292968
Epoch #40: loss=0.020487801840718446
Epoch #41: loss=0.01659873361417405
Epoch #42: loss=0.01895443046388746
Epoch #43: loss=0.021667809728283915
Epoch #44: loss=0.017468299719303974
Epoch #45: loss=0.020806797789813963
Epoch #46: loss=0.02269104427166964
Epoch #47: loss=0.01637740311326539
Epoch #48: loss=0.01641202755585479
Epoch #49: loss=0.018992099994723743
Epoch #50: loss=0.018169191703363185
Epoch #51: loss=0.016047470717838026
Epoch #52: loss=0.016424144769596714
Epoch #53: loss=0.01904066451468492
Epoch #54: loss=0.023436525400199127
Epoch #55: loss=0.01490831259050857
Epoch #56: loss=0.016333012237731363
Epoch #57: loss=0.013983645824992527
Epoch #58: loss=0.020516431487142515
Epoch #59: loss=0.024183839144831527
Epoch #60: loss=0.0135469335592695
Epoch #61: loss=0.01722943892686079
Epoch #62: loss=0.01250730705849569
Epoch #63: loss=0.018098706981528948
Epoch #64: loss=0.013527584344678345
Epoch #65: loss=0.014138034878452374
Epoch #66: loss=0.013193079881518082
Epoch #67: loss=0.01481143092883163
Epoch #68: loss=0.011351357409858504
Epoch #69: loss=0.016499309176371685
Epoch #70: loss=0.01997528348560949
Epoch #71: loss=0.01728297012281735
Epoch #72: loss=0.011942551172996885
Epoch #73: loss=0.010470649639109547
Epoch #74: loss=0.02173193691973109
Epoch #75: loss=0.014829563026512848
Epoch #76: loss=0.012707413886209263
Epoch #77: loss=0.01627319577326657
Epoch #78: loss=0.015068020858297079
Epoch #79: loss=0.013007241554776278
Epoch #80: loss=0.016053140631724316
Epoch #81: loss=0.011546051941392105
Epoch #82: loss=0.017117313562664976
Epoch #83: loss=0.011866486699489134
Epoch #84: loss=0.01280215336276423
Epoch #85: loss=0.01593639075496877
Epoch #86: loss=0.011358754472164343
Epoch #87: loss=0.016365660201548483
Epoch #88: loss=0.01016539223748773
Epoch #89: loss=0.022209004193464322
Epoch #90: loss=0.011186343888759142
Epoch #91: loss=0.012240779530000601
Epoch #92: loss=0.011040053995945364
Epoch #93: loss=0.011772080438073335
Epoch #94: loss=0.014463626613062485
Epoch #95: loss=0.012743864942283497
Epoch #96: loss=0.01391247261960085
Epoch #97: loss=0.01152581408347308
Epoch #98: loss=0.013441721957092981
Epoch #99: loss=0.012376728961729856
Epoch #100: loss=0.01128598085547806
Epoch #101: loss=0.012270157622524031
Epoch #102: loss=0.010035963156331552
Epoch #103: loss=0.012807635561402943
Epoch #104: loss=0.013327824321587483
Epoch #105: loss=0.015037225460434732
Epoch #106: loss=0.011446720193355688
Epoch #107: loss=0.009285099299416013
Epoch #108: loss=0.015403447095034287
Epoch #109: loss=0.010574730384221695
Epoch #110: loss=0.014590304961876745
Epoch #111: loss=0.009660831142574018
Epoch #112: loss=0.01312358865172373
Epoch #113: loss=0.01399095425424228
Epoch #114: loss=0.010944787692700278
Epoch #115: loss=0.017530529930763844
Epoch #116: loss=0.009450568148991726
Epoch #117: loss=0.010297822234309787
Epoch #118: loss=0.013533710830639055
Epoch #119: loss=0.01190889917789407
Epoch #120: loss=0.012959014010923114
Epoch #121: loss=0.009671930945834606
Epoch #122: loss=0.011692892930214603
Epoch #123: loss=0.011088002978967636
Epoch #124: loss=0.010235039242057166
Epoch #125: loss=0.010177125808910632
Epoch #126: loss=0.016310670099598818
Epoch #127: loss=0.011821458310958582
Epoch #128: loss=0.01268782386567221
Epoch #129: loss=0.009493250153366252
Epoch #130: loss=0.009091262954133497
Epoch #131: loss=0.010273771741883353
Epoch #132: loss=0.008805866655732474
Epoch #133: loss=0.011743459297024104
Epoch #134: loss=0.01070093545473313
Epoch #135: loss=0.013060845741108598
Epoch #136: loss=0.0107110110106688
Epoch #137: loss=0.007870129156272453
Epoch #138: loss=0.009972191316929207
Epoch #139: loss=0.018421687706216407
Epoch #140: loss=0.01386300675837237
Epoch #141: loss=0.009724009246708376
Epoch #142: loss=0.00885115626141011
Epoch #143: loss=0.010892190345511426
Epoch #144: loss=0.008164113119291007
Epoch #145: loss=0.011548242228743767
Epoch #146: loss=0.02164458564822279
Epoch #147: loss=0.009582309322243151
Epoch #148: loss=0.01035766196188913
Epoch #149: loss=0.012511929238568793
Epoch #150: loss=0.013247405049004526
Epoch #151: loss=0.007792192218768225
Epoch #152: loss=0.010905141305299277
Epoch #153: loss=0.009284309687416652
Epoch #154: loss=0.01159731269253492
Epoch #155: loss=0.009834304898556594
Epoch #156: loss=0.008713117746661862
Epoch #157: loss=0.014347970382163889
Epoch #158: loss=0.010349040919067461
Epoch #159: loss=0.008774378372555224
Epoch #160: loss=0.012450115189600914
Epoch #161: loss=0.006541146251091309
Epoch #162: loss=0.010816563937286122
Epoch #163: loss=0.009510958607452123
Epoch #164: loss=0.010910457406753964
Epoch #165: loss=0.008144378058677437
Epoch #166: loss=0.008809681017571002
Epoch #167: loss=0.01071708234155996
Epoch #168: loss=0.011277292517930243
Epoch #169: loss=0.010941822463970768
Epoch #170: loss=0.006952526755290012
Epoch #171: loss=0.009144306932739332
Epoch #172: loss=0.010175649156572172
Epoch #173: loss=0.008996658876284218
Epoch #174: loss=0.010464617637828707
Epoch #175: loss=0.010796198339453436
Epoch #176: loss=0.010407055696949625
Epoch #177: loss=0.011211568731098054
Epoch #178: loss=0.00853296600117747
Epoch #179: loss=0.008045539549785704
Epoch #180: loss=0.010826375411225466
Epoch #181: loss=0.009538122301837749
Epoch #182: loss=0.009043356776932975
Epoch #183: loss=0.009348132244297485
Epoch #184: loss=0.008957452057047725
Epoch #185: loss=0.01074179853380039
Epoch #186: loss=0.009171435035861741
Epoch #187: loss=0.008729199989192164
Epoch #188: loss=0.009046715556248518
Epoch #189: loss=0.009561571715699433
Epoch #190: loss=0.010370409339165228
Epoch #191: loss=0.009045233193428339
Epoch #192: loss=0.012688644850148907
Epoch #193: loss=0.00980799552814735
Epoch #194: loss=0.019701941062176334
Epoch #195: loss=0.009307619352638586
Epoch #196: loss=0.0098390177976683
Epoch #197: loss=0.01218035898317151
Epoch #198: loss=0.008813040880210598
Epoch #199: loss=0.010540114781878728
Epoch #200: loss=0.011216383370894397
Epoch #201: loss=0.011732891562584204
Epoch #202: loss=0.011572807797817315
Epoch #203: loss=0.009552421599632745
Epoch #204: loss=0.010264699712815952
Epoch #205: loss=0.009834500034129869
Epoch #206: loss=0.010042276885205387
Epoch #207: loss=0.008963005050535927
Epoch #208: loss=0.008636729928985853
Epoch #209: loss=0.008408855283326449
Epoch #210: loss=0.006959809929446534
Epoch #211: loss=0.013182067585902868
Epoch #212: loss=0.010480350458849692
Epoch #213: loss=0.009884788701005419
Epoch #214: loss=0.007539001243611915
Epoch #215: loss=0.008396984736436956
Epoch #216: loss=0.0088339549763443
Epoch #217: loss=0.010529773411417637
Epoch #218: loss=0.00877434101548367
Epoch #219: loss=0.012366164568079818
Epoch #220: loss=0.007324515783596709
Epoch #221: loss=0.006447839719293219
Epoch #222: loss=0.006720791758744932
Epoch #223: loss=0.008392237384004474
Epoch #224: loss=0.008311041420458331
Epoch #225: loss=0.014341740466039364
Epoch #226: loss=0.008679997129241002
Epoch #227: loss=0.009868170906071625
Epoch #228: loss=0.009318250858558471
Epoch #229: loss=0.00791420297694327
Epoch #230: loss=0.009437402577000728
Epoch #231: loss=0.010155053809594134
Epoch #232: loss=0.010893226250689449
Epoch #233: loss=0.00694434278646972
Epoch #234: loss=0.007708210284832061
Epoch #235: loss=0.01024416541521919
Epoch #236: loss=0.008190429870665502
Epoch #237: loss=0.010052671989487363
Epoch #238: loss=0.0076444657393598455
Epoch #239: loss=0.00920064091678266
Epoch #240: loss=0.01047318762174201
Epoch #241: loss=0.00945812074817125
Epoch #242: loss=0.00927094215982745
Epoch #243: loss=0.006135576921914769
Epoch #244: loss=0.008911281218135536
Epoch #245: loss=0.009373024495789233
Epoch #246: loss=0.008036230445430314
Epoch #247: loss=0.006195102986263111
Epoch #248: loss=0.01274484645442585
Epoch #249: loss=0.008490092294142793

Training time: 5:04:18.325871

Finished.
n2one setting etth1_ettm2_electricity_traffic -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm2_electricity_traffic_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_ettm2_electricity_traffic', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.0425e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.11193e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.49927e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.43300836044200264, 'MAE': 0.48979479667067943}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm2_electricity_traffic -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm2_electricity_traffic_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_ettm2_electricity_traffic', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.88784e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.28519953114824353, 'MAE': 0.3603643862860234}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm2_electricity_weather', random_seed=2023, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm2_electricity_weather_epochs_250_seed_2023
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.7568981458062995
Epoch #1: loss=0.790821635723114
Epoch #2: loss=0.5838681292860475
Epoch #3: loss=0.4768907553937337
Epoch #4: loss=0.39564355856751743
Epoch #5: loss=0.3490660339185636
Epoch #6: loss=0.320783203962731
Epoch #7: loss=0.2878255157029792
Epoch #8: loss=0.25074789522037116
Epoch #9: loss=0.24849726902703717
Epoch #10: loss=0.21238927253305095
Epoch #11: loss=0.20943050201829166
Epoch #12: loss=0.1960871306592471
Epoch #13: loss=0.1736867187672282
Epoch #14: loss=0.15016575441376803
Epoch #15: loss=0.15621980219467047
Epoch #16: loss=0.14986258531882338
Epoch #17: loss=0.11443294134654411
Epoch #18: loss=0.10627912962171313
Epoch #19: loss=0.1308999382571815
Epoch #20: loss=0.10243911647480236
Epoch #21: loss=0.09465856506450944
Epoch #22: loss=0.08636137237644767
Epoch #23: loss=0.1034878287489896
Epoch #24: loss=0.09109358239714822
Epoch #25: loss=0.06591383326569036
Epoch #26: loss=0.07268406259891105
Epoch #27: loss=0.0674027305568428
Epoch #28: loss=0.0785662365656295
Epoch #29: loss=0.061183681249720595
Epoch #30: loss=0.05654828423914844
Epoch #31: loss=0.04725439069562987
Epoch #32: loss=0.07510114317912965
Epoch #33: loss=0.04628780036016482
Epoch #34: loss=0.06413052449104925
Epoch #35: loss=0.05242733716428892
Epoch #36: loss=0.1081656337173477
Epoch #37: loss=0.060322543616368345
Epoch #38: loss=0.04679524318876434
Epoch #39: loss=0.04701857339297358
Epoch #40: loss=0.040994924949545875
Epoch #41: loss=0.043397576390599754
Epoch #42: loss=0.04438376939370718
Epoch #43: loss=0.04936233571003357
Epoch #44: loss=0.05433948607413634
Epoch #45: loss=0.039839804412363324
Epoch #46: loss=0.06510475189999154
Epoch #47: loss=0.044103998086759695
Epoch #48: loss=0.029555592613856065
Epoch #49: loss=0.03318181717002841
Epoch #50: loss=0.03545763641500157
Epoch #51: loss=0.026839199488701886
Epoch #52: loss=0.03828563866435155
Epoch #53: loss=0.07859839333718872
Epoch #54: loss=0.03968123715842934
Epoch #55: loss=0.031991504683248594
Epoch #56: loss=0.028131724255835662
Epoch #57: loss=0.03846527437602922
Epoch #58: loss=0.053792172797942815
Epoch #59: loss=0.04164758753063387
Epoch #60: loss=0.031135840597243544
Epoch #61: loss=0.034727267980294886
Epoch #62: loss=0.0453394162487749
Epoch #63: loss=0.04214415955006413
Epoch #64: loss=0.02523946239172851
Epoch #65: loss=0.031735568776190895
Epoch #66: loss=0.02483841952778501
Epoch #67: loss=0.03605994765059895
Epoch #68: loss=0.026912017343789084
Epoch #69: loss=0.038440468391620436
Epoch #70: loss=0.027548801533444082
Epoch #71: loss=0.027942025152749496
Epoch #72: loss=0.02756007768928188
Epoch #73: loss=0.028388308612023773
Epoch #74: loss=0.023478084203327865
Epoch #75: loss=0.03222989918144216
Epoch #76: loss=0.037513133322131145
Epoch #77: loss=0.03730619149697204
Epoch #78: loss=0.02569566696391071
Epoch #79: loss=0.027802095340233143
Epoch #80: loss=0.03657382849559239
Epoch #81: loss=0.025278360475403296
Epoch #82: loss=0.017407083432572856
Epoch #83: loss=0.024941783946020247
Epoch #84: loss=0.01644782226673034
Epoch #85: loss=0.018510435572793478
Epoch #86: loss=0.03297525434722894
Epoch #87: loss=0.041331197506403676
Epoch #88: loss=0.02359773170518727
Epoch #89: loss=0.024638005231398682
Epoch #90: loss=0.019457745450797606
Epoch #91: loss=0.025184172529038297
Epoch #92: loss=0.019109474354876487
Epoch #93: loss=0.018466792365835902
Epoch #94: loss=0.029662075463669654
Epoch #95: loss=0.02217462663538754
Epoch #96: loss=0.024788855036644086
Epoch #97: loss=0.020775433305542507
Epoch #98: loss=0.020694319841177648
Epoch #99: loss=0.022883152713271956
Epoch #100: loss=0.02993559778782807
Epoch #101: loss=0.03297523703164587
Epoch #102: loss=0.03109633238947861
Epoch #103: loss=0.024317767309528865
Epoch #104: loss=0.020705904781799254
Epoch #105: loss=0.02492580364381716
Epoch #106: loss=0.03962137783201386
Epoch #107: loss=0.023800990448256776
Epoch #108: loss=0.014516331304234695
Epoch #109: loss=0.01964107932226273
Epoch #110: loss=0.03005023031457238
Epoch #111: loss=0.016771069909956256
Epoch #112: loss=0.04930610663946463
Epoch #113: loss=0.024026235196044132
Epoch #114: loss=0.02391048496244603
Epoch #115: loss=0.02828293250258119
Epoch #116: loss=0.02230692908362396
Epoch #117: loss=0.016347065106933706
Epoch #118: loss=0.014088318827450402
Epoch #119: loss=0.02599715182752259
Epoch #120: loss=0.019204893343673687
Epoch #121: loss=0.022092820321248003
Epoch #122: loss=0.01524029114723767
Epoch #123: loss=0.020477534063664354
Epoch #124: loss=0.025751328526689887
Epoch #125: loss=0.016850786762031382
Epoch #126: loss=0.016146917528056616
Epoch #127: loss=0.015027531868401812
Epoch #128: loss=0.02072665910244511
Epoch #129: loss=0.02830037493848765
Epoch #130: loss=0.015384715959455257
Epoch #131: loss=0.014381760336643672
Epoch #132: loss=0.02042832334226074
Epoch #133: loss=0.01716137352552622
Epoch #134: loss=0.021526239046504823
Epoch #135: loss=0.01830018612297813
Epoch #136: loss=0.014381479732181929
Epoch #137: loss=0.02888097389129131
Epoch #138: loss=0.029690852016529504
Epoch #139: loss=0.017646937447596878
Epoch #140: loss=0.019969488774292325
Epoch #141: loss=0.019192763226751033
Epoch #142: loss=0.017238106389533193
Epoch #143: loss=0.033555982926579776
Epoch #144: loss=0.01917085001900575
Epoch #145: loss=0.019059332174229858
Epoch #146: loss=0.01772119169879373
Epoch #147: loss=0.02776276042895417
Epoch #148: loss=0.020409573889369374
Epoch #149: loss=0.018992565598096443
Epoch #150: loss=0.011696174654835351
Epoch #151: loss=0.02409607738189476
Epoch #152: loss=0.023237075246806727
Epoch #153: loss=0.01265533197653633
Epoch #154: loss=0.01518282217853894
Epoch #155: loss=0.014304285040699354
Epoch #156: loss=0.029420810639985823
Epoch #157: loss=0.02163180746664357
Epoch #158: loss=0.020981758160433694
Epoch #159: loss=0.02029153378855769
Epoch #160: loss=0.018524672845155257
Epoch #161: loss=0.016781399018858393
Epoch #162: loss=0.012535944078851185
Epoch #163: loss=0.024959823800161582
Epoch #164: loss=0.015548385032899167
Epoch #165: loss=0.01518949563248236
Epoch #166: loss=0.017351875080302843
Epoch #167: loss=0.018624023009212815
Epoch #168: loss=0.012799879328398774
Epoch #169: loss=0.013525212976973096
Epoch #170: loss=0.016924607905253054
Epoch #171: loss=0.020155466218121757
Epoch #172: loss=0.025744984086207432
Epoch #173: loss=0.01534552455430034
Epoch #174: loss=0.013100327122860831
Epoch #175: loss=0.020853836606384242
Epoch #176: loss=0.021827855614039486
Epoch #177: loss=0.022126939870123687
Epoch #178: loss=0.014337632664453799
Epoch #179: loss=0.012559906643343298
Epoch #180: loss=0.013610767775888185
Epoch #181: loss=0.020580346636754804
Epoch #182: loss=0.020104536471237774
Epoch #183: loss=0.011118418384145639
Epoch #184: loss=0.014872368248115766
Epoch #185: loss=0.024580089518742968
Epoch #186: loss=0.020460543773704758
Epoch #187: loss=0.014219217531044956
Epoch #188: loss=0.013565420154131286
Epoch #189: loss=0.013627686653898595
Epoch #190: loss=0.01337305253047866
Epoch #191: loss=0.01321569039862705
Epoch #192: loss=0.01534132998562673
Epoch #193: loss=0.014211875810654681
Epoch #194: loss=0.0224160374453202
Epoch #195: loss=0.012673469524422328
Epoch #196: loss=0.01680401515367932
Epoch #197: loss=0.009631544122335259
Epoch #198: loss=0.013223780480321905
Epoch #199: loss=0.01939832707667685
Epoch #200: loss=0.013742972640815025
Epoch #201: loss=0.013022058783736948
Epoch #202: loss=0.009347067664820727
Epoch #203: loss=0.009080113944986656
Epoch #204: loss=0.010088107993424397
Epoch #205: loss=0.01402288334338913
Epoch #206: loss=0.010447086524601057
Epoch #207: loss=0.01754691621993528
Epoch #208: loss=0.024063666131704638
Epoch #209: loss=0.015825652526308822
Epoch #210: loss=0.012422231501701913
Epoch #211: loss=0.009159914260548348
Epoch #212: loss=0.01472663665166418
Epoch #213: loss=0.014492490465437024
Epoch #214: loss=0.01829498888580256
Epoch #215: loss=0.014504355393758375
Epoch #216: loss=0.018166985437401556
Epoch #217: loss=0.00867712907915718
Epoch #218: loss=0.013043736670985946
Epoch #219: loss=0.017742494066893315
Epoch #220: loss=0.013431004691974273
Epoch #221: loss=0.01596324322418284
Epoch #222: loss=0.04275311210642454
Epoch #223: loss=0.02121602258715166
Epoch #224: loss=0.012843806084408107
Epoch #225: loss=0.01314916079082488
Epoch #226: loss=0.020908005187791862
Epoch #227: loss=0.009589901499925436
Epoch #228: loss=0.016104943652347062
Epoch #229: loss=0.009603816645908845
Epoch #230: loss=0.011271392549260533
Epoch #231: loss=0.013823606318886685
Epoch #232: loss=0.01844719610900988
Epoch #233: loss=0.013487302850412
Epoch #234: loss=0.011231228392507422
Epoch #235: loss=0.009742144427393015
Epoch #236: loss=0.017975742913055398
Epoch #237: loss=0.012188297994945148
Epoch #238: loss=0.013794008400594204
Epoch #239: loss=0.016048925324049716
Epoch #240: loss=0.012606974183868821
Epoch #241: loss=0.009989423670547644
Epoch #242: loss=0.013704664569048288
Epoch #243: loss=0.015307955077549519
Epoch #244: loss=0.0251627966235328
Epoch #245: loss=0.016558799395666214
Epoch #246: loss=0.012423698590950378
Epoch #247: loss=0.01540174283930866
Epoch #248: loss=0.012067708843834188
Epoch #249: loss=0.011621346551213694

Training time: 1:46:01.713074

Finished.
n2one setting etth1_ettm2_electricity_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm2_electricity_weather_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_ettm2_electricity_weather', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.56783e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.56783e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.2762530262605565, 'MAE': 0.3606261528532632}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm2_electricity_exchange', random_seed=2023, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm2_electricity_exchange_epochs_250_seed_2023
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.7043160918123097
Epoch #1: loss=0.722346832068578
Epoch #2: loss=0.5295496695924561
Epoch #3: loss=0.43705572071954907
Epoch #4: loss=0.36133443248546776
Epoch #5: loss=0.3099379345388165
Epoch #6: loss=0.2841761364072819
Epoch #7: loss=0.24829774912478944
Epoch #8: loss=0.2129051717755087
Epoch #9: loss=0.2111404188599985
Epoch #10: loss=0.18118819287342022
Epoch #11: loss=0.17966451564594374
Epoch #12: loss=0.1750299075044026
Epoch #13: loss=0.142819860193245
Epoch #14: loss=0.11808909577255805
Epoch #15: loss=0.13092230471865587
Epoch #16: loss=0.11984152417168321
Epoch #17: loss=0.10756951654786163
Epoch #18: loss=0.11082843622402087
Epoch #19: loss=0.10403597936495838
Epoch #20: loss=0.10937070680959338
Epoch #21: loss=0.08389397982980315
Epoch #22: loss=0.08459768577019874
Epoch #23: loss=0.08110337343431945
Epoch #24: loss=0.08526736922878826
Epoch #25: loss=0.08395060525015426
Epoch #26: loss=0.07628608326983212
Epoch #27: loss=0.08147808827153845
Epoch #28: loss=0.07035731775176199
Epoch #29: loss=0.0679504533139962
Epoch #30: loss=0.06659135688633071
Epoch #31: loss=0.05101648684301191
Epoch #32: loss=0.06071171120362039
Epoch #33: loss=0.04871892358809817
Epoch #34: loss=0.047672242091925714
Epoch #35: loss=0.06068555140258578
Epoch #36: loss=0.05779017355247409
Epoch #37: loss=0.0491038406018157
Epoch #38: loss=0.05091152548312239
Epoch #39: loss=0.06471329749567215
Epoch #40: loss=0.05247178640262216
Epoch #41: loss=0.06097596550295908
Epoch #42: loss=0.05022404041417716
Epoch #43: loss=0.04737715473833362
Epoch #44: loss=0.036747434987050485
Epoch #45: loss=0.03491063025325097
Epoch #46: loss=0.05068098603189528
Epoch #47: loss=0.0416333148301571
Epoch #48: loss=0.051533639928197185
Epoch #49: loss=0.036174179237974696
Epoch #50: loss=0.041647853060714064
Epoch #51: loss=0.037352200944422174
Epoch #52: loss=0.04234031087655832
Epoch #53: loss=0.050601960673139185
Epoch #54: loss=0.03680647375942436
Epoch #55: loss=0.0374356705355874
Epoch #56: loss=0.03644292326597094
Epoch #57: loss=0.03717262315851038
Epoch #58: loss=0.028728393101742657
Epoch #59: loss=0.03302481073264827
Epoch #60: loss=0.04061875003658407
Epoch #61: loss=0.04406967754703906
Epoch #62: loss=0.026468576320583907
Epoch #63: loss=0.03782356758226214
Epoch #64: loss=0.027160700656183773
Epoch #65: loss=0.03964202822540331
Epoch #66: loss=0.031057263080698977
Epoch #67: loss=0.02753724736129323
Epoch #68: loss=0.025490489847399832
Epoch #69: loss=0.028085913170452476
Epoch #70: loss=0.03252496789155866
Epoch #71: loss=0.035334798774443114
Epoch #72: loss=0.03213887712052656
Epoch #73: loss=0.023863857778417274
Epoch #74: loss=0.02907750392010602
Epoch #75: loss=0.03065197921749902
Epoch #76: loss=0.027480453397388912
Epoch #77: loss=0.033000995063824146
Epoch #78: loss=0.03578622670715369
Epoch #79: loss=0.027610403384277945
Epoch #80: loss=0.03013395221356399
Epoch #81: loss=0.03695783250051301
Epoch #82: loss=0.029875526074199302
Epoch #83: loss=0.044477588817160525
Epoch #84: loss=0.022458562422282082
Epoch #85: loss=0.019399751676246524
Epoch #86: loss=0.02206750323805389
Epoch #87: loss=0.025614636629130102
Epoch #88: loss=0.04151705031112771
Epoch #89: loss=0.03958888386472823
Epoch #90: loss=0.040605472235052016
Epoch #91: loss=0.025360208235195265
Epoch #92: loss=0.027139738709357184
Epoch #93: loss=0.021526239065571502
Epoch #94: loss=0.024604337802056158
Epoch #95: loss=0.019271106111967362
Epoch #96: loss=0.02651254990861432
Epoch #97: loss=0.020976093455126524
Epoch #98: loss=0.02508055981482119
Epoch #99: loss=0.034110766725134245
Epoch #100: loss=0.037594231098195166
Epoch #101: loss=0.036797241253948766
Epoch #102: loss=0.031116292544711724
Epoch #103: loss=0.029604942369092287
Epoch #104: loss=0.027386348546192086
Epoch #105: loss=0.020101710134259657
Epoch #106: loss=0.033141815985763656
Epoch #107: loss=0.03191267664682507
Epoch #108: loss=0.026147158114274465
Epoch #109: loss=0.029391988466751444
Epoch #110: loss=0.020990775972410166
Epoch #111: loss=0.017923884104664896
Epoch #112: loss=0.04239294364708221
Epoch #113: loss=0.023753709038008296
Epoch #114: loss=0.03321820907415527
Epoch #115: loss=0.02117515033126409
Epoch #116: loss=0.022352368473404112
Epoch #117: loss=0.01887189955245945
Epoch #118: loss=0.017124392993691825
Epoch #119: loss=0.02086925504612401
Epoch #120: loss=0.021509308931592218
Epoch #121: loss=0.026693269840551686
Epoch #122: loss=0.02094943647847245
Epoch #123: loss=0.019272598549683367
Epoch #124: loss=0.016770768616588716
Epoch #125: loss=0.03683768062193419
Epoch #126: loss=0.026425275679876334
Epoch #127: loss=0.022407260769709773
Epoch #128: loss=0.03616168575665997
Epoch #129: loss=0.03753905214794699
Epoch #130: loss=0.021197022521608006
Epoch #131: loss=0.016738991069229003
Epoch #132: loss=0.027261176838516726
Epoch #133: loss=0.01402366078329227
Epoch #134: loss=0.013228438490322693
Epoch #135: loss=0.018812458157695035
Epoch #136: loss=0.018172141182154513
Epoch #137: loss=0.020381531263808976
Epoch #138: loss=0.04707083237654012
Epoch #139: loss=0.025506413007465055
Epoch #140: loss=0.01757583178003434
Epoch #141: loss=0.02220257586545931
Epoch #142: loss=0.021958927050573746
Epoch #143: loss=0.021416125485273642
Epoch #144: loss=0.011441752834410623
Epoch #145: loss=0.019497102433117777
Epoch #146: loss=0.02776929066078308
Epoch #147: loss=0.029086112957622222
Epoch #148: loss=0.02446533261156864
Epoch #149: loss=0.020728033298934523
Epoch #150: loss=0.01791339403542392
Epoch #151: loss=0.025124305661939492
Epoch #152: loss=0.023348916221345623
Epoch #153: loss=0.01647110976565962
Epoch #154: loss=0.01865440761648328
Epoch #155: loss=0.01888520575547188
Epoch #156: loss=0.016207631463765353
Epoch #157: loss=0.038108398629753695
Epoch #158: loss=0.021486548748657762
Epoch #159: loss=0.022036857904848894
Epoch #160: loss=0.022573853139725302
Epoch #161: loss=0.02384046626814724
Epoch #162: loss=0.01883733578637559
Epoch #163: loss=0.022103424132190998
Epoch #164: loss=0.018991950956563752
Epoch #165: loss=0.01730188636511151
Epoch #166: loss=0.0162068655994863
Epoch #167: loss=0.016283427898890153
Epoch #168: loss=0.01838688791592965
Epoch #169: loss=0.029442519648168342
Epoch #170: loss=0.024786252017308736
Epoch #171: loss=0.017453861060758292
Epoch #172: loss=0.015994267412548568
Epoch #173: loss=0.014243874916694764
Epoch #174: loss=0.01996282257239659
Epoch #175: loss=0.02603163115122632
Epoch #176: loss=0.027014116182257703
Epoch #177: loss=0.0211920813579845
Epoch #178: loss=0.016905618039421436
Epoch #179: loss=0.012031291387217006
Epoch #180: loss=0.012716326810991907
Epoch #181: loss=0.013140511930509543
Epoch #182: loss=0.01981441332252095
Epoch #183: loss=0.02316791310913791
Epoch #184: loss=0.02148563119798217
Epoch #185: loss=0.020192988165043647
Epoch #186: loss=0.016019946437930255
Epoch #187: loss=0.019848231040511647
Epoch #188: loss=0.01681074586036677
Epoch #189: loss=0.016958199258087208
Epoch #190: loss=0.02149634731373876
Epoch #191: loss=0.013595272980493518
Epoch #192: loss=0.011670242542614328
Epoch #193: loss=0.018175943863060814
Epoch #194: loss=0.018621231359832246
Epoch #195: loss=0.015736684221599885
Epoch #196: loss=0.022628333507963224
Epoch #197: loss=0.017496053174893594
Epoch #198: loss=0.024562039295471776
Epoch #199: loss=0.019073617068905736
Epoch #200: loss=0.01664938243659232
Epoch #201: loss=0.013155989100121938
Epoch #202: loss=0.01571317249271611
Epoch #203: loss=0.014575142849851347
Epoch #204: loss=0.015061233192891947
Epoch #205: loss=0.026243613379831648
Epoch #206: loss=0.01696157240025667
Epoch #207: loss=0.01339887119723975
Epoch #208: loss=0.015719697884852953
Epoch #209: loss=0.01920633099457217
Epoch #210: loss=0.018833161441418705
Epoch #211: loss=0.010298496078258992
Epoch #212: loss=0.016736751309057874
Epoch #213: loss=0.019219801411796255
Epoch #214: loss=0.0167437752404167
Epoch #215: loss=0.011024360093157283
Epoch #216: loss=0.014543585726013004
Epoch #217: loss=0.011739925967421388
Epoch #218: loss=0.02097130945051003
Epoch #219: loss=0.015631600785148345
Epoch #220: loss=0.021292102279413964
Epoch #221: loss=0.024666703121786298
Epoch #222: loss=0.025998059930937414
Epoch #223: loss=0.013943584287614275
Epoch #224: loss=0.013872856698139847
Epoch #225: loss=0.013544548986451459
Epoch #226: loss=0.01583777691087664
Epoch #227: loss=0.015338461878991308
Epoch #228: loss=0.019120464863668946
Epoch #229: loss=0.017731533206409508
Epoch #230: loss=0.015654129862365303
Epoch #231: loss=0.01966451835145594
Epoch #232: loss=0.019628372515071324
Epoch #233: loss=0.020296142808791058
Epoch #234: loss=0.012609087704435615
Epoch #235: loss=0.01877301788395029
Epoch #236: loss=0.020454468015683357
Epoch #237: loss=0.01664866232554769
Epoch #238: loss=0.04939460802973605
Epoch #239: loss=0.032254172341263335
Epoch #240: loss=0.017247046861812332
Epoch #241: loss=0.015153827645157675
Epoch #242: loss=0.016612800855225793
Epoch #243: loss=0.018880979453048452
Epoch #244: loss=0.016523780042465953
Epoch #245: loss=0.025267629547350602
Epoch #246: loss=0.015146741614024817
Epoch #247: loss=0.013396910542299467
Epoch #248: loss=0.012701901002744782
Epoch #249: loss=0.011778922277329603

Training time: 1:39:14.922816

Finished.
n2one setting etth1_ettm2_electricity_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm2_electricity_exchange_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_ettm2_electricity_exchange', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.14162e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.30185e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.47284e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.14162e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.9500422927298239, 'MAE': 0.7595123097512395}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm2_traffic_weather', random_seed=2023, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm2_traffic_weather_epochs_250_seed_2023
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.0698284830149698
Epoch #1: loss=0.40779269300812393
Epoch #2: loss=0.3088817077033041
Epoch #3: loss=0.23416383362994025
Epoch #4: loss=0.18559115508748075
Epoch #5: loss=0.15132339477999585
Epoch #6: loss=0.14884099909094128
Epoch #7: loss=0.11873779651270994
Epoch #8: loss=0.10907401368803207
Epoch #9: loss=0.09064345150182711
Epoch #10: loss=0.08996283179498535
Epoch #11: loss=0.07989174411087308
Epoch #12: loss=0.0724038903778275
Epoch #13: loss=0.07250590222963763
Epoch #14: loss=0.06457898880315999
Epoch #15: loss=0.060261349105348125
Epoch #16: loss=0.05559012538698969
Epoch #17: loss=0.05277620811451218
Epoch #18: loss=0.05064906437894654
Epoch #19: loss=0.05641285195729796
Epoch #20: loss=0.043780599911974756
Epoch #21: loss=0.0428536516189201
Epoch #22: loss=0.04626235477837053
Epoch #23: loss=0.045818320866011154
Epoch #24: loss=0.04538410741123464
Epoch #25: loss=0.039329191349872346
Epoch #26: loss=0.03511746826072308
Epoch #27: loss=0.03342369270729925
Epoch #28: loss=0.03847786669375757
Epoch #29: loss=0.037544105858305594
Epoch #30: loss=0.029926161656323738
Epoch #31: loss=0.031365260796644055
Epoch #32: loss=0.026954214591928705
Epoch #33: loss=0.03720214820305547
Epoch #34: loss=0.029581688103038885
Epoch #35: loss=0.025137089866431424
Epoch #36: loss=0.02376634170130105
Epoch #37: loss=0.031770333663725434
Epoch #38: loss=0.029544913602266132
Epoch #39: loss=0.019990754556812852
Epoch #40: loss=0.026122883159657488
Epoch #41: loss=0.03150009492434824
Epoch #42: loss=0.02618261065285768
Epoch #43: loss=0.03118356913672534
Epoch #44: loss=0.026327252346625505
Epoch #45: loss=0.019592636636303888
Epoch #46: loss=0.02537646706897825
Epoch #47: loss=0.01747431571303176
Epoch #48: loss=0.02918433509675825
Epoch #49: loss=0.02464665135343536
Epoch #50: loss=0.019104482362878962
Epoch #51: loss=0.01825480006823304
Epoch #52: loss=0.021857618654101046
Epoch #53: loss=0.02234668402502644
Epoch #54: loss=0.02521083955414656
Epoch #55: loss=0.02467240575153872
Epoch #56: loss=0.02639606004482172
Epoch #57: loss=0.01870179420198822
Epoch #58: loss=0.021397008965738637
Epoch #59: loss=0.01902954967316779
Epoch #60: loss=0.026739609624923742
Epoch #61: loss=0.02310808683580063
Epoch #62: loss=0.01900383842219578
Epoch #63: loss=0.01349088787176378
Epoch #64: loss=0.02385487396809839
Epoch #65: loss=0.014329735170514658
Epoch #66: loss=0.02369067645789778
Epoch #67: loss=0.017948442664849067
Epoch #68: loss=0.015335694243086792
Epoch #69: loss=0.021875356424370652
Epoch #70: loss=0.01716223765854882
Epoch #71: loss=0.015238572018218193
Epoch #72: loss=0.021579882166840272
Epoch #73: loss=0.020241967555017018
Epoch #74: loss=0.01630930917389063
Epoch #75: loss=0.04362761040712104
Epoch #76: loss=0.014968644233288657
Epoch #77: loss=0.02070796268822
Epoch #78: loss=0.023985090341811403
Epoch #79: loss=0.016291133415932555
Epoch #80: loss=0.013815433869469103
Epoch #81: loss=0.014255819444980979
Epoch #82: loss=0.021165070265120874
Epoch #83: loss=0.021800873446212485
Epoch #84: loss=0.017985106177521904
Epoch #85: loss=0.015377109914516442
Epoch #86: loss=0.016831649714248255
Epoch #87: loss=0.018256861073783215
Epoch #88: loss=0.0189199708834217
Epoch #89: loss=0.020179340036554576
Epoch #90: loss=0.012704772846297258
Epoch #91: loss=0.023216323576096362
Epoch #92: loss=0.015374599973483281
Epoch #93: loss=0.02525276416951159
Epoch #94: loss=0.019610720009934395
Epoch #95: loss=0.015550312101739463
Epoch #96: loss=0.01866086898631777
Epoch #97: loss=0.020911078094121863
Epoch #98: loss=0.01920448852186816
Epoch #99: loss=0.013702641686322589
Epoch #100: loss=0.018608283309474644
Epoch #101: loss=0.013176302770890241
Epoch #102: loss=0.030136737919590647
Epoch #103: loss=0.022245374035859116
Epoch #104: loss=0.011620153114495173
Epoch #105: loss=0.01584171065686103
Epoch #106: loss=0.015261430667664007
Epoch #107: loss=0.01856415354327821
Epoch #108: loss=0.01654574959859469
Epoch #109: loss=0.014484494306265569
Epoch #110: loss=0.016209106043614106
Epoch #111: loss=0.01261559014902995
Epoch #112: loss=0.016404555759584907
Epoch #113: loss=0.0113676658176026
Epoch #114: loss=0.015878879186556217
Epoch #115: loss=0.01916628029184059
Epoch #116: loss=0.0157257691975142
Epoch #117: loss=0.02007295889346259
Epoch #118: loss=0.01646684008744539
Epoch #119: loss=0.012774498188639703
Epoch #120: loss=0.017430905458349303
Epoch #121: loss=0.012224804341526308
Epoch #122: loss=0.013941873073137533
Epoch #123: loss=0.012867334127603726
Epoch #124: loss=0.0175718563874743
Epoch #125: loss=0.013066380851865832
Epoch #126: loss=0.011874763483297754
Epoch #127: loss=0.024069496955996004
Epoch #128: loss=0.025739065704895
Epoch #129: loss=0.018182487575138018
Epoch #130: loss=0.02051785403249552
Epoch #131: loss=0.012164877326229395
Epoch #132: loss=0.010771192313106005
Epoch #133: loss=0.017731368661891293
Epoch #134: loss=0.013905534382646639
Epoch #135: loss=0.011258082822850925
Epoch #136: loss=0.015300976018684508
Epoch #137: loss=0.01674077545999905
Epoch #138: loss=0.017110344538703883
Epoch #139: loss=0.01591092264404362
Epoch #140: loss=0.015391575657286133
Epoch #141: loss=0.01387833903124633
Epoch #142: loss=0.016151687716841636
Epoch #143: loss=0.025316887719422865
Epoch #144: loss=0.011020492068364668
Epoch #145: loss=0.01168304303277178
Epoch #146: loss=0.012599154690014061
Epoch #147: loss=0.009162011234257802
Epoch #148: loss=0.014821104899712605
Epoch #149: loss=0.01274937213792735
Epoch #150: loss=0.009503910319591054
Epoch #151: loss=0.01742389496458975
Epoch #152: loss=0.015168876636970714
Epoch #153: loss=0.009269963384755126
Epoch #154: loss=0.019366529497306918
Epoch #155: loss=0.010341946270429786
Epoch #156: loss=0.016237599357783232
Epoch #157: loss=0.012056083448175197
Epoch #158: loss=0.009902418210162425
Epoch #159: loss=0.014642680180580283
Epoch #160: loss=0.01432477765970773
Epoch #161: loss=0.013087165293696997
Epoch #162: loss=0.028085520451845526
Epoch #163: loss=0.01449654073816535
Epoch #164: loss=0.014604408863478826
Epoch #165: loss=0.013164051481030874
Epoch #166: loss=0.013060555385827101
Epoch #167: loss=0.019226345383442905
Epoch #168: loss=0.02415253734916385
Epoch #169: loss=0.022613480801243854
Epoch #170: loss=0.01034555680716768
Epoch #171: loss=0.011357810204776948
Epoch #172: loss=0.01525084895038323
Epoch #173: loss=0.011198788877720117
Epoch #174: loss=0.01427877565513241
Epoch #175: loss=0.00919896847375776
Epoch #176: loss=0.013560383575549555
Epoch #177: loss=0.013506908536354511
Epoch #178: loss=0.01221671304039099
Epoch #179: loss=0.012393136005629564
Epoch #180: loss=0.019330493170477882
Epoch #181: loss=0.011605524563066873
Epoch #182: loss=0.012437285720333447
Epoch #183: loss=0.01516189147056765
Epoch #184: loss=0.013125727826408312
Epoch #185: loss=0.009172545553196096
Epoch #186: loss=0.010339337974583675
Epoch #187: loss=0.015095284175758452
Epoch #188: loss=0.027496637269040152
Epoch #189: loss=0.016631029987829546
Epoch #190: loss=0.010896805018278699
Epoch #191: loss=0.008675330624341678
Epoch #192: loss=0.011715271790749876
Epoch #193: loss=0.01142373330110276
Epoch #194: loss=0.017530281113336793
Epoch #195: loss=0.012506251348345489
Epoch #196: loss=0.012694306245325396
Epoch #197: loss=0.011130153352741505
Epoch #198: loss=0.0072997461220739865
Epoch #199: loss=0.014470103359922548
Epoch #200: loss=0.013267652295267891
Epoch #201: loss=0.016548632633901626
Epoch #202: loss=0.010316217369205297
Epoch #203: loss=0.012097093624624482
Epoch #204: loss=0.01433444786661358
Epoch #205: loss=0.012252523563545255
Epoch #206: loss=0.015473078656896679
Epoch #207: loss=0.008458556724322197
Epoch #208: loss=0.008046485318708625
Epoch #209: loss=0.012661778836254859
Epoch #210: loss=0.015134190848948091
Epoch #211: loss=0.011691265921624326
Epoch #212: loss=0.01652173788112508
Epoch #213: loss=0.01346620600382429
Epoch #214: loss=0.018932882010972457
Epoch #215: loss=0.01218954351329166
Epoch #216: loss=0.009753069652144352
Epoch #217: loss=0.008336055829778475
Epoch #218: loss=0.013701285832469294
Epoch #219: loss=0.008217012739081011
Epoch #220: loss=0.01110917088817085
Epoch #221: loss=0.012830966341433695
Epoch #222: loss=0.010381801764500173
Epoch #223: loss=0.013594317751352353
Epoch #224: loss=0.01533907649308884
Epoch #225: loss=0.008017817809344522
Epoch #226: loss=0.012105772652961139
Epoch #227: loss=0.009745644583062539
Epoch #228: loss=0.008135376729648848
Epoch #229: loss=0.01169990544581066
Epoch #230: loss=0.013570561120114724
Epoch #231: loss=0.016106486416673164
Epoch #232: loss=0.01538656195445129
Epoch #233: loss=0.01517379269426998
Epoch #234: loss=0.011944849146285753
Epoch #235: loss=0.01162774693473344
Epoch #236: loss=0.012836952527569813
Epoch #237: loss=0.019468796073486585
Epoch #238: loss=0.00876811447959184
Epoch #239: loss=0.0069937920397451486
Epoch #240: loss=0.010590601702539145
Epoch #241: loss=0.014095026193879607
Epoch #242: loss=0.010545298582378895
Epoch #243: loss=0.0217289867374733
Epoch #244: loss=0.01403746690263204
Epoch #245: loss=0.00795721930923456
Epoch #246: loss=0.009349473651326245
Epoch #247: loss=0.00874264952021071
Epoch #248: loss=0.013209516760763644
Epoch #249: loss=0.009597316220073898

Training time: 3:47:28.371794

Finished.
n2one setting etth1_ettm2_traffic_weather -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm2_traffic_weather_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_ettm2_traffic_weather', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.16746e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.76287e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.33171e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.16746e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4067077084562539, 'MAE': 0.4527535937466381}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm2_traffic_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm2_traffic_weather_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_ettm2_traffic_weather', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
Evaluation result: {'MSE': 0.31320000027024747, 'MAE': 0.37402240482248084}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm2_traffic_exchange', random_seed=2023, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm2_traffic_exchange_epochs_250_seed_2023
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.0292177136886764
Epoch #1: loss=0.38954274841324166
Epoch #2: loss=0.2827823867702538
Epoch #3: loss=0.22403305311276167
Epoch #4: loss=0.17896019899798138
Epoch #5: loss=0.1350077833615344
Epoch #6: loss=0.12440967263637094
Epoch #7: loss=0.10534692435894531
Epoch #8: loss=0.10083566303469811
Epoch #9: loss=0.08528012310014199
Epoch #10: loss=0.07819864657384486
Epoch #11: loss=0.06688164690245144
Epoch #12: loss=0.06673443027004297
Epoch #13: loss=0.0629957041578359
Epoch #14: loss=0.06459578757881196
Epoch #15: loss=0.05129032337493766
Epoch #16: loss=0.05284589468155409
Epoch #17: loss=0.049261216197198525
Epoch #18: loss=0.05015847242729914
Epoch #19: loss=0.05152614669625748
Epoch #20: loss=0.045268453209795195
Epoch #21: loss=0.041763092616419854
Epoch #22: loss=0.03717380144063337
Epoch #23: loss=0.04659180734663161
Epoch #24: loss=0.03672260560710423
Epoch #25: loss=0.038074685438160644
Epoch #26: loss=0.03548659452251347
Epoch #27: loss=0.042744434660333126
Epoch #28: loss=0.03786908137100237
Epoch #29: loss=0.03276635715857238
Epoch #30: loss=0.0345020740195167
Epoch #31: loss=0.03494617573393567
Epoch #32: loss=0.03972818084488002
Epoch #33: loss=0.029101745487030317
Epoch #34: loss=0.028819634543856613
Epoch #35: loss=0.03591956874820548
Epoch #36: loss=0.02623313367908227
Epoch #37: loss=0.03163218608287033
Epoch #38: loss=0.033152730069264794
Epoch #39: loss=0.033309030647049785
Epoch #40: loss=0.02711623600286354
Epoch #41: loss=0.026393413608365425
Epoch #42: loss=0.024971970658789196
Epoch #43: loss=0.03229352058314452
Epoch #44: loss=0.023851212272396928
Epoch #45: loss=0.031095723448694067
Epoch #46: loss=0.02509250186732708
Epoch #47: loss=0.026053745259592722
Epoch #48: loss=0.02536111651512853
Epoch #49: loss=0.036004919667312923
Epoch #50: loss=0.021957545181886327
Epoch #51: loss=0.021960085702245648
Epoch #52: loss=0.024052401048040566
Epoch #53: loss=0.024481960846887803
Epoch #54: loss=0.022379572972862957
Epoch #55: loss=0.020474650039374806
Epoch #56: loss=0.023949244855028664
Epoch #57: loss=0.021828043007894645
Epoch #58: loss=0.02020796973164915
Epoch #59: loss=0.026698567420254705
Epoch #60: loss=0.018079588169466414
Epoch #61: loss=0.024521048322279606
Epoch #62: loss=0.02133064414042009
Epoch #63: loss=0.028767187001764657
Epoch #64: loss=0.017884927785138366
Epoch #65: loss=0.01926848119654932
Epoch #66: loss=0.02477454883452853
Epoch #67: loss=0.020795955630337877
Epoch #68: loss=0.017708388844963535
Epoch #69: loss=0.022363767647818947
Epoch #70: loss=0.022013543621306034
Epoch #71: loss=0.01865028229368109
Epoch #72: loss=0.020503814778249262
Epoch #73: loss=0.022491299713291082
Epoch #74: loss=0.024505723699172727
Epoch #75: loss=0.019676292547661137
Epoch #76: loss=0.019202871985619714
Epoch #77: loss=0.02236295093311341
Epoch #78: loss=0.024761594093597687
Epoch #79: loss=0.01660006986010656
Epoch #80: loss=0.017358894636214112
Epoch #81: loss=0.020616467090394098
Epoch #82: loss=0.02432738599131594
Epoch #83: loss=0.016895329577220092
Epoch #84: loss=0.024445619192897335
Epoch #85: loss=0.017838111202608007
Epoch #86: loss=0.019424877101636748
Epoch #87: loss=0.0157449018564597
Epoch #88: loss=0.014370722356886233
Epoch #89: loss=0.020364804175908642
Epoch #90: loss=0.024650790918262378
Epoch #91: loss=0.014259478288754058
Epoch #92: loss=0.020777704992445883
Epoch #93: loss=0.019282554879274348
Epoch #94: loss=0.016976409351726132
Epoch #95: loss=0.018363375470627188
Epoch #96: loss=0.016295552399111197
Epoch #97: loss=0.015082258642832056
Epoch #98: loss=0.016936711795940872
Epoch #99: loss=0.01530786758109923
Epoch #100: loss=0.01768961775018692
Epoch #101: loss=0.016004215465776774
Epoch #102: loss=0.01772848698234517
Epoch #103: loss=0.023595164705880422
Epoch #104: loss=0.012831679899734497
Epoch #105: loss=0.02751244598343997
Epoch #106: loss=0.021170235867848042
Epoch #107: loss=0.014166472286232674
Epoch #108: loss=0.010661105489808498
Epoch #109: loss=0.014442545643416108
Epoch #110: loss=0.014960738494050314
Epoch #111: loss=0.013446768269565288
Epoch #112: loss=0.01975121809762739
Epoch #113: loss=0.020165932132783324
Epoch #114: loss=0.01763250651830432
Epoch #115: loss=0.017036388110149722
Epoch #116: loss=0.024722678892037553
Epoch #117: loss=0.016978428998074606
Epoch #118: loss=0.015045706775249978
Epoch #119: loss=0.019212035597389855
Epoch #120: loss=0.01144873077397393
Epoch #121: loss=0.015673508037375664
Epoch #122: loss=0.021921751565018854
Epoch #123: loss=0.019166210534020647
Epoch #124: loss=0.01486691223079368
Epoch #125: loss=0.013514889361537932
Epoch #126: loss=0.01580985621701263
Epoch #127: loss=0.015099781554093718
Epoch #128: loss=0.01787580648627366
Epoch #129: loss=0.012534290283502406
Epoch #130: loss=0.0201848739624938
Epoch #131: loss=0.01575223215704805
Epoch #132: loss=0.011600610277234516
Epoch #133: loss=0.018752341457166203
Epoch #134: loss=0.013714651361714549
Epoch #135: loss=0.016373705531592137
Epoch #136: loss=0.016110418003442754
Epoch #137: loss=0.013352590378368355
Epoch #138: loss=0.024246360503942316
Epoch #139: loss=0.01378714025963131
Epoch #140: loss=0.011722688939879116
Epoch #141: loss=0.016807358133781498
Epoch #142: loss=0.012519830304046155
Epoch #143: loss=0.014291943745103036
Epoch #144: loss=0.01437315079691961
Epoch #145: loss=0.014431527780215146
Epoch #146: loss=0.02287600961842743
Epoch #147: loss=0.011308732356786725
Epoch #148: loss=0.012137078164160557
Epoch #149: loss=0.012882919679172987
Epoch #150: loss=0.01509552797316238
Epoch #151: loss=0.016076490649268364
Epoch #152: loss=0.01224782330039464
Epoch #153: loss=0.017963744961823912
Epoch #154: loss=0.00966415144907555
Epoch #155: loss=0.014452795770036598
Epoch #156: loss=0.015560027128198239
Epoch #157: loss=0.020989796722796536
Epoch #158: loss=0.014242396723283172
Epoch #159: loss=0.015575021012721065
Epoch #160: loss=0.012195818979586244
Epoch #161: loss=0.012697492655222976
Epoch #162: loss=0.014260319005368909
Epoch #163: loss=0.010506183070141105
Epoch #164: loss=0.013408961746454798
Epoch #165: loss=0.015954657039991296
Epoch #166: loss=0.015201636599715686
Epoch #167: loss=0.019660437234526873
Epoch #168: loss=0.01889364739461369
Epoch #169: loss=0.011051508426520217
Epoch #170: loss=0.014348002231476916
Epoch #171: loss=0.017512908723146463
Epoch #172: loss=0.012432099328220871
Epoch #173: loss=0.01080432034349714
Epoch #174: loss=0.016873065586722833
Epoch #175: loss=0.020913280114040686
Epoch #176: loss=0.01659816835626361
Epoch #177: loss=0.014665399551328543
Epoch #178: loss=0.013960751100721364
Epoch #179: loss=0.012179041645763104
Epoch #180: loss=0.018788074557501654
Epoch #181: loss=0.014552569302739701
Epoch #182: loss=0.013589964329553736
Epoch #183: loss=0.01618456923107088
Epoch #184: loss=0.011023806729484407
Epoch #185: loss=0.015744662510982593
Epoch #186: loss=0.009650803784917027
Epoch #187: loss=0.014956592030963244
Epoch #188: loss=0.01347397704598775
Epoch #189: loss=0.014172349761924255
Epoch #190: loss=0.013913484952178175
Epoch #191: loss=0.01184976118033241
Epoch #192: loss=0.01128684292703215
Epoch #193: loss=0.016080556411415693
Epoch #194: loss=0.012049593122929428
Epoch #195: loss=0.020828476807494282
Epoch #196: loss=0.010094860281189031
Epoch #197: loss=0.020040832850714355
Epoch #198: loss=0.011686813053054246
Epoch #199: loss=0.0110513304361866
Epoch #200: loss=0.013542038603715424
Epoch #201: loss=0.012043674853520404
Epoch #202: loss=0.01094124667919836
Epoch #203: loss=0.013515274115454778
Epoch #204: loss=0.011323044317471507
Epoch #205: loss=0.01370617410261197
Epoch #206: loss=0.012435839670001154
Epoch #207: loss=0.01747780662232004
Epoch #208: loss=0.013104045554608272
Epoch #209: loss=0.015241936309303435
Epoch #210: loss=0.012284785707477666
Epoch #211: loss=0.015249487862568023
Epoch #212: loss=0.013480937323447916
Epoch #213: loss=0.010658231598263065
Epoch #214: loss=0.012216106446266913
Epoch #215: loss=0.012886149457240658
Epoch #216: loss=0.010074836421391647
Epoch #217: loss=0.014266051633041553
Epoch #218: loss=0.011049126433152213
Epoch #219: loss=0.010275056567414073
Epoch #220: loss=0.014054803514014353
Epoch #221: loss=0.013244610378581103
Epoch #222: loss=0.009548507773132285
Epoch #223: loss=0.016541782083484512
Epoch #224: loss=0.021109466792450304
Epoch #225: loss=0.018888022069142345
Epoch #226: loss=0.01047165598648208
Epoch #227: loss=0.009580393279762362
Epoch #228: loss=0.009280341362543229
Epoch #229: loss=0.020699966522557702
Epoch #230: loss=0.014665636073488288
Epoch #231: loss=0.011916144654556725
Epoch #232: loss=0.01392409812520323
Epoch #233: loss=0.008739040918101694
Epoch #234: loss=0.013538935169488977
Epoch #235: loss=0.011986895231825041
Epoch #236: loss=0.010311333425691759
Epoch #237: loss=0.008572573714666982
Epoch #238: loss=0.011481985109459676
Epoch #239: loss=0.014035119136334854
Epoch #240: loss=0.010949722597181355
Epoch #241: loss=0.013481639970032612
Epoch #242: loss=0.012489520058326365
Epoch #243: loss=0.014006823418615543
Epoch #244: loss=0.01093354142822054
Epoch #245: loss=0.015353212009162037
Epoch #246: loss=0.008785037102366455
Epoch #247: loss=0.011694491703344061
Epoch #248: loss=0.014659768923003276
Epoch #249: loss=0.016508110335577454

Training time: 3:39:23.269953

Finished.
n2one setting etth1_ettm2_traffic_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm2_traffic_exchange_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_ettm2_traffic_exchange', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.70096e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.90065e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.72549e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.70096e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.42063520686825345, 'MAE': 0.46360874578354594}
Finished.
------------------------- record done -------------------------
n2one setting etth1_ettm2_traffic_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm2_traffic_exchange_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_ettm2_traffic_exchange', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=6.7374e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.59842e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.20163e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=6.7374e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.6107729832268274, 'MAE': 0.5887968206956619}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_ettm2_weather_exchange', random_seed=2023, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_ettm2_weather_exchange_epochs_250_seed_2023
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=4.149117960379674
Epoch #1: loss=2.71454911507093
Epoch #2: loss=2.199047496685615
Epoch #3: loss=2.080401438933152
Epoch #4: loss=1.9234894514083862
Epoch #5: loss=1.7421737852004857
Epoch #6: loss=1.6445367703071008
Epoch #7: loss=1.5027993894540346
Epoch #8: loss=1.3831389248371124
Epoch #9: loss=1.3321701402847583
Epoch #10: loss=1.2621477590157435
Epoch #11: loss=1.3018568398860784
Epoch #12: loss=1.1491665347264364
Epoch #13: loss=1.0827884410436337
Epoch #14: loss=0.9925813629077032
Epoch #15: loss=1.037451990521871
Epoch #16: loss=1.030266666641602
Epoch #17: loss=0.9647607940893906
Epoch #18: loss=0.9308402423675244
Epoch #19: loss=0.9485941185401037
Epoch #20: loss=1.0172372850087972
Epoch #21: loss=0.888563871383667
Epoch #22: loss=0.8629142687870905
Epoch #23: loss=0.7679511171120864
Epoch #24: loss=0.7932973469679172
Epoch #25: loss=0.7332782160777312
Epoch #26: loss=0.7585047030678163
Epoch #27: loss=0.7220642520831182
Epoch #28: loss=0.7028397631186706
Epoch #29: loss=0.7135122561684022
Epoch #30: loss=0.6683901978226808
Epoch #31: loss=0.669576189838923
Epoch #32: loss=0.7096899449825287
Epoch #33: loss=0.6739545544752708
Epoch #34: loss=0.6408387737778517
Epoch #35: loss=0.5594510751274916
Epoch #36: loss=0.5313659774569365
Epoch #37: loss=0.5934906865541751
Epoch #38: loss=0.5329656497790263
Epoch #39: loss=0.5386014792781609
Epoch #40: loss=0.5238153854241738
Epoch #41: loss=0.4865195888739366
Epoch #42: loss=0.5321487967784588
Epoch #43: loss=0.481704731973318
Epoch #44: loss=0.517675516123955
Epoch #45: loss=0.5330293740217502
Epoch #46: loss=0.5378209851109065
Epoch #47: loss=0.5389562272108518
Epoch #48: loss=0.5184134838099663
Epoch #49: loss=0.4404493183470689
Epoch #50: loss=0.42718840275819486
Epoch #51: loss=0.4153296801333244
Epoch #52: loss=0.42568427610855836
Epoch #53: loss=0.3918757622058575
Epoch #54: loss=0.4053634124306532
Epoch #55: loss=0.41659013812358564
Epoch #56: loss=0.38257685504280603
Epoch #57: loss=0.4028261690758742
Epoch #58: loss=0.4398144452044597
Epoch #59: loss=0.4093562224163459
Epoch #60: loss=0.5488497044604558
Epoch #61: loss=0.3685071224776598
Epoch #62: loss=0.4032446349469515
Epoch #63: loss=0.3648520986048075
Epoch #64: loss=0.35962185822427273
Epoch #65: loss=0.3671937412940539
Epoch #66: loss=0.3586286756281669
Epoch #67: loss=0.32859932774534595
Epoch #68: loss=0.37762753378886443
Epoch #69: loss=0.35460897176884687
Epoch #70: loss=0.364307642269593
Epoch #71: loss=0.32510918464798194
Epoch #72: loss=0.39867684259437597
Epoch #73: loss=0.30924657789560467
Epoch #74: loss=0.3549039266430415
Epoch #75: loss=0.39972864793470275
Epoch #76: loss=0.36527396423312336
Epoch #77: loss=0.34721981318524253
Epoch #78: loss=0.311675305549915
Epoch #79: loss=0.2772895283997059
Epoch #80: loss=0.2748046633429252
Epoch #81: loss=0.2581022556584615
Epoch #82: loss=0.22391938647398582
Epoch #83: loss=0.2268924115655514
Epoch #84: loss=0.2819431640494328
Epoch #85: loss=0.24396301848957172
Epoch #86: loss=0.2096496820449829
Epoch #87: loss=0.2765045426785946
Epoch #88: loss=0.3269596333400561
Epoch #89: loss=0.2501316892986114
Epoch #90: loss=0.27257311000273776
Epoch #91: loss=0.25964380901020306
Epoch #92: loss=0.27412107615516734
Epoch #93: loss=0.269537111887565
Epoch #94: loss=0.24651200274148813
Epoch #95: loss=0.26317639147432953
Epoch #96: loss=0.24723692847272524
Epoch #97: loss=0.1966295068940291
Epoch #98: loss=0.17822724437484375
Epoch #99: loss=0.2021454801209844
Epoch #100: loss=0.2333599765999959
Epoch #101: loss=0.19950131312585795
Epoch #102: loss=0.1697394996881485
Epoch #103: loss=0.21401121252431318
Epoch #104: loss=0.23833222852016872
Epoch #105: loss=0.22777557050665984
Epoch #106: loss=0.24268424396331495
Epoch #107: loss=0.19488661858038261
Epoch #108: loss=0.22587136573229843
Epoch #109: loss=0.20978282671421766
Epoch #110: loss=0.1633896712357035
Epoch #111: loss=0.15331750112370804
Epoch #112: loss=0.16840282211510035
Epoch #113: loss=0.15933867973776963
Epoch #114: loss=0.19196385209663555
Epoch #115: loss=0.2032107126970704
Epoch #116: loss=0.2441882799881009
Epoch #117: loss=0.21000299258874014
Epoch #118: loss=0.17563058794117892
Epoch #119: loss=0.21746717465038484
Epoch #120: loss=0.20490403215472514
Epoch #121: loss=0.19606561937297767
Epoch #122: loss=0.29545634949149996
Epoch #123: loss=0.21433163756647935
Epoch #124: loss=0.15796517233292645
Epoch #125: loss=0.2125775024581414
Epoch #126: loss=0.18289802760745472
Epoch #127: loss=0.14456135192169592
Epoch #128: loss=0.19200790444245705
Epoch #129: loss=0.1557559475231056
Epoch #130: loss=0.1331849809234532
Epoch #131: loss=0.17541334083160529
Epoch #132: loss=0.1744281186077457
Epoch #133: loss=0.15566633093672302
Epoch #134: loss=0.17290303583901662
Epoch #135: loss=0.18678452701379472
Epoch #136: loss=0.14103840259262002
Epoch #137: loss=0.14408116364994875
Epoch #138: loss=0.15159473614767194
Epoch #139: loss=0.1425143931992352
Epoch #140: loss=0.11089078125615533
Epoch #141: loss=0.11806993118415658
Epoch #142: loss=0.13136890408797905
Epoch #143: loss=0.1378798154182732
Epoch #144: loss=0.12058628124829668
Epoch #145: loss=0.1559033689017479
Epoch #146: loss=0.12464777978423697
Epoch #147: loss=0.12767056347085878
Epoch #148: loss=0.12709833771133652
Epoch #149: loss=0.10728900786489248
Epoch #150: loss=0.1391319126750414
Epoch #151: loss=0.14180306434774628
Epoch #152: loss=0.15649544770041338
Epoch #153: loss=0.10862354919887506
Epoch #154: loss=0.1149909686153898
Epoch #155: loss=0.15458063423060453
Epoch #156: loss=0.1493562082401835
Epoch #157: loss=0.20723154979686326
Epoch #158: loss=0.2304449102912958
Epoch #159: loss=0.23491105616379243
Epoch #160: loss=0.18044345152492708
Epoch #161: loss=0.20640764492922103
Epoch #162: loss=0.13769936522182363
Epoch #163: loss=0.1582397403410421
Epoch #164: loss=0.1761507733653371
Epoch #165: loss=0.17651678840271556
Epoch #166: loss=0.17075353191019252
Epoch #167: loss=0.13460515152949554
Epoch #168: loss=0.11853225353675392
Epoch #169: loss=0.1212349897966935
Epoch #170: loss=0.13198631364279068
Epoch #171: loss=0.13997060590638563
Epoch #172: loss=0.09964848650046267
Epoch #173: loss=0.1416022517145253
Epoch #174: loss=0.14875956137592977
Epoch #175: loss=0.14131802947332078
Epoch #176: loss=0.13720842676523787
Epoch #177: loss=0.1140414558780881
Epoch #178: loss=0.1154008808438308
Epoch #179: loss=0.11038030332957323
Epoch #180: loss=0.09605083650407883
Epoch #181: loss=0.10181955101255041
Epoch #182: loss=0.10223382962151216
Epoch #183: loss=0.10651364030603033
Epoch #184: loss=0.09730153233529283
Epoch #185: loss=0.07888371449035521
Epoch #186: loss=0.10251872993719119
Epoch #187: loss=0.10900961305014789
Epoch #188: loss=0.10839185458966173
Epoch #189: loss=0.11588928259264392
Epoch #190: loss=0.1265890351496637
Epoch #191: loss=0.11529447204576662
Epoch #192: loss=0.10007800358849075
Epoch #193: loss=0.10284542718615669
Epoch #194: loss=0.08429655995076665
Epoch #195: loss=0.10530611634469376
Epoch #196: loss=0.1079992746683554
Epoch #197: loss=0.09414709090756682
Epoch #198: loss=0.13957436834103787
Epoch #199: loss=0.122857477551756
Epoch #200: loss=0.11957048502965616
Epoch #201: loss=0.09940333657253247
Epoch #202: loss=0.10633824090473354
Epoch #203: loss=0.10374774475796865
Epoch #204: loss=0.1084720314695285
Epoch #205: loss=0.14172171878341872
Epoch #206: loss=0.11820139741310133
Epoch #207: loss=0.0856857282969241
Epoch #208: loss=0.13434334095710745
Epoch #209: loss=0.10729971753719908
Epoch #210: loss=0.09536443915791236
Epoch #211: loss=0.07753638192438163
Epoch #212: loss=0.0996984166200631
Epoch #213: loss=0.11821882333606482
Epoch #214: loss=0.07614774758426043
Epoch #215: loss=0.08542541838967456
Epoch #216: loss=0.11584943432647449
Epoch #217: loss=0.07274593830180283
Epoch #218: loss=0.07870897211922476
Epoch #219: loss=0.11820888759281772
Epoch #220: loss=0.10497487855788606
Epoch #221: loss=0.07781328368358888
Epoch #222: loss=0.07905945416468267
Epoch #223: loss=0.07658073329366744
Epoch #224: loss=0.12489504451290347
Epoch #225: loss=0.1176133079525943
Epoch #226: loss=0.15561109315603971
Epoch #227: loss=0.1529840171838609
Epoch #228: loss=0.12990519855744564
Epoch #229: loss=0.09562198622510411
Epoch #230: loss=0.13075957775044328
Epoch #231: loss=0.1474024832714349
Epoch #232: loss=0.12586502028772464
Epoch #233: loss=0.10908159540178111
Epoch #234: loss=0.1105675991767874
Epoch #235: loss=0.1309833156231504
Epoch #236: loss=0.0980130174698738
Epoch #237: loss=0.13539124167380998
Epoch #238: loss=0.09906861160953458
Epoch #239: loss=0.07248381564680201
Epoch #240: loss=0.0786313408305152
Epoch #241: loss=0.18242090927938429
Epoch #242: loss=0.14585146418987557
Epoch #243: loss=0.12688216309134775
Epoch #244: loss=0.10764926387212025
Epoch #245: loss=0.08290492098491925
Epoch #246: loss=0.09772193233052698
Epoch #247: loss=0.07996795172444902
Epoch #248: loss=0.10659102644198216
Epoch #249: loss=0.08630333593688332

Training time: 0:18:50.790409

Finished.
n2one setting etth1_ettm2_weather_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_ettm2_weather_exchange_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_ettm2_weather_exchange', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.48119e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.80088e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.48119e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.37038198451347853, 'MAE': 0.43202880230148544}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_electricity_traffic_weather', random_seed=2023, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_electricity_traffic_weather_epochs_250_seed_2023
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.8323687173083032
Epoch #1: loss=0.33404302508815337
Epoch #2: loss=0.22482868268056527
Epoch #3: loss=0.16751411069172287
Epoch #4: loss=0.12303340108758819
Epoch #5: loss=0.10682534050551783
Epoch #6: loss=0.08768102348365478
Epoch #7: loss=0.07924031744838239
Epoch #8: loss=0.06971124732617202
Epoch #9: loss=0.06224582371942233
Epoch #10: loss=0.0642015729093768
Epoch #11: loss=0.0528955542550217
Epoch #12: loss=0.047566776086712614
Epoch #13: loss=0.04739828528181533
Epoch #14: loss=0.04559781852463187
Epoch #15: loss=0.03865132105669258
Epoch #16: loss=0.0389397989998351
Epoch #17: loss=0.03125251495236482
Epoch #18: loss=0.03408439888253748
Epoch #19: loss=0.03525533445204737
Epoch #20: loss=0.03761721233039632
Epoch #21: loss=0.0260638535679678
Epoch #22: loss=0.04121537534717247
Epoch #23: loss=0.028578186332580163
Epoch #24: loss=0.02951748164578978
Epoch #25: loss=0.02617649216929414
Epoch #26: loss=0.029284569681773353
Epoch #27: loss=0.027249397136936176
Epoch #28: loss=0.028242248924231574
Epoch #29: loss=0.026373032001653262
Epoch #30: loss=0.024293468783884907
Epoch #31: loss=0.02110318095329651
Epoch #32: loss=0.021457840792448366
Epoch #33: loss=0.022351294719508013
Epoch #34: loss=0.02096710523306013
Epoch #35: loss=0.018469517098262594
Epoch #36: loss=0.021013919083328034
Epoch #37: loss=0.026676733156053064
Epoch #38: loss=0.01933762511587127
Epoch #39: loss=0.021646004392335414
Epoch #40: loss=0.022190900197194042
Epoch #41: loss=0.02481817407825522
Epoch #42: loss=0.020953429817693273
Epoch #43: loss=0.030168479532652493
Epoch #44: loss=0.017210722709669904
Epoch #45: loss=0.02092148616604486
Epoch #46: loss=0.01965258244494132
Epoch #47: loss=0.019422453430611074
Epoch #48: loss=0.01949261892873198
Epoch #49: loss=0.01922166168376287
Epoch #50: loss=0.01771202281595738
Epoch #51: loss=0.022846484472259027
Epoch #52: loss=0.021813253838660642
Epoch #53: loss=0.021011746093695126
Epoch #54: loss=0.015297509728689443
Epoch #55: loss=0.01808405320937374
Epoch #56: loss=0.0168824507739038
Epoch #57: loss=0.015869402754345317
Epoch #58: loss=0.01795654372333382
Epoch #59: loss=0.017102571923783814
Epoch #60: loss=0.01624646432513768
Epoch #61: loss=0.017185722434945955
Epoch #62: loss=0.018111556842373637
Epoch #63: loss=0.01660416349439306
Epoch #64: loss=0.015457717235377507
Epoch #65: loss=0.023095141116067152
Epoch #66: loss=0.013643899834374008
Epoch #67: loss=0.014485697974913293
Epoch #68: loss=0.017879699553879237
Epoch #69: loss=0.02364295001066957
Epoch #70: loss=0.026990115527328988
Epoch #71: loss=0.013581150377472352
Epoch #72: loss=0.01873942965965781
Epoch #73: loss=0.015885161404998814
Epoch #74: loss=0.019607282834122566
Epoch #75: loss=0.014956838388618627
Epoch #76: loss=0.017939205813634448
Epoch #77: loss=0.016560612798194166
Epoch #78: loss=0.015907771544526758
Epoch #79: loss=0.016231623812736393
Epoch #80: loss=0.015865984891206608
Epoch #81: loss=0.012222075171226416
Epoch #82: loss=0.016012709572494618
Epoch #83: loss=0.015349469200893844
Epoch #84: loss=0.014547286240958544
Epoch #85: loss=0.012585278971755542
Epoch #86: loss=0.01687853274408649
Epoch #87: loss=0.015254660096041718
Epoch #88: loss=0.014367594576039042
Epoch #89: loss=0.01241317795737766
Epoch #90: loss=0.019130802135159206
Epoch #91: loss=0.02449894663244011
Epoch #92: loss=0.017461842939299362
Epoch #93: loss=0.011902453413576472
Epoch #94: loss=0.009891504612488987
Epoch #95: loss=0.017439757623857365
Epoch #96: loss=0.01593229201065888
Epoch #97: loss=0.015890506424368237
Epoch #98: loss=0.012984002775522785
Epoch #99: loss=0.014556897200763112
Epoch #100: loss=0.01244863303822728
Epoch #101: loss=0.015246633087982494
Epoch #102: loss=0.014231386299585617
Epoch #103: loss=0.014471749898755087
Epoch #104: loss=0.011718374084418764
Epoch #105: loss=0.014604586583740647
Epoch #106: loss=0.013144223865071436
Epoch #107: loss=0.013510415732741277
Epoch #108: loss=0.016210600575169865
Epoch #109: loss=0.014215783979627878
Epoch #110: loss=0.015105266373044096
Epoch #111: loss=0.01802580866502754
Epoch #112: loss=0.010793935815196451
Epoch #113: loss=0.018791161863454794
Epoch #114: loss=0.012475558000149153
Epoch #115: loss=0.01095635300692409
Epoch #116: loss=0.017816929436728395
Epoch #117: loss=0.01198276111164145
Epoch #118: loss=0.012372983526527031
Epoch #119: loss=0.011728516497370086
Epoch #120: loss=0.01427278532578145
Epoch #121: loss=0.014278938449502962
Epoch #122: loss=0.013167286782307105
Epoch #123: loss=0.019077680947535362
Epoch #124: loss=0.010762665188442617
Epoch #125: loss=0.017002311757072387
Epoch #126: loss=0.011501608668392069
Epoch #127: loss=0.009948469734994385
Epoch #128: loss=0.015598685687241175
Epoch #129: loss=0.012381058312377334
Epoch #130: loss=0.00871520589472359
Epoch #131: loss=0.010308329410798634
Epoch #132: loss=0.011349920214043826
Epoch #133: loss=0.015941991128006282
Epoch #134: loss=0.012749358006179759
Epoch #135: loss=0.012513118629182205
Epoch #136: loss=0.018082453973647716
Epoch #137: loss=0.015420174140660348
Epoch #138: loss=0.010931293756165791
Epoch #139: loss=0.011022119857246156
Epoch #140: loss=0.009533195650994074
Epoch #141: loss=0.015737803756636776
Epoch #142: loss=0.009820842904685522
Epoch #143: loss=0.01625709636685937
Epoch #144: loss=0.011526856488408635
Epoch #145: loss=0.00858687668516579
Epoch #146: loss=0.01120888755705389
Epoch #147: loss=0.014252755373009126
Epoch #148: loss=0.01248038283404783
Epoch #149: loss=0.011396340983908789
Epoch #150: loss=0.011315904888910211
Epoch #151: loss=0.012342216984291698
Epoch #152: loss=0.011022897060911419
Epoch #153: loss=0.0143484898423555
Epoch #154: loss=0.010996525837682432
Epoch #155: loss=0.024187093885936855
Epoch #156: loss=0.009875999824304782
Epoch #157: loss=0.00846309956168206
Epoch #158: loss=0.012830834785554066
Epoch #159: loss=0.012541289071601855
Epoch #160: loss=0.011002982650708011
Epoch #161: loss=0.01731943141206964
Epoch #162: loss=0.011784666883410242
Epoch #163: loss=0.015919360999018146
Epoch #164: loss=0.011895316054853155
Epoch #165: loss=0.010234557270917466
Epoch #166: loss=0.019598354567242973
Epoch #167: loss=0.01168705606163425
Epoch #168: loss=0.008943809378826316
Epoch #169: loss=0.010548548403867722
Epoch #170: loss=0.01818820375585442
Epoch #171: loss=0.01098437324836404
Epoch #172: loss=0.011171841921826567
Epoch #173: loss=0.0114427596098195
Epoch #174: loss=0.016847315099025047
Epoch #175: loss=0.013234742191618926
Epoch #176: loss=0.009498876295837315
Epoch #177: loss=0.009881622473041094
Epoch #178: loss=0.015884201108328375
Epoch #179: loss=0.008386811822794315
Epoch #180: loss=0.012137218403363716
Epoch #181: loss=0.009042123656377998
Epoch #182: loss=0.011421466592710922
Epoch #183: loss=0.016201689630041694
Epoch #184: loss=0.010910514917309468
Epoch #185: loss=0.012722782438258213
Epoch #186: loss=0.010026858619022206
Epoch #187: loss=0.0076116876099676075
Epoch #188: loss=0.012296764294854975
Epoch #189: loss=0.011088074465198204
Epoch #190: loss=0.009324307647961848
Epoch #191: loss=0.009560436562471122
Epoch #192: loss=0.014428630174267565
Epoch #193: loss=0.01041700382694743
Epoch #194: loss=0.009483197998179094
Epoch #195: loss=0.010998558436737863
Epoch #196: loss=0.00965626670322067
Epoch #197: loss=0.009339211782126336
Epoch #198: loss=0.012784136739372199
Epoch #199: loss=0.011202982506239622
Epoch #200: loss=0.010383485710810035
Epoch #201: loss=0.009890523013513973
Epoch #202: loss=0.015164218483661037
Epoch #203: loss=0.012137074587180427
Epoch #204: loss=0.008166701334391147
Epoch #205: loss=0.010337669419844755
Epoch #206: loss=0.01276794622706228
Epoch #207: loss=0.010090537975860283
Epoch #208: loss=0.014950566001097718
Epoch #209: loss=0.01743118979627405
Epoch #210: loss=0.009749867454095357
Epoch #211: loss=0.01025339315952734
Epoch #212: loss=0.009208950504300543
Epoch #213: loss=0.018158820342633636
Epoch #214: loss=0.010021432144484558
Epoch #215: loss=0.010141047717417294
Epoch #216: loss=0.01002001885468704
Epoch #217: loss=0.011994526172166411
Epoch #218: loss=0.010575529770784143
Epoch #219: loss=0.010601704108072036
Epoch #220: loss=0.010673278339333748
Epoch #221: loss=0.010230034352532943
Epoch #222: loss=0.009712425881757195
Epoch #223: loss=0.021990178833747404
Epoch #224: loss=0.009201728849084725
Epoch #225: loss=0.014422375764453184
Epoch #226: loss=0.011390241381928047
Epoch #227: loss=0.011256396239595665
Epoch #228: loss=0.00967462408930499
Epoch #229: loss=0.014324991161964519
Epoch #230: loss=0.008179703204638443
Epoch #231: loss=0.010271019547752459
Epoch #232: loss=0.013008957769642393
Epoch #233: loss=0.009701650648857571
Epoch #234: loss=0.009026683947913745
Epoch #235: loss=0.009815429125736548
Epoch #236: loss=0.010361075004987853
Epoch #237: loss=0.008340161736513389
Epoch #238: loss=0.01569434067304379
Epoch #239: loss=0.011452956798632985
Epoch #240: loss=0.006646857923315851
Epoch #241: loss=0.013173423846596003
Epoch #242: loss=0.009148342213542923
Epoch #243: loss=0.008453285192971586
Epoch #244: loss=0.008805665835567604
Epoch #245: loss=0.01065584365639887
Epoch #246: loss=0.007982760082846221
Epoch #247: loss=0.01707545382982732
Epoch #248: loss=0.01146194265374178
Epoch #249: loss=0.008771330423709705

Training time: 5:29:01.982868

Finished.
n2one setting etth1_electricity_traffic_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_electricity_traffic_weather_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_electricity_traffic_weather', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.7379e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3199665853255568, 'MAE': 0.37006051885554275}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_electricity_traffic_exchange', random_seed=2023, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_electricity_traffic_exchange_epochs_250_seed_2023
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.8179778673115478
Epoch #1: loss=0.3048091753819749
Epoch #2: loss=0.21221353932095688
Epoch #3: loss=0.15093312774767761
Epoch #4: loss=0.117135956986047
Epoch #5: loss=0.0952392213539421
Epoch #6: loss=0.08032209452207453
Epoch #7: loss=0.07245137100496667
Epoch #8: loss=0.058876120051966116
Epoch #9: loss=0.057221623876704236
Epoch #10: loss=0.04990475110317859
Epoch #11: loss=0.05452026347964007
Epoch #12: loss=0.05234840834176693
Epoch #13: loss=0.041760352950345705
Epoch #14: loss=0.047077743062719966
Epoch #15: loss=0.052668871119764565
Epoch #16: loss=0.032091713540189165
Epoch #17: loss=0.037421837520497214
Epoch #18: loss=0.03397910625124599
Epoch #19: loss=0.03333488246455139
Epoch #20: loss=0.03366971724499126
Epoch #21: loss=0.02916895592575877
Epoch #22: loss=0.030379691406490387
Epoch #23: loss=0.030878582576624833
Epoch #24: loss=0.030970489568654634
Epoch #25: loss=0.02975586753073094
Epoch #26: loss=0.030803730347761668
Epoch #27: loss=0.028133759108909993
Epoch #28: loss=0.024348992209699633
Epoch #29: loss=0.02600444013725901
Epoch #30: loss=0.02700937984744281
Epoch #31: loss=0.027777730427233065
Epoch #32: loss=0.031980469129007476
Epoch #33: loss=0.022448138072311285
Epoch #34: loss=0.024147382957778425
Epoch #35: loss=0.025612664042195796
Epoch #36: loss=0.024046174127519915
Epoch #37: loss=0.029059014272965873
Epoch #38: loss=0.024327495179775765
Epoch #39: loss=0.023118610743917946
Epoch #40: loss=0.027431744322525136
Epoch #41: loss=0.01737524207627194
Epoch #42: loss=0.02526979254663048
Epoch #43: loss=0.029706299245685575
Epoch #44: loss=0.01966153147049483
Epoch #45: loss=0.01850666243696464
Epoch #46: loss=0.026113800622560922
Epoch #47: loss=0.03968581554727887
Epoch #48: loss=0.02249437315823496
Epoch #49: loss=0.018494723945572732
Epoch #50: loss=0.021419007162048864
Epoch #51: loss=0.018260806899826596
Epoch #52: loss=0.01863880651769868
Epoch #53: loss=0.021203944711385835
Epoch #54: loss=0.01886348711855932
Epoch #55: loss=0.01651168252285671
Epoch #56: loss=0.022007007013173784
Epoch #57: loss=0.018641840912117343
Epoch #58: loss=0.019095290096217996
Epoch #59: loss=0.020459516017508454
Epoch #60: loss=0.016111888721332037
Epoch #61: loss=0.01708758917690324
Epoch #62: loss=0.018346790412784118
Epoch #63: loss=0.01999679204463867
Epoch #64: loss=0.021743331902248603
Epoch #65: loss=0.014975745926198327
Epoch #66: loss=0.02118117342099492
Epoch #67: loss=0.018906202158964127
Epoch #68: loss=0.021535623201479254
Epoch #69: loss=0.013007871177925368
Epoch #70: loss=0.01686702150978204
Epoch #71: loss=0.016190061025675783
Epoch #72: loss=0.019593857966190655
Epoch #73: loss=0.020751121964472586
Epoch #74: loss=0.022226100059317307
Epoch #75: loss=0.013631372030531733
Epoch #76: loss=0.013675059771675614
Epoch #77: loss=0.01747993784041734
Epoch #78: loss=0.014916214549635888
Epoch #79: loss=0.012439368209301261
Epoch #80: loss=0.017572962964984493
Epoch #81: loss=0.014633739796882645
Epoch #82: loss=0.013380855044377431
Epoch #83: loss=0.016768455381716254
Epoch #84: loss=0.018681340323437417
Epoch #85: loss=0.01510205087933642
Epoch #86: loss=0.014885685939118477
Epoch #87: loss=0.013850891230970339
Epoch #88: loss=0.018735104595893646
Epoch #89: loss=0.012184113168087379
Epoch #90: loss=0.014276127738764728
Epoch #91: loss=0.0141610756589532
Epoch #92: loss=0.014759355778030458
Epoch #93: loss=0.015568253581594534
Epoch #94: loss=0.014936318531177063
Epoch #95: loss=0.014586448234090822
Epoch #96: loss=0.018727883531917813
Epoch #97: loss=0.01592321678711267
Epoch #98: loss=0.014744414492323296
Epoch #99: loss=0.014766548548078589
Epoch #100: loss=0.015180164808635786
Epoch #101: loss=0.020064444385963772
Epoch #102: loss=0.01641645593235276
Epoch #103: loss=0.013123435053247718
Epoch #104: loss=0.014785950165105912
Epoch #105: loss=0.0167068989819119
Epoch #106: loss=0.019416820000559176
Epoch #107: loss=0.012305496920000075
Epoch #108: loss=0.012096845046361585
Epoch #109: loss=0.01882461046914489
Epoch #110: loss=0.014559683388176134
Epoch #111: loss=0.013729657823092985
Epoch #112: loss=0.0153117989369113
Epoch #113: loss=0.016068152192183608
Epoch #114: loss=0.018597046483389897
Epoch #115: loss=0.014838224495008965
Epoch #116: loss=0.013588356680600384
Epoch #117: loss=0.015720556842794647
Epoch #118: loss=0.013640472999054243
Epoch #119: loss=0.012842062757369842
Epoch #120: loss=0.011894467618245268
Epoch #121: loss=0.013151763013755922
Epoch #122: loss=0.013517735718080124
Epoch #123: loss=0.017595412570688782
Epoch #124: loss=0.014878634374199251
Epoch #125: loss=0.016708439415833255
Epoch #126: loss=0.011660364160225482
Epoch #127: loss=0.01379531820937105
Epoch #128: loss=0.016455279222517764
Epoch #129: loss=0.011416251227337958
Epoch #130: loss=0.011776423067543835
Epoch #131: loss=0.013226101683575263
Epoch #132: loss=0.010578566196251474
Epoch #133: loss=0.013911015029363248
Epoch #134: loss=0.013508516499406903
Epoch #135: loss=0.018328346842960166
Epoch #136: loss=0.011873616009765229
Epoch #137: loss=0.010957124289226752
Epoch #138: loss=0.01337856247537973
Epoch #139: loss=0.009937672251680471
Epoch #140: loss=0.012268129244602428
Epoch #141: loss=0.01103302160079629
Epoch #142: loss=0.016484761550160203
Epoch #143: loss=0.017653350489570112
Epoch #144: loss=0.012747753446368588
Epoch #145: loss=0.014372695164274167
Epoch #146: loss=0.009155063254130772
Epoch #147: loss=0.01013556547708525
Epoch #148: loss=0.011271556590190888
Epoch #149: loss=0.01229220271628573
Epoch #150: loss=0.012580054912284014
Epoch #151: loss=0.012768888259906118
Epoch #152: loss=0.012693177696599436
Epoch #153: loss=0.015881496040715693
Epoch #154: loss=0.011972978096881144
Epoch #155: loss=0.012256696786988897
Epoch #156: loss=0.013576676034485088
Epoch #157: loss=0.011336886659131922
Epoch #158: loss=0.013055598675138285
Epoch #159: loss=0.010340079639350727
Epoch #160: loss=0.013823720654683335
Epoch #161: loss=0.012207223605159523
Epoch #162: loss=0.011118357822530085
Epoch #163: loss=0.01310019255838301
Epoch #164: loss=0.012339037759138197
Epoch #165: loss=0.011815615640738427
Epoch #166: loss=0.01370469893117539
Epoch #167: loss=0.012922144288041486
Epoch #168: loss=0.011545826446184133
Epoch #169: loss=0.01263535447817932
Epoch #170: loss=0.016049927454407045
Epoch #171: loss=0.010967677639285729
Epoch #172: loss=0.008291399477979477
Epoch #173: loss=0.012080861667425913
Epoch #174: loss=0.00965278295442171
Epoch #175: loss=0.012079928623085207
Epoch #176: loss=0.013057897976328128
Epoch #177: loss=0.01127106298142807
Epoch #178: loss=0.022379501067188053
Epoch #179: loss=0.011470826982463867
Epoch #180: loss=0.012953380197930266
Epoch #181: loss=0.008921274379625444
Epoch #182: loss=0.026179000389340873
Epoch #183: loss=0.008935914069856478
Epoch #184: loss=0.013919914426365473
Epoch #185: loss=0.009818449376957224
Epoch #186: loss=0.006977746638477706
Epoch #187: loss=0.011176775545648044
Epoch #188: loss=0.016317353475692555
Epoch #189: loss=0.013824213250770113
Epoch #190: loss=0.009531892299227835
Epoch #191: loss=0.008170929994683468
Epoch #192: loss=0.008633682885306257
Epoch #193: loss=0.008710321903354893
Epoch #194: loss=0.01143206525090874
Epoch #195: loss=0.010864801391130679
Epoch #196: loss=0.008692446773399717
Epoch #197: loss=0.01096490249751005
Epoch #198: loss=0.016220818555584493
Epoch #199: loss=0.02165627965368548
Epoch #200: loss=0.009740109338820795
Epoch #201: loss=0.010289360976281699
Epoch #202: loss=0.00983233779516924
Epoch #203: loss=0.010425736748176179
Epoch #204: loss=0.014600986446954001
Epoch #205: loss=0.012970041254284024
Epoch #206: loss=0.010704668808895305
Epoch #207: loss=0.008927104117980717
Epoch #208: loss=0.013754395769472115
Epoch #209: loss=0.015750657399931305
Epoch #210: loss=0.012297770873469904
Epoch #211: loss=0.011142372933061959
Epoch #212: loss=0.010298957787759742
Epoch #213: loss=0.01408351225526772
Epoch #214: loss=0.009866868232990338
Epoch #215: loss=0.012110849703153485
Epoch #216: loss=0.015350646849086925
Epoch #217: loss=0.010539493721616645
Epoch #218: loss=0.01000163878088703
Epoch #219: loss=0.009994723023878813
Epoch #220: loss=0.010469949590771773
Epoch #221: loss=0.011919437742512012
Epoch #222: loss=0.01294985010619973
Epoch #223: loss=0.012589234774670865
Epoch #224: loss=0.008084670471869318
Epoch #225: loss=0.012378217769304827
Epoch #226: loss=0.01067665502245737
Epoch #227: loss=0.008386742170119161
Epoch #228: loss=0.00989942493873428
Epoch #229: loss=0.009036414243182328
Epoch #230: loss=0.007945569975322808
Epoch #231: loss=0.013128065653904248
Epoch #232: loss=0.009004947587688513
Epoch #233: loss=0.01001762511503433
Epoch #234: loss=0.008695621538958864
Epoch #235: loss=0.01176534035962527
Epoch #236: loss=0.00833614498241482
Epoch #237: loss=0.011666598891658057
Epoch #238: loss=0.009763408653360327
Epoch #239: loss=0.008427462029118118
Epoch #240: loss=0.012107834902706475
Epoch #241: loss=0.00998307997578254
Epoch #242: loss=0.009370740695563724
Epoch #243: loss=0.007669661667108347
Epoch #244: loss=0.011025827670591251
Epoch #245: loss=0.012516848359631882
Epoch #246: loss=0.010849352894550982
Epoch #247: loss=0.011508087379502627
Epoch #248: loss=0.015466445980351889
Epoch #249: loss=0.00958729720146942

Training time: 13:24:12.933652

Finished.
n2one setting etth1_electricity_traffic_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_electricity_traffic_exchange_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_electricity_traffic_exchange', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.52105e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.59087e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.52105e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.5381144094465623, 'MAE': 0.5553166091455733}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_electricity_weather_exchange', random_seed=2023, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_electricity_weather_exchange_epochs_250_seed_2023
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.735228545263986
Epoch #1: loss=0.8193524918668178
Epoch #2: loss=0.5798217223658746
Epoch #3: loss=0.5002398377294699
Epoch #4: loss=0.4096110690776156
Epoch #5: loss=0.3639478401090559
Epoch #6: loss=0.3415627135838593
Epoch #7: loss=0.32228664454916567
Epoch #8: loss=0.2872423244362378
Epoch #9: loss=0.252225745592822
Epoch #10: loss=0.23553795357188467
Epoch #11: loss=0.2220333845081909
Epoch #12: loss=0.19964232174319457
Epoch #13: loss=0.19161638307760762
Epoch #14: loss=0.16983293137868136
Epoch #15: loss=0.1707701845845794
Epoch #16: loss=0.1439115996189539
Epoch #17: loss=0.1383815669500943
Epoch #18: loss=0.13988075228356525
Epoch #19: loss=0.13125792461143837
Epoch #20: loss=0.14315643604556666
Epoch #21: loss=0.10943321212200005
Epoch #22: loss=0.1298143262974918
Epoch #23: loss=0.10565993659846608
Epoch #24: loss=0.08915407198496698
Epoch #25: loss=0.084028338403724
Epoch #26: loss=0.07936523576236192
Epoch #27: loss=0.08339848566172614
Epoch #28: loss=0.0741687083632289
Epoch #29: loss=0.08475353812942929
Epoch #30: loss=0.08622532036253225
Epoch #31: loss=0.0656467390141208
Epoch #32: loss=0.062459250548031205
Epoch #33: loss=0.06610244679784412
Epoch #34: loss=0.07613413673002294
Epoch #35: loss=0.0625491183642195
Epoch #36: loss=0.06839354465797914
Epoch #37: loss=0.06485292666980184
Epoch #38: loss=0.07065944518515768
Epoch #39: loss=0.06444572399882342
Epoch #40: loss=0.08766108045730102
Epoch #41: loss=0.060692293712231254
Epoch #42: loss=0.04234105230949675
Epoch #43: loss=0.0522582695558307
Epoch #44: loss=0.0525632825550155
Epoch #45: loss=0.04668803967455742
Epoch #46: loss=0.043013004982941756
Epoch #47: loss=0.05868188344303632
Epoch #48: loss=0.06973411153181255
Epoch #49: loss=0.05623698693723289
Epoch #50: loss=0.05003331969324911
Epoch #51: loss=0.0438943768437252
Epoch #52: loss=0.04388139253605713
Epoch #53: loss=0.04669754908391845
Epoch #54: loss=0.059844508850098024
Epoch #55: loss=0.06432387548066594
Epoch #56: loss=0.04888464410876783
Epoch #57: loss=0.04934952566683169
Epoch #58: loss=0.0373357298895871
Epoch #59: loss=0.05101667635351193
Epoch #60: loss=0.04691628609894574
Epoch #61: loss=0.03390840077560488
Epoch #62: loss=0.03850854922359995
Epoch #63: loss=0.04181914261441925
Epoch #64: loss=0.03720126374018795
Epoch #65: loss=0.039492184422634934
Epoch #66: loss=0.03510332801662262
Epoch #67: loss=0.034598580149943985
Epoch #68: loss=0.027920169370230903
Epoch #69: loss=0.032818004508240364
Epoch #70: loss=0.04765363312705847
Epoch #71: loss=0.05871257532255477
Epoch #72: loss=0.04388431301250416
Epoch #73: loss=0.05457062526986785
Epoch #74: loss=0.031152396763543706
Epoch #75: loss=0.03135703306243812
Epoch #76: loss=0.060829425257314204
Epoch #77: loss=0.028235593918892323
Epoch #78: loss=0.030510507791254218
Epoch #79: loss=0.027692095485891507
Epoch #80: loss=0.03691590333213381
Epoch #81: loss=0.02946410181344286
Epoch #82: loss=0.030151270075253526
Epoch #83: loss=0.03304727673877895
Epoch #84: loss=0.025535094006648235
Epoch #85: loss=0.035545811321597946
Epoch #86: loss=0.0316470180221998
Epoch #87: loss=0.046386997598141064
Epoch #88: loss=0.04393354298332089
Epoch #89: loss=0.027255033723815752
Epoch #90: loss=0.029564573780218015
Epoch #91: loss=0.030041054095391144
Epoch #92: loss=0.03775128044152005
Epoch #93: loss=0.028161047267385383
Epoch #94: loss=0.03915953309917102
Epoch #95: loss=0.030006215947027993
Epoch #96: loss=0.03942403321470216
Epoch #97: loss=0.027510650434405207
Epoch #98: loss=0.035636655476590035
Epoch #99: loss=0.03195253909740453
Epoch #100: loss=0.052738197043490496
Epoch #101: loss=0.02919681609601158
Epoch #102: loss=0.02456387855885653
Epoch #103: loss=0.026118206629820312
Epoch #104: loss=0.028405355974402823
Epoch #105: loss=0.02872898433346543
Epoch #106: loss=0.026312158195731534
Epoch #107: loss=0.023459275560234853
Epoch #108: loss=0.026906923193790698
Epoch #109: loss=0.038083541733135585
Epoch #110: loss=0.026106141233953096
Epoch #111: loss=0.017923314971894345
Epoch #112: loss=0.023363612954329843
Epoch #113: loss=0.02520990473840859
Epoch #114: loss=0.03562773550115783
Epoch #115: loss=0.02910395166148478
Epoch #116: loss=0.021091201572417853
Epoch #117: loss=0.021853232345909128
Epoch #118: loss=0.023288645757618232
Epoch #119: loss=0.03035502655474078
Epoch #120: loss=0.02920288538324868
Epoch #121: loss=0.01827225512429398
Epoch #122: loss=0.0250877289960768
Epoch #123: loss=0.020556897711097546
Epoch #124: loss=0.026730355554763923
Epoch #125: loss=0.032995706182925126
Epoch #126: loss=0.02782007408420329
Epoch #127: loss=0.01990630974039919
Epoch #128: loss=0.025055214671034737
Epoch #129: loss=0.02989610429298138
Epoch #130: loss=0.03831630090968066
Epoch #131: loss=0.037262038050382786
Epoch #132: loss=0.021156182510711417
Epoch #133: loss=0.02054157791075873
Epoch #134: loss=0.02490912837530126
Epoch #135: loss=0.0319407692660503
Epoch #136: loss=0.036981634907418015
Epoch #137: loss=0.026045777732686484
Epoch #138: loss=0.0328385157943819
Epoch #139: loss=0.02621790668534794
Epoch #140: loss=0.029424268033102063
Epoch #141: loss=0.020846597373245016
Epoch #142: loss=0.04865338549677808
Epoch #143: loss=0.021720033331943975
Epoch #144: loss=0.0166876341334611
Epoch #145: loss=0.024483257760013998
Epoch #146: loss=0.01899787259142774
Epoch #147: loss=0.015838940074900165
Epoch #148: loss=0.026553675008150465
Epoch #149: loss=0.03777596247089816
Epoch #150: loss=0.04179286430441924
Epoch #151: loss=0.022867020788134296
Epoch #152: loss=0.024583206499491958
Epoch #153: loss=0.02503564505492471
Epoch #154: loss=0.04050578060576008
Epoch #155: loss=0.020679268329944565
Epoch #156: loss=0.018112452129913154
Epoch #157: loss=0.026317896933400316
Epoch #158: loss=0.017449775752669344
Epoch #159: loss=0.0251281502123926
Epoch #160: loss=0.03333697510323325
Epoch #161: loss=0.024427538025173622
Epoch #162: loss=0.030200236380963395
Epoch #163: loss=0.024705283146818524
Epoch #164: loss=0.022410943241370586
Epoch #165: loss=0.012848361332267935
Epoch #166: loss=0.014590424773648629
Epoch #167: loss=0.020143515230523094
Epoch #168: loss=0.035167667741092305
Epoch #169: loss=0.015733780890885864
Epoch #170: loss=0.014783918012437816
Epoch #171: loss=0.018632049769907934
Epoch #172: loss=0.022814226483421924
Epoch #173: loss=0.03649331585958199
Epoch #174: loss=0.026683499346627438
Epoch #175: loss=0.016640207453506087
Epoch #176: loss=0.020367282892169575
Epoch #177: loss=0.019386138331089736
Epoch #178: loss=0.02051288197225459
Epoch #179: loss=0.023723410024244638
Epoch #180: loss=0.028021573982116618
Epoch #181: loss=0.022802800153162155
Epoch #182: loss=0.01783642013916149
Epoch #183: loss=0.023264015400322354
Epoch #184: loss=0.02220444856192248
Epoch #185: loss=0.021258922167076054
Epoch #186: loss=0.043965717783237636
Epoch #187: loss=0.02600815855526206
Epoch #188: loss=0.017597065398209724
Epoch #189: loss=0.025393887136925208
Epoch #190: loss=0.02321757258379765
Epoch #191: loss=0.018424475320582074
Epoch #192: loss=0.0338250376430928
Epoch #193: loss=0.02057579962037586
Epoch #194: loss=0.017126035327458426
Epoch #195: loss=0.019607485660630954
Epoch #196: loss=0.020422819437290598
Epoch #197: loss=0.032391137168845625
Epoch #198: loss=0.035895755313348425
Epoch #199: loss=0.018547473192660046
Epoch #200: loss=0.013807221842082011
Epoch #201: loss=0.018425739404857314
Epoch #202: loss=0.013294104281208318
Epoch #203: loss=0.01871611079699887
Epoch #204: loss=0.016481782573293597
Epoch #205: loss=0.01947863247709925
Epoch #206: loss=0.019595515463553956
Epoch #207: loss=0.019940167827401774
Epoch #208: loss=0.018572787482494704
Epoch #209: loss=0.01354648450764799
Epoch #210: loss=0.015690878230129053
Epoch #211: loss=0.012533130270695232
Epoch #212: loss=0.02237131574576417
Epoch #213: loss=0.0141155926403924
Epoch #214: loss=0.027416719551434873
Epoch #215: loss=0.012913068884614473
Epoch #216: loss=0.0172619945215298
Epoch #217: loss=0.022406740145930165
Epoch #218: loss=0.03383679259073205
Epoch #219: loss=0.03179509372795155
Epoch #220: loss=0.02430288331568349
Epoch #221: loss=0.015313990966150619
Epoch #222: loss=0.03063794104584997
Epoch #223: loss=0.023633178540740873
Epoch #224: loss=0.018067377642278164
Epoch #225: loss=0.015353936011158831
Epoch #226: loss=0.01794122118462335
Epoch #227: loss=0.04098273813837074
Epoch #228: loss=0.03534035130615542
Epoch #229: loss=0.018134410441460767
Epoch #230: loss=0.01937858638964987
Epoch #231: loss=0.01840882869379451
Epoch #232: loss=0.0179655914630957
Epoch #233: loss=0.013923509477204206
Epoch #234: loss=0.013972975067594918
Epoch #235: loss=0.017147830940473657
Epoch #236: loss=0.019231965351552003
Epoch #237: loss=0.018628543814597907
Epoch #238: loss=0.01518550864067083
Epoch #239: loss=0.016028414626550497
Epoch #240: loss=0.02086362392446721
Epoch #241: loss=0.020319849968638955
Epoch #242: loss=0.014877420336359247
Epoch #243: loss=0.01387986685831141
Epoch #244: loss=0.017196025478606016
Epoch #245: loss=0.01841657460285788
Epoch #246: loss=0.02403281785892477
Epoch #247: loss=0.015244740922356446
Epoch #248: loss=0.016082553816213176
Epoch #249: loss=0.02174109506542352

Training time: 4:07:59.517004

Finished.
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth1_traffic_weather_exchange', random_seed=2023, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth1_traffic_weather_exchange_epochs_250_seed_2023
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.0089330361167985
Epoch #1: loss=0.4171165536144379
Epoch #2: loss=0.3152566032106694
Epoch #3: loss=0.2530465635284369
Epoch #4: loss=0.19148374515134894
Epoch #5: loss=0.17027516210098995
Epoch #6: loss=0.1418600062636508
Epoch #7: loss=0.12094026880085072
Epoch #8: loss=0.10619158984769388
Epoch #9: loss=0.1055168340019758
Epoch #10: loss=0.0877133262547915
Epoch #11: loss=0.07875550409019869
Epoch #12: loss=0.07797307134291377
Epoch #13: loss=0.0755336889899145
Epoch #14: loss=0.0654555249186738
Epoch #15: loss=0.06003083819255299
Epoch #16: loss=0.05372374917788932
Epoch #17: loss=0.06855901880040229
Epoch #18: loss=0.05513276815453621
Epoch #19: loss=0.056108480999308125
Epoch #20: loss=0.047935871216071436
Epoch #21: loss=0.043247364739116986
Epoch #22: loss=0.05059081924860577
Epoch #23: loss=0.03924390812291519
Epoch #24: loss=0.042623235751510676
Epoch #25: loss=0.04160558022282799
Epoch #26: loss=0.040101525763226085
Epoch #27: loss=0.041177394050085796
Epoch #28: loss=0.03180829295708054
Epoch #29: loss=0.03170891018565806
Epoch #30: loss=0.042098598706212145
Epoch #31: loss=0.02967243273366049
Epoch #32: loss=0.036234894417513035
Epoch #33: loss=0.02834647482681085
Epoch #34: loss=0.03296159150612366
Epoch #35: loss=0.033441475212495624
Epoch #36: loss=0.03181690263253397
Epoch #37: loss=0.028889297326376448
Epoch #38: loss=0.03211392624255224
Epoch #39: loss=0.03160430374761563
Epoch #40: loss=0.029179212893733233
Epoch #41: loss=0.036380671390929445
Epoch #42: loss=0.027246622316738342
Epoch #43: loss=0.027362087151037728
Epoch #44: loss=0.030055117800987532
Epoch #45: loss=0.023552501913928967
Epoch #46: loss=0.031805416484541806
Epoch #47: loss=0.027279302130524454
Epoch #48: loss=0.02429845847951605
Epoch #49: loss=0.029948790195157726
Epoch #50: loss=0.02504690439318609
Epoch #51: loss=0.024628979494539426
Epoch #52: loss=0.0242696499175718
Epoch #53: loss=0.021904128632160905
Epoch #54: loss=0.03311684592405245
Epoch #55: loss=0.030161164601522693
Epoch #56: loss=0.02863009444787038
Epoch #57: loss=0.023730171092884906
Epoch #58: loss=0.02514073243037878
Epoch #59: loss=0.024245951553567645
Epoch #60: loss=0.02499822363263725
Epoch #61: loss=0.02389029433173648
Epoch #62: loss=0.028024127419650192
Epoch #63: loss=0.02365712740650382
Epoch #64: loss=0.029597001989652604
Epoch #65: loss=0.024085555784030408
Epoch #66: loss=0.02202598144941533
Epoch #67: loss=0.02781611417799493
Epoch #68: loss=0.022937354762415253
Epoch #69: loss=0.035150783531564256
Epoch #70: loss=0.03113336656497872
Epoch #71: loss=0.020664904225792462
Epoch #72: loss=0.02080252877841905
Epoch #73: loss=0.025209205095254757
Epoch #74: loss=0.0244142055963148
Epoch #75: loss=0.020019337143920464
Epoch #76: loss=0.019690906925838293
Epoch #77: loss=0.026107529125855525
Epoch #78: loss=0.02245638368507911
Epoch #79: loss=0.024586599382731996
Epoch #80: loss=0.029910890298293736
Epoch #81: loss=0.02143510782231029
Epoch #82: loss=0.018204943943687005
Epoch #83: loss=0.01966690062596808
Epoch #84: loss=0.023244980549009708
Epoch #85: loss=0.016746544297980528
Epoch #86: loss=0.019258602023938698
Epoch #87: loss=0.019802009318598133
Epoch #88: loss=0.01843784960592862
Epoch #89: loss=0.01988030177734329
Epoch #90: loss=0.01618881216513793
Epoch #91: loss=0.01631840053835037
Epoch #92: loss=0.018953964613047495
Epoch #93: loss=0.03179122955210358
Epoch #94: loss=0.018682315797076517
Epoch #95: loss=0.017079879230517195
Epoch #96: loss=0.019477600742163443
Epoch #97: loss=0.019910531888200498
Epoch #98: loss=0.023468509900261433
Epoch #99: loss=0.03191497291486369
Epoch #100: loss=0.016738230074977076
Epoch #101: loss=0.019581791194935007
Epoch #102: loss=0.0285236119840718
Epoch #103: loss=0.019352184329143235
Epoch #104: loss=0.015513126651009628
Epoch #105: loss=0.02139848378883491
Epoch #106: loss=0.019052955729002237
Epoch #107: loss=0.016858189957955613
Epoch #108: loss=0.01567960259900596
Epoch #109: loss=0.019318888951745296
Epoch #110: loss=0.015812342822026246
Epoch #111: loss=0.015205144128951183
Epoch #112: loss=0.014519500689774933
Epoch #113: loss=0.01994493094608492
Epoch #114: loss=0.014353565173916564
Epoch #115: loss=0.024323926583731264
Epoch #116: loss=0.014659490117559298
Epoch #117: loss=0.021462540472242702
Epoch #118: loss=0.019381400538674955
Epoch #119: loss=0.029820853530975668
Epoch #120: loss=0.020920492997046215
Epoch #121: loss=0.017681360497983308
Epoch #122: loss=0.015999714836564222
Epoch #123: loss=0.018117181061027554
Epoch #124: loss=0.015409505207001713
Epoch #125: loss=0.012523002786201385
Epoch #126: loss=0.017434305755171672
Epoch #127: loss=0.01984042331854429
Epoch #128: loss=0.019655192267764767
Epoch #129: loss=0.014518274129757706
Epoch #130: loss=0.02152155474668749
Epoch #131: loss=0.018149994201620407
Epoch #132: loss=0.016612194459270407
Epoch #133: loss=0.013720445523699483
Epoch #134: loss=0.021033742691076683
Epoch #135: loss=0.021234027850044558
Epoch #136: loss=0.02536997862822471
Epoch #137: loss=0.016642684439301416
Epoch #138: loss=0.01476502624600904
Epoch #139: loss=0.013125269404256144
Epoch #140: loss=0.016203282164847572
Epoch #141: loss=0.019022398981947908
Epoch #142: loss=0.029389702240164996
Epoch #143: loss=0.018877268648402896
Epoch #144: loss=0.018990857927200223
Epoch #145: loss=0.012710118315079231
Epoch #146: loss=0.01482274751871224
Epoch #147: loss=0.014239623466651507
Epoch #148: loss=0.02032184473103583
Epoch #149: loss=0.020439186546538212
Epoch #150: loss=0.018541788918459694
Epoch #151: loss=0.014248894221110192
Epoch #152: loss=0.022686324543528494
Epoch #153: loss=0.026529448925369757
Epoch #154: loss=0.020179573506428083
Epoch #155: loss=0.020235862896908156
Epoch #156: loss=0.016709631871683978
Epoch #157: loss=0.01455808448813962
Epoch #158: loss=0.012343715292926705
Epoch #159: loss=0.016310221490617543
Epoch #160: loss=0.0158318985862529
Epoch #161: loss=0.01213739294970536
Epoch #162: loss=0.018831331047509486
Epoch #163: loss=0.017883375851696064
Epoch #164: loss=0.014667525111451633
Epoch #165: loss=0.020224699745861212
Epoch #166: loss=0.018562369162142267
Epoch #167: loss=0.01636849987142176
Epoch #168: loss=0.01626448546591574
Epoch #169: loss=0.019550344720360352
Epoch #170: loss=0.009892800604003228
Epoch #171: loss=0.013651223802661362
Epoch #172: loss=0.01709668439739989
Epoch #173: loss=0.020437394311580166
Epoch #174: loss=0.018395629400814906
Epoch #175: loss=0.012327002257925787
Epoch #176: loss=0.014818631551808091
Epoch #177: loss=0.010769774194395945
Epoch #178: loss=0.011308570906710306
Epoch #179: loss=0.01683887504068913
Epoch #180: loss=0.01548110091121396
Epoch #181: loss=0.016374386214921384
Epoch #182: loss=0.025226076515154256
Epoch #183: loss=0.015686124514033947
Epoch #184: loss=0.014106697366055429
Epoch #185: loss=0.014593389505391994
Epoch #186: loss=0.015706136444884517
Epoch #187: loss=0.012595737517212135
Epoch #188: loss=0.01875207353304532
Epoch #189: loss=0.01615684803118963
Epoch #190: loss=0.014967774019524694
Epoch #191: loss=0.018405520675383775
Epoch #192: loss=0.014241761237658522
Epoch #193: loss=0.014392176696527596
Epoch #194: loss=0.018722530612421653
Epoch #195: loss=0.014672735151290741
Epoch #196: loss=0.01515783027779045
Epoch #197: loss=0.008452443276307802
Epoch #198: loss=0.02252936953998966
Epoch #199: loss=0.019305224361706213
Epoch #200: loss=0.018385186535158016
Epoch #201: loss=0.011879853542157601
Epoch #202: loss=0.009746349610086347
Epoch #203: loss=0.016135224052064134
Epoch #204: loss=0.01574843893917525
Epoch #205: loss=0.018216222245658716
Epoch #206: loss=0.016919093911688422
Epoch #207: loss=0.01961534100224095
Epoch #208: loss=0.017248080988184592
Epoch #209: loss=0.012861653170717266
Epoch #210: loss=0.0184557509334546
Epoch #211: loss=0.012871825809757858
Epoch #212: loss=0.012699841308751833
Epoch #213: loss=0.012455892592766126
Epoch #214: loss=0.017384245098818734
Epoch #215: loss=0.016804866655446084
Epoch #216: loss=0.013705359488464082
Epoch #217: loss=0.016140034504852064
Epoch #218: loss=0.01307727739982684
Epoch #219: loss=0.014472474056388358
Epoch #220: loss=0.014122238313337811
Epoch #221: loss=0.02080698313565661
Epoch #222: loss=0.013008369684342415
Epoch #223: loss=0.013939647226428596
Epoch #224: loss=0.012921196935113864
Epoch #225: loss=0.012500793590395508
Epoch #226: loss=0.017147164117422543
Epoch #227: loss=0.0214547639158526
Epoch #228: loss=0.012617223993324595
Epoch #229: loss=0.014958779278388176
Epoch #230: loss=0.013907859612932864
Epoch #231: loss=0.012610378283501943
Epoch #232: loss=0.015045906101619173
Epoch #233: loss=0.009687888308839227
Epoch #234: loss=0.015826776271901512
Epoch #235: loss=0.02264631067985124
Epoch #236: loss=0.012939423857504814
Epoch #237: loss=0.0124434172415617
Epoch #238: loss=0.019032814972239815
Epoch #239: loss=0.011211894174135555
Epoch #240: loss=0.01109347614167374
Epoch #241: loss=0.014314899595673758
Epoch #242: loss=0.020122368678875766
Epoch #243: loss=0.015446321687106496
Epoch #244: loss=0.010759455683572937
Epoch #245: loss=0.014115619556055272
Epoch #246: loss=0.010885523872782996
Epoch #247: loss=0.01565408799884318
Epoch #248: loss=0.016803471295470836
Epoch #249: loss=0.023034148033326277

Training time: 3:43:42.894677

Finished.
n2one setting etth1_traffic_weather_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth1_traffic_weather_exchange_epochs_250_seed_2023/model.pkl', muti_dataset='etth1_traffic_weather_exchange', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.44674e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.83181e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.84504e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.44674e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4218044158520463, 'MAE': 0.46372477907021126}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm1_ettm2_electricity', random_seed=2023, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm1_ettm2_electricity_epochs_250_seed_2023
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.6919181958266667
Epoch #1: loss=0.7233649754524231
Epoch #2: loss=0.4944637707727296
Epoch #3: loss=0.3712731098277228
Epoch #4: loss=0.34083773493766784
Epoch #5: loss=0.2825955181675298
Epoch #6: loss=0.264262480118445
Epoch #7: loss=0.24804455325007438
Epoch #8: loss=0.19967906064220836
Epoch #9: loss=0.1610630157057728
Epoch #10: loss=0.1595915935082095
Epoch #11: loss=0.14835496920560087
Epoch #12: loss=0.12564265451260975
Epoch #13: loss=0.1233675188624433
Epoch #14: loss=0.096086267908769
Epoch #15: loss=0.11122568603072848
Epoch #16: loss=0.09347346876348768
Epoch #17: loss=0.08506292809067027
Epoch #18: loss=0.07673264805759702
Epoch #19: loss=0.07053064287241016
Epoch #20: loss=0.0728548084013164
Epoch #21: loss=0.07369293781263488
Epoch #22: loss=0.06366601783117014
Epoch #23: loss=0.06590909452842815
Epoch #24: loss=0.05191047352871724
Epoch #25: loss=0.05423018649752651
Epoch #26: loss=0.05943783804641238
Epoch #27: loss=0.044548025428583576
Epoch #28: loss=0.07978571704721876
Epoch #29: loss=0.057697719956881235
Epoch #30: loss=0.03905238504920687
Epoch #31: loss=0.0441270493463214
Epoch #32: loss=0.06079746372465576
Epoch #33: loss=0.034652778410485814
Epoch #34: loss=0.04496513565270496
Epoch #35: loss=0.039580570738762616
Epoch #36: loss=0.036117818015627565
Epoch #37: loss=0.05774906288100672
Epoch #38: loss=0.03619277058302292
Epoch #39: loss=0.044317498534385644
Epoch #40: loss=0.03280304093512573
Epoch #41: loss=0.037351429919778766
Epoch #42: loss=0.04224013802395867
Epoch #43: loss=0.031859445554603426
Epoch #44: loss=0.02853615250471713
Epoch #45: loss=0.03604569958655962
Epoch #46: loss=0.024844918251037598
Epoch #47: loss=0.03718705513414794
Epoch #48: loss=0.04888547999584781
Epoch #49: loss=0.0288943485350215
Epoch #50: loss=0.025592209700095868
Epoch #51: loss=0.031239318038403456
Epoch #52: loss=0.026138804664037056
Epoch #53: loss=0.03029104438477329
Epoch #54: loss=0.03490508740102606
Epoch #55: loss=0.021774184105784765
Epoch #56: loss=0.03357005370614518
Epoch #57: loss=0.02755751536127978
Epoch #58: loss=0.025633495457004756
Epoch #59: loss=0.026886697393077027
Epoch #60: loss=0.020561029010651898
Epoch #61: loss=0.030407087402418254
Epoch #62: loss=0.019965615071788696
Epoch #63: loss=0.021499821023982284
Epoch #64: loss=0.02875548179427694
Epoch #65: loss=0.025572747217624314
Epoch #66: loss=0.020432025931908616
Epoch #67: loss=0.021029521353609328
Epoch #68: loss=0.025107123924618852
Epoch #69: loss=0.019378160335057015
Epoch #70: loss=0.024002355192787945
Epoch #71: loss=0.01981015367632998
Epoch #72: loss=0.01852080195410443
Epoch #73: loss=0.018913489860465885
Epoch #74: loss=0.023190007153233248
Epoch #75: loss=0.020308782928124335
Epoch #76: loss=0.0320436663144002
Epoch #77: loss=0.019491985949155476
Epoch #78: loss=0.029261387333473457
Epoch #79: loss=0.015908432438570475
Epoch #80: loss=0.020047824795557452
Epoch #81: loss=0.0326736579093683
Epoch #82: loss=0.019901747759098986
Epoch #83: loss=0.018275166328863373
Epoch #84: loss=0.020603952781031176
Epoch #85: loss=0.017747628763650675
Epoch #86: loss=0.010462205982101815
Epoch #87: loss=0.02228715372953697
Epoch #88: loss=0.018415449377748052
Epoch #89: loss=0.0209964874990484
Epoch #90: loss=0.020018105881089078
Epoch #91: loss=0.01750620094959491
Epoch #92: loss=0.022210966578984102
Epoch #93: loss=0.02310339704588322
Epoch #94: loss=0.018704673440494975
Epoch #95: loss=0.01761276359254095
Epoch #96: loss=0.035144354935036974
Epoch #97: loss=0.026907781912346503
Epoch #98: loss=0.04183746418125728
Epoch #99: loss=0.021223456866573544
Epoch #100: loss=0.017268827587332843
Epoch #101: loss=0.017208831819007172
Epoch #102: loss=0.01340132600112286
Epoch #103: loss=0.03300857275591365
Epoch #104: loss=0.017968692727653043
Epoch #105: loss=0.009265791927048538
Epoch #106: loss=0.013297300031907591
Epoch #107: loss=0.054019807604573936
Epoch #108: loss=0.016151908018426704
Epoch #109: loss=0.015624624250589737
Epoch #110: loss=0.015594443649585758
Epoch #111: loss=0.014785575610834972
Epoch #112: loss=0.019627843421185388
Epoch #113: loss=0.017400524052624988
Epoch #114: loss=0.010630052162201278
Epoch #115: loss=0.012049545344863353
Epoch #116: loss=0.02892885915336332
Epoch #117: loss=0.010927838722959028
Epoch #118: loss=0.01587829550728202
Epoch #119: loss=0.016138444477858553
Epoch #120: loss=0.013985694205122334
Epoch #121: loss=0.016442918725078925
Epoch #122: loss=0.012356895460980013
Epoch #123: loss=0.01862006927873673
Epoch #124: loss=0.0158375994326447
Epoch #125: loss=0.012823635768145323
Epoch #126: loss=0.013254246846939039
Epoch #127: loss=0.019418439690156705
Epoch #128: loss=0.029121254900736467
Epoch #129: loss=0.017121686140973386
Epoch #130: loss=0.017771069297034824
Epoch #131: loss=0.01712683123336839
Epoch #132: loss=0.01565652656668265
Epoch #133: loss=0.010934996399779006
Epoch #134: loss=0.01345287001284305
Epoch #135: loss=0.01956439364169325
Epoch #136: loss=0.01210733042323097
Epoch #137: loss=0.010402997225589518
Epoch #138: loss=0.008976944207845788
Epoch #139: loss=0.014621977029601113
Epoch #140: loss=0.014366744230335047
Epoch #141: loss=0.011560480331619537
Epoch #142: loss=0.012514875437315953
Epoch #143: loss=0.010692398868850433
Epoch #144: loss=0.024549294638979646
Epoch #145: loss=0.013170154955670504
Epoch #146: loss=0.016999122533182216
Epoch #147: loss=0.014644300983054564
Epoch #148: loss=0.01658440253830382
Epoch #149: loss=0.015139270233921706
Epoch #150: loss=0.012879241768969223
Epoch #151: loss=0.00941488946089521
Epoch #152: loss=0.012972849562730907
Epoch #153: loss=0.015783851506920264
Epoch #154: loss=0.015317715650723715
Epoch #155: loss=0.015841144968788804
Epoch #156: loss=0.014462679917258876
Epoch #157: loss=0.008458612397537634
Epoch #158: loss=0.013892849391725446
Epoch #159: loss=0.013955041495750525
Epoch #160: loss=0.017642957670447816
Epoch #161: loss=0.018823614573339
Epoch #162: loss=0.015560901794649128
Epoch #163: loss=0.011939209006689322
Epoch #164: loss=0.013055404469404104
Epoch #165: loss=0.009978035546165692
Epoch #166: loss=0.02142074973887897
Epoch #167: loss=0.013238974142919427
Epoch #168: loss=0.00902064333794572
Epoch #169: loss=0.010511165640938479
Epoch #170: loss=0.009653541006181123
Epoch #171: loss=0.014278949706682137
Epoch #172: loss=0.01562689494125412
Epoch #173: loss=0.01836791537934914
Epoch #174: loss=0.01853996804865476
Epoch #175: loss=0.010277323727495968
Epoch #176: loss=0.012922308093153072
Epoch #177: loss=0.011964092930845384
Epoch #178: loss=0.015009590637637302
Epoch #179: loss=0.016126423104932265
Epoch #180: loss=0.01174615862072512
Epoch #181: loss=0.010321147300419397
Epoch #182: loss=0.013870175758077363
Epoch #183: loss=0.010512835295355346
Epoch #184: loss=0.010673500426221706
Epoch #185: loss=0.012826623094900113
Epoch #186: loss=0.013190388405263157
Epoch #187: loss=0.012755574065127543
Epoch #188: loss=0.012865740228776953
Epoch #189: loss=0.01790829463828621
Epoch #190: loss=0.012296880956938757
Epoch #191: loss=0.014848926685683961
Epoch #192: loss=0.005870095333708117
Epoch #193: loss=0.0106948571772747
Epoch #194: loss=0.01691037495121626
Epoch #195: loss=0.01692375221655571
Epoch #196: loss=0.014293054513816189
Epoch #197: loss=0.011092826500950781
Epoch #198: loss=0.010640562615507016
Epoch #199: loss=0.010630592626153625
Epoch #200: loss=0.021430055201386234
Epoch #201: loss=0.013383828003092535
Epoch #202: loss=0.00988099613725873
Epoch #203: loss=0.010972366141920377
Epoch #204: loss=0.014102975378544736
Epoch #205: loss=0.009104025333903597
Epoch #206: loss=0.011716896950134208
Epoch #207: loss=0.013113125449329216
Epoch #208: loss=0.010404543142898806
Epoch #209: loss=0.01004993522257012
Epoch #210: loss=0.011960311663403575
Epoch #211: loss=0.007454177001657496
Epoch #212: loss=0.011723159100843726
Epoch #213: loss=0.013022183245962618
Epoch #214: loss=0.008595381592708042
Epoch #215: loss=0.01993396311948475
Epoch #216: loss=0.009210919960002815
Epoch #217: loss=0.008272896780565914
Epoch #218: loss=0.03479909091688959
Epoch #219: loss=0.010657823201784464
Epoch #220: loss=0.011333989778317378
Epoch #221: loss=0.00843009137980906
Epoch #222: loss=0.009143445871304721
Epoch #223: loss=0.010259205041885643
Epoch #224: loss=0.01732147842795322
Epoch #225: loss=0.01236621914065576
Epoch #226: loss=0.006953426718786691
Epoch #227: loss=0.015014170836158363
Epoch #228: loss=0.015446635965740176
Epoch #229: loss=0.00906097085581028
Epoch #230: loss=0.008870411881528395
Epoch #231: loss=0.008297078732617333
Epoch #232: loss=0.008037682861738307
Epoch #233: loss=0.01226995404319106
Epoch #234: loss=0.006932196660449595
Epoch #235: loss=0.008042567192793025
Epoch #236: loss=0.01108718399316006
Epoch #237: loss=0.010171999203240766
Epoch #238: loss=0.010741430947756661
Epoch #239: loss=0.00992845303329107
Epoch #240: loss=0.00827119389345171
Epoch #241: loss=0.009472900603182746
Epoch #242: loss=0.01646869671699408
Epoch #243: loss=0.00904734040319454
Epoch #244: loss=0.009231473505829594
Epoch #245: loss=0.020254518949160617
Epoch #246: loss=0.011522535324578972
Epoch #247: loss=0.007433809958913896
Epoch #248: loss=0.010926344237273691
Epoch #249: loss=0.009901464897474009

Training time: 1:42:12.436766

Finished.
n2one setting etth2_ettm1_ettm2_electricity -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_ettm2_electricity_epochs_250_seed_2023/model.pkl', muti_dataset='etth2_ettm1_ettm2_electricity', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=6.73382e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.28009e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.31661e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=6.73382e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.6541064443308308, 'MAE': 0.6237341496690543}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm1_ettm2_electricity -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_ettm2_electricity_epochs_250_seed_2023/model.pkl', muti_dataset='etth2_ettm1_ettm2_electricity', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.68179e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.25226212572508455, 'MAE': 0.33987170245795983}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm1_ettm2_traffic', random_seed=2023, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm1_ettm2_traffic_epochs_250_seed_2023
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.0008883289950998
Epoch #1: loss=0.36701257172323903
Epoch #2: loss=0.2804864106154201
Epoch #3: loss=0.20528915638624617
Epoch #4: loss=0.15768169647231112
Epoch #5: loss=0.13063999792450137
Epoch #6: loss=0.11007889178733098
Epoch #7: loss=0.08763181732070667
Epoch #8: loss=0.08959796433478143
Epoch #9: loss=0.0801413304707627
Epoch #10: loss=0.07255292045554579
Epoch #11: loss=0.06489457808671191
Epoch #12: loss=0.06295790346302761
Epoch #13: loss=0.056886349550702354
Epoch #14: loss=0.05600120232510564
Epoch #15: loss=0.06815945628301923
Epoch #16: loss=0.04316767151979677
Epoch #17: loss=0.04003742726871955
Epoch #18: loss=0.04465677690829174
Epoch #19: loss=0.040366722801182836
Epoch #20: loss=0.03675970857582493
Epoch #21: loss=0.03274647969837216
Epoch #22: loss=0.03710638872213457
Epoch #23: loss=0.039906769580527614
Epoch #24: loss=0.030128651775219024
Epoch #25: loss=0.049779878675260326
Epoch #26: loss=0.031857235179602574
Epoch #27: loss=0.042121755469048984
Epoch #28: loss=0.02805693071637633
Epoch #29: loss=0.026772178404031094
Epoch #30: loss=0.031189381565394844
Epoch #31: loss=0.026280763769139747
Epoch #32: loss=0.02393696563920439
Epoch #33: loss=0.02613469683605703
Epoch #34: loss=0.027273870625741693
Epoch #35: loss=0.02125929464733983
Epoch #36: loss=0.02369163434135369
Epoch #37: loss=0.026522015288639938
Epoch #38: loss=0.019451968716279792
Epoch #39: loss=0.02669632763172762
Epoch #40: loss=0.019363941730331426
Epoch #41: loss=0.021506332315574583
Epoch #42: loss=0.023239863665179192
Epoch #43: loss=0.020813083609654417
Epoch #44: loss=0.02543973341084051
Epoch #45: loss=0.021363499761659938
Epoch #46: loss=0.018869589967313447
Epoch #47: loss=0.016478115604867935
Epoch #48: loss=0.02011438381877638
Epoch #49: loss=0.01851249853811226
Epoch #50: loss=0.02015616865098261
Epoch #51: loss=0.018445138043838193
Epoch #52: loss=0.018589323051284277
Epoch #53: loss=0.01656974136568585
Epoch #54: loss=0.02129992716217949
Epoch #55: loss=0.023379000803044402
Epoch #56: loss=0.01695850007544354
Epoch #57: loss=0.020247808650661756
Epoch #58: loss=0.014124129993376436
Epoch #59: loss=0.01887757564956525
Epoch #60: loss=0.019788409071291382
Epoch #61: loss=0.016801148734821632
Epoch #62: loss=0.020849579963890582
Epoch #63: loss=0.015971951168234324
Epoch #64: loss=0.019370270569275178
Epoch #65: loss=0.012310932027753525
Epoch #66: loss=0.025347821307070677
Epoch #67: loss=0.01713342475606856
Epoch #68: loss=0.01576453229197114
Epoch #69: loss=0.02306021093494101
Epoch #70: loss=0.01694458698380611
Epoch #71: loss=0.015757388233145236
Epoch #72: loss=0.015947136796422158
Epoch #73: loss=0.018341518575935776
Epoch #74: loss=0.014313315873027243
Epoch #75: loss=0.012486885423867678
Epoch #76: loss=0.017789220895849986
Epoch #77: loss=0.01250736194409406
Epoch #78: loss=0.015082924137359451
Epoch #79: loss=0.02207744348074694
Epoch #80: loss=0.019337851818604968
Epoch #81: loss=0.014224296956544943
Epoch #82: loss=0.014265117034858029
Epoch #83: loss=0.01818686915970774
Epoch #84: loss=0.01687255662696867
Epoch #85: loss=0.014310027112747677
Epoch #86: loss=0.012293695335023735
Epoch #87: loss=0.013854268920402995
Epoch #88: loss=0.013837594529650436
Epoch #89: loss=0.014359408778831724
Epoch #90: loss=0.013303772833828859
Epoch #91: loss=0.014764502109890734
Epoch #92: loss=0.012718544957279223
Epoch #93: loss=0.026308264063171338
Epoch #94: loss=0.01393038732307131
Epoch #95: loss=0.020323656874436543
Epoch #96: loss=0.01990468088627869
Epoch #97: loss=0.013584968386628444
Epoch #98: loss=0.013312932119289817
Epoch #99: loss=0.01327040244239482
Epoch #100: loss=0.012634585030817486
Epoch #101: loss=0.013125306091214636
Epoch #102: loss=0.013462443727196124
Epoch #103: loss=0.012383966256318745
Epoch #104: loss=0.018925307420970598
Epoch #105: loss=0.012986319373704348
Epoch #106: loss=0.014275789668938504
Epoch #107: loss=0.011754293299447952
Epoch #108: loss=0.01312666887928435
Epoch #109: loss=0.012146205134151763
Epoch #110: loss=0.014242876857964267
Epoch #111: loss=0.01863792677358076
Epoch #112: loss=0.011535326159516334
Epoch #113: loss=0.013762449857365449
Epoch #114: loss=0.01281483103401617
Epoch #115: loss=0.014913576958442575
Epoch #116: loss=0.01045574824017782
Epoch #117: loss=0.009942969424024978
Epoch #118: loss=0.014951871263442612
Epoch #119: loss=0.016538063177660444
Epoch #120: loss=0.01086300630857695
Epoch #121: loss=0.013701116846063368
Epoch #122: loss=0.012480624457620692
Epoch #123: loss=0.011818423946044439
Epoch #124: loss=0.008710136012682184
Epoch #125: loss=0.01316318033849835
Epoch #126: loss=0.01390226980107894
Epoch #127: loss=0.02063259947633446
Epoch #128: loss=0.012360322503838166
Epoch #129: loss=0.010334412712509997
Epoch #130: loss=0.03282790858003647
Epoch #131: loss=0.010710148878673073
Epoch #132: loss=0.009715567011885005
Epoch #133: loss=0.01196946432809037
Epoch #134: loss=0.010586501781508722
Epoch #135: loss=0.01082341239526847
Epoch #136: loss=0.016702643074347417
Epoch #137: loss=0.011292093222102152
Epoch #138: loss=0.014055908242644017
Epoch #139: loss=0.011492357761869583
Epoch #140: loss=0.0143244375331551
Epoch #141: loss=0.010640536017924198
Epoch #142: loss=0.01536670908995347
Epoch #143: loss=0.012619110113122053
Epoch #144: loss=0.013877122920192308
Epoch #145: loss=0.021327969853585434
Epoch #146: loss=0.010000295524561059
Epoch #147: loss=0.009394872542227019
Epoch #148: loss=0.009916917803666846
Epoch #149: loss=0.012004483634055678
Epoch #150: loss=0.00928535437913414
Epoch #151: loss=0.009124023073071178
Epoch #152: loss=0.01413705519328153
Epoch #153: loss=0.011408880791523914
Epoch #154: loss=0.013242045295067804
Epoch #155: loss=0.023326360925772845
Epoch #156: loss=0.013603243649666492
Epoch #157: loss=0.009930662099996114
Epoch #158: loss=0.01227492843677502
Epoch #159: loss=0.008762309642557834
Epoch #160: loss=0.010134479301540922
Epoch #161: loss=0.015702625222121323
Epoch #162: loss=0.010441574026785026
Epoch #163: loss=0.0117515394019477
Epoch #164: loss=0.00965712142655939
Epoch #165: loss=0.00784897259058296
Epoch #166: loss=0.0078075866744712185
Epoch #167: loss=0.012235697294726778
Epoch #168: loss=0.011327585353102578
Epoch #169: loss=0.01598520856817759
Epoch #170: loss=0.013112186829597526
Epoch #171: loss=0.010834084564896236
Epoch #172: loss=0.011023098466231989
Epoch #173: loss=0.009153982705794516
Epoch #174: loss=0.008253569376568558
Epoch #175: loss=0.010580427777353992
Epoch #176: loss=0.010677926415831266
Epoch #177: loss=0.011357562892169923
Epoch #178: loss=0.01113838016298677
Epoch #179: loss=0.010262528236728193
Epoch #180: loss=0.010190894834612451
Epoch #181: loss=0.01045941850248234
Epoch #182: loss=0.011391269827323499
Epoch #183: loss=0.009660081708900198
Epoch #184: loss=0.007739260084865673
Epoch #185: loss=0.010904197748892211
Epoch #186: loss=0.012423659041688398
Epoch #187: loss=0.00871365934728742
Epoch #188: loss=0.011072469711748337
Epoch #189: loss=0.008817290011622868
Epoch #190: loss=0.010634438564476826
Epoch #191: loss=0.00957484627184032
Epoch #192: loss=0.013305655611413985
Epoch #193: loss=0.009496387591082227
Epoch #194: loss=0.0079503770332213
Epoch #195: loss=0.015170943433429061
Epoch #196: loss=0.006420871428148771
Epoch #197: loss=0.010968503775303728
Epoch #198: loss=0.01121185847241434
Epoch #199: loss=0.014152125750364439
Epoch #200: loss=0.010317527347992465
Epoch #201: loss=0.011377716269822948
Epoch #202: loss=0.009219285202962014
Epoch #203: loss=0.007323824667201253
Epoch #204: loss=0.008492063627164528
Epoch #205: loss=0.010481775371675555
Epoch #206: loss=0.013042755908798949
Epoch #207: loss=0.009341951212177922
Epoch #208: loss=0.010105484176651072
Epoch #209: loss=0.010527802410138449
Epoch #210: loss=0.009118802944956976
Epoch #211: loss=0.009725718576145933
Epoch #212: loss=0.015187776398116736
Epoch #213: loss=0.006726370416250742
Epoch #214: loss=0.0076405966274975855
Epoch #215: loss=0.0076704529318317
Epoch #216: loss=0.014689485169858954
Epoch #217: loss=0.00854716470938238
Epoch #218: loss=0.00928200793530759
Epoch #219: loss=0.00923127132942145
Epoch #220: loss=0.006702875151986784
Epoch #221: loss=0.011311975920298627
Epoch #222: loss=0.006359036836839574
Epoch #223: loss=0.01018724370139764
Epoch #224: loss=0.014230674906818445
Epoch #225: loss=0.01013338364829516
Epoch #226: loss=0.007869653168364217
Epoch #227: loss=0.011602092244139129
Epoch #228: loss=0.007900950786765162
Epoch #229: loss=0.007360999590847129
Epoch #230: loss=0.01184754120893152
Epoch #231: loss=0.007985623294433242
Epoch #232: loss=0.006970686446476504
Epoch #233: loss=0.01837535297402597
Epoch #234: loss=0.007551564194505419
Epoch #235: loss=0.008567144625600912
Epoch #236: loss=0.011369088073967283
Epoch #237: loss=0.01056455415078085
Epoch #238: loss=0.010150394967633564
Epoch #239: loss=0.005537825511233028
Epoch #240: loss=0.009726273129791765
Epoch #241: loss=0.009224566366544997
Epoch #242: loss=0.016248935658836033
Epoch #243: loss=0.009148743321601259
Epoch #244: loss=0.014822135672384667
Epoch #245: loss=0.007900498280311228
Epoch #246: loss=0.007077077472765771
Epoch #247: loss=0.009824690390974033
Epoch #248: loss=0.009382020839129776
Epoch #249: loss=0.011968111674261869

Training time: 3:37:57.273790

Finished.
n2one setting etth2_ettm1_ettm2_traffic -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_ettm2_traffic_epochs_250_seed_2023/model.pkl', muti_dataset='etth2_ettm1_ettm2_traffic', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.4251e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.84818e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.62477e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.4251e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3972745246330205, 'MAE': 0.4449942629102847}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm1_ettm2_traffic -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_ettm2_traffic_epochs_250_seed_2023/model.pkl', muti_dataset='etth2_ettm1_ettm2_traffic', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.3574e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.67785e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.13113e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.3574e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4579322389641026, 'MAE': 0.504276013044089}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm1_ettm2_traffic -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_ettm2_traffic_epochs_250_seed_2023/model.pkl', muti_dataset='etth2_ettm1_ettm2_traffic', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
Evaluation result: {'MSE': 0.21217750140850916, 'MAE': 0.3194106148295618}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm1_ettm2_weather', random_seed=2023, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm1_ettm2_weather_epochs_250_seed_2023
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=3.951625832644376
Epoch #1: loss=2.35266159881245
Epoch #2: loss=2.14414917122234
Epoch #3: loss=1.815168302709406
Epoch #4: loss=1.6486143784089522
Epoch #5: loss=1.5092710408297452
Epoch #6: loss=1.311782631007108
Epoch #7: loss=1.276170271093195
Epoch #8: loss=1.176351389017972
Epoch #9: loss=1.1504270900379527
Epoch #10: loss=1.0204346743496981
Epoch #11: loss=0.9446455435319381
Epoch #12: loss=0.9409375309944152
Epoch #13: loss=0.947173437205228
Epoch #14: loss=0.9114880865270442
Epoch #15: loss=0.8168378298932856
Epoch #16: loss=0.8435655853965066
Epoch #17: loss=0.8360419370911338
Epoch #18: loss=0.7792047370563854
Epoch #19: loss=0.69131126945669
Epoch #20: loss=0.696003770828247
Epoch #21: loss=0.637863386219198
Epoch #22: loss=0.6145667829296806
Epoch #23: loss=0.5873318802226674
Epoch #24: loss=0.5931897938251496
Epoch #25: loss=0.6024216738614169
Epoch #26: loss=0.6146168486638502
Epoch #27: loss=0.505919174714522
Epoch #28: loss=0.532751858776266
Epoch #29: loss=0.5551993424242193
Epoch #30: loss=0.5681810319423676
Epoch #31: loss=0.4868173582987352
Epoch #32: loss=0.4591094092889266
Epoch #33: loss=0.5001224994659423
Epoch #34: loss=0.5504840119318528
Epoch #35: loss=0.5031945992599834
Epoch #36: loss=0.4038851103999398
Epoch #37: loss=0.4214652581648393
Epoch #38: loss=0.3734448026527058
Epoch #39: loss=0.35166458568789744
Epoch #40: loss=0.43870428529652683
Epoch #41: loss=0.3591303275390105
Epoch #42: loss=0.36170710352334107
Epoch #43: loss=0.4360623226924376
Epoch #44: loss=0.37004367167299446
Epoch #45: loss=0.40057153539224105
Epoch #46: loss=0.35747148909352044
Epoch #47: loss=0.432871875166893
Epoch #48: loss=0.3526493714614348
Epoch #49: loss=0.33116732944141736
Epoch #50: loss=0.3349915918978778
Epoch #51: loss=0.3750735561956059
Epoch #52: loss=0.34902744049375706
Epoch #53: loss=0.31158113235777074
Epoch #54: loss=0.2767315838824619
Epoch #55: loss=0.2788927666165612
Epoch #56: loss=0.2573497839949348
Epoch #57: loss=0.2587991463867101
Epoch #58: loss=0.2133092621510679
Epoch #59: loss=0.21762545948678796
Epoch #60: loss=0.2064653691920367
Epoch #61: loss=0.21843027540228582
Epoch #62: loss=0.24372994086959146
Epoch #63: loss=0.23660614991729909
Epoch #64: loss=0.21314361359585415
Epoch #65: loss=0.20655012780969792
Epoch #66: loss=0.16815964328971775
Epoch #67: loss=0.18854309916496276
Epoch #68: loss=0.179640209403905
Epoch #69: loss=0.19622243683446539
Epoch #70: loss=0.18042623895135793
Epoch #71: loss=0.17134844267910176
Epoch #72: loss=0.18183764016086404
Epoch #73: loss=0.22448380494659598
Epoch #74: loss=0.17938176359642635
Epoch #75: loss=0.181646836345846
Epoch #76: loss=0.17312473099340092
Epoch #77: loss=0.1792119515890425
Epoch #78: loss=0.13394483144987712
Epoch #79: loss=0.11959566548466682
Epoch #80: loss=0.14761031066829508
Epoch #81: loss=0.15736575052142143
Epoch #82: loss=0.17189907384189693
Epoch #83: loss=0.13328067470680582
Epoch #84: loss=0.22483269301327793
Epoch #85: loss=0.14296344329010358
Epoch #86: loss=0.19866173978556287
Epoch #87: loss=0.20987336750734936
Epoch #88: loss=0.35752340108156205
Epoch #89: loss=0.16653752624988555
Epoch #90: loss=0.17819433703341267
Epoch #91: loss=0.20811461535367098
Epoch #92: loss=0.14752408628436653
Epoch #93: loss=0.12212655273350802
Epoch #94: loss=0.2015936023809693
Epoch #95: loss=0.14382898753339593
Epoch #96: loss=0.11224443221634084
Epoch #97: loss=0.10729899314994162
Epoch #98: loss=0.15948841734365984
Epoch #99: loss=0.10979346605864439
Epoch #100: loss=0.1530196385627443
Epoch #101: loss=0.10502290454777805
Epoch #102: loss=0.11009109849956902
Epoch #103: loss=0.09503474743528799
Epoch #104: loss=0.11376029926944863
Epoch #105: loss=0.1084575967355208
Epoch #106: loss=0.13416114937175405
Epoch #107: loss=0.12995310584929856
Epoch #108: loss=0.13827735009518535
Epoch #109: loss=0.10133191875436089
Epoch #110: loss=0.12092874205925248
Epoch #111: loss=0.1105275252664631
Epoch #112: loss=0.09497076279737733
Epoch #113: loss=0.11932303173975511
Epoch #114: loss=0.07861567816951058
Epoch #115: loss=0.08920261565257202
Epoch #116: loss=0.13262173184617
Epoch #117: loss=0.09957240545614199
Epoch #118: loss=0.11430334293029525
Epoch #119: loss=0.16271759976040234
Epoch #120: loss=0.1330113521353765
Epoch #121: loss=0.08245103545486927
Epoch #122: loss=0.11187619759955189
Epoch #123: loss=0.08599412663077766
Epoch #124: loss=0.11053453937850215
Epoch #125: loss=0.10342531214383516
Epoch #126: loss=0.11620189208876003
Epoch #127: loss=0.09367484159090302
Epoch #128: loss=0.07605004960840399
Epoch #129: loss=0.1005351935936646
Epoch #130: loss=0.09506392133506862
Epoch #131: loss=0.07914698510007424
Epoch #132: loss=0.14774980710988694
Epoch #133: loss=0.09685627608136697
Epoch #134: loss=0.12813772410154342
Epoch #135: loss=0.09364376781000332
Epoch #136: loss=0.1424334255470471
Epoch #137: loss=0.12202246930788864
Epoch #138: loss=0.08427827805280685
Epoch #139: loss=0.0805689410391179
Epoch #140: loss=0.07251277596435764
Epoch #141: loss=0.09497437243434516
Epoch #142: loss=0.07580520883202553
Epoch #143: loss=0.08909463545476848
Epoch #144: loss=0.06754389899698171
Epoch #145: loss=0.06886583614078436
Epoch #146: loss=0.0635508226908066
Epoch #147: loss=0.07452887977388772
Epoch #148: loss=0.08398366599259051
Epoch #149: loss=0.09286335422234102
Epoch #150: loss=0.06786419901658189
Epoch #151: loss=0.07877872721715407
Epoch #152: loss=0.08621250125156207
Epoch #153: loss=0.08152732965959744
Epoch #154: loss=0.0991750492291017
Epoch #155: loss=0.12836670467460698
Epoch #156: loss=0.10425250697880983
Epoch #157: loss=0.0553913705389608
Epoch #158: loss=0.0760362155904824
Epoch #159: loss=0.07845683399249206
Epoch #160: loss=0.13813452786681327
Epoch #161: loss=0.16735953170467507
Epoch #162: loss=0.09391944059594111
Epoch #163: loss=0.08759000125256451
Epoch #164: loss=0.0769508763470433
Epoch #165: loss=0.06357863498005
Epoch #166: loss=0.12113333056596193
Epoch #167: loss=0.10415733886713331
Epoch #168: loss=0.0788227520713752
Epoch #169: loss=0.06492517725987867
Epoch #170: loss=0.07171915264969522
Epoch #171: loss=0.059393045881932435
Epoch #172: loss=0.07512230415913192
Epoch #173: loss=0.057214321077547294
Epoch #174: loss=0.06531168881126426
Epoch #175: loss=0.08673465897075154
Epoch #176: loss=0.09834485985338688
Epoch #177: loss=0.08058822153305466
Epoch #178: loss=0.06796194235370918
Epoch #179: loss=0.06082813387567347
Epoch #180: loss=0.06359711782160131
Epoch #181: loss=0.05882847114381465
Epoch #182: loss=0.07361289856278083
Epoch #183: loss=0.06589739270169627
Epoch #184: loss=0.05432590334252878
Epoch #185: loss=0.07008884489874947
Epoch #186: loss=0.15815927968783813
Epoch #187: loss=0.09301631301641464
Epoch #188: loss=0.0552329843017188
Epoch #189: loss=0.13613515787503935
Epoch #190: loss=0.08015057861127636
Epoch #191: loss=0.05819514007730917
Epoch #192: loss=0.05691282618790865
Epoch #193: loss=0.05614223243160681
Epoch #194: loss=0.06489124706184322
Epoch #195: loss=0.0861627767031843
Epoch #196: loss=0.07935776673257351
Epoch #197: loss=0.05734947620129043
Epoch #198: loss=0.05163123908198693
Epoch #199: loss=0.053861790472133596
Epoch #200: loss=0.09335804697634144
Epoch #201: loss=0.07260015088726174
Epoch #202: loss=0.06888069010932338
Epoch #203: loss=0.04372380562126636
Epoch #204: loss=0.039232909730212255
Epoch #205: loss=0.08379797333512794
Epoch #206: loss=0.04253708154640414
Epoch #207: loss=0.06845919159664349
Epoch #208: loss=0.04600303261117502
Epoch #209: loss=0.04346277214248072
Epoch #210: loss=0.059042575100267475
Epoch #211: loss=0.04080048586157235
Epoch #212: loss=0.04987531125714833
Epoch #213: loss=0.06528088551183993
Epoch #214: loss=0.03541130201721733
Epoch #215: loss=0.06852825174785473
Epoch #216: loss=0.08749235826121135
Epoch #217: loss=0.0871308137578043
Epoch #218: loss=0.1444374434988607
Epoch #219: loss=0.11575959079306233
Epoch #220: loss=0.10835740110752258
Epoch #221: loss=0.06166115701198578
Epoch #222: loss=0.0675768019631505
Epoch #223: loss=0.05901902127502994
Epoch #224: loss=0.0904575011438944
Epoch #225: loss=0.05864259698851542
Epoch #226: loss=0.04902136519720608
Epoch #227: loss=0.0425160254267129
Epoch #228: loss=0.04117380362004042
Epoch #229: loss=0.12662172861058604
Epoch #230: loss=0.09854719823395663
Epoch #231: loss=0.07956018171865832
Epoch #232: loss=0.0637451180849563
Epoch #233: loss=0.042136799323965204
Epoch #234: loss=0.050409157015383246
Epoch #235: loss=0.04986435411159288
Epoch #236: loss=0.09046253984455357
Epoch #237: loss=0.054220586591823536
Epoch #238: loss=0.051153288603844965
Epoch #239: loss=0.05053461254997687
Epoch #240: loss=0.047787686860696836
Epoch #241: loss=0.05313057201829824
Epoch #242: loss=0.07061144177039916
Epoch #243: loss=0.11180565430020745
Epoch #244: loss=0.05714546574956991
Epoch #245: loss=0.046128936899317935
Epoch #246: loss=0.03462277815931223
Epoch #247: loss=0.0498060625215823
Epoch #248: loss=0.04103291908448393
Epoch #249: loss=0.08648475424640557

Training time: 0:18:42.306092

Finished.
n2one setting etth2_ettm1_ettm2_weather -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_ettm2_weather_epochs_250_seed_2023/model.pkl', muti_dataset='etth2_ettm1_ettm2_weather', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.51256e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.92367e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.51256e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.369162067769816, 'MAE': 0.429498747822141}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm1_ettm2_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_ettm2_weather_epochs_250_seed_2023/model.pkl', muti_dataset='etth2_ettm1_ettm2_weather', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.31076e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.221254990618738, 'MAE': 0.3192618554447428}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm1_ettm2_exchange', random_seed=2023, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm1_ettm2_exchange_epochs_250_seed_2023
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=4.042095831922583
Epoch #1: loss=2.3350608703252433
Epoch #2: loss=2.0318867483654537
Epoch #3: loss=1.871361442514368
Epoch #4: loss=1.6926198811144442
Epoch #5: loss=1.507151941995363
Epoch #6: loss=1.4009396868783075
Epoch #7: loss=1.405512017172736
Epoch #8: loss=1.2695825099945068
Epoch #9: loss=1.1683371582546749
Epoch #10: loss=1.1568665536674294
Epoch #11: loss=1.1269575325218406
Epoch #12: loss=1.0479904815957353
Epoch #13: loss=0.9987002772253912
Epoch #14: loss=0.9665075862729872
Epoch #15: loss=0.9122655327255661
Epoch #16: loss=0.9399745303231317
Epoch #17: loss=0.8287131721908981
Epoch #18: loss=0.8452656172417305
Epoch #19: loss=0.8244400507694966
Epoch #20: loss=0.809134794248117
Epoch #21: loss=0.8392279953569979
Epoch #22: loss=0.7948703121494602
Epoch #23: loss=0.7818698061479105
Epoch #24: loss=0.750436166653762
Epoch #25: loss=0.7036530214387018
Epoch #26: loss=0.6942096022335259
Epoch #27: loss=0.6504076654846603
Epoch #28: loss=0.6313792120765995
Epoch #29: loss=0.6500220773993312
Epoch #30: loss=0.6090939351030298
Epoch #31: loss=0.6525513288137075
Epoch #32: loss=0.5622993264649365
Epoch #33: loss=0.5527205813575435
Epoch #34: loss=0.612437745203843
Epoch #35: loss=0.5995775122900266
Epoch #36: loss=0.6345054724731961
Epoch #37: loss=0.622866228625581
Epoch #38: loss=0.5525609955594346
Epoch #39: loss=0.5624193492773417
Epoch #40: loss=0.5869647908855129
Epoch #41: loss=0.5297010710110536
Epoch #42: loss=0.552970430335483
Epoch #43: loss=0.55214485042804
Epoch #44: loss=0.5647652986887339
Epoch #45: loss=0.4857350007907764
Epoch #46: loss=0.4483252997333939
Epoch #47: loss=0.4742104233922185
Epoch #48: loss=0.5123102487744512
Epoch #49: loss=0.4251776281240824
Epoch #50: loss=0.3998136270690609
Epoch #51: loss=0.4111437934475976
Epoch #52: loss=0.41490799148340485
Epoch #53: loss=0.39960286101779424
Epoch #54: loss=0.4600709696879258
Epoch #55: loss=0.38892885035759694
Epoch #56: loss=0.3968692043343106
Epoch #57: loss=0.3756276042880239
Epoch #58: loss=0.35985722050473495
Epoch #59: loss=0.3814026036778012
Epoch #60: loss=0.3409068987176225
Epoch #61: loss=0.3195753218354406
Epoch #62: loss=0.3421602901574728
Epoch #63: loss=0.2725748435871021
Epoch #64: loss=0.2617988799874847
Epoch #65: loss=0.31313584422742996
Epoch #66: loss=0.31919149410080266
Epoch #67: loss=0.30867117965543595
Epoch #68: loss=0.32495072222239263
Epoch #69: loss=0.32056611393754547
Epoch #70: loss=0.2895802980339205
Epoch #71: loss=0.2724166975633518
Epoch #72: loss=0.338372584533047
Epoch #73: loss=0.2759909319716531
Epoch #74: loss=0.3258037768505715
Epoch #75: loss=0.28182189146409165
Epoch #76: loss=0.40709909071793426
Epoch #77: loss=0.3246971751387055
Epoch #78: loss=0.2993717175480482
Epoch #79: loss=0.24467157713464788
Epoch #80: loss=0.2504994708138543
Epoch #81: loss=0.22515299896130692
Epoch #82: loss=0.2458467465397474
Epoch #83: loss=0.22825171516553774
Epoch #84: loss=0.2901748579901618
Epoch #85: loss=0.2766474702873746
Epoch #86: loss=0.28813027560308174
Epoch #87: loss=0.29710235003684016
Epoch #88: loss=0.3014833963400609
Epoch #89: loss=0.225750520624019
Epoch #90: loss=0.26297286998581243
Epoch #91: loss=0.19085923562178742
Epoch #92: loss=0.21531064677480105
Epoch #93: loss=0.22355468138246923
Epoch #94: loss=0.2694099148785746
Epoch #95: loss=0.27879452443606145
Epoch #96: loss=0.293633600344529
Epoch #97: loss=0.21590170989165436
Epoch #98: loss=0.24314074661280657
Epoch #99: loss=0.22991916074140653
Epoch #100: loss=0.15988940373063087
Epoch #101: loss=0.18244294399345243
Epoch #102: loss=0.24502718589595845
Epoch #103: loss=0.19577950954034523
Epoch #104: loss=0.1991962890165883
Epoch #105: loss=0.19882129958352526
Epoch #106: loss=0.18927991118382764
Epoch #107: loss=0.19493069590346232
Epoch #108: loss=0.22062152543583433
Epoch #109: loss=0.15715842190626506
Epoch #110: loss=0.23679206761959437
Epoch #111: loss=0.2676236719094418
Epoch #112: loss=0.23486120243732994
Epoch #113: loss=0.1866217010931389
Epoch #114: loss=0.1967634911069999
Epoch #115: loss=0.26224347405337
Epoch #116: loss=0.21101829510282827
Epoch #117: loss=0.15716369258793625
Epoch #118: loss=0.23520633910556096
Epoch #119: loss=0.17862474193444122
Epoch #120: loss=0.1761626170293705
Epoch #121: loss=0.13378701026777964
Epoch #122: loss=0.13675135207941402
Epoch #123: loss=0.13488230602564039
Epoch #124: loss=0.17389215518896645
Epoch #125: loss=0.12988069814604683
Epoch #126: loss=0.1924398674352749
Epoch #127: loss=0.30955106019973755
Epoch #128: loss=0.1693421687830139
Epoch #129: loss=0.17266897091994415
Epoch #130: loss=0.1302459943234115
Epoch #131: loss=0.1614005616488489
Epoch #132: loss=0.13432751022077896
Epoch #133: loss=0.16814022415594473
Epoch #134: loss=0.1312486938628796
Epoch #135: loss=0.14409672826327183
Epoch #136: loss=0.18619980079096718
Epoch #137: loss=0.15149006041119228
Epoch #138: loss=0.1341747149220995
Epoch #139: loss=0.16339610119325085
Epoch #140: loss=0.19462005300699053
Epoch #141: loss=0.21616474186649193
Epoch #142: loss=0.1998855560212522
Epoch #143: loss=0.28409761774378856
Epoch #144: loss=0.12454961300701708
Epoch #145: loss=0.2272043193413599
Epoch #146: loss=0.14102741874553062
Epoch #147: loss=0.18205822400144628
Epoch #148: loss=0.15919873440587842
Epoch #149: loss=0.1661685924171596
Epoch #150: loss=0.183580322442828
Epoch #151: loss=0.16954209288028446
Epoch #152: loss=0.2144982418599161
Epoch #153: loss=0.15701393702545682
Epoch #154: loss=0.15257079949652827
Epoch #155: loss=0.17400605689633536
Epoch #156: loss=0.11588201752385578
Epoch #157: loss=0.12500118912273162
Epoch #158: loss=0.13206335715949535
Epoch #159: loss=0.12295361990864212
Epoch #160: loss=0.11545622932749826
Epoch #161: loss=0.10960141926802494
Epoch #162: loss=0.09783271020530043
Epoch #163: loss=0.08335277976820597
Epoch #164: loss=0.10191810100867942
Epoch #165: loss=0.17281017543093577
Epoch #166: loss=0.11130380509672938
Epoch #167: loss=0.09931289087477568
Epoch #168: loss=0.1756565257202129
Epoch #169: loss=0.1211637386901153
Epoch #170: loss=0.10915799685628028
Epoch #171: loss=0.13963250793214585
Epoch #172: loss=0.1513792883000664
Epoch #173: loss=0.12725914682488185
Epoch #174: loss=0.16777713234360153
Epoch #175: loss=0.17840752755669323
Epoch #176: loss=0.1785176900794377
Epoch #177: loss=0.11671340636707642
Epoch #178: loss=0.12595512627347097
Epoch #179: loss=0.1371911864828419
Epoch #180: loss=0.09344620297889451
Epoch #181: loss=0.09004368416562274
Epoch #182: loss=0.11263789717309378
Epoch #183: loss=0.2093780536103893
Epoch #184: loss=0.12907136558882287
Epoch #185: loss=0.13486174204562967
Epoch #186: loss=0.09124741038760624
Epoch #187: loss=0.09586660961645681
Epoch #188: loss=0.11706939858157893
Epoch #189: loss=0.1310623951910718
Epoch #190: loss=0.13519719509860953
Epoch #191: loss=0.11700031272060163
Epoch #192: loss=0.10777907476231859
Epoch #193: loss=0.12681166435012947
Epoch #194: loss=0.09733304653216053
Epoch #195: loss=0.13080201247656667
Epoch #196: loss=0.11427013133023237
Epoch #197: loss=0.07231425425994235
Epoch #198: loss=0.07234534268846383
Epoch #199: loss=0.09361721401581087
Epoch #200: loss=0.062448370597652486
Epoch #201: loss=0.10333916310825057
Epoch #202: loss=0.10832803726599023
Epoch #203: loss=0.10037685885421328
Epoch #204: loss=0.0917961827252765
Epoch #205: loss=0.13196429041390484
Epoch #206: loss=0.10305265593971755
Epoch #207: loss=0.1701393121148686
Epoch #208: loss=0.18765038397867936
Epoch #209: loss=0.17027101685871948
Epoch #210: loss=0.15315124130732305
Epoch #211: loss=0.12472599573634766
Epoch #212: loss=0.12647066280447147
Epoch #213: loss=0.11434992815594415
Epoch #214: loss=0.10485788283718599
Epoch #215: loss=0.09826307300780271
Epoch #216: loss=0.07783589036380117
Epoch #217: loss=0.07718332549808798
Epoch #218: loss=0.1358355819876935
Epoch #219: loss=0.0944479155933132
Epoch #220: loss=0.13577545731252916
Epoch #221: loss=0.12133488602734901
Epoch #222: loss=0.10443194235700208
Epoch #223: loss=0.07651253915517717
Epoch #224: loss=0.09637006331939955
Epoch #225: loss=0.10672190543767568
Epoch #226: loss=0.08379146990341109
Epoch #227: loss=0.07782249497501431
Epoch #228: loss=0.09989548152362979
Epoch #229: loss=0.08965436049510499
Epoch #230: loss=0.12399088669366934
Epoch #231: loss=0.08241012350127504
Epoch #232: loss=0.11712869941382795
Epoch #233: loss=0.16447829563372038
Epoch #234: loss=0.15370395537969228
Epoch #235: loss=0.12719291763229146
Epoch #236: loss=0.10108484448613347
Epoch #237: loss=0.11264237313455827
Epoch #238: loss=0.09473416194118359
Epoch #239: loss=0.1142502428611388
Epoch #240: loss=0.07581020801051243
Epoch #241: loss=0.06645291517614513
Epoch #242: loss=0.09926226568987241
Epoch #243: loss=0.1328824246302247
Epoch #244: loss=0.08993236891723969
Epoch #245: loss=0.08197872073867836
Epoch #246: loss=0.09632248036261346
Epoch #247: loss=0.09401924080039198
Epoch #248: loss=0.1948156546096544
Epoch #249: loss=0.2855770126287196

Training time: 0:11:20.466765

Finished.
n2one setting etth2_ettm1_ettm2_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_ettm2_exchange_epochs_250_seed_2023/model.pkl', muti_dataset='etth2_ettm1_ettm2_exchange', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.47386e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.89243e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.47386e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.3724026274227961, 'MAE': 0.43273596217078303}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm1_ettm2_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_ettm2_exchange_epochs_250_seed_2023/model.pkl', muti_dataset='etth2_ettm1_ettm2_exchange', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.48961e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.87076e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.48961e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 1.544471861133419, 'MAE': 1.045450435479527}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm1_electricity_traffic', random_seed=2023, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm1_electricity_traffic_epochs_250_seed_2023
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.8410545524138395
Epoch #1: loss=0.3026785393564231
Epoch #2: loss=0.21254805859789364
Epoch #3: loss=0.1470090603637358
Epoch #4: loss=0.11560914765339311
Epoch #5: loss=0.08807774561904774
Epoch #6: loss=0.07060713985381178
Epoch #7: loss=0.07019595494013059
Epoch #8: loss=0.05711499980916824
Epoch #9: loss=0.04938825311955006
Epoch #10: loss=0.0508551101460448
Epoch #11: loss=0.04512207051890311
Epoch #12: loss=0.03959821453814292
Epoch #13: loss=0.03797820408595532
Epoch #14: loss=0.038993700377493445
Epoch #15: loss=0.03419233797343726
Epoch #16: loss=0.04240006108793099
Epoch #17: loss=0.039435534133148584
Epoch #18: loss=0.03261317372427545
Epoch #19: loss=0.030553648580694655
Epoch #20: loss=0.03487132101691561
Epoch #21: loss=0.0270540455429327
Epoch #22: loss=0.034490165337695305
Epoch #23: loss=0.02851759216259253
Epoch #24: loss=0.022315920515724154
Epoch #25: loss=0.029217224584316227
Epoch #26: loss=0.02340523092170982
Epoch #27: loss=0.026567768722638444
Epoch #28: loss=0.027305426999428725
Epoch #29: loss=0.021786494944384206
Epoch #30: loss=0.025776190194417625
Epoch #31: loss=0.020957321660555542
Epoch #32: loss=0.021750903164938426
Epoch #33: loss=0.019687165208069762
Epoch #34: loss=0.021209204882210033
Epoch #35: loss=0.021222830720096175
Epoch #36: loss=0.01978794513116137
Epoch #37: loss=0.026976335581379837
Epoch #38: loss=0.019701963084640152
Epoch #39: loss=0.019860093650500368
Epoch #40: loss=0.018203236387157
Epoch #41: loss=0.01749710891893844
Epoch #42: loss=0.016373809315914638
Epoch #43: loss=0.023466512037896327
Epoch #44: loss=0.016193697476688987
Epoch #45: loss=0.0166901764074361
Epoch #46: loss=0.024193804098250924
Epoch #47: loss=0.017295535311756576
Epoch #48: loss=0.018123021683047722
Epoch #49: loss=0.014725435915475572
Epoch #50: loss=0.017946632789311422
Epoch #51: loss=0.01294287676640614
Epoch #52: loss=0.018156512699060476
Epoch #53: loss=0.01954685019985759
Epoch #54: loss=0.020656498463048546
Epoch #55: loss=0.01616385596188609
Epoch #56: loss=0.014445013258269648
Epoch #57: loss=0.014608878866136602
Epoch #58: loss=0.02311968728903833
Epoch #59: loss=0.020382288045594568
Epoch #60: loss=0.01446402710214952
Epoch #61: loss=0.01707794943949065
Epoch #62: loss=0.014586223981368024
Epoch #63: loss=0.01637799275335666
Epoch #64: loss=0.013813771615360768
Epoch #65: loss=0.01571163664089942
Epoch #66: loss=0.017202568378325258
Epoch #67: loss=0.01896313914908391
Epoch #68: loss=0.013054979724311685
Epoch #69: loss=0.015070976615183754
Epoch #70: loss=0.01654715341035832
Epoch #71: loss=0.015421129291393205
Epoch #72: loss=0.014569138462737058
Epoch #73: loss=0.010353572166257877
Epoch #74: loss=0.018637728556835726
Epoch #75: loss=0.017177837001530843
Epoch #76: loss=0.010974905827900993
Epoch #77: loss=0.016974984736629235
Epoch #78: loss=0.01356605713692479
Epoch #79: loss=0.01729601309354127
Epoch #80: loss=0.015247138653333988
Epoch #81: loss=0.013209870475441098
Epoch #82: loss=0.01625326668390373
Epoch #83: loss=0.012057086520282192
Epoch #84: loss=0.013105671875145664
Epoch #85: loss=0.012818993139228525
Epoch #86: loss=0.012467793650785286
Epoch #87: loss=0.011012094533578846
Epoch #88: loss=0.012118766574425776
Epoch #89: loss=0.017946848111711038
Epoch #90: loss=0.011009941905787133
Epoch #91: loss=0.012817713909234417
Epoch #92: loss=0.011538345428595345
Epoch #93: loss=0.010666156794060081
Epoch #94: loss=0.014977485391465081
Epoch #95: loss=0.011620296259516529
Epoch #96: loss=0.012546245407145998
Epoch #97: loss=0.009918615976992633
Epoch #98: loss=0.012575517941409176
Epoch #99: loss=0.015033104404108986
Epoch #100: loss=0.010996781062150799
Epoch #101: loss=0.009552713175570602
Epoch #102: loss=0.013439900856026
Epoch #103: loss=0.01160130537079221
Epoch #104: loss=0.012805512667317885
Epoch #105: loss=0.010971869673669787
Epoch #106: loss=0.014098836844147129
Epoch #107: loss=0.01058057422033183
Epoch #108: loss=0.011876354107141357
Epoch #109: loss=0.009919281842469459
Epoch #110: loss=0.015015655001885196
Epoch #111: loss=0.010638236830410831
Epoch #112: loss=0.01343480947957706
Epoch #113: loss=0.012222513018095894
Epoch #114: loss=0.011572764500088427
Epoch #115: loss=0.015697618278402013
Epoch #116: loss=0.010679875059144611
Epoch #117: loss=0.01016249475712609
Epoch #118: loss=0.013877888479540287
Epoch #119: loss=0.010259802901887789
Epoch #120: loss=0.011065686553763356
Epoch #121: loss=0.010169977435098107
Epoch #122: loss=0.011130274250527698
Epoch #123: loss=0.009170011035748273
Epoch #124: loss=0.011417368607115556
Epoch #125: loss=0.010428451120579689
Epoch #126: loss=0.013976697441337624
Epoch #127: loss=0.00957840779490495
Epoch #128: loss=0.013303174256206278
Epoch #129: loss=0.01115132555721836
Epoch #130: loss=0.008791403768994252
Epoch #131: loss=0.011628074082123071
Epoch #132: loss=0.011001200832195463
Epoch #133: loss=0.014530801524605515
Epoch #134: loss=0.010389960320662264
Epoch #135: loss=0.01141187231675836
Epoch #136: loss=0.011290652606438351
Epoch #137: loss=0.008390496445750526
Epoch #138: loss=0.009016012444493985
Epoch #139: loss=0.017699322041792354
Epoch #140: loss=0.01269901613414973
Epoch #141: loss=0.010624684481541328
Epoch #142: loss=0.007805044133980257
Epoch #143: loss=0.01109137711770248
Epoch #144: loss=0.010152149024401263
Epoch #145: loss=0.00651539144357554
Epoch #146: loss=0.013516746711960646
Epoch #147: loss=0.016217277746353988
Epoch #148: loss=0.009287027097360942
Epoch #149: loss=0.010489125159506273
Epoch #150: loss=0.009747744035533853
Epoch #151: loss=0.009228258359487897
Epoch #152: loss=0.00938496151253483
Epoch #153: loss=0.010260370293893914
Epoch #154: loss=0.01192432508971136
Epoch #155: loss=0.007881530779267997
Epoch #156: loss=0.008222339321870765
Epoch #157: loss=0.01203711699423664
Epoch #158: loss=0.009652747899481657
Epoch #159: loss=0.008873638826021386
Epoch #160: loss=0.012400941918974477
Epoch #161: loss=0.007531379983501317
Epoch #162: loss=0.010374739924943978
Epoch #163: loss=0.01017930715430728
Epoch #164: loss=0.010274833591266345
Epoch #165: loss=0.007964747118702606
Epoch #166: loss=0.00799679987847762
Epoch #167: loss=0.012665161060651188
Epoch #168: loss=0.011294759096951242
Epoch #169: loss=0.011184612031534898
Epoch #170: loss=0.008634258222851375
Epoch #171: loss=0.007289760954471642
Epoch #172: loss=0.00879876847144528
Epoch #173: loss=0.00998728773913844
Epoch #174: loss=0.00812825750596451
Epoch #175: loss=0.010822965014770222
Epoch #176: loss=0.012718786107991542
Epoch #177: loss=0.01088029549534533
Epoch #178: loss=0.010011449297513002
Epoch #179: loss=0.009495726597827272
Epoch #180: loss=0.008778315627919872
Epoch #181: loss=0.010323284206971341
Epoch #182: loss=0.008349632523314358
Epoch #183: loss=0.009778777381576466
Epoch #184: loss=0.00926307824026013
Epoch #185: loss=0.008563570641787671
Epoch #186: loss=0.008698363306952605
Epoch #187: loss=0.008483941407864437
Epoch #188: loss=0.008515992136508324
Epoch #189: loss=0.012402072800283624
Epoch #190: loss=0.009760705914082008
Epoch #191: loss=0.011437882239691685
Epoch #192: loss=0.009353856280491417
Epoch #193: loss=0.01317290542638761
Epoch #194: loss=0.015569077446133202
Epoch #195: loss=0.00999743082412729
Epoch #196: loss=0.008545914249529132
Epoch #197: loss=0.01185662281666352
Epoch #198: loss=0.00827060670800755
Epoch #199: loss=0.011595107458273194
Epoch #200: loss=0.010089066061233911
Epoch #201: loss=0.012602904483386712
Epoch #202: loss=0.00969850907488162
Epoch #203: loss=0.00831108177065726
Epoch #204: loss=0.00983158282876849
Epoch #205: loss=0.00811327440058541
Epoch #206: loss=0.008845603935759097
Epoch #207: loss=0.010099051319094504
Epoch #208: loss=0.008556713313634428
Epoch #209: loss=0.0070458265195660445
Epoch #210: loss=0.007765879962955802
Epoch #211: loss=0.00954301136267739
Epoch #212: loss=0.011530442208524186
Epoch #213: loss=0.008067984553032165
Epoch #214: loss=0.009085851522052248
Epoch #215: loss=0.006602005511441598
Epoch #216: loss=0.009774787459568238
Epoch #217: loss=0.009326639880906186
Epoch #218: loss=0.00899809187620903
Epoch #219: loss=0.00984197116353354
Epoch #220: loss=0.006775646180215182
Epoch #221: loss=0.008703226827450065
Epoch #222: loss=0.005756718938238288
Epoch #223: loss=0.006552987317633168
Epoch #224: loss=0.009588717559640612
Epoch #225: loss=0.01691826491182508
Epoch #226: loss=0.006658569395643126
Epoch #227: loss=0.007705188752603971
Epoch #228: loss=0.010778162113909352
Epoch #229: loss=0.006424616696984278
Epoch #230: loss=0.007854608933680375
Epoch #231: loss=0.011137816106355202
Epoch #232: loss=0.010542547152147742
Epoch #233: loss=0.007402652154232813
Epoch #234: loss=0.007957707491746369
Epoch #235: loss=0.0089901094598962
Epoch #236: loss=0.00753744104080924
Epoch #237: loss=0.007602071972074792
Epoch #238: loss=0.00689423325797691
Epoch #239: loss=0.01004009785338
Epoch #240: loss=0.008015409442332967
Epoch #241: loss=0.009694619239340898
Epoch #242: loss=0.010257862842088338
Epoch #243: loss=0.007054440235125812
Epoch #244: loss=0.007049017487420455
Epoch #245: loss=0.00862378296298386
Epoch #246: loss=0.009360283295092335
Epoch #247: loss=0.004899543215739189
Epoch #248: loss=0.01131785927852262
Epoch #249: loss=0.008656777929045302

Training time: 4:57:35.604962

Finished.
n2one setting etth2_ettm1_electricity_traffic -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_electricity_traffic_epochs_250_seed_2023/model.pkl', muti_dataset='etth2_ettm1_electricity_traffic', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.59554e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.8646e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.6405e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.59554e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.42347233568529913, 'MAE': 0.48195399485552565}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm1_electricity_traffic -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_electricity_traffic_epochs_250_seed_2023/model.pkl', muti_dataset='etth2_ettm1_electricity_traffic', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.90202e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.16259320424296236, 'MAE': 0.2825375119013217}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm1_electricity_weather', random_seed=2023, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm1_electricity_weather_epochs_250_seed_2023
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.7613204074232545
Epoch #1: loss=0.796301753716926
Epoch #2: loss=0.583145893191638
Epoch #3: loss=0.47907809137481533
Epoch #4: loss=0.3939642415471273
Epoch #5: loss=0.34667273951719885
Epoch #6: loss=0.3172951306790522
Epoch #7: loss=0.2958587434806236
Epoch #8: loss=0.25098238701689735
Epoch #9: loss=0.24716475216084963
Epoch #10: loss=0.2144737501871096
Epoch #11: loss=0.20549037625936611
Epoch #12: loss=0.1934147592787057
Epoch #13: loss=0.18673192170793063
Epoch #14: loss=0.15062226094815828
Epoch #15: loss=0.1608180890242531
Epoch #16: loss=0.15707483807553166
Epoch #17: loss=0.11674425712186996
Epoch #18: loss=0.10678102333251745
Epoch #19: loss=0.13067571711152384
Epoch #20: loss=0.10135941176279767
Epoch #21: loss=0.09780319513217227
Epoch #22: loss=0.09113258192290181
Epoch #23: loss=0.10916618300117042
Epoch #24: loss=0.09258703276872227
Epoch #25: loss=0.06771351892552147
Epoch #26: loss=0.07289766545777451
Epoch #27: loss=0.06420889420001066
Epoch #28: loss=0.08184713714513672
Epoch #29: loss=0.056649584614046636
Epoch #30: loss=0.06601075296711227
Epoch #31: loss=0.05196977253008175
Epoch #32: loss=0.08672356047118976
Epoch #33: loss=0.04617260085571914
Epoch #34: loss=0.05905074202391791
Epoch #35: loss=0.05156095427754399
Epoch #36: loss=0.10326730124588597
Epoch #37: loss=0.060287055831198415
Epoch #38: loss=0.04647118008874153
Epoch #39: loss=0.04747988431561381
Epoch #40: loss=0.043758195143333345
Epoch #41: loss=0.03921960369645529
Epoch #42: loss=0.04419241017559926
Epoch #43: loss=0.04667546420919467
Epoch #44: loss=0.05561490626240226
Epoch #45: loss=0.03821266228524483
Epoch #46: loss=0.05900320371115351
Epoch #47: loss=0.03731906757983443
Epoch #48: loss=0.028141282066345624
Epoch #49: loss=0.03734135260862898
Epoch #50: loss=0.03847388403860163
Epoch #51: loss=0.02816491350850524
Epoch #52: loss=0.03902545454242101
Epoch #53: loss=0.06395489108391514
Epoch #54: loss=0.03860032448978865
Epoch #55: loss=0.02942088204691161
Epoch #56: loss=0.028322398998736315
Epoch #57: loss=0.041237920256688786
Epoch #58: loss=0.055551884212365295
Epoch #59: loss=0.0454668868601016
Epoch #60: loss=0.02708143565312589
Epoch #61: loss=0.03318112500279836
Epoch #62: loss=0.040754950852197123
Epoch #63: loss=0.04400279874505143
Epoch #64: loss=0.02721292922298794
Epoch #65: loss=0.03770598224523694
Epoch #66: loss=0.02520934533972089
Epoch #67: loss=0.029444470769113364
Epoch #68: loss=0.0276568820531008
Epoch #69: loss=0.04529985275680888
Epoch #70: loss=0.028319345915702822
Epoch #71: loss=0.029563515421883395
Epoch #72: loss=0.01994397010867905
Epoch #73: loss=0.031933630557016354
Epoch #74: loss=0.022533393176974194
Epoch #75: loss=0.026745278454602582
Epoch #76: loss=0.03350273796727192
Epoch #77: loss=0.02947860041167587
Epoch #78: loss=0.024237367143050755
Epoch #79: loss=0.02317660941474446
Epoch #80: loss=0.03671601733945514
Epoch #81: loss=0.02214740942461952
Epoch #82: loss=0.023078637553238603
Epoch #83: loss=0.023523561180926453
Epoch #84: loss=0.01892371462045671
Epoch #85: loss=0.01757886843462411
Epoch #86: loss=0.0369905418155026
Epoch #87: loss=0.04489474792562884
Epoch #88: loss=0.02375777143672466
Epoch #89: loss=0.024220781894049876
Epoch #90: loss=0.023760884924479187
Epoch #91: loss=0.021007411833693056
Epoch #92: loss=0.018823444878216834
Epoch #93: loss=0.01941007332691336
Epoch #94: loss=0.028869824147821493
Epoch #95: loss=0.022138980722488606
Epoch #96: loss=0.01871371865384153
Epoch #97: loss=0.02134395729134829
Epoch #98: loss=0.018565661900466282
Epoch #99: loss=0.022878463552907517
Epoch #100: loss=0.025821113497758768
Epoch #101: loss=0.03713943438735242
Epoch #102: loss=0.03550199931742598
Epoch #103: loss=0.022275950535749125
Epoch #104: loss=0.01616093099933781
Epoch #105: loss=0.021330148062815454
Epoch #106: loss=0.03781029375346556
Epoch #107: loss=0.022448342933147278
Epoch #108: loss=0.014413160035444092
Epoch #109: loss=0.021160730697399592
Epoch #110: loss=0.03197424816596003
Epoch #111: loss=0.016391900076837062
Epoch #112: loss=0.044515696783192865
Epoch #113: loss=0.022940694257036515
Epoch #114: loss=0.022096567543555205
Epoch #115: loss=0.028882799386078722
Epoch #116: loss=0.018427192686087362
Epoch #117: loss=0.015294136155288258
Epoch #118: loss=0.020148501806407655
Epoch #119: loss=0.02867849113113464
Epoch #120: loss=0.021743070036778864
Epoch #121: loss=0.02122291099114267
Epoch #122: loss=0.01465041902871509
Epoch #123: loss=0.016785773065113398
Epoch #124: loss=0.021419623352057774
Epoch #125: loss=0.01575539900254688
Epoch #126: loss=0.02139187422461412
Epoch #127: loss=0.02682706281695872
Epoch #128: loss=0.017327528121906702
Epoch #129: loss=0.022302834236235296
Epoch #130: loss=0.014514794429502615
Epoch #131: loss=0.013329056245179159
Epoch #132: loss=0.025688804130943824
Epoch #133: loss=0.01705277423344055
Epoch #134: loss=0.018956189972511174
Epoch #135: loss=0.01277024032873395
Epoch #136: loss=0.015297965756585591
Epoch #137: loss=0.022221529415540703
Epoch #138: loss=0.02634457700745496
Epoch #139: loss=0.016419609907013046
Epoch #140: loss=0.01717175198065066
Epoch #141: loss=0.020406553460833653
Epoch #142: loss=0.013492966661618843
Epoch #143: loss=0.02029367337921915
Epoch #144: loss=0.01376898914311649
Epoch #145: loss=0.015970998872964555
Epoch #146: loss=0.01590838818172988
Epoch #147: loss=0.028807109964482026
Epoch #148: loss=0.020970366831888024
Epoch #149: loss=0.014870322701738102
Epoch #150: loss=0.01133774893481144
Epoch #151: loss=0.024256212049887885
Epoch #152: loss=0.022171727009596024
Epoch #153: loss=0.011999466771192926
Epoch #154: loss=0.01306051388032071
Epoch #155: loss=0.0209242296657104
Epoch #156: loss=0.0274902920804803
Epoch #157: loss=0.025106137657493404
Epoch #158: loss=0.019712823137085986
Epoch #159: loss=0.017464510255257203
Epoch #160: loss=0.013690367471171569
Epoch #161: loss=0.014695011999391095
Epoch #162: loss=0.012391236942733497
Epoch #163: loss=0.01722508925683031
Epoch #164: loss=0.013575170151825536
Epoch #165: loss=0.013771048751388588
Epoch #166: loss=0.014649942693019873
Epoch #167: loss=0.020289905352696574
Epoch #168: loss=0.015358214180721991
Epoch #169: loss=0.011690871758077115
Epoch #170: loss=0.011111754671373876
Epoch #171: loss=0.01601558846815438
Epoch #172: loss=0.0263715970396919
Epoch #173: loss=0.01640739831802346
Epoch #174: loss=0.015422001313450045
Epoch #175: loss=0.016194151188023642
Epoch #176: loss=0.019463357137044102
Epoch #177: loss=0.019257496908300697
Epoch #178: loss=0.01370808287836254
Epoch #179: loss=0.011307845207741356
Epoch #180: loss=0.014492512087430166
Epoch #181: loss=0.01732310954081086
Epoch #182: loss=0.018837226371835814
Epoch #183: loss=0.010086904076400073
Epoch #184: loss=0.014877438217988365
Epoch #185: loss=0.022038237917418782
Epoch #186: loss=0.020281648479102257
Epoch #187: loss=0.012316310603716985
Epoch #188: loss=0.013152639060568268
Epoch #189: loss=0.011072310246606931
Epoch #190: loss=0.0152664206965112
Epoch #191: loss=0.012174059724920009
Epoch #192: loss=0.018077576490141425
Epoch #193: loss=0.018974856821475677
Epoch #194: loss=0.018422639318295332
Epoch #195: loss=0.009649939860308173
Epoch #196: loss=0.015003304501472373
Epoch #197: loss=0.013499908265099567
Epoch #198: loss=0.014519258214667924
Epoch #199: loss=0.012966953711791525
Epoch #200: loss=0.014541483672705722
Epoch #201: loss=0.012800914271782895
Epoch #202: loss=0.013944346066771637
Epoch #203: loss=0.0104416675736477
Epoch #204: loss=0.013982182253496594
Epoch #205: loss=0.013464103646461584
Epoch #206: loss=0.011851139993435537
Epoch #207: loss=0.013495806328894902
Epoch #208: loss=0.02397303534863032
Epoch #209: loss=0.019546129171934285
Epoch #210: loss=0.013503554738477535
Epoch #211: loss=0.009121922982142192
Epoch #212: loss=0.015514302654080221
Epoch #213: loss=0.014990473900162551
Epoch #214: loss=0.016525264652302387
Epoch #215: loss=0.00986809601009766
Epoch #216: loss=0.026390683276527754
Epoch #217: loss=0.009746842925143365
Epoch #218: loss=0.01068000011480962
Epoch #219: loss=0.012536222776732955
Epoch #220: loss=0.013404551188522082
Epoch #221: loss=0.014624664524158667
Epoch #222: loss=0.039581837012808874
Epoch #223: loss=0.0200222974253997
Epoch #224: loss=0.012317333202123361
Epoch #225: loss=0.009766875847708434
Epoch #226: loss=0.021594284828720386
Epoch #227: loss=0.008874674010878327
Epoch #228: loss=0.01473595554061706
Epoch #229: loss=0.008370336121480835
Epoch #230: loss=0.01156359306458473
Epoch #231: loss=0.015885540361241884
Epoch #232: loss=0.020903226688953933
Epoch #233: loss=0.01500468596661374
Epoch #234: loss=0.015034665317874249
Epoch #235: loss=0.011689789188397436
Epoch #236: loss=0.01555609307172134
Epoch #237: loss=0.011453736301316969
Epoch #238: loss=0.00934749354575665
Epoch #239: loss=0.013561909044582448
Epoch #240: loss=0.012323331588413566
Epoch #241: loss=0.012112352709933376
Epoch #242: loss=0.011341329738625313
Epoch #243: loss=0.013164152830204454
Epoch #244: loss=0.019236490479670465
Epoch #245: loss=0.013398392787059668
Epoch #246: loss=0.013969189011769318
Epoch #247: loss=0.01848065472217532
Epoch #248: loss=0.011327718390464425
Epoch #249: loss=0.015724970603661535

Training time: 1:43:44.883455

Finished.
n2one setting etth2_ettm1_electricity_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_electricity_weather_epochs_250_seed_2023/model.pkl', muti_dataset='etth2_ettm1_electricity_weather', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.09176e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.09176e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.266653172000852, 'MAE': 0.34547367638351495}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm1_electricity_exchange', random_seed=2023, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm1_electricity_exchange_epochs_250_seed_2023
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.703736136385618
Epoch #1: loss=0.7198596712663469
Epoch #2: loss=0.5142315842146832
Epoch #3: loss=0.432911190545181
Epoch #4: loss=0.3591864448287645
Epoch #5: loss=0.30788689175411327
Epoch #6: loss=0.28884354802734225
Epoch #7: loss=0.2476361758942563
Epoch #8: loss=0.22032538359120532
Epoch #9: loss=0.20873125666156625
Epoch #10: loss=0.1790562884758632
Epoch #11: loss=0.17221273306853832
Epoch #12: loss=0.17362592736479185
Epoch #13: loss=0.14156188248450027
Epoch #14: loss=0.12303670492527807
Epoch #15: loss=0.13306879465835925
Epoch #16: loss=0.11794012153161534
Epoch #17: loss=0.10831607330687108
Epoch #18: loss=0.11673094444406307
Epoch #19: loss=0.09962611924588509
Epoch #20: loss=0.10283602388999734
Epoch #21: loss=0.0821352833962492
Epoch #22: loss=0.08826121074611842
Epoch #23: loss=0.08564803681419544
Epoch #24: loss=0.08714398389322528
Epoch #25: loss=0.07775966848464151
Epoch #26: loss=0.07422317891792322
Epoch #27: loss=0.0844750300006839
Epoch #28: loss=0.061383463212849855
Epoch #29: loss=0.06586905614062284
Epoch #30: loss=0.06319651235383465
Epoch #31: loss=0.05138168916822833
Epoch #32: loss=0.056658081647266316
Epoch #33: loss=0.04998369738647462
Epoch #34: loss=0.05028451465523831
Epoch #35: loss=0.06965918245561614
Epoch #36: loss=0.0558460192742787
Epoch #37: loss=0.0470104166279716
Epoch #38: loss=0.0524391261833889
Epoch #39: loss=0.057290349917899636
Epoch #40: loss=0.052450269680760095
Epoch #41: loss=0.058788968849342094
Epoch #42: loss=0.04693612883871244
Epoch #43: loss=0.046132622304122885
Epoch #44: loss=0.039358508679210626
Epoch #45: loss=0.043519842211607984
Epoch #46: loss=0.04519127757370375
Epoch #47: loss=0.04390528598620479
Epoch #48: loss=0.045156678563971556
Epoch #49: loss=0.03621784647824699
Epoch #50: loss=0.03754350813461323
Epoch #51: loss=0.042793694037812566
Epoch #52: loss=0.04088981174837036
Epoch #53: loss=0.04141572357815629
Epoch #54: loss=0.032708805409375506
Epoch #55: loss=0.040757391692718935
Epoch #56: loss=0.03956383543346689
Epoch #57: loss=0.03521908398600891
Epoch #58: loss=0.029630124535725617
Epoch #59: loss=0.030790911112128293
Epoch #60: loss=0.041235835766835774
Epoch #61: loss=0.041049280375314696
Epoch #62: loss=0.02978375994181663
Epoch #63: loss=0.03908200858104491
Epoch #64: loss=0.032408662485254
Epoch #65: loss=0.04059492759939997
Epoch #66: loss=0.02952038726174898
Epoch #67: loss=0.030550777534712695
Epoch #68: loss=0.02501294697448343
Epoch #69: loss=0.026715440851413464
Epoch #70: loss=0.028657480246677285
Epoch #71: loss=0.03720910038956057
Epoch #72: loss=0.029976208819081786
Epoch #73: loss=0.031529014400389015
Epoch #74: loss=0.03236100045589714
Epoch #75: loss=0.03224255773708525
Epoch #76: loss=0.029143445382648892
Epoch #77: loss=0.02948467650934544
Epoch #78: loss=0.03352139269200392
Epoch #79: loss=0.02418049498929532
Epoch #80: loss=0.03157652964981901
Epoch #81: loss=0.029063925418804162
Epoch #82: loss=0.02408309821079697
Epoch #83: loss=0.04437540938691249
Epoch #84: loss=0.024418487159034736
Epoch #85: loss=0.019137483716188185
Epoch #86: loss=0.021728177850808335
Epoch #87: loss=0.024668267446299023
Epoch #88: loss=0.021457053064060014
Epoch #89: loss=0.0292258969892584
Epoch #90: loss=0.034504963315202065
Epoch #91: loss=0.026283426749418016
Epoch #92: loss=0.02829992761385898
Epoch #93: loss=0.023502873816736772
Epoch #94: loss=0.024915923985454017
Epoch #95: loss=0.025478719000607965
Epoch #96: loss=0.027049986772394875
Epoch #97: loss=0.017339956483861396
Epoch #98: loss=0.018858687337877104
Epoch #99: loss=0.024534168981467923
Epoch #100: loss=0.030154909555778788
Epoch #101: loss=0.03445158010920354
Epoch #102: loss=0.022587455013499833
Epoch #103: loss=0.026099370997157537
Epoch #104: loss=0.03250276954725159
Epoch #105: loss=0.025884625656256502
Epoch #106: loss=0.029656212425640427
Epoch #107: loss=0.02615094925756687
Epoch #108: loss=0.027511732030447884
Epoch #109: loss=0.03249382361151031
Epoch #110: loss=0.01890274056623306
Epoch #111: loss=0.017206510119791
Epoch #112: loss=0.04527653403437941
Epoch #113: loss=0.01900409676033268
Epoch #114: loss=0.03386983754628631
Epoch #115: loss=0.024386419545622914
Epoch #116: loss=0.023626331203370234
Epoch #117: loss=0.020628992140008625
Epoch #118: loss=0.02208375992063535
Epoch #119: loss=0.017894491514725133
Epoch #120: loss=0.018563330752717367
Epoch #121: loss=0.029680288185416494
Epoch #122: loss=0.024779394680972316
Epoch #123: loss=0.025761062250826885
Epoch #124: loss=0.018201840697399874
Epoch #125: loss=0.02123854852429798
Epoch #126: loss=0.02260420782262089
Epoch #127: loss=0.01855575718168137
Epoch #128: loss=0.021765436023683086
Epoch #129: loss=0.02892720903372607
Epoch #130: loss=0.018622322840701994
Epoch #131: loss=0.018182136256969735
Epoch #132: loss=0.02930584962406633
Epoch #133: loss=0.014151046887276324
Epoch #134: loss=0.013538081777820187
Epoch #135: loss=0.019222383880558334
Epoch #136: loss=0.01729699792370592
Epoch #137: loss=0.021077368974582338
Epoch #138: loss=0.04245545692817021
Epoch #139: loss=0.029384882280586947
Epoch #140: loss=0.018086815477678986
Epoch #141: loss=0.02283786150297386
Epoch #142: loss=0.02766753857541341
Epoch #143: loss=0.02872527519144354
Epoch #144: loss=0.015499322386143155
Epoch #145: loss=0.018510344494952785
Epoch #146: loss=0.019898291323629212
Epoch #147: loss=0.021772395027331706
Epoch #148: loss=0.03183574486565467
Epoch #149: loss=0.018854896923103062
Epoch #150: loss=0.014652245211675333
Epoch #151: loss=0.020339947395491
Epoch #152: loss=0.026934777525211992
Epoch #153: loss=0.01902062669550726
Epoch #154: loss=0.019670662525350158
Epoch #155: loss=0.018682558569414354
Epoch #156: loss=0.017365468620330695
Epoch #157: loss=0.037821540893498345
Epoch #158: loss=0.014512822967826494
Epoch #159: loss=0.024937411010673306
Epoch #160: loss=0.021802332635059072
Epoch #161: loss=0.033254847955763854
Epoch #162: loss=0.026518611547064776
Epoch #163: loss=0.01712312652448981
Epoch #164: loss=0.013072054584994401
Epoch #165: loss=0.014852215808944412
Epoch #166: loss=0.014866335471482781
Epoch #167: loss=0.01723382854649679
Epoch #168: loss=0.021590702060740225
Epoch #169: loss=0.02847672427698476
Epoch #170: loss=0.022486751008562754
Epoch #171: loss=0.017047085080487703
Epoch #172: loss=0.01461337585913377
Epoch #173: loss=0.015131213188121734
Epoch #174: loss=0.01877781149199211
Epoch #175: loss=0.022895275290232817
Epoch #176: loss=0.02473919688668961
Epoch #177: loss=0.020008636140821486
Epoch #178: loss=0.02259124674574641
Epoch #179: loss=0.015465749117682663
Epoch #180: loss=0.019054963183824124
Epoch #181: loss=0.017603716286139492
Epoch #182: loss=0.01468709525679069
Epoch #183: loss=0.01389387721998982
Epoch #184: loss=0.02219976487501406
Epoch #185: loss=0.022360241532081507
Epoch #186: loss=0.01475741577778221
Epoch #187: loss=0.020252941237690104
Epoch #188: loss=0.021145088417470315
Epoch #189: loss=0.020719063251718118
Epoch #190: loss=0.01830231506791454
Epoch #191: loss=0.013623165089324363
Epoch #192: loss=0.01091242963478361
Epoch #193: loss=0.016870468971235623
Epoch #194: loss=0.024955208164033203
Epoch #195: loss=0.014069455417704444
Epoch #196: loss=0.018796686367574617
Epoch #197: loss=0.018598744524434822
Epoch #198: loss=0.01765316254515516
Epoch #199: loss=0.018673942512591028
Epoch #200: loss=0.019356883692243795
Epoch #201: loss=0.012187715808599946
Epoch #202: loss=0.015630795547496447
Epoch #203: loss=0.013111871166066843
Epoch #204: loss=0.020833952184155936
Epoch #205: loss=0.031865127175316345
Epoch #206: loss=0.019091573658248984
Epoch #207: loss=0.013699366213295538
Epoch #208: loss=0.01341311453897989
Epoch #209: loss=0.020936006096376896
Epoch #210: loss=0.015931636875398694
Epoch #211: loss=0.009139616158036032
Epoch #212: loss=0.015870900819801408
Epoch #213: loss=0.020234585483524928
Epoch #214: loss=0.023659694490965017
Epoch #215: loss=0.015841531416640138
Epoch #216: loss=0.012855146104494721
Epoch #217: loss=0.012108131578884568
Epoch #218: loss=0.021354220844288584
Epoch #219: loss=0.011118714741272824
Epoch #220: loss=0.014767018164090694
Epoch #221: loss=0.0167048326893931
Epoch #222: loss=0.020384837076992537
Epoch #223: loss=0.020662276776137117
Epoch #224: loss=0.014003229285395767
Epoch #225: loss=0.019666349985341537
Epoch #226: loss=0.015439692257567354
Epoch #227: loss=0.013948710045679298
Epoch #228: loss=0.020869517949998903
Epoch #229: loss=0.01515974618133187
Epoch #230: loss=0.016123815906896346
Epoch #231: loss=0.0216802647390996
Epoch #232: loss=0.01785669993112328
Epoch #233: loss=0.024804363942098527
Epoch #234: loss=0.01626579302161132
Epoch #235: loss=0.01564554286710059
Epoch #236: loss=0.018279833281318783
Epoch #237: loss=0.011336690913657698
Epoch #238: loss=0.030440926139836094
Epoch #239: loss=0.01879135574118881
Epoch #240: loss=0.012186642422512581
Epoch #241: loss=0.013696721468458989
Epoch #242: loss=0.015518527875704052
Epoch #243: loss=0.014598008409787979
Epoch #244: loss=0.01966219877734276
Epoch #245: loss=0.02653422665776234
Epoch #246: loss=0.014664696884792437
Epoch #247: loss=0.019480246979819062
Epoch #248: loss=0.018569333663496113
Epoch #249: loss=0.013885112512710449

Training time: 1:36:17.601551

Finished.
n2one setting etth2_ettm1_electricity_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_electricity_exchange_epochs_250_seed_2023/model.pkl', muti_dataset='etth2_ettm1_electricity_exchange', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.13287e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.267e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.87929e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.13287e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 1.1494878531456998, 'MAE': 0.8796293820678196}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm1_traffic_weather', random_seed=2023, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm1_traffic_weather_epochs_250_seed_2023
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.0569485575289652
Epoch #1: loss=0.4046466842655578
Epoch #2: loss=0.30209773782204846
Epoch #3: loss=0.2329934790615346
Epoch #4: loss=0.18257996916080152
Epoch #5: loss=0.14652771076339627
Epoch #6: loss=0.14572335895002875
Epoch #7: loss=0.11086728144642664
Epoch #8: loss=0.10390871724886841
Epoch #9: loss=0.08769956726691877
Epoch #10: loss=0.08606448585771961
Epoch #11: loss=0.07544346107426973
Epoch #12: loss=0.06910277063296347
Epoch #13: loss=0.0658589378975858
Epoch #14: loss=0.06665421991915366
Epoch #15: loss=0.054341409700793146
Epoch #16: loss=0.05379310615050296
Epoch #17: loss=0.047287772255168434
Epoch #18: loss=0.04449161176624241
Epoch #19: loss=0.049000011889364724
Epoch #20: loss=0.03989413855818386
Epoch #21: loss=0.0407966094206665
Epoch #22: loss=0.043620685509289873
Epoch #23: loss=0.04277747723072969
Epoch #24: loss=0.040783922567554476
Epoch #25: loss=0.039881763737838895
Epoch #26: loss=0.03616366314936365
Epoch #27: loss=0.02738725621495848
Epoch #28: loss=0.03238677560474115
Epoch #29: loss=0.03410733435094813
Epoch #30: loss=0.03085637578348039
Epoch #31: loss=0.033877184114698526
Epoch #32: loss=0.02729037233234371
Epoch #33: loss=0.03661305162331981
Epoch #34: loss=0.02752226039036907
Epoch #35: loss=0.02629541468967953
Epoch #36: loss=0.02074138951687904
Epoch #37: loss=0.03558765006920828
Epoch #38: loss=0.02320074930694057
Epoch #39: loss=0.022733750635661416
Epoch #40: loss=0.027171118847823292
Epoch #41: loss=0.03262480128193881
Epoch #42: loss=0.02694305127666992
Epoch #43: loss=0.028101233842322156
Epoch #44: loss=0.023500193755728836
Epoch #45: loss=0.01857378971135906
Epoch #46: loss=0.02028928101303058
Epoch #47: loss=0.023497542636929013
Epoch #48: loss=0.022535192463716602
Epoch #49: loss=0.032617463296352296
Epoch #50: loss=0.022477660864675376
Epoch #51: loss=0.018561764843052636
Epoch #52: loss=0.019064975294919795
Epoch #53: loss=0.02463855806025769
Epoch #54: loss=0.0258640701829923
Epoch #55: loss=0.029919177253237693
Epoch #56: loss=0.027539400007536175
Epoch #57: loss=0.019869437728766672
Epoch #58: loss=0.01688623213862988
Epoch #59: loss=0.018126491337917463
Epoch #60: loss=0.02786780227620461
Epoch #61: loss=0.020944701886037365
Epoch #62: loss=0.021201148336030085
Epoch #63: loss=0.014641374143618663
Epoch #64: loss=0.017528879712065126
Epoch #65: loss=0.017256827553604148
Epoch #66: loss=0.02218877004650185
Epoch #67: loss=0.01777132055010884
Epoch #68: loss=0.016112656080383484
Epoch #69: loss=0.020159904085725204
Epoch #70: loss=0.016571523982938482
Epoch #71: loss=0.017153518768902466
Epoch #72: loss=0.017795596867353887
Epoch #73: loss=0.01903271718749547
Epoch #74: loss=0.016249015879772077
Epoch #75: loss=0.044430170050875135
Epoch #76: loss=0.014583702969127622
Epoch #77: loss=0.015653134945244992
Epoch #78: loss=0.030630459047685105
Epoch #79: loss=0.017571525329860928
Epoch #80: loss=0.014501786220147507
Epoch #81: loss=0.016261597241874565
Epoch #82: loss=0.01790820674786486
Epoch #83: loss=0.020608153977057217
Epoch #84: loss=0.018721849450206274
Epoch #85: loss=0.015173150432674126
Epoch #86: loss=0.017165161493474877
Epoch #87: loss=0.021627854001394803
Epoch #88: loss=0.01650336743919662
Epoch #89: loss=0.02372347208184666
Epoch #90: loss=0.014204068672617289
Epoch #91: loss=0.023980655276836422
Epoch #92: loss=0.01813715785740778
Epoch #93: loss=0.016086492740403177
Epoch #94: loss=0.01515279848386637
Epoch #95: loss=0.017305121860206312
Epoch #96: loss=0.01962495033332932
Epoch #97: loss=0.01712395971216658
Epoch #98: loss=0.020794502878645135
Epoch #99: loss=0.014421642796725196
Epoch #100: loss=0.01871371262945943
Epoch #101: loss=0.016353098148366725
Epoch #102: loss=0.025528949702452307
Epoch #103: loss=0.025681915136542947
Epoch #104: loss=0.011122007342010467
Epoch #105: loss=0.022257686013388747
Epoch #106: loss=0.014699932222195821
Epoch #107: loss=0.017920597841812578
Epoch #108: loss=0.017451869472741792
Epoch #109: loss=0.011502134688090632
Epoch #110: loss=0.013101783843879859
Epoch #111: loss=0.009483452084220877
Epoch #112: loss=0.016036458299684166
Epoch #113: loss=0.012762119494305068
Epoch #114: loss=0.02061405616623394
Epoch #115: loss=0.020926305157310796
Epoch #116: loss=0.017569791386796985
Epoch #117: loss=0.014015819066060604
Epoch #118: loss=0.016954992874663618
Epoch #119: loss=0.012710352061182994
Epoch #120: loss=0.01957387620852435
Epoch #121: loss=0.015491438199649436
Epoch #122: loss=0.014427869755309075
Epoch #123: loss=0.01971820874702983
Epoch #124: loss=0.015070101996191425
Epoch #125: loss=0.012416268114288899
Epoch #126: loss=0.012939801429973754
Epoch #127: loss=0.018142682330668226
Epoch #128: loss=0.024324815890316955
Epoch #129: loss=0.0176935870945081
Epoch #130: loss=0.01942585286714916
Epoch #131: loss=0.01255692367959268
Epoch #132: loss=0.010901875193016866
Epoch #133: loss=0.01332961796983618
Epoch #134: loss=0.014765292419156391
Epoch #135: loss=0.015347609458568046
Epoch #136: loss=0.017061011319957926
Epoch #137: loss=0.01493647335226073
Epoch #138: loss=0.012657300033201833
Epoch #139: loss=0.013331118103053917
Epoch #140: loss=0.013888526503470182
Epoch #141: loss=0.013141817644527069
Epoch #142: loss=0.017595879302915726
Epoch #143: loss=0.020562480862546535
Epoch #144: loss=0.010316796595293403
Epoch #145: loss=0.013571429379724087
Epoch #146: loss=0.012005465546327079
Epoch #147: loss=0.01481938531264307
Epoch #148: loss=0.016570334672365954
Epoch #149: loss=0.009262740695197598
Epoch #150: loss=0.011759702237661507
Epoch #151: loss=0.013399078024710251
Epoch #152: loss=0.014072920861131015
Epoch #153: loss=0.00965538105545974
Epoch #154: loss=0.017536429116633726
Epoch #155: loss=0.009143488460342979
Epoch #156: loss=0.018666457231049878
Epoch #157: loss=0.011545083039028006
Epoch #158: loss=0.01192835181246056
Epoch #159: loss=0.014118054123868021
Epoch #160: loss=0.012945039700116668
Epoch #161: loss=0.013652922197459132
Epoch #162: loss=0.022264362956414197
Epoch #163: loss=0.01273597637519074
Epoch #164: loss=0.012242635063824853
Epoch #165: loss=0.013903576579215015
Epoch #166: loss=0.009116785966731591
Epoch #167: loss=0.01838121834266561
Epoch #168: loss=0.016662969036353135
Epoch #169: loss=0.023039764448217575
Epoch #170: loss=0.011111924264953414
Epoch #171: loss=0.014198911302124466
Epoch #172: loss=0.01622610323713932
Epoch #173: loss=0.011348298961153986
Epoch #174: loss=0.013147239614289385
Epoch #175: loss=0.009537999572600629
Epoch #176: loss=0.011298282592058558
Epoch #177: loss=0.013546517091241671
Epoch #178: loss=0.009854196212332203
Epoch #179: loss=0.014950036389198644
Epoch #180: loss=0.016205152509801878
Epoch #181: loss=0.013653726742142106
Epoch #182: loss=0.011417297957807875
Epoch #183: loss=0.015051770491542106
Epoch #184: loss=0.014271285771804108
Epoch #185: loss=0.008129926709801054
Epoch #186: loss=0.015219758032050413
Epoch #187: loss=0.02128768191400712
Epoch #188: loss=0.018170965918948914
Epoch #189: loss=0.01237959916867618
Epoch #190: loss=0.010310143179165237
Epoch #191: loss=0.012667518642765833
Epoch #192: loss=0.00970298995322829
Epoch #193: loss=0.009801851130591394
Epoch #194: loss=0.014812563502089178
Epoch #195: loss=0.007850884663021213
Epoch #196: loss=0.01394303670076825
Epoch #197: loss=0.01386804699103161
Epoch #198: loss=0.010167663123833954
Epoch #199: loss=0.01461640326878021
Epoch #200: loss=0.00914729265300503
Epoch #201: loss=0.018060760991402094
Epoch #202: loss=0.010487792761766385
Epoch #203: loss=0.014263319471829404
Epoch #204: loss=0.016054080502192668
Epoch #205: loss=0.009695149214411973
Epoch #206: loss=0.013674148285757493
Epoch #207: loss=0.009386552795458766
Epoch #208: loss=0.009985568545073596
Epoch #209: loss=0.01611717960124714
Epoch #210: loss=0.020549913574587457
Epoch #211: loss=0.009216215744226935
Epoch #212: loss=0.016268424465708798
Epoch #213: loss=0.014506478924500842
Epoch #214: loss=0.01109869020036833
Epoch #215: loss=0.012190533243752548
Epoch #216: loss=0.008606289458148801
Epoch #217: loss=0.008764906634004694
Epoch #218: loss=0.013392655097311013
Epoch #219: loss=0.010537455175287824
Epoch #220: loss=0.010520002132031869
Epoch #221: loss=0.009947011935248766
Epoch #222: loss=0.013618833279689706
Epoch #223: loss=0.011642244699490503
Epoch #224: loss=0.013744669764214781
Epoch #225: loss=0.010100166712548105
Epoch #226: loss=0.012369166514444987
Epoch #227: loss=0.008194259536659722
Epoch #228: loss=0.007111370648626147
Epoch #229: loss=0.016558524392014287
Epoch #230: loss=0.012817783544105262
Epoch #231: loss=0.01016802847888604
Epoch #232: loss=0.016195622823320877
Epoch #233: loss=0.01446958848595322
Epoch #234: loss=0.013108671435989091
Epoch #235: loss=0.011114911035611835
Epoch #236: loss=0.010130731597969747
Epoch #237: loss=0.02022110073219777
Epoch #238: loss=0.011927346463828392
Epoch #239: loss=0.00835300249637171
Epoch #240: loss=0.008158253646879991
Epoch #241: loss=0.012690836439099601
Epoch #242: loss=0.011902646072569691
Epoch #243: loss=0.009745598943694854
Epoch #244: loss=0.013029016004611248
Epoch #245: loss=0.008803764947900928
Epoch #246: loss=0.0073744102955307905
Epoch #247: loss=0.013102457443555194
Epoch #248: loss=0.0115286930443874
Epoch #249: loss=0.010091258482134435

Training time: 3:39:28.466665

Finished.
n2one setting etth2_ettm1_traffic_weather -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_traffic_weather_epochs_250_seed_2023/model.pkl', muti_dataset='etth2_ettm1_traffic_weather', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.19881e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.60038e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.18482e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.19881e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.409931805422614, 'MAE': 0.4573930389696367}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm1_traffic_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_traffic_weather_epochs_250_seed_2023/model.pkl', muti_dataset='etth2_ettm1_traffic_weather', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
Evaluation result: {'MSE': 0.3860562815099306, 'MAE': 0.4056646006966794}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm1_traffic_exchange', random_seed=2023, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm1_traffic_exchange_epochs_250_seed_2023
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.0143429987837334
Epoch #1: loss=0.39003060687635394
Epoch #2: loss=0.27860573830234037
Epoch #3: loss=0.21501915718151912
Epoch #4: loss=0.1737294249270145
Epoch #5: loss=0.13210079539147718
Epoch #6: loss=0.11897920009885654
Epoch #7: loss=0.10226710527078123
Epoch #8: loss=0.09517068124107748
Epoch #9: loss=0.08371873212944683
Epoch #10: loss=0.07681498236572454
Epoch #11: loss=0.0685108454660974
Epoch #12: loss=0.06469602682806032
Epoch #13: loss=0.05873599557493402
Epoch #14: loss=0.062237055225482396
Epoch #15: loss=0.05595882928763466
Epoch #16: loss=0.05392185904831324
Epoch #17: loss=0.04987632652229697
Epoch #18: loss=0.04790816155588989
Epoch #19: loss=0.05375045820439302
Epoch #20: loss=0.05041593498380452
Epoch #21: loss=0.04591914904088847
Epoch #22: loss=0.03742629313172336
Epoch #23: loss=0.04457251513064818
Epoch #24: loss=0.038433730566736754
Epoch #25: loss=0.03855298584060186
Epoch #26: loss=0.03651383460742141
Epoch #27: loss=0.04513815138987182
Epoch #28: loss=0.04187899524149871
Epoch #29: loss=0.031112045805055968
Epoch #30: loss=0.03740847389319144
Epoch #31: loss=0.02975958239115137
Epoch #32: loss=0.03613833421767849
Epoch #33: loss=0.02783453698203949
Epoch #34: loss=0.02995909754368309
Epoch #35: loss=0.028897892132082634
Epoch #36: loss=0.025141922417550394
Epoch #37: loss=0.03139531965653815
Epoch #38: loss=0.033497079025543934
Epoch #39: loss=0.03480837301459679
Epoch #40: loss=0.027775882488378294
Epoch #41: loss=0.028816759900904685
Epoch #42: loss=0.026024740549178818
Epoch #43: loss=0.03256112881301617
Epoch #44: loss=0.02251741049756445
Epoch #45: loss=0.03159103597037658
Epoch #46: loss=0.02423848591006554
Epoch #47: loss=0.025522128093373113
Epoch #48: loss=0.025635452071747004
Epoch #49: loss=0.027263023017833288
Epoch #50: loss=0.024213846709064277
Epoch #51: loss=0.025218823153343627
Epoch #52: loss=0.023190153969833545
Epoch #53: loss=0.022666076751914073
Epoch #54: loss=0.025693886366679106
Epoch #55: loss=0.024133198107773677
Epoch #56: loss=0.02205928057708923
Epoch #57: loss=0.021839910794435192
Epoch #58: loss=0.01939412462148162
Epoch #59: loss=0.023277443081079163
Epoch #60: loss=0.02075888152218
Epoch #61: loss=0.02057974647251031
Epoch #62: loss=0.023912898960596986
Epoch #63: loss=0.02605834380842311
Epoch #64: loss=0.018889988929364696
Epoch #65: loss=0.015718119949949823
Epoch #66: loss=0.027664773170178156
Epoch #67: loss=0.022979587464523082
Epoch #68: loss=0.018780308117817873
Epoch #69: loss=0.020244788996179677
Epoch #70: loss=0.021070843856537354
Epoch #71: loss=0.02201284551093678
Epoch #72: loss=0.018759391896113614
Epoch #73: loss=0.022918504778112744
Epoch #74: loss=0.02618917814690068
Epoch #75: loss=0.01977426883581552
Epoch #76: loss=0.018895276272192237
Epoch #77: loss=0.020956710976066575
Epoch #78: loss=0.02530371076896732
Epoch #79: loss=0.020642969644049537
Epoch #80: loss=0.021488740580009092
Epoch #81: loss=0.017528409728231612
Epoch #82: loss=0.023072459836839698
Epoch #83: loss=0.01899937124992878
Epoch #84: loss=0.017885462354402366
Epoch #85: loss=0.020000167250809435
Epoch #86: loss=0.0179537717179358
Epoch #87: loss=0.016379905470383673
Epoch #88: loss=0.015526048658664074
Epoch #89: loss=0.02124785120106829
Epoch #90: loss=0.023310888706505096
Epoch #91: loss=0.014950540198221896
Epoch #92: loss=0.019284919151982036
Epoch #93: loss=0.016512672674834576
Epoch #94: loss=0.015706039465668082
Epoch #95: loss=0.02063584277133126
Epoch #96: loss=0.01861838460618028
Epoch #97: loss=0.01773179873089248
Epoch #98: loss=0.022326432793560596
Epoch #99: loss=0.016096735984942538
Epoch #100: loss=0.017270032028029965
Epoch #101: loss=0.014956504970885706
Epoch #102: loss=0.01582141234951098
Epoch #103: loss=0.02155477456206525
Epoch #104: loss=0.013577227951155929
Epoch #105: loss=0.02735268532456872
Epoch #106: loss=0.021033022559906286
Epoch #107: loss=0.01630770875180223
Epoch #108: loss=0.010234713566410597
Epoch #109: loss=0.016440108614784416
Epoch #110: loss=0.017516653318871086
Epoch #111: loss=0.01532883285950562
Epoch #112: loss=0.016639885706214816
Epoch #113: loss=0.017315945606504363
Epoch #114: loss=0.015973434608338163
Epoch #115: loss=0.017376106446357193
Epoch #116: loss=0.02176821355107251
Epoch #117: loss=0.017864055501647543
Epoch #118: loss=0.013710815438677961
Epoch #119: loss=0.019645423673880957
Epoch #120: loss=0.013418238307814783
Epoch #121: loss=0.01477431142913767
Epoch #122: loss=0.018175475816737948
Epoch #123: loss=0.022000276528054093
Epoch #124: loss=0.01762175061715728
Epoch #125: loss=0.015596600291502484
Epoch #126: loss=0.019174073432254402
Epoch #127: loss=0.018969042681747268
Epoch #128: loss=0.014324601569053295
Epoch #129: loss=0.014196463255552566
Epoch #130: loss=0.01967077810253171
Epoch #131: loss=0.016065294640488777
Epoch #132: loss=0.013847052039276244
Epoch #133: loss=0.02000565293921788
Epoch #134: loss=0.011217587167331724
Epoch #135: loss=0.013833635944195578
Epoch #136: loss=0.017602586938517413
Epoch #137: loss=0.014634996306241347
Epoch #138: loss=0.023824236868119793
Epoch #139: loss=0.012566844368946575
Epoch #140: loss=0.014614060704860111
Epoch #141: loss=0.01591297347807962
Epoch #142: loss=0.013580287924711016
Epoch #143: loss=0.011419425559988422
Epoch #144: loss=0.014016355291017602
Epoch #145: loss=0.013127808135683514
Epoch #146: loss=0.03417422930267692
Epoch #147: loss=0.011680334823353946
Epoch #148: loss=0.012389963934462381
Epoch #149: loss=0.012026206770364346
Epoch #150: loss=0.018463682437704684
Epoch #151: loss=0.014199396050874688
Epoch #152: loss=0.01508395280695556
Epoch #153: loss=0.01607200288888815
Epoch #154: loss=0.01033613799670609
Epoch #155: loss=0.011805298611688084
Epoch #156: loss=0.01443250550357891
Epoch #157: loss=0.017421191542690305
Epoch #158: loss=0.013665730393686236
Epoch #159: loss=0.014054759200007538
Epoch #160: loss=0.01679407184686473
Epoch #161: loss=0.013430087666911113
Epoch #162: loss=0.014796998175321228
Epoch #163: loss=0.013506149233247524
Epoch #164: loss=0.014867332612452997
Epoch #165: loss=0.013836996654284015
Epoch #166: loss=0.013799503809587058
Epoch #167: loss=0.013616662518862533
Epoch #168: loss=0.014371440685421033
Epoch #169: loss=0.011791669406250605
Epoch #170: loss=0.01071840783346865
Epoch #171: loss=0.013688679075556563
Epoch #172: loss=0.016624758526099334
Epoch #173: loss=0.01405389750731489
Epoch #174: loss=0.016132333296001423
Epoch #175: loss=0.019902477050588157
Epoch #176: loss=0.014793674694472528
Epoch #177: loss=0.014369040363620827
Epoch #178: loss=0.012540529021255983
Epoch #179: loss=0.014197502822941903
Epoch #180: loss=0.01700408446895135
Epoch #181: loss=0.01589547503232376
Epoch #182: loss=0.012785153179589412
Epoch #183: loss=0.014184874295375545
Epoch #184: loss=0.017127170900461317
Epoch #185: loss=0.01710861906289833
Epoch #186: loss=0.0077808128814000595
Epoch #187: loss=0.014372643220741412
Epoch #188: loss=0.010139736440865195
Epoch #189: loss=0.011018761653021274
Epoch #190: loss=0.015182812529691309
Epoch #191: loss=0.013192235319972193
Epoch #192: loss=0.011874671368262556
Epoch #193: loss=0.01490180081710351
Epoch #194: loss=0.01482256972675722
Epoch #195: loss=0.020914462820065958
Epoch #196: loss=0.009690332689527306
Epoch #197: loss=0.02344673155738263
Epoch #198: loss=0.013196488682657579
Epoch #199: loss=0.01130250688915079
Epoch #200: loss=0.013215376237821073
Epoch #201: loss=0.011950750653770601
Epoch #202: loss=0.007088695451170065
Epoch #203: loss=0.010585895421074284
Epoch #204: loss=0.016379901125555416
Epoch #205: loss=0.011523899025059445
Epoch #206: loss=0.012659107875561359
Epoch #207: loss=0.010694169863183544
Epoch #208: loss=0.010304789907004798
Epoch #209: loss=0.014903172540243759
Epoch #210: loss=0.014847999536819721
Epoch #211: loss=0.011333879269751289
Epoch #212: loss=0.014918213603278174
Epoch #213: loss=0.011464991550694633
Epoch #214: loss=0.011605126280129125
Epoch #215: loss=0.012512175027360491
Epoch #216: loss=0.010796748962109649
Epoch #217: loss=0.012316554398231339
Epoch #218: loss=0.010449588021524629
Epoch #219: loss=0.011897587430097587
Epoch #220: loss=0.013311830743085928
Epoch #221: loss=0.013019106604907712
Epoch #222: loss=0.011432659527001617
Epoch #223: loss=0.015985143981254682
Epoch #224: loss=0.02042709374638418
Epoch #225: loss=0.02282685587001058
Epoch #226: loss=0.009776505939330778
Epoch #227: loss=0.010294608930282495
Epoch #228: loss=0.009789381961872842
Epoch #229: loss=0.01668287792628755
Epoch #230: loss=0.010658512003329134
Epoch #231: loss=0.011784620558525628
Epoch #232: loss=0.014861556534637825
Epoch #233: loss=0.009429961625042976
Epoch #234: loss=0.015155709113297472
Epoch #235: loss=0.01483512978223656
Epoch #236: loss=0.01332745128692713
Epoch #237: loss=0.00834612865805907
Epoch #238: loss=0.010287018005246782
Epoch #239: loss=0.01300742543174295
Epoch #240: loss=0.01305705051109308
Epoch #241: loss=0.011914238277264254
Epoch #242: loss=0.010225437147350172
Epoch #243: loss=0.01694675222444841
Epoch #244: loss=0.009665531330688487
Epoch #245: loss=0.012362653263505661
Epoch #246: loss=0.008378887828855711
Epoch #247: loss=0.011576532516554064
Epoch #248: loss=0.012228961523260706
Epoch #249: loss=0.012860346420361034

Training time: 3:30:01.714688

Finished.
n2one setting etth2_ettm1_traffic_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_traffic_exchange_epochs_250_seed_2023/model.pkl', muti_dataset='etth2_ettm1_traffic_exchange', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.00234e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.77942e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.44403e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.00234e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4091226682244569, 'MAE': 0.45607089245127264}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm1_traffic_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_traffic_exchange_epochs_250_seed_2023/model.pkl', muti_dataset='etth2_ettm1_traffic_exchange', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.26512e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.95245e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.92861e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=9.26512e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.6275763744965377, 'MAE': 0.6261311254354662}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm1_weather_exchange', random_seed=2023, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm1_weather_exchange_epochs_250_seed_2023
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=4.160465041032205
Epoch #1: loss=2.7260547692959127
Epoch #2: loss=2.205618156836583
Epoch #3: loss=2.0904155236024122
Epoch #4: loss=1.9228729330576384
Epoch #5: loss=1.7534519594449263
Epoch #6: loss=1.6591840294691234
Epoch #7: loss=1.5453522503376007
Epoch #8: loss=1.4414065228058741
Epoch #9: loss=1.3828359017005334
Epoch #10: loss=1.2900834003320107
Epoch #11: loss=1.2685817594711597
Epoch #12: loss=1.1442386576762567
Epoch #13: loss=1.079323491224876
Epoch #14: loss=1.0079832615760655
Epoch #15: loss=1.0377966234317193
Epoch #16: loss=1.0338253802978075
Epoch #17: loss=0.9671479990849128
Epoch #18: loss=0.9126379501361114
Epoch #19: loss=0.9232503886406238
Epoch #20: loss=1.00654687331273
Epoch #21: loss=0.8816151091685662
Epoch #22: loss=0.8772405615219703
Epoch #23: loss=0.7904521421744273
Epoch #24: loss=0.8315129772974894
Epoch #25: loss=0.7405354483769491
Epoch #26: loss=0.7581684589385986
Epoch #27: loss=0.7506591746440301
Epoch #28: loss=0.704574500138943
Epoch #29: loss=0.7096821488096163
Epoch #30: loss=0.670881812962202
Epoch #31: loss=0.6676060442741101
Epoch #32: loss=0.6992168180071391
Epoch #33: loss=0.6439396463907682
Epoch #34: loss=0.6188573390245438
Epoch #35: loss=0.5475319434817021
Epoch #36: loss=0.5282709042613323
Epoch #37: loss=0.6054299766054521
Epoch #38: loss=0.5165238644068058
Epoch #39: loss=0.531413988998303
Epoch #40: loss=0.5272923599068935
Epoch #41: loss=0.47813614916342956
Epoch #42: loss=0.5435027417082053
Epoch #43: loss=0.48313378857878536
Epoch #44: loss=0.5210880287564718
Epoch #45: loss=0.5575922676003896
Epoch #46: loss=0.496892145046821
Epoch #47: loss=0.5215365267716922
Epoch #48: loss=0.5179681290800755
Epoch #49: loss=0.4309377415248981
Epoch #50: loss=0.41591693432285237
Epoch #51: loss=0.40245504591327447
Epoch #52: loss=0.41766928652158153
Epoch #53: loss=0.35329630598425865
Epoch #54: loss=0.38956764483681094
Epoch #55: loss=0.4014189400925086
Epoch #56: loss=0.37411841134039253
Epoch #57: loss=0.40479634845486057
Epoch #58: loss=0.4375867680288278
Epoch #59: loss=0.4444765273768168
Epoch #60: loss=0.43436146728121316
Epoch #61: loss=0.3589558813434381
Epoch #62: loss=0.4542432991931072
Epoch #63: loss=0.41618559394891447
Epoch #64: loss=0.365244126950319
Epoch #65: loss=0.3590565757969251
Epoch #66: loss=0.3630278712281814
Epoch #67: loss=0.37715372314246803
Epoch #68: loss=0.39696297307427114
Epoch #69: loss=0.3537148741575388
Epoch #70: loss=0.42706244725447434
Epoch #71: loss=0.37857683862631136
Epoch #72: loss=0.38814023309029066
Epoch #73: loss=0.29037371249153066
Epoch #74: loss=0.29897230190153307
Epoch #75: loss=0.3101809901686815
Epoch #76: loss=0.3258963083991638
Epoch #77: loss=0.30719684436917305
Epoch #78: loss=0.30150934437719673
Epoch #79: loss=0.2743135750866853
Epoch #80: loss=0.2536094720260455
Epoch #81: loss=0.24548730884607023
Epoch #82: loss=0.218902962640501
Epoch #83: loss=0.22427790282437435
Epoch #84: loss=0.2800637718576651
Epoch #85: loss=0.23717191786720201
Epoch #86: loss=0.20159919574283636
Epoch #87: loss=0.26651883196945375
Epoch #88: loss=0.31082515375545394
Epoch #89: loss=0.2623342854472307
Epoch #90: loss=0.26913892255666166
Epoch #91: loss=0.2535390095928541
Epoch #92: loss=0.264935202180193
Epoch #93: loss=0.21924354422550935
Epoch #94: loss=0.2132520007972534
Epoch #95: loss=0.24209178582980082
Epoch #96: loss=0.2652525178228433
Epoch #97: loss=0.20696119663233942
Epoch #98: loss=0.18540190597279713
Epoch #99: loss=0.2077295846090867
Epoch #100: loss=0.22477950184391096
Epoch #101: loss=0.19579525098491174
Epoch #102: loss=0.16915583374122015
Epoch #103: loss=0.24115328727146754
Epoch #104: loss=0.2637628668632645
Epoch #105: loss=0.26033350130399835
Epoch #106: loss=0.275875273375557
Epoch #107: loss=0.19468672537746337
Epoch #108: loss=0.22351507075990623
Epoch #109: loss=0.20922292511050516
Epoch #110: loss=0.15872231849397606
Epoch #111: loss=0.14326453782044923
Epoch #112: loss=0.15849537825068602
Epoch #113: loss=0.15861696771417672
Epoch #114: loss=0.19866623922895926
Epoch #115: loss=0.21516007371246815
Epoch #116: loss=0.2454255474731326
Epoch #117: loss=0.19874092764579332
Epoch #118: loss=0.15566252515866205
Epoch #119: loss=0.196431619903216
Epoch #120: loss=0.22612003065072572
Epoch #121: loss=0.2264410941503369
Epoch #122: loss=0.28416823925307166
Epoch #123: loss=0.19098198127288085
Epoch #124: loss=0.14036243183251756
Epoch #125: loss=0.20686429079908591
Epoch #126: loss=0.17596593248442963
Epoch #127: loss=0.14017855311528996
Epoch #128: loss=0.17605823593643996
Epoch #129: loss=0.15994417026209143
Epoch #130: loss=0.14307461188246423
Epoch #131: loss=0.20102954462457162
Epoch #132: loss=0.20534904351314673
Epoch #133: loss=0.16288154582994488
Epoch #134: loss=0.17526117454354578
Epoch #135: loss=0.1601373512082948
Epoch #136: loss=0.1249905155183604
Epoch #137: loss=0.13979859091341496
Epoch #138: loss=0.15831188506518418
Epoch #139: loss=0.1574336584800711
Epoch #140: loss=0.1370125005308252
Epoch #141: loss=0.13808623207016632
Epoch #142: loss=0.13511645872719014
Epoch #143: loss=0.15460064380358046
Epoch #144: loss=0.11933711196224277
Epoch #145: loss=0.15264324088079426
Epoch #146: loss=0.14054715257281294
Epoch #147: loss=0.14433137642649504
Epoch #148: loss=0.13602909846947744
Epoch #149: loss=0.11132961955781166
Epoch #150: loss=0.13798943455689228
Epoch #151: loss=0.12412330880761147
Epoch #152: loss=0.15337771585641
Epoch #153: loss=0.12373598718729156
Epoch #154: loss=0.12742122828673857
Epoch #155: loss=0.13994827777004012
Epoch #156: loss=0.1409750496968627
Epoch #157: loss=0.12218484873525225
Epoch #158: loss=0.12530083732249644
Epoch #159: loss=0.15515985511816466
Epoch #160: loss=0.12953005723941785
Epoch #161: loss=0.16346290392371324
Epoch #162: loss=0.12359688169537829
Epoch #163: loss=0.11387263539318855
Epoch #164: loss=0.1277430713391648
Epoch #165: loss=0.17852860538718793
Epoch #166: loss=0.17484790889116433
Epoch #167: loss=0.13294369182907617
Epoch #168: loss=0.10448422376066446
Epoch #169: loss=0.10921940554936345
Epoch #170: loss=0.11037267973789802
Epoch #171: loss=0.12204673854061045
Epoch #172: loss=0.0927644703680506
Epoch #173: loss=0.1446930619601447
Epoch #174: loss=0.1566747106038607
Epoch #175: loss=0.13944237865507603
Epoch #176: loss=0.13504505716264248
Epoch #177: loss=0.10906884378681962
Epoch #178: loss=0.1176951289570962
Epoch #179: loss=0.12165310266069494
Epoch #180: loss=0.08790784364996049
Epoch #181: loss=0.09280926101984313
Epoch #182: loss=0.11368311370293108
Epoch #183: loss=0.12998398998752236
Epoch #184: loss=0.10209455738703792
Epoch #185: loss=0.08818559656636073
Epoch #186: loss=0.11127603297623304
Epoch #187: loss=0.11475363167790839
Epoch #188: loss=0.11166289437992069
Epoch #189: loss=0.08709515065241319
Epoch #190: loss=0.09316176056073835
Epoch #191: loss=0.08726850323952161
Epoch #192: loss=0.09635116618413192
Epoch #193: loss=0.1258995498960408
Epoch #194: loss=0.11075473071720737
Epoch #195: loss=0.10161657018873554
Epoch #196: loss=0.1000040742711952
Epoch #197: loss=0.09377286135433958
Epoch #198: loss=0.13882705755531788
Epoch #199: loss=0.13944002169256026
Epoch #200: loss=0.1410714052259349
Epoch #201: loss=0.09769538886701831
Epoch #202: loss=0.09876945682872947
Epoch #203: loss=0.09729869502524917
Epoch #204: loss=0.10163144724300274
Epoch #205: loss=0.14612510402758533
Epoch #206: loss=0.1409092079848051
Epoch #207: loss=0.09380574248587856
Epoch #208: loss=0.128759591267086
Epoch #209: loss=0.10680564417718695
Epoch #210: loss=0.11153617377679509
Epoch #211: loss=0.09158188450293472
Epoch #212: loss=0.11358232592017604
Epoch #213: loss=0.11494255291584593
Epoch #214: loss=0.07251065417837638
Epoch #215: loss=0.07790111787975408
Epoch #216: loss=0.10547051838455865
Epoch #217: loss=0.07247069952651285
Epoch #218: loss=0.07463327021552967
Epoch #219: loss=0.1261667783300464
Epoch #220: loss=0.11681536405992049
Epoch #221: loss=0.08773001378330474
Epoch #222: loss=0.08655909289462635
Epoch #223: loss=0.0900038093006095
Epoch #224: loss=0.108822031179443
Epoch #225: loss=0.08571583838560261
Epoch #226: loss=0.12601381284184754
Epoch #227: loss=0.15333126517585838
Epoch #228: loss=0.1385765500151767
Epoch #229: loss=0.10537049367737311
Epoch #230: loss=0.13570089718828407
Epoch #231: loss=0.12883836140211385
Epoch #232: loss=0.10929747952076678
Epoch #233: loss=0.09620984581012565
Epoch #234: loss=0.08827562574655391
Epoch #235: loss=0.09511295826031038
Epoch #236: loss=0.06946464898422934
Epoch #237: loss=0.12840341644075054
Epoch #238: loss=0.09475262866068918
Epoch #239: loss=0.07122666410242136
Epoch #240: loss=0.07606221393395501
Epoch #241: loss=0.1682821860930954
Epoch #242: loss=0.11954974361623709
Epoch #243: loss=0.11201276030176534
Epoch #244: loss=0.10793111555708143
Epoch #245: loss=0.07324754224660304
Epoch #246: loss=0.07723744202835056
Epoch #247: loss=0.06476675444998993
Epoch #248: loss=0.099033360548604
Epoch #249: loss=0.07991107798611316

Training time: 0:16:18.138309

Finished.
n2one setting etth2_ettm1_weather_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm1_weather_exchange_epochs_250_seed_2023/model.pkl', muti_dataset='etth2_ettm1_weather_exchange', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.3391e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.68239e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.3391e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4011421300809924, 'MAE': 0.4395860288768119}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm2_electricity_traffic', random_seed=2023, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm2_electricity_traffic_epochs_250_seed_2023
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.8248172434640864
Epoch #1: loss=0.3025216880711191
Epoch #2: loss=0.2112268895394697
Epoch #3: loss=0.1457829837354643
Epoch #4: loss=0.11362630502009868
Epoch #5: loss=0.0904807115437387
Epoch #6: loss=0.0719343398780648
Epoch #7: loss=0.06863372429288757
Epoch #8: loss=0.05772013585784974
Epoch #9: loss=0.05070632416910052
Epoch #10: loss=0.05229454950645076
Epoch #11: loss=0.04183382120489032
Epoch #12: loss=0.04071103175491371
Epoch #13: loss=0.038616652663860725
Epoch #14: loss=0.038071765292778635
Epoch #15: loss=0.034816684844115785
Epoch #16: loss=0.03654671681714907
Epoch #17: loss=0.04230217143042567
Epoch #18: loss=0.03244803905757307
Epoch #19: loss=0.029865668253735836
Epoch #20: loss=0.03155348622203292
Epoch #21: loss=0.02523207320686512
Epoch #22: loss=0.03587266693933154
Epoch #23: loss=0.026703692293845328
Epoch #24: loss=0.021587039838850554
Epoch #25: loss=0.026687881825270782
Epoch #26: loss=0.02694480291469454
Epoch #27: loss=0.02388425655734743
Epoch #28: loss=0.02152624212148802
Epoch #29: loss=0.02323755940448006
Epoch #30: loss=0.022091587089707022
Epoch #31: loss=0.020900893058444836
Epoch #32: loss=0.018864898158570398
Epoch #33: loss=0.021662235799581698
Epoch #34: loss=0.018874411139050598
Epoch #35: loss=0.021903830567109425
Epoch #36: loss=0.02031550602551215
Epoch #37: loss=0.02566179129588561
Epoch #38: loss=0.018910266454044658
Epoch #39: loss=0.018585390668017496
Epoch #40: loss=0.021467325168335695
Epoch #41: loss=0.016222015536752964
Epoch #42: loss=0.01691640640496913
Epoch #43: loss=0.027081025914130284
Epoch #44: loss=0.016247977498863714
Epoch #45: loss=0.01718997092394904
Epoch #46: loss=0.023231707338806317
Epoch #47: loss=0.01656333047921438
Epoch #48: loss=0.018218915793064946
Epoch #49: loss=0.016070941269466944
Epoch #50: loss=0.019284495781694378
Epoch #51: loss=0.016654199502938973
Epoch #52: loss=0.017439298147324405
Epoch #53: loss=0.016778314878284344
Epoch #54: loss=0.022908710903623997
Epoch #55: loss=0.016016573334216674
Epoch #56: loss=0.017966132506446682
Epoch #57: loss=0.0127750557517413
Epoch #58: loss=0.022095370572302677
Epoch #59: loss=0.025759102047863434
Epoch #60: loss=0.014232715502913771
Epoch #61: loss=0.01627507637499453
Epoch #62: loss=0.013805288739163556
Epoch #63: loss=0.01824690580829826
Epoch #64: loss=0.014109398516837407
Epoch #65: loss=0.014626912656942923
Epoch #66: loss=0.019012835464135146
Epoch #67: loss=0.014065621970830134
Epoch #68: loss=0.012083650431502203
Epoch #69: loss=0.01648886836320782
Epoch #70: loss=0.017942015591530566
Epoch #71: loss=0.015504996899153979
Epoch #72: loss=0.01374539700596532
Epoch #73: loss=0.011293963712031762
Epoch #74: loss=0.017165999564001583
Epoch #75: loss=0.01591322708222201
Epoch #76: loss=0.017410930675644618
Epoch #77: loss=0.017491000547243608
Epoch #78: loss=0.011813008480858329
Epoch #79: loss=0.01856597417140737
Epoch #80: loss=0.014238624399462768
Epoch #81: loss=0.013393549087669059
Epoch #82: loss=0.016839075872162202
Epoch #83: loss=0.013178539255583158
Epoch #84: loss=0.011817560848505852
Epoch #85: loss=0.014488483891185748
Epoch #86: loss=0.012515701251625969
Epoch #87: loss=0.011997680980081632
Epoch #88: loss=0.01209331748189339
Epoch #89: loss=0.020835553034872504
Epoch #90: loss=0.011153675445938423
Epoch #91: loss=0.011916322680878423
Epoch #92: loss=0.012187854344288715
Epoch #93: loss=0.012116767456350836
Epoch #94: loss=0.014250547376445431
Epoch #95: loss=0.012981770146245774
Epoch #96: loss=0.012574064192404004
Epoch #97: loss=0.010928630925668249
Epoch #98: loss=0.015216267956180389
Epoch #99: loss=0.012848844508307313
Epoch #100: loss=0.012540231235196417
Epoch #101: loss=0.010984429203477017
Epoch #102: loss=0.011137162137512086
Epoch #103: loss=0.012358074357649188
Epoch #104: loss=0.014555260521146685
Epoch #105: loss=0.013013824755355962
Epoch #106: loss=0.009962397445615367
Epoch #107: loss=0.009638904016954818
Epoch #108: loss=0.0149063971576992
Epoch #109: loss=0.012143420523968811
Epoch #110: loss=0.012172955781623463
Epoch #111: loss=0.012156754669804688
Epoch #112: loss=0.013909138476584643
Epoch #113: loss=0.011099341939162536
Epoch #114: loss=0.012287084004257438
Epoch #115: loss=0.01495869629565168
Epoch #116: loss=0.011140072099957732
Epoch #117: loss=0.012184572249095438
Epoch #118: loss=0.011456006076174294
Epoch #119: loss=0.01381746329697505
Epoch #120: loss=0.012881513736265046
Epoch #121: loss=0.009837562211498976
Epoch #122: loss=0.012986507040520604
Epoch #123: loss=0.010909316004407076
Epoch #124: loss=0.009633227533881447
Epoch #125: loss=0.00871902002198038
Epoch #126: loss=0.016527501513994805
Epoch #127: loss=0.009850706875259402
Epoch #128: loss=0.014341033981811255
Epoch #129: loss=0.01127306209900591
Epoch #130: loss=0.007758002559695417
Epoch #131: loss=0.013556979341283856
Epoch #132: loss=0.009463643503870092
Epoch #133: loss=0.014056628516187572
Epoch #134: loss=0.010181554694948672
Epoch #135: loss=0.011295992275040835
Epoch #136: loss=0.008569552586097678
Epoch #137: loss=0.010595043239174127
Epoch #138: loss=0.009310508996757526
Epoch #139: loss=0.020232449680574832
Epoch #140: loss=0.012621682064043014
Epoch #141: loss=0.008455340655219197
Epoch #142: loss=0.008907137733873397
Epoch #143: loss=0.010968913981115663
Epoch #144: loss=0.010538539889521182
Epoch #145: loss=0.009154895476680028
Epoch #146: loss=0.0174110991925783
Epoch #147: loss=0.011841580707923936
Epoch #148: loss=0.01102565262973696
Epoch #149: loss=0.010525659119690842
Epoch #150: loss=0.012628967905497345
Epoch #151: loss=0.0078167972627168
Epoch #152: loss=0.011339268350946487
Epoch #153: loss=0.008590713073045549
Epoch #154: loss=0.013093255661856608
Epoch #155: loss=0.009357517368491114
Epoch #156: loss=0.00876078245981339
Epoch #157: loss=0.013275749395025384
Epoch #158: loss=0.008178347579127115
Epoch #159: loss=0.008646213760010922
Epoch #160: loss=0.011311317442379912
Epoch #161: loss=0.0077688489936107614
Epoch #162: loss=0.01044948812218941
Epoch #163: loss=0.012279320616975115
Epoch #164: loss=0.009303650224996133
Epoch #165: loss=0.012811588203409635
Epoch #166: loss=0.006524640908754132
Epoch #167: loss=0.010416642546828806
Epoch #168: loss=0.008936894317867957
Epoch #169: loss=0.010991941967194507
Epoch #170: loss=0.0070050372702798415
Epoch #171: loss=0.011392352683939773
Epoch #172: loss=0.010437063472963656
Epoch #173: loss=0.008130722432542219
Epoch #174: loss=0.00947853486820814
Epoch #175: loss=0.00904763872731519
Epoch #176: loss=0.009719264008455016
Epoch #177: loss=0.009247780259763864
Epoch #178: loss=0.008884319924997107
Epoch #179: loss=0.009311560986575776
Epoch #180: loss=0.00907985908627406
Epoch #181: loss=0.009254340337622874
Epoch #182: loss=0.008307719775538083
Epoch #183: loss=0.009475565385800118
Epoch #184: loss=0.010849356107699427
Epoch #185: loss=0.0088261649969454
Epoch #186: loss=0.00936885990472528
Epoch #187: loss=0.007993272879276484
Epoch #188: loss=0.012117137539235235
Epoch #189: loss=0.010559710699468863
Epoch #190: loss=0.009801621642080038
Epoch #191: loss=0.010557355368623204
Epoch #192: loss=0.009717927847085353
Epoch #193: loss=0.013506581072075698
Epoch #194: loss=0.020055315270108776
Epoch #195: loss=0.010934393566684738
Epoch #196: loss=0.008846669805753875
Epoch #197: loss=0.007934420942881867
Epoch #198: loss=0.009916343810657627
Epoch #199: loss=0.01091905947444159
Epoch #200: loss=0.008356417390811546
Epoch #201: loss=0.012981185938174844
Epoch #202: loss=0.008059417425359332
Epoch #203: loss=0.008880769490795252
Epoch #204: loss=0.009969120101827189
Epoch #205: loss=0.007174933285484025
Epoch #206: loss=0.010406804275040791
Epoch #207: loss=0.008532761206478154
Epoch #208: loss=0.008013067325819906
Epoch #209: loss=0.008488880165228946
Epoch #210: loss=0.008114216508978481
Epoch #211: loss=0.009369946399836515
Epoch #212: loss=0.009610424417449056
Epoch #213: loss=0.008301066136491493
Epoch #214: loss=0.009515672205043643
Epoch #215: loss=0.009210329153356907
Epoch #216: loss=0.008755134903000153
Epoch #217: loss=0.00909937813651396
Epoch #218: loss=0.01103963256604043
Epoch #219: loss=0.012042284993034905
Epoch #220: loss=0.006985634106743909
Epoch #221: loss=0.01023428812094987
Epoch #222: loss=0.006739025721674456
Epoch #223: loss=0.004555029393396504
Epoch #224: loss=0.0111003096732341
Epoch #225: loss=0.015638725595142313
Epoch #226: loss=0.008636757850445936
Epoch #227: loss=0.00855807686299896
Epoch #228: loss=0.006935523139042375
Epoch #229: loss=0.008431249548978953
Epoch #230: loss=0.00794246494897031
Epoch #231: loss=0.010698112200455964
Epoch #232: loss=0.009076140651742873
Epoch #233: loss=0.007806064224099552
Epoch #234: loss=0.00918009341000745
Epoch #235: loss=0.008519174858659613
Epoch #236: loss=0.008987721440875056
Epoch #237: loss=0.006964464455024478
Epoch #238: loss=0.006936964219260409
Epoch #239: loss=0.01207577917986065
Epoch #240: loss=0.0122401093867393
Epoch #241: loss=0.008514573990375253
Epoch #242: loss=0.0101443165416993
Epoch #243: loss=0.00558888162145418
Epoch #244: loss=0.006846570742938145
Epoch #245: loss=0.00721578294534696
Epoch #246: loss=0.0119097947249183
Epoch #247: loss=0.005304163489090661
Epoch #248: loss=0.012565306667926691
Epoch #249: loss=0.006648271394728064

Training time: 9:07:33.459743

Finished.
n2one setting etth2_ettm2_electricity_traffic -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm2_electricity_traffic_epochs_250_seed_2023/model.pkl', muti_dataset='etth2_ettm2_electricity_traffic', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.2181e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.61742e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.5875687467904832, 'MAE': 0.6295868178912312}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm2_electricity_traffic -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm2_electricity_traffic_epochs_250_seed_2023/model.pkl', muti_dataset='etth2_ettm2_electricity_traffic', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.97083e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.22805825427828277, 'MAE': 0.32820164667238216}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm2_electricity_weather', random_seed=2023, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm2_electricity_weather_epochs_250_seed_2023
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.7219786861171462
Epoch #1: loss=0.7776901824017094
Epoch #2: loss=0.5705340095578808
Epoch #3: loss=0.46544685543399966
Epoch #4: loss=0.38628539741039275
Epoch #5: loss=0.3479089965559032
Epoch #6: loss=0.31897781372886813
Epoch #7: loss=0.2897727847099304
Epoch #8: loss=0.2495077084188592
Epoch #9: loss=0.25068895059497387
Epoch #10: loss=0.2117890702739154
Epoch #11: loss=0.21067318550936162
Epoch #12: loss=0.19438269075057277
Epoch #13: loss=0.17769957104161993
Epoch #14: loss=0.1532362116118
Epoch #15: loss=0.15914232253211819
Epoch #16: loss=0.1485610619595606
Epoch #17: loss=0.11068614922872144
Epoch #18: loss=0.11258608169139248
Epoch #19: loss=0.11650125171019607
Epoch #20: loss=0.09900270147274619
Epoch #21: loss=0.09443756065599314
Epoch #22: loss=0.08599277172645886
Epoch #23: loss=0.09891120132620204
Epoch #24: loss=0.09086919795874863
Epoch #25: loss=0.06741962803093945
Epoch #26: loss=0.06439475161342384
Epoch #27: loss=0.07103416108436984
Epoch #28: loss=0.10645939003140346
Epoch #29: loss=0.0606641217377292
Epoch #30: loss=0.057931197453800536
Epoch #31: loss=0.04836163273438403
Epoch #32: loss=0.08542121760802318
Epoch #33: loss=0.04655260968162385
Epoch #34: loss=0.05926061558524427
Epoch #35: loss=0.04880678062582363
Epoch #36: loss=0.09635448238161737
Epoch #37: loss=0.05817687067726295
Epoch #38: loss=0.04652039485804941
Epoch #39: loss=0.04432470958794735
Epoch #40: loss=0.04338034805459009
Epoch #41: loss=0.04188114891326285
Epoch #42: loss=0.04399262727748551
Epoch #43: loss=0.04802089821457965
Epoch #44: loss=0.05192168996835204
Epoch #45: loss=0.04492350950620252
Epoch #46: loss=0.06525850630786321
Epoch #47: loss=0.03926232809979111
Epoch #48: loss=0.031075225191905278
Epoch #49: loss=0.032737699574918476
Epoch #50: loss=0.03934011002587894
Epoch #51: loss=0.037557913991941576
Epoch #52: loss=0.03752836772744633
Epoch #53: loss=0.061047151104598116
Epoch #54: loss=0.036816673787081075
Epoch #55: loss=0.02944841199229178
Epoch #56: loss=0.02852344486945347
Epoch #57: loss=0.037446794743738965
Epoch #58: loss=0.06076301871033462
Epoch #59: loss=0.04584067133669933
Epoch #60: loss=0.04056435084761414
Epoch #61: loss=0.03507841432256598
Epoch #62: loss=0.04080913722680958
Epoch #63: loss=0.03343184156509193
Epoch #64: loss=0.023471992962343032
Epoch #65: loss=0.029486730154476143
Epoch #66: loss=0.03128091644125748
Epoch #67: loss=0.030894838110543787
Epoch #68: loss=0.025127790853929743
Epoch #69: loss=0.02961815033380695
Epoch #70: loss=0.02562905465386655
Epoch #71: loss=0.03086229749374755
Epoch #72: loss=0.023041838609090405
Epoch #73: loss=0.026619694729444046
Epoch #74: loss=0.026499097780898623
Epoch #75: loss=0.032158477558460956
Epoch #76: loss=0.05775293381310591
Epoch #77: loss=0.040069367275063
Epoch #78: loss=0.024110883080451558
Epoch #79: loss=0.02162804465712214
Epoch #80: loss=0.03192359860141264
Epoch #81: loss=0.020671493987782463
Epoch #82: loss=0.018248388414232902
Epoch #83: loss=0.028161636216259778
Epoch #84: loss=0.024229212022348217
Epoch #85: loss=0.017696142707606905
Epoch #86: loss=0.029696351594661604
Epoch #87: loss=0.03150993350587071
Epoch #88: loss=0.026031263544836578
Epoch #89: loss=0.018611669989481366
Epoch #90: loss=0.01806305201153258
Epoch #91: loss=0.023888608144455883
Epoch #92: loss=0.020189450030559546
Epoch #93: loss=0.018841289986907313
Epoch #94: loss=0.03389075308023914
Epoch #95: loss=0.026719707532543435
Epoch #96: loss=0.022132926790222322
Epoch #97: loss=0.020223156655086078
Epoch #98: loss=0.01728554351146856
Epoch #99: loss=0.02013610751170359
Epoch #100: loss=0.030651597712150685
Epoch #101: loss=0.03203475755090787
Epoch #102: loss=0.031133563366195518
Epoch #103: loss=0.02480764932426535
Epoch #104: loss=0.020442353468388318
Epoch #105: loss=0.026512344283600376
Epoch #106: loss=0.039447575637772486
Epoch #107: loss=0.025537000584722278
Epoch #108: loss=0.031758307920424396
Epoch #109: loss=0.01975097739973348
Epoch #110: loss=0.029719769169117182
Epoch #111: loss=0.019148795013092714
Epoch #112: loss=0.042976768895639235
Epoch #113: loss=0.021789778595509596
Epoch #114: loss=0.019580212365740222
Epoch #115: loss=0.032651326390723254
Epoch #116: loss=0.02346370038783739
Epoch #117: loss=0.01320378161290635
Epoch #118: loss=0.015667410395331427
Epoch #119: loss=0.024652973737739895
Epoch #120: loss=0.01868985522098278
Epoch #121: loss=0.019173026855633123
Epoch #122: loss=0.01505748541684413
Epoch #123: loss=0.019466881847570408
Epoch #124: loss=0.020589367304737233
Epoch #125: loss=0.019678717117743848
Epoch #126: loss=0.022311537704041408
Epoch #127: loss=0.016755827734317018
Epoch #128: loss=0.018184147664658368
Epoch #129: loss=0.026015894290710453
Epoch #130: loss=0.015313631325022458
Epoch #131: loss=0.013510663753011812
Epoch #132: loss=0.02219679455913935
Epoch #133: loss=0.01792027682643256
Epoch #134: loss=0.025780931057740156
Epoch #135: loss=0.015675530142361324
Epoch #136: loss=0.019631415255182767
Epoch #137: loss=0.019561560794532504
Epoch #138: loss=0.03112081294952675
Epoch #139: loss=0.017322546329783046
Epoch #140: loss=0.019923515407821443
Epoch #141: loss=0.017129068637317786
Epoch #142: loss=0.015493787451781179
Epoch #143: loss=0.020925789243981804
Epoch #144: loss=0.019279731177622834
Epoch #145: loss=0.016568963631687764
Epoch #146: loss=0.01532439781155131
Epoch #147: loss=0.020389209595215445
Epoch #148: loss=0.023422272461753543
Epoch #149: loss=0.016129949629906413
Epoch #150: loss=0.014886003326184486
Epoch #151: loss=0.05622946159668547
Epoch #152: loss=0.026264029257764963
Epoch #153: loss=0.0122492282981474
Epoch #154: loss=0.013453312827216794
Epoch #155: loss=0.017162530010164243
Epoch #156: loss=0.02506233166284502
Epoch #157: loss=0.020292059475339134
Epoch #158: loss=0.01670689616361888
Epoch #159: loss=0.020932437766866426
Epoch #160: loss=0.01658887249873696
Epoch #161: loss=0.01746696690057583
Epoch #162: loss=0.01157280916741998
Epoch #163: loss=0.01630021521362336
Epoch #164: loss=0.012352292127715908
Epoch #165: loss=0.01511978290955957
Epoch #166: loss=0.018437283337259767
Epoch #167: loss=0.019227294652237978
Epoch #168: loss=0.014192065993189965
Epoch #169: loss=0.011977708071377767
Epoch #170: loss=0.014292460774575449
Epoch #171: loss=0.01844670382266137
Epoch #172: loss=0.02562806681404528
Epoch #173: loss=0.015573211846480861
Epoch #174: loss=0.014847695889997565
Epoch #175: loss=0.017672779831767387
Epoch #176: loss=0.019065741193401053
Epoch #177: loss=0.02018825407235641
Epoch #178: loss=0.010448696688917937
Epoch #179: loss=0.012071626215107892
Epoch #180: loss=0.015309276095709496
Epoch #181: loss=0.010493478482853851
Epoch #182: loss=0.02059797078613447
Epoch #183: loss=0.012854782525411718
Epoch #184: loss=0.019729919091731385
Epoch #185: loss=0.02340531271104127
Epoch #186: loss=0.02865518150876646
Epoch #187: loss=0.01224268668104754
Epoch #188: loss=0.014269431920447833
Epoch #189: loss=0.013907772751065762
Epoch #190: loss=0.011580157089158764
Epoch #191: loss=0.012666945904014912
Epoch #192: loss=0.019450909502195093
Epoch #193: loss=0.01049583311661542
Epoch #194: loss=0.020519564800085627
Epoch #195: loss=0.014882414782505916
Epoch #196: loss=0.015032774035552554
Epoch #197: loss=0.011399647415685787
Epoch #198: loss=0.01360105885454786
Epoch #199: loss=0.014232964196229634
Epoch #200: loss=0.020037646581297613
Epoch #201: loss=0.016892713458239013
Epoch #202: loss=0.009627255989311977
Epoch #203: loss=0.009859838608966515
Epoch #204: loss=0.008669121378525607
Epoch #205: loss=0.013597756317156456
Epoch #206: loss=0.010683502239089026
Epoch #207: loss=0.014808067607403132
Epoch #208: loss=0.025361264029307266
Epoch #209: loss=0.01673050377492423
Epoch #210: loss=0.013183408687273933
Epoch #211: loss=0.008636096499067705
Epoch #212: loss=0.018538299150133428
Epoch #213: loss=0.013569882150726674
Epoch #214: loss=0.01875505482886395
Epoch #215: loss=0.011323681813289972
Epoch #216: loss=0.020098889932795492
Epoch #217: loss=0.010890925879516856
Epoch #218: loss=0.013479342056942262
Epoch #219: loss=0.015080717198904732
Epoch #220: loss=0.015401642561542533
Epoch #221: loss=0.012506876105270412
Epoch #222: loss=0.03380976803281842
Epoch #223: loss=0.02062185886331949
Epoch #224: loss=0.011755614271562877
Epoch #225: loss=0.010451231503776236
Epoch #226: loss=0.025990628018697774
Epoch #227: loss=0.01010872602489879
Epoch #228: loss=0.013926215393848283
Epoch #229: loss=0.010079487000292243
Epoch #230: loss=0.011137018441413975
Epoch #231: loss=0.012897522561331854
Epoch #232: loss=0.013957312993373569
Epoch #233: loss=0.014487412801946908
Epoch #234: loss=0.01267892693245962
Epoch #235: loss=0.02223141335376717
Epoch #236: loss=0.024914175329318475
Epoch #237: loss=0.01340411840698822
Epoch #238: loss=0.009990201287421284
Epoch #239: loss=0.010160036850880117
Epoch #240: loss=0.014569963137571355
Epoch #241: loss=0.011668199223740511
Epoch #242: loss=0.013992207160391781
Epoch #243: loss=0.012958200993287466
Epoch #244: loss=0.020126065518308353
Epoch #245: loss=0.012429746589782865
Epoch #246: loss=0.018325471477774417
Epoch #247: loss=0.015600048604083235
Epoch #248: loss=0.009236361109173205
Epoch #249: loss=0.010506230023010214

Training time: 4:42:12.880751

Finished.
n2one setting etth2_ettm2_electricity_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm2_electricity_weather_epochs_250_seed_2023/model.pkl', muti_dataset='etth2_ettm2_electricity_weather', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.88976e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.88976e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.25588034578032876, 'MAE': 0.34374505694526075}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm2_electricity_exchange', random_seed=2023, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm2_electricity_exchange_epochs_250_seed_2023
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.669807051719094
Epoch #1: loss=0.7089318125495306
Epoch #2: loss=0.5201351921307594
Epoch #3: loss=0.42747003960849916
Epoch #4: loss=0.35505785760858904
Epoch #5: loss=0.30866401975367874
Epoch #6: loss=0.28373095927819053
Epoch #7: loss=0.24499180799173004
Epoch #8: loss=0.21873543523144653
Epoch #9: loss=0.21209155523381934
Epoch #10: loss=0.17696994450748482
Epoch #11: loss=0.1667173950898029
Epoch #12: loss=0.1742983092835726
Epoch #13: loss=0.14656549398532345
Epoch #14: loss=0.13281506838368237
Epoch #15: loss=0.13781347649134373
Epoch #16: loss=0.12067386794094566
Epoch #17: loss=0.10790689381896934
Epoch #18: loss=0.10787528217837257
Epoch #19: loss=0.10923846822865414
Epoch #20: loss=0.10492671270632005
Epoch #21: loss=0.08264414137309842
Epoch #22: loss=0.08629144098534536
Epoch #23: loss=0.08542905520025093
Epoch #24: loss=0.08899954417371526
Epoch #25: loss=0.07408098393369476
Epoch #26: loss=0.07527971164771605
Epoch #27: loss=0.0736084757077505
Epoch #28: loss=0.06258240905899007
Epoch #29: loss=0.06563292457171922
Epoch #30: loss=0.06895637940159148
Epoch #31: loss=0.05498137949598196
Epoch #32: loss=0.05781076524691168
Epoch #33: loss=0.045587195379401875
Epoch #34: loss=0.04918032694911257
Epoch #35: loss=0.06283712722575802
Epoch #36: loss=0.05078641546592224
Epoch #37: loss=0.04727301236929141
Epoch #38: loss=0.05355790540943679
Epoch #39: loss=0.05040800756095809
Epoch #40: loss=0.05237028247982757
Epoch #41: loss=0.05904276480546667
Epoch #42: loss=0.05214834843174439
Epoch #43: loss=0.048845233466819744
Epoch #44: loss=0.040768363341952135
Epoch #45: loss=0.037682832285804775
Epoch #46: loss=0.04600306397226105
Epoch #47: loss=0.0397921550370785
Epoch #48: loss=0.04656705411650262
Epoch #49: loss=0.03492857906155514
Epoch #50: loss=0.038976801484179084
Epoch #51: loss=0.035123231959990855
Epoch #52: loss=0.04210858675148016
Epoch #53: loss=0.04207664958579783
Epoch #54: loss=0.0346264618120803
Epoch #55: loss=0.04069813070832202
Epoch #56: loss=0.04018619147858043
Epoch #57: loss=0.03431167466779339
Epoch #58: loss=0.029438569896883985
Epoch #59: loss=0.030941640371416484
Epoch #60: loss=0.045640948416412905
Epoch #61: loss=0.03545197718360754
Epoch #62: loss=0.029215136882097537
Epoch #63: loss=0.038277489758534115
Epoch #64: loss=0.031439449838751805
Epoch #65: loss=0.040582262418401946
Epoch #66: loss=0.03219240897781986
Epoch #67: loss=0.03705308505774124
Epoch #68: loss=0.025596850273542922
Epoch #69: loss=0.025766211170676335
Epoch #70: loss=0.025562289434448906
Epoch #71: loss=0.034243859474141936
Epoch #72: loss=0.02978521178379891
Epoch #73: loss=0.022857563408099715
Epoch #74: loss=0.029815078052753845
Epoch #75: loss=0.03674992915076507
Epoch #76: loss=0.03462719695470819
Epoch #77: loss=0.0299331908369563
Epoch #78: loss=0.027902934454168093
Epoch #79: loss=0.030816334715416328
Epoch #80: loss=0.036126794592109684
Epoch #81: loss=0.03626336648816012
Epoch #82: loss=0.02574371476858983
Epoch #83: loss=0.04511493018738421
Epoch #84: loss=0.023042490983634156
Epoch #85: loss=0.01970196061788438
Epoch #86: loss=0.02142393767266059
Epoch #87: loss=0.029172665853206315
Epoch #88: loss=0.029930726338516095
Epoch #89: loss=0.04100444919217689
Epoch #90: loss=0.03903419946612903
Epoch #91: loss=0.02456046945716708
Epoch #92: loss=0.02793780323762114
Epoch #93: loss=0.022574457078762836
Epoch #94: loss=0.02498537443544023
Epoch #95: loss=0.023727756866048593
Epoch #96: loss=0.02576808445574984
Epoch #97: loss=0.019438690200960666
Epoch #98: loss=0.024405597117984457
Epoch #99: loss=0.02431980901168289
Epoch #100: loss=0.027788005396186963
Epoch #101: loss=0.03434892854571439
Epoch #102: loss=0.021145151604989528
Epoch #103: loss=0.02262712815932135
Epoch #104: loss=0.033175499402912555
Epoch #105: loss=0.024586881505042284
Epoch #106: loss=0.029787452827222505
Epoch #107: loss=0.02623780018224593
Epoch #108: loss=0.02385970737526102
Epoch #109: loss=0.030634849885497403
Epoch #110: loss=0.019832144073017414
Epoch #111: loss=0.016326724576779913
Epoch #112: loss=0.04014620160155927
Epoch #113: loss=0.026133938466221557
Epoch #114: loss=0.031099306331257678
Epoch #115: loss=0.021753548363006275
Epoch #116: loss=0.022807083486831647
Epoch #117: loss=0.017921320072634236
Epoch #118: loss=0.01810463668220953
Epoch #119: loss=0.02334401986554335
Epoch #120: loss=0.02163093095401742
Epoch #121: loss=0.02985870793880492
Epoch #122: loss=0.022618859048673792
Epoch #123: loss=0.020998578147911694
Epoch #124: loss=0.017705950141053712
Epoch #125: loss=0.029558210194537613
Epoch #126: loss=0.02283674557169937
Epoch #127: loss=0.019651479082737622
Epoch #128: loss=0.026199256881175064
Epoch #129: loss=0.02857100647560157
Epoch #130: loss=0.017589379572685304
Epoch #131: loss=0.01681458735345361
Epoch #132: loss=0.027938501060415618
Epoch #133: loss=0.014750764512585111
Epoch #134: loss=0.018529017100087836
Epoch #135: loss=0.02184014171375343
Epoch #136: loss=0.022773390306396038
Epoch #137: loss=0.0333915374326313
Epoch #138: loss=0.03896860889681167
Epoch #139: loss=0.02604353705103045
Epoch #140: loss=0.018044982738061526
Epoch #141: loss=0.024156695027313643
Epoch #142: loss=0.033327105720641535
Epoch #143: loss=0.029656710596157973
Epoch #144: loss=0.01636915349268008
Epoch #145: loss=0.01779528173499926
Epoch #146: loss=0.02025982635518434
Epoch #147: loss=0.01681062922345324
Epoch #148: loss=0.02016630015078991
Epoch #149: loss=0.018729312745626125
Epoch #150: loss=0.020425545909543995
Epoch #151: loss=0.01825089464017783
Epoch #152: loss=0.017413100684484366
Epoch #153: loss=0.02470858693921332
Epoch #154: loss=0.027518946198700937
Epoch #155: loss=0.02110507793678239
Epoch #156: loss=0.017817098561889743
Epoch #157: loss=0.03949511118594863
Epoch #158: loss=0.024837738823753536
Epoch #159: loss=0.02174008312408332
Epoch #160: loss=0.01594690073054064
Epoch #161: loss=0.022407782565324597
Epoch #162: loss=0.01851077125423188
Epoch #163: loss=0.019399856112700127
Epoch #164: loss=0.017569146878944886
Epoch #165: loss=0.015012226759349412
Epoch #166: loss=0.014896259051247739
Epoch #167: loss=0.024313720830203563
Epoch #168: loss=0.03597212271390467
Epoch #169: loss=0.03127206799319894
Epoch #170: loss=0.02151982151797197
Epoch #171: loss=0.010778093633882067
Epoch #172: loss=0.013984501848476388
Epoch #173: loss=0.01248293397501943
Epoch #174: loss=0.016553174315647137
Epoch #175: loss=0.021436643296073025
Epoch #176: loss=0.019981847071694075
Epoch #177: loss=0.018749992503893295
Epoch #178: loss=0.018070224393763035
Epoch #179: loss=0.015642394584647893
Epoch #180: loss=0.017565880514451862
Epoch #181: loss=0.01807192038232729
Epoch #182: loss=0.01992345748449775
Epoch #183: loss=0.01455844815361504
Epoch #184: loss=0.026057005300144973
Epoch #185: loss=0.02408623972623166
Epoch #186: loss=0.018654293247823327
Epoch #187: loss=0.025159551734366434
Epoch #188: loss=0.020549812591171713
Epoch #189: loss=0.020496355599498306
Epoch #190: loss=0.017754166201578978
Epoch #191: loss=0.01490150539101147
Epoch #192: loss=0.015267966553181012
Epoch #193: loss=0.016949888680520084
Epoch #194: loss=0.018215783458385586
Epoch #195: loss=0.01579616049445343
Epoch #196: loss=0.019395771954223373
Epoch #197: loss=0.015680796114837896
Epoch #198: loss=0.019407940818793986
Epoch #199: loss=0.020284589262100833
Epoch #200: loss=0.019429467129319776
Epoch #201: loss=0.018455567480345398
Epoch #202: loss=0.017184109737112263
Epoch #203: loss=0.012942287392135286
Epoch #204: loss=0.012551007880336104
Epoch #205: loss=0.028701043136046142
Epoch #206: loss=0.02501035699324269
Epoch #207: loss=0.01311844508787644
Epoch #208: loss=0.021768536124786398
Epoch #209: loss=0.04240327349612999
Epoch #210: loss=0.015408704815209664
Epoch #211: loss=0.012025171656682229
Epoch #212: loss=0.016196350789473256
Epoch #213: loss=0.019494714207346053
Epoch #214: loss=0.017491089211060917
Epoch #215: loss=0.014231844804510044
Epoch #216: loss=0.01701134919394908
Epoch #217: loss=0.012131363406920972
Epoch #218: loss=0.014078018489201158
Epoch #219: loss=0.010643279475498119
Epoch #220: loss=0.01315536757037701
Epoch #221: loss=0.016482135678984704
Epoch #222: loss=0.02205430705632722
Epoch #223: loss=0.01578454254278967
Epoch #224: loss=0.013412529632589385
Epoch #225: loss=0.019048737361859424
Epoch #226: loss=0.02032095592426034
Epoch #227: loss=0.013705753155155993
Epoch #228: loss=0.020108947056759637
Epoch #229: loss=0.016980540164698032
Epoch #230: loss=0.014264074955014807
Epoch #231: loss=0.017600530551669994
Epoch #232: loss=0.019717014804334843
Epoch #233: loss=0.024310739573375765
Epoch #234: loss=0.012105584435714462
Epoch #235: loss=0.015199205640455847
Epoch #236: loss=0.014953590358502798
Epoch #237: loss=0.013977693634037927
Epoch #238: loss=0.03403573633142766
Epoch #239: loss=0.022506029812266154
Epoch #240: loss=0.01947482723884636
Epoch #241: loss=0.017972548065676223
Epoch #242: loss=0.018329510517433145
Epoch #243: loss=0.01433745416500089
Epoch #244: loss=0.011371332260656576
Epoch #245: loss=0.02437066279773759
Epoch #246: loss=0.013890355891012654
Epoch #247: loss=0.012245104265881043
Epoch #248: loss=0.011968626662460088
Epoch #249: loss=0.013529276457026075

Training time: 4:28:22.325100

Finished.
n2one setting etth2_ettm2_electricity_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm2_electricity_exchange_epochs_250_seed_2023/model.pkl', muti_dataset='etth2_ettm2_electricity_exchange', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.07144e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.16517e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.63862e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.07144e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.5036192173504689, 'MAE': 0.5372736525433651}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm2_traffic_weather', random_seed=2023, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm2_traffic_weather_epochs_250_seed_2023
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.0441223472422585
Epoch #1: loss=0.4002135664093047
Epoch #2: loss=0.29798111433027596
Epoch #3: loss=0.22527457626483036
Epoch #4: loss=0.18133197915606677
Epoch #5: loss=0.14110015628337202
Epoch #6: loss=0.13811978627876204
Epoch #7: loss=0.11407661805994332
Epoch #8: loss=0.10566478611481998
Epoch #9: loss=0.08692458185118522
Epoch #10: loss=0.08265840504051208
Epoch #11: loss=0.07540375697704045
Epoch #12: loss=0.06816143711985687
Epoch #13: loss=0.06571913679967127
Epoch #14: loss=0.05960811879670876
Epoch #15: loss=0.05650177787373636
Epoch #16: loss=0.05291008857432465
Epoch #17: loss=0.04758902408941248
Epoch #18: loss=0.04578270706158978
Epoch #19: loss=0.04803936320722461
Epoch #20: loss=0.038260115286392914
Epoch #21: loss=0.04520214766970163
Epoch #22: loss=0.043694327339462144
Epoch #23: loss=0.04053452140643934
Epoch #24: loss=0.04250307443858048
Epoch #25: loss=0.03930781775737021
Epoch #26: loss=0.03482636932754441
Epoch #27: loss=0.029374132822673753
Epoch #28: loss=0.03295367069516195
Epoch #29: loss=0.03639294210591129
Epoch #30: loss=0.029449894168467116
Epoch #31: loss=0.031373311857878956
Epoch #32: loss=0.02674435755957759
Epoch #33: loss=0.03640082116594957
Epoch #34: loss=0.026965232414761908
Epoch #35: loss=0.02102578924982973
Epoch #36: loss=0.023012666304638944
Epoch #37: loss=0.03372193295047331
Epoch #38: loss=0.02380399392237956
Epoch #39: loss=0.022468300732998815
Epoch #40: loss=0.027022873609320097
Epoch #41: loss=0.03074884465774809
Epoch #42: loss=0.02442935602066146
Epoch #43: loss=0.03005316662536595
Epoch #44: loss=0.021835058454582706
Epoch #45: loss=0.020279627223126487
Epoch #46: loss=0.03005011797336261
Epoch #47: loss=0.018127405979885425
Epoch #48: loss=0.023658521546295816
Epoch #49: loss=0.019832831712798926
Epoch #50: loss=0.021618135711523833
Epoch #51: loss=0.01859410950144605
Epoch #52: loss=0.01971260008046755
Epoch #53: loss=0.02353088440354009
Epoch #54: loss=0.02271119338957152
Epoch #55: loss=0.02577333905858504
Epoch #56: loss=0.024397066098156797
Epoch #57: loss=0.019928544604401445
Epoch #58: loss=0.021355306281552446
Epoch #59: loss=0.017372641278568052
Epoch #60: loss=0.025421731814983143
Epoch #61: loss=0.02031488198036956
Epoch #62: loss=0.02163994511869267
Epoch #63: loss=0.017185283555864062
Epoch #64: loss=0.016994570240403566
Epoch #65: loss=0.017193121724747504
Epoch #66: loss=0.02145240375666497
Epoch #67: loss=0.01703457775887844
Epoch #68: loss=0.016313205007399446
Epoch #69: loss=0.020146699430303807
Epoch #70: loss=0.018814664923202527
Epoch #71: loss=0.01726904955953303
Epoch #72: loss=0.01665386778302312
Epoch #73: loss=0.02222993205559479
Epoch #74: loss=0.015707602481130064
Epoch #75: loss=0.04404015112101618
Epoch #76: loss=0.016068757529182628
Epoch #77: loss=0.023060883821683902
Epoch #78: loss=0.020613455897642744
Epoch #79: loss=0.016681534583422315
Epoch #80: loss=0.012306586989564215
Epoch #81: loss=0.021438541771573165
Epoch #82: loss=0.017778983010370005
Epoch #83: loss=0.020420001445363316
Epoch #84: loss=0.018829612924666485
Epoch #85: loss=0.016446266423906487
Epoch #86: loss=0.017382965091608752
Epoch #87: loss=0.024338234676303604
Epoch #88: loss=0.014414535508079663
Epoch #89: loss=0.020748003972824055
Epoch #90: loss=0.013496779813565318
Epoch #91: loss=0.02414482520878054
Epoch #92: loss=0.01565804859161635
Epoch #93: loss=0.023881829407597557
Epoch #94: loss=0.019116428167417605
Epoch #95: loss=0.01217410303571737
Epoch #96: loss=0.01975337981784672
Epoch #97: loss=0.018518580129949856
Epoch #98: loss=0.024916800725128332
Epoch #99: loss=0.014959481626193432
Epoch #100: loss=0.015329074869526007
Epoch #101: loss=0.014285883826602168
Epoch #102: loss=0.026483444455293034
Epoch #103: loss=0.025095118876248775
Epoch #104: loss=0.012709348050378383
Epoch #105: loss=0.015121892443332065
Epoch #106: loss=0.013743763435719045
Epoch #107: loss=0.021643679071492495
Epoch #108: loss=0.01762880028143117
Epoch #109: loss=0.012866112589566284
Epoch #110: loss=0.01684102339684325
Epoch #111: loss=0.010531410111243391
Epoch #112: loss=0.012469311281892366
Epoch #113: loss=0.015653799415408495
Epoch #114: loss=0.01693216886461448
Epoch #115: loss=0.01773758060659285
Epoch #116: loss=0.01681370922529666
Epoch #117: loss=0.020509989218589507
Epoch #118: loss=0.01580096427870351
Epoch #119: loss=0.01318142900747611
Epoch #120: loss=0.01963716252201579
Epoch #121: loss=0.010913482009454516
Epoch #122: loss=0.011358936153756759
Epoch #123: loss=0.014198711723570812
Epoch #124: loss=0.014418204916196786
Epoch #125: loss=0.015920657239415915
Epoch #126: loss=0.009375871289493187
Epoch #127: loss=0.025619132239443496
Epoch #128: loss=0.023643788651531876
Epoch #129: loss=0.016155234490461967
Epoch #130: loss=0.01941152761949105
Epoch #131: loss=0.011916959633369454
Epoch #132: loss=0.009838112992976964
Epoch #133: loss=0.01722957350278135
Epoch #134: loss=0.013268960872986282
Epoch #135: loss=0.01270777448779486
Epoch #136: loss=0.01623284699253699
Epoch #137: loss=0.012826373417659768
Epoch #138: loss=0.01488783736816668
Epoch #139: loss=0.014289438017625614
Epoch #140: loss=0.016085735759907942
Epoch #141: loss=0.01570751917460363
Epoch #142: loss=0.015407781599929338
Epoch #143: loss=0.02253636881307813
Epoch #144: loss=0.010191714702195655
Epoch #145: loss=0.013335250154280606
Epoch #146: loss=0.010768649326295595
Epoch #147: loss=0.012719673510752906
Epoch #148: loss=0.016754442038776886
Epoch #149: loss=0.010672138094410293
Epoch #150: loss=0.012788088505937451
Epoch #151: loss=0.012636826764980447
Epoch #152: loss=0.015460226414811274
Epoch #153: loss=0.011303582558402983
Epoch #154: loss=0.01299428629858723
Epoch #155: loss=0.013127630419311398
Epoch #156: loss=0.016191855268028646
Epoch #157: loss=0.01977130180893843
Epoch #158: loss=0.01678232038495137
Epoch #159: loss=0.01253072767174724
Epoch #160: loss=0.011878357721456926
Epoch #161: loss=0.011044666396869525
Epoch #162: loss=0.029806222339556758
Epoch #163: loss=0.011916587013366044
Epoch #164: loss=0.010755030329887361
Epoch #165: loss=0.01265883329714724
Epoch #166: loss=0.01168176865509185
Epoch #167: loss=0.017725006739529793
Epoch #168: loss=0.02038364347700589
Epoch #169: loss=0.024384985318565207
Epoch #170: loss=0.009492882672191297
Epoch #171: loss=0.01203322171508057
Epoch #172: loss=0.013009285137223254
Epoch #173: loss=0.012077226832060726
Epoch #174: loss=0.014313723589049521
Epoch #175: loss=0.010197006925688692
Epoch #176: loss=0.015339511569302064
Epoch #177: loss=0.009098481977455136
Epoch #178: loss=0.012746733343893011
Epoch #179: loss=0.012136225891720363
Epoch #180: loss=0.017239706350568703
Epoch #181: loss=0.01099505530678059
Epoch #182: loss=0.012028911960646989
Epoch #183: loss=0.012188243426537505
Epoch #184: loss=0.013144528347958767
Epoch #185: loss=0.009540845506916298
Epoch #186: loss=0.011726890871062039
Epoch #187: loss=0.01731041370314483
Epoch #188: loss=0.01774758598716787
Epoch #189: loss=0.015182396806054389
Epoch #190: loss=0.009614060850986553
Epoch #191: loss=0.009997314203035977
Epoch #192: loss=0.01250671204318941
Epoch #193: loss=0.007877084375569847
Epoch #194: loss=0.014288680558828518
Epoch #195: loss=0.010644351946286114
Epoch #196: loss=0.015479259728633945
Epoch #197: loss=0.013657235152270053
Epoch #198: loss=0.009162453131865998
Epoch #199: loss=0.0145740706190453
Epoch #200: loss=0.00856194172826648
Epoch #201: loss=0.017679663856791216
Epoch #202: loss=0.01111969137079559
Epoch #203: loss=0.015881586801319816
Epoch #204: loss=0.01742533127484698
Epoch #205: loss=0.009783799447546863
Epoch #206: loss=0.018794850129996495
Epoch #207: loss=0.008754697818554235
Epoch #208: loss=0.008470694962043467
Epoch #209: loss=0.012282792342339475
Epoch #210: loss=0.016348414895851753
Epoch #211: loss=0.009505222725794264
Epoch #212: loss=0.014411583708966188
Epoch #213: loss=0.013399042696494811
Epoch #214: loss=0.012170096623951443
Epoch #215: loss=0.010168362350652696
Epoch #216: loss=0.01036474816041133
Epoch #217: loss=0.009749320097699752
Epoch #218: loss=0.01348805180220108
Epoch #219: loss=0.009815932789660819
Epoch #220: loss=0.014322262410120634
Epoch #221: loss=0.01039396579293254
Epoch #222: loss=0.011630896732505877
Epoch #223: loss=0.01528088955140429
Epoch #224: loss=0.017062304544327604
Epoch #225: loss=0.008331578627966163
Epoch #226: loss=0.011868576857242213
Epoch #227: loss=0.010667426124317021
Epoch #228: loss=0.010174803002987383
Epoch #229: loss=0.01034686591544648
Epoch #230: loss=0.014242693633474584
Epoch #231: loss=0.011787153977393064
Epoch #232: loss=0.011727995937489367
Epoch #233: loss=0.01554531803396767
Epoch #234: loss=0.015501141115518341
Epoch #235: loss=0.010696299842559572
Epoch #236: loss=0.010548072828386733
Epoch #237: loss=0.024004597665464363
Epoch #238: loss=0.009670307962187909
Epoch #239: loss=0.007729542024093618
Epoch #240: loss=0.013049625837979462
Epoch #241: loss=0.013191149226551985
Epoch #242: loss=0.008740059516523584
Epoch #243: loss=0.013353065875502536
Epoch #244: loss=0.011127331329053592
Epoch #245: loss=0.009732385978680135
Epoch #246: loss=0.007929974334287498
Epoch #247: loss=0.008621910176748968
Epoch #248: loss=0.010868421316973194
Epoch #249: loss=0.012504993994527154

Training time: 10:04:21.270198

Finished.
n2one setting etth2_ettm2_traffic_weather -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm2_traffic_weather_epochs_250_seed_2023/model.pkl', muti_dataset='etth2_ettm2_traffic_weather', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.64636e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.80814e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.4382e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.64636e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.41013472185658195, 'MAE': 0.45718805462504125}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm2_traffic_weather -> exchange
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm2_traffic_weather_epochs_250_seed_2023/model.pkl', muti_dataset='etth2_ettm2_traffic_weather', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='exchange')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.8378e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.23523551298301515, 'MAE': 0.330811185186977}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm2_traffic_exchange', random_seed=2023, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm2_traffic_exchange_epochs_250_seed_2023
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=1.003086655274839
Epoch #1: loss=0.38195781874562706
Epoch #2: loss=0.2772302051402024
Epoch #3: loss=0.21243953556745304
Epoch #4: loss=0.17185831628739834
Epoch #5: loss=0.13535431617250046
Epoch #6: loss=0.12248628844112695
Epoch #7: loss=0.10454593068680952
Epoch #8: loss=0.09515939377613265
Epoch #9: loss=0.08314923798195548
Epoch #10: loss=0.07462263572489138
Epoch #11: loss=0.06516855969125204
Epoch #12: loss=0.0667005224475377
Epoch #13: loss=0.05998706076239647
Epoch #14: loss=0.05868804862597949
Epoch #15: loss=0.05366576594659253
Epoch #16: loss=0.05063613457447925
Epoch #17: loss=0.05322513979115536
Epoch #18: loss=0.046468247046750795
Epoch #19: loss=0.056002567141518196
Epoch #20: loss=0.04608638834120152
Epoch #21: loss=0.04417250267526781
Epoch #22: loss=0.04096296783652039
Epoch #23: loss=0.043138919415231375
Epoch #24: loss=0.0387273049552302
Epoch #25: loss=0.039531869299894384
Epoch #26: loss=0.036810831426116346
Epoch #27: loss=0.04262911802868837
Epoch #28: loss=0.04234790935879573
Epoch #29: loss=0.029503127427610173
Epoch #30: loss=0.03199895678843458
Epoch #31: loss=0.034750243306982224
Epoch #32: loss=0.036314923024022124
Epoch #33: loss=0.028177698757284455
Epoch #34: loss=0.028017407038819615
Epoch #35: loss=0.03011841280077771
Epoch #36: loss=0.026340408455727302
Epoch #37: loss=0.02843126515228079
Epoch #38: loss=0.033874982044057235
Epoch #39: loss=0.03804271274251782
Epoch #40: loss=0.026406858699710364
Epoch #41: loss=0.02724714135809598
Epoch #42: loss=0.023976862933203526
Epoch #43: loss=0.03774196429678652
Epoch #44: loss=0.024373070463322644
Epoch #45: loss=0.02883256227754713
Epoch #46: loss=0.02569869791720218
Epoch #47: loss=0.02619258499068999
Epoch #48: loss=0.028487549171693098
Epoch #49: loss=0.032062674552435055
Epoch #50: loss=0.021256230040733924
Epoch #51: loss=0.02649935700062522
Epoch #52: loss=0.02110217898531643
Epoch #53: loss=0.024866981307953923
Epoch #54: loss=0.024493009744325826
Epoch #55: loss=0.02812208752899047
Epoch #56: loss=0.02209140512842406
Epoch #57: loss=0.01897557858781609
Epoch #58: loss=0.023208675358661026
Epoch #59: loss=0.023781954358947498
Epoch #60: loss=0.01753540702109374
Epoch #61: loss=0.02314448640154788
Epoch #62: loss=0.02395409706907624
Epoch #63: loss=0.026644716948204725
Epoch #64: loss=0.01705787806005557
Epoch #65: loss=0.01950922401543344
Epoch #66: loss=0.025250589037429425
Epoch #67: loss=0.025278851787768397
Epoch #68: loss=0.017271066521848174
Epoch #69: loss=0.025089497635243797
Epoch #70: loss=0.02122804963912606
Epoch #71: loss=0.022333342796562582
Epoch #72: loss=0.019795219814900396
Epoch #73: loss=0.02055262673008025
Epoch #74: loss=0.024788145618282492
Epoch #75: loss=0.02235542990272914
Epoch #76: loss=0.01715393568385709
Epoch #77: loss=0.019093497776666808
Epoch #78: loss=0.028968307675231616
Epoch #79: loss=0.017262597476793737
Epoch #80: loss=0.01898776693466258
Epoch #81: loss=0.016257165486414114
Epoch #82: loss=0.020895783066743542
Epoch #83: loss=0.014724357631223995
Epoch #84: loss=0.022066746764516917
Epoch #85: loss=0.01615268460588046
Epoch #86: loss=0.015996497771403804
Epoch #87: loss=0.017046642538401567
Epoch #88: loss=0.015239693261334265
Epoch #89: loss=0.022381334710246906
Epoch #90: loss=0.02193219086896263
Epoch #91: loss=0.013210806913529933
Epoch #92: loss=0.01950730060890966
Epoch #93: loss=0.015263154895856624
Epoch #94: loss=0.019350684947320597
Epoch #95: loss=0.014347456101146433
Epoch #96: loss=0.017354713842963124
Epoch #97: loss=0.017145286877863115
Epoch #98: loss=0.0233138312865809
Epoch #99: loss=0.017234123103785474
Epoch #100: loss=0.014356590903041358
Epoch #101: loss=0.01717511533681793
Epoch #102: loss=0.018291463167557382
Epoch #103: loss=0.02025753258996767
Epoch #104: loss=0.013935299161915339
Epoch #105: loss=0.023600791695096157
Epoch #106: loss=0.020291972599151702
Epoch #107: loss=0.012356814869211096
Epoch #108: loss=0.012195562305531165
Epoch #109: loss=0.016439988620710017
Epoch #110: loss=0.021026854592622973
Epoch #111: loss=0.013507311238418543
Epoch #112: loss=0.014084893886746129
Epoch #113: loss=0.016936626904098702
Epoch #114: loss=0.018580273019127874
Epoch #115: loss=0.01595559117006954
Epoch #116: loss=0.022629605985465796
Epoch #117: loss=0.01662183627912954
Epoch #118: loss=0.012533317364261722
Epoch #119: loss=0.019495628460447792
Epoch #120: loss=0.012840989405712872
Epoch #121: loss=0.012131257513714331
Epoch #122: loss=0.016978555235615565
Epoch #123: loss=0.02243388599931718
Epoch #124: loss=0.014553372735446811
Epoch #125: loss=0.01431034370575248
Epoch #126: loss=0.01611777078145318
Epoch #127: loss=0.02016065918261931
Epoch #128: loss=0.01445710200078047
Epoch #129: loss=0.01308833692005997
Epoch #130: loss=0.016298417589119332
Epoch #131: loss=0.014518387196526542
Epoch #132: loss=0.011841102271687673
Epoch #133: loss=0.01746627989367069
Epoch #134: loss=0.012955675674396564
Epoch #135: loss=0.014952385282536066
Epoch #136: loss=0.013337027972050459
Epoch #137: loss=0.013485813733102594
Epoch #138: loss=0.020375924962626503
Epoch #139: loss=0.014637524262693373
Epoch #140: loss=0.013395987375547478
Epoch #141: loss=0.015073899620842936
Epoch #142: loss=0.013584902939721753
Epoch #143: loss=0.011620825455244264
Epoch #144: loss=0.017531307865217904
Epoch #145: loss=0.012420691291153743
Epoch #146: loss=0.029160797316377808
Epoch #147: loss=0.011131870897860698
Epoch #148: loss=0.013430726011712387
Epoch #149: loss=0.014620176005550305
Epoch #150: loss=0.020065946612990333
Epoch #151: loss=0.015279817557441405
Epoch #152: loss=0.01434501744963429
Epoch #153: loss=0.01673524516586399
Epoch #154: loss=0.009794304165159308
Epoch #155: loss=0.010059155618020324
Epoch #156: loss=0.019369233119619935
Epoch #157: loss=0.014576868773384287
Epoch #158: loss=0.013621331297317001
Epoch #159: loss=0.019737918669036573
Epoch #160: loss=0.015844164556370856
Epoch #161: loss=0.015476302749153252
Epoch #162: loss=0.012208352962310577
Epoch #163: loss=0.010980464392811907
Epoch #164: loss=0.013410287950735126
Epoch #165: loss=0.01030843561556639
Epoch #166: loss=0.013859044866769985
Epoch #167: loss=0.01565406250849084
Epoch #168: loss=0.015872552389467002
Epoch #169: loss=0.01015644540441556
Epoch #170: loss=0.011082293534330732
Epoch #171: loss=0.015641165160739726
Epoch #172: loss=0.014918915460388694
Epoch #173: loss=0.014966886469771559
Epoch #174: loss=0.01876806252376965
Epoch #175: loss=0.01843612081355385
Epoch #176: loss=0.013191968880762631
Epoch #177: loss=0.012907071576469083
Epoch #178: loss=0.013709815612438015
Epoch #179: loss=0.010066057232465895
Epoch #180: loss=0.016983645776178433
Epoch #181: loss=0.015167220408001994
Epoch #182: loss=0.011181460532194857
Epoch #183: loss=0.01200771136974983
Epoch #184: loss=0.010440285743358004
Epoch #185: loss=0.013746950743814785
Epoch #186: loss=0.009806712313769134
Epoch #187: loss=0.019152168461562372
Epoch #188: loss=0.014357372205398991
Epoch #189: loss=0.011808928896219161
Epoch #190: loss=0.013134449828801013
Epoch #191: loss=0.009555153729665975
Epoch #192: loss=0.010266864880618455
Epoch #193: loss=0.01556975602746919
Epoch #194: loss=0.012710983705645803
Epoch #195: loss=0.023092964884707325
Epoch #196: loss=0.010181809116794931
Epoch #197: loss=0.01415528217215864
Epoch #198: loss=0.015408415748900374
Epoch #199: loss=0.011473514133261208
Epoch #200: loss=0.014032920836004312
Epoch #201: loss=0.00978249941610622
Epoch #202: loss=0.011644471874556198
Epoch #203: loss=0.01412935636671882
Epoch #204: loss=0.013029415947007569
Epoch #205: loss=0.01239382136735183
Epoch #206: loss=0.012520308859739662
Epoch #207: loss=0.010601060810782853
Epoch #208: loss=0.012410821766090588
Epoch #209: loss=0.017563552460292276
Epoch #210: loss=0.011435683923139607
Epoch #211: loss=0.012417848481860134
Epoch #212: loss=0.012356247180054328
Epoch #213: loss=0.011521201322007523
Epoch #214: loss=0.013457960201649586
Epoch #215: loss=0.011883445379197353
Epoch #216: loss=0.00947668955435605
Epoch #217: loss=0.014608337282068631
Epoch #218: loss=0.00828080977951866
Epoch #219: loss=0.010066669217210162
Epoch #220: loss=0.012877335084815533
Epoch #221: loss=0.01221932817606029
Epoch #222: loss=0.009561192749839261
Epoch #223: loss=0.013803290888071395
Epoch #224: loss=0.019812210317501047
Epoch #225: loss=0.02035423814450533
Epoch #226: loss=0.010850855112686724
Epoch #227: loss=0.008682713824577854
Epoch #228: loss=0.007660115390183467
Epoch #229: loss=0.021486859844010615
Epoch #230: loss=0.012101182187679287
Epoch #231: loss=0.01033073110769905
Epoch #232: loss=0.010831512054079081
Epoch #233: loss=0.009586092593983742
Epoch #234: loss=0.012188571279792185
Epoch #235: loss=0.009534342836805326
Epoch #236: loss=0.010729151300479358
Epoch #237: loss=0.006490333366398543
Epoch #238: loss=0.010516910244601801
Epoch #239: loss=0.01343290117992191
Epoch #240: loss=0.010241299677865164
Epoch #241: loss=0.012330272295232364
Epoch #242: loss=0.012515466162316902
Epoch #243: loss=0.014634258775635038
Epoch #244: loss=0.01157811915542986
Epoch #245: loss=0.009901083004716621
Epoch #246: loss=0.007189207814811091
Epoch #247: loss=0.01315616536377494
Epoch #248: loss=0.013353553525621054
Epoch #249: loss=0.01685535861910106

Training time: 9:34:30.614379

Finished.
n2one setting etth2_ettm2_traffic_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm2_traffic_exchange_epochs_250_seed_2023/model.pkl', muti_dataset='etth2_ettm2_traffic_exchange', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.96723e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.94721e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.8156e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.96723e-09): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4077030902593533, 'MAE': 0.45528334216628563}
Finished.
------------------------- record done -------------------------
n2one setting etth2_ettm2_traffic_exchange -> weather
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm2_traffic_exchange_epochs_250_seed_2023/model.pkl', muti_dataset='etth2_ettm2_traffic_exchange', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='weather')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.00014e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.08095e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.13254e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.00014e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.4799444287213032, 'MAE': 0.5062128937642087}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_ettm2_weather_exchange', random_seed=2023, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_ettm2_weather_exchange_epochs_250_seed_2023
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=4.024878575251653
Epoch #1: loss=2.693242703492825
Epoch #2: loss=2.1846834398232975
Epoch #3: loss=2.084680133141004
Epoch #4: loss=1.914577236542335
Epoch #5: loss=1.7349442209188755
Epoch #6: loss=1.6401844758253832
Epoch #7: loss=1.4927315322252421
Epoch #8: loss=1.3783467205671163
Epoch #9: loss=1.3424064494096315
Epoch #10: loss=1.2315805382453477
Epoch #11: loss=1.2259741952786078
Epoch #12: loss=1.109539033128665
Epoch #13: loss=1.0504386906440442
Epoch #14: loss=0.9775389432907104
Epoch #15: loss=1.01814910196341
Epoch #16: loss=1.0144546249738107
Epoch #17: loss=0.9503654218637027
Epoch #18: loss=0.8948127203262769
Epoch #19: loss=0.945027496952277
Epoch #20: loss=0.9528744495832003
Epoch #21: loss=0.8643248551166974
Epoch #22: loss=0.8773804719631488
Epoch #23: loss=0.7917593006904309
Epoch #24: loss=0.8990112015834222
Epoch #25: loss=0.7211659779915442
Epoch #26: loss=0.744753516637362
Epoch #27: loss=0.7281424397459397
Epoch #28: loss=0.6898769638859309
Epoch #29: loss=0.6954491104070957
Epoch #30: loss=0.6566957688102355
Epoch #31: loss=0.651652023769342
Epoch #32: loss=0.6934074409879171
Epoch #33: loss=0.6642668287341411
Epoch #34: loss=0.6351823227909895
Epoch #35: loss=0.5557261739785855
Epoch #36: loss=0.5292609328260789
Epoch #37: loss=0.5957607477903366
Epoch #38: loss=0.5171210777301055
Epoch #39: loss=0.5374016945178692
Epoch #40: loss=0.5287703986351306
Epoch #41: loss=0.4936508352939899
Epoch #42: loss=0.5397612647368357
Epoch #43: loss=0.5037538953698598
Epoch #44: loss=0.548409525018472
Epoch #45: loss=0.5779448862259204
Epoch #46: loss=0.5242715655611112
Epoch #47: loss=0.5273683873506693
Epoch #48: loss=0.5113699946265954
Epoch #49: loss=0.4287885046349122
Epoch #50: loss=0.415177651322805
Epoch #51: loss=0.3996103019095384
Epoch #52: loss=0.4056890497987087
Epoch #53: loss=0.34434662701991886
Epoch #54: loss=0.3936390830920293
Epoch #55: loss=0.413089034649042
Epoch #56: loss=0.38072114896315795
Epoch #57: loss=0.3979122329216737
Epoch #58: loss=0.40685615602594155
Epoch #59: loss=0.4269065080353847
Epoch #60: loss=0.43681276646944195
Epoch #61: loss=0.3505887807561801
Epoch #62: loss=0.42104316789370316
Epoch #63: loss=0.37239332783680695
Epoch #64: loss=0.36973565659270835
Epoch #65: loss=0.37266342241603595
Epoch #66: loss=0.33646199923868364
Epoch #67: loss=0.33282696226468456
Epoch #68: loss=0.3666433130319302
Epoch #69: loss=0.33712937066761345
Epoch #70: loss=0.37313892047565717
Epoch #71: loss=0.30877758691517204
Epoch #72: loss=0.36276667206906354
Epoch #73: loss=0.2830293083993288
Epoch #74: loss=0.24846643094833082
Epoch #75: loss=0.27308920512978846
Epoch #76: loss=0.3043833595628922
Epoch #77: loss=0.2832051287763394
Epoch #78: loss=0.28695616885446584
Epoch #79: loss=0.25307174772024155
Epoch #80: loss=0.26642630277917934
Epoch #81: loss=0.2601351710752799
Epoch #82: loss=0.22622492293325755
Epoch #83: loss=0.2315820504266482
Epoch #84: loss=0.2775641672599774
Epoch #85: loss=0.23339696722821549
Epoch #86: loss=0.2007403105783921
Epoch #87: loss=0.2667589455556411
Epoch #88: loss=0.307720589523132
Epoch #89: loss=0.25429764934457266
Epoch #90: loss=0.28119421800455224
Epoch #91: loss=0.2578724599085175
Epoch #92: loss=0.2709671866435271
Epoch #93: loss=0.23657363173193657
Epoch #94: loss=0.2140292895671267
Epoch #95: loss=0.21693493705242872
Epoch #96: loss=0.2501228845033508
Epoch #97: loss=0.28880568486280167
Epoch #98: loss=0.5321366262550538
Epoch #99: loss=0.28935045619996697
Epoch #100: loss=0.2501639471604274
Epoch #101: loss=0.20063671756249207
Epoch #102: loss=0.1970576258519521
Epoch #103: loss=0.2439752506951873
Epoch #104: loss=0.25594470413545
Epoch #105: loss=0.24120216021457544
Epoch #106: loss=0.3003984500582402
Epoch #107: loss=0.20219738960552675
Epoch #108: loss=0.22587112946292529
Epoch #109: loss=0.20774986731031767
Epoch #110: loss=0.1636623993086127
Epoch #111: loss=0.16076464893726203
Epoch #112: loss=0.16404101059127313
Epoch #113: loss=0.15306418883399323
Epoch #114: loss=0.18709508150529403
Epoch #115: loss=0.18693362076122028
Epoch #116: loss=0.22238313779234886
Epoch #117: loss=0.18648402063319316
Epoch #118: loss=0.15650986242466247
Epoch #119: loss=0.20227712607727602
Epoch #120: loss=0.21504538642385831
Epoch #121: loss=0.18688761335439408
Epoch #122: loss=0.2729426726985436
Epoch #123: loss=0.20024394587828562
Epoch #124: loss=0.14689547640199846
Epoch #125: loss=0.19714423204557255
Epoch #126: loss=0.17609731838680232
Epoch #127: loss=0.1355177076676717
Epoch #128: loss=0.17462096649866837
Epoch #129: loss=0.14884152281312987
Epoch #130: loss=0.1263358236577075
Epoch #131: loss=0.15437415303089297
Epoch #132: loss=0.15359932646298638
Epoch #133: loss=0.15118495296113765
Epoch #134: loss=0.1514711411168369
Epoch #135: loss=0.1591816532353942
Epoch #136: loss=0.12493331719619724
Epoch #137: loss=0.13758698084320015
Epoch #138: loss=0.15694487324127784
Epoch #139: loss=0.15005795897629398
Epoch #140: loss=0.12009249262225169
Epoch #141: loss=0.13382912516737214
Epoch #142: loss=0.1474754620128526
Epoch #143: loss=0.14271438555218852
Epoch #144: loss=0.12342759537009093
Epoch #145: loss=0.14990102331368968
Epoch #146: loss=0.1248328977336104
Epoch #147: loss=0.12885494945714107
Epoch #148: loss=0.1363970348611474
Epoch #149: loss=0.10645328553465123
Epoch #150: loss=0.14130118045096213
Epoch #151: loss=0.12765861306196222
Epoch #152: loss=0.13723445024627906
Epoch #153: loss=0.0952008253751466
Epoch #154: loss=0.11018429764618094
Epoch #155: loss=0.12747136048542765
Epoch #156: loss=0.12396619648027879
Epoch #157: loss=0.11668405531404111
Epoch #158: loss=0.12537561894322818
Epoch #159: loss=0.16749011990256035
Epoch #160: loss=0.13021095727498716
Epoch #161: loss=0.17680009074795705
Epoch #162: loss=0.1498913953009133
Epoch #163: loss=0.17496522465864053
Epoch #164: loss=0.19365132478280708
Epoch #165: loss=0.18495206402328151
Epoch #166: loss=0.1655984357572519
Epoch #167: loss=0.1349295458684747
Epoch #168: loss=0.1081632227780154
Epoch #169: loss=0.10341724628009476
Epoch #170: loss=0.10416898991052921
Epoch #171: loss=0.10526257602927777
Epoch #172: loss=0.08325381193739864
Epoch #173: loss=0.1446173589748259
Epoch #174: loss=0.15070948133674952
Epoch #175: loss=0.12110524381009433
Epoch #176: loss=0.11786942889627355
Epoch #177: loss=0.10154310821627195
Epoch #178: loss=0.1195657373083612
Epoch #179: loss=0.13111132043055618
Epoch #180: loss=0.1111208453702812
Epoch #181: loss=0.11085906646286066
Epoch #182: loss=0.12543847128892174
Epoch #183: loss=0.11922480939672543
Epoch #184: loss=0.09631324251397298
Epoch #185: loss=0.08763722613310584
Epoch #186: loss=0.1039228864157429
Epoch #187: loss=0.10637565972641684
Epoch #188: loss=0.10252142355490762
Epoch #189: loss=0.10038803270659767
Epoch #190: loss=0.10513327199106033
Epoch #191: loss=0.09241313997727747
Epoch #192: loss=0.10175029879722458
Epoch #193: loss=0.13498807361779305
Epoch #194: loss=0.1087619609092004
Epoch #195: loss=0.11490253624148093
Epoch #196: loss=0.11736196564295544
Epoch #197: loss=0.1011059400267326
Epoch #198: loss=0.12735609187243077
Epoch #199: loss=0.12470560209252514
Epoch #200: loss=0.12179814053412813
Epoch #201: loss=0.09548818298543875
Epoch #202: loss=0.10832840686019224
Epoch #203: loss=0.11121359893765587
Epoch #204: loss=0.12175332826490586
Epoch #205: loss=0.1344942465926019
Epoch #206: loss=0.11979868354347463
Epoch #207: loss=0.07639084579064868
Epoch #208: loss=0.12355831682753678
Epoch #209: loss=0.095844919148546
Epoch #210: loss=0.0937696413960881
Epoch #211: loss=0.07970847488524249
Epoch #212: loss=0.10986730214566566
Epoch #213: loss=0.1146802931594161
Epoch #214: loss=0.07573210313701285
Epoch #215: loss=0.07795971544244541
Epoch #216: loss=0.11251953457338879
Epoch #217: loss=0.07023208579406716
Epoch #218: loss=0.11788950944677569
Epoch #219: loss=0.15552267493106997
Epoch #220: loss=0.24429621522386485
Epoch #221: loss=0.11686848644883586
Epoch #222: loss=0.09918327199725005
Epoch #223: loss=0.15300857963470313
Epoch #224: loss=0.1539930967040933
Epoch #225: loss=0.10172665359165806
Epoch #226: loss=0.18184728666137046
Epoch #227: loss=0.19092079144544327
Epoch #228: loss=0.12664239298408994
Epoch #229: loss=0.10426842089957343
Epoch #230: loss=0.15113878156989813
Epoch #231: loss=0.1340776677064311
Epoch #232: loss=0.10984769519060276
Epoch #233: loss=0.0938586823713894
Epoch #234: loss=0.08532440911333722
Epoch #235: loss=0.1033918115740212
Epoch #236: loss=0.07362019856317112
Epoch #237: loss=0.13771101891492996
Epoch #238: loss=0.09545738747916542
Epoch #239: loss=0.07174856749434884
Epoch #240: loss=0.0778717679114869
Epoch #241: loss=0.16173308226279914
Epoch #242: loss=0.11209704777082571
Epoch #243: loss=0.11369378769841905
Epoch #244: loss=0.10677033150568604
Epoch #245: loss=0.07826544496660623
Epoch #246: loss=0.08971251966431737
Epoch #247: loss=0.09384239291270766
Epoch #248: loss=0.10991688264318956
Epoch #249: loss=0.08791172409501787

Training time: 0:43:51.942607

Finished.
n2one setting etth2_ettm2_weather_exchange -> electricity
Dataset: ETTh1
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=None, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.001, max_threads=None, max_train_length=3000, model_name='TS2vec', model_path='./training/etth2_ettm2_weather_exchange_epochs_250_seed_2023/model.pkl', muti_dataset='etth2_ettm2_weather_exchange', random_seed=2023, record=1, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None, target='electricity')
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.48853e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.92631e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
/home/yupengz/anaconda3/envs/TimesNet/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.48853e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T
Evaluation result: {'MSE': 0.39957873179950737, 'MAE': 0.4393058523328514}
Finished.
------------------------- record done -------------------------
Arguments: Namespace(batch_size=8, dataset='ETTh1', epochs=250, eval=False, gpu=4, irregular=0, iters=None, loader='forecast_csv', lr=0.0003, max_threads=None, max_train_length=3000, muti_dataset='etth2_electricity_traffic_weather', random_seed=2023, repr_dims=320, run_name='forecast_multivar', save_every=None, seed=None)
training/etth2_electricity_traffic_weather_epochs_250_seed_2023
Loading data... /home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
/home/yupengz/ts2vec/datautils.py:136: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)
  dt.weekofyear.to_numpy(),
done
Epoch #0: loss=0.8257438053842634
Epoch #1: loss=0.33082708277077855
Epoch #2: loss=0.22097935688093698
Epoch #3: loss=0.16313486449163114
Epoch #4: loss=0.1242079207302978
Epoch #5: loss=0.10312091578855057
Epoch #6: loss=0.08595507441005841
Epoch #7: loss=0.07776393780123296
Epoch #8: loss=0.06987407346720206
Epoch #9: loss=0.05906672978361664
Epoch #10: loss=0.06150155440551125
Epoch #11: loss=0.05551009251920684
Epoch #12: loss=0.05304695116922774
Epoch #13: loss=0.045607950791140627
Epoch #14: loss=0.0417743389862153
Epoch #15: loss=0.03828045328727488
Epoch #16: loss=0.03641860483395775
Epoch #17: loss=0.03431991005852883
Epoch #18: loss=0.03246669051599096
Epoch #19: loss=0.03605798454392291
Epoch #20: loss=0.033068651919261595
Epoch #21: loss=0.03098148553678919
Epoch #22: loss=0.03699034752495017
Epoch #23: loss=0.026116519113920253
Epoch #24: loss=0.041152993702780805
Epoch #25: loss=0.026606670413217983
Epoch #26: loss=0.02989102489989723
Epoch #27: loss=0.025901577210980145
Epoch #28: loss=0.024818903771933708
Epoch #29: loss=0.025339253883909185
Epoch #30: loss=0.025082270942412402
Epoch #31: loss=0.02257255405186841
Epoch #32: loss=0.02088295767871865
Epoch #33: loss=0.02175394728419633
Epoch #34: loss=0.022803372427317396
Epoch #35: loss=0.020011520034418744
Epoch #36: loss=0.018472281967277876
Epoch #37: loss=0.026642654741863225
Epoch #38: loss=0.0201813380166593
Epoch #39: loss=0.023080647728611917
Epoch #40: loss=0.02339518670291191
Epoch #41: loss=0.02825750048372069
Epoch #42: loss=0.02507697568087583
Epoch #43: loss=0.028210571017074183
Epoch #44: loss=0.013569053176291547
Epoch #45: loss=0.022610843161242213
Epoch #46: loss=0.023171091876544158
Epoch #47: loss=0.022286919987508508
Epoch #48: loss=0.01584189137898456
Epoch #49: loss=0.02129613696242335
Epoch #50: loss=0.02073521992571458
Epoch #51: loss=0.026091938766009997
Epoch #52: loss=0.025510047264943797
Epoch #53: loss=0.022196159494749162
Epoch #54: loss=0.014619225197293417
Epoch #55: loss=0.018385333146732973
Epoch #56: loss=0.01789016265011493
Epoch #57: loss=0.020914205738695034
Epoch #58: loss=0.01677131876979394
Epoch #59: loss=0.01657295220152982
Epoch #60: loss=0.015925121846500565
Epoch #61: loss=0.02126486238227555
Epoch #62: loss=0.01797259624657655
Epoch #63: loss=0.018457460753971214
Epoch #64: loss=0.018709503315078205
Epoch #65: loss=0.018264702557261397
Epoch #66: loss=0.013773115976403605
Epoch #67: loss=0.015156369432989586
Epoch #68: loss=0.020160184253463262
Epoch #69: loss=0.024246447748761345
Epoch #70: loss=0.026978041101971797
Epoch #71: loss=0.01480805951505796
Epoch #72: loss=0.01878588996456337
Epoch #73: loss=0.014362809080610436
Epoch #74: loss=0.016466360355910804
Epoch #75: loss=0.01480312818229753
Epoch #76: loss=0.02108585697988019
Epoch #77: loss=0.017335994567355028
Epoch #78: loss=0.013157673820118313
Epoch #79: loss=0.017172838322470563
Epoch #80: loss=0.01229693597800681
Epoch #81: loss=0.016135671054048305
Epoch #82: loss=0.014480415680186286
Epoch #83: loss=0.016178253207901828
Epoch #84: loss=0.013497554442748975
Epoch #85: loss=0.014208026878493814
Epoch #86: loss=0.016800474618895878
Epoch #87: loss=0.013319062246906517
Epoch #88: loss=0.013291334700002872
Epoch #89: loss=0.011441528686358842
Epoch #90: loss=0.021287607421359815
Epoch #91: loss=0.025258929923893447
Epoch #92: loss=0.016004782669609228
Epoch #93: loss=0.014349774626943576
Epoch #94: loss=0.010544300155719324
Epoch #95: loss=0.01944860150438456
Epoch #96: loss=0.017110888685405563
Epoch #97: loss=0.01788455874516091
Epoch #98: loss=0.010977267660707998
Epoch #99: loss=0.01419666713627521
Epoch #100: loss=0.016705227710728746
Epoch #101: loss=0.012060882161114549
Epoch #102: loss=0.013340801794530116
Epoch #103: loss=0.01509439594447988
Epoch #104: loss=0.014002163216326536
Epoch #105: loss=0.01269908563382447
Epoch #106: loss=0.014305548218209495
Epoch #107: loss=0.01869857034447657
Epoch #108: loss=0.01722428287198933
Epoch #109: loss=0.013599715647507381
Epoch #110: loss=0.01425609557961587
Epoch #111: loss=0.0185242532862192
Epoch #112: loss=0.010996921713836184
Epoch #113: loss=0.018617877359546536
Epoch #114: loss=0.013421588582691345
Epoch #115: loss=0.01269656929068668
Epoch #116: loss=0.014749038224420618
Epoch #117: loss=0.013799750516047999
Epoch #118: loss=0.014230889583646595
Epoch #119: loss=0.010906468201555023
Epoch #120: loss=0.013371585560403451
Epoch #121: loss=0.010600885727473192
Epoch #122: loss=0.019339834595424883
Epoch #123: loss=0.012648176906315717
Epoch #124: loss=0.009681598426979576
Epoch #125: loss=0.019759493840698077
Epoch #126: loss=0.010928398179681895
Epoch #127: loss=0.009513998877058552
Epoch #128: loss=0.015419791206448664
Epoch #129: loss=0.011078001823462776
Epoch #130: loss=0.008641865963711911
Epoch #131: loss=0.0122222318923856
Epoch #132: loss=0.00895849975622516
Epoch #133: loss=0.016560451886179134
Epoch #134: loss=0.011726048219483537
